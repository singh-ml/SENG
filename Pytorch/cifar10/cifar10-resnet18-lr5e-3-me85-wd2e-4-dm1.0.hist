Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7648076288 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4350     46.740  1.7534    34.850  24.61
   2   1.2014     56.740  1.3375    51.040  46.78
   3   1.0233     63.390  1.1296    59.136  69.00
   4   0.9358     66.690  0.9786    64.960  91.22
   5   0.8248     70.750  0.8782    68.792  113.43
   6   0.7842     72.130  0.7966    71.764  135.65
   7   0.7269     74.600  0.7333    74.112  157.87
   8   0.6553     77.040  0.6742    76.162  180.10
   9   0.6353     77.850  0.6283    78.032  202.42
  10   0.5929     79.560  0.5873    79.380  224.58
  11   0.5818     79.660  0.5531    80.658  246.75
  12   0.5863     80.110  0.5181    81.690  268.95
  13   0.5540     81.080  0.4953    82.614  291.16
  14   0.5074     81.920  0.4635    83.838  313.38
  15   0.5053     83.150  0.4408    84.580  335.53
  16   0.5093     82.440  0.4211    85.520  357.73
  17   0.4854     83.350  0.3983    86.330  379.93
  18   0.4734     83.980  0.3831    86.514  402.13
  19   0.4651     83.900  0.3691    87.214  424.36
  20   0.4698     84.710  0.3541    87.572  446.53
  21   0.5001     83.450  0.3391    88.130  468.75
  22   0.4410     85.090  0.3215    88.692  490.95
  23   0.4660     84.950  0.3090    89.136  513.13
  24   0.4397     85.550  0.2967    89.694  535.27
  25   0.4397     85.610  0.2827    90.216  557.47
  26   0.4372     86.190  0.2741    90.502  579.69
  27   0.4496     85.700  0.2598    90.746  601.85
  28   0.4683     85.750  0.2527    91.204  624.03
  29   0.4457     86.340  0.2432    91.472  646.18
  30   0.4285     86.570  0.2344    91.744  668.35
  31   0.4308     86.350  0.2233    92.246  690.58
  32   0.4366     86.570  0.2141    92.506  712.81
  33   0.4535     86.660  0.2081    92.632  735.01
  34   0.4483     86.570  0.1996    93.024  757.20
  35   0.4514     86.710  0.1890    93.396  779.39
  36   0.4503     86.580  0.1818    93.620  801.57
  37   0.4161     87.420  0.1770    93.826  823.73
  38   0.4429     87.330  0.1670    94.068  845.93
  39   0.4354     87.570  0.1618    94.390  868.17
  40   0.4257     87.620  0.1521    94.634  890.35
  41   0.4710     86.620  0.1437    94.882  912.59
  42   0.4693     87.270  0.1412    95.000  934.77
  43   0.4477     87.580  0.1329    95.308  956.95
  44   0.4410     87.830  0.1294    95.414  979.09
  45   0.4447     87.580  0.1250    95.666  1001.31
  46   0.4512     87.520  0.1163    95.920  1023.48
  47   0.4454     87.830  0.1162    95.914  1045.72
  48   0.4769     87.440  0.1065    96.262  1067.90
  49   0.4629     87.660  0.1047    96.266  1090.06
  50   0.4521     88.140  0.1019    96.430  1112.06
  51   0.4636     87.770  0.1009    96.540  1134.27
  52   0.4638     87.970  0.0902    96.826  1156.51
  53   0.4545     88.270  0.0858    97.038  1178.75
  54   0.4499     88.250  0.0793    97.302  1200.91
  55   0.4879     87.860  0.0767    97.422  1223.15
  56   0.4689     88.390  0.0780    97.386  1245.30
  57   0.4567     88.800  0.0721    97.618  1267.48
  58   0.4768     88.600  0.0665    97.686  1289.65
  59   0.4747     88.670  0.0632    97.802  1311.83
  60   0.4872     88.490  0.0607    98.014  1334.00
  61   0.4779     88.350  0.0573    98.120  1356.24
  62   0.4798     88.700  0.0558    98.122  1378.45
  63   0.4916     88.190  0.0489    98.456  1400.65
  64   0.5022     88.260  0.0496    98.324  1422.80
  65   0.4923     88.730  0.0483    98.428  1445.03
  66   0.4942     88.400  0.0463    98.506  1467.19
  67   0.4906     88.620  0.0473    98.430  1489.36
  68   0.4995     88.650  0.0430    98.542  1511.54
  69   0.5035     88.440  0.0417    98.660  1533.78
  70   0.5026     88.780  0.0388    98.766  1555.98
  71   0.5124     88.450  0.0384    98.778  1578.18
  72   0.5010     88.950  0.0370    98.766  1600.36
  73   0.5301     88.460  0.0347    98.964  1622.52
  74   0.5083     88.820  0.0341    98.958  1644.78
  75   0.5119     88.520  0.0327    98.986  1666.95
  76   0.5139     88.730  0.0310    99.054  1689.14
  77   0.5143     88.450  0.0307    99.092  1711.34
  78   0.5201     88.960  0.0300    99.160  1733.62
  79   0.5145     88.820  0.0296    99.042  1755.79
  80   0.5141     88.680  0.0290    99.118  1777.94
  81   0.5198     88.890  0.0281    99.140  1800.12
  82   0.5276     89.010  0.0259    99.216  1822.32
  83   0.5214     88.910  0.0257    99.218  1844.54
  84   0.5312     88.740  0.0253    99.300  1866.82
  85   0.5259     88.920  0.0260    99.210  1889.04
