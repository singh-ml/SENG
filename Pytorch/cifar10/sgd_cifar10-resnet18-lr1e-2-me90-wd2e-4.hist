Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4340     47.410  1.6697    37.638  21.97
   2   1.1305     58.970  1.2519    54.610  41.92
   3   1.0078     65.390  1.0224    63.206  61.84
   4   0.9126     69.250  0.8761    68.780  81.76
   5   0.8340     70.990  0.7682    72.918  101.74
   6   0.7015     76.140  0.6850    76.070  121.71
   7   0.7478     75.080  0.6187    78.376  141.67
   8   0.6305     78.980  0.5638    80.290  161.62
   9   0.7019     77.800  0.5352    81.156  181.61
  10   0.5724     81.060  0.4943    82.530  201.56
  11   0.6138     79.900  0.4592    83.928  221.48
  12   0.6214     79.900  0.4281    85.294  241.42
  13   0.5611     81.740  0.4025    86.036  261.40
  14   0.4896     83.870  0.3816    86.640  281.34
  15   0.4833     83.980  0.3575    87.508  301.28
  16   0.7131     78.830  0.3406    88.190  321.22
  17   0.4905     84.100  0.3165    88.864  341.14
  18   0.4759     84.860  0.3076    89.202  361.13
  19   0.5520     82.680  0.2911    89.714  381.02
  20   0.5143     83.920  0.2800    90.398  400.94
  21   0.4641     85.760  0.2596    91.022  420.86
  22   0.4826     85.260  0.2454    91.332  440.79
  23   0.4717     85.560  0.2372    91.598  460.72
  24   0.4310     87.300  0.2225    92.042  480.66
  25   0.4910     85.230  0.2091    92.554  500.61
  26   0.5438     84.780  0.2002    92.974  520.50
  27   0.4574     86.150  0.1932    93.154  540.43
  28   0.5140     85.180  0.1819    93.530  560.36
  29   0.4227     87.170  0.1757    93.732  580.33
  30   0.5195     85.740  0.1627    94.282  600.28
  31   0.4919     86.300  0.1511    94.798  620.20
  32   0.4801     86.700  0.1445    94.922  640.15
  33   0.4726     87.000  0.1360    95.192  660.10
  34   0.4529     87.740  0.1224    95.672  680.02
  35   0.4722     87.280  0.1189    95.800  699.97
  36   0.4897     87.100  0.1113    96.100  719.88
  37   0.4362     88.420  0.1090    96.080  739.78
  38   0.5538     86.060  0.0949    96.614  759.75
  39   0.4320     88.840  0.0984    96.450  779.73
  40   0.4566     88.180  0.0871    97.002  799.66
  41   0.5266     86.830  0.0870    96.922  819.52
  42   0.4721     88.500  0.0805    97.252  839.45
  43   0.4462     88.530  0.0747    97.370  859.42
  44   0.4540     88.490  0.0691    97.630  879.34
  45   0.4673     88.640  0.0617    97.928  899.26
  46   0.4584     88.880  0.0573    97.996  919.19
  47   0.4362     89.250  0.0528    98.212  939.16
  48   0.4792     88.790  0.0517    98.254  959.09
  49   0.4473     89.680  0.0507    98.298  978.99
  50   0.4679     89.580  0.0426    98.598  998.90
  51   0.4694     89.170  0.0410    98.672  1018.81
  52   0.4391     89.950  0.0364    98.798  1038.75
  53   0.4484     89.760  0.0349    98.930  1058.64
  54   0.4976     89.370  0.0317    98.978  1078.62
  55   0.4683     89.620  0.0283    99.126  1098.53
  56   0.4680     89.850  0.0270    99.168  1118.51
  57   0.4538     90.140  0.0264    99.218  1138.43
  58   0.4794     89.640  0.0258    99.228  1158.35
  59   0.4580     90.110  0.0234    99.310  1178.26
  60   0.4700     90.050  0.0207    99.410  1198.19
  61   0.4729     90.090  0.0195    99.444  1218.11
  62   0.4590     89.940  0.0184    99.468  1238.07
  63   0.4466     90.430  0.0176    99.480  1257.93
  64   0.4520     90.310  0.0152    99.596  1277.85
  65   0.4774     90.300  0.0160    99.574  1297.76
  66   0.4776     90.360  0.0151    99.564  1317.68
  67   0.4652     90.270  0.0143    99.608  1337.61
  68   0.4663     90.330  0.0125    99.682  1357.61
  69   0.4577     90.470  0.0120    99.722  1377.52
  70   0.4600     90.450  0.0104    99.754  1397.44
  71   0.4650     90.390  0.0106    99.756  1417.36
  72   0.4589     90.610  0.0098    99.784  1437.29
  73   0.4589     90.310  0.0096    99.778  1457.26
  74   0.4734     90.260  0.0092    99.792  1477.25
  75   0.4679     90.550  0.0091    99.760  1497.20
  76   0.4673     90.830  0.0086    99.834  1517.16
  77   0.4687     90.610  0.0081    99.814  1537.07
  78   0.4675     90.410  0.0082    99.826  1557.03
  79   0.4682     90.440  0.0080    99.830  1576.97
  80   0.4685     90.520  0.0076    99.842  1596.93
  81   0.4658     90.610  0.0075    99.828  1616.88
  82   0.4638     90.650  0.0070    99.858  1636.84
  83   0.4586     90.730  0.0066    99.872  1656.72
  84   0.4624     90.790  0.0065    99.874  1676.67
  85   0.4713     90.670  0.0067    99.858  1696.60
  86   0.4719     90.710  0.0065    99.876  1716.55
  87   0.4755     90.640  0.0061    99.894  1736.52
  88   0.4714     90.590  0.0062    99.882  1756.46
  89   0.4732     90.650  0.0059    99.884  1776.40
  90   0.4754     90.480  0.0062    99.904  1796.33
