Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3277     51.310  1.5430    43.028  22.32
   2   1.1607     58.270  1.1806    57.232  42.56
   3   0.9250     67.150  0.9673    65.398  62.77
   4   0.8567     69.760  0.8222    70.612  82.97
   5   0.6848     76.180  0.7176    74.652  103.18
   6   0.6496     77.160  0.6351    77.818  123.40
   7   0.6206     78.610  0.5690    80.208  143.63
   8   0.6107     78.990  0.5206    81.742  163.86
   9   0.5403     81.330  0.4853    83.036  184.10
  10   0.5160     82.310  0.4445    84.528  204.29
  11   0.5189     82.800  0.4103    85.662  224.51
  12   0.4745     84.440  0.3802    86.756  244.71
  13   0.5047     83.580  0.3631    87.168  264.92
  14   0.5265     83.130  0.3480    87.868  285.13
  15   0.4857     84.710  0.3194    88.922  305.35
  16   0.4903     83.830  0.3003    89.446  325.61
  17   0.4593     84.950  0.2824    90.128  345.80
  18   0.4509     85.430  0.2710    90.616  365.98
  19   0.4314     86.210  0.2583    90.890  386.19
  20   0.4261     87.040  0.2487    91.384  406.40
  21   0.4339     86.450  0.2331    91.982  426.64
  22   0.4259     86.720  0.2165    92.408  446.84
  23   0.4443     86.930  0.2039    92.836  467.07
  24   0.4213     87.300  0.2004    92.914  487.31
  25   0.4388     86.900  0.1940    93.198  507.53
  26   0.4327     87.790  0.1824    93.554  527.78
  27   0.4286     87.420  0.1657    94.092  547.98
  28   0.4297     87.400  0.1589    94.372  568.21
  29   0.4339     87.820  0.1507    94.766  588.40
  30   0.4202     87.950  0.1443    94.810  608.65
  31   0.4486     87.470  0.1331    95.298  628.82
  32   0.4297     87.730  0.1311    95.442  649.05
  33   0.4020     88.620  0.1320    95.314  669.29
  34   0.4537     87.410  0.1304    95.428  689.49
  35   0.4364     88.670  0.1172    95.942  709.70
  36   0.4331     88.000  0.1198    95.852  729.93
  37   0.4152     88.430  0.1152    95.890  750.12
  38   0.4285     88.480  0.1076    96.296  770.35
  39   0.4177     88.630  0.0998    96.466  790.57
  40   0.4011     89.110  0.1001    96.438  810.80
  41   0.4593     87.900  0.0973    96.494  831.00
  42   0.4365     88.130  0.0967    96.648  851.25
  43   0.4478     88.420  0.0961    96.526  871.47
  44   0.4229     89.060  0.0969    96.530  891.68
  45   0.4056     89.440  0.0824    97.152  911.87
  46   0.4208     89.440  0.0776    97.240  932.13
  47   0.4755     88.450  0.0797    97.118  952.34
  48   0.4372     88.550  0.0770    97.292  972.54
  49   0.4406     88.820  0.0753    97.382  992.80
  50   0.4457     89.120  0.0736    97.394  1013.04
  51   0.4748     88.790  0.0723    97.460  1033.27
  52   0.4174     89.450  0.0695    97.622  1053.50
  53   0.4338     89.830  0.0660    97.678  1073.77
  54   0.4620     88.700  0.0665    97.676  1094.01
  55   0.4102     89.910  0.0668    97.704  1114.26
  56   0.4468     89.260  0.0599    97.846  1134.44
  57   0.4716     89.070  0.0683    97.660  1154.70
  58   0.4327     89.460  0.0659    97.696  1174.93
  59   0.4123     89.880  0.0580    97.956  1195.13
  60   0.4481     89.100  0.0575    98.026  1215.35
  61   0.4783     89.160  0.0633    97.804  1235.63
  62   0.4387     89.750  0.0608    97.866  1255.87
  63   0.4402     89.620  0.0538    98.194  1276.09
  64   0.4350     89.780  0.0542    98.096  1296.28
  65   0.4419     89.860  0.0530    98.200  1316.45
  66   0.4905     88.690  0.0523    98.142  1336.68
  67   0.4556     89.490  0.0538    98.140  1356.88
  68   0.4603     89.610  0.0502    98.200  1377.12
  69   0.4534     89.560  0.0546    98.114  1397.33
  70   0.4623     89.680  0.0518    98.200  1417.55
  71   0.4447     89.700  0.0473    98.382  1437.74
  72   0.4524     89.670  0.0503    98.240  1457.96
  73   0.4476     89.680  0.0494    98.278  1478.20
  74   0.4472     89.890  0.0467    98.358  1498.40
  75   0.4405     89.930  0.0450    98.442  1518.62
  76   0.4676     89.230  0.0453    98.414  1538.83
  77   0.4468     89.900  0.0489    98.318  1559.05
  78   0.4413     89.960  0.0479    98.382  1579.25
  79   0.4277     90.280  0.0450    98.422  1599.46
  80   0.4414     89.830  0.0452    98.514  1619.66
  81   0.4570     90.080  0.0496    98.294  1639.84
  82   0.4324     90.240  0.0438    98.484  1660.07
  83   0.4316     90.380  0.0390    98.652  1680.31
  84   0.4882     89.240  0.0402    98.582  1700.51
  85   0.4604     90.020  0.0459    98.362  1720.77
