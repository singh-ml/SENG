Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6674     35.380  1.9441    28.270  22.08
   2   1.4141     48.080  1.4770    45.454  42.40
   3   1.1883     57.320  1.2512    54.338  62.73
   4   1.0932     61.320  1.0530    62.376  83.01
   5   0.9412     66.110  0.9351    66.750  103.30
   6   1.1552     61.660  0.8509    69.998  123.65
   7   0.8777     69.520  0.7710    73.030  143.91
   8   0.7401     74.140  0.7103    74.806  164.18
   9   0.7062     75.990  0.6596    77.130  184.46
  10   0.7120     75.410  0.6242    78.284  204.76
  11   0.6583     77.200  0.6038    79.106  225.07
  12   0.6543     77.940  0.5824    79.840  245.31
  13   0.5868     79.840  0.5665    80.364  265.57
  14   0.6701     77.720  0.5505    81.094  285.82
  15   0.6236     79.170  0.5475    81.212  306.08
  16   0.5879     79.740  0.5363    81.556  326.38
  17   0.5873     80.330  0.5257    81.890  346.65
  18   0.5752     80.380  0.5153    82.270  366.95
  19   0.6078     79.360  0.5058    82.488  387.21
  20   0.5679     80.250  0.5066    82.550  407.47
  21   0.5789     80.250  0.5008    82.718  427.77
  22   0.5475     81.340  0.4992    82.750  448.06
  23   0.5457     81.580  0.4931    83.038  468.31
  24   0.6800     78.430  0.4809    83.336  488.62
  25   0.5613     81.070  0.4807    83.548  508.92
  26   0.5902     79.880  0.4797    83.384  529.23
  27   0.6647     78.070  0.4780    83.612  549.52
  28   0.5282     82.630  0.4759    83.568  569.79
  29   0.5425     82.100  0.4691    83.820  590.02
  30   0.5294     81.880  0.4676    83.824  610.29
  31   0.5011     82.780  0.4662    84.030  630.54
  32   0.6259     78.970  0.4573    84.134  650.77
  33   0.5230     82.260  0.4643    84.164  671.11
  34   0.5561     80.910  0.4684    83.852  691.42
  35   0.6203     79.870  0.4613    84.344  711.65
  36   0.5867     79.910  0.4568    84.316  731.92
  37   0.5312     82.220  0.4588    84.216  752.16
  38   0.5623     81.470  0.4466    84.686  772.41
  39   0.6185     79.410  0.4565    84.128  792.72
  40   0.5907     79.880  0.4470    84.820  812.96
  41   0.5208     83.140  0.4523    84.464  833.25
  42   0.5133     82.620  0.4546    84.562  853.52
  43   0.5181     82.310  0.4505    84.388  873.79
  44   0.5396     81.700  0.4424    84.800  894.06
  45   0.5270     81.960  0.4429    84.706  914.34
  46   0.5394     81.640  0.4440    84.748  934.60
  47   0.5247     82.330  0.4411    84.776  954.84
  48   0.5550     81.170  0.4430    84.724  975.13
  49   0.6093     79.890  0.4401    84.760  995.40
  50   0.5468     81.520  0.4456    84.714  1015.77
  51   0.5014     82.760  0.4362    85.172  1036.05
  52   0.5291     82.210  0.4349    85.012  1056.37
  53   0.5139     83.030  0.4357    84.920  1076.67
  54   0.5672     81.320  0.4374    84.960  1096.96
  55   0.4976     82.780  0.4369    84.948  1117.26
  56   0.4884     83.960  0.4296    85.252  1137.56
  57   0.4989     82.840  0.4299    85.088  1157.84
  58   0.5107     82.660  0.4271    85.276  1178.15
  59   0.4645     84.260  0.4328    85.056  1198.41
  60   0.5217     82.910  0.4269    85.364  1218.74
  61   0.4968     83.270  0.4265    85.336  1238.98
  62   0.4893     83.210  0.4241    85.418  1259.27
  63   0.5615     81.720  0.4334    85.110  1279.55
  64   0.5116     83.020  0.4256    85.420  1299.82
  65   0.5430     82.050  0.4227    85.524  1320.03
  66   0.4744     84.220  0.4284    85.202  1340.36
  67   0.5193     82.980  0.4236    85.318  1360.63
  68   0.5028     83.240  0.4253    85.362  1380.94
  69   0.5209     82.770  0.4244    85.132  1401.21
  70   0.5742     81.850  0.4189    85.366  1421.48
  71   0.4904     83.480  0.4290    85.252  1441.74
  72   0.5131     83.020  0.4217    85.394  1462.02
  73   0.5146     82.520  0.4237    85.454  1482.28
  74   0.5161     82.670  0.4175    85.590  1502.52
  75   0.5107     82.760  0.4211    85.702  1522.77
  76   0.4928     83.420  0.4198    85.534  1543.02
  77   0.6110     79.740  0.4183    85.604  1563.27
  78   0.5487     81.960  0.4214    85.472  1583.53
  79   0.5757     81.190  0.4238    85.494  1603.85
  80   0.4944     82.820  0.4202    85.724  1624.11
  81   0.5289     82.250  0.4156    85.710  1644.35
  82   0.5291     82.610  0.4119    85.814  1664.66
  83   0.4943     83.300  0.4151    85.772  1684.90
  84   0.4714     84.180  0.4221    85.568  1705.13
  85   0.5338     82.350  0.4143    85.746  1725.35
  86   0.5677     81.510  0.4145    85.650  1745.63
  87   0.4816     83.770  0.4217    85.462  1765.87
  88   0.4764     84.070  0.4182    85.836  1786.14
  89   0.5355     82.050  0.4200    85.558  1806.38
  90   0.4876     83.930  0.4183    85.524  1826.68
