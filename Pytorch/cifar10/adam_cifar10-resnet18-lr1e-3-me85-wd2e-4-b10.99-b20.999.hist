Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3268     50.880  1.5315    43.290  22.17
   2   1.0587     62.360  1.1504    58.274  42.43
   3   0.9745     65.480  0.9454    66.146  62.72
   4   0.7541     73.550  0.8181    71.024  83.04
   5   0.7599     73.630  0.7099    74.808  103.29
   6   0.6666     77.220  0.6344    77.810  123.58
   7   0.5938     79.750  0.5637    80.618  143.83
   8   0.5844     80.820  0.5234    82.006  164.13
   9   0.5312     81.900  0.4794    83.520  184.41
  10   0.5234     82.850  0.4447    84.786  204.66
  11   0.4807     83.860  0.4233    85.364  224.97
  12   0.4401     85.040  0.3959    86.364  245.22
  13   0.4384     85.160  0.3812    86.828  265.45
  14   0.4642     84.370  0.3576    87.654  285.68
  15   0.4046     86.390  0.3369    88.540  305.90
  16   0.4501     85.020  0.3156    89.150  326.12
  17   0.4101     86.260  0.3064    89.464  346.43
  18   0.4004     86.900  0.2949    89.896  366.68
  19   0.3878     87.040  0.2776    90.472  386.92
  20   0.3766     87.900  0.2643    91.094  407.21
  21   0.4155     86.980  0.2598    91.196  427.51
  22   0.3668     88.560  0.2542    91.328  447.75
  23   0.3766     87.700  0.2345    91.968  468.09
  24   0.3741     88.350  0.2251    92.118  488.37
  25   0.3601     88.820  0.2175    92.554  508.72
  26   0.3529     89.010  0.2114    92.740  529.02
  27   0.3614     88.670  0.2063    92.920  549.33
  28   0.3303     89.530  0.2008    93.054  569.61
  29   0.3350     89.570  0.1951    93.252  589.86
  30   0.3457     89.290  0.1949    93.316  610.15
  31   0.3283     89.890  0.1854    93.664  630.44
  32   0.3385     89.470  0.1846    93.754  650.74
  33   0.3831     88.850  0.1774    93.994  671.00
  34   0.3538     89.500  0.1729    94.026  691.29
  35   0.3360     89.860  0.1712    94.182  711.56
  36   0.3683     89.430  0.1602    94.490  731.82
  37   0.3438     89.750  0.1641    94.358  752.08
  38   0.3578     89.730  0.1562    94.546  772.38
  39   0.3605     89.840  0.1539    94.684  792.61
  40   0.3273     90.180  0.1549    94.632  812.86
  41   0.3297     90.240  0.1502    94.818  833.11
  42   0.3377     90.140  0.1464    94.912  853.41
  43   0.3557     89.300  0.1461    94.842  873.66
  44   0.3663     89.340  0.1492    94.792  893.91
  45   0.3306     90.560  0.1404    95.186  914.17
  46   0.3499     90.130  0.1363    95.270  934.46
  47   0.3640     90.180  0.1336    95.338  954.73
  48   0.3408     90.560  0.1399    95.150  975.03
  49   0.3651     90.320  0.1301    95.554  995.34
  50   0.3360     90.570  0.1341    95.360  1015.58
  51   0.3225     90.630  0.1298    95.530  1036.00
  52   0.3563     90.180  0.1283    95.458  1056.27
  53   0.3315     90.520  0.1151    96.006  1076.51
  54   0.3800     89.780  0.1278    95.616  1096.74
  55   0.3286     91.280  0.1228    95.848  1116.98
  56   0.3379     90.610  0.1209    95.792  1137.21
  57   0.3439     89.970  0.1277    95.532  1157.50
  58   0.3159     90.960  0.1168    95.886  1177.74
  59   0.3173     91.160  0.1162    95.986  1198.00
  60   0.3426     90.320  0.1128    96.144  1218.22
  61   0.3533     90.270  0.1212    95.852  1238.42
  62   0.3495     90.980  0.1199    95.776  1258.67
  63   0.3330     90.810  0.1093    96.244  1278.94
  64   0.3263     90.880  0.1090    96.292  1299.18
  65   0.3618     90.530  0.1088    96.264  1319.47
  66   0.3511     90.400  0.1123    96.226  1339.71
  67   0.3556     90.380  0.1145    96.016  1359.93
  68   0.3352     91.180  0.1045    96.420  1380.19
  69   0.3649     90.590  0.1072    96.238  1400.42
  70   0.3276     90.670  0.1040    96.436  1420.63
  71   0.3390     90.650  0.1063    96.346  1440.88
  72   0.3633     90.260  0.1050    96.350  1461.15
  73   0.3637     90.660  0.1098    96.190  1481.41
  74   0.3625     90.600  0.1085    96.244  1501.75
  75   0.3304     90.850  0.1015    96.520  1522.03
  76   0.3388     90.610  0.1078    96.314  1542.29
  77   0.3343     91.100  0.0999    96.554  1562.56
  78   0.3288     91.330  0.1050    96.444  1582.84
  79   0.3472     90.750  0.1015    96.524  1603.07
  80   0.3301     91.210  0.1022    96.440  1623.30
  81   0.3603     90.900  0.1013    96.532  1643.54
  82   0.3420     90.840  0.0983    96.588  1663.79
  83   0.3388     91.230  0.1031    96.478  1684.03
  84   0.3495     90.900  0.0983    96.666  1704.31
  85   0.3424     90.910  0.0950    96.680  1724.52
