Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2612     54.340  1.4697    46.226  22.18
   2   1.0075     65.210  1.0529    62.344  42.46
   3   0.8286     71.110  0.8618    69.440  62.69
   4   0.8452     71.130  0.7245    74.570  82.94
   5   0.7173     75.490  0.6367    77.540  103.23
   6   0.8473     72.390  0.5729    80.132  123.49
   7   0.6442     77.800  0.5247    81.762  143.77
   8   0.5801     80.170  0.4820    83.194  164.01
   9   0.5225     82.440  0.4487    84.424  184.30
  10   0.5517     81.590  0.4180    85.452  204.55
  11   0.5917     80.830  0.3883    86.608  224.77
  12   0.5553     82.060  0.3634    87.250  245.03
  13   0.5439     82.860  0.3445    87.968  265.30
  14   0.4894     83.720  0.3221    88.760  285.55
  15   0.4948     84.200  0.3036    89.484  305.79
  16   0.5809     82.030  0.2869    89.956  326.01
  17   0.4494     85.980  0.2756    90.264  346.30
  18   0.4743     85.050  0.2599    90.882  366.55
  19   0.4529     86.030  0.2398    91.688  386.77
  20   0.4743     85.230  0.2327    91.992  407.02
  21   0.4245     86.680  0.2177    92.298  427.31
  22   0.5594     83.780  0.2093    92.668  447.53
  23   0.4955     85.230  0.2034    92.820  467.80
  24   0.4988     85.270  0.1982    93.004  488.05
  25   0.4595     86.200  0.1804    93.740  508.30
  26   0.4292     86.460  0.1791    93.758  528.56
  27   0.4324     87.590  0.1686    94.082  548.78
  28   0.3929     88.130  0.1624    94.388  569.00
  29   0.4219     87.760  0.1539    94.674  589.23
  30   0.4503     87.070  0.1492    94.860  609.49
  31   0.4593     87.090  0.1457    94.952  629.73
  32   0.5265     85.480  0.1318    95.376  649.97
  33   0.4518     87.150  0.1319    95.448  670.21
  34   0.4693     87.270  0.1290    95.476  690.48
  35   0.5246     85.940  0.1230    95.674  710.76
  36   0.4232     87.950  0.1193    95.826  731.03
  37   0.4402     87.790  0.1128    96.078  751.30
  38   0.5979     84.250  0.1105    96.262  771.57
  39   0.4429     87.620  0.1047    96.294  791.82
  40   0.3951     88.750  0.1061    96.368  812.06
  41   0.4277     88.390  0.0998    96.550  832.32
  42   0.4087     89.050  0.0991    96.556  852.56
  43   0.5184     86.410  0.0911    96.702  872.87
  44   0.4673     87.460  0.0921    96.778  893.12
  45   0.4858     87.360  0.0865    97.004  913.37
  46   0.4506     88.150  0.0900    96.890  933.62
  47   0.4521     88.340  0.0852    97.108  953.88
  48   0.5015     87.400  0.0833    97.148  974.13
  49   0.4780     88.150  0.0838    97.102  994.41
  50   0.5328     87.170  0.0788    97.226  1014.64
  51   0.4599     88.220  0.0753    97.336  1034.84
  52   0.4876     87.900  0.0705    97.556  1055.08
  53   0.4878     88.120  0.0750    97.336  1075.38
  54   0.5626     86.760  0.0712    97.474  1095.64
  55   0.4225     89.310  0.0757    97.374  1115.87
  56   0.4135     89.400  0.0701    97.594  1136.10
  57   0.4314     89.390  0.0667    97.726  1156.32
  58   0.4984     87.440  0.0669    97.672  1176.56
  59   0.5369     87.320  0.0612    97.882  1196.79
  60   0.4258     89.160  0.0669    97.690  1217.00
  61   0.4353     89.330  0.0642    97.872  1237.26
  62   0.4237     89.300  0.0661    97.718  1257.47
  63   0.3945     90.300  0.0678    97.694  1277.72
  64   0.5111     87.900  0.0575    98.026  1297.94
  65   0.4543     88.840  0.0569    98.046  1318.20
  66   0.4211     89.630  0.0586    98.066  1338.46
  67   0.4373     88.970  0.0589    97.934  1358.72
  68   0.4435     88.810  0.0562    98.082  1379.00
  69   0.4816     89.060  0.0560    98.052  1399.27
  70   0.4624     89.510  0.0633    97.838  1419.53
  71   0.4501     89.810  0.0578    98.020  1439.80
  72   0.4917     88.670  0.0512    98.278  1460.06
  73   0.4256     89.760  0.0543    98.048  1480.33
  74   0.4781     89.050  0.0564    98.028  1500.56
  75   0.4599     89.320  0.0540    98.130  1520.83
  76   0.4685     88.960  0.0497    98.304  1541.08
  77   0.4888     88.830  0.0527    98.206  1561.34
  78   0.4027     90.020  0.0513    98.328  1581.65
  79   0.4740     88.550  0.0483    98.380  1601.93
  80   0.4329     89.870  0.0490    98.322  1622.18
  81   0.4278     89.630  0.0495    98.302  1642.40
  82   0.4185     90.210  0.0533    98.178  1662.65
  83   0.5006     89.070  0.0488    98.330  1682.92
  84   0.4886     89.140  0.0479    98.330  1703.18
  85   0.4551     89.630  0.0478    98.402  1723.43
