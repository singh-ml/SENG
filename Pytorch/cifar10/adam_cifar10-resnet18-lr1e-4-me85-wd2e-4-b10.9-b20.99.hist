Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3002     52.330  1.5667    42.380  22.26
   2   1.0974     60.300  1.2065    56.462  42.55
   3   1.0051     64.730  1.0357    62.804  62.83
   4   0.9218     67.140  0.9232    67.196  83.08
   5   0.8505     70.430  0.8326    70.270  103.36
   6   0.8689     69.760  0.7565    73.014  123.63
   7   0.7296     74.710  0.6923    75.294  143.91
   8   0.6983     75.260  0.6365    77.714  164.20
   9   0.7030     76.030  0.5925    79.090  184.46
  10   0.6880     76.160  0.5513    80.608  204.73
  11   0.6490     77.630  0.5157    81.992  224.97
  12   0.6362     78.220  0.4831    83.138  245.21
  13   0.5925     80.100  0.4605    83.752  265.55
  14   0.5867     80.230  0.4315    85.078  285.78
  15   0.5490     81.830  0.4065    85.720  306.04
  16   0.5728     80.950  0.3899    86.282  326.29
  17   0.5545     81.250  0.3692    87.166  346.52
  18   0.5094     83.170  0.3521    87.660  366.84
  19   0.5377     82.200  0.3301    88.452  387.13
  20   0.5183     83.320  0.3142    88.996  407.41
  21   0.5071     83.220  0.2994    89.648  427.68
  22   0.5281     82.870  0.2879    89.898  447.90
  23   0.5362     83.100  0.2709    90.408  468.15
  24   0.4988     84.390  0.2588    91.006  488.48
  25   0.4995     84.340  0.2490    91.296  508.69
  26   0.4828     85.000  0.2355    91.910  528.96
  27   0.5268     84.510  0.2297    91.984  549.19
  28   0.5022     84.690  0.2159    92.514  569.45
  29   0.4915     84.910  0.2078    92.754  589.75
  30   0.5108     84.650  0.1988    93.104  610.03
  31   0.5348     84.260  0.1862    93.326  630.37
  32   0.4591     86.150  0.1813    93.634  650.65
  33   0.5170     84.920  0.1700    94.012  670.89
  34   0.5240     84.750  0.1668    94.172  691.12
  35   0.4886     85.770  0.1582    94.328  711.44
  36   0.4865     86.090  0.1550    94.520  731.73
  37   0.4964     85.430  0.1419    95.126  751.97
  38   0.5471     84.700  0.1412    95.106  772.20
  39   0.5385     84.660  0.1350    95.374  792.46
  40   0.5467     85.600  0.1263    95.588  812.76
  41   0.6141     83.750  0.1211    95.752  833.01
  42   0.5657     85.150  0.1192    95.828  853.26
  43   0.4944     86.370  0.1189    95.836  873.51
  44   0.5097     86.100  0.1127    96.086  893.76
  45   0.5376     85.740  0.1104    96.160  914.08
  46   0.5476     85.650  0.0983    96.544  934.38
  47   0.5733     85.410  0.0957    96.656  954.70
  48   0.4987     86.800  0.0965    96.678  974.98
  49   0.5396     86.560  0.0981    96.578  995.22
  50   0.6033     84.940  0.0916    96.812  1015.44
  51   0.5974     85.060  0.0838    97.116  1035.66
  52   0.5132     86.960  0.0812    97.226  1055.90
  53   0.5617     86.180  0.0830    97.090  1076.15
  54   0.5418     86.740  0.0792    97.228  1096.41
  55   0.5175     86.690  0.0764    97.392  1116.68
  56   0.5730     86.540  0.0755    97.416  1136.88
  57   0.5201     86.560  0.0768    97.334  1157.17
  58   0.5861     85.990  0.0729    97.458  1177.40
  59   0.5432     86.850  0.0698    97.604  1197.65
  60   0.6057     85.540  0.0688    97.646  1217.94
  61   0.5475     86.900  0.0676    97.726  1238.17
  62   0.6192     85.630  0.0615    97.878  1258.38
  63   0.5419     86.880  0.0641    97.718  1278.63
  64   0.5166     87.440  0.0638    97.750  1298.86
  65   0.5615     86.770  0.0632    97.870  1319.10
  66   0.5551     87.000  0.0637    97.850  1339.33
  67   0.5736     86.640  0.0595    97.950  1359.58
  68   0.5671     87.110  0.0598    97.986  1379.84
  69   0.5174     87.530  0.0601    97.926  1400.06
  70   0.5511     87.070  0.0566    98.044  1420.31
  71   0.6191     86.070  0.0561    98.082  1440.60
  72   0.5626     86.950  0.0546    98.164  1460.82
  73   0.5333     87.480  0.0530    98.260  1481.03
  74   0.5229     87.650  0.0529    98.226  1501.27
  75   0.5506     87.240  0.0520    98.212  1521.53
  76   0.5074     87.640  0.0531    98.142  1541.75
  77   0.5811     86.350  0.0490    98.338  1562.00
  78   0.6461     85.880  0.0505    98.214  1582.27
  79   0.5315     87.580  0.0455    98.486  1602.55
  80   0.5549     87.380  0.0500    98.236  1622.82
  81   0.5639     87.020  0.0466    98.392  1643.08
  82   0.5648     87.250  0.0462    98.414  1663.33
  83   0.6465     85.780  0.0477    98.396  1683.58
  84   0.5034     88.120  0.0445    98.514  1703.88
  85   0.5875     86.880  0.0439    98.546  1724.12
