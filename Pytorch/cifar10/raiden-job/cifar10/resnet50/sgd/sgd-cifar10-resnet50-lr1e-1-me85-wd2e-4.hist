Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 17946863104 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2979     11.590  3.7110    10.754  25.48
   2   2.5616     18.210  2.3261    12.038  48.43
   3   2.2018     19.910  2.0832    20.196  71.36
   4   2.0042     26.090  1.9821    22.574  94.28
   5   7.8880     19.470  1.9007    26.036  117.22
   6   1.7449     34.760  1.8800    27.918  140.18
   7   1.7076     36.650  1.7307    34.428  163.10
   8   1.5590     40.630  1.6454    37.894  186.03
   9   1.6594     43.250  1.5767    40.746  208.96
  10   1.4668     46.280  1.5055    44.000  231.86
  11   1.4941     49.740  1.4130    47.834  254.81
  12   1.2775     52.750  1.3081    51.800  277.74
  13   1.1584     57.200  1.1925    56.684  300.64
  14   1.0451     63.310  1.0784    60.806  323.59
  15   0.9766     64.530  0.9965    64.012  346.53
  16   1.1502     66.490  0.9333    66.516  369.49
  17   0.8891     69.200  0.8720    68.690  392.42
  18   0.8433     70.340  0.8255    70.604  415.37
  19   0.7992     72.440  0.7749    72.264  438.34
  20   0.7408     74.810  0.7244    74.354  461.26
  21   0.7041     75.270  0.6846    75.718  484.18
  22   0.6592     77.530  0.6433    77.214  507.13
  23   0.6114     78.850  0.5968    79.002  530.08
  24   0.5959     79.660  0.5494    80.730  553.01
  25   0.5953     79.970  0.5202    81.728  575.97
  26   0.5774     80.490  0.4925    82.790  598.91
  27   0.5643     81.010  0.4605    83.976  621.86
  28   0.5278     82.930  0.4367    84.682  644.79
  29   0.5098     83.450  0.4128    85.636  667.72
  30   0.5079     83.290  0.4017    85.902  690.64
  31   0.4764     84.350  0.3753    86.926  713.57
  32   0.4956     83.920  0.3617    87.386  736.53
  33   0.5256     84.030  0.3460    87.988  759.48
  34   0.4595     85.620  0.3320    88.364  782.45
  35   0.5409     83.250  0.3130    89.220  805.39
  36   0.4300     86.280  0.2981    89.710  828.34
  37   0.4491     85.850  0.2863    89.880  851.30
  38   0.4261     86.210  0.2775    90.280  874.26
  39   0.3908     87.070  0.2633    90.904  897.21
  40   0.4294     87.080  0.2512    91.040  920.15
  41   0.4565     85.730  0.2374    91.714  943.11
  42   0.4495     86.570  0.2277    92.034  966.06
  43   0.4226     87.090  0.2207    92.360  989.00
  44   0.4797     86.220  0.2100    92.666  1011.93
  45   0.3917     87.860  0.1970    93.070  1034.86
  46   0.4044     88.360  0.1868    93.388  1057.80
  47   0.4068     87.760  0.1780    93.738  1080.74
  48   0.4113     87.940  0.1675    94.006  1103.67
  49   0.3980     88.120  0.1556    94.488  1126.63
  50   0.3864     88.190  0.1437    94.938  1149.56
  51   0.4441     88.260  0.1441    95.000  1172.49
  52   0.4029     88.720  0.1315    95.424  1195.43
  53   0.3983     88.830  0.1250    95.608  1218.37
  54   0.3872     89.640  0.1154    96.014  1241.27
  55   0.4284     89.100  0.1067    96.152  1264.19
  56   0.3988     89.540  0.1026    96.330  1287.10
  57   0.4113     89.480  0.0858    97.050  1310.02
  58   0.4272     89.040  0.0828    97.086  1332.95
  59   0.4236     89.460  0.0754    97.294  1355.86
  60   0.4403     89.400  0.0667    97.670  1378.81
  61   0.4230     89.760  0.0625    97.858  1401.77
  62   0.4730     88.970  0.0574    97.984  1424.71
  63   0.4964     89.640  0.0483    98.344  1447.64
  64   0.4593     89.900  0.0392    98.684  1470.56
  65   0.4373     90.100  0.0383    98.716  1493.48
  66   0.4150     90.590  0.0303    98.990  1516.42
  67   0.4188     90.310  0.0278    99.064  1539.36
  68   0.5061     89.870  0.0228    99.238  1562.32
  69   0.4533     90.520  0.0188    99.388  1585.27
  70   0.4370     91.050  0.0179    99.428  1608.21
  71   0.5066     90.090  0.0148    99.556  1631.16
  72   0.4415     91.190  0.0130    99.622  1654.10
  73   0.4584     90.600  0.0115    99.648  1677.04
  74   0.4899     90.440  0.0104    99.722  1699.95
  75   0.4258     90.990  0.0087    99.762  1722.92
  76   0.4416     91.250  0.0084    99.782  1745.85
  77   0.4399     91.170  0.0076    99.802  1768.78
  78   0.4653     90.990  0.0067    99.824  1791.72
  79   0.4642     90.840  0.0072    99.826  1814.64
  80   0.4522     91.100  0.0054    99.890  1837.57
  81   0.4384     91.260  0.0058    99.874  1860.48
  82   0.4192     91.640  0.0058    99.858  1883.42
  83   0.4322     91.280  0.0054    99.862  1906.36
  84   0.4717     90.820  0.0050    99.890  1929.30
  85   0.4249     91.580  0.0053    99.878  1952.25
