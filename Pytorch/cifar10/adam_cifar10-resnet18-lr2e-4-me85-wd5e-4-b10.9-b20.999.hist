Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2442     55.300  1.4699    45.850  22.26
   2   0.9789     65.060  1.0639    61.768  42.48
   3   0.9024     68.460  0.8740    69.050  62.68
   4   0.7289     74.430  0.7438    73.782  82.88
   5   0.7426     74.830  0.6539    77.088  103.18
   6   0.7699     75.530  0.5851    79.548  123.47
   7   0.6976     76.790  0.5336    81.382  143.71
   8   0.5814     79.900  0.4921    82.790  163.91
   9   0.7558     75.290  0.4624    84.056  184.11
  10   0.6698     78.510  0.4308    84.960  204.32
  11   0.6185     79.190  0.4005    86.248  224.54
  12   0.5461     81.340  0.3779    86.928  244.81
  13   0.5903     80.870  0.3602    87.596  265.08
  14   0.4841     83.770  0.3369    88.448  285.28
  15   0.5684     81.690  0.3176    88.944  305.55
  16   0.5027     83.530  0.3069    89.232  325.76
  17   0.5285     83.680  0.2848    90.224  345.94
  18   0.4436     85.230  0.2768    90.454  366.16
  19   0.6726     79.610  0.2640    90.934  386.34
  20   0.4793     84.370  0.2523    91.192  406.60
  21   0.5542     82.930  0.2403    91.604  426.80
  22   0.4704     84.990  0.2309    91.924  447.02
  23   0.4323     85.930  0.2196    92.338  467.25
  24   0.4093     86.480  0.2110    92.628  487.49
  25   0.4644     86.210  0.1969    93.090  507.74
  26   0.4289     86.350  0.1933    93.270  527.97
  27   0.5123     84.530  0.1871    93.624  548.19
  28   0.4927     85.100  0.1837    93.682  568.47
  29   0.4721     86.140  0.1720    94.086  588.70
  30   0.5070     85.450  0.1649    94.378  608.92
  31   0.5924     82.620  0.1594    94.564  629.21
  32   0.5403     84.220  0.1565    94.658  649.42
  33   0.4158     87.720  0.1527    94.746  669.62
  34   0.5855     83.900  0.1439    95.070  689.81
  35   0.4082     87.690  0.1444    94.948  710.03
  36   0.4405     87.160  0.1396    95.184  730.26
  37   0.4069     88.290  0.1232    95.804  750.47
  38   0.4412     87.220  0.1303    95.608  770.71
  39   0.4063     88.320  0.1275    95.638  790.91
  40   0.5472     85.140  0.1263    95.708  811.14
  41   0.3930     88.010  0.1134    96.114  831.38
  42   0.4318     87.840  0.1143    96.108  851.61
  43   0.4563     87.170  0.1128    96.074  871.84
  44   0.4236     87.710  0.1097    96.290  892.06
  45   0.4763     87.560  0.1064    96.398  912.27
  46   0.4738     86.830  0.1054    96.410  932.50
  47   0.4837     86.940  0.1029    96.550  952.70
  48   0.4670     87.600  0.0963    96.708  972.91
  49   0.3858     89.430  0.0936    96.824  993.11
  50   0.4825     86.790  0.0971    96.640  1013.38
  51   0.3732     89.420  0.0981    96.696  1033.63
  52   0.3851     89.200  0.0885    96.926  1053.84
  53   0.4196     88.700  0.0926    96.772  1074.09
  54   0.3899     88.820  0.0883    96.958  1094.31
  55   0.4151     88.400  0.0887    96.994  1114.50
  56   0.4187     88.930  0.0803    97.336  1134.71
  57   0.4189     88.660  0.0834    97.108  1154.92
  58   0.4363     88.100  0.0795    97.240  1175.16
  59   0.4622     88.010  0.0815    97.234  1195.39
  60   0.3840     89.540  0.0812    97.228  1215.58
  61   0.4250     89.120  0.0769    97.386  1235.82
  62   0.4514     88.500  0.0738    97.516  1256.08
  63   0.4040     88.990  0.0761    97.330  1276.35
  64   0.3830     89.540  0.0777    97.362  1296.59
  65   0.4009     89.010  0.0737    97.424  1316.84
  66   0.4672     87.600  0.0732    97.564  1337.02
  67   0.4854     87.230  0.0679    97.706  1357.23
  68   0.4340     89.060  0.0710    97.634  1377.45
  69   0.4524     88.650  0.0684    97.664  1397.66
  70   0.4082     89.180  0.0687    97.724  1417.83
  71   0.4564     88.820  0.0663    97.744  1438.04
  72   0.4348     89.100  0.0693    97.608  1458.30
  73   0.4075     89.380  0.0657    97.866  1478.52
  74   0.4005     89.780  0.0627    97.936  1498.75
  75   0.4001     89.360  0.0677    97.750  1519.00
  76   0.4058     89.340  0.0640    97.838  1539.22
  77   0.3787     89.730  0.0661    97.726  1559.45
  78   0.4348     89.360  0.0668    97.724  1579.70
  79   0.3894     89.620  0.0647    97.802  1599.89
  80   0.4275     88.650  0.0622    97.954  1620.12
  81   0.4038     89.530  0.0624    97.964  1640.31
  82   0.4363     89.050  0.0641    97.840  1660.51
  83   0.4529     88.280  0.0630    97.882  1680.75
  84   0.4979     87.970  0.0601    97.908  1701.00
  85   0.4143     89.390  0.0601    98.058  1721.23
