Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 15427437056 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4425      9.740  16.7685     9.502  27.77
   2   2.4428      9.490  16.7676     9.415  52.97
   3   2.4439      9.520  16.7685     9.488  78.16
   4   2.4509      9.640  16.7676     9.568  103.56
   5   2.4466      9.300  16.7687     9.452  128.88
   6   2.4437      9.450  16.7679     9.527  154.17
   7   2.4451      9.520  16.7687     9.425  179.61
   8   2.4454      9.560  16.7687     9.457  204.95
   9   2.4382      9.620  16.7687     9.567  230.33
  10   2.4387      9.690  16.7691     9.407  255.52
  11   2.4381      9.520  16.7671     9.458  280.78
  12   2.4453      9.400  16.7692     9.377  306.17
  13   2.4458      9.340  16.7688     9.462  331.48
  14   2.4372      9.550  16.7689     9.608  356.84
  15   2.4433      9.870  16.7688     9.398  382.03
  16   2.4460      9.430  16.7675     9.493  407.27
  17   2.4482      9.610  16.7681     9.462  432.44
  18   2.4421      9.580  16.7676     9.592  457.67
  19   2.4446      9.460  16.7682     9.443  482.93
  20   2.4473      9.570  16.7678     9.413  508.10
  21   2.4449      9.370  16.7691     9.282  533.49
  22   2.4424      9.750  16.7686     9.453  558.89
  23   2.4488      9.200  16.7671     9.537  584.20
  24   2.4456      9.460  16.7695     9.508  609.56
  25   2.4414      9.400  16.7675     9.423  634.93
  26   2.4430      9.680  16.7686     9.508  660.23
  27   2.4437      9.450  16.7691     9.487  685.40
  28   2.4485      9.360  16.7676     9.452  710.64
  29   2.4478      9.410  16.7685     9.483  735.86
  30   2.4458      9.390  16.7680     9.418  761.17
  31   2.4479      9.320  16.7683     9.378  786.55
  32   2.4470      9.460  16.7680     9.432  811.95
  33   2.4427      9.740  16.7688     9.402  837.25
  34   2.4494      9.100  16.7683     9.477  862.63
  35   2.4442      9.420  16.7679     9.395  888.01
  36   2.4514      9.490  16.7688     9.500  913.31
  37   2.4437      9.520  16.7697     9.425  938.49
  38   2.4447      9.600  16.7676     9.552  963.85
  39   2.4452      9.490  16.7688     9.535  989.23
  40   2.4426      9.220  16.7684     9.462  1014.42
  41   2.4386      9.600  16.7680     9.593  1039.71
  42   2.4383      9.510  16.7683     9.538  1065.11
  43   2.4411      9.700  16.7681     9.495  1090.39
  44   2.4406      9.540  16.7689     9.382  1115.58
  45   2.4464      9.620  16.7677     9.393  1140.95
  46   2.4390      9.800  16.7688     9.483  1166.32
  47   2.4403      9.500  16.7694     9.423  1191.62
  48   2.4502      9.280  16.7687     9.525  1216.97
  49   2.4475      9.350  16.7688     9.385  1242.31
  50   2.4443      9.400  16.7685     9.383  1267.63
  51   2.4420      9.580  16.7684     9.485  1292.98
  52   2.4448      9.390  16.7687     9.423  1318.27
  53   2.4507      9.420  16.7689     9.425  1343.45
  54   2.4474      9.670  16.7687     9.397  1368.61
  55   2.4454      9.380  16.7680     9.468  1393.84
  56   2.4406      9.540  16.7685     9.412  1419.07
  57   2.4452      9.650  16.7683     9.488  1444.27
  58   2.4438      9.420  16.7688     9.470  1469.62
  59   2.4451      9.450  16.7678     9.507  1494.98
  60   2.4483      9.440  16.7684     9.542  1520.31
  61   2.4449      9.480  16.7674     9.482  1545.70
  62   2.4490      9.490  16.7670     9.448  1571.05
  63   2.4447      9.620  16.7672     9.472  1596.34
  64   2.4435      9.330  16.7686     9.515  1621.68
  65   2.4457      8.970  16.7671     9.482  1646.91
  66   2.4400      9.740  16.7680     9.488  1672.20
  67   2.4486      9.550  16.7688     9.432  1697.55
  68   2.4454      9.380  16.7684     9.530  1722.86
  69   2.4425      9.520  16.7683     9.510  1748.22
  70   2.4492      9.400  16.7693     9.408  1773.43
  71   2.4432      9.700  16.7682     9.438  1798.62
  72   2.4427      9.180  16.7680     9.447  1823.99
  73   2.4375      9.880  16.7673     9.465  1849.34
  74   2.4383      9.690  16.7683     9.442  1874.65
  75   2.4509      9.100  16.7686     9.482  1899.97
  76   2.4394      9.630  16.7682     9.443  1925.33
  77   2.4448      9.630  16.7679     9.472  1950.72
  78   2.4494      9.430  16.7701     9.385  1976.02
  79   2.4499      9.670  16.7668     9.468  2001.38
  80   2.4456      9.100  16.7677     9.470  2026.77
  81   2.4509      9.560  16.7680     9.397  2052.11
  82   2.4384      9.760  16.7684     9.457  2077.40
  83   2.4468      9.510  16.7679     9.373  2102.70
  84   2.4493      9.550  16.7680     9.388  2128.08
  85   2.4437      9.640  16.7681     9.482  2153.42
