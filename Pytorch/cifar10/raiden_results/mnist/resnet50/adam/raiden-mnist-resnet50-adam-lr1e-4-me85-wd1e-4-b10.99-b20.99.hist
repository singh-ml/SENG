Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.4293     85.900  1.0886    62.372  25.47
   2   0.1773     94.330  0.3011    89.890  48.58
   3   0.0873     97.100  0.1289    95.792  71.65
   4   0.0719     97.580  0.0902    97.202  94.73
   5   0.0571     98.200  0.0721    97.750  117.81
   6   0.0490     98.390  0.0615    98.102  140.92
   7   0.0646     98.010  0.0530    98.285  164.02
   8   0.0496     98.420  0.0495    98.445  187.13
   9   0.0526     98.360  0.0453    98.527  210.21
  10   0.0538     98.320  0.0452    98.588  233.29
  11   0.0513     98.340  0.0404    98.728  256.36
  12   0.0467     98.500  0.0380    98.812  279.49
  13   0.0453     98.630  0.0370    98.845  302.58
  14   0.0372     98.700  0.0365    98.817  325.65
  15   0.0395     98.740  0.0351    98.885  348.76
  16   0.0391     98.680  0.0326    98.938  371.81
  17   0.0462     98.600  0.0308    99.002  394.87
  18   0.0481     98.460  0.0329    98.923  417.96
  19   0.0461     98.430  0.0308    99.028  441.06
  20   0.0402     98.720  0.0291    99.067  464.16
  21   0.0519     98.330  0.0291    99.055  487.23
  22   0.0392     98.750  0.0274    99.090  510.29
  23   0.0329     98.970  0.0277    99.098  533.35
  24   0.0411     98.700  0.0256    99.152  556.43
  25   0.0455     98.590  0.0268    99.143  579.48
  26   0.0421     98.670  0.0249    99.207  602.54
  27   0.0454     98.610  0.0262    99.157  625.64
  28   0.0333     98.880  0.0262    99.143  648.77
  29   0.0345     98.920  0.0231    99.250  671.84
  30   0.0416     98.580  0.0244    99.235  694.97
  31   0.0493     98.450  0.0218    99.297  718.07
  32   0.0337     98.990  0.0241    99.207  741.16
  33   0.0327     98.970  0.0249    99.185  764.27
  34   0.0348     98.920  0.0239    99.230  787.38
  35   0.0274     99.160  0.0241    99.262  810.46
  36   0.0194     99.350  0.0235    99.240  833.56
  37   0.0402     98.700  0.0203    99.338  856.67
  38   0.0332     98.900  0.0236    99.265  879.73
  39   0.0279     99.110  0.0203    99.358  902.86
  40   0.0346     98.940  0.0205    99.368  925.96
  41   0.0428     98.630  0.0201    99.360  949.06
  42   0.0428     98.770  0.0190    99.390  972.14
  43   0.0451     98.540  0.0180    99.408  995.23
  44   0.0299     99.020  0.0184    99.382  1018.31
  45   0.0340     98.940  0.0207    99.347  1041.44
  46   0.0378     98.820  0.0206    99.293  1064.53
  47   0.0356     99.030  0.0174    99.452  1087.67
  48   0.0380     98.880  0.0203    99.352  1110.77
  49   0.0452     98.690  0.0188    99.392  1133.87
  50   0.0428     98.720  0.0187    99.383  1156.92
  51   0.0461     98.600  0.0187    99.390  1179.99
  52   0.0381     98.860  0.0170    99.463  1203.12
  53   0.0422     98.600  0.0176    99.422  1226.19
  54   0.0376     98.880  0.0182    99.443  1249.31
  55   0.0527     98.510  0.0187    99.412  1272.40
  56   0.0368     98.900  0.0188    99.370  1295.50
  57   0.0312     98.970  0.0167    99.463  1318.58
  58   0.0360     98.910  0.0170    99.455  1341.65
  59   0.0330     98.930  0.0161    99.482  1364.72
  60   0.0284     99.120  0.0153    99.508  1387.79
  61   0.0399     98.760  0.0164    99.463  1410.87
  62   0.0360     99.010  0.0162    99.482  1433.95
  63   0.0285     99.170  0.0179    99.453  1457.05
  64   0.0470     98.650  0.0147    99.543  1480.14
  65   0.0294     99.120  0.0163    99.500  1503.26
  66   0.0361     98.940  0.0152    99.515  1526.38
  67   0.0368     98.840  0.0147    99.523  1549.49
  68   0.0326     99.080  0.0155    99.528  1572.61
  69   0.0316     99.030  0.0163    99.488  1595.71
  70   0.0316     99.100  0.0153    99.525  1618.80
  71   0.0308     99.110  0.0131    99.597  1641.92
  72   0.0441     98.680  0.0162    99.512  1665.02
  73   0.0371     98.850  0.0155    99.497  1688.11
  74   0.0406     98.760  0.0138    99.587  1711.22
  75   0.0369     98.950  0.0142    99.508  1734.33
  76   0.0356     98.930  0.0150    99.513  1757.40
  77   0.0439     98.750  0.0130    99.568  1780.51
  78   0.0431     98.810  0.0138    99.550  1803.60
  79   0.0475     98.680  0.0135    99.537  1826.68
  80   0.0362     98.990  0.0138    99.560  1849.80
  81   0.0442     98.650  0.0135    99.580  1872.87
  82   0.0342     99.020  0.0122    99.605  1895.96
  83   0.0409     98.710  0.0125    99.602  1919.08
  84   0.0497     98.650  0.0135    99.553  1942.23
  85   0.0414     98.810  0.0125    99.612  1965.30
