Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2170     92.750  0.6828    76.607  25.38
   2   0.1112     96.560  0.1597    94.928  48.52
   3   0.0640     98.160  0.0966    96.967  71.57
   4   0.0701     97.900  0.0822    97.482  94.65
   5   0.0994     96.520  0.0708    97.833  117.73
   6   0.0751     97.740  0.0635    98.002  140.81
   7   0.0639     98.040  0.0629    98.040  163.92
   8   0.0537     98.260  0.0612    98.075  186.98
   9   0.0487     98.530  0.0580    98.187  210.02
  10   0.0570     98.300  0.0603    98.205  233.09
  11   0.0499     98.610  0.0537    98.347  256.16
  12   0.0493     98.540  0.0530    98.357  279.24
  13   0.0628     97.790  0.0499    98.470  302.28
  14   0.0479     98.480  0.0530    98.442  325.37
  15   0.0545     98.130  0.0509    98.435  348.43
  16   0.0611     98.100  0.0502    98.503  371.48
  17   0.0508     98.340  0.0490    98.492  394.55
  18   0.0561     98.350  0.0494    98.503  417.62
  19   0.0432     98.610  0.0432    98.730  440.71
  20   0.0505     98.560  0.0473    98.560  463.79
  21   0.0543     98.420  0.0464    98.620  486.87
  22   0.0644     98.040  0.0415    98.765  509.97
  23   0.0604     98.260  0.0445    98.685  533.05
  24   0.0582     98.270  0.0444    98.682  556.10
  25   0.0413     98.840  0.0430    98.787  579.15
  26   0.0537     98.500  0.0391    98.832  602.23
  27   0.0514     98.400  0.0400    98.817  625.27
  28   0.0483     98.520  0.0415    98.782  648.37
  29   0.0571     98.380  0.0384    98.892  671.45
  30   0.0501     98.390  0.0394    98.825  694.51
  31   0.0378     98.800  0.0414    98.798  717.60
  32   0.0420     98.720  0.0416    98.803  740.66
  33   0.0452     98.610  0.0376    98.927  763.72
  34   0.0436     98.590  0.0380    98.920  786.82
  35   0.0330     99.020  0.0389    98.828  809.89
  36   0.0440     98.570  0.0387    98.858  832.96
  37   0.0355     98.890  0.0350    98.963  856.04
  38   0.0405     98.770  0.0349    98.955  879.10
  39   0.0362     99.080  0.0335    98.995  902.16
  40   0.0551     98.350  0.0361    98.963  925.26
  41   0.0450     98.660  0.0348    98.965  948.37
  42   0.0391     98.800  0.0341    99.023  971.43
  43   0.0534     98.340  0.0329    99.050  994.49
  44   0.0352     98.920  0.0312    99.088  1017.57
  45   0.0315     98.990  0.0319    99.078  1040.62
  46   0.0551     98.330  0.0311    99.100  1063.72
  47   0.0383     98.740  0.0341    98.960  1086.77
  48   0.0422     98.790  0.0287    99.175  1109.84
  49   0.0591     98.140  0.0317    99.077  1132.93
  50   0.0339     99.040  0.0312    99.093  1156.04
  51   0.0386     98.850  0.0309    99.057  1179.11
  52   0.0371     98.850  0.0289    99.142  1202.17
  53   0.0398     98.820  0.0276    99.212  1225.25
  54   0.0431     98.680  0.0303    99.125  1248.31
  55   0.0441     98.620  0.0284    99.173  1271.41
  56   0.0282     99.200  0.0274    99.203  1294.49
  57   0.0428     98.740  0.0293    99.175  1317.54
  58   0.0485     98.580  0.0282    99.168  1340.62
  59   0.0360     98.940  0.0286    99.185  1363.72
  60   0.0509     98.580  0.0289    99.157  1386.79
  61   0.0361     98.860  0.0291    99.152  1409.86
  62   0.0420     98.680  0.0275    99.182  1432.94
  63   0.0465     98.670  0.0280    99.182  1455.99
  64   0.0322     99.060  0.0279    99.187  1479.05
  65   0.0380     98.760  0.0262    99.232  1502.20
  66   0.0294     99.130  0.0260    99.237  1525.26
  67   0.0400     98.830  0.0258    99.217  1548.34
  68   0.0837     98.100  0.0276    99.167  1571.43
  69   0.0427     98.820  0.0290    99.142  1594.48
  70   0.0380     98.920  0.0248    99.245  1617.56
  71   0.0554     98.410  0.0260    99.248  1640.66
  72   0.0592     98.200  0.0266    99.190  1663.73
  73   0.0430     98.690  0.0257    99.223  1686.81
  74   0.0553     98.350  0.0259    99.223  1709.87
  75   0.0352     99.090  0.0256    99.213  1732.96
  76   0.0504     98.470  0.0266    99.225  1756.03
  77   0.0295     99.160  0.0261    99.260  1779.14
  78   0.0465     98.840  0.0246    99.272  1802.20
  79   0.0460     98.680  0.0243    99.303  1825.28
  80   0.0471     98.740  0.0254    99.263  1848.34
  81   0.0441     98.640  0.0247    99.233  1871.39
  82   0.0317     99.070  0.0247    99.263  1895.05
  83   0.0428     98.880  0.0235    99.293  1918.12
  84   0.0359     98.990  0.0254    99.253  1941.17
  85   0.0283     99.200  0.0224    99.335  1964.23
  86   0.0580     98.370  0.0252    99.273  1987.34
  87   0.0471     98.660  0.0252    99.268  2010.46
  88   0.0499     98.590  0.0248    99.258  2033.52
  89   0.0302     99.130  0.0246    99.300  2056.58
  90   0.0419     98.940  0.0229    99.328  2079.65
