Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.8466     75.400  1.6727    47.955  25.25
   2   0.3058     90.350  0.3117    90.463  48.37
   3   0.1827     95.040  0.2052    93.763  71.33
   4   0.1577     94.870  0.1670    94.955  94.33
   5   0.1551     95.030  0.1445    95.472  117.30
   6   0.1185     96.300  0.1345    95.880  140.27
   7   0.1083     96.620  0.1273    96.085  163.30
   8   0.1111     96.580  0.1172    96.427  186.34
   9   0.1081     96.690  0.1150    96.432  209.34
  10   0.0884     97.150  0.1129    96.495  232.39
  11   0.0756     97.590  0.1100    96.500  255.39
  12   0.0923     96.960  0.1044    96.765  278.46
  13   0.0987     96.780  0.1010    96.948  301.50
  14   0.0799     97.490  0.1016    96.922  324.53
  15   0.0856     97.430  0.0967    97.045  347.58
  16   0.1311     95.720  0.0979    97.015  370.64
  17   0.0849     97.350  0.0977    96.960  393.70
  18   0.0768     97.410  0.0951    97.028  416.73
  19   0.0986     96.750  0.0924    97.183  439.79
  20   0.1074     96.740  0.0932    97.105  462.82
  21   0.1227     96.220  0.0892    97.202  485.87
  22   0.0993     96.860  0.0926    97.118  508.89
  23   0.0820     97.550  0.0919    97.212  531.93
  24   0.0632     98.110  0.0872    97.348  554.97
  25   0.0808     97.420  0.0886    97.215  578.00
  26   0.0821     97.300  0.0874    97.260  601.02
  27   0.1049     96.740  0.0839    97.418  624.04
  28   0.0750     97.660  0.0856    97.330  647.11
  29   0.0859     97.140  0.0850    97.427  670.14
  30   0.0956     96.850  0.0870    97.282  693.16
  31   0.0923     96.990  0.0849    97.323  716.24
  32   0.0815     97.320  0.0846    97.357  739.27
  33   0.0927     96.720  0.0821    97.490  762.31
  34   0.1077     96.610  0.0849    97.400  785.36
  35   0.0842     97.180  0.0820    97.512  808.40
  36   0.0835     97.420  0.0857    97.405  831.45
  37   0.1285     95.770  0.0804    97.558  854.52
  38   0.1390     95.640  0.0814    97.468  877.56
  39   0.1092     96.140  0.0838    97.412  900.55
  40   0.0962     97.040  0.0817    97.478  923.59
  41   0.0997     96.840  0.0791    97.582  946.67
  42   0.1152     96.050  0.0817    97.395  969.70
  43   0.0686     97.860  0.0811    97.475  992.76
  44   0.0830     97.410  0.0816    97.440  1015.84
  45   0.0611     98.020  0.0835    97.428  1038.86
  46   0.0823     97.250  0.0772    97.622  1061.95
  47   0.0785     97.350  0.0815    97.462  1084.99
  48   0.0763     97.410  0.0800    97.483  1108.01
  49   0.0660     97.900  0.0794    97.557  1131.05
  50   0.0783     97.510  0.0836    97.398  1154.07
  51   0.0850     97.390  0.0812    97.530  1177.10
  52   0.1065     96.670  0.0776    97.595  1200.12
  53   0.0620     97.850  0.0778    97.560  1223.17
  54   0.1253     96.260  0.0795    97.480  1246.20
  55   0.0670     97.800  0.0789    97.582  1269.26
  56   0.1036     96.550  0.0790    97.577  1292.32
  57   0.1095     96.590  0.0785    97.552  1315.33
  58   0.0817     97.310  0.0782    97.557  1338.37
  59   0.0871     97.200  0.0773    97.648  1361.43
  60   0.0783     97.500  0.0810    97.470  1384.46
  61   0.0841     97.240  0.0769    97.680  1407.47
  62   0.0844     97.220  0.0795    97.575  1430.48
  63   0.0966     96.730  0.0815    97.405  1453.50
  64   0.0752     97.600  0.0771    97.612  1476.52
  65   0.0808     97.540  0.0772    97.588  1499.54
  66   0.0772     97.370  0.0786    97.560  1522.66
  67   0.1383     95.510  0.0765    97.560  1545.68
  68   0.0800     97.370  0.0760    97.605  1568.71
  69   0.0895     97.000  0.0789    97.563  1591.71
  70   0.0679     97.850  0.0772    97.593  1614.72
  71   0.0905     97.060  0.0768    97.560  1637.74
  72   0.0947     96.960  0.0776    97.618  1660.73
  73   0.0905     97.230  0.0789    97.490  1683.76
  74   0.0908     97.020  0.0785    97.533  1706.81
  75   0.0670     97.760  0.0770    97.598  1729.83
  76   0.0777     97.370  0.0758    97.613  1752.85
  77   0.1150     96.170  0.0784    97.575  1776.02
  78   0.1845     94.240  0.0799    97.507  1799.01
  79   0.0727     97.790  0.0780    97.533  1822.04
  80   0.0989     96.780  0.0736    97.662  1845.06
  81   0.1064     96.520  0.0758    97.582  1868.07
  82   0.1340     95.630  0.0755    97.647  1891.09
  83   0.1025     96.660  0.0764    97.660  1914.11
  84   0.0803     97.420  0.0762    97.632  1937.10
  85   0.1022     96.710  0.0778    97.590  1960.17
