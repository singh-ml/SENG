Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1218     60.730  3.0505    29.275  25.41
   2   0.2170     93.220  0.4808    84.595  48.48
   3   0.2645     91.740  0.2439    92.607  71.53
   4   0.1864     94.150  0.1830    94.383  94.53
   5   0.1830     93.920  0.1563    95.005  117.54
   6   0.1639     94.420  0.1445    95.383  140.57
   7   0.1341     95.440  0.1358    95.757  163.63
   8   0.1448     95.320  0.1350    95.822  186.66
   9   0.1520     95.010  0.1310    95.965  209.70
  10   0.1511     95.920  0.1278    96.023  232.71
  11   0.1312     96.020  0.1285    95.985  255.73
  12   0.0922     96.970  0.1293    95.957  278.78
  13   0.1247     95.980  0.1245    96.173  301.80
  14   0.1744     94.250  0.1311    95.975  324.82
  15   0.1370     95.400  0.1235    96.190  347.86
  16   0.1326     95.700  0.1221    96.153  370.93
  17   0.1328     95.640  0.1232    96.273  393.95
  18   0.1329     95.940  0.1200    96.223  417.00
  19   0.0898     97.250  0.1221    96.220  440.05
  20   0.1069     96.610  0.1213    96.283  463.04
  21   0.1174     96.300  0.1204    96.242  486.03
  22   0.1146     96.280  0.1176    96.373  509.08
  23   0.1060     96.550  0.1193    96.255  532.10
  24   0.1805     94.330  0.1203    96.340  555.16
  25   0.1181     96.350  0.1169    96.353  578.21
  26   0.0888     97.300  0.1153    96.482  601.22
  27   0.1142     96.210  0.1137    96.438  624.27
  28   0.1070     96.640  0.1147    96.437  647.35
  29   0.1186     96.050  0.1164    96.373  670.39
  30   0.1177     96.330  0.1152    96.507  693.45
  31   0.0814     97.380  0.1164    96.443  716.47
  32   0.1605     94.940  0.1134    96.470  739.53
  33   0.1200     96.150  0.1145    96.393  762.63
  34   0.1105     96.340  0.1120    96.555  785.66
  35   0.1168     96.190  0.1161    96.388  808.69
  36   0.1070     96.630  0.1148    96.522  831.74
  37   0.1023     96.700  0.1138    96.547  854.78
  38   0.0755     97.420  0.1110    96.518  877.84
  39   0.1066     96.620  0.1122    96.540  900.90
  40   0.1039     96.600  0.1123    96.547  923.96
  41   0.0819     97.230  0.1102    96.603  947.05
  42   0.1222     96.070  0.1100    96.517  970.16
  43   0.0912     97.000  0.1120    96.455  993.19
  44   0.1961     93.890  0.1092    96.628  1016.26
  45   0.1039     96.650  0.1110    96.523  1039.33
  46   0.1042     96.820  0.1081    96.647  1062.34
  47   0.1157     96.460  0.1127    96.485  1085.38
  48   0.1161     96.250  0.1098    96.623  1108.42
  49   0.1503     95.660  0.1102    96.523  1131.46
  50   0.1134     96.330  0.1116    96.500  1154.54
  51   0.1461     95.250  0.1087    96.578  1177.58
  52   0.1079     96.550  0.1099    96.588  1200.62
  53   0.1051     96.550  0.1099    96.648  1223.71
  54   0.1259     96.250  0.1125    96.483  1246.71
  55   0.0940     96.860  0.1095    96.617  1269.76
  56   0.1290     96.150  0.1082    96.640  1292.83
  57   0.1105     96.460  0.1083    96.630  1315.89
  58   0.0866     97.160  0.1088    96.612  1338.90
  59   0.1055     96.400  0.1090    96.557  1361.95
  60   0.1205     95.990  0.1089    96.703  1385.01
  61   0.1307     96.000  0.1072    96.713  1408.05
  62   0.0749     97.460  0.1105    96.570  1431.12
  63   0.0934     97.140  0.1072    96.653  1454.20
  64   0.1167     96.430  0.1078    96.623  1477.24
  65   0.1170     96.230  0.1070    96.607  1500.33
  66   0.1150     96.250  0.1094    96.625  1523.43
  67   0.1337     95.760  0.1107    96.687  1546.47
  68   0.1055     96.530  0.1077    96.668  1569.50
  69   0.0854     97.100  0.1070    96.742  1592.56
  70   0.0941     96.910  0.1100    96.595  1615.57
  71   0.0992     96.670  0.1127    96.608  1638.61
  72   0.1840     94.120  0.1120    96.538  1661.68
  73   0.1224     96.160  0.1067    96.685  1684.73
  74   0.0900     97.210  0.1068    96.723  1707.78
  75   0.0922     97.050  0.1107    96.542  1730.84
  76   0.1146     96.520  0.1086    96.588  1753.89
  77   0.0782     97.580  0.1069    96.675  1776.98
  78   0.1179     96.050  0.1098    96.565  1800.01
  79   0.1018     96.660  0.1052    96.710  1823.05
  80   0.1008     96.970  0.1079    96.738  1846.12
  81   0.1307     95.790  0.1068    96.717  1869.15
  82   0.1573     94.850  0.1087    96.647  1892.20
  83   0.0937     96.700  0.1067    96.743  1915.26
  84   0.1037     96.430  0.1076    96.672  1938.33
  85   0.1013     96.700  0.1061    96.787  1961.37
