Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.7192     76.540  1.6326    49.020  25.27
   2   0.3286     88.620  0.3077    90.550  48.32
   3   0.2040     93.560  0.2197    93.297  71.35
   4   0.1673     94.910  0.1867    94.357  94.34
   5   0.6492     79.210  0.1634    95.068  117.33
   6   0.1336     95.950  0.1480    95.378  140.38
   7   0.1027     96.480  0.1400    95.720  163.40
   8   0.1801     93.850  0.1401    95.722  186.42
   9   2.6477     40.470  0.1274    96.163  209.47
  10   0.1590     94.910  0.1332    95.955  232.53
  11   0.1371     95.540  0.1240    96.240  255.63
  12   0.1031     97.130  0.1213    96.343  278.73
  13   0.1101     96.600  0.1166    96.517  301.78
  14   0.1262     95.980  0.1177    96.375  324.88
  15   0.1057     96.740  0.1125    96.557  347.98
  16   1.0263     77.060  0.1166    96.450  371.05
  17   0.0960     96.930  0.1115    96.548  394.16
  18   0.1005     96.890  0.1131    96.572  417.28
  19   0.1463     95.180  0.1096    96.635  440.32
  20   0.1318     95.810  0.1072    96.692  463.42
  21   0.0892     97.220  0.1073    96.690  486.49
  22   0.1051     96.620  0.1082    96.630  509.56
  23   0.1114     96.310  0.1067    96.750  532.64
  24   0.1617     94.590  0.1055    96.698  555.71
  25   0.1231     96.190  0.1042    96.872  578.76
  26   0.1095     96.350  0.1041    96.855  601.83
  27   0.1993     93.670  0.0998    96.888  624.90
  28   0.0974     96.830  0.1024    96.888  647.97
  29   0.0870     97.360  0.1021    96.863  671.04
  30   0.1971     93.650  0.1025    96.863  694.12
  31   0.0750     97.770  0.1023    96.912  717.19
  32   0.1796     94.070  0.0997    96.918  740.27
  33   0.0993     96.720  0.1013    96.923  763.36
  34   0.1426     95.600  0.0998    96.897  786.46
  35   0.1809     94.290  0.0986    96.950  809.51
  36   0.0785     97.440  0.1025    96.898  832.59
  37   0.1673     94.420  0.1001    96.910  855.66
  38   0.0776     97.500  0.1022    96.902  878.77
  39   0.1537     95.100  0.0972    97.045  901.86
  40   0.1246     96.060  0.1004    96.937  924.93
  41   0.1277     96.110  0.0961    97.102  948.02
  42   0.1169     96.250  0.1004    96.942  971.06
  43   0.9154     74.650  0.1035    96.768  994.15
  44   0.0860     97.320  0.1008    96.807  1017.21
  45   0.1025     96.770  0.0970    96.997  1040.30
  46   0.0792     97.360  0.0979    96.935  1063.41
  47   0.1581     95.000  0.0996    96.875  1086.46
  48   0.0854     97.070  0.1002    96.862  1109.56
  49   0.1175     95.970  0.1003    96.923  1132.63
  50   0.1699     94.880  0.0989    96.923  1155.70
  51   0.1830     94.090  0.0971    97.038  1178.74
  52   0.1738     94.570  0.1016    96.805  1201.79
  53   0.1407     95.510  0.0986    96.948  1224.82
  54   4.5534     15.750  0.0986    96.973  1247.89
  55   0.0908     97.050  0.1001    96.888  1270.96
  56   0.0984     96.700  0.0946    97.052  1294.00
  57   0.0941     97.050  0.0962    97.033  1317.06
  58   0.2001     93.470  0.0972    96.988  1340.15
  59   0.0905     97.120  0.0976    97.058  1363.20
  60   0.1427     95.830  0.0956    97.063  1386.24
  61   0.1623     95.010  0.0957    97.068  1409.27
  62   0.1739     94.520  0.0979    96.965  1432.31
  63   0.1355     95.360  0.0949    97.155  1455.36
  64   0.0976     97.100  0.1013    96.887  1478.43
  65   0.1361     95.390  0.0950    97.100  1501.46
  66   0.1620     94.730  0.0960    97.048  1524.49
  67   0.1284     95.730  0.0996    96.987  1547.56
  68   0.0783     97.750  0.0981    96.935  1570.59
  69   0.0915     97.040  0.0954    97.058  1593.66
  70   0.1413     95.260  0.0958    97.107  1616.70
  71   0.1224     96.120  0.0968    97.042  1639.72
  72   0.1018     96.770  0.0944    97.142  1662.75
  73   0.0990     96.730  0.0984    96.970  1685.83
  74   0.2023     93.440  0.0983    96.973  1708.87
  75   0.1175     96.450  0.0958    97.047  1731.94
  76   0.0850     97.320  0.0977    97.022  1754.97
  77   0.0899     97.180  0.1001    96.922  1778.12
  78   0.0877     97.420  0.0973    97.043  1801.21
  79   0.0807     97.510  0.0954    97.103  1824.27
  80   0.1128     96.030  0.0985    96.993  1847.33
  81   0.1116     96.520  0.0955    97.067  1870.37
  82   1.1298     61.330  0.1035    96.835  1893.41
  83   0.2136     93.170  0.1017    96.890  1916.40
  84   0.1597     95.000  0.0941    97.172  1939.42
  85   0.1001     96.750  0.0923    97.182  1962.45
