Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5220     50.090  3.0414    19.958  25.34
   2   0.2851     90.440  0.5197    83.020  48.34
   3   0.1505     95.340  0.2264    92.958  71.39
   4   0.1368     95.780  0.1565    95.220  94.42
   5   0.1042     96.710  0.1307    95.920  117.39
   6   0.1177     96.370  0.1237    96.137  140.39
   7   0.1065     96.680  0.1195    96.270  163.37
   8   0.0952     96.860  0.1143    96.455  186.35
   9   0.1341     95.430  0.1116    96.587  209.30
  10   0.1010     96.950  0.1112    96.487  232.29
  11   0.1326     95.710  0.1055    96.720  255.27
  12   0.1064     96.460  0.1084    96.590  278.28
  13   0.0962     96.760  0.1064    96.753  301.28
  14   0.0829     97.350  0.1071    96.680  324.28
  15   0.0729     97.560  0.1074    96.652  347.30
  16   0.0997     96.780  0.1067    96.705  370.29
  17   0.1784     94.150  0.1067    96.727  393.29
  18   0.1451     95.500  0.1093    96.608  416.29
  19   0.1048     96.660  0.1030    96.808  439.29
  20   0.0789     97.370  0.1034    96.763  462.26
  21   0.1094     96.530  0.1055    96.713  485.22
  22   0.0879     97.120  0.1007    96.762  508.20
  23   0.0981     96.850  0.1026    96.797  531.17
  24   0.1055     96.620  0.1040    96.820  554.16
  25   0.0827     97.230  0.1015    96.842  577.18
  26   0.1002     96.670  0.1007    96.880  600.15
  27   0.1028     96.890  0.1011    96.815  623.15
  28   0.1951     93.480  0.1020    96.827  646.16
  29   0.1030     96.590  0.1009    96.923  669.13
  30   0.0909     97.010  0.1014    96.903  692.16
  31   0.0756     97.560  0.1031    96.715  715.18
  32   0.0749     97.600  0.1012    96.857  738.17
  33   0.0786     97.540  0.0996    96.947  761.20
  34   0.0826     97.100  0.1027    96.805  784.21
  35   0.1353     95.710  0.1022    96.865  807.20
  36   0.1121     96.710  0.1055    96.795  830.18
  37   0.0957     97.010  0.1011    96.813  853.19
  38   0.0871     97.200  0.1010    96.830  876.14
  39   0.0761     97.490  0.1054    96.727  899.13
  40   0.1582     94.980  0.1022    96.840  922.13
  41   0.4068     91.110  0.1028    96.757  945.15
  42   0.1157     96.260  0.1051    96.698  968.14
  43   0.0889     96.920  0.0999    96.870  991.17
  44   0.1028     96.780  0.1034    96.785  1014.21
  45   0.1280     95.860  0.1054    96.685  1037.20
  46   0.0937     96.880  0.1030    96.887  1060.20
  47   0.0899     97.310  0.1009    96.845  1083.15
  48   0.1367     95.290  0.0997    96.897  1106.16
  49   0.0988     96.890  0.1006    96.917  1129.19
  50   0.1404     95.450  0.1001    96.850  1152.19
  51   0.1462     95.590  0.1014    96.812  1175.18
  52   0.0824     97.430  0.1018    96.892  1198.19
  53   0.0876     97.240  0.1007    96.857  1221.16
  54   0.0928     97.010  0.1051    96.793  1244.15
  55   0.1000     96.900  0.1031    96.775  1267.15
  56   1.1146     80.170  0.1038    96.743  1290.14
  57   0.0995     96.970  0.0986    96.948  1313.13
  58   0.1021     96.620  0.1026    96.767  1336.17
  59   0.1139     96.170  0.0987    96.915  1359.14
  60   0.1044     96.780  0.1015    96.790  1382.13
  61   0.1027     96.550  0.0990    96.915  1405.16
  62   0.4537     86.600  0.0999    96.895  1428.15
  63   0.1059     96.670  0.1018    96.875  1451.15
  64   0.0780     97.520  0.0997    96.958  1474.17
  65   0.1071     96.630  0.1026    96.882  1497.20
  66   0.0914     97.010  0.1002    96.875  1520.18
  67   0.1155     96.290  0.1025    96.887  1543.20
  68   0.1245     95.940  0.1006    96.867  1566.17
  69   0.1049     96.690  0.1022    96.838  1589.15
  70   0.1840     93.990  0.0991    96.997  1612.13
  71   0.0996     96.700  0.1006    96.845  1635.14
  72   0.0978     97.030  0.1028    96.862  1658.13
  73   0.1313     95.600  0.1018    96.835  1681.11
  74   0.0981     96.580  0.1066    96.742  1704.09
  75   0.0969     96.960  0.1044    96.807  1727.06
  76   0.1135     96.310  0.1015    96.817  1750.07
  77   0.1195     96.270  0.1018    96.793  1773.09
  78   0.1008     96.800  0.0996    96.935  1796.09
  79   0.0957     96.960  0.1025    96.837  1819.10
  80   0.0977     96.950  0.1000    96.837  1842.09
  81   0.1078     96.520  0.0972    97.038  1865.07
  82   0.1532     95.080  0.1008    96.907  1888.08
  83   0.0974     96.820  0.0992    96.978  1911.08
  84   0.0942     96.940  0.1011    96.922  1934.06
  85   0.1112     96.440  0.1012    96.945  1957.02
  86   0.0963     96.800  0.1006    96.945  1980.02
  87   0.0931     96.960  0.0996    96.967  2002.99
  88   0.0944     96.870  0.1021    96.800  2026.01
  89   0.0966     97.050  0.1007    96.868  2049.01
  90   0.0942     96.670  0.1001    96.963  2071.97
