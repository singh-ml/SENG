Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1328     96.020  0.3692    88.018  25.34
   2   0.1284     95.990  0.1443    95.702  48.29
   3   0.0985     96.920  0.1321    95.955  71.26
   4   0.1200     96.090  0.1224    96.412  94.23
   5   0.0940     97.050  0.1146    96.525  117.15
   6   0.1219     96.440  0.1005    96.965  140.11
   7   0.0648     98.090  0.0922    97.307  163.05
   8   0.0875     97.490  0.0838    97.495  185.98
   9   0.0675     98.010  0.0784    97.652  208.91
  10   0.0663     97.950  0.0745    97.825  231.89
  11   0.0720     97.820  0.0709    97.902  254.82
  12   0.0854     97.380  0.0645    98.100  277.80
  13   0.0477     98.520  0.0650    98.108  300.76
  14   0.0734     97.730  0.0645    98.107  323.72
  15   0.0541     98.220  0.0601    98.267  346.69
  16   0.0732     97.770  0.0595    98.230  369.67
  17   0.0510     98.440  0.0590    98.252  392.60
  18   0.0538     98.320  0.0558    98.335  415.55
  19   0.0568     98.120  0.0555    98.365  438.54
  20   0.0560     98.260  0.0550    98.425  461.49
  21   0.0690     97.990  0.0523    98.472  484.43
  22   0.0511     98.470  0.0536    98.465  507.39
  23   0.0796     97.520  0.0525    98.440  530.40
  24   0.0504     98.500  0.0515    98.483  553.35
  25   0.0600     98.100  0.0532    98.440  576.29
  26   0.0583     98.120  0.0496    98.540  599.23
  27   0.0458     98.630  0.0496    98.528  622.22
  28   0.0463     98.590  0.0481    98.560  645.19
  29   0.0620     98.090  0.0504    98.492  668.13
  30   0.0474     98.540  0.0479    98.625  691.07
  31   0.0409     98.830  0.0489    98.572  714.03
  32   0.0546     98.180  0.0490    98.550  736.97
  33   0.0633     97.910  0.0473    98.550  759.93
  34   0.0457     98.640  0.0467    98.627  782.87
  35   0.0584     98.220  0.0448    98.698  805.81
  36   0.0534     98.320  0.0463    98.655  828.78
  37   0.0660     98.020  0.0453    98.650  851.74
  38   0.0586     98.200  0.0460    98.682  874.67
  39   0.0671     97.920  0.0454    98.623  897.65
  40   0.0821     97.330  0.0439    98.690  920.64
  41   0.0447     98.650  0.0444    98.642  943.57
  42   0.0404     98.690  0.0448    98.673  966.50
  43   0.0565     98.340  0.0437    98.698  989.46
  44   0.0476     98.620  0.0444    98.677  1012.40
  45   0.0479     98.640  0.0438    98.718  1035.40
  46   0.0558     98.240  0.0445    98.655  1058.37
  47   0.0494     98.640  0.0426    98.733  1081.31
  48   0.0409     98.760  0.0419    98.715  1104.25
  49   0.0517     98.370  0.0441    98.658  1127.24
  50   0.0476     98.460  0.0410    98.835  1150.19
  51   0.0438     98.710  0.0436    98.745  1173.15
  52   0.0606     98.160  0.0403    98.787  1196.13
  53   0.0456     98.640  0.0434    98.688  1219.09
  54   0.0476     98.510  0.0417    98.762  1242.09
  55   0.0577     98.260  0.0400    98.813  1265.05
  56   0.0568     98.260  0.0421    98.743  1287.99
  57   0.0362     98.840  0.0433    98.730  1310.94
  58   0.0509     98.420  0.0406    98.812  1333.89
  59   0.0315     99.010  0.0406    98.758  1356.87
  60   0.0484     98.590  0.0427    98.737  1379.80
  61   0.0500     98.420  0.0411    98.823  1402.77
  62   0.0420     98.730  0.0419    98.772  1425.72
  63   0.0488     98.520  0.0401    98.847  1448.69
  64   0.0573     98.360  0.0425    98.742  1471.67
  65   0.0506     98.360  0.0410    98.805  1494.64
  66   0.0439     98.770  0.0418    98.747  1517.59
  67   0.0440     98.790  0.0394    98.843  1540.56
  68   0.0355     98.920  0.0408    98.758  1563.51
  69   0.0571     98.300  0.0412    98.770  1586.44
  70   0.0484     98.470  0.0408    98.793  1609.40
  71   0.0580     98.120  0.0409    98.827  1632.34
  72   0.0439     98.750  0.0407    98.775  1655.30
  73   0.0614     98.140  0.0403    98.843  1678.27
  74   0.0508     98.450  0.0400    98.767  1701.26
  75   0.0387     98.700  0.0410    98.762  1724.20
  76   0.0392     98.740  0.0388    98.813  1747.18
  77   0.0615     98.210  0.0389    98.837  1770.14
  78   0.0380     98.750  0.0382    98.823  1793.09
  79   0.0361     98.820  0.0392    98.843  1816.03
  80   0.0510     98.510  0.0392    98.837  1839.03
  81   0.0359     98.960  0.0374    98.903  1861.96
  82   0.0637     98.190  0.0389    98.857  1884.90
  83   0.0537     98.280  0.0390    98.795  1907.86
  84   0.0499     98.550  0.0405    98.760  1930.85
  85   0.0595     98.240  0.0386    98.810  1953.82
