Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2582     91.210  0.7457    74.377  25.36
   2   0.1146     96.220  0.1664    94.655  48.37
   3   0.0943     96.920  0.0924    97.143  71.34
   4   0.0674     97.660  0.0761    97.653  94.35
   5   0.0663     97.860  0.0665    97.915  117.34
   6   0.0687     97.810  0.0611    98.132  140.38
   7   0.0533     98.250  0.0547    98.272  163.36
   8   0.0542     98.250  0.0552    98.237  186.36
   9   0.0449     98.650  0.0511    98.413  209.33
  10   0.0554     98.190  0.0517    98.410  232.32
  11   0.0509     98.360  0.0473    98.548  255.30
  12   0.0496     98.630  0.0480    98.525  278.28
  13   0.0464     98.580  0.0492    98.500  301.28
  14   0.0460     98.570  0.0492    98.495  324.24
  15   0.0652     97.980  0.0436    98.662  347.22
  16   0.0501     98.450  0.0425    98.673  370.25
  17   0.0520     98.290  0.0422    98.703  393.25
  18   0.0376     98.770  0.0404    98.768  416.22
  19   0.0467     98.490  0.0402    98.730  439.23
  20   0.0402     98.620  0.0426    98.683  462.25
  21   0.0338     98.900  0.0409    98.757  485.24
  22   0.0320     98.970  0.0400    98.743  508.27
  23   0.0520     98.340  0.0395    98.753  531.27
  24   0.0426     98.640  0.0351    98.912  554.27
  25   0.0407     98.700  0.0362    98.882  577.25
  26   0.0380     98.900  0.0357    98.907  600.24
  27   0.0467     98.460  0.0350    98.938  623.30
  28   0.0398     98.720  0.0317    99.032  646.31
  29   0.0455     98.700  0.0349    98.912  669.30
  30   0.0403     98.690  0.0346    98.943  692.27
  31   0.0404     98.720  0.0321    99.028  715.31
  32   0.0349     98.940  0.0343    98.955  738.30
  33   0.0331     98.960  0.0319    99.028  761.30
  34   0.0417     98.730  0.0301    99.060  784.29
  35   0.0432     98.630  0.0312    99.047  807.26
  36   0.0431     98.720  0.0310    99.105  830.28
  37   0.0393     98.780  0.0290    99.127  853.30
  38   0.0308     99.080  0.0295    99.120  876.29
  39   0.0355     98.880  0.0291    99.082  899.28
  40   0.0480     98.640  0.0294    99.140  922.30
  41   0.0301     99.150  0.0297    99.085  945.28
  42   0.0338     98.950  0.0285    99.097  968.27
  43   0.0471     98.580  0.0311    99.063  991.29
  44   0.0312     98.970  0.0282    99.147  1014.26
  45   0.0329     98.990  0.0275    99.173  1037.28
  46   0.0558     98.330  0.0284    99.137  1060.33
  47   0.0276     99.080  0.0295    99.113  1083.31
  48   0.0321     99.010  0.0265    99.198  1106.35
  49   0.0363     98.880  0.0255    99.207  1129.39
  50   0.0412     98.580  0.0294    99.070  1152.38
  51   0.0465     98.610  0.0240    99.268  1175.41
  52   0.0334     98.950  0.0259    99.210  1198.41
  53   0.0351     98.950  0.0242    99.250  1221.43
  54   0.0336     98.960  0.0255    99.220  1244.43
  55   0.0311     99.030  0.0248    99.217  1267.43
  56   0.0407     98.750  0.0261    99.223  1290.42
  57   0.0463     98.630  0.0259    99.252  1313.43
  58   0.0443     98.630  0.0243    99.243  1336.44
  59   0.0283     99.110  0.0252    99.232  1359.43
  60   0.0421     98.760  0.0236    99.245  1382.47
  61   0.0374     98.930  0.0221    99.315  1405.49
  62   0.0262     99.160  0.0248    99.212  1428.46
  63   0.0385     98.870  0.0247    99.245  1451.43
  64   0.0295     99.110  0.0235    99.290  1474.45
  65   0.0344     98.870  0.0224    99.288  1497.42
  66   0.0548     98.220  0.0236    99.248  1520.42
  67   0.0373     98.980  0.0227    99.282  1543.43
  68   0.0318     99.010  0.0231    99.308  1566.41
  69   0.0348     98.990  0.0216    99.352  1589.44
  70   0.0305     99.020  0.0223    99.250  1612.45
  71   0.0419     98.530  0.0193    99.387  1635.43
  72   0.0534     98.550  0.0217    99.320  1658.46
  73   0.0437     98.770  0.0226    99.328  1681.46
  74   0.0393     98.820  0.0214    99.363  1704.46
  75   0.0424     98.770  0.0201    99.398  1727.49
  76   0.0362     98.990  0.0227    99.288  1750.50
  77   0.0467     98.630  0.0209    99.355  1773.46
  78   0.0307     99.050  0.0211    99.337  1796.48
  79   0.0587     98.330  0.0209    99.382  1819.46
  80   0.0461     98.640  0.0195    99.407  1842.43
  81   0.0396     98.730  0.0190    99.405  1865.42
  82   0.0337     99.040  0.0216    99.360  1888.45
  83   0.0480     98.650  0.0222    99.318  1911.46
  84   0.0348     98.980  0.0211    99.353  1934.46
  85   0.0361     98.860  0.0197    99.403  1957.47
  86   0.0365     98.980  0.0181    99.415  1980.46
  87   0.0392     98.730  0.0187    99.417  2003.47
  88   0.0363     98.890  0.0209    99.342  2026.47
  89   0.0350     98.890  0.0188    99.417  2049.46
  90   0.0331     99.000  0.0180    99.445  2072.47
