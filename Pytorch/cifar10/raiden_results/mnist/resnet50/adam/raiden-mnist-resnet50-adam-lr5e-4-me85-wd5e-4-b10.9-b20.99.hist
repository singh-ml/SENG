Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1086     96.650  0.4273    85.400  25.36
   2   0.1147     96.310  0.1219    96.263  48.46
   3   0.1344     95.700  0.1069    96.698  71.54
   4   0.0800     97.510  0.1033    96.898  94.61
   5   0.1412     95.840  0.0933    97.173  117.70
   6   0.0885     97.400  0.0846    97.417  140.79
   7   0.0887     97.440  0.0852    97.402  163.85
   8   0.1128     96.600  0.0775    97.720  186.92
   9   0.0754     97.630  0.0757    97.738  209.97
  10   0.1082     96.690  0.0720    97.805  233.03
  11   0.1400     95.440  0.0699    97.932  256.06
  12   0.0507     98.440  0.0641    98.088  279.12
  13   0.0838     97.330  0.0641    98.103  302.17
  14   0.0700     97.860  0.0572    98.297  325.24
  15   0.0642     97.910  0.0595    98.260  348.31
  16   0.0594     98.130  0.0585    98.268  371.38
  17   0.0408     98.850  0.0544    98.428  394.50
  18   0.0354     98.890  0.0547    98.407  417.59
  19   0.0498     98.480  0.0520    98.502  440.70
  20   0.0661     97.910  0.0508    98.447  463.82
  21   0.0545     98.500  0.0504    98.495  486.95
  22   0.0489     98.490  0.0503    98.517  510.07
  23   0.0466     98.590  0.0501    98.532  533.20
  24   0.0564     98.230  0.0466    98.672  556.32
  25   0.0449     98.550  0.0471    98.607  579.42
  26   0.0383     98.740  0.0450    98.670  602.53
  27   0.0577     98.260  0.0448    98.658  625.68
  28   0.0644     98.040  0.0444    98.697  648.79
  29   0.0663     98.130  0.0421    98.725  671.90
  30   0.0524     98.510  0.0433    98.708  695.03
  31   0.0545     98.330  0.0417    98.808  718.13
  32   0.0590     98.110  0.0420    98.798  741.27
  33   0.0401     98.790  0.0418    98.780  764.40
  34   0.0376     98.900  0.0401    98.768  787.53
  35   0.0312     99.040  0.0388    98.840  810.66
  36   0.0493     98.510  0.0406    98.835  833.79
  37   0.0538     98.460  0.0387    98.883  856.91
  38   0.0565     98.250  0.0401    98.847  880.06
  39   0.0375     98.830  0.0400    98.857  903.20
  40   0.0412     98.840  0.0374    98.885  926.31
  41   0.0545     98.350  0.0383    98.868  949.46
  42   0.0444     98.640  0.0368    98.928  972.61
  43   0.0542     98.540  0.0383    98.872  995.73
  44   0.0449     98.720  0.0371    98.897  1018.86
  45   0.0334     98.960  0.0365    98.908  1042.00
  46   0.0351     98.850  0.0379    98.843  1065.12
  47   0.0547     98.370  0.0362    98.948  1088.24
  48   0.0339     99.000  0.0364    98.977  1111.38
  49   0.0442     98.760  0.0376    98.867  1134.49
  50   0.0280     99.120  0.0369    98.978  1157.60
  51   0.0446     98.630  0.0348    98.953  1180.73
  52   0.0539     98.470  0.0350    98.952  1203.85
  53   0.0611     98.020  0.0355    98.950  1226.97
  54   0.0394     98.890  0.0351    98.970  1250.11
  55   0.0386     98.810  0.0349    98.957  1273.23
  56   0.0455     98.500  0.0336    98.978  1296.34
  57   0.0432     98.700  0.0344    98.970  1319.48
  58   0.0408     98.780  0.0344    98.967  1342.58
  59   0.0313     99.030  0.0340    98.993  1365.69
  60   0.0360     98.940  0.0340    99.000  1388.79
  61   0.0413     98.730  0.0335    98.997  1411.91
  62   0.0329     98.970  0.0328    99.053  1435.02
  63   0.0509     98.520  0.0324    99.002  1458.15
  64   0.0582     98.420  0.0324    99.023  1481.27
  65   0.0269     99.260  0.0333    98.995  1504.40
  66   0.0494     98.520  0.0339    99.020  1527.50
  67   0.0490     98.670  0.0320    99.077  1550.66
  68   0.0354     99.010  0.0344    98.997  1573.78
  69   0.0456     98.750  0.0315    99.075  1596.92
  70   0.0480     98.490  0.0320    99.057  1620.05
  71   0.0436     98.790  0.0314    99.080  1643.18
  72   0.0312     99.010  0.0327    99.057  1666.32
  73   0.0482     98.610  0.0307    99.058  1689.52
  74   0.0497     98.550  0.0315    99.050  1712.61
  75   0.0315     99.080  0.0317    99.093  1735.71
  76   0.0368     98.890  0.0316    99.097  1758.82
  77   0.0322     99.090  0.0307    99.107  1781.92
  78   0.0413     98.790  0.0308    99.102  1805.02
  79   0.0460     98.650  0.0335    99.045  1828.15
  80   0.0328     98.970  0.0316    99.057  1851.27
  81   0.0409     98.830  0.0302    99.097  1874.39
  82   0.0412     98.870  0.0321    99.075  1897.51
  83   0.0292     99.100  0.0320    99.060  1920.62
  84   0.0415     98.710  0.0312    99.112  1943.86
  85   0.0407     98.880  0.0321    99.050  1967.04
