Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2062     93.210  0.4345    85.693  25.37
   2   0.1187     96.500  0.1500    95.383  48.49
   3   0.1092     96.600  0.1256    96.165  71.57
   4   0.0860     97.350  0.1146    96.558  94.67
   5   0.1157     96.600  0.1059    96.812  117.76
   6   0.0877     97.260  0.0928    97.173  140.89
   7   0.0716     97.870  0.0851    97.455  163.98
   8   0.0564     98.080  0.0785    97.543  187.11
   9   0.0723     97.870  0.0738    97.747  210.22
  10   0.0572     98.340  0.0692    97.908  233.32
  11   0.0698     98.030  0.0696    97.910  256.46
  12   0.0671     97.760  0.0652    98.030  279.58
  13   0.0461     98.710  0.0606    98.162  302.68
  14   0.0581     98.080  0.0602    98.162  325.79
  15   0.0642     97.990  0.0581    98.242  348.89
  16   0.0538     98.330  0.0565    98.295  372.00
  17   0.0481     98.690  0.0542    98.422  395.13
  18   0.0428     98.650  0.0545    98.365  418.21
  19   0.0508     98.460  0.0535    98.367  441.33
  20   0.0495     98.630  0.0539    98.383  464.45
  21   0.0630     98.070  0.0501    98.505  487.55
  22   0.0736     97.710  0.0504    98.440  510.69
  23   0.0445     98.750  0.0499    98.523  533.82
  24   0.0709     97.880  0.0488    98.545  556.92
  25   0.0563     98.090  0.0476    98.568  580.06
  26   0.0760     97.830  0.0477    98.567  603.18
  27   0.0542     98.290  0.0458    98.622  626.29
  28   0.0699     97.810  0.0468    98.555  649.39
  29   0.0410     98.710  0.0444    98.678  672.54
  30   0.0631     98.030  0.0458    98.620  695.64
  31   0.0495     98.340  0.0479    98.567  718.72
  32   0.0577     98.160  0.0464    98.558  741.85
  33   0.0376     98.770  0.0458    98.612  764.96
  34   0.0572     98.130  0.0419    98.723  788.09
  35   0.0423     98.690  0.0441    98.647  811.19
  36   0.0617     98.140  0.0435    98.738  834.30
  37   0.0517     98.350  0.0425    98.720  857.43
  38   0.0388     98.700  0.0434    98.692  880.52
  39   0.0699     97.690  0.0435    98.693  903.66
  40   0.0389     98.740  0.0413    98.758  926.78
  41   0.0634     98.150  0.0406    98.813  949.87
  42   0.0335     98.940  0.0398    98.798  973.00
  43   0.0398     98.810  0.0412    98.768  996.11
  44   0.0534     98.470  0.0399    98.842  1019.20
  45   0.0405     98.710  0.0403    98.782  1042.34
  46   0.0468     98.580  0.0383    98.832  1065.42
  47   0.0359     98.880  0.0381    98.838  1088.53
  48   0.0474     98.550  0.0386    98.833  1111.69
  49   0.0523     98.490  0.0421    98.733  1134.78
  50   0.0419     98.670  0.0377    98.880  1157.92
  51   0.0427     98.700  0.0380    98.830  1181.04
  52   0.0322     98.940  0.0386    98.825  1204.16
  53   0.0359     98.880  0.0400    98.775  1227.32
  54   0.0543     98.340  0.0389    98.853  1250.43
  55   0.0557     98.320  0.0396    98.838  1273.53
  56   0.0712     97.930  0.0387    98.862  1296.66
  57   0.0350     98.860  0.0379    98.882  1319.75
  58   0.0833     97.730  0.0377    98.898  1342.84
  59   0.0391     98.860  0.0389    98.817  1365.98
  60   0.0563     98.400  0.0382    98.855  1389.10
  61   0.0542     98.310  0.0397    98.778  1412.20
  62   0.0584     98.220  0.0386    98.868  1435.30
  63   0.1056     97.230  0.0365    98.910  1458.39
  64   0.0392     98.870  0.0402    98.815  1481.49
  65   0.0416     98.800  0.0388    98.852  1504.59
  66   0.0405     98.680  0.0372    98.888  1527.70
  67   0.0353     98.800  0.0378    98.883  1550.79
  68   0.0689     97.980  0.0356    98.900  1573.92
  69   0.0505     98.330  0.0368    98.897  1597.02
  70   0.0431     98.660  0.0383    98.880  1620.13
  71   0.0461     98.540  0.0361    98.905  1643.23
  72   0.0695     97.920  0.0357    98.952  1666.32
  73   0.0426     98.770  0.0356    98.912  1689.47
  74   0.0408     98.800  0.0366    98.888  1712.58
  75   0.0439     98.630  0.0350    98.935  1735.66
  76   0.0391     98.790  0.0384    98.860  1758.78
  77   0.0571     98.170  0.0361    98.875  1781.90
  78   0.0398     98.840  0.0358    98.922  1804.98
  79   0.0417     98.660  0.0343    98.987  1828.09
  80   0.0403     98.790  0.0364    98.877  1851.21
  81   0.0557     98.270  0.0371    98.875  1874.29
  82   0.0428     98.730  0.0356    98.947  1897.37
  83   0.0428     98.670  0.0351    98.922  1920.49
  84   0.0636     98.130  0.0371    98.888  1943.60
  85   0.0442     98.540  0.0373    98.868  1966.71
  86   0.0690     97.970  0.0360    98.900  1989.85
  87   0.0364     98.860  0.0339    98.948  2012.97
  88   0.0402     98.880  0.0347    98.952  2036.07
  89   0.0372     98.900  0.0331    99.020  2059.15
  90   0.0989     96.960  0.0354    98.972  2082.29
