Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.7424     76.030  1.8523    40.213  25.33
   2   0.2235     92.550  0.4487    85.577  48.45
   3   0.1737     94.530  0.1773    94.570  71.55
   4   0.1387     95.500  0.1409    95.657  94.67
   5   0.1024     96.490  0.1114    96.628  117.80
   6   0.0762     97.550  0.0967    96.983  140.91
   7   0.0792     97.440  0.0927    97.132  164.02
   8   0.0741     97.770  0.0868    97.360  187.13
   9   0.0609     98.090  0.0834    97.462  210.24
  10   0.0792     97.470  0.0788    97.610  233.35
  11   0.0746     97.550  0.0784    97.533  256.48
  12   0.0701     97.840  0.0761    97.722  279.58
  13   0.0556     98.230  0.0744    97.752  302.71
  14   0.0651     97.790  0.0733    97.718  325.81
  15   0.0668     97.830  0.0719    97.753  348.92
  16   0.0729     97.610  0.0728    97.768  372.03
  17   0.0491     98.370  0.0707    97.830  395.13
  18   0.0632     97.940  0.0704    97.832  418.22
  19   0.0455     98.450  0.0704    97.852  441.32
  20   0.0696     97.810  0.0692    97.898  464.41
  21   0.0579     98.150  0.0703    97.935  487.52
  22   0.0511     98.300  0.0686    97.890  510.62
  23   0.0649     97.850  0.0680    97.905  533.70
  24   0.0567     98.170  0.0674    97.918  556.83
  25   0.0672     97.850  0.0683    97.907  579.96
  26   0.0740     97.560  0.0663    97.982  603.04
  27   0.0570     98.130  0.0666    97.948  626.17
  28   0.0726     97.660  0.0658    97.933  649.28
  29   0.0596     98.020  0.0666    97.997  672.43
  30   0.0635     97.840  0.0653    97.982  695.55
  31   0.0639     97.960  0.0659    97.982  718.64
  32   0.0494     98.470  0.0645    98.013  741.76
  33   0.0797     97.520  0.0643    98.037  764.89
  34   0.0535     98.340  0.0648    98.007  788.01
  35   0.0652     97.750  0.0679    97.895  811.12
