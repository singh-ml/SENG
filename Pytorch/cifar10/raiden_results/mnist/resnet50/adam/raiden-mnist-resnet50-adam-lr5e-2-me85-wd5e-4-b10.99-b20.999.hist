Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.8650     70.440  2.9221    40.988  25.34
   2   0.3573     89.670  0.3873    87.802  48.41
   3   0.1766     94.360  0.2444    92.548  71.44
   4   0.2260     92.870  0.2122    93.460  94.44
   5   0.1439     95.440  0.1927    93.913  117.43
   6   0.1494     95.470  0.1729    94.660  140.48
   7   0.1859     94.420  0.1710    94.785  163.47
   8   0.8365     70.990  0.1667    94.833  186.52
   9   0.1383     95.790  0.1652    94.977  209.54
  10   0.1914     93.760  0.1605    95.128  232.53
  11   0.1562     95.350  0.1603    95.025  255.54
  12   0.1485     95.280  0.1565    95.178  278.56
  13   0.1435     95.470  0.1557    95.233  301.57
  14   0.1475     95.310  0.1576    95.102  324.58
  15   0.1394     95.550  0.1495    95.358  347.56
  16   0.1613     95.130  0.1524    95.400  370.57
  17   0.2295     92.720  0.1530    95.197  393.60
  18   0.2070     93.910  0.1519    95.307  416.62
  19   0.1317     95.940  0.1511    95.352  439.59
  20   0.2164     92.630  0.1513    95.297  462.62
  21   0.1146     96.570  0.1459    95.495  485.63
  22   0.1516     95.180  0.1470    95.412  508.62
  23   0.1597     94.940  0.1482    95.430  531.61
  24   0.1723     94.350  0.1511    95.338  554.62
  25   0.2111     93.110  0.1506    95.438  577.62
  26   0.2472     92.070  0.1534    95.310  600.61
  27   0.2251     92.860  0.1480    95.460  623.62
  28   2.6515     43.650  0.1521    95.387  646.62
  29   0.1191     96.380  0.1455    95.415  669.64
  30   0.1356     95.450  0.1492    95.405  692.64
  31   0.1216     96.050  0.1510    95.380  715.66
  32   0.1386     95.440  0.1468    95.550  738.66
  33   0.3124     90.140  0.1452    95.558  761.67
  34   0.1714     94.960  0.1525    95.373  784.69
  35   0.1343     95.690  0.1498    95.395  807.71
  36   0.3986     87.140  0.1460    95.587  830.72
  37   0.3467     87.690  0.1486    95.463  853.73
  38   0.1586     94.760  0.1474    95.515  876.76
  39   0.2165     92.920  0.1453    95.498  899.76
  40   0.2927     91.270  0.1519    95.412  922.78
  41   0.1134     96.690  0.1481    95.555  945.81
  42   0.2362     90.850  0.1469    95.473  968.83
  43   0.1482     95.390  0.1459    95.567  991.85
  44   0.2519     91.720  0.1446    95.552  1014.87
  45   0.2149     92.930  0.1479    95.603  1037.87
  46   0.2578     91.060  0.1450    95.547  1060.92
  47   0.1654     94.370  0.1487    95.518  1083.91
  48   0.1225     96.110  0.1438    95.568  1106.95
  49   0.1622     94.600  0.1472    95.440  1129.94
  50   0.1190     96.230  0.1465    95.570  1152.96
  51   0.1688     94.240  0.1495    95.323  1175.97
  52   0.1203     96.000  0.1465    95.497  1198.97
  53   0.2188     93.140  0.1466    95.432  1221.99
  54   0.4624     86.620  0.1439    95.572  1245.00
  55   0.2278     91.950  0.1403    95.693  1268.04
  56   0.1728     94.620  0.1487    95.425  1291.07
  57   0.1372     95.700  0.1485    95.495  1314.09
  58   0.1767     94.120  0.1438    95.653  1337.10
  59   0.5329     81.860  0.1482    95.447  1360.16
  60   11.3682     10.460  0.1440    95.552  1383.18
  61   0.2601     91.930  0.1465    95.467  1406.18
  62   0.1069     96.560  0.1442    95.532  1429.24
  63   0.1690     94.820  0.1440    95.632  1452.23
  64   0.1885     93.390  0.1458    95.527  1475.26
  65   0.1051     96.630  0.1449    95.595  1498.30
  66   0.1973     94.300  0.1448    95.497  1521.31
  67   0.1130     96.410  0.1451    95.563  1544.38
  68   0.1940     94.030  0.1478    95.467  1567.41
  69   0.1498     95.170  0.1441    95.587  1590.43
  70   0.1417     95.250  0.1462    95.567  1613.43
  71   0.1384     95.730  0.1468    95.528  1636.43
  72   0.1527     95.130  0.1434    95.562  1659.46
  73   0.2232     93.140  0.1432    95.645  1682.48
  74   0.2765     90.810  0.1478    95.480  1705.51
  75   0.5390     83.810  0.1474    95.543  1728.51
  76   0.3146     90.110  0.1453    95.550  1751.53
  77   0.1373     95.690  0.1437    95.630  1774.56
  78   0.1651     94.910  0.1428    95.618  1797.58
  79   0.1475     94.840  0.1445    95.538  1820.62
  80   0.1302     95.940  0.1442    95.635  1843.63
  81   0.2162     93.110  0.1464    95.535  1866.64
  82   0.1450     95.200  0.1473    95.563  1889.66
  83   0.1499     95.180  0.1464    95.577  1912.70
  84   0.2415     91.870  0.1464    95.545  1935.68
  85   0.1701     94.370  0.1498    95.347  1958.70
