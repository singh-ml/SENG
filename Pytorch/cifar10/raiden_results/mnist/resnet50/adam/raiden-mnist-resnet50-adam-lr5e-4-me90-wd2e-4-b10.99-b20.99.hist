Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1595     94.980  0.5062    82.873  25.28
   2   0.0875     97.230  0.1375    95.675  48.29
   3   0.1220     96.050  0.0980    96.908  71.27
   4   0.0679     97.770  0.0891    97.273  94.31
   5   0.0767     97.720  0.0846    97.407  117.32
   6   0.0611     97.960  0.0736    97.737  140.30
   7   0.0529     98.250  0.0710    97.838  163.27
   8   0.0578     98.320  0.0708    97.823  186.25
   9   0.0556     98.270  0.0631    98.000  209.25
  10   0.0637     97.970  0.0591    98.197  232.26
  11   0.0524     98.270  0.0577    98.255  255.24
  12   0.0540     98.340  0.0563    98.303  278.22
  13   0.0535     98.210  0.0554    98.302  301.23
  14   0.0738     97.780  0.0539    98.393  324.22
  15   0.0555     98.320  0.0515    98.413  347.19
  16   0.0613     97.980  0.0501    98.480  370.20
  17   0.0578     98.320  0.0511    98.422  393.22
  18   0.0641     98.100  0.0484    98.512  416.19
  19   0.0525     98.170  0.0453    98.617  439.23
  20   0.0473     98.500  0.0465    98.555  462.23
  21   0.0428     98.710  0.0457    98.597  485.21
  22   0.0416     98.590  0.0445    98.617  508.22
  23   0.0446     98.520  0.0433    98.638  531.18
  24   0.0400     98.680  0.0404    98.808  554.18
  25   0.0486     98.510  0.0404    98.777  577.19
  26   0.0474     98.420  0.0408    98.732  600.16
  27   0.0488     98.410  0.0398    98.775  623.17
  28   0.0480     98.440  0.0395    98.792  646.17
  29   0.0467     98.450  0.0393    98.793  669.17
  30   0.0404     98.650  0.0393    98.778  692.16
  31   0.0575     98.120  0.0404    98.777  715.15
  32   0.0578     98.230  0.0372    98.818  738.18
  33   0.0538     98.220  0.0369    98.863  761.16
  34   0.0264     99.140  0.0364    98.922  784.18
  35   0.0364     98.820  0.0352    98.878  807.20
  36   0.0329     98.940  0.0364    98.890  830.19
  37   0.0433     98.550  0.0333    98.943  853.22
  38   0.0341     98.850  0.0325    98.983  876.24
  39   0.0359     98.900  0.0320    98.983  899.22
  40   0.0574     98.130  0.0348    98.882  922.22
  41   0.0325     99.040  0.0338    98.955  945.22
  42   0.0314     99.040  0.0351    98.963  968.18
  43   0.0379     98.720  0.0323    99.025  991.19
  44   0.0551     98.380  0.0318    99.022  1014.17
  45   0.0476     98.570  0.0309    99.045  1037.17
  46   0.0320     98.960  0.0320    98.985  1060.21
  47   0.0467     98.520  0.0329    98.992  1083.22
  48   0.0355     98.940  0.0302    99.072  1106.23
  49   0.0350     98.930  0.0289    99.082  1129.21
  50   0.0405     98.680  0.0316    98.992  1152.23
  51   0.0446     98.550  0.0299    99.057  1175.22
  52   0.0434     98.640  0.0293    99.085  1198.23
  53   0.0378     98.930  0.0294    99.087  1221.22
  54   0.0402     98.740  0.0290    99.105  1244.19
  55   0.0397     98.700  0.0268    99.160  1267.19
  56   0.0502     98.450  0.0293    99.107  1290.19
  57   0.0355     98.850  0.0290    99.095  1313.17
  58   0.0375     98.780  0.0295    99.087  1336.14
  59   0.0399     98.750  0.0295    99.070  1359.11
  60   0.0355     98.810  0.0281    99.153  1382.07
  61   0.0444     98.680  0.0273    99.138  1405.07
  62   0.0350     98.910  0.0281    99.153  1428.07
  63   0.0511     98.200  0.0243    99.235  1451.06
  64   0.0382     98.680  0.0283    99.115  1474.05
  65   0.0334     99.030  0.0261    99.168  1497.02
  66   0.0335     98.940  0.0279    99.133  1519.99
  67   0.0434     98.650  0.0274    99.133  1542.97
  68   0.0424     98.770  0.0262    99.188  1565.99
  69   0.0424     98.540  0.0262    99.143  1588.96
  70   0.0494     98.630  0.0271    99.168  1611.96
  71   0.0404     98.770  0.0267    99.145  1634.97
  72   0.0400     98.830  0.0261    99.175  1657.93
  73   0.0404     98.800  0.0254    99.185  1680.93
  74   0.0480     98.340  0.0243    99.230  1703.91
  75   0.0389     98.750  0.0246    99.217  1726.90
  76   0.0395     98.860  0.0247    99.233  1749.90
  77   0.0347     98.840  0.0256    99.220  1772.91
  78   0.0430     98.740  0.0248    99.178  1795.90
  79   0.0357     98.930  0.0246    99.227  1818.92
  80   0.0272     99.180  0.0253    99.183  1841.92
  81   0.0393     98.650  0.0240    99.257  1864.93
  82   0.0275     99.240  0.0228    99.270  1887.95
  83   0.0446     98.810  0.0254    99.188  1910.96
  84   0.0431     98.680  0.0230    99.275  1933.95
  85   0.0388     98.720  0.0240    99.263  1956.94
  86   0.0441     98.680  0.0239    99.265  1979.94
  87   0.0318     99.050  0.0239    99.248  2002.90
  88   0.0368     98.810  0.0237    99.243  2025.90
  89   0.0428     98.770  0.0232    99.283  2048.89
  90   0.0430     98.770  0.0239    99.258  2071.87
