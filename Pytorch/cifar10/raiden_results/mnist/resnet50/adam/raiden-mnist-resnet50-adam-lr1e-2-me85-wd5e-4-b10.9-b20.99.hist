Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.7417     78.430  1.3871    58.903  25.53
   2   0.3436     89.270  0.2680    91.900  48.67
   3   0.3459     90.410  0.1978    94.050  71.75
   4   0.1626     94.800  0.1650    94.925  94.82
   5   0.1462     95.550  0.1409    95.750  117.92
   6   0.1367     95.580  0.1299    96.098  141.02
   7   0.1999     93.770  0.1237    96.280  164.13
   8   0.0935     96.890  0.1190    96.417  187.29
   9   0.1091     96.440  0.1181    96.357  210.40
  10   0.2074     93.040  0.1120    96.637  233.52
  11   0.1356     95.730  0.1105    96.622  256.62
  12   0.1279     95.940  0.1112    96.640  279.68
  13   0.1040     96.520  0.1061    96.750  302.75
  14   0.1393     95.110  0.1066    96.752  325.85
  15   0.0990     96.730  0.1071    96.802  348.96
  16   0.2728     91.390  0.1045    96.785  372.11
  17   0.1901     94.100  0.1024    96.847  395.23
  18   0.1341     95.640  0.1015    96.902  418.33
  19   0.1195     96.210  0.1033    96.890  441.45
  20   0.1055     96.650  0.1031    96.973  464.56
  21   0.1273     95.870  0.0984    97.045  487.64
  22   0.1098     96.510  0.1004    96.865  510.76
  23   0.1113     96.430  0.0984    96.962  533.86
  24   0.1337     95.600  0.1011    96.920  556.94
  25   0.1054     96.610  0.1005    96.937  580.05
  26   0.1293     95.650  0.0990    97.017  603.16
  27   0.1801     94.030  0.0988    96.983  626.23
  28   3.2357     35.130  0.0971    97.023  649.31
  29   0.0832     97.490  0.1006    96.883  672.45
  30   0.0988     96.980  0.1006    96.942  695.54
  31   0.1054     96.760  0.0989    97.027  718.63
  32   0.0848     97.560  0.0995    96.948  741.77
  33   0.1140     96.370  0.0976    96.990  764.84
  34   0.1642     94.700  0.0968    96.990  787.94
  35   0.1163     96.100  0.0945    97.128  811.02
  36   0.1085     96.480  0.0961    97.072  834.11
  37   0.1903     94.180  0.0955    97.055  857.23
  38   0.1515     95.110  0.0958    97.080  880.34
  39   0.0706     97.740  0.0963    97.103  903.40
  40   0.0969     96.800  0.0998    96.993  926.52
  41   0.1180     96.500  0.0960    96.995  949.61
  42   0.1374     95.330  0.0964    97.038  972.70
  43   0.0984     96.730  0.0980    97.025  995.80
  44   0.1123     96.330  0.0969    97.145  1018.89
  45   0.1408     95.390  0.1000    96.975  1041.95
  46   0.0886     97.080  0.0991    97.035  1065.04
  47   0.1150     96.410  0.0937    97.132  1088.15
  48   0.0880     97.300  0.0971    97.102  1111.24
  49   0.0779     97.730  0.0965    97.028  1134.36
  50   0.0859     96.990  0.0967    97.037  1157.49
  51   0.1193     95.970  0.0965    97.072  1180.57
  52   0.0724     97.530  0.0952    97.110  1203.67
  53   0.0693     97.630  0.0954    97.107  1226.80
  54   0.1578     94.840  0.0963    97.048  1249.89
  55   0.1220     96.180  0.0972    97.032  1273.03
  56   0.1375     95.630  0.0951    97.137  1296.14
  57   0.3138     89.520  0.0947    97.040  1319.22
  58   0.0791     97.220  0.0956    97.072  1342.30
  59   0.1481     95.410  0.0972    96.977  1365.44
  60   0.1709     94.580  0.0953    97.095  1388.51
  61   0.0823     97.430  0.0954    97.052  1411.56
  62   0.0778     97.490  0.0924    97.137  1434.66
  63   0.0882     97.230  0.0962    97.033  1457.77
  64   0.1056     96.670  0.0948    97.108  1480.88
  65   0.1029     96.810  0.0957    97.053  1504.00
  66   0.0741     97.740  0.0952    97.077  1527.12
  67   0.0901     96.890  0.0945    97.093  1550.18
  68   0.0899     96.940  0.0932    97.145  1573.28
  69   0.0906     97.140  0.0962    97.080  1596.37
  70   0.0944     96.880  0.0956    97.135  1619.45
  71   0.0883     97.040  0.0942    97.155  1642.57
  72   0.0948     97.160  0.0959    97.065  1665.67
  73   0.1310     95.850  0.0953    97.053  1688.76
  74   0.1050     96.330  0.0964    97.103  1711.88
  75   0.1614     94.820  0.0955    97.047  1735.01
  76   0.0870     97.160  0.0948    97.075  1758.08
  77   0.0764     97.280  0.0935    97.152  1781.17
  78   0.1207     96.000  0.0944    97.148  1804.39
  79   0.2912     91.100  0.0961    97.002  1827.49
  80   0.1016     96.680  0.0948    97.140  1850.60
  81   0.1594     94.900  0.0962    97.037  1873.69
  82   0.0727     97.750  0.0946    97.057  1896.77
  83   0.0919     97.010  0.0972    96.967  1919.91
  84   0.0740     97.530  0.0921    97.192  1942.99
  85   0.0712     97.520  0.0963    97.038  1966.11
