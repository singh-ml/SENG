Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.3149     89.170  0.8735    69.827  25.27
   2   0.1141     96.330  0.2331    92.278  48.24
   3   0.0999     96.600  0.1239    96.038  71.21
   4   0.0876     97.080  0.0880    97.252  94.21
   5   0.0716     97.680  0.0739    97.645  117.21
   6   0.0515     98.300  0.0634    97.978  140.24
   7   0.0490     98.450  0.0570    98.210  163.21
   8   0.0573     98.100  0.0521    98.333  186.22
   9   0.0515     98.170  0.0499    98.407  209.19
  10   0.0366     98.800  0.0465    98.527  232.16
  11   0.0478     98.670  0.0414    98.635  255.14
  12   0.0434     98.590  0.0409    98.707  278.11
  13   0.0369     98.740  0.0389    98.730  301.08
  14   0.0488     98.300  0.0370    98.817  324.10
  15   0.0436     98.480  0.0371    98.813  347.06
  16   0.0358     98.970  0.0348    98.862  370.03
  17   0.0373     98.880  0.0335    98.928  393.06
  18   0.0323     98.900  0.0344    98.922  416.10
  19   0.0290     99.080  0.0328    98.935  439.09
  20   0.0334     98.940  0.0310    98.990  462.09
  21   0.0401     98.660  0.0290    99.120  485.09
  22   0.0375     98.850  0.0306    99.008  508.07
  23   0.0247     99.200  0.0291    99.035  531.10
  24   0.0384     98.800  0.0285    99.060  554.09
  25   0.0372     98.850  0.0271    99.105  577.08
  26   0.0426     98.620  0.0276    99.152  600.12
  27   0.0478     98.520  0.0255    99.145  623.11
  28   0.0429     98.590  0.0275    99.077  646.11
  29   0.0470     98.510  0.0265    99.192  669.11
  30   0.0407     98.720  0.0262    99.158  692.12
  31   0.0389     98.760  0.0256    99.185  715.09
  32   0.0390     98.750  0.0243    99.210  738.09
  33   0.0361     98.900  0.0236    99.253  761.10
  34   0.0379     98.890  0.0241    99.223  784.08
  35   0.0309     98.950  0.0242    99.233  807.04
  36   0.0337     98.930  0.0235    99.237  830.07
  37   0.0363     98.760  0.0216    99.258  853.06
  38   0.0312     98.930  0.0223    99.308  876.08
  39   0.0607     98.230  0.0217    99.320  899.09
  40   0.0371     98.900  0.0224    99.325  922.09
  41   0.0282     99.070  0.0219    99.293  945.11
  42   0.0386     98.820  0.0203    99.335  968.11
  43   0.0453     98.710  0.0202    99.352  991.11
  44   0.0414     98.610  0.0207    99.358  1014.10
  45   0.0386     98.730  0.0204    99.325  1037.09
  46   0.0377     98.660  0.0200    99.338  1060.10
  47   0.0306     99.040  0.0181    99.437  1083.12
  48   0.0328     98.990  0.0182    99.397  1106.13
  49   0.0324     99.010  0.0187    99.382  1129.10
  50   0.0325     98.930  0.0192    99.380  1152.09
  51   0.0378     98.890  0.0186    99.410  1175.08
  52   0.0350     98.880  0.0185    99.388  1198.07
  53   0.0328     98.980  0.0184    99.432  1221.07
  54   0.0449     98.600  0.0184    99.388  1244.11
  55   0.0466     98.660  0.0181    99.427  1267.10
  56   0.0384     98.860  0.0174    99.435  1290.12
  57   0.0476     98.650  0.0169    99.452  1313.15
  58   0.0465     98.630  0.0174    99.437  1336.14
  59   0.0345     98.980  0.0176    99.460  1359.14
  60   0.0424     98.790  0.0167    99.465  1382.17
  61   0.0341     99.040  0.0160    99.502  1405.16
  62   0.0465     98.550  0.0158    99.498  1428.16
  63   0.0407     98.810  0.0158    99.528  1451.19
  64   0.0486     98.480  0.0155    99.498  1474.18
  65   0.0363     98.840  0.0151    99.538  1497.17
  66   0.0428     98.660  0.0168    99.475  1520.20
  67   0.0360     98.940  0.0150    99.502  1543.19
  68   0.0377     98.910  0.0158    99.495  1566.21
  69   0.0484     98.610  0.0158    99.517  1589.25
  70   0.0321     99.010  0.0143    99.525  1612.24
  71   0.0386     98.870  0.0156    99.502  1635.25
  72   0.0459     98.620  0.0149    99.527  1658.25
  73   0.0335     98.860  0.0142    99.525  1681.27
  74   0.0366     98.900  0.0144    99.563  1704.27
  75   0.0468     98.570  0.0147    99.527  1727.25
  76   0.0337     98.900  0.0133    99.577  1750.25
  77   0.0335     99.030  0.0140    99.555  1773.30
  78   0.0344     98.930  0.0139    99.583  1796.31
  79   0.0394     98.850  0.0139    99.547  1819.35
  80   0.0475     98.540  0.0132    99.563  1842.39
  81   0.0418     98.790  0.0133    99.592  1865.40
  82   0.0333     98.970  0.0134    99.590  1888.43
  83   0.0607     98.120  0.0127    99.583  1911.48
  84   0.0362     98.930  0.0125    99.590  1934.48
  85   0.0496     98.400  0.0123    99.585  1957.50
