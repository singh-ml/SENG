Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8435     29.630  3.4451    19.518  25.68
   2   0.4395     85.020  0.8686    70.050  48.66
   3   0.2634     91.880  0.2865    91.040  71.61
   4   0.1406     95.630  0.1904    94.185  94.59
   5   0.2594     92.960  0.1695    94.802  117.54
   6   0.2093     93.450  0.1610    95.068  140.48
   7   0.1918     93.720  0.1567    95.167  163.46
   8   0.1659     95.040  0.1527    95.265  186.41
   9   0.6064     81.200  0.1487    95.433  209.38
  10   0.1675     95.100  0.1489    95.527  232.32
  11   0.2869     90.570  0.1477    95.552  255.27
  12   0.2075     93.540  0.1461    95.413  278.22
  13   0.1223     96.210  0.1401    95.697  301.16
  14   0.2508     92.390  0.1451    95.560  324.11
  15   0.1614     94.560  0.1450    95.618  347.10
  16   0.1516     95.380  0.1442    95.595  370.03
  17   0.1117     96.260  0.1428    95.598  393.00
  18   0.1705     94.630  0.1427    95.653  415.92
  19   0.1274     96.040  0.1402    95.712  438.91
  20   0.1554     95.180  0.1398    95.710  461.89
  21   0.1750     94.590  0.1388    95.712  484.82
  22   0.1509     95.410  0.1367    95.750  507.78
  23   0.1218     96.000  0.1379    95.732  530.72
  24   0.1551     95.310  0.1374    95.820  553.66
  25   0.1351     95.870  0.1331    95.885  576.62
  26   0.2521     92.430  0.1366    95.827  599.56
  27   0.1493     94.910  0.1362    95.760  622.54
  28   0.1704     94.700  0.1343    95.900  645.49
  29   0.1504     94.860  0.1344    95.807  668.43
  30   0.1335     95.790  0.1373    95.780  691.37
  31   0.1357     95.680  0.1368    95.752  714.32
  32   0.1678     94.580  0.1383    95.785  737.24
  33   0.1139     96.250  0.1367    95.753  760.20
  34   0.1128     96.240  0.1374    95.725  783.17
  35   0.1916     93.980  0.1341    95.860  806.10
  36   0.1708     94.610  0.1344    95.788  829.09
  37   0.3111     90.250  0.1382    95.745  852.04
  38   0.1574     95.220  0.1355    95.842  875.03
  39   0.1661     95.020  0.1353    95.857  897.98
  40   0.1622     94.970  0.1383    95.728  920.95
  41   0.2089     93.180  0.1341    95.808  943.90
  42   0.1607     94.960  0.1367    95.823  966.84
  43   0.1946     94.050  0.1369    95.792  989.80
  44   0.1374     95.580  0.1367    95.807  1012.72
  45   0.1519     94.920  0.1342    95.855  1035.67
  46   0.1223     96.300  0.1391    95.640  1058.63
  47   0.1391     95.490  0.1370    95.787  1081.58
  48   0.1596     94.960  0.1345    95.827  1104.52
  49   0.1656     94.820  0.1382    95.710  1127.44
  50   1.1432     65.600  0.1331    95.882  1150.40
  51   0.1559     94.790  0.1354    95.818  1173.34
  52   0.2329     92.560  0.1380    95.743  1196.29
  53   0.2172     92.360  0.1327    95.907  1219.22
  54   2.1938     50.700  0.1346    95.838  1242.15
  55   0.1596     95.020  0.1343    95.815  1265.09
  56   0.1929     94.130  0.1384    95.738  1288.03
  57   0.1845     94.350  0.1363    95.755  1310.98
  58   0.1211     96.450  0.1367    95.807  1333.95
  59   0.1499     95.460  0.1335    95.867  1356.90
  60   0.1506     95.480  0.1348    95.803  1379.85
  61   0.2867     91.060  0.1344    95.885  1402.82
  62   0.1967     93.700  0.1385    95.717  1425.75
  63   0.1586     95.190  0.1362    95.785  1448.74
  64   0.1692     94.890  0.1349    95.870  1471.71
  65   0.5268     83.910  0.1329    95.898  1494.63
  66   0.2565     92.020  0.1372    95.810  1517.60
  67   0.2608     91.130  0.1370    95.760  1540.56
  68   0.1522     95.010  0.1400    95.712  1563.49
  69   0.0992     96.730  0.1358    95.773  1586.42
  70   0.1373     95.600  0.1372    95.790  1609.38
  71   0.1617     94.870  0.1349    95.853  1632.36
  72   0.1304     96.040  0.1314    95.993  1655.29
  73   0.1453     95.390  0.1333    95.883  1678.24
  74   0.1364     95.680  0.1336    95.910  1701.16
  75   0.1209     96.020  0.1347    95.752  1724.13
  76   0.1708     94.470  0.1374    95.745  1747.12
  77   0.1313     95.710  0.1354    95.852  1770.05
  78   0.1793     94.150  0.1345    95.880  1793.14
  79   0.2193     92.680  0.1312    95.950  1816.09
  80   0.1572     94.950  0.1356    95.863  1839.03
  81   0.2333     92.340  0.1369    95.820  1862.01
  82   0.1299     95.850  0.1333    95.878  1884.98
  83   0.1656     95.000  0.1350    95.838  1907.92
  84   0.2929     90.330  0.1356    95.727  1930.88
  85   0.2459     92.420  0.1323    95.897  1953.84
