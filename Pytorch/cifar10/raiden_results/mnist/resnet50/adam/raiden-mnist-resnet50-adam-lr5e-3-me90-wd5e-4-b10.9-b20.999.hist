Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.3330     86.510  1.3703    57.037  25.34
   2   0.2163     93.210  0.2792    91.285  48.60
   3   0.1636     94.790  0.2036    93.845  71.82
   4   0.2174     93.270  0.1756    94.767  95.03
   5   0.1338     96.040  0.1588    95.203  118.24
   6   0.1431     95.640  0.1429    95.657  141.47
   7   0.1548     95.360  0.1353    95.970  164.69
   8   0.1320     96.020  0.1289    96.123  187.91
   9   0.1273     96.060  0.1222    96.377  211.11
  10   0.1169     96.340  0.1158    96.490  234.36
  11   0.1026     96.690  0.1105    96.658  257.66
  12   0.1401     95.750  0.1077    96.732  280.88
  13   0.0793     97.570  0.1058    96.807  304.16
  14   0.1162     96.220  0.1037    96.847  327.42
  15   0.0794     97.500  0.1006    96.957  350.66
  16   0.0878     97.190  0.1006    96.975  373.93
  17   0.1009     96.900  0.0959    97.083  397.24
  18   0.0931     97.190  0.0956    97.072  420.50
  19   0.0898     97.330  0.0980    97.032  443.79
  20   0.1013     96.880  0.0939    97.105  467.07
  21   0.1130     96.380  0.0944    97.120  490.35
  22   0.1127     96.520  0.0918    97.203  513.64
  23   0.0773     97.530  0.0881    97.380  536.92
  24   0.0746     97.570  0.0925    97.163  560.28
  25   0.0818     97.320  0.0849    97.425  583.58
  26   0.0758     97.740  0.0861    97.388  606.86
  27   0.0985     96.820  0.0913    97.260  630.15
  28   0.0873     97.530  0.0905    97.225  653.46
  29   0.1093     96.510  0.0868    97.350  676.76
  30   0.0851     97.290  0.0849    97.415  700.07
  31   0.0809     97.520  0.0849    97.485  723.39
  32   0.0749     97.660  0.0812    97.502  746.66
  33   0.0842     97.370  0.0863    97.355  770.02
  34   0.0851     97.430  0.0843    97.472  793.33
  35   0.0849     97.290  0.0825    97.523  816.61
  36   0.0761     97.500  0.0824    97.545  839.91
