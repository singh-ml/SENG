Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1699     94.610  0.5433    81.253  25.28
   2   0.1069     96.570  0.1284    95.943  48.30
   3   0.1094     96.630  0.1055    96.792  71.31
   4   0.0716     97.670  0.0927    97.148  94.29
   5   0.0697     97.830  0.0833    97.427  117.24
   6   0.0491     98.340  0.0720    97.797  140.20
   7   0.0872     97.190  0.0743    97.747  163.14
   8   0.0693     97.710  0.0664    97.968  186.12
   9   0.0647     98.010  0.0662    97.992  209.08
  10   0.0701     97.760  0.0627    98.125  232.03
  11   0.0524     98.280  0.0615    98.103  254.98
  12   0.0551     98.320  0.0601    98.150  277.97
  13   0.0561     98.230  0.0582    98.200  300.91
  14   0.0444     98.640  0.0502    98.447  323.84
  15   0.0593     98.050  0.0505    98.495  346.83
  16   0.0502     98.280  0.0467    98.548  369.78
  17   0.0681     97.990  0.0535    98.383  392.73
  18   0.0535     98.240  0.0456    98.618  415.68
  19   0.0407     98.750  0.0498    98.478  438.62
  20   0.0385     98.680  0.0450    98.602  461.60
  21   0.0434     98.520  0.0448    98.652  484.54
  22   0.0611     98.010  0.0422    98.722  507.48
  23   0.0423     98.660  0.0438    98.667  530.48
  24   0.0360     98.890  0.0436    98.647  553.43
  25   0.0511     98.290  0.0402    98.757  576.37
  26   0.0451     98.570  0.0416    98.723  599.31
  27   0.0442     98.620  0.0417    98.680  622.26
  28   0.0351     98.890  0.0367    98.908  645.23
  29   0.0370     98.790  0.0397    98.773  668.14
  30   0.0403     98.690  0.0359    98.900  691.08
  31   0.0401     98.820  0.0382    98.833  714.02
  32   0.0650     98.090  0.0378    98.800  736.95
  33   0.0440     98.750  0.0375    98.898  759.91
  34   0.0485     98.410  0.0343    98.928  782.85
  35   0.0410     98.660  0.0350    98.913  805.87
  36   0.0442     98.670  0.0343    98.967  828.83
  37   0.0445     98.510  0.0320    98.940  851.75
  38   0.0752     97.950  0.0336    98.985  874.70
  39   0.0527     98.370  0.0318    98.998  897.65
  40   0.0356     98.910  0.0322    98.998  920.61
  41   0.0425     98.770  0.0340    98.985  943.56
  42   0.0281     99.010  0.0323    99.013  966.53
  43   0.0361     98.830  0.0315    99.017  989.47
  44   0.0399     98.830  0.0320    99.008  1012.44
  45   0.0323     99.020  0.0319    98.975  1035.42
  46   0.0503     98.350  0.0298    99.092  1058.35
  47   0.0489     98.360  0.0296    99.090  1081.31
  48   0.0463     98.520  0.0308    99.020  1104.27
  49   0.0424     98.720  0.0300    99.040  1127.21
  50   0.0358     98.860  0.0293    99.105  1150.19
  51   0.0416     98.680  0.0291    99.075  1173.10
  52   0.0431     98.500  0.0301    99.083  1196.03
  53   0.0452     98.690  0.0288    99.120  1218.99
  54   0.0382     98.880  0.0291    99.098  1241.97
  55   0.0426     98.670  0.0277    99.120  1264.94
  56   0.0369     98.860  0.0294    99.077  1287.91
  57   0.0387     98.760  0.0267    99.182  1310.88
  58   0.0360     98.970  0.0264    99.165  1333.80
  59   0.0429     98.740  0.0284    99.128  1356.78
  60   0.0433     98.540  0.0282    99.133  1379.73
  61   0.0417     98.770  0.0281    99.090  1402.69
  62   0.0258     99.190  0.0262    99.173  1425.64
  63   0.0325     98.890  0.0268    99.132  1448.62
  64   0.0327     98.910  0.0259    99.210  1471.59
  65   0.0303     99.100  0.0259    99.182  1494.59
  66   0.0357     98.860  0.0272    99.170  1517.54
  67   0.0398     98.710  0.0246    99.240  1540.50
  68   0.0330     98.960  0.0277    99.153  1563.47
  69   0.0378     98.850  0.0262    99.178  1586.42
  70   0.0387     98.940  0.0270    99.147  1609.39
  71   0.0396     98.860  0.0262    99.183  1632.35
  72   0.0394     98.710  0.0255    99.207  1655.31
  73   0.0363     98.860  0.0245    99.233  1678.24
  74   0.0383     98.800  0.0259    99.197  1701.20
  75   0.0259     99.240  0.0262    99.167  1724.18
  76   0.0243     99.240  0.0247    99.252  1747.13
  77   0.0377     98.770  0.0248    99.195  1770.12
  78   0.0362     99.040  0.0259    99.200  1793.29
  79   0.0329     99.000  0.0246    99.232  1816.23
  80   0.0385     98.700  0.0238    99.240  1839.17
  81   0.0350     98.920  0.0238    99.243  1862.13
  82   0.0371     98.820  0.0245    99.217  1885.06
  83   0.0459     98.640  0.0219    99.335  1908.04
  84   0.0335     98.960  0.0230    99.275  1931.04
  85   0.0438     98.700  0.0232    99.255  1953.99
