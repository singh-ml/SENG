Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 13828049408 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2477     91.890  0.7267    74.932  25.44
   2   0.1371     95.600  0.1681    94.658  48.56
   3   0.0729     97.740  0.0932    97.047  71.61
   4   0.0555     98.190  0.0727    97.737  94.69
   5   0.0684     97.840  0.0618    98.023  117.75
   6   0.0816     97.400  0.0579    98.227  140.83
   7   0.0496     98.270  0.0541    98.353  163.89
   8   0.0661     97.890  0.0513    98.408  186.96
   9   0.0545     98.220  0.0522    98.318  210.02
  10   0.0555     98.310  0.0533    98.320  233.09
  11   0.0746     97.770  0.0446    98.595  256.16
  12   0.0431     98.530  0.0463    98.538  279.23
  13   0.0604     98.090  0.0482    98.478  302.33
  14   0.0543     98.290  0.0421    98.707  325.38
  15   0.0547     98.250  0.0417    98.663  348.47
  16   0.0437     98.680  0.0439    98.677  371.57
  17   0.0518     98.340  0.0420    98.687  394.64
  18   0.0447     98.650  0.0397    98.762  417.75
  19   0.0463     98.490  0.0394    98.787  440.85
  20   0.0562     98.160  0.0428    98.710  463.92
  21   0.0600     98.060  0.0396    98.755  487.03
  22   0.0397     98.560  0.0391    98.750  510.12
  23   0.0640     97.990  0.0426    98.672  533.21
  24   0.0370     98.890  0.0388    98.812  556.30
  25   0.0465     98.400  0.0397    98.817  579.37
  26   0.0385     98.810  0.0391    98.810  602.41
  27   0.0539     98.320  0.0384    98.845  625.49
  28   0.0497     98.530  0.0371    98.808  648.56
  29   0.0423     98.870  0.0375    98.828  671.62
  30   0.0357     98.760  0.0397    98.772  694.67
  31   0.0512     98.390  0.0376    98.882  717.72
  32   0.0539     98.400  0.0385    98.870  740.78
  33   0.0458     98.560  0.0377    98.865  763.86
  34   0.0404     98.860  0.0357    98.877  786.92
  35   0.0430     98.560  0.0322    99.005  809.99
  36   0.0409     98.750  0.0338    98.965  833.05
  37   0.0412     98.550  0.0360    98.903  856.13
  38   0.0373     98.920  0.0346    98.985  879.21
  39   0.0484     98.400  0.0353    98.950  902.34
  40   0.0385     98.780  0.0328    99.040  925.46
  41   0.0455     98.510  0.0329    99.017  948.53
  42   0.0351     98.830  0.0347    98.927  971.61
  43   0.0452     98.590  0.0314    99.037  994.66
  44   0.0381     98.880  0.0328    99.005  1017.73
  45   0.0355     98.950  0.0324    98.993  1040.79
  46   0.0402     98.760  0.0310    99.073  1063.88
  47   0.0356     98.920  0.0281    99.147  1086.93
  48   0.0578     98.260  0.0284    99.142  1110.01
  49   0.0377     98.740  0.0288    99.143  1133.08
  50   0.0303     99.030  0.0326    98.973  1156.15
  51   0.0524     98.380  0.0303    99.095  1179.23
  52   0.0430     98.680  0.0289    99.127  1202.32
  53   0.0375     98.890  0.0273    99.170  1225.38
  54   0.0355     98.860  0.0257    99.218  1248.45
  55   0.0615     98.300  0.0283    99.092  1271.53
  56   0.0342     98.990  0.0282    99.165  1294.61
  57   0.0511     98.580  0.0281    99.105  1317.72
  58   0.0376     98.780  0.0278    99.108  1340.80
  59   0.0404     98.880  0.0254    99.220  1363.87
  60   0.0391     98.730  0.0256    99.187  1386.96
  61   0.0363     98.910  0.0265    99.212  1410.03
  62   0.0376     98.870  0.0276    99.115  1433.09
  63   0.0349     98.910  0.0258    99.203  1456.19
  64   0.0412     98.720  0.0271    99.153  1479.26
  65   0.0436     98.670  0.0268    99.160  1502.34
  66   0.0254     99.160  0.0253    99.202  1525.39
  67   0.0278     99.020  0.0227    99.328  1548.46
  68   0.0279     99.170  0.0247    99.222  1571.51
  69   0.0360     98.970  0.0245    99.232  1594.58
  70   0.0348     99.100  0.0234    99.263  1617.66
  71   0.0359     98.940  0.0234    99.300  1640.71
  72   0.0315     99.070  0.0236    99.270  1663.82
  73   0.0327     99.020  0.0220    99.337  1686.89
  74   0.0379     98.980  0.0249    99.205  1709.98
  75   0.0406     98.830  0.0236    99.263  1733.08
  76   0.0469     98.530  0.0230    99.327  1756.17
  77   0.0350     98.920  0.0227    99.335  1779.22
  78   0.0311     99.030  0.0221    99.333  1802.31
  79   0.0355     98.850  0.0221    99.277  1825.38
  80   0.0554     98.390  0.0263    99.202  1848.47
  81   0.0325     99.110  0.0222    99.320  1871.55
  82   0.0357     98.860  0.0196    99.357  1894.65
  83   0.0332     99.030  0.0211    99.365  1917.75
  84   0.0347     99.080  0.0229    99.273  1940.84
  85   0.0318     99.020  0.0227    99.295  1963.94
