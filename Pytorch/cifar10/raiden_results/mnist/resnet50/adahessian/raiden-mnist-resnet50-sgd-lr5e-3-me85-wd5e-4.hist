Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 32180217344 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8505     35.260  2.0122    27.195  133.13
   2   1.6456     47.740  1.7886    38.663  261.51
   3   1.3463     58.820  1.5679    49.420  389.90
   4   1.0063     67.960  1.2236    62.232  518.30
   5   0.7124     77.550  0.8738    72.992  646.69
   6   0.5499     82.780  0.6503    79.390  775.09
   7   0.4307     85.710  0.5139    83.228  903.49
   8   0.3886     86.940  0.4334    85.707  1031.94
   9   0.3503     88.570  0.3744    87.600  1160.33
  10   0.2800     91.110  0.3260    89.290  1288.79
  11   0.2643     91.410  0.2794    90.838  1417.19
  12   0.2223     92.930  0.2404    92.148  1545.57
  13   0.1916     93.740  0.2111    93.235  1673.96
  14   0.1679     94.550  0.1844    94.103  1802.33
  15   0.1514     95.110  0.1641    94.670  1930.67
  16   0.1374     95.630  0.1441    95.458  2058.97
  17   0.1358     95.670  0.1293    95.878  2187.37
  18   0.1136     96.370  0.1201    96.215  2315.79
  19   0.1019     96.650  0.1093    96.528  2444.26
  20   0.1127     96.270  0.1013    96.795  2572.59
  21   0.1013     96.780  0.0917    97.082  2700.97
  22   0.0894     97.040  0.0868    97.330  2829.28
  23   0.0985     96.800  0.0812    97.465  2957.70
  24   0.0902     96.880  0.0772    97.577  3086.09
  25   0.0805     97.420  0.0726    97.722  3214.38
  26   0.0796     97.310  0.0685    97.843  3342.77
  27   0.0673     97.810  0.0652    97.948  3471.09
  28   0.0646     97.810  0.0641    97.978  3599.37
  29   0.0639     97.760  0.0589    98.102  3727.80
  30   0.0691     97.630  0.0572    98.213  3856.04
  31   0.0630     97.880  0.0548    98.282  3984.41
  32   0.0584     98.120  0.0529    98.362  4112.83
  33   0.0578     97.990  0.0511    98.347  4241.19
  34   0.0955     96.910  0.0488    98.455  4369.64
  35   0.0498     98.170  0.0452    98.567  4498.00
  36   0.0551     98.250  0.0457    98.560  4626.37
  37   0.0511     98.260  0.0443    98.572  4754.77
  38   0.0505     98.350  0.0410    98.705  4883.16
  39   0.0555     98.030  0.0405    98.740  5011.53
  40   0.0580     98.000  0.0397    98.770  5139.90
  41   0.0525     98.280  0.0385    98.798  5268.35
  42   0.0493     98.290  0.0367    98.807  5396.72
  43   0.0556     98.200  0.0363    98.825  5525.07
  44   0.0475     98.560  0.0346    98.875  5653.49
  45   0.0486     98.360  0.0338    98.893  5781.79
  46   0.0455     98.480  0.0329    98.945  5910.19
  47   0.0511     98.270  0.0322    98.955  6038.60
  48   0.0421     98.570  0.0304    99.013  6166.88
  49   0.0472     98.430  0.0305    99.023  6295.23
  50   0.0430     98.440  0.0287    99.055  6423.54
  51   0.0477     98.370  0.0294    99.012  6551.92
  52   0.0393     98.570  0.0286    99.103  6680.27
  53   0.0435     98.400  0.0267    99.140  6808.61
  54   0.0437     98.420  0.0266    99.108  6936.97
  55   0.0429     98.590  0.0252    99.177  7065.37
  56   0.0499     98.510  0.0264    99.188  7193.75
  57   0.0499     98.290  0.0251    99.180  7322.02
  58   0.0518     98.360  0.0251    99.180  7450.39
  59   0.0426     98.590  0.0244    99.218  7578.75
  60   0.0415     98.670  0.0232    99.260  7707.13
  61   0.0438     98.610  0.0222    99.308  7835.56
  62   0.0416     98.610  0.0223    99.285  7963.95
  63   0.0464     98.510  0.0214    99.327  8092.33
  64   0.0420     98.600  0.0219    99.307  8220.69
  65   0.0401     98.690  0.0207    99.345  8349.07
  66   0.0391     98.610  0.0200    99.355  8477.43
  67   0.0432     98.520  0.0196    99.350  8605.75
  68   0.0502     98.420  0.0203    99.328  8734.11
  69   0.0467     98.520  0.0189    99.397  8862.51
  70   0.0495     98.330  0.0182    99.388  8990.87
  71   0.0368     98.750  0.0183    99.417  9119.17
  72   0.0423     98.640  0.0175    99.448  9247.55
  73   0.0420     98.700  0.0180    99.392  9375.91
  74   0.0455     98.510  0.0185    99.427  9504.29
  75   0.0374     98.850  0.0162    99.492  9632.60
  76   0.0430     98.690  0.0168    99.455  9760.90
  77   0.0405     98.700  0.0166    99.460  9889.21
  78   0.0433     98.730  0.0167    99.470  10017.53
  79   0.0360     98.830  0.0165    99.478  10145.91
  80   0.0415     98.610  0.0157    99.458  10274.30
  81   0.0406     98.630  0.0152    99.513  10402.64
  82   0.0371     98.900  0.0155    99.502  10531.07
  83   0.0387     98.690  0.0147    99.547  10659.49
  84   0.0363     98.800  0.0157    99.482  10787.76
  85   0.0435     98.630  0.0151    99.522  10916.13
