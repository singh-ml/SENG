Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 32179955200 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1309     23.920  2.2367    18.788  132.96
   2   2.0360     25.370  2.1015    23.070  261.33
   3   1.9686     30.320  2.0286    25.488  389.86
   4   1.9141     33.150  1.9751    28.192  518.39
   5   1.8828     35.350  1.9331    30.878  646.85
   6   1.8384     37.490  1.8909    33.218  775.32
   7   1.7955     38.870  1.8550    35.173  903.80
   8   1.7452     42.680  1.8173    37.555  1032.33
   9   1.6952     44.660  1.7812    39.488  1160.82
  10   1.6717     44.810  1.7376    41.652  1289.23
  11   1.6193     45.890  1.6964    43.773  1417.72
  12   1.5437     52.220  1.6516    45.673  1546.17
  13   1.5159     50.970  1.5983    48.233  1674.66
  14   1.4492     52.310  1.5376    50.477  1803.22
  15   1.3580     57.530  1.4724    53.463  1931.75
  16   1.2950     58.790  1.4001    56.213  2060.26
  17   1.1651     65.300  1.3204    59.013  2188.86
  18   1.0901     67.120  1.2312    62.027  2317.39
  19   0.9860     70.010  1.1421    65.003  2445.77
  20   0.9324     70.270  1.0556    67.177  2574.33
  21   0.9280     68.720  0.9808    68.865  2702.87
  22   0.8061     73.820  0.9149    70.835  2831.32
  23   0.7809     74.230  0.8575    72.655  2959.85
  24   0.8067     72.610  0.8106    74.008  3088.39
  25   0.6948     77.140  0.7643    75.382  3216.79
  26   0.6444     79.580  0.7182    77.045  3345.28
  27   0.6077     80.290  0.6761    78.278  3473.73
  28   0.5819     81.170  0.6361    79.643  3602.12
  29   0.5313     82.700  0.5970    80.600  3730.72
  30   0.5117     83.190  0.5643    81.735  3859.19
  31   0.4754     84.180  0.5352    82.372  3987.64
  32   0.4689     84.290  0.5114    83.138  4116.04
  33   0.4511     84.360  0.4857    83.837  4244.58
  34   0.4347     85.390  0.4689    84.295  4373.01
  35   0.4148     85.560  0.4484    85.025  4501.41
  36   0.3927     86.740  0.4327    85.467  4629.81
  37   0.3946     86.280  0.4161    86.063  4758.38
  38   0.3774     86.960  0.4002    86.668  4886.86
  39   0.3524     87.700  0.3845    87.172  5015.34
  40   0.3471     88.040  0.3737    87.380  5143.90
  41   0.3312     88.470  0.3570    87.963  5272.32
  42   0.3242     88.940  0.3444    88.407  5400.76
  43   0.3125     89.240  0.3326    88.958  5529.30
  44   0.2984     89.770  0.3210    89.167  5657.79
  45   0.2885     89.930  0.3097    89.687  5786.23
  46   0.2895     90.350  0.2957    90.273  5914.82
  47   0.2881     90.010  0.2871    90.592  6043.36
  48   0.2570     91.290  0.2746    90.990  6171.94
  49   0.2516     91.460  0.2691    91.093  6300.39
  50   0.2472     91.640  0.2586    91.485  6428.95
  51   0.2591     91.510  0.2485    91.808  6557.51
  52   0.2279     92.130  0.2376    92.222  6686.03
  53   0.2384     91.990  0.2282    92.620  6814.46
  54   0.2138     92.750  0.2225    92.807  6942.99
  55   0.2196     92.720  0.2133    93.100  7071.50
  56   0.2015     93.100  0.2085    93.283  7199.93
  57   0.1847     93.870  0.2011    93.495  7328.36
  58   0.1910     93.690  0.1931    93.770  7456.82
  59   0.1720     94.200  0.1886    93.995  7585.33
  60   0.1773     94.160  0.1817    94.125  7713.93
  61   0.1634     94.650  0.1767    94.302  7842.69
  62   0.1673     94.630  0.1741    94.437  7971.14
  63   0.1562     94.850  0.1662    94.708  8099.52
  64   0.2061     93.160  0.1620    94.850  8227.91
  65   0.1552     94.870  0.1555    95.085  8356.37
  66   0.1453     95.180  0.1521    95.147  8484.93
  67   0.1359     95.640  0.1474    95.278  8613.33
  68   0.1321     95.680  0.1438    95.497  8741.78
  69   0.1377     95.420  0.1415    95.487  8870.26
  70   0.1244     96.050  0.1343    95.747  8998.80
  71   0.1223     96.130  0.1317    95.802  9127.30
  72   0.1190     96.100  0.1277    95.932  9255.67
  73   0.1153     96.270  0.1284    95.858  9384.07
  74   0.1212     96.020  0.1196    96.260  9512.61
  75   0.1085     96.460  0.1196    96.190  9641.19
  76   0.1063     96.480  0.1172    96.322  9769.64
  77   0.1102     96.360  0.1150    96.352  9898.09
  78   0.1354     95.620  0.1114    96.543  10026.58
  79   0.1007     96.810  0.1088    96.680  10155.07
  80   0.1005     96.720  0.1044    96.695  10283.53
  81   0.1002     96.580  0.1030    96.760  10411.94
  82   0.1046     96.500  0.1005    96.787  10540.41
  83   0.0974     96.940  0.0997    96.850  10668.90
  84   0.0907     97.030  0.0972    96.983  10797.37
  85   0.1094     96.360  0.0948    97.020  10925.84
  86   0.0880     96.960  0.0938    96.970  11054.37
  87   0.0940     96.920  0.0924    97.093  11182.86
  88   0.1025     96.770  0.0895    97.222  11311.33
  89   0.0903     97.070  0.0880    97.262  11439.83
  90   0.1016     96.810  0.0867    97.313  11568.35
