Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 32177858048 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.4057     86.710  1.2160    59.257  133.67
   2   0.2121     93.030  0.2832    90.838  262.30
   3   0.1121     96.340  0.1394    95.535  390.89
   4   0.0886     97.010  0.1014    96.692  519.39
   5   0.0886     97.020  0.0797    97.463  647.90
   6   0.0667     97.710  0.0679    97.883  776.44
   7   0.0579     98.240  0.0601    98.062  905.03
   8   0.0502     98.500  0.0549    98.267  1033.61
   9   0.0517     98.480  0.0514    98.380  1162.23
  10   0.0599     98.210  0.0482    98.457  1290.84
  11   0.0542     98.140  0.0472    98.522  1419.43
  12   0.0466     98.440  0.0446    98.610  1547.99
  13   0.0523     98.330  0.0431    98.632  1676.51
  14   0.0487     98.490  0.0432    98.605  1805.14
  15   0.0502     98.340  0.0400    98.738  1933.74
  16   0.0435     98.590  0.0393    98.725  2062.32
  17   0.0535     98.340  0.0384    98.748  2190.99
  18   0.0589     98.150  0.0392    98.735  2319.52
  19   0.0571     98.160  0.0382    98.802  2448.03
  20   0.0463     98.610  0.0378    98.798  2576.63
  21   0.0441     98.570  0.0359    98.892  2705.14
  22   0.0519     98.360  0.0353    98.870  2833.66
  23   0.0485     98.580  0.0366    98.850  2962.28
  24   0.0377     98.730  0.0365    98.832  3090.88
  25   0.0307     98.990  0.0349    98.912  3219.44
  26   0.0501     98.390  0.0342    98.890  3348.03
  27   0.0435     98.690  0.0338    98.895  3476.64
  28   0.0288     99.150  0.0305    99.063  3605.26
  29   0.0522     98.270  0.0349    98.895  3733.87
  30   0.0586     98.230  0.0336    98.937  3862.39
  31   0.0301     98.940  0.0303    99.035  3990.90
  32   0.0488     98.360  0.0330    98.930  4119.49
  33   0.0354     98.950  0.0327    98.962  4248.02
  34   0.0408     98.780  0.0344    98.912  4376.57
  35   0.0430     98.630  0.0307    99.030  4505.11
  36   0.0561     98.370  0.0310    98.992  4633.67
  37   0.0385     98.840  0.0318    98.958  4762.26
  38   0.0343     98.820  0.0325    98.977  4890.84
  39   0.0283     99.070  0.0292    99.110  5019.54
  40   0.0383     98.720  0.0285    99.065  5148.10
  41   0.0363     98.880  0.0281    99.098  5276.70
  42   0.0398     98.780  0.0251    99.215  5405.31
  43   0.0348     98.990  0.0256    99.162  5533.85
  44   0.0417     98.680  0.0266    99.170  5662.38
  45   0.0433     98.770  0.0235    99.250  5790.94
  46   0.0407     98.880  0.0249    99.212  5919.45
  47   0.0346     98.950  0.0262    99.145  6047.95
  48   0.0437     98.850  0.0222    99.270  6176.57
  49   0.0308     99.020  0.0217    99.310  6305.19
  50   0.0324     98.960  0.0227    99.240  6433.77
  51   0.0347     99.010  0.0215    99.315  6562.38
  52   0.0526     98.540  0.0195    99.358  6690.98
  53   0.0359     99.060  0.0192    99.382  6819.65
  54   0.0334     99.050  0.0192    99.377  6948.27
  55   0.0443     98.750  0.0170    99.440  7076.90
  56   0.0417     98.710  0.0167    99.465  7205.44
  57   0.0512     98.580  0.0176    99.417  7333.97
  58   0.0387     99.000  0.0128    99.603  7462.59
  59   0.0394     98.980  0.0136    99.532  7591.22
  60   0.0309     99.030  0.0112    99.627  7719.71
  61   0.0354     99.050  0.0107    99.630  7848.29
  62   0.0335     99.140  0.0093    99.680  7976.87
  63   0.0338     99.110  0.0098    99.698  8105.50
  64   0.0290     99.200  0.0084    99.727  8234.04
  65   0.0298     99.090  0.0080    99.737  8362.64
  66   0.0306     99.240  0.0065    99.762  8491.13
  67   0.0382     98.990  0.0055    99.815  8619.63
  68   0.0357     99.010  0.0049    99.833  8748.18
  69   0.0393     99.060  0.0044    99.855  8877.17
  70   0.0375     99.100  0.0041    99.855  9005.73
  71   0.0383     98.990  0.0032    99.895  9134.29
  72   0.0323     99.200  0.0029    99.908  9262.87
  73   0.0395     99.140  0.0029    99.897  9391.38
  74   0.0399     99.030  0.0022    99.937  9519.95
  75   0.0324     99.210  0.0020    99.937  9648.56
  76   0.0386     99.100  0.0015    99.950  9777.15
  77   0.0367     99.210  0.0014    99.952  9905.76
  78   0.0382     99.180  0.0010    99.978  10034.35
  79   0.0514     99.090  0.0010    99.973  10162.86
  80   0.0424     99.180  0.0011    99.970  10291.48
  81   0.0463     99.130  0.0008    99.973  10420.14
  82   0.0428     99.060  0.0008    99.978  10548.76
  83   0.0487     99.060  0.0008    99.983  10677.34
  84   0.0425     99.230  0.0006    99.978  10805.92
  85   0.0464     99.160  0.0007    99.980  10934.54
