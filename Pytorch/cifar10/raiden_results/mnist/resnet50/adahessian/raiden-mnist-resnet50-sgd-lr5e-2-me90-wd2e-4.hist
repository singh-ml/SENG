Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 32186246656 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5592     81.430  1.3820    53.983  133.58
   2   0.2478     91.660  0.3879    87.105  262.42
   3   0.1427     95.570  0.1931    93.802  391.27
   4   0.1032     96.550  0.1247    96.075  520.11
   5   0.0967     96.860  0.0976    96.855  649.09
   6   0.0718     97.710  0.0798    97.455  777.96
   7   0.0727     97.680  0.0680    97.777  906.91
   8   0.0625     97.880  0.0634    97.980  1035.78
   9   0.0784     97.510  0.0569    98.237  1164.75
  10   0.0649     97.820  0.0547    98.278  1293.68
  11   0.0577     98.130  0.0488    98.460  1422.67
  12   0.0637     98.110  0.0492    98.443  1551.72
  13   0.0640     97.930  0.0464    98.517  1680.69
  14   0.0537     98.340  0.0428    98.633  1809.50
  15   0.0426     98.440  0.0427    98.662  1938.38
  16   0.0572     98.050  0.0416    98.632  2067.28
  17   0.0475     98.450  0.0402    98.703  2196.17
  18   0.0429     98.620  0.0393    98.735  2325.13
  19   0.0438     98.580  0.0402    98.698  2453.96
  20   0.0562     98.160  0.0372    98.810  2582.79
  21   0.0384     98.730  0.0378    98.802  2711.70
  22   0.0571     98.120  0.0389    98.753  2840.60
  23   0.0472     98.380  0.0377    98.817  2969.43
  24   0.0470     98.650  0.0358    98.895  3098.33
  25   0.0360     98.730  0.0362    98.832  3227.26
  26   0.0350     98.940  0.0386    98.728  3356.22
  27   0.0447     98.610  0.0345    98.870  3485.11
  28   0.0485     98.620  0.0350    98.870  3613.99
  29   0.0316     99.070  0.0357    98.840  3742.78
  30   0.0568     98.430  0.0337    98.930  3871.71
  31   0.0439     98.670  0.0346    98.895  4000.67
  32   0.0464     98.540  0.0339    98.942  4129.50
  33   0.0334     98.960  0.0321    98.985  4258.34
  34   0.0491     98.510  0.0315    98.978  4387.21
  35   0.0449     98.660  0.0353    98.862  4516.08
  36   0.0368     98.740  0.0341    98.927  4644.91
  37   0.0478     98.470  0.0301    99.060  4773.73
  38   0.0370     98.880  0.0331    98.957  4902.59
  39   0.0275     99.140  0.0301    99.058  5031.37
  40   0.0526     98.370  0.0316    99.008  5160.24
  41   0.0410     98.630  0.0323    98.968  5289.22
  42   0.0341     98.800  0.0305    99.095  5418.19
  43   0.0395     98.820  0.0285    99.075  5547.17
  44   0.0326     98.970  0.0275    99.107  5676.17
  45   0.0427     98.640  0.0301    99.047  5805.07
  46   0.0363     98.860  0.0295    99.102  5933.93
  47   0.0361     98.920  0.0260    99.177  6062.70
  48   0.0289     99.160  0.0266    99.103  6191.53
  49   0.0395     98.840  0.0294    99.103  6320.32
  50   0.0373     98.940  0.0249    99.210  6449.11
  51   0.0324     98.900  0.0233    99.252  6577.89
  52   0.0537     98.340  0.0231    99.257  6706.77
  53   0.0324     98.980  0.0261    99.187  6835.66
  54   0.0380     98.830  0.0212    99.282  6964.48
  55   0.0392     98.800  0.0203    99.353  7093.36
  56   0.0313     99.010  0.0219    99.288  7222.32
  57   0.0444     98.620  0.0206    99.328  7351.25
  58   0.0317     98.940  0.0203    99.347  7480.19
  59   0.0354     98.850  0.0191    99.330  7609.11
  60   0.0415     98.890  0.0174    99.432  7738.01
  61   0.0346     99.050  0.0153    99.487  7867.29
  62   0.0348     99.070  0.0158    99.497  7996.18
  63   0.0317     99.080  0.0142    99.510  8125.10
  64   0.0233     99.250  0.0141    99.522  8253.96
  65   0.0352     98.950  0.0121    99.603  8382.80
  66   0.0234     99.270  0.0125    99.575  8511.69
  67   0.0483     98.710  0.0106    99.638  8640.66
  68   0.0331     99.040  0.0108    99.637  8769.53
  69   0.0324     99.100  0.0087    99.697  8898.40
  70   0.0311     99.140  0.0088    99.688  9027.32
  71   0.0301     99.240  0.0076    99.737  9156.25
  72   0.0288     99.170  0.0060    99.787  9285.13
  73   0.0379     99.040  0.0053    99.813  9413.98
  74   0.0332     99.110  0.0044    99.840  9542.85
  75   0.0365     99.000  0.0040    99.863  9671.76
  76   0.0397     98.970  0.0036    99.868  9800.68
  77   0.0303     99.220  0.0030    99.897  9929.57
  78   0.0323     99.130  0.0022    99.932  10058.40
  79   0.0368     99.140  0.0024    99.907  10187.24
  80   0.0399     98.990  0.0018    99.945  10316.09
  81   0.0359     99.140  0.0021    99.923  10444.97
  82   0.0344     99.150  0.0018    99.940  10573.80
  83   0.0379     99.100  0.0015    99.952  10702.69
  84   0.0341     99.210  0.0011    99.968  10831.59
  85   0.0384     99.180  0.0011    99.963  10960.45
  86   0.0376     99.190  0.0010    99.970  11089.32
  87   0.0332     99.230  0.0008    99.982  11218.17
  88   0.0388     99.200  0.0010    99.967  11346.95
  89   0.0476     98.990  0.0009    99.980  11475.76
  90   0.0392     99.150  0.0009    99.973  11604.60
