Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 32178906624 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1080     24.500  2.2290    18.668  132.89
   2   2.0094     26.760  2.0722    23.908  261.53
   3   1.9367     30.860  1.9948    27.032  390.08
   4   1.8821     32.860  1.9387    29.725  518.60
   5   1.8339     36.640  1.8931    32.093  647.20
   6   1.8033     37.980  1.8502    34.747  775.76
   7   1.7426     41.640  1.8078    36.900  904.33
   8   1.6941     44.740  1.7666    39.208  1032.85
   9   1.6514     44.930  1.7210    41.407  1161.37
  10   1.6084     49.010  1.6732    43.790  1289.87
  11   1.5541     51.130  1.6215    46.058  1418.49
  12   1.4835     52.240  1.5655    48.420  1547.01
  13   1.3977     57.030  1.5000    51.282  1675.55
  14   1.3457     56.300  1.4338    53.583  1804.05
  15   1.2612     59.550  1.3616    56.573  1932.51
  16   1.1395     65.740  1.2755    59.737  2060.99
  17   1.0547     67.380  1.1908    62.703  2189.44
  18   0.9799     69.490  1.1044    65.308  2317.90
  19   0.9199     70.880  1.0270    67.338  2446.47
  20   0.8539     72.400  0.9582    69.333  2575.03
  21   0.8192     73.310  0.9023    71.127  2703.55
  22   0.7769     74.610  0.8500    72.593  2832.13
  23   0.7372     75.830  0.8042    73.817  2960.75
  24   0.6901     76.900  0.7620    75.195  3089.29
  25   0.6675     78.070  0.7249    76.508  3217.86
  26   0.6327     79.610  0.6840    77.885  3346.47
  27   0.5870     80.890  0.6461    79.253  3475.02
  28   0.5573     82.080  0.6033    80.713  3603.59
  29   0.5097     83.500  0.5670    81.828  3732.11
  30   0.4900     83.940  0.5359    82.767  3860.64
  31   0.4670     84.470  0.5043    83.633  3989.26
  32   0.4322     85.760  0.4812    84.285  4117.81
  33   0.4424     85.430  0.4570    84.947  4246.33
  34   0.3970     86.880  0.4340    85.743  4374.98
  35   0.3776     87.440  0.4166    86.248  4503.44
  36   0.3610     88.000  0.3979    86.863  4631.91
  37   0.3520     88.240  0.3832    87.347  4760.51
  38   0.3477     88.260  0.3683    87.752  4889.07
  39   0.3236     88.980  0.3539    88.213  5017.60
  40   0.3393     88.560  0.3400    88.782  5146.23
  41   0.3005     89.900  0.3312    89.090  5274.73
  42   0.2954     89.870  0.3172    89.512  5403.38
  43   0.2845     90.480  0.3031    90.052  5531.98
  44   0.2794     90.610  0.2896    90.392  5660.48
  45   0.2601     91.390  0.2802    90.820  5789.13
  46   0.2499     91.710  0.2704    91.087  5917.67
  47   0.2605     91.190  0.2594    91.363  6046.23
  48   0.2356     92.310  0.2477    91.813  6174.78
  49   0.2327     92.450  0.2420    92.003  6303.30
  50   0.2646     91.370  0.2319    92.462  6431.83
  51   0.2031     93.330  0.2224    92.718  6560.49
  52   0.2129     92.930  0.2155    92.982  6689.05
  53   0.1972     93.400  0.2074    93.205  6817.66
  54   0.1902     93.680  0.2016    93.495  6946.20
  55   0.1832     94.230  0.1950    93.668  7074.66
  56   0.2008     93.390  0.1880    93.785  7203.16
  57   0.1741     94.450  0.1837    93.955  7331.70
  58   0.1723     94.190  0.1758    94.258  7460.21
  59   0.1638     94.580  0.1709    94.417  7588.75
  60   0.1704     94.570  0.1650    94.705  7717.31
  61   0.1656     94.520  0.1597    94.842  7846.00
  62   0.1583     94.810  0.1533    95.143  7974.59
  63   0.1475     95.070  0.1510    95.210  8103.13
  64   0.1438     95.330  0.1462    95.322  8231.67
  65   0.1400     95.430  0.1428    95.368  8360.26
  66   0.1328     95.740  0.1393    95.458  8488.76
  67   0.1297     95.690  0.1347    95.645  8617.33
  68   0.1244     95.850  0.1312    95.845  8745.96
  69   0.1407     95.150  0.1272    95.925  8874.52
  70   0.1212     96.050  0.1248    95.992  9003.02
  71   0.1267     95.940  0.1212    96.143  9131.63
  72   0.1128     96.270  0.1179    96.285  9260.13
  73   0.1172     96.350  0.1143    96.397  9388.59
  74   0.1112     96.430  0.1133    96.317  9517.14
  75   0.1183     96.010  0.1095    96.457  9645.69
  76   0.1075     96.510  0.1040    96.683  9774.14
  77   0.1051     96.610  0.1027    96.640  9902.75
  78   0.1150     96.040  0.1017    96.710  10031.16
  79   0.0990     96.510  0.0993    96.857  10159.66
  80   0.0976     96.800  0.0971    96.893  10288.06
  81   0.0990     96.710  0.0944    96.947  10416.52
  82   0.1005     96.640  0.0937    97.040  10544.99
  83   0.0960     96.810  0.0923    97.062  10673.41
  84   0.0907     96.960  0.0878    97.268  10801.96
  85   0.0880     97.160  0.0879    97.183  10930.46
  86   0.0907     97.000  0.0855    97.310  11059.01
  87   0.0885     97.060  0.0838    97.432  11187.54
  88   0.0824     97.250  0.0842    97.360  11315.93
  89   0.0820     97.280  0.0810    97.498  11444.48
  90   0.0884     97.170  0.0806    97.377  11572.99
