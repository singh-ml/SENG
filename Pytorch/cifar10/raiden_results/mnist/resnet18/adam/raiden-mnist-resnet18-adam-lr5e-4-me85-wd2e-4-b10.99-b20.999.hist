Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2006     93.600  0.3362    88.818  7.69
   2   0.0715     97.710  0.0971    96.938  13.82
   3   0.0712     97.790  0.0754    97.637  19.94
   4   0.0541     98.300  0.0692    97.813  26.05
   5   0.0466     98.350  0.0628    98.042  32.14
   6   0.0832     97.200  0.0693    97.877  38.33
   7   0.0595     97.990  0.0600    98.157  44.43
   8   0.0615     97.980  0.0511    98.407  50.53
   9   0.0495     98.370  0.0530    98.342  56.63
  10   0.0476     98.490  0.0512    98.395  62.74
  11   0.0550     98.280  0.0519    98.417  68.93
  12   0.0537     98.400  0.0497    98.468  75.02
  13   0.0441     98.500  0.0487    98.472  81.14
  14   0.0608     98.080  0.0464    98.582  87.32
  15   0.0582     98.040  0.0503    98.475  93.42
  16   0.0554     98.340  0.0509    98.413  99.53
  17   0.0367     98.870  0.0437    98.617  105.73
  18   0.0454     98.640  0.0425    98.722  111.82
  19   0.0539     98.320  0.0450    98.635  117.91
  20   0.0380     98.750  0.0435    98.717  124.02
  21   0.0401     98.690  0.0387    98.858  130.13
  22   0.0413     98.730  0.0415    98.708  136.35
  23   0.0444     98.480  0.0430    98.675  142.44
  24   0.0436     98.750  0.0402    98.755  148.54
  25   0.0447     98.630  0.0400    98.773  154.65
  26   0.0475     98.540  0.0420    98.745  160.73
  27   0.0440     98.400  0.0381    98.820  166.93
  28   0.0303     99.030  0.0363    98.853  173.01
  29   0.0335     98.940  0.0388    98.777  179.17
  30   0.0391     98.720  0.0370    98.843  185.27
  31   0.0398     98.730  0.0354    98.897  191.34
  32   0.0397     98.700  0.0339    98.977  197.43
  33   0.0365     98.700  0.0339    98.945  203.65
  34   0.0317     98.990  0.0322    98.993  209.74
  35   0.0386     98.830  0.0328    99.007  215.85
  36   0.0331     98.930  0.0328    99.008  221.95
  37   0.0283     99.090  0.0325    98.958  228.06
  38   0.0335     98.930  0.0305    99.008  234.26
  39   0.0431     98.490  0.0335    98.978  240.40
  40   0.0368     98.800  0.0325    98.977  246.50
  41   0.0421     98.570  0.0319    99.032  252.61
  42   0.0392     98.640  0.0321    98.988  258.69
  43   0.0365     98.820  0.0312    99.045  264.79
  44   0.0412     98.620  0.0301    99.073  270.88
  45   0.0348     98.950  0.0287    99.128  277.09
  46   0.0250     99.180  0.0295    99.103  283.19
  47   0.0397     98.780  0.0287    99.107  289.30
  48   0.0363     98.870  0.0287    99.080  295.42
  49   0.0314     99.060  0.0290    99.118  301.55
  50   0.0261     99.100  0.0278    99.128  307.63
  51   0.0450     98.440  0.0285    99.110  313.87
  52   0.0377     98.740  0.0267    99.172  319.98
  53   0.0397     98.740  0.0287    99.105  326.10
  54   0.0332     98.990  0.0251    99.213  332.20
  55   0.0321     99.020  0.0236    99.253  338.31
  56   0.0359     98.830  0.0248    99.175  344.41
  57   0.0383     98.820  0.0254    99.233  350.66
  58   0.0412     98.770  0.0269    99.165  356.76
  59   0.0300     99.000  0.0234    99.248  362.88
  60   0.0219     99.240  0.0252    99.207  368.96
  61   0.0219     99.300  0.0230    99.252  375.06
  62   0.0383     98.720  0.0243    99.255  381.27
  63   0.0327     98.940  0.0248    99.205  387.37
  64   0.0328     98.990  0.0247    99.230  393.46
  65   0.0379     98.700  0.0252    99.197  399.59
  66   0.0312     99.010  0.0244    99.265  405.68
  67   0.0338     98.920  0.0227    99.298  411.89
  68   0.0284     99.140  0.0225    99.305  417.99
  69   0.0254     99.120  0.0215    99.327  424.09
  70   0.0232     99.230  0.0239    99.238  430.18
  71   0.0392     98.670  0.0232    99.260  436.28
  72   0.0300     98.890  0.0234    99.263  442.37
  73   0.0287     99.040  0.0229    99.308  448.58
  74   0.0393     98.760  0.0214    99.363  454.68
  75   0.0329     98.970  0.0211    99.357  460.77
  76   0.0461     98.550  0.0220    99.290  466.86
  77   0.0345     98.860  0.0224    99.325  472.98
  78   0.0388     98.920  0.0199    99.383  479.18
  79   0.0339     98.890  0.0205    99.387  485.27
  80   0.0262     99.170  0.0222    99.295  491.39
  81   0.0281     99.100  0.0233    99.242  497.55
  82   0.0317     99.110  0.0210    99.348  503.65
  83   0.0280     99.070  0.0205    99.342  509.76
  84   0.0346     98.940  0.0198    99.362  515.96
  85   0.0253     99.250  0.0210    99.313  522.06
