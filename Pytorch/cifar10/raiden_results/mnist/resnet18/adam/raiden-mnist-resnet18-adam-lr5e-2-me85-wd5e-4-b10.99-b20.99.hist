Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   8.2472     25.280  1.3410    58.530  7.57
   2   0.2078     93.400  0.2531    92.197  13.63
   3   0.2717     91.360  0.1806    94.395  19.78
   4   0.7836     76.940  0.1606    95.072  25.85
   5   0.5382     82.690  0.1512    95.357  31.91
   6   0.4343     86.580  0.1463    95.483  38.01
   7   0.1629     94.940  0.1447    95.528  44.07
   8   0.4011     88.660  0.1366    95.785  50.12
   9   1.1272     70.110  0.1361    95.767  56.35
  10   0.1835     93.970  0.1305    95.933  62.42
  11   0.4163     87.420  0.1334    95.893  68.49
  12   0.9141     71.150  0.1341    95.883  74.57
  13   0.1857     94.170  0.1309    95.915  80.64
  14   0.4722     84.490  0.1303    96.070  86.71
  15   0.8399     72.050  0.1295    96.005  92.86
  16   0.2774     91.320  0.1270    96.097  98.93
  17   0.4085     87.970  0.1240    96.130  105.00
  18   0.3619     87.740  0.1274    96.043  111.06
  19   0.2925     90.280  0.1265    96.178  117.12
  20   0.3033     91.180  0.1273    96.112  123.20
  21   0.1882     94.050  0.1292    96.143  129.40
  22   0.7852     76.050  0.1273    96.190  135.49
  23   0.4400     86.100  0.1284    96.030  141.57
  24   0.6378     82.300  0.1268    96.093  147.63
  25   0.2888     91.180  0.1279    96.110  153.72
  26   0.4515     85.620  0.1268    96.107  159.91
  27   0.1690     94.870  0.1272    96.018  165.97
  28   0.7482     81.040  0.1266    96.083  172.04
  29   0.9691     74.080  0.1310    95.987  178.11
  30   0.1947     93.700  0.1275    96.065  184.18
  31   0.2650     91.830  0.1237    96.197  190.24
  32   0.2985     90.730  0.1249    96.250  196.39
  33   0.2034     93.860  0.1247    96.128  202.44
  34   0.4791     83.700  0.1297    96.040  208.51
  35   0.1464     95.200  0.1266    96.070  214.57
  36   1.0133     69.370  0.1290    95.987  220.66
  37   0.6142     84.370  0.1238    96.177  226.79
  38   0.4673     90.030  0.1283    96.108  232.86
  39   0.3678     88.840  0.1233    96.195  238.92
  40   0.2296     92.830  0.1256    96.170  245.02
  41   0.8188     77.110  0.1230    96.208  251.09
  42   1.3227     71.030  0.1261    96.108  257.12
  43   0.2427     92.420  0.1292    96.167  263.30
  44   0.2603     91.580  0.1256    96.208  269.40
  45   0.8837     76.250  0.1252    96.103  275.46
  46   0.2992     89.380  0.1245    96.155  281.52
  47   0.1763     94.770  0.1241    96.215  287.57
  48   0.3909     86.950  0.1251    96.145  293.73
  49   0.1840     94.020  0.1232    96.218  299.80
  50   0.2079     93.760  0.1265    96.135  305.85
  51   0.6933     80.400  0.1257    96.143  311.91
  52   0.5320     82.700  0.1233    96.275  318.02
  53   0.2272     92.640  0.1253    96.198  324.10
  54   1.6568     58.180  0.1253    96.158  330.28
  55   1.3178     68.670  0.1280    96.127  336.38
  56   0.6006     82.430  0.1290    96.092  342.47
  57   0.3162     90.620  0.1266    96.092  348.53
  58   0.7075     80.520  0.1256    96.088  354.63
  59   0.4886     85.240  0.1244    96.227  360.70
  60   0.3628     88.940  0.1275    96.123  366.83
  61   0.7958     78.900  0.1266    96.168  372.91
  62   0.5309     84.090  0.1233    96.295  378.97
  63   0.3905     87.700  0.1279    96.075  385.04
  64   0.3773     88.240  0.1283    96.087  391.10
  65   1.2786     62.530  0.1239    96.217  397.17
  66   0.4363     85.250  0.1251    96.187  403.33
  67   0.2361     91.920  0.1262    96.137  409.44
  68   0.3870     88.740  0.1216    96.282  415.49
  69   0.1983     93.350  0.1243    96.223  421.56
  70   0.7227     76.960  0.1248    96.218  427.62
  71   0.3175     90.500  0.1247    96.245  433.68
  72   0.3603     88.790  0.1231    96.203  439.86
  73   0.3334     90.150  0.1259    96.132  445.93
  74   0.4673     86.410  0.1265    96.140  452.00
  75   0.2084     93.370  0.1236    96.260  458.07
  76   0.4608     86.640  0.1242    96.182  464.15
  77   0.3908     88.380  0.1260    96.147  470.34
  78   0.3790     89.350  0.1251    96.145  476.40
  79   0.3657     88.850  0.1250    96.192  482.48
  80   0.3537     89.520  0.1254    96.130  488.55
  81   0.6100     83.660  0.1226    96.222  494.63
  82   0.4254     86.730  0.1228    96.202  500.74
  83   0.5366     84.680  0.1220    96.238  506.82
  84   0.5884     85.410  0.1223    96.227  512.89
  85   0.3811     89.420  0.1220    96.315  518.94
