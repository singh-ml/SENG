Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1057     96.510  0.2871    90.617  7.71
   2   0.1090     96.740  0.0999    96.878  13.78
   3   0.0799     97.410  0.0905    97.247  19.94
   4   0.0605     98.050  0.0835    97.365  26.03
   5   0.1154     96.120  0.0766    97.617  32.11
   6   0.0670     97.670  0.0684    97.915  38.20
   7   0.0697     97.600  0.0647    97.962  44.29
   8   0.0655     97.760  0.0604    98.142  50.44
   9   0.0716     97.730  0.0581    98.158  56.53
  10   0.0408     98.730  0.0589    98.227  62.63
  11   0.0608     98.050  0.0572    98.245  68.72
  12   0.0609     98.010  0.0513    98.415  74.81
  13   0.0424     98.650  0.0523    98.372  80.89
  14   0.0474     98.390  0.0500    98.478  87.08
  15   0.0564     98.050  0.0482    98.495  93.16
  16   0.0583     98.270  0.0489    98.502  99.25
  17   0.0438     98.530  0.0467    98.540  105.33
  18   0.0521     98.330  0.0448    98.597  111.41
  19   0.0397     98.640  0.0426    98.685  117.50
  20   0.0329     99.000  0.0436    98.655  123.70
  21   0.0406     98.630  0.0405    98.757  129.78
  22   0.0442     98.670  0.0407    98.757  135.87
  23   0.0364     98.970  0.0415    98.678  141.96
  24   0.0421     98.640  0.0382    98.838  148.09
  25   0.0446     98.500  0.0370    98.887  154.18
  26   0.0319     98.980  0.0387    98.783  160.44
  27   0.0396     98.690  0.0364    98.885  166.55
  28   0.0508     98.210  0.0377    98.838  172.64
  29   0.0317     98.950  0.0363    98.887  178.72
  30   0.0326     98.890  0.0356    98.872  184.83
  31   0.0376     98.830  0.0346    98.945  190.92
  32   0.0374     98.650  0.0343    98.905  197.11
  33   0.0355     98.810  0.0334    98.953  203.20
  34   0.0344     98.850  0.0344    98.957  209.28
  35   0.0391     98.720  0.0341    98.910  215.37
  36   0.0300     99.070  0.0318    98.973  221.46
  37   0.0475     98.470  0.0315    99.025  227.56
  38   0.0285     99.090  0.0321    98.988  233.74
  39   0.0363     98.870  0.0315    99.008  239.84
  40   0.0348     98.820  0.0325    98.963  245.91
  41   0.0351     98.820  0.0311    99.027  251.99
  42   0.0365     98.770  0.0301    99.038  258.07
  43   0.0296     99.090  0.0296    99.068  264.16
  44   0.0309     99.010  0.0279    99.110  270.32
  45   0.0326     98.910  0.0306    99.093  276.41
  46   0.0377     98.770  0.0289    99.103  282.51
  47   0.0298     99.000  0.0306    99.023  288.61
  48   0.0333     98.940  0.0308    99.038  294.70
  49   0.0264     99.240  0.0297    99.068  300.79
  50   0.0333     98.950  0.0290    99.110  306.95
  51   0.0283     99.100  0.0287    99.113  313.03
  52   0.0397     98.660  0.0287    99.102  319.13
  53   0.0319     98.960  0.0282    99.090  325.25
  54   0.0373     98.750  0.0280    99.133  331.34
  55   0.0400     98.800  0.0314    99.038  337.51
  56   0.0333     98.970  0.0294    99.078  343.59
  57   0.0406     98.730  0.0286    99.125  349.68
  58   0.0395     98.730  0.0289    99.107  355.77
  59   0.0412     98.660  0.0279    99.138  361.83
  60   0.0418     98.750  0.0274    99.108  367.92
  61   0.0356     98.800  0.0275    99.100  374.10
  62   0.0280     99.130  0.0263    99.173  380.20
  63   0.0346     98.850  0.0273    99.155  386.32
  64   0.0259     99.230  0.0267    99.150  392.42
  65   0.0334     98.890  0.0263    99.173  398.52
  66   0.0372     98.850  0.0273    99.145  404.71
  67   0.0372     98.760  0.0268    99.165  410.79
  68   0.0340     98.920  0.0271    99.128  416.88
  69   0.0274     99.180  0.0276    99.150  422.96
  70   0.0350     98.890  0.0267    99.185  429.05
  71   0.0542     98.350  0.0258    99.187  435.15
  72   0.0267     99.040  0.0258    99.158  441.32
  73   0.0351     98.860  0.0264    99.160  447.44
  74   0.0289     99.170  0.0249    99.235  453.55
  75   0.0299     98.970  0.0270    99.153  459.64
  76   0.0395     98.780  0.0248    99.207  465.72
  77   0.0359     98.850  0.0251    99.183  471.91
  78   0.0436     98.520  0.0261    99.177  477.97
  79   0.0342     98.860  0.0253    99.205  484.05
  80   0.0303     99.030  0.0264    99.165  490.11
  81   0.0293     99.060  0.0251    99.200  496.19
  82   0.0249     99.220  0.0260    99.168  502.28
  83   0.0364     98.800  0.0247    99.225  508.39
  84   0.0297     99.060  0.0255    99.202  514.49
  85   0.0334     98.900  0.0252    99.203  520.55
  86   0.0326     98.990  0.0248    99.205  526.63
  87   0.0345     98.890  0.0239    99.262  532.72
  88   0.0338     98.810  0.0249    99.223  538.82
  89   0.0264     99.140  0.0271    99.147  544.99
  90   0.0322     99.030  0.0242    99.235  551.10
