Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1693     94.110  0.2800    90.805  7.69
   2   0.1907     93.810  0.0858    97.370  13.75
   3   0.0694     97.760  0.0690    97.880  19.92
   4   0.0702     97.650  0.0597    98.188  26.01
   5   0.0779     97.580  0.0562    98.282  32.06
   6   0.0497     98.220  0.0521    98.333  38.12
   7   0.0567     98.230  0.0526    98.335  44.17
   8   0.0642     97.850  0.0486    98.460  50.33
   9   0.1053     96.640  0.0506    98.395  56.38
  10   0.0572     98.150  0.0456    98.555  62.45
  11   0.0711     97.710  0.0467    98.520  68.50
  12   0.0359     98.800  0.0460    98.568  74.56
  13   0.0410     98.760  0.0431    98.672  80.62
  14   0.0481     98.450  0.0428    98.690  86.75
  15   0.0430     98.740  0.0419    98.668  92.82
  16   0.0444     98.480  0.0415    98.702  98.88
  17   0.0510     98.280  0.0412    98.717  104.98
  18   0.0504     98.360  0.0414    98.758  111.03
  19   0.0686     97.830  0.0400    98.720  117.09
  20   0.0390     98.690  0.0394    98.782  123.25
  21   0.0443     98.620  0.0404    98.747  129.31
  22   0.0672     97.840  0.0370    98.837  135.37
  23   0.0423     98.640  0.0357    98.897  141.43
  24   0.0679     97.640  0.0363    98.840  147.48
  25   0.0338     98.970  0.0337    98.932  153.62
  26   0.0426     98.610  0.0369    98.833  159.69
  27   0.0503     98.480  0.0348    98.863  165.76
  28   0.0416     98.590  0.0348    98.898  171.87
  29   0.0391     98.760  0.0337    98.948  177.93
  30   0.0408     98.720  0.0307    99.015  183.99
  31   0.0361     98.830  0.0331    98.987  190.13
  32   0.0343     98.870  0.0339    98.947  196.19
  33   0.0316     98.940  0.0327    98.997  202.28
  34   0.0404     98.660  0.0312    99.002  208.36
  35   0.0357     98.820  0.0309    98.988  214.46
  36   0.0244     99.130  0.0310    99.063  220.54
  37   0.0271     99.110  0.0296    99.080  226.70
  38   0.0341     98.910  0.0301    99.055  232.78
  39   0.0480     98.580  0.0282    99.128  238.85
  40   0.0270     99.120  0.0293    99.093  244.92
  41   0.0338     98.850  0.0282    99.108  251.05
  42   0.0355     98.840  0.0281    99.133  257.12
  43   0.0377     98.890  0.0282    99.082  263.29
  44   0.0355     98.770  0.0276    99.128  269.37
  45   0.0359     98.880  0.0271    99.157  275.45
  46   0.0274     99.060  0.0267    99.148  281.51
  47   0.0295     99.090  0.0248    99.205  287.60
  48   0.0264     99.190  0.0254    99.193  293.67
  49   0.0393     98.660  0.0239    99.265  299.83
  50   0.0273     99.040  0.0245    99.220  305.91
  51   0.0323     99.000  0.0245    99.210  312.00
  52   0.0446     98.540  0.0251    99.242  318.06
  53   0.0311     99.020  0.0237    99.250  324.13
  54   0.0356     98.890  0.0236    99.235  330.30
  55   0.0430     98.590  0.0233    99.268  336.37
  56   0.0388     98.840  0.0231    99.267  342.44
  57   0.0335     98.910  0.0241    99.213  348.51
  58   0.0400     98.830  0.0226    99.272  354.58
  59   0.0343     98.990  0.0232    99.242  360.70
  60   0.0302     98.970  0.0222    99.305  366.79
  61   0.0364     98.920  0.0219    99.292  372.88
  62   0.0399     98.760  0.0227    99.237  378.96
  63   0.0273     99.110  0.0211    99.307  385.04
  64   0.0287     99.150  0.0202    99.372  391.17
  65   0.0566     98.130  0.0225    99.275  397.32
  66   0.0306     98.970  0.0230    99.243  403.41
  67   0.0258     99.200  0.0207    99.352  409.49
  68   0.0330     98.950  0.0216    99.317  415.56
  69   0.0300     99.010  0.0204    99.338  421.66
  70   0.0401     98.740  0.0216    99.295  427.72
  71   0.0284     99.160  0.0201    99.333  433.90
  72   0.0333     98.910  0.0215    99.333  439.97
  73   0.0264     99.150  0.0190    99.392  446.06
  74   0.0292     99.200  0.0199    99.378  452.14
  75   0.0347     98.940  0.0203    99.357  458.22
  76   0.0410     98.670  0.0193    99.355  464.38
  77   0.0278     99.120  0.0204    99.330  470.47
  78   0.0353     98.850  0.0208    99.333  476.54
  79   0.0407     98.820  0.0187    99.402  482.61
  80   0.0307     99.070  0.0196    99.357  488.67
  81   0.0394     98.670  0.0170    99.450  494.74
  82   0.0314     98.980  0.0185    99.382  500.90
  83   0.0391     98.820  0.0179    99.440  507.01
  84   0.0303     98.970  0.0186    99.383  513.16
  85   0.0307     98.920  0.0203    99.347  519.26
