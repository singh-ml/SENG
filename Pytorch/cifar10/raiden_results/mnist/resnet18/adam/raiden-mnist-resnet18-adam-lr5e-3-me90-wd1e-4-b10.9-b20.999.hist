Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5506     83.980  0.5317    82.742  7.54
   2   0.4047     86.750  0.1475    95.425  13.66
   3   0.3232     90.690  0.1262    96.110  19.78
   4   0.1681     94.770  0.1069    96.742  25.98
   5   0.2404     92.800  0.0971    97.065  32.09
   6   0.0760     97.690  0.0902    97.170  38.21
   7   0.1305     96.000  0.0821    97.415  44.32
   8   0.1360     96.150  0.0789    97.575  50.45
   9   0.0905     97.070  0.0737    97.753  56.58
  10   0.1040     96.570  0.0706    97.848  62.80
  11   0.0497     98.590  0.0688    97.858  68.91
  12   0.0753     97.560  0.0627    98.002  75.04
  13   0.0793     97.410  0.0639    98.007  81.16
  14   0.0557     98.190  0.0615    98.080  87.27
  15   0.0889     97.070  0.0596    98.202  93.41
  16   0.0565     98.120  0.0611    98.135  99.54
  17   0.0541     98.250  0.0582    98.228  105.68
  18   0.0751     97.490  0.0579    98.245  111.82
  19   0.0734     97.900  0.0577    98.205  117.99
  20   0.0596     97.870  0.0542    98.335  124.14
  21   0.0681     97.860  0.0572    98.183  130.29
  22   0.1757     92.940  0.0538    98.305  136.54
  23   0.0894     97.320  0.0509    98.447  142.66
  24   0.0627     98.000  0.0540    98.340  148.80
  25   0.0599     98.150  0.0536    98.325  154.96
  26   0.0724     97.550  0.0520    98.403  161.09
  27   0.0569     98.120  0.0503    98.480  167.23
  28   0.0489     98.420  0.0543    98.348  173.44
  29   0.0427     98.550  0.0503    98.448  179.59
  30   0.0490     98.540  0.0508    98.435  185.72
  31   0.0548     98.260  0.0507    98.450  191.89
  32   0.0449     98.530  0.0523    98.368  198.06
  33   0.0362     98.820  0.0515    98.363  204.34
  34   0.0604     98.030  0.0494    98.458  210.48
  35   0.0555     98.310  0.0515    98.443  216.63
  36   0.0680     97.900  0.0490    98.468  222.78
  37   0.0482     98.450  0.0487    98.500  228.91
  38   0.1520     95.660  0.0500    98.453  235.15
  39   0.0565     98.180  0.0477    98.513  241.28
  40   0.0565     98.020  0.0508    98.470  247.42
  41   0.0580     98.160  0.0469    98.562  253.56
  42   0.0834     97.530  0.0486    98.517  259.70
  43   0.0700     97.700  0.0486    98.507  265.89
  44   0.0666     97.740  0.0491    98.507  272.20
  45   0.0475     98.560  0.0475    98.488  278.37
  46   0.0780     97.530  0.0490    98.442  284.54
  47   0.0427     98.610  0.0473    98.545  290.68
  48   0.0517     98.440  0.0489    98.493  296.80
  49   0.0413     98.530  0.0486    98.492  303.03
  50   0.1553     95.090  0.0485    98.488  309.17
  51   0.0457     98.440  0.0473    98.537  315.32
  52   0.0711     97.760  0.0475    98.525  321.48
  53   0.0549     98.380  0.0468    98.550  327.62
  54   0.1000     97.120  0.0490    98.482  333.75
  55   0.0453     98.580  0.0467    98.575  339.98
  56   0.0582     98.180  0.0458    98.600  346.12
  57   0.0531     98.270  0.0471    98.518  352.25
  58   0.1074     96.680  0.0458    98.563  358.41
  59   0.0540     98.420  0.0464    98.515  364.60
  60   0.0542     98.180  0.0463    98.543  370.86
  61   0.1199     96.190  0.0479    98.540  377.00
  62   0.1558     95.150  0.0458    98.565  383.15
  63   0.0496     98.400  0.0481    98.543  389.29
  64   0.0391     98.560  0.0468    98.597  395.43
  65   0.0610     98.090  0.0467    98.502  401.56
  66   0.0756     97.650  0.0451    98.572  407.78
  67   0.0525     98.310  0.0486    98.507  413.91
  68   0.1066     96.550  0.0467    98.548  420.06
  69   0.0765     97.680  0.0463    98.545  426.17
  70   0.0886     97.260  0.0466    98.595  432.33
  71   0.1336     96.050  0.0470    98.525  438.47
  72   0.1951     94.440  0.0448    98.623  444.70
  73   0.0514     98.440  0.0447    98.582  450.86
  74   0.0474     98.470  0.0460    98.565  457.01
  75   0.0717     97.780  0.0466    98.578  463.15
  76   0.0431     98.700  0.0476    98.505  469.29
  77   0.2784     89.720  0.0453    98.565  475.45
  78   0.0393     98.770  0.0446    98.545  481.70
  79   0.1333     95.900  0.0472    98.522  487.83
  80   0.0468     98.530  0.0449    98.562  493.98
  81   0.0545     98.180  0.0444    98.620  500.12
  82   0.3259     88.720  0.0458    98.582  506.26
  83   0.0473     98.550  0.0450    98.590  512.50
  84   0.0788     97.590  0.0445    98.603  518.65
  85   0.0683     97.880  0.0449    98.568  524.80
  86   0.0825     97.330  0.0451    98.562  530.99
  87   0.0850     97.320  0.0452    98.567  537.14
  88   0.0563     98.230  0.0436    98.595  543.28
  89   0.0481     98.470  0.0449    98.568  549.55
  90   0.0590     98.060  0.0456    98.638  555.68
