Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2368     91.880  0.3143    89.568  7.64
   2   0.2043     93.440  0.1141    96.508  13.78
   3   0.0864     97.340  0.0957    97.060  20.01
   4   0.0768     97.570  0.0916    97.158  26.13
   5   0.1025     96.680  0.0803    97.567  32.24
   6   0.0775     97.570  0.0744    97.803  38.37
   7   0.0843     97.470  0.0762    97.738  44.54
   8   0.0898     97.150  0.0742    97.793  50.73
   9   0.0507     98.370  0.0664    98.068  56.99
  10   0.0747     97.570  0.0629    98.142  63.11
  11   0.0428     98.780  0.0650    98.068  69.24
  12   0.0493     98.640  0.0642    98.097  75.37
  13   0.0582     98.260  0.0629    98.128  81.51
  14   0.0579     98.170  0.0575    98.260  87.75
  15   0.0458     98.700  0.0547    98.347  93.90
  16   0.0471     98.490  0.0560    98.302  100.02
  17   0.0427     98.610  0.0521    98.483  106.14
  18   0.0431     98.620  0.0486    98.570  112.28
  19   0.0338     98.860  0.0485    98.555  118.54
  20   0.0364     98.810  0.0518    98.433  124.67
  21   0.0506     98.360  0.0491    98.537  130.78
  22   0.0465     98.470  0.0466    98.625  136.89
  23   0.0536     98.340  0.0460    98.622  143.02
  24   0.0447     98.530  0.0483    98.532  149.16
  25   0.0513     98.490  0.0460    98.620  155.41
  26   0.0482     98.440  0.0461    98.640  161.54
  27   0.0534     98.190  0.0475    98.535  167.68
  28   0.0461     98.650  0.0432    98.727  173.80
  29   0.0441     98.620  0.0414    98.732  179.94
  30   0.0426     98.580  0.0405    98.777  186.06
  31   0.0437     98.710  0.0407    98.827  192.19
  32   0.0369     98.780  0.0419    98.762  198.41
  33   0.0380     98.850  0.0406    98.797  204.54
  34   0.0441     98.630  0.0396    98.832  210.67
  35   0.0420     98.670  0.0420    98.763  216.85
  36   0.0384     98.760  0.0384    98.803  222.99
  37   0.0404     98.670  0.0383    98.843  229.21
  38   0.0375     98.790  0.0367    98.853  235.34
  39   0.0488     98.590  0.0389    98.828  241.47
  40   0.0453     98.590  0.0362    98.905  247.60
  41   0.0410     98.620  0.0372    98.873  253.73
  42   0.0497     98.450  0.0345    98.975  259.95
  43   0.0296     99.000  0.0378    98.922  266.13
  44   0.0362     98.840  0.0367    98.883  272.25
  45   0.0330     98.990  0.0357    98.930  278.40
  46   0.0337     98.870  0.0355    98.895  284.54
  47   0.0353     98.860  0.0352    98.950  290.67
  48   0.0386     98.790  0.0342    98.980  296.82
  49   0.0483     98.490  0.0337    98.995  302.94
  50   0.0333     98.990  0.0343    98.992  309.05
  51   0.0401     98.800  0.0349    98.942  315.23
  52   0.0454     98.630  0.0369    98.920  321.34
  53   0.0345     98.860  0.0348    98.977  327.58
  54   0.0384     98.770  0.0351    98.948  333.72
  55   0.0456     98.500  0.0354    98.922  339.91
  56   0.0386     98.860  0.0359    98.907  346.04
  57   0.0339     98.950  0.0343    98.955  352.20
  58   0.0448     98.420  0.0333    99.000  358.33
  59   0.0354     98.900  0.0342    98.990  364.57
  60   0.0320     99.030  0.0328    99.038  370.70
  61   0.0376     98.880  0.0337    98.965  376.86
  62   0.0327     99.000  0.0330    99.040  382.98
  63   0.0281     99.090  0.0326    98.998  389.11
  64   0.0331     99.070  0.0341    98.955  395.33
  65   0.0409     98.630  0.0337    99.007  401.45
  66   0.0358     98.840  0.0313    99.077  407.59
  67   0.0370     98.770  0.0317    99.058  413.73
  68   0.0437     98.620  0.0338    99.003  419.85
  69   0.0369     98.910  0.0336    99.030  425.98
  70   0.0434     98.560  0.0327    99.042  432.10
  71   0.0314     98.970  0.0321    99.012  438.33
  72   0.0369     98.820  0.0344    98.925  444.53
  73   0.0354     98.870  0.0312    99.062  450.66
  74   0.0325     98.940  0.0324    99.043  456.79
  75   0.0345     98.890  0.0341    98.992  462.93
  76   0.0379     98.770  0.0324    99.043  469.06
  77   0.0312     98.970  0.0332    99.012  475.31
  78   0.0388     98.760  0.0317    99.010  481.43
  79   0.0376     98.870  0.0319    99.028  487.58
  80   0.0350     98.930  0.0321    99.013  493.71
  81   0.0326     98.910  0.0327    99.058  499.86
  82   0.0366     98.900  0.0317    99.060  506.09
  83   0.0347     98.860  0.0298    99.058  512.23
  84   0.0283     99.050  0.0311    99.093  518.33
  85   0.0293     99.150  0.0316    99.060  524.48
  86   0.0406     98.670  0.0315    99.052  530.61
  87   0.0346     98.850  0.0322    99.045  536.74
  88   0.0377     98.870  0.0310    99.072  542.97
  89   0.0424     98.700  0.0315    99.015  549.10
  90   0.0525     98.330  0.0327    99.018  555.24
