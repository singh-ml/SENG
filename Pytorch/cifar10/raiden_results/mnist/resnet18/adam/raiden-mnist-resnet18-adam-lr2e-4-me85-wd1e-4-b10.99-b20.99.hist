Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1260     95.960  0.4329    85.798  7.71
   2   0.0844     97.150  0.1111    96.448  13.79
   3   0.0761     97.590  0.0757    97.655  19.86
   4   0.0582     98.240  0.0649    98.000  25.96
   5   0.0570     98.110  0.0542    98.303  32.02
   6   0.0642     97.800  0.0499    98.440  38.09
   7   0.0446     98.590  0.0489    98.518  44.28
   8   0.0420     98.700  0.0466    98.500  50.38
   9   0.0436     98.550  0.0413    98.727  56.48
  10   0.0456     98.430  0.0426    98.633  62.57
  11   0.0411     98.570  0.0399    98.722  68.67
  12   0.0345     98.840  0.0398    98.753  74.74
  13   0.0555     98.200  0.0365    98.827  80.94
  14   0.0328     98.850  0.0369    98.855  87.02
  15   0.0328     98.880  0.0333    98.952  93.10
  16   0.0351     98.940  0.0346    98.878  99.17
  17   0.0409     98.700  0.0318    98.978  105.26
  18   0.0391     98.720  0.0355    98.872  111.35
  19   0.0380     98.830  0.0335    98.940  117.56
  20   0.0496     98.450  0.0321    99.007  123.69
  21   0.0367     98.840  0.0318    98.987  129.77
  22   0.0342     98.860  0.0309    99.068  135.90
  23   0.0335     98.890  0.0291    99.037  141.96
  24   0.0411     98.740  0.0279    99.110  148.02
  25   0.0382     98.820  0.0280    99.118  154.22
  26   0.0287     99.080  0.0284    99.098  160.34
  27   0.0282     99.200  0.0265    99.145  166.42
  28   0.0294     99.060  0.0263    99.148  172.49
  29   0.0312     98.990  0.0250    99.213  178.59
  30   0.0351     98.860  0.0269    99.118  184.67
  31   0.0306     98.940  0.0265    99.153  190.77
  32   0.0356     98.880  0.0256    99.190  196.84
  33   0.0397     98.710  0.0241    99.242  202.92
  34   0.0272     99.220  0.0248    99.197  209.02
  35   0.0333     98.970  0.0247    99.205  215.11
  36   0.0339     98.880  0.0234    99.295  221.30
  37   0.0345     98.910  0.0239    99.250  227.38
  38   0.0279     99.100  0.0232    99.272  233.47
  39   0.0298     99.110  0.0231    99.272  239.54
  40   0.0270     99.200  0.0239    99.240  245.60
  41   0.0387     98.820  0.0221    99.270  251.67
  42   0.0300     99.060  0.0232    99.255  257.87
  43   0.0353     98.890  0.0221    99.292  263.94
  44   0.0368     99.010  0.0217    99.320  270.03
  45   0.0375     98.870  0.0235    99.250  276.12
  46   0.0287     99.160  0.0211    99.345  282.21
  47   0.0362     98.830  0.0217    99.323  288.33
  48   0.0295     99.140  0.0193    99.372  294.44
  49   0.0390     98.700  0.0210    99.352  300.53
  50   0.0311     99.080  0.0188    99.380  306.68
  51   0.0314     99.130  0.0190    99.387  312.77
  52   0.0341     98.870  0.0204    99.353  318.84
  53   0.0375     98.870  0.0205    99.340  324.99
  54   0.0282     99.110  0.0198    99.332  331.07
  55   0.0324     98.950  0.0184    99.402  337.16
  56   0.0276     99.150  0.0187    99.385  343.26
  57   0.0356     98.830  0.0178    99.420  349.37
  58   0.0327     98.960  0.0190    99.387  355.44
  59   0.0297     99.070  0.0181    99.378  361.60
  60   0.0400     98.770  0.0186    99.413  367.69
  61   0.0313     99.050  0.0175    99.450  373.78
  62   0.0276     99.180  0.0168    99.452  379.87
  63   0.0316     98.920  0.0180    99.397  385.98
  64   0.0311     99.000  0.0165    99.472  392.06
  65   0.0370     98.860  0.0161    99.477  398.24
  66   0.0270     99.130  0.0171    99.440  404.30
  67   0.0282     99.130  0.0162    99.495  410.39
  68   0.0342     98.900  0.0153    99.503  416.47
  69   0.0244     99.250  0.0168    99.417  422.60
  70   0.0354     98.860  0.0163    99.482  428.71
  71   0.0353     98.830  0.0181    99.432  434.88
  72   0.0360     98.970  0.0157    99.503  440.96
  73   0.0310     98.980  0.0164    99.423  447.02
  74   0.0398     98.800  0.0162    99.472  453.09
  75   0.0443     98.590  0.0158    99.500  459.17
  76   0.0444     98.550  0.0170    99.447  465.38
  77   0.0342     99.010  0.0169    99.432  471.48
  78   0.0368     98.890  0.0147    99.517  477.56
  79   0.0309     99.070  0.0149    99.525  483.66
  80   0.0259     99.220  0.0149    99.502  489.75
  81   0.0330     98.960  0.0140    99.570  495.90
  82   0.0309     99.050  0.0135    99.578  502.00
  83   0.0295     99.020  0.0143    99.505  508.07
  84   0.0269     99.180  0.0135    99.558  514.14
  85   0.0313     99.050  0.0128    99.585  520.24
