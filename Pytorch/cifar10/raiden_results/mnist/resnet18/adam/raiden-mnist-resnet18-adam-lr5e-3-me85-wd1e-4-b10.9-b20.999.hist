Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5365     80.930  0.6831    77.352  7.71
   2   0.2276     93.050  0.1604    94.953  13.88
   3   0.1569     94.980  0.1220    96.192  19.97
   4   0.1580     95.240  0.1094    96.660  26.06
   5   0.1501     95.140  0.0976    96.950  32.14
   6   0.1777     94.450  0.0896    97.190  38.22
   7   0.0838     97.310  0.0800    97.560  44.31
   8   0.1665     94.680  0.0774    97.665  50.49
   9   0.0918     97.130  0.0742    97.677  56.57
  10   0.0982     97.100  0.0741    97.782  62.66
  11   0.0776     97.530  0.0712    97.777  68.74
  12   0.0769     97.880  0.0679    97.892  74.84
  13   0.0701     97.790  0.0652    97.997  80.96
  14   0.0696     97.660  0.0627    98.100  87.14
  15   0.0619     98.130  0.0610    98.122  93.24
  16   0.0660     97.800  0.0622    97.983  99.35
  17   0.0530     98.300  0.0617    98.032  105.46
  18   0.0568     98.270  0.0587    98.245  111.56
  19   0.0946     96.800  0.0574    98.230  117.66
  20   0.0463     98.560  0.0578    98.258  123.89
  21   0.0708     97.620  0.0567    98.248  130.01
  22   0.0510     98.320  0.0565    98.250  136.13
  23   0.0441     98.600  0.0564    98.232  142.22
  24   0.0480     98.470  0.0545    98.315  148.33
  25   0.0787     97.490  0.0554    98.280  154.47
  26   0.0507     98.300  0.0549    98.233  160.65
  27   0.0535     98.220  0.0544    98.295  166.75
  28   0.0486     98.460  0.0532    98.307  172.90
  29   0.2154     92.290  0.0513    98.408  179.00
  30   0.0543     98.260  0.0517    98.397  185.12
  31   0.0406     98.750  0.0522    98.358  191.32
  32   0.0647     98.040  0.0505    98.442  197.44
  33   0.0509     98.400  0.0515    98.418  203.53
  34   0.0773     97.700  0.0514    98.400  209.64
  35   0.0805     97.430  0.0506    98.378  215.76
  36   0.0457     98.420  0.0500    98.455  221.86
  37   0.0523     98.210  0.0488    98.453  228.07
  38   0.0641     97.890  0.0485    98.495  234.20
  39   0.0554     98.330  0.0493    98.412  240.30
  40   0.0727     97.760  0.0490    98.505  246.44
  41   0.0455     98.510  0.0479    98.502  252.56
  42   0.0482     98.510  0.0489    98.518  258.78
  43   0.0479     98.320  0.0474    98.525  264.87
  44   0.1164     96.490  0.0459    98.565  270.97
  45   0.0572     98.150  0.0467    98.585  277.04
  46   0.0486     98.450  0.0478    98.528  283.15
  47   0.0434     98.540  0.0474    98.510  289.29
  48   0.0484     98.510  0.0488    98.527  295.49
  49   0.0536     98.330  0.0477    98.533  301.61
  50   0.0677     97.940  0.0477    98.527  307.74
  51   0.0728     97.710  0.0477    98.482  313.84
  52   0.0825     97.560  0.0451    98.612  319.94
  53   0.0596     98.070  0.0463    98.528  326.12
  54   0.0606     98.110  0.0480    98.530  332.23
  55   0.0909     97.070  0.0467    98.555  338.36
  56   0.0487     98.360  0.0455    98.583  344.46
  57   0.0980     96.780  0.0475    98.532  350.54
  58   0.0590     98.150  0.0478    98.537  356.65
  59   0.0471     98.340  0.0479    98.460  362.74
  60   0.0523     98.320  0.0460    98.567  368.91
  61   0.0661     97.760  0.0448    98.610  375.01
  62   0.0508     98.300  0.0476    98.553  381.11
  63   0.0508     98.350  0.0457    98.560  387.20
  64   0.0596     98.130  0.0451    98.623  393.35
  65   0.0735     97.550  0.0449    98.570  399.56
  66   0.0425     98.580  0.0451    98.565  405.67
  67   0.0399     98.760  0.0475    98.510  411.76
  68   0.0543     98.270  0.0459    98.565  417.86
  69   0.2367     93.420  0.0458    98.607  423.96
  70   0.0823     97.280  0.0461    98.590  430.07
  71   0.0621     97.820  0.0462    98.535  436.29
  72   0.0700     97.940  0.0480    98.452  442.39
  73   0.0860     97.210  0.0451    98.593  448.53
  74   0.0590     97.970  0.0464    98.567  454.64
  75   0.0415     98.550  0.0442    98.577  460.75
  76   0.0689     97.710  0.0450    98.567  466.83
  77   0.0743     97.570  0.0460    98.563  473.03
  78   0.0576     98.260  0.0445    98.607  479.16
  79   0.1072     96.600  0.0432    98.657  485.27
  80   0.0765     97.740  0.0446    98.588  491.38
  81   0.0567     98.050  0.0438    98.625  497.47
  82   0.0464     98.570  0.0452    98.580  503.56
  83   0.0843     97.490  0.0444    98.602  509.76
  84   0.0862     97.260  0.0461    98.553  515.91
  85   0.0455     98.480  0.0453    98.575  522.02
