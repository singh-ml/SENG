Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2665     91.800  0.2657    91.237  7.68
   2   0.2121     92.860  0.0907    97.208  13.71
   3   0.0902     96.910  0.0742    97.708  19.76
   4   0.0847     97.140  0.0681    97.913  25.80
   5   0.0850     97.250  0.0644    98.050  31.87
   6   0.0921     97.230  0.0615    98.105  37.92
   7   0.0882     97.270  0.0589    98.187  44.05
   8   0.0831     97.390  0.0611    98.133  50.09
   9   0.0775     97.390  0.0566    98.222  56.14
  10   0.0923     97.040  0.0548    98.367  62.18
  11   0.0614     98.140  0.0586    98.217  68.22
  12   0.0809     97.630  0.0538    98.390  74.38
  13   0.0567     98.280  0.0502    98.487  80.42
  14   0.0681     97.810  0.0502    98.473  86.47
  15   0.0520     98.340  0.0511    98.450  92.52
  16   0.0580     98.220  0.0487    98.510  98.60
  17   0.0549     98.110  0.0461    98.560  104.65
  18   0.0576     97.960  0.0452    98.552  110.79
  19   0.0676     97.950  0.0442    98.652  116.84
  20   0.0448     98.510  0.0459    98.645  122.87
  21   0.0545     98.190  0.0432    98.623  128.92
  22   0.0452     98.540  0.0410    98.722  134.97
  23   0.0516     98.420  0.0410    98.708  141.12
  24   0.0499     98.390  0.0392    98.767  147.18
  25   0.0360     98.760  0.0405    98.763  153.26
  26   0.0372     98.800  0.0381    98.848  159.31
  27   0.0434     98.570  0.0375    98.815  165.35
  28   0.0392     98.760  0.0375    98.860  171.45
  29   0.0458     98.440  0.0366    98.847  177.51
  30   0.0410     98.560  0.0366    98.787  183.57
  31   0.0402     98.560  0.0358    98.893  189.63
  32   0.0319     99.050  0.0358    98.865  195.71
  33   0.0931     97.250  0.0342    98.893  201.75
  34   0.0335     98.940  0.0349    98.857  207.80
  35   0.0319     98.820  0.0323    98.997  213.93
  36   0.0332     98.950  0.0321    99.020  220.00
  37   0.0388     98.680  0.0325    98.985  226.10
  38   0.0459     98.450  0.0328    98.985  232.18
  39   0.0465     98.530  0.0301    99.042  238.25
  40   0.0323     98.930  0.0333    98.983  244.30
  41   0.0378     98.710  0.0301    99.053  250.48
  42   0.0361     98.860  0.0299    99.083  256.54
  43   0.0320     98.970  0.0322    98.977  262.61
  44   0.0389     98.720  0.0309    99.053  268.68
  45   0.0301     99.040  0.0287    99.133  274.76
  46   0.0356     98.900  0.0270    99.168  280.82
  47   0.0282     99.100  0.0295    99.048  287.00
  48   0.0330     98.860  0.0290    99.055  293.06
  49   0.0386     98.690  0.0285    99.128  299.12
  50   0.0457     98.550  0.0285    99.090  305.20
  51   0.0274     99.080  0.0277    99.117  311.28
  52   0.0321     98.990  0.0276    99.143  317.35
  53   0.0377     98.810  0.0264    99.168  323.52
  54   0.0277     99.100  0.0291    99.072  329.60
  55   0.0418     98.600  0.0260    99.203  335.67
  56   0.0456     98.410  0.0269    99.162  341.75
  57   0.0306     98.930  0.0261    99.177  347.83
  58   0.0555     98.270  0.0268    99.177  353.91
  59   0.0306     98.940  0.0260    99.172  360.09
  60   0.0479     98.460  0.0261    99.202  366.17
  61   0.0300     99.070  0.0257    99.183  372.23
  62   0.0355     98.860  0.0259    99.163  378.29
  63   0.0427     98.520  0.0241    99.248  384.36
  64   0.0246     99.250  0.0241    99.227  390.42
  65   0.0367     98.840  0.0252    99.177  396.61
  66   0.0369     98.860  0.0269    99.125  402.68
  67   0.0358     98.860  0.0242    99.225  408.79
  68   0.0366     98.850  0.0257    99.183  414.87
  69   0.0291     99.040  0.0236    99.235  420.93
  70   0.0348     98.940  0.0234    99.237  427.10
  71   0.0434     98.770  0.0247    99.203  433.18
  72   0.0425     98.840  0.0261    99.143  439.24
  73   0.0408     98.730  0.0230    99.265  445.32
  74   0.0262     99.130  0.0233    99.253  451.43
  75   0.0344     98.940  0.0237    99.243  457.54
  76   0.0333     99.060  0.0239    99.227  463.68
  77   0.0341     98.820  0.0225    99.247  469.76
  78   0.0407     98.720  0.0243    99.220  475.83
  79   0.0277     99.120  0.0230    99.285  481.89
  80   0.0361     98.850  0.0231    99.275  487.99
  81   0.0377     98.730  0.0249    99.202  494.16
  82   0.0278     99.110  0.0226    99.263  500.23
  83   0.0309     98.970  0.0224    99.280  506.30
  84   0.0295     98.990  0.0216    99.300  512.36
  85   0.0544     98.510  0.0241    99.207  518.44
