Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5655     78.770  0.6095    80.147  7.55
   2   0.2133     93.590  0.1832    94.317  13.66
   3   0.2257     92.860  0.1255    96.125  19.78
   4   0.0973     97.050  0.1091    96.593  25.88
   5   0.1466     95.240  0.0944    97.080  32.07
   6   0.0882     97.320  0.0867    97.290  38.15
   7   0.0697     97.750  0.0794    97.558  44.27
   8   0.0656     97.800  0.0729    97.780  50.39
   9   0.0640     97.920  0.0727    97.737  56.51
  10   0.0583     98.030  0.0662    97.927  62.64
  11   0.0680     97.750  0.0646    97.962  68.92
  12   0.0576     98.190  0.0605    98.187  75.04
  13   0.0658     97.690  0.0583    98.202  81.16
  14   0.0835     97.560  0.0586    98.182  87.27
  15   0.0581     98.050  0.0588    98.228  93.38
  16   0.0467     98.430  0.0541    98.343  99.59
  17   0.0463     98.520  0.0559    98.273  105.73
  18   0.0548     98.260  0.0520    98.433  111.84
  19   0.0547     98.320  0.0545    98.212  117.96
  20   0.0481     98.480  0.0535    98.372  124.06
  21   0.0530     98.220  0.0502    98.418  130.19
  22   0.0541     98.220  0.0516    98.425  136.42
  23   0.0526     98.240  0.0512    98.437  142.53
  24   0.0659     97.900  0.0522    98.367  148.64
  25   0.0413     98.580  0.0489    98.478  154.76
  26   0.0703     97.550  0.0492    98.493  160.91
  27   0.0467     98.470  0.0485    98.450  167.01
  28   0.0498     98.360  0.0461    98.520  173.22
  29   0.0430     98.620  0.0492    98.460  179.32
  30   0.0469     98.420  0.0459    98.563  185.42
  31   0.0482     98.340  0.0465    98.540  191.56
  32   0.0456     98.490  0.0452    98.557  197.67
  33   0.0522     98.300  0.0463    98.552  203.78
  34   0.0604     98.010  0.0442    98.613  209.99
  35   0.0455     98.550  0.0465    98.532  216.09
  36   0.0431     98.590  0.0436    98.605  222.20
  37   0.0392     98.770  0.0448    98.630  228.29
  38   0.0330     98.830  0.0444    98.575  234.40
  39   0.0414     98.460  0.0436    98.638  240.50
  40   0.0419     98.610  0.0434    98.582  246.70
  41   0.0477     98.280  0.0414    98.685  252.81
  42   0.0430     98.590  0.0426    98.698  258.92
  43   0.0466     98.590  0.0438    98.555  265.03
  44   0.0471     98.430  0.0434    98.627  271.12
  45   0.0444     98.500  0.0439    98.658  277.22
  46   0.0648     98.130  0.0441    98.622  283.43
  47   0.0388     98.770  0.0434    98.670  289.54
  48   0.0421     98.600  0.0413    98.708  295.64
  49   0.0401     98.660  0.0421    98.665  301.74
  50   0.0421     98.600  0.0457    98.568  307.84
  51   0.0401     98.650  0.0439    98.615  314.04
  52   0.0433     98.450  0.0439    98.608  320.13
  53   0.0483     98.480  0.0430    98.618  326.27
  54   0.0328     98.850  0.0421    98.725  332.41
  55   0.0442     98.590  0.0398    98.743  338.53
  56   0.0399     98.630  0.0411    98.692  344.65
  57   0.0336     98.910  0.0431    98.635  350.87
  58   0.0571     98.210  0.0426    98.635  356.97
  59   0.0487     98.420  0.0397    98.760  363.09
  60   0.0485     98.330  0.0426    98.635  369.20
  61   0.0364     98.780  0.0422    98.628  375.31
  62   0.0404     98.560  0.0424    98.630  381.53
  63   0.0482     98.290  0.0402    98.743  387.62
  64   0.0445     98.470  0.0413    98.678  393.70
  65   0.0538     98.230  0.0416    98.688  399.82
  66   0.0496     98.510  0.0425    98.638  405.96
  67   0.0500     98.290  0.0410    98.685  412.12
  68   0.0428     98.540  0.0427    98.642  418.23
  69   0.0587     98.010  0.0396    98.730  424.35
  70   0.0419     98.590  0.0415    98.682  430.46
  71   0.0463     98.480  0.0417    98.680  436.56
  72   0.0416     98.690  0.0433    98.585  442.68
  73   0.0357     98.720  0.0402    98.722  448.89
  74   0.0412     98.660  0.0404    98.722  455.00
  75   0.0527     98.330  0.0395    98.718  461.10
  76   0.0449     98.520  0.0386    98.762  467.20
  77   0.0573     98.150  0.0400    98.735  473.30
  78   0.0480     98.510  0.0406    98.705  479.45
  79   0.0456     98.420  0.0382    98.797  485.59
  80   0.0478     98.470  0.0400    98.712  491.69
  81   0.0433     98.570  0.0391    98.770  497.78
  82   0.0423     98.580  0.0428    98.665  503.89
  83   0.0491     98.480  0.0411    98.648  510.00
  84   0.0410     98.610  0.0404    98.753  516.22
  85   0.0397     98.670  0.0405    98.723  522.32
  86   0.0495     98.430  0.0413    98.725  528.40
  87   0.0414     98.750  0.0415    98.733  534.52
  88   0.0473     98.440  0.0386    98.783  540.61
  89   0.0447     98.620  0.0414    98.700  546.73
  90   0.0392     98.710  0.0380    98.803  552.94
