Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1618     94.790  0.2507    91.820  7.70
   2   0.0778     97.700  0.0902    97.210  13.83
   3   0.2194     93.160  0.0746    97.705  19.93
   4   0.1307     95.740  0.0690    97.893  26.03
   5   0.0808     97.580  0.0642    98.030  32.14
   6   0.1228     96.200  0.0643    97.983  38.24
   7   0.0972     96.830  0.0627    98.065  44.45
   8   0.0648     97.860  0.0593    98.147  50.57
   9   0.0589     98.050  0.0571    98.268  56.67
  10   0.0472     98.560  0.0545    98.365  62.80
  11   0.0769     97.520  0.0537    98.352  68.90
  12   0.0748     97.550  0.0531    98.302  75.00
  13   0.0769     97.780  0.0523    98.372  81.20
  14   0.0750     97.580  0.0528    98.355  87.30
  15   0.0752     97.610  0.0492    98.472  93.43
  16   0.0533     98.480  0.0487    98.475  99.56
  17   0.0649     97.960  0.0466    98.563  105.67
  18   0.0872     97.270  0.0461    98.622  111.81
  19   0.1213     96.230  0.0456    98.625  117.92
  20   0.0402     98.700  0.0436    98.652  124.04
  21   0.0515     98.240  0.0441    98.670  130.15
  22   0.0438     98.650  0.0410    98.758  136.25
  23   0.0487     98.340  0.0439    98.668  142.37
  24   0.0434     98.510  0.0407    98.777  148.58
  25   0.0458     98.550  0.0390    98.750  154.70
  26   0.0412     98.750  0.0387    98.830  160.80
  27   0.0535     98.270  0.0375    98.838  166.91
  28   0.0338     98.930  0.0373    98.838  173.04
  29   0.2716     91.390  0.0360    98.840  179.24
  30   0.0382     98.740  0.0373    98.808  185.36
  31   0.0448     98.540  0.0348    98.922  191.46
  32   0.0600     98.090  0.0344    98.955  197.61
  33   0.0256     99.120  0.0336    98.945  203.73
  34   0.0539     98.400  0.0353    98.903  209.85
  35   0.0407     98.610  0.0350    98.908  216.07
  36   0.0503     98.260  0.0333    98.932  222.20
  37   0.0420     98.590  0.0347    98.897  228.32
  38   0.0392     98.760  0.0320    98.947  234.45
  39   0.0439     98.570  0.0324    99.022  240.59
  40   0.0276     99.000  0.0335    98.948  246.77
  41   0.0396     98.730  0.0301    99.045  252.89
  42   0.0277     99.100  0.0308    99.033  259.07
  43   0.0516     98.400  0.0293    99.087  265.23
  44   0.0311     98.930  0.0334    98.947  271.36
  45   0.0291     99.040  0.0285    99.108  277.56
  46   0.0524     98.330  0.0295    99.103  283.78
  47   0.0303     99.060  0.0295    99.068  289.92
  48   0.0254     99.220  0.0288    99.053  296.03
  49   0.0347     98.890  0.0301    99.027  302.17
  50   0.0430     98.590  0.0277    99.135  308.28
  51   0.0227     99.240  0.0281    99.068  314.53
  52   0.0443     98.600  0.0284    99.117  320.65
  53   0.0397     98.750  0.0274    99.122  326.79
  54   0.0301     99.020  0.0265    99.183  332.90
  55   0.0476     98.590  0.0275    99.102  339.04
  56   0.0309     98.950  0.0276    99.125  345.16
  57   0.0462     98.440  0.0268    99.127  351.37
  58   0.0395     98.680  0.0278    99.107  357.49
  59   0.0342     99.010  0.0269    99.150  363.61
  60   0.0293     99.020  0.0260    99.205  369.71
  61   0.0328     98.890  0.0268    99.168  375.84
  62   0.0322     98.990  0.0257    99.178  381.97
  63   0.0303     99.030  0.0255    99.183  388.21
  64   0.0410     98.630  0.0251    99.215  394.33
  65   0.0269     99.070  0.0259    99.142  400.45
  66   0.0321     99.000  0.0250    99.227  406.58
  67   0.0444     98.540  0.0246    99.238  412.75
  68   0.0512     98.380  0.0260    99.212  418.89
  69   0.0339     98.910  0.0238    99.223  425.15
  70   0.0291     99.120  0.0259    99.200  431.27
  71   0.0388     98.850  0.0246    99.210  437.41
  72   0.0403     98.790  0.0237    99.265  443.53
  73   0.0276     99.120  0.0244    99.202  449.66
  74   0.0307     99.040  0.0232    99.235  455.88
  75   0.0314     98.970  0.0238    99.227  462.00
  76   0.0305     99.120  0.0235    99.245  468.15
  77   0.0360     98.710  0.0243    99.243  474.27
  78   0.0297     98.980  0.0229    99.222  480.40
  79   0.0221     99.230  0.0243    99.205  486.66
  80   0.0309     98.960  0.0233    99.275  492.79
  81   0.0422     98.560  0.0237    99.230  498.92
  82   0.0322     99.040  0.0227    99.337  505.04
  83   0.0290     99.070  0.0227    99.267  511.18
  84   0.0339     99.020  0.0230    99.283  517.32
  85   0.0313     99.030  0.0232    99.238  523.53
  86   0.0381     98.780  0.0239    99.247  529.64
  87   0.0271     99.170  0.0232    99.247  535.78
  88   0.0382     98.880  0.0222    99.277  541.92
  89   0.0401     98.680  0.0223    99.300  548.09
  90   0.0291     99.120  0.0224    99.270  554.32
