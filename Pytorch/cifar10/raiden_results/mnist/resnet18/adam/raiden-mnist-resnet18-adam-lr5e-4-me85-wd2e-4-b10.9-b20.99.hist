Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1715     94.600  0.2810    90.787  7.63
   2   0.1462     95.130  0.0933    97.055  13.72
   3   0.0786     97.420  0.0768    97.605  19.91
   4   0.0716     97.680  0.0698    97.830  25.99
   5   0.1078     96.600  0.0665    97.933  32.09
   6   0.0886     97.310  0.0606    98.082  38.17
   7   0.1103     96.510  0.0597    98.125  44.26
   8   0.0690     97.800  0.0562    98.292  50.35
   9   0.0766     97.460  0.0539    98.335  56.55
  10   0.1015     96.820  0.0529    98.392  62.64
  11   0.0559     98.330  0.0482    98.488  68.72
  12   0.0376     98.840  0.0497    98.483  74.83
  13   0.0513     98.430  0.0464    98.560  80.91
  14   0.0535     98.230  0.0479    98.535  87.08
  15   0.0745     97.590  0.0444    98.627  93.17
  16   0.0477     98.520  0.0449    98.602  99.25
  17   0.0612     98.050  0.0435    98.643  105.33
  18   0.0549     98.330  0.0407    98.733  111.43
  19   0.0454     98.590  0.0398    98.755  117.53
  20   0.0390     98.650  0.0389    98.807  123.74
  21   0.0702     97.680  0.0382    98.807  129.83
  22   0.0426     98.700  0.0394    98.750  135.91
  23   0.0381     98.770  0.0370    98.838  142.01
  24   0.0464     98.450  0.0373    98.832  148.09
  25   0.0407     98.730  0.0362    98.920  154.17
  26   0.0459     98.390  0.0359    98.903  160.37
  27   0.0486     98.330  0.0353    98.908  166.46
  28   0.0351     98.910  0.0355    98.903  172.58
  29   0.0835     97.480  0.0335    98.947  178.68
  30   0.0365     98.750  0.0359    98.897  184.77
  31   0.0421     98.690  0.0331    98.957  190.86
  32   0.0315     99.140  0.0315    99.008  197.06
  33   0.0621     98.050  0.0334    98.947  203.19
  34   0.0306     99.040  0.0314    99.010  209.30
  35   0.0313     99.010  0.0322    98.985  215.43
  36   0.0335     98.790  0.0313    99.018  221.52
  37   0.0316     98.990  0.0305    99.045  227.67
  38   0.0568     98.130  0.0293    99.045  233.87
  39   0.0463     98.510  0.0300    99.040  239.96
  40   0.0445     98.550  0.0296    99.107  246.06
  41   0.0569     98.070  0.0305    99.060  252.16
  42   0.0385     98.830  0.0280    99.107  258.32
  43   0.0316     99.000  0.0278    99.128  264.50
  44   0.0329     98.950  0.0277    99.138  270.60
  45   0.0330     99.030  0.0283    99.098  276.71
  46   0.0441     98.580  0.0272    99.115  282.81
  47   0.0311     99.040  0.0268    99.198  288.91
  48   0.0433     98.540  0.0268    99.180  295.00
  49   0.0313     98.990  0.0267    99.192  301.20
  50   0.0415     98.590  0.0266    99.137  307.30
  51   0.0313     99.090  0.0258    99.222  313.44
  52   0.0368     98.850  0.0256    99.203  319.56
  53   0.0483     98.570  0.0252    99.202  325.66
  54   0.0417     98.630  0.0260    99.202  331.85
  55   0.0365     98.780  0.0247    99.248  337.96
  56   0.0345     98.960  0.0243    99.238  344.06
  57   0.0442     98.680  0.0239    99.232  350.17
  58   0.0389     98.720  0.0259    99.168  356.27
  59   0.0285     99.060  0.0238    99.247  362.36
  60   0.0347     98.910  0.0243    99.240  368.57
  61   0.0286     99.030  0.0240    99.265  374.67
  62   0.0268     99.120  0.0237    99.277  380.79
  63   0.0277     99.130  0.0237    99.260  386.91
  64   0.0307     98.990  0.0246    99.205  393.01
  65   0.0355     98.830  0.0233    99.285  399.18
  66   0.0421     98.610  0.0231    99.290  405.30
  67   0.0344     98.840  0.0230    99.277  411.45
  68   0.0344     98.910  0.0228    99.295  417.54
  69   0.0464     98.630  0.0235    99.280  423.65
  70   0.0299     99.050  0.0224    99.308  429.74
  71   0.0285     99.140  0.0231    99.297  435.95
  72   0.0485     98.430  0.0225    99.302  442.05
  73   0.0338     98.900  0.0210    99.338  448.16
  74   0.0389     98.720  0.0227    99.280  454.25
  75   0.0417     98.710  0.0219    99.318  460.37
  76   0.0417     98.830  0.0209    99.347  466.59
  77   0.0249     99.190  0.0222    99.312  472.71
  78   0.0263     99.160  0.0209    99.338  478.81
  79   0.0262     99.140  0.0231    99.275  484.91
  80   0.0316     98.960  0.0218    99.318  491.00
  81   0.0250     99.190  0.0210    99.330  497.10
  82   0.0275     99.080  0.0209    99.320  503.27
  83   0.0261     99.220  0.0204    99.365  509.37
  84   0.0352     98.880  0.0209    99.355  515.46
  85   0.0376     98.800  0.0213    99.317  521.57
