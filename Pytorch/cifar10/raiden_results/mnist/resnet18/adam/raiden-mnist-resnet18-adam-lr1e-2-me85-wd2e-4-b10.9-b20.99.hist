Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.0139     63.860  0.9919    67.350  7.57
   2   0.4184     86.320  0.2176    93.287  13.67
   3   0.1782     94.600  0.1421    95.640  19.78
   4   0.2376     92.640  0.1137    96.473  25.97
   5   1.3721     61.720  0.0996    96.925  32.07
   6   0.1228     96.260  0.0929    97.053  38.18
   7   0.1560     94.840  0.0887    97.252  44.30
   8   0.1139     96.390  0.0860    97.362  50.42
   9   0.1180     96.130  0.0823    97.533  56.54
  10   0.1148     96.020  0.0799    97.572  62.77
  11   1.1636     66.180  0.0802    97.538  68.86
  12   0.1505     95.680  0.0756    97.673  74.96
  13   0.2998     89.950  0.0802    97.550  81.06
  14   0.2513     91.810  0.0770    97.608  87.16
  15   0.2677     91.170  0.0748    97.737  93.26
  16   0.0906     97.140  0.0778    97.612  99.46
  17   0.2170     93.990  0.0758    97.670  105.58
  18   0.0797     97.540  0.0740    97.707  111.67
  19   0.1037     96.900  0.0743    97.685  117.79
  20   0.2734     91.050  0.0745    97.735  123.88
  21   0.3081     90.750  0.0736    97.708  129.98
  22   0.1035     96.370  0.0731    97.793  136.17
  23   0.0930     96.980  0.0730    97.733  142.28
  24   0.0719     97.770  0.0734    97.735  148.43
  25   0.1470     95.600  0.0721    97.710  154.56
  26   0.4724     85.860  0.0712    97.832  160.67
  27   0.0698     97.780  0.0739    97.655  166.86
  28   0.1248     95.990  0.0696    97.860  172.98
  29   0.2376     92.890  0.0708    97.847  179.06
  30   0.2183     92.880  0.0715    97.828  185.16
  31   0.6475     83.510  0.0728    97.732  191.24
  32   0.1517     95.310  0.0732    97.735  197.46
  33   0.5669     84.730  0.0731    97.718  203.59
  34   0.0690     97.910  0.0719    97.782  209.75
  35   0.2190     92.920  0.0728    97.758  215.86
  36   0.2575     91.960  0.0715    97.790  221.96
  37   0.0612     98.060  0.0719    97.792  228.08
  38   0.0796     97.540  0.0733    97.777  234.27
  39   0.5072     84.290  0.0701    97.843  240.38
  40   0.0890     97.000  0.0698    97.850  246.48
  41   0.1627     95.260  0.0697    97.815  252.60
  42   0.1564     95.030  0.0723    97.782  258.71
  43   0.3247     90.100  0.0712    97.838  264.95
  44   0.1222     95.810  0.0700    97.865  271.07
  45   0.0832     97.330  0.0700    97.805  277.19
  46   3.1745     40.880  0.0712    97.827  283.33
  47   0.1574     95.090  0.0705    97.798  289.45
  48   0.1534     95.200  0.0722    97.793  295.56
  49   0.0870     97.260  0.0713    97.755  301.75
  50   0.2192     92.810  0.0693    97.823  307.86
  51   0.1888     93.900  0.0678    97.830  313.98
  52   0.5288     84.080  0.0712    97.720  320.09
  53   0.1396     95.550  0.0696    97.888  326.18
  54   0.2065     93.700  0.0706    97.755  332.26
  55   0.1053     96.640  0.0723    97.712  338.47
  56   0.1431     95.300  0.0693    97.792  344.58
  57   0.1365     95.880  0.0686    97.853  350.67
  58   0.2062     93.730  0.0705    97.803  356.78
  59   0.0832     97.290  0.0696    97.885  362.89
  60   0.0829     97.430  0.0699    97.830  368.99
  61   0.0831     97.360  0.0706    97.812  375.21
  62   0.1365     95.740  0.0687    97.863  381.32
  63   0.2100     93.100  0.0687    97.887  387.43
  64   0.1815     94.170  0.0694    97.877  393.55
  65   0.1180     96.550  0.0701    97.812  399.69
  66   0.0966     96.950  0.0711    97.785  405.85
  67   0.2162     93.690  0.0703    97.820  411.93
  68   0.1566     95.170  0.0698    97.888  418.05
  69   0.0919     97.150  0.0700    97.813  424.15
  70   0.1278     95.790  0.0706    97.823  430.25
  71   0.1084     96.370  0.0708    97.888  436.37
  72   0.0836     97.140  0.0708    97.812  442.57
  73   0.0883     97.210  0.0687    97.885  448.68
  74   0.2441     92.740  0.0725    97.745  454.80
  75   0.1742     94.380  0.0695    97.863  460.96
  76   0.1299     95.720  0.0725    97.793  467.07
  77   0.1880     94.340  0.0718    97.763  473.26
  78   0.0609     98.060  0.0690    97.802  479.35
  79   0.1102     96.560  0.0691    97.885  485.47
  80   0.1231     95.930  0.0689    97.793  491.62
  81   0.4676     86.330  0.0675    97.895  497.73
  82   0.1818     94.330  0.0690    97.878  503.83
  83   0.2638     92.250  0.0697    97.817  510.04
  84   0.1374     95.380  0.0716    97.808  516.16
  85   0.1374     95.750  0.0701    97.788  522.26
