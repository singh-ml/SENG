Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.6092     78.720  1.2966    56.212  7.51
   2   0.2154     93.100  0.2187    93.192  13.66
   3   0.1375     95.510  0.1406    95.625  19.71
   4   0.1127     96.230  0.1191    96.350  25.79
   5   0.1857     94.050  0.1050    96.780  31.89
   6   0.0713     97.740  0.1011    96.853  37.95
   7   0.1347     95.620  0.0924    97.187  44.01
   8   0.1311     95.670  0.0954    97.135  50.15
   9   0.0696     97.740  0.0922    97.203  56.23
  10   0.1096     96.510  0.0894    97.265  62.31
  11   0.0878     96.910  0.0862    97.393  68.38
  12   0.0928     96.950  0.0843    97.453  74.47
  13   0.1064     96.830  0.0857    97.337  80.53
  14   0.0756     97.630  0.0807    97.553  86.72
  15   0.1297     95.990  0.0806    97.623  92.82
  16   0.0901     97.210  0.0801    97.552  98.90
  17   0.0783     97.660  0.0806    97.517  104.98
  18   0.0876     97.030  0.0802    97.588  111.07
  19   0.1455     95.370  0.0801    97.547  117.22
  20   0.0783     97.520  0.0783    97.550  123.29
  21   0.1458     95.660  0.0800    97.560  129.36
  22   0.0787     97.420  0.0795    97.542  135.47
  23   0.1175     96.230  0.0760    97.653  141.55
  24   0.1102     96.640  0.0807    97.592  147.63
  25   0.0804     97.490  0.0750    97.745  153.78
  26   0.1164     96.170  0.0754    97.707  159.84
  27   0.0954     96.760  0.0779    97.613  165.93
  28   0.0751     97.480  0.0772    97.637  172.01
  29   0.1838     94.620  0.0799    97.557  178.09
  30   0.0766     97.640  0.0767    97.663  184.20
  31   0.0879     97.080  0.0743    97.783  190.27
  32   0.1327     95.890  0.0764    97.583  196.34
  33   0.0762     97.540  0.0745    97.738  202.42
  34   0.0742     97.630  0.0763    97.732  208.50
  35   0.0744     97.610  0.0761    97.668  214.57
  36   0.0525     98.420  0.0758    97.670  220.74
  37   0.1209     96.110  0.0732    97.785  226.79
  38   0.0786     97.450  0.0763    97.698  232.87
  39   0.1344     95.720  0.0766    97.680  238.93
  40   0.1339     95.820  0.0745    97.710  244.99
  41   0.1001     96.880  0.0731    97.800  251.14
  42   0.1066     96.850  0.0766    97.698  257.21
  43   0.0842     97.250  0.0754    97.665  263.28
  44   0.0743     97.690  0.0762    97.732  269.34
  45   0.0673     97.890  0.0738    97.745  275.40
  46   0.0640     97.960  0.0752    97.642  281.49
  47   0.0680     97.930  0.0710    97.872  287.56
  48   0.1204     96.220  0.0755    97.717  293.64
  49   0.0780     97.500  0.0753    97.668  299.73
  50   0.0675     97.820  0.0729    97.760  305.84
  51   0.0977     96.970  0.0779    97.602  311.93
  52   0.0749     97.620  0.0758    97.703  318.00
  53   0.1093     96.520  0.0726    97.805  324.15
  54   0.0907     97.320  0.0729    97.792  330.24
  55   0.1908     94.160  0.0740    97.787  336.30
  56   0.0772     97.720  0.0755    97.685  342.42
  57   0.1031     96.990  0.0728    97.782  348.49
  58   0.0744     97.700  0.0741    97.755  354.55
  59   0.0910     97.290  0.0731    97.715  360.76
  60   0.0729     97.500  0.0753    97.712  366.85
  61   0.0896     96.890  0.0743    97.707  372.93
  62   0.0962     97.050  0.0718    97.897  379.00
  63   0.1043     96.820  0.0715    97.850  385.07
  64   0.0892     97.250  0.0719    97.808  391.11
  65   0.1336     95.670  0.0746    97.687  397.26
  66   0.1243     96.010  0.0750    97.693  403.32
  67   0.0950     96.790  0.0716    97.787  409.38
  68   0.0861     97.250  0.0731    97.825  415.45
  69   0.0692     97.720  0.0732    97.745  421.53
  70   0.0872     97.200  0.0737    97.742  427.61
  71   0.0963     96.920  0.0718    97.828  433.83
  72   0.0844     97.200  0.0720    97.800  439.90
  73   0.0790     97.560  0.0719    97.828  445.96
  74   0.0657     97.880  0.0705    97.850  452.05
  75   0.1023     97.010  0.0715    97.815  458.11
  76   0.1309     95.910  0.0740    97.755  464.20
  77   0.0771     97.340  0.0724    97.780  470.37
  78   0.0653     97.960  0.0737    97.755  476.41
  79   0.0977     96.870  0.0703    97.858  482.49
  80   0.0708     97.700  0.0732    97.693  488.59
  81   0.0624     98.080  0.0730    97.732  494.66
  82   0.0950     97.030  0.0737    97.715  500.82
  83   0.0739     97.650  0.0719    97.783  506.89
  84   0.1380     95.600  0.0729    97.845  512.96
  85   0.0954     96.870  0.0713    97.862  519.04
