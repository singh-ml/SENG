Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1973     93.640  0.6639    78.165  7.73
   2   0.1007     96.630  0.1471    95.320  13.84
   3   0.0755     97.510  0.0883    97.255  19.93
   4   0.0640     97.830  0.0685    97.838  26.02
   5   0.0546     98.090  0.0617    98.055  32.13
   6   0.0483     98.360  0.0547    98.282  38.31
   7   0.0453     98.320  0.0479    98.522  44.46
   8   0.0452     98.510  0.0454    98.558  50.59
   9   0.0456     98.570  0.0483    98.447  56.68
  10   0.0401     98.680  0.0429    98.687  62.79
  11   0.0369     98.830  0.0409    98.730  69.01
  12   0.0400     98.670  0.0381    98.808  75.10
  13   0.0395     98.670  0.0373    98.828  81.24
  14   0.0366     98.760  0.0394    98.773  87.35
  15   0.0391     98.700  0.0353    98.897  93.44
  16   0.0347     98.860  0.0363    98.852  99.55
  17   0.0358     98.720  0.0379    98.827  105.75
  18   0.0349     98.930  0.0385    98.772  111.84
  19   0.0488     98.280  0.0350    98.912  117.95
  20   0.0291     99.060  0.0318    99.057  124.05
  21   0.0426     98.660  0.0333    98.953  130.16
  22   0.0327     99.010  0.0332    98.940  136.28
  23   0.0531     98.410  0.0310    99.033  142.49
  24   0.0443     98.500  0.0310    99.067  148.60
  25   0.0373     98.720  0.0282    99.113  154.71
  26   0.0376     98.760  0.0270    99.152  160.80
  27   0.0526     98.270  0.0285    99.125  166.90
  28   0.0395     98.650  0.0318    98.970  173.02
  29   0.0340     98.810  0.0294    99.045  179.23
  30   0.0400     98.740  0.0290    99.110  185.36
  31   0.0352     98.840  0.0269    99.140  191.48
  32   0.0456     98.570  0.0290    99.077  197.60
  33   0.0280     99.070  0.0266    99.177  203.69
  34   0.0439     98.540  0.0253    99.220  209.81
  35   0.0334     98.980  0.0282    99.123  216.01
  36   0.0342     98.960  0.0261    99.198  222.11
  37   0.0376     98.750  0.0236    99.265  228.20
  38   0.0351     98.860  0.0262    99.193  234.30
  39   0.0339     98.860  0.0284    99.123  240.42
  40   0.0295     99.020  0.0253    99.223  246.56
  41   0.0375     98.850  0.0252    99.218  252.76
  42   0.0314     99.010  0.0245    99.268  258.86
  43   0.0331     98.970  0.0228    99.310  264.97
  44   0.0271     99.100  0.0251    99.218  271.04
  45   0.0268     99.150  0.0227    99.363  277.16
  46   0.0459     98.600  0.0258    99.247  283.40
  47   0.0253     99.210  0.0247    99.277  289.50
  48   0.0282     99.040  0.0226    99.347  295.61
  49   0.0270     99.190  0.0226    99.332  301.69
  50   0.0370     98.800  0.0234    99.293  307.79
  51   0.0432     98.670  0.0229    99.352  313.98
  52   0.0316     99.020  0.0243    99.258  320.08
  53   0.0270     99.150  0.0230    99.300  326.19
  54   0.0367     98.790  0.0223    99.352  332.30
  55   0.0289     99.110  0.0248    99.260  338.44
  56   0.0260     99.190  0.0223    99.338  344.61
  57   0.0304     99.040  0.0208    99.373  350.83
  58   0.0304     99.010  0.0219    99.313  356.96
  59   0.0236     99.190  0.0212    99.375  363.07
  60   0.0347     98.900  0.0193    99.430  369.18
  61   0.0388     98.760  0.0215    99.352  375.28
  62   0.0307     99.030  0.0216    99.375  381.38
  63   0.0428     98.670  0.0205    99.362  387.57
  64   0.0292     99.120  0.0207    99.403  393.68
  65   0.0339     98.980  0.0208    99.378  399.79
  66   0.0290     99.160  0.0207    99.392  405.90
  67   0.0305     98.990  0.0224    99.360  412.00
  68   0.0452     98.490  0.0214    99.397  418.18
  69   0.0285     99.020  0.0193    99.448  424.29
  70   0.0304     98.980  0.0175    99.522  430.40
  71   0.0307     99.000  0.0189    99.418  436.51
  72   0.0301     99.040  0.0190    99.423  442.61
  73   0.0314     99.020  0.0187    99.455  448.72
  74   0.0359     98.840  0.0195    99.453  454.92
  75   0.0257     99.230  0.0193    99.418  461.01
  76   0.0283     98.990  0.0188    99.445  467.12
  77   0.0347     99.060  0.0163    99.500  473.21
  78   0.0352     98.900  0.0184    99.440  479.30
  79   0.0462     98.620  0.0188    99.443  485.42
  80   0.0305     99.070  0.0175    99.482  491.61
  81   0.0362     98.850  0.0190    99.440  497.69
  82   0.0379     98.840  0.0176    99.477  503.79
  83   0.0339     98.980  0.0160    99.527  509.92
  84   0.0317     99.060  0.0165    99.523  516.06
  85   0.0313     99.020  0.0164    99.515  522.19
  86   0.0248     99.110  0.0164    99.492  528.41
  87   0.0255     99.260  0.0175    99.512  534.52
  88   0.0365     98.780  0.0170    99.493  540.61
  89   0.0284     99.180  0.0162    99.510  546.72
  90   0.0245     99.220  0.0174    99.487  552.82
