Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1240     96.070  0.3344    88.962  7.71
   2   0.0983     96.940  0.1008    96.832  13.76
   3   0.1525     95.260  0.0851    97.393  19.82
   4   0.0717     97.620  0.0735    97.657  25.86
   5   0.0600     98.100  0.0633    98.027  31.92
   6   0.0924     97.140  0.0671    97.853  37.97
   7   0.0528     98.270  0.0591    98.132  44.12
   8   0.0569     98.030  0.0555    98.282  50.17
   9   0.0618     98.110  0.0544    98.310  56.25
  10   0.0458     98.440  0.0544    98.350  62.31
  11   0.0521     98.360  0.0528    98.393  68.37
  12   0.0467     98.450  0.0470    98.515  74.39
  13   0.0400     98.800  0.0465    98.588  80.54
  14   0.0408     98.860  0.0456    98.563  86.60
  15   0.0362     98.800  0.0444    98.603  92.66
  16   0.0357     98.810  0.0442    98.680  98.70
  17   0.0439     98.610  0.0415    98.705  104.74
  18   0.0465     98.510  0.0413    98.703  110.83
  19   0.0313     98.990  0.0396    98.745  116.91
  20   0.0435     98.730  0.0368    98.843  122.98
  21   0.0242     99.230  0.0382    98.837  129.03
  22   0.0335     98.870  0.0388    98.785  135.08
  23   0.0450     98.570  0.0379    98.842  141.13
  24   0.0308     99.090  0.0363    98.888  147.25
  25   0.0354     98.920  0.0351    98.893  153.31
  26   0.0509     98.450  0.0335    98.948  159.38
  27   0.0331     98.950  0.0345    98.893  165.42
  28   0.0375     98.770  0.0362    98.848  171.48
  29   0.0405     98.660  0.0324    99.005  177.52
  30   0.0339     98.790  0.0336    98.947  183.68
  31   0.0321     98.930  0.0333    98.947  189.72
  32   0.0345     98.830  0.0317    99.012  195.79
  33   0.0355     98.910  0.0303    99.062  201.84
  34   0.0375     98.750  0.0303    99.062  207.89
  35   0.0360     98.900  0.0314    99.035  214.02
  36   0.0287     99.120  0.0308    99.093  220.04
  37   0.0427     98.700  0.0293    99.098  226.09
  38   0.0333     98.830  0.0298    99.055  232.14
  39   0.0330     98.890  0.0305    99.085  238.18
  40   0.0364     98.800  0.0312    99.087  244.22
  41   0.0289     99.050  0.0285    99.133  250.34
  42   0.0262     99.120  0.0294    99.063  256.38
  43   0.0284     99.090  0.0254    99.168  262.44
  44   0.0322     98.830  0.0259    99.188  268.51
  45   0.0287     98.980  0.0275    99.163  274.55
  46   0.0314     99.040  0.0262    99.177  280.70
  47   0.0371     98.850  0.0279    99.135  286.78
  48   0.0321     98.940  0.0264    99.187  292.83
  49   0.0300     99.050  0.0258    99.183  298.87
  50   0.0308     99.140  0.0236    99.223  304.94
  51   0.0395     98.660  0.0244    99.248  310.98
  52   0.0345     99.040  0.0260    99.193  317.14
  53   0.0284     99.100  0.0237    99.283  323.18
  54   0.0299     98.990  0.0241    99.267  329.25
  55   0.0388     98.790  0.0243    99.260  335.30
  56   0.0239     99.280  0.0244    99.222  341.36
  57   0.0341     98.990  0.0227    99.253  347.40
  58   0.0353     98.900  0.0224    99.308  353.54
  59   0.0309     99.070  0.0229    99.295  359.59
  60   0.0290     99.090  0.0225    99.290  365.65
  61   0.0294     99.070  0.0231    99.262  371.70
  62   0.0344     98.860  0.0228    99.305  377.78
  63   0.0392     98.840  0.0224    99.265  383.82
  64   0.0355     98.880  0.0230    99.247  390.05
  65   0.0261     99.110  0.0241    99.220  396.12
  66   0.0360     98.850  0.0232    99.302  402.17
  67   0.0352     98.960  0.0227    99.265  408.21
  68   0.0304     99.040  0.0222    99.285  414.26
  69   0.0401     98.780  0.0225    99.305  420.32
  70   0.0313     98.970  0.0222    99.312  426.46
  71   0.0345     98.780  0.0212    99.355  432.52
  72   0.0265     99.180  0.0223    99.273  438.57
  73   0.0258     99.160  0.0204    99.312  444.63
  74   0.0374     98.760  0.0218    99.288  450.68
  75   0.0357     98.780  0.0202    99.370  456.73
  76   0.0317     99.070  0.0206    99.355  462.90
  77   0.0422     98.690  0.0216    99.300  468.95
  78   0.0333     98.900  0.0201    99.397  474.99
  79   0.0339     98.960  0.0214    99.325  481.05
  80   0.0228     99.220  0.0199    99.357  487.09
  81   0.0327     98.830  0.0184    99.422  493.16
  82   0.0277     99.160  0.0199    99.383  499.28
  83   0.0436     98.620  0.0210    99.355  505.31
  84   0.0315     99.000  0.0219    99.317  511.36
  85   0.0334     98.870  0.0189    99.398  517.41
  86   0.0301     98.980  0.0185    99.392  523.42
  87   0.0323     99.040  0.0191    99.393  529.46
  88   0.0296     99.010  0.0203    99.372  535.61
  89   0.0310     98.920  0.0173    99.477  541.65
  90   0.0381     98.780  0.0194    99.383  547.70
