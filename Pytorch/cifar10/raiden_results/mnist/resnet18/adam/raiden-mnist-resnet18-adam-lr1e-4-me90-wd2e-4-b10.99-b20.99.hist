Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1832     93.840  0.6282    79.503  7.58
   2   0.0908     96.910  0.1388    95.558  13.67
   3   0.0829     97.160  0.0836    97.357  19.74
   4   0.0647     98.040  0.0673    97.910  25.81
   5   0.0511     98.350  0.0574    98.132  31.87
   6   0.0503     98.320  0.0538    98.322  37.94
   7   0.0585     98.090  0.0485    98.473  44.08
   8   0.0429     98.380  0.0453    98.590  50.16
   9   0.0469     98.360  0.0413    98.705  56.28
  10   0.0482     98.510  0.0417    98.680  62.36
  11   0.0451     98.640  0.0405    98.757  68.43
  12   0.0472     98.400  0.0375    98.770  74.61
  13   0.0485     98.410  0.0367    98.848  80.66
  14   0.0380     98.740  0.0366    98.843  86.74
  15   0.0379     98.790  0.0349    98.868  92.83
  16   0.0405     98.750  0.0331    98.948  98.90
  17   0.0331     98.910  0.0324    98.977  104.97
  18   0.0347     98.800  0.0301    99.005  111.17
  19   0.0479     98.510  0.0312    99.012  117.25
  20   0.0349     98.830  0.0300    99.050  123.37
  21   0.0361     98.940  0.0294    99.053  129.45
  22   0.0255     99.110  0.0292    99.097  135.52
  23   0.0391     98.600  0.0296    99.042  141.61
  24   0.0346     98.770  0.0269    99.130  147.77
  25   0.0321     98.860  0.0272    99.130  153.83
  26   0.0325     98.950  0.0285    99.097  159.91
  27   0.0339     98.920  0.0275    99.123  165.99
  28   0.0294     99.130  0.0269    99.110  172.05
  29   0.0361     98.820  0.0261    99.173  178.14
  30   0.0300     99.080  0.0262    99.173  184.32
  31   0.0410     98.690  0.0213    99.345  190.40
  32   0.0354     98.840  0.0234    99.258  196.50
  33   0.0320     98.940  0.0242    99.220  202.55
  34   0.0255     99.210  0.0218    99.327  208.61
  35   0.0328     98.980  0.0245    99.205  214.70
  36   0.0286     99.050  0.0217    99.315  220.86
  37   0.0392     98.650  0.0220    99.272  226.95
  38   0.0294     99.000  0.0215    99.323  233.04
  39   0.0315     98.950  0.0229    99.228  239.11
  40   0.0260     99.180  0.0230    99.278  245.17
  41   0.0224     99.260  0.0212    99.343  251.24
  42   0.0285     99.180  0.0202    99.350  257.38
  43   0.0388     98.820  0.0218    99.307  263.44
  44   0.0388     98.820  0.0210    99.320  269.51
  45   0.0279     99.140  0.0193    99.368  275.57
  46   0.0306     99.020  0.0199    99.333  281.66
  47   0.0261     99.130  0.0190    99.403  287.78
  48   0.0283     99.060  0.0203    99.333  293.84
  49   0.0299     98.990  0.0194    99.392  299.92
  50   0.0355     98.970  0.0204    99.402  305.99
  51   0.0386     98.700  0.0186    99.428  312.03
  52   0.0343     98.830  0.0172    99.457  318.09
  53   0.0279     99.160  0.0173    99.450  324.27
  54   0.0307     99.030  0.0186    99.400  330.35
  55   0.0310     99.080  0.0167    99.468  336.42
  56   0.0360     98.890  0.0179    99.415  342.49
  57   0.0220     99.220  0.0182    99.457  348.54
  58   0.0375     98.860  0.0162    99.483  354.69
  59   0.0258     99.190  0.0181    99.423  360.79
  60   0.0308     99.130  0.0174    99.442  366.89
  61   0.0298     98.990  0.0169    99.467  372.99
  62   0.0315     98.980  0.0173    99.460  379.06
  63   0.0250     99.180  0.0188    99.390  385.15
  64   0.0286     99.070  0.0164    99.478  391.39
  65   0.0364     98.890  0.0157    99.502  397.53
  66   0.0240     99.150  0.0176    99.473  403.62
  67   0.0267     99.130  0.0158    99.483  409.70
  68   0.0334     98.980  0.0154    99.503  415.79
  69   0.0257     99.110  0.0156    99.492  421.96
  70   0.0258     99.100  0.0153    99.537  428.03
  71   0.0318     98.950  0.0141    99.545  434.09
  72   0.0278     99.080  0.0154    99.517  440.16
  73   0.0385     98.780  0.0153    99.515  446.22
  74   0.0254     99.170  0.0160    99.492  452.32
  75   0.0325     98.910  0.0153    99.498  458.49
  76   0.0293     99.020  0.0161    99.503  464.58
  77   0.0390     98.720  0.0138    99.572  470.66
  78   0.0348     98.820  0.0137    99.552  476.74
  79   0.0257     99.190  0.0137    99.585  482.83
  80   0.0342     98.920  0.0151    99.522  489.00
  81   0.0341     98.940  0.0127    99.575  495.08
  82   0.0298     99.120  0.0140    99.552  501.15
  83   0.0340     99.020  0.0141    99.582  507.22
  84   0.0302     99.080  0.0137    99.542  513.30
  85   0.0253     99.140  0.0134    99.578  519.36
  86   0.0362     98.850  0.0124    99.597  525.50
  87   0.0317     99.120  0.0134    99.595  531.58
  88   0.0393     98.690  0.0129    99.610  537.64
  89   0.0272     99.110  0.0126    99.607  543.72
  90   0.0265     99.180  0.0133    99.572  549.80
