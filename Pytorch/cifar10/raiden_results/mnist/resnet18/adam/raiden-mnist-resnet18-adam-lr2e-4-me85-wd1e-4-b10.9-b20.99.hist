Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1568     94.990  0.3539    88.388  7.70
   2   0.1545     94.920  0.0892    97.227  13.90
   3   0.0870     97.280  0.0710    97.765  20.00
   4   0.0948     96.850  0.0591    98.153  26.10
   5   0.0396     98.710  0.0528    98.350  32.24
   6   0.0337     98.800  0.0495    98.450  38.34
   7   0.0612     97.990  0.0471    98.530  44.48
   8   0.0396     98.930  0.0450    98.537  50.73
   9   0.0775     97.820  0.0428    98.663  56.85
  10   0.0514     98.280  0.0395    98.773  62.99
  11   0.0713     97.740  0.0398    98.763  69.09
  12   0.0479     98.370  0.0372    98.788  75.18
  13   0.0590     98.120  0.0370    98.818  81.39
  14   0.0577     98.210  0.0347    98.883  87.49
  15   0.0772     97.630  0.0332    98.920  93.60
  16   0.0550     98.250  0.0346    98.923  99.71
  17   0.0458     98.560  0.0327    98.970  105.82
  18   0.0634     98.080  0.0308    99.012  111.92
  19   0.0360     98.680  0.0307    99.053  118.12
  20   0.0371     98.720  0.0307    99.032  124.23
  21   0.0419     98.660  0.0290    99.105  130.34
  22   0.0422     98.630  0.0283    99.093  136.43
  23   0.0298     98.990  0.0300    99.047  142.61
  24   0.0308     98.990  0.0284    99.120  148.80
  25   0.0520     98.350  0.0268    99.137  154.92
  26   0.0364     98.810  0.0261    99.190  161.02
  27   0.0468     98.560  0.0272    99.152  167.13
  28   0.0271     99.070  0.0266    99.122  173.24
  29   0.0429     98.660  0.0261    99.168  179.35
  30   0.0309     98.980  0.0269    99.148  185.46
  31   0.0358     98.960  0.0250    99.185  191.65
  32   0.0513     98.320  0.0254    99.182  197.77
  33   0.0339     98.870  0.0237    99.275  203.88
  34   0.0319     99.010  0.0246    99.210  209.97
  35   0.0405     98.690  0.0227    99.263  216.13
  36   0.0515     98.350  0.0239    99.228  222.36
  37   0.0284     98.980  0.0233    99.222  228.46
  38   0.0445     98.610  0.0233    99.267  234.57
  39   0.0492     98.450  0.0214    99.327  240.69
  40   0.0427     98.820  0.0215    99.315  246.81
  41   0.0376     98.810  0.0226    99.243  252.93
  42   0.0353     98.800  0.0224    99.295  259.06
  43   0.0321     99.000  0.0220    99.337  265.33
  44   0.0345     98.940  0.0210    99.342  271.46
  45   0.0457     98.660  0.0201    99.323  277.62
  46   0.0281     99.150  0.0209    99.297  283.74
  47   0.0398     98.700  0.0205    99.342  289.85
  48   0.0370     98.920  0.0210    99.302  296.05
  49   0.0263     99.150  0.0198    99.365  302.17
  50   0.0294     99.070  0.0200    99.357  308.26
  51   0.0269     99.130  0.0200    99.352  314.40
  52   0.0322     98.870  0.0190    99.357  320.49
  53   0.0294     99.070  0.0199    99.345  326.58
  54   0.0257     99.170  0.0178    99.427  332.81
  55   0.0368     98.860  0.0188    99.400  338.93
  56   0.0395     98.820  0.0179    99.418  345.05
  57   0.0289     99.150  0.0184    99.398  351.17
  58   0.0243     99.200  0.0176    99.432  357.28
  59   0.0564     98.250  0.0181    99.425  363.48
  60   0.0313     98.920  0.0187    99.408  369.58
  61   0.0347     98.880  0.0184    99.378  375.70
  62   0.0562     98.190  0.0175    99.440  381.80
  63   0.0331     98.970  0.0181    99.427  387.91
  64   0.0382     98.850  0.0155    99.488  394.04
  65   0.0328     98.950  0.0174    99.423  400.25
  66   0.0269     99.040  0.0154    99.493  406.36
  67   0.0331     98.980  0.0171    99.428  412.48
  68   0.0283     99.100  0.0157    99.488  418.62
  69   0.0544     98.250  0.0169    99.440  424.73
  70   0.0424     98.650  0.0166    99.457  430.84
  71   0.0421     98.680  0.0158    99.478  437.07
  72   0.0545     98.390  0.0157    99.523  443.18
  73   0.0346     98.910  0.0166    99.447  449.34
  74   0.0332     98.980  0.0153    99.482  455.48
  75   0.0445     98.680  0.0156    99.513  461.58
  76   0.0304     98.980  0.0153    99.498  467.76
  77   0.0375     98.810  0.0133    99.578  473.91
  78   0.0351     98.880  0.0148    99.487  480.03
  79   0.0318     99.080  0.0131    99.558  486.15
  80   0.0277     99.110  0.0148    99.513  492.28
  81   0.0253     99.210  0.0159    99.487  498.41
  82   0.0232     99.230  0.0146    99.518  504.61
  83   0.0387     98.800  0.0142    99.525  510.73
  84   0.0226     99.190  0.0141    99.578  516.84
  85   0.0269     99.100  0.0141    99.545  522.96
