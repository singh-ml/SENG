Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1084     96.370  0.3579    88.498  7.71
   2   0.1034     96.640  0.0910    97.162  13.86
   3   0.0913     96.990  0.0701    97.890  19.96
   4   0.0976     96.820  0.0625    98.022  26.07
   5   0.0716     97.540  0.0574    98.173  32.28
   6   0.0646     97.880  0.0527    98.357  38.40
   7   0.0613     98.000  0.0483    98.497  44.55
   8   0.0535     98.240  0.0457    98.558  50.65
   9   0.0766     97.770  0.0449    98.588  56.77
  10   0.0566     98.440  0.0439    98.605  62.87
  11   0.0424     98.710  0.0404    98.763  69.08
  12   0.0543     98.120  0.0420    98.657  75.20
  13   0.0573     98.050  0.0390    98.748  81.33
  14   0.0521     98.400  0.0375    98.783  87.44
  15   0.0469     98.570  0.0376    98.843  93.55
  16   0.0386     98.740  0.0369    98.810  99.66
  17   0.0399     98.690  0.0338    98.952  105.92
  18   0.0449     98.520  0.0343    98.960  112.05
  19   0.0475     98.400  0.0335    98.928  118.18
  20   0.0407     98.740  0.0334    98.923  124.31
  21   0.0628     98.060  0.0328    98.977  130.43
  22   0.0521     98.410  0.0308    99.032  136.54
  23   0.0319     98.950  0.0309    99.032  142.73
  24   0.0409     98.640  0.0312    98.998  148.85
  25   0.0319     98.940  0.0309    99.032  154.97
  26   0.0306     99.020  0.0301    99.057  161.10
  27   0.0333     98.940  0.0283    99.095  167.22
  28   0.0400     98.690  0.0295    99.100  173.44
  29   0.0485     98.430  0.0287    99.088  179.55
  30   0.0303     98.940  0.0278    99.130  185.68
  31   0.0354     98.950  0.0267    99.138  191.80
  32   0.0357     98.850  0.0279    99.140  197.91
  33   0.0349     98.820  0.0271    99.165  204.03
  34   0.0373     98.720  0.0274    99.143  210.16
  35   0.0362     98.940  0.0268    99.193  216.27
  36   0.0467     98.480  0.0254    99.267  222.41
  37   0.0305     98.960  0.0259    99.227  228.53
  38   0.0377     98.780  0.0250    99.210  234.64
  39   0.0457     98.560  0.0262    99.158  240.85
  40   0.0439     98.570  0.0247    99.192  246.95
  41   0.0607     98.080  0.0242    99.235  253.12
  42   0.0370     98.850  0.0259    99.178  259.24
  43   0.0285     99.140  0.0246    99.218  265.35
  44   0.0276     99.060  0.0247    99.210  271.59
  45   0.0399     98.680  0.0225    99.305  277.74
  46   0.0475     98.410  0.0234    99.267  283.88
  47   0.0338     98.970  0.0222    99.297  290.00
  48   0.0447     98.570  0.0232    99.275  296.11
  49   0.0351     98.990  0.0227    99.288  302.22
  50   0.0313     98.870  0.0227    99.333  308.46
  51   0.0352     99.000  0.0218    99.330  314.58
  52   0.0387     98.720  0.0221    99.295  320.70
  53   0.0359     98.840  0.0217    99.300  326.82
  54   0.0459     98.620  0.0204    99.383  332.94
  55   0.0368     98.810  0.0207    99.342  339.15
  56   0.0306     98.990  0.0198    99.382  345.26
  57   0.0284     99.090  0.0200    99.358  351.38
  58   0.0213     99.230  0.0209    99.367  357.48
  59   0.0360     98.920  0.0208    99.323  363.60
  60   0.0333     98.810  0.0204    99.367  369.71
  61   0.0398     98.790  0.0211    99.345  375.93
  62   0.0274     99.100  0.0196    99.367  382.06
  63   0.0434     98.670  0.0187    99.412  388.19
  64   0.0287     99.180  0.0196    99.365  394.32
  65   0.0403     98.590  0.0191    99.380  400.44
  66   0.0406     98.780  0.0197    99.373  406.56
  67   0.0310     99.100  0.0186    99.390  412.78
  68   0.0411     98.770  0.0194    99.383  418.91
  69   0.0369     98.880  0.0189    99.443  425.03
  70   0.0308     99.040  0.0185    99.417  431.15
  71   0.0191     99.390  0.0191    99.393  437.30
  72   0.0453     98.690  0.0172    99.500  443.49
  73   0.0476     98.610  0.0176    99.428  449.59
  74   0.0260     99.200  0.0180    99.427  455.72
  75   0.0299     98.930  0.0179    99.437  461.86
  76   0.0396     98.850  0.0173    99.452  467.96
  77   0.0287     99.050  0.0174    99.467  474.06
  78   0.0313     99.070  0.0175    99.433  480.21
  79   0.0368     98.930  0.0169    99.467  486.41
  80   0.0347     98.940  0.0169    99.488  492.52
  81   0.0275     99.090  0.0175    99.432  498.64
  82   0.0301     99.040  0.0169    99.475  504.78
  83   0.0346     99.040  0.0164    99.482  510.89
  84   0.0246     99.160  0.0162    99.487  517.02
  85   0.0288     99.060  0.0173    99.458  523.22
  86   0.0349     98.880  0.0152    99.532  529.34
  87   0.0295     99.130  0.0159    99.523  535.47
  88   0.0369     98.900  0.0163    99.472  541.58
  89   0.0296     99.050  0.0157    99.548  547.71
  90   0.0360     98.900  0.0165    99.480  553.93
