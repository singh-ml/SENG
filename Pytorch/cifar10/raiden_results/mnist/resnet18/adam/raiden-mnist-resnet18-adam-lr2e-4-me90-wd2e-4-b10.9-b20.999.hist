Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1894     93.990  0.3669    87.947  7.70
   2   0.1576     94.820  0.0936    97.020  13.79
   3   0.0973     96.830  0.0690    97.850  19.95
   4   0.0532     98.220  0.0593    98.213  26.05
   5   0.1365     95.310  0.0545    98.262  32.14
   6   0.0607     97.970  0.0492    98.462  38.23
   7   0.0552     98.270  0.0482    98.480  44.29
   8   0.0459     98.510  0.0445    98.575  50.37
   9   0.0772     97.280  0.0438    98.677  56.44
  10   0.0495     98.230  0.0423    98.693  62.66
  11   0.0554     98.070  0.0410    98.738  68.74
  12   0.0532     98.180  0.0410    98.700  74.82
  13   0.0458     98.500  0.0373    98.865  80.89
  14   0.0625     97.910  0.0366    98.808  86.98
  15   0.0626     97.910  0.0377    98.772  93.16
  16   0.0416     98.670  0.0358    98.832  99.22
  17   0.0602     98.030  0.0358    98.867  105.34
  18   0.0372     98.820  0.0356    98.877  111.42
  19   0.0492     98.570  0.0348    98.890  117.49
  20   0.0526     98.240  0.0336    98.942  123.55
  21   0.0510     98.460  0.0328    98.978  129.74
  22   0.0378     98.870  0.0314    98.983  135.84
  23   0.0475     98.380  0.0329    98.983  141.94
  24   0.0568     98.250  0.0325    98.983  148.02
  25   0.0403     98.780  0.0320    98.963  154.09
  26   0.0622     98.070  0.0318    99.022  160.18
  27   0.0370     98.800  0.0300    99.093  166.36
  28   0.0364     99.020  0.0301    99.060  172.44
  29   0.0456     98.570  0.0308    99.008  178.52
  30   0.0421     98.670  0.0291    99.095  184.60
  31   0.0577     98.140  0.0285    99.148  190.68
  32   0.0584     98.100  0.0285    99.088  196.84
  33   0.0447     98.450  0.0298    99.078  202.94
  34   0.0430     98.520  0.0276    99.120  209.02
  35   0.0331     98.890  0.0274    99.092  215.11
  36   0.0696     97.910  0.0267    99.145  221.20
  37   0.0463     98.540  0.0285    99.097  227.25
  38   0.0356     98.960  0.0255    99.223  233.38
  39   0.0484     98.430  0.0265    99.177  239.49
  40   0.0449     98.520  0.0245    99.242  245.61
  41   0.0353     98.840  0.0263    99.182  251.70
  42   0.0367     98.760  0.0255    99.232  257.80
  43   0.0490     98.350  0.0264    99.177  264.06
  44   0.0466     98.680  0.0234    99.280  270.17
  45   0.0542     98.300  0.0241    99.270  276.25
  46   0.0387     98.800  0.0247    99.255  282.33
  47   0.0392     98.770  0.0251    99.168  288.43
  48   0.0245     99.110  0.0237    99.290  294.51
  49   0.0456     98.670  0.0233    99.268  300.69
  50   0.0475     98.530  0.0215    99.338  306.76
  51   0.0343     98.870  0.0240    99.228  312.84
  52   0.0361     98.770  0.0231    99.283  318.93
  53   0.0377     98.710  0.0236    99.263  325.00
  54   0.0368     98.820  0.0225    99.318  331.20
  55   0.0328     98.940  0.0222    99.298  337.29
  56   0.0269     99.080  0.0209    99.360  343.38
  57   0.0373     98.780  0.0225    99.283  349.46
  58   0.0532     98.400  0.0231    99.257  355.55
  59   0.0491     98.440  0.0214    99.322  361.64
  60   0.0334     98.910  0.0206    99.355  367.76
  61   0.0395     98.800  0.0212    99.343  373.82
  62   0.0293     99.140  0.0194    99.390  379.91
  63   0.0292     99.150  0.0199    99.347  386.01
  64   0.0277     99.050  0.0196    99.405  392.10
  65   0.0480     98.540  0.0207    99.342  398.19
  66   0.0487     98.390  0.0199    99.373  404.38
  67   0.0348     98.920  0.0196    99.405  410.46
  68   0.0212     99.310  0.0201    99.365  416.54
  69   0.0358     98.840  0.0188    99.403  422.63
  70   0.0430     98.710  0.0196    99.405  428.76
  71   0.0333     99.090  0.0192    99.390  434.98
  72   0.0274     99.120  0.0193    99.392  441.07
  73   0.0296     99.170  0.0182    99.453  447.17
  74   0.0254     99.180  0.0185    99.407  453.28
  75   0.0275     99.120  0.0164    99.457  459.36
  76   0.0451     98.800  0.0167    99.453  465.45
  77   0.0275     99.080  0.0196    99.377  471.61
  78   0.0283     99.140  0.0178    99.417  477.72
  79   0.0339     99.000  0.0180    99.430  483.81
  80   0.0410     98.640  0.0164    99.470  489.96
  81   0.0418     98.760  0.0168    99.488  496.05
  82   0.0397     98.860  0.0164    99.477  502.13
  83   0.0518     98.440  0.0167    99.448  508.22
  84   0.0335     98.970  0.0164    99.480  514.33
  85   0.0315     98.950  0.0170    99.467  520.42
  86   0.0364     98.880  0.0150    99.545  526.52
  87   0.0294     99.020  0.0156    99.495  532.60
  88   0.0393     98.770  0.0154    99.503  538.68
  89   0.0336     98.940  0.0160    99.507  544.90
  90   0.0286     99.050  0.0161    99.447  551.06
