Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1248     95.980  0.3376    88.718  7.66
   2   0.0856     97.420  0.1036    96.773  13.77
   3   0.0701     97.920  0.0822    97.480  19.86
   4   0.0827     97.460  0.0728    97.703  25.96
   5   0.0712     97.670  0.0679    97.890  32.23
   6   0.0609     98.000  0.0662    98.000  38.33
   7   0.0710     97.830  0.0647    98.018  44.43
   8   0.0559     98.410  0.0598    98.157  50.61
   9   0.1005     96.850  0.0604    98.157  56.73
  10   0.0618     97.970  0.0586    98.260  62.99
  11   0.0582     98.200  0.0561    98.332  69.09
  12   0.0515     98.390  0.0546    98.370  75.25
  13   0.0497     98.490  0.0526    98.457  81.35
  14   0.0475     98.610  0.0550    98.360  87.47
  15   0.0637     98.060  0.0550    98.335  93.59
  16   0.0489     98.510  0.0503    98.540  99.74
  17   0.0390     98.760  0.0478    98.568  105.83
  18   0.0550     98.400  0.0480    98.592  111.91
  19   0.0674     97.980  0.0511    98.502  118.05
  20   0.0432     98.530  0.0507    98.495  124.15
  21   0.0342     99.070  0.0444    98.685  130.24
  22   0.0421     98.800  0.0450    98.695  136.46
  23   0.0498     98.290  0.0440    98.682  142.56
  24   0.0390     98.730  0.0424    98.722  148.67
  25   0.0493     98.390  0.0405    98.813  154.75
  26   0.0470     98.600  0.0424    98.768  160.85
  27   0.0316     98.990  0.0410    98.810  166.99
  28   0.0377     98.720  0.0420    98.763  173.07
  29   0.0492     98.430  0.0414    98.757  179.34
  30   0.0385     98.790  0.0390    98.820  185.44
  31   0.0400     98.800  0.0395    98.818  191.56
  32   0.0277     99.190  0.0372    98.867  197.65
  33   0.0367     98.840  0.0383    98.877  203.75
  34   0.0417     98.520  0.0369    98.882  209.85
  35   0.0389     98.650  0.0336    98.957  216.01
  36   0.0388     98.810  0.0368    98.897  222.11
  37   0.0445     98.690  0.0364    98.913  228.21
  38   0.0339     98.980  0.0349    98.938  234.31
  39   0.0452     98.590  0.0337    98.990  240.42
  40   0.0383     98.880  0.0343    98.947  246.62
  41   0.0335     98.940  0.0321    99.055  252.73
  42   0.0478     98.580  0.0337    98.940  258.84
  43   0.0336     98.970  0.0338    98.962  264.95
  44   0.0304     98.990  0.0312    99.053  271.06
  45   0.0418     98.720  0.0326    99.030  277.29
  46   0.0395     98.790  0.0330    99.010  283.40
  47   0.0388     98.710  0.0316    99.070  289.56
  48   0.0304     99.050  0.0315    99.028  295.67
  49   0.0367     98.810  0.0313    99.100  301.77
  50   0.0382     98.720  0.0316    99.017  307.86
  51   0.0500     98.340  0.0307    99.103  314.08
  52   0.0327     98.880  0.0291    99.123  320.18
  53   0.0287     99.080  0.0298    99.122  326.26
  54   0.0328     98.990  0.0294    99.082  332.36
  55   0.0308     99.060  0.0302    99.127  338.48
  56   0.0416     98.620  0.0292    99.122  344.68
  57   0.0269     99.190  0.0297    99.112  350.75
  58   0.0301     98.980  0.0289    99.173  356.84
  59   0.0384     98.710  0.0278    99.172  362.94
  60   0.0289     99.060  0.0267    99.208  369.04
  61   0.0320     99.020  0.0275    99.167  375.14
  62   0.0327     98.950  0.0310    99.133  381.34
  63   0.0448     98.500  0.0277    99.182  387.47
  64   0.0417     98.740  0.0281    99.178  393.57
  65   0.0346     98.930  0.0269    99.200  399.66
  66   0.0318     98.940  0.0276    99.155  405.77
  67   0.0316     98.970  0.0270    99.187  411.97
  68   0.0360     98.820  0.0254    99.218  418.08
  69   0.0337     98.960  0.0280    99.120  424.19
  70   0.0300     99.070  0.0268    99.190  430.30
  71   0.0282     99.130  0.0287    99.107  436.41
  72   0.0296     99.060  0.0266    99.162  442.53
  73   0.0343     98.980  0.0248    99.273  448.71
  74   0.0350     98.960  0.0263    99.202  454.82
  75   0.0409     98.650  0.0279    99.175  460.92
  76   0.0366     98.790  0.0257    99.225  467.01
  77   0.0341     98.930  0.0250    99.252  473.11
  78   0.0432     98.680  0.0251    99.252  479.23
  79   0.0296     99.110  0.0256    99.240  485.35
  80   0.0277     99.150  0.0257    99.205  491.58
  81   0.0394     98.810  0.0247    99.252  497.69
  82   0.0320     98.960  0.0248    99.222  503.78
  83   0.0356     98.860  0.0254    99.243  509.92
  84   0.0348     98.790  0.0248    99.247  516.02
  85   0.0339     99.010  0.0253    99.248  522.21
  86   0.0286     99.110  0.0266    99.158  528.32
  87   0.0301     99.020  0.0251    99.232  534.42
  88   0.0306     99.030  0.0250    99.213  540.51
  89   0.0360     98.830  0.0249    99.290  546.60
  90   0.0310     99.020  0.0232    99.280  552.73
