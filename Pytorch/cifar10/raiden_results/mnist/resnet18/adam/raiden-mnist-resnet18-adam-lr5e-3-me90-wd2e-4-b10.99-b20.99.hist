Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8165     46.420  0.6029    80.130  7.60
   2   0.4154     85.750  0.1759    94.567  13.74
   3   0.1030     96.640  0.1242    96.237  19.80
   4   0.1028     96.720  0.1020    96.862  25.87
   5   0.1191     96.120  0.0897    97.265  31.94
   6   0.0664     97.890  0.0792    97.585  38.05
   7   0.0828     97.260  0.0743    97.698  44.14
   8   0.0771     97.450  0.0684    97.870  50.33
   9   0.0680     97.670  0.0668    97.980  56.43
  10   0.0724     97.670  0.0605    98.108  62.55
  11   0.0515     98.250  0.0622    98.062  68.63
  12   0.0627     97.950  0.0578    98.208  74.72
  13   0.0962     96.950  0.0587    98.190  80.91
  14   0.0614     97.860  0.0573    98.243  87.00
  15   0.0638     98.080  0.0535    98.338  93.09
  16   0.0496     98.300  0.0562    98.258  99.16
  17   0.0810     97.470  0.0535    98.350  105.24
  18   0.0411     98.640  0.0532    98.343  111.32
  19   0.0518     98.410  0.0535    98.390  117.49
  20   0.0446     98.660  0.0520    98.363  123.63
  21   0.0535     98.300  0.0523    98.337  129.72
  22   0.0792     97.480  0.0522    98.370  135.77
  23   0.0359     98.740  0.0518    98.388  141.85
  24   0.0394     98.690  0.0531    98.332  148.04
  25   0.0417     98.590  0.0505    98.405  154.13
  26   0.0631     97.980  0.0525    98.335  160.20
  27   0.0487     98.420  0.0493    98.437  166.28
  28   0.0380     98.650  0.0496    98.490  172.37
  29   0.0756     97.500  0.0494    98.432  178.46
  30   0.0451     98.530  0.0498    98.500  184.66
  31   0.0758     97.460  0.0505    98.373  190.71
  32   0.0589     97.990  0.0480    98.500  196.77
  33   0.0455     98.460  0.0502    98.438  202.84
  34   0.0412     98.720  0.0498    98.403  208.93
  35   0.0426     98.680  0.0470    98.520  215.00
  36   0.0623     97.980  0.0501    98.478  221.18
  37   0.0563     98.110  0.0512    98.425  227.28
  38   0.0752     97.590  0.0478    98.527  233.41
  39   0.0486     98.460  0.0497    98.417  239.51
  40   0.0574     98.110  0.0495    98.473  245.60
  41   0.0480     98.390  0.0494    98.478  251.68
  42   0.0544     98.190  0.0467    98.552  257.87
  43   0.0430     98.590  0.0486    98.493  263.96
  44   0.0487     98.340  0.0478    98.510  270.03
  45   0.0391     98.630  0.0492    98.538  276.13
  46   0.0429     98.550  0.0471    98.563  282.22
  47   0.0556     98.240  0.0494    98.462  288.30
  48   0.0420     98.520  0.0472    98.490  294.51
  49   0.0362     98.820  0.0472    98.518  300.59
  50   0.0383     98.740  0.0484    98.495  306.69
  51   0.0530     98.440  0.0481    98.477  312.77
  52   0.0409     98.620  0.0481    98.512  318.85
  53   0.0403     98.640  0.0460    98.538  324.93
  54   0.0454     98.410  0.0483    98.503  331.09
  55   0.0492     98.370  0.0500    98.438  337.17
  56   0.0479     98.430  0.0471    98.605  343.24
  57   0.0577     98.120  0.0473    98.518  349.32
  58   0.0551     98.100  0.0468    98.508  355.37
  59   0.0580     98.150  0.0474    98.503  361.46
  60   0.0355     98.850  0.0490    98.483  367.61
  61   0.0396     98.630  0.0452    98.568  373.69
  62   0.0515     98.200  0.0452    98.607  379.77
  63   0.0555     98.160  0.0485    98.475  385.89
  64   0.0494     98.460  0.0461    98.592  392.02
  65   0.0577     98.160  0.0462    98.555  398.32
  66   0.0518     98.400  0.0463    98.575  404.42
  67   0.0529     98.250  0.0479    98.517  410.50
  68   0.0573     98.200  0.0461    98.635  416.59
  69   0.0502     98.300  0.0467    98.558  422.65
  70   0.0413     98.690  0.0449    98.613  428.84
  71   0.0565     98.160  0.0473    98.490  434.91
  72   0.0487     98.430  0.0456    98.562  441.00
  73   0.0469     98.340  0.0477    98.510  447.08
  74   0.0511     98.440  0.0448    98.652  453.19
  75   0.0412     98.650  0.0484    98.508  459.30
  76   0.0505     98.440  0.0463    98.553  465.47
  77   0.0416     98.700  0.0463    98.542  471.56
  78   0.0408     98.650  0.0460    98.517  477.64
  79   0.0467     98.520  0.0446    98.552  483.72
  80   0.0373     98.850  0.0435    98.662  489.79
  81   0.0463     98.460  0.0448    98.595  495.87
  82   0.0495     98.390  0.0443    98.625  502.05
  83   0.0618     97.950  0.0453    98.647  508.11
  84   0.0431     98.490  0.0467    98.553  514.21
  85   0.0528     98.390  0.0475    98.533  520.32
  86   0.0454     98.530  0.0478    98.492  526.38
  87   0.0514     98.310  0.0452    98.555  532.48
  88   0.0434     98.570  0.0456    98.555  538.61
  89   0.0540     98.150  0.0448    98.567  544.69
  90   0.0382     98.780  0.0447    98.622  550.77
