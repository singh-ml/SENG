Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7790     39.180  1.7263    54.842  7.59
   2   0.3476     88.250  0.3270    89.673  13.69
   3   0.4239     86.250  0.2076    93.512  19.76
   4   0.6899     77.980  0.1664    94.857  25.85
   5   0.2705     90.580  0.1495    95.428  31.94
   6   0.7293     79.550  0.1412    95.487  38.04
   7   0.2607     91.950  0.1389    95.738  44.13
   8   0.2295     92.330  0.1338    95.810  50.23
   9   0.3043     89.790  0.1399    95.688  56.32
  10   0.5499     82.430  0.1294    95.973  62.42
  11   0.2726     91.100  0.1286    95.997  68.61
  12   0.1557     94.710  0.1300    96.043  74.71
  13   0.2592     92.120  0.1249    96.017  80.81
  14   0.2861     90.890  0.1263    96.110  86.90
  15   0.5217     87.850  0.1216    96.187  93.00
  16   0.4174     87.020  0.1250    96.138  99.08
  17   0.3925     87.300  0.1221    96.192  105.24
  18   0.5779     82.070  0.1222    96.203  111.30
  19   0.1653     94.550  0.1183    96.318  117.40
  20   0.2125     92.680  0.1183    96.292  123.52
  21   0.7904     79.990  0.1206    96.263  129.66
  22   0.2091     92.970  0.1161    96.363  135.76
  23   0.5483     82.820  0.1186    96.293  141.94
  24   0.4256     83.560  0.1220    96.253  148.04
  25   0.2214     92.360  0.1178    96.285  154.13
  26   0.1857     93.880  0.1168    96.415  160.22
  27   0.5531     84.260  0.1163    96.370  166.29
  28   0.1938     93.590  0.1160    96.447  172.38
  29   0.2037     93.270  0.1184    96.315  178.54
  30   0.2221     92.750  0.1198    96.272  184.63
  31   0.3879     88.060  0.1204    96.238  190.73
  32   0.3077     91.170  0.1165    96.428  196.84
  33   0.2162     93.140  0.1170    96.378  202.93
  34   0.2295     92.710  0.1183    96.317  209.11
  35   1.6348     62.590  0.1160    96.432  215.21
  36   0.2964     90.530  0.1192    96.293  221.30
  37   0.1666     94.590  0.1156    96.493  227.39
  38   1.7732     61.070  0.1174    96.357  233.48
  39   0.6311     79.920  0.1184    96.312  239.56
  40   1.2244     74.760  0.1170    96.395  245.75
  41   0.2703     90.950  0.1143    96.477  251.87
  42   0.1822     93.840  0.1162    96.433  257.95
  43   0.1768     94.240  0.1148    96.413  264.03
  44   0.4523     87.690  0.1166    96.413  270.10
  45   0.2610     92.210  0.1151    96.405  276.19
  46   0.3325     89.320  0.1156    96.382  282.38
  47   0.9911     75.230  0.1148    96.482  288.45
  48   0.2048     93.650  0.1192    96.303  294.56
  49   0.2553     91.930  0.1174    96.383  300.68
  50   0.7873     79.320  0.1155    96.345  306.79
  51   0.1719     95.030  0.1150    96.393  312.98
  52   0.1777     94.600  0.1184    96.393  319.06
  53   0.3623     87.110  0.1141    96.467  325.14
  54   0.2452     91.960  0.1129    96.508  331.24
  55   0.2344     93.080  0.1166    96.375  337.32
  56   0.2036     94.410  0.1165    96.390  343.45
  57   0.1473     95.050  0.1189    96.338  349.63
  58   0.2330     92.850  0.1157    96.455  355.71
  59   0.1719     94.720  0.1151    96.472  361.79
  60   0.4350     86.360  0.1168    96.390  367.85
  61   0.1278     95.960  0.1133    96.497  373.93
  62   0.2531     91.910  0.1173    96.373  380.10
  63   0.5552     83.220  0.1123    96.582  386.20
  64   0.2479     92.650  0.1158    96.432  392.32
  65   0.1354     95.920  0.1157    96.443  398.40
  66   0.1317     95.870  0.1137    96.487  404.48
  67   0.3219     90.400  0.1142    96.498  410.64
  68   0.1137     96.520  0.1135    96.487  416.73
  69   0.3388     89.450  0.1145    96.510  422.88
  70   0.2059     93.520  0.1144    96.523  428.94
  71   0.2430     92.180  0.1176    96.318  435.02
  72   0.1365     95.880  0.1192    96.298  441.11
  73   0.1933     93.940  0.1138    96.492  447.20
  74   0.2732     90.920  0.1156    96.443  453.38
  75   0.2870     91.630  0.1161    96.463  459.46
  76   0.3690     89.270  0.1174    96.382  465.55
  77   0.1982     93.480  0.1167    96.400  471.65
  78   0.3340     90.080  0.1161    96.405  477.72
  79   0.2387     92.890  0.1134    96.393  483.78
  80   0.3525     89.980  0.1142    96.468  489.95
  81   0.3140     91.210  0.1158    96.498  496.04
  82   0.2928     91.340  0.1183    96.327  502.14
  83   0.3842     89.740  0.1143    96.483  508.23
  84   0.1523     95.120  0.1154    96.395  514.31
  85   0.2042     93.550  0.1122    96.483  520.40
