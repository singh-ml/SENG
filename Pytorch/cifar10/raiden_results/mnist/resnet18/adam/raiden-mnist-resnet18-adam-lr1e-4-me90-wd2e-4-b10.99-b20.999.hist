Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2015     93.250  0.6367    79.147  7.70
   2   0.1290     95.730  0.1572    95.083  13.78
   3   0.0691     97.740  0.0955    97.028  19.99
   4   0.0658     97.810  0.0725    97.772  26.08
   5   0.0764     97.330  0.0620    98.083  32.17
   6   0.0484     98.380  0.0531    98.353  38.23
   7   0.0403     98.680  0.0499    98.415  44.32
   8   0.0520     98.170  0.0465    98.570  50.52
   9   0.0401     98.640  0.0433    98.662  56.64
  10   0.0417     98.690  0.0402    98.697  62.76
  11   0.0365     98.750  0.0393    98.755  68.89
  12   0.0371     98.750  0.0369    98.800  74.97
  13   0.0418     98.570  0.0374    98.857  81.06
  14   0.0391     98.620  0.0364    98.852  87.15
  15   0.0344     98.920  0.0345    98.887  93.32
  16   0.0363     98.700  0.0317    98.988  99.41
  17   0.0355     98.860  0.0311    98.953  105.50
  18   0.0421     98.650  0.0300    99.018  111.56
  19   0.0406     98.620  0.0329    98.943  117.64
  20   0.0374     98.860  0.0302    99.023  123.71
  21   0.0359     98.900  0.0308    99.012  129.85
  22   0.0430     98.610  0.0273    99.112  135.95
  23   0.0320     98.900  0.0300    99.023  142.02
  24   0.0552     98.220  0.0268    99.162  148.12
  25   0.0280     99.140  0.0292    99.057  154.19
  26   0.0307     99.050  0.0262    99.175  160.39
  27   0.0404     98.720  0.0268    99.162  166.49
  28   0.0326     98.970  0.0249    99.168  172.62
  29   0.0300     98.970  0.0238    99.253  178.67
  30   0.0385     98.630  0.0241    99.232  184.73
  31   0.0307     99.060  0.0254    99.212  190.83
  32   0.0301     99.060  0.0262    99.152  196.99
  33   0.0412     98.630  0.0241    99.203  203.09
  34   0.0350     98.810  0.0243    99.217  209.18
  35   0.0331     98.900  0.0218    99.298  215.30
  36   0.0344     98.960  0.0239    99.227  221.38
  37   0.0311     99.000  0.0235    99.225  227.47
  38   0.0260     99.110  0.0221    99.265  233.66
  39   0.0318     99.060  0.0228    99.297  239.73
  40   0.0347     98.900  0.0210    99.330  245.79
  41   0.0284     99.100  0.0196    99.392  251.86
  42   0.0292     99.200  0.0195    99.402  257.91
  43   0.0448     98.510  0.0201    99.358  264.11
  44   0.0276     99.100  0.0216    99.298  270.21
  45   0.0339     98.800  0.0208    99.322  276.30
  46   0.0288     98.970  0.0213    99.303  282.40
  47   0.0343     98.960  0.0193    99.383  288.49
  48   0.0301     99.020  0.0184    99.387  294.57
  49   0.0356     98.830  0.0206    99.353  300.73
  50   0.0315     99.020  0.0188    99.395  306.81
  51   0.0321     98.970  0.0199    99.358  312.94
  52   0.0302     99.040  0.0186    99.422  319.05
  53   0.0291     99.080  0.0206    99.322  325.14
  54   0.0358     98.890  0.0206    99.348  331.36
  55   0.0307     99.040  0.0206    99.345  337.49
  56   0.0326     98.900  0.0185    99.422  343.61
  57   0.0273     99.120  0.0175    99.453  349.70
  58   0.0334     98.860  0.0167    99.457  355.79
  59   0.0347     98.890  0.0151    99.537  361.89
  60   0.0378     98.830  0.0157    99.538  368.06
  61   0.0323     98.970  0.0172    99.457  374.18
  62   0.0215     99.350  0.0173    99.428  380.26
  63   0.0298     99.140  0.0161    99.522  386.34
  64   0.0370     98.750  0.0161    99.497  392.41
  65   0.0278     99.100  0.0162    99.507  398.63
  66   0.0413     98.770  0.0165    99.495  404.71
  67   0.0325     98.860  0.0193    99.432  410.79
  68   0.0339     98.920  0.0175    99.397  416.85
  69   0.0368     98.830  0.0171    99.442  422.93
  70   0.0295     99.110  0.0171    99.482  429.01
  71   0.0353     98.860  0.0148    99.523  435.21
  72   0.0237     99.180  0.0168    99.472  441.30
  73   0.0330     98.810  0.0158    99.507  447.37
  74   0.0333     98.930  0.0148    99.542  453.44
  75   0.0246     99.240  0.0139    99.568  459.52
  76   0.0311     99.030  0.0153    99.513  465.59
  77   0.0272     99.100  0.0131    99.608  471.77
  78   0.0300     99.060  0.0145    99.568  477.85
  79   0.0308     99.200  0.0143    99.555  483.93
  80   0.0314     99.010  0.0160    99.477  490.02
  81   0.0267     99.150  0.0147    99.522  496.16
  82   0.0325     98.980  0.0151    99.537  502.38
  83   0.0296     99.010  0.0132    99.580  508.47
  84   0.0297     99.070  0.0140    99.568  514.56
  85   0.0329     99.070  0.0134    99.578  520.66
  86   0.0321     98.950  0.0134    99.593  526.75
  87   0.0294     99.160  0.0130    99.580  532.81
  88   0.0308     99.050  0.0132    99.587  538.88
  89   0.0415     98.810  0.0134    99.568  545.02
  90   0.0210     99.270  0.0133    99.585  551.10
