Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2271     93.020  0.2676    91.075  7.68
   2   0.1828     94.020  0.1008    96.865  13.75
   3   0.1410     95.670  0.0877    97.243  19.83
   4   0.5123     83.500  0.0784    97.545  25.98
   5   0.1323     95.860  0.0737    97.643  32.05
   6   0.0871     97.380  0.0711    97.818  38.14
   7   0.1248     96.120  0.0670    97.902  44.22
   8   0.0595     98.160  0.0610    98.108  50.30
   9   0.0535     98.230  0.0613    98.167  56.38
  10   0.0785     97.510  0.0554    98.297  62.60
  11   0.1069     96.570  0.0552    98.290  68.68
  12   0.0509     98.370  0.0521    98.402  74.76
  13   0.0423     98.610  0.0508    98.402  80.83
  14   0.0585     97.920  0.0472    98.577  86.92
  15   0.0648     97.530  0.0491    98.490  93.09
  16   0.0802     97.460  0.0464    98.577  99.21
  17   0.0441     98.630  0.0467    98.597  105.32
  18   0.0516     98.290  0.0434    98.718  111.47
  19   0.0536     98.190  0.0452    98.593  117.55
  20   0.0399     98.720  0.0436    98.623  123.63
  21   0.0386     98.760  0.0422    98.667  129.85
  22   0.0501     98.270  0.0413    98.712  135.92
  23   0.0434     98.670  0.0405    98.760  142.00
  24   0.0669     98.120  0.0407    98.715  148.07
  25   0.0467     98.490  0.0379    98.843  154.16
  26   0.0369     98.750  0.0392    98.812  160.35
  27   0.0351     98.910  0.0371    98.807  166.44
  28   0.0421     98.690  0.0380    98.823  172.54
  29   0.0407     98.610  0.0366    98.893  178.64
  30   0.0369     98.810  0.0369    98.865  184.73
  31   0.0346     98.900  0.0379    98.848  190.81
  32   0.0375     98.710  0.0341    98.950  196.99
  33   0.0291     99.080  0.0364    98.912  203.05
  34   0.0391     98.630  0.0356    98.897  209.14
  35   0.0257     99.150  0.0329    98.997  215.25
  36   0.0281     99.050  0.0335    98.995  221.36
  37   0.0417     98.600  0.0353    98.880  227.43
  38   0.0361     98.890  0.0336    98.943  233.62
  39   0.0560     98.280  0.0333    98.965  239.71
  40   0.0541     98.340  0.0347    98.888  245.77
  41   0.0456     98.600  0.0327    98.993  251.87
  42   0.0343     98.920  0.0321    99.015  257.98
  43   0.0459     98.420  0.0337    98.947  264.08
  44   0.0314     99.020  0.0319    98.992  270.28
  45   0.0360     98.800  0.0320    98.987  276.38
  46   0.0367     98.890  0.0314    99.052  282.47
  47   0.0364     98.760  0.0322    98.970  288.56
  48   0.0312     99.020  0.0314    99.052  294.65
  49   0.0344     98.950  0.0304    99.023  300.76
  50   0.0350     98.940  0.0310    99.048  306.91
  51   0.0348     98.830  0.0308    99.037  313.02
  52   0.0334     98.950  0.0295    99.088  319.12
  53   0.0346     98.890  0.0303    99.040  325.20
  54   0.0297     98.980  0.0306    99.015  331.29
  55   0.0389     98.580  0.0302    99.037  337.40
  56   0.0355     98.780  0.0310    99.037  343.58
  57   0.0423     98.570  0.0306    99.025  349.65
  58   0.0426     98.540  0.0288    99.128  355.76
  59   0.0320     99.020  0.0296    99.080  361.84
  60   0.0284     99.100  0.0289    99.135  367.93
  61   0.0295     99.100  0.0294    99.110  374.01
  62   0.0443     98.500  0.0303    99.052  380.18
  63   0.0341     98.880  0.0297    99.075  386.28
  64   0.0472     98.460  0.0283    99.133  392.39
  65   0.0413     98.730  0.0281    99.122  398.45
  66   0.0414     98.630  0.0296    99.083  404.52
  67   0.0308     98.900  0.0295    99.050  410.60
  68   0.0391     98.770  0.0284    99.120  416.70
  69   0.0375     98.910  0.0276    99.158  422.80
  70   0.0480     98.520  0.0288    99.090  428.93
  71   0.0323     98.840  0.0283    99.128  435.01
  72   0.0329     98.960  0.0265    99.158  441.10
  73   0.0294     99.110  0.0270    99.143  447.27
  74   0.0443     98.560  0.0277    99.113  453.37
  75   0.0471     98.420  0.0279    99.128  459.46
  76   0.0421     98.720  0.0273    99.158  465.54
  77   0.0403     98.700  0.0287    99.100  471.63
  78   0.0253     99.230  0.0260    99.195  477.72
  79   0.0346     98.890  0.0274    99.180  483.90
  80   0.0469     98.480  0.0271    99.150  489.99
  81   0.0341     98.900  0.0270    99.188  496.13
  82   0.0422     98.750  0.0274    99.092  502.23
  83   0.0377     98.740  0.0266    99.137  508.32
  84   0.0360     98.860  0.0267    99.135  514.52
  85   0.0384     98.750  0.0277    99.113  520.63
  86   0.0390     98.830  0.0261    99.195  526.73
  87   0.0449     98.550  0.0275    99.133  532.83
  88   0.0476     98.330  0.0264    99.173  538.92
  89   0.0462     98.610  0.0266    99.163  545.00
  90   0.0354     98.820  0.0268    99.143  551.18
