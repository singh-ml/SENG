Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1152     96.160  0.2566    91.498  7.65
   2   0.1068     96.590  0.0928    97.085  13.69
   3   0.2103     93.330  0.0812    97.508  19.80
   4   0.1128     96.580  0.0763    97.583  25.83
   5   0.1014     96.590  0.0709    97.798  31.88
   6   0.0824     97.390  0.0705    97.848  37.94
   7   0.0819     97.200  0.0676    97.950  43.98
   8   0.1110     96.330  0.0643    98.045  50.05
   9   0.0712     97.780  0.0649    98.023  56.20
  10   0.0705     97.650  0.0599    98.173  62.25
  11   0.0756     97.680  0.0615    98.138  68.30
  12   0.0539     98.230  0.0606    98.183  74.38
  13   0.0749     97.760  0.0534    98.368  80.42
  14   0.0717     97.610  0.0556    98.333  86.56
  15   0.0498     98.500  0.0535    98.403  92.62
  16   0.0518     98.390  0.0496    98.475  98.70
  17   0.0817     97.440  0.0528    98.338  104.80
  18   0.0629     97.890  0.0480    98.538  110.84
  19   0.0572     98.190  0.0493    98.450  116.89
  20   0.0830     97.370  0.0474    98.558  123.03
  21   0.0337     98.880  0.0468    98.585  129.08
  22   0.0468     98.460  0.0445    98.620  135.12
  23   0.0501     98.320  0.0427    98.633  141.20
  24   0.0447     98.500  0.0421    98.708  147.24
  25   0.0498     98.370  0.0414    98.723  153.41
  26   0.0785     97.650  0.0424    98.647  159.50
  27   0.0601     98.200  0.0401    98.762  165.60
  28   0.0519     98.300  0.0405    98.738  171.67
  29   0.0579     98.190  0.0417    98.765  177.74
  30   0.0317     98.920  0.0375    98.850  183.80
  31   0.0276     99.120  0.0391    98.828  189.99
  32   0.0456     98.520  0.0378    98.865  196.06
  33   0.0487     98.460  0.0388    98.822  202.13
  34   0.0334     98.910  0.0356    98.918  208.20
  35   0.0418     98.650  0.0378    98.782  214.26
  36   0.0331     98.890  0.0348    98.900  220.31
  37   0.0338     98.830  0.0369    98.882  226.50
  38   0.0439     98.520  0.0345    98.968  232.55
  39   0.0483     98.390  0.0352    98.870  238.62
  40   0.0446     98.440  0.0342    98.955  244.71
  41   0.0446     98.620  0.0348    98.900  250.84
  42   0.0373     98.830  0.0345    98.885  256.91
  43   0.0246     99.150  0.0333    98.967  263.14
  44   0.0466     98.470  0.0338    98.973  269.25
  45   0.0367     98.830  0.0337    98.953  275.32
  46   0.0387     98.710  0.0327    99.008  281.37
  47   0.0276     99.120  0.0327    99.007  287.44
  48   0.0437     98.650  0.0324    98.985  293.52
  49   0.0275     99.040  0.0329    98.970  299.69
  50   0.0247     99.160  0.0323    98.968  305.78
  51   0.0388     98.830  0.0305    99.060  311.86
  52   0.0387     98.640  0.0328    98.955  317.94
  53   0.0371     98.680  0.0305    99.043  324.02
  54   0.0282     99.160  0.0326    98.998  330.10
  55   0.0427     98.660  0.0301    99.067  336.30
  56   0.0386     98.770  0.0315    99.010  342.38
  57   0.0366     98.930  0.0305    99.045  348.46
  58   0.0338     98.910  0.0313    99.018  354.53
  59   0.0401     98.730  0.0297    99.063  360.63
  60   0.0318     98.970  0.0310    99.032  366.69
  61   0.0320     98.910  0.0295    99.070  372.84
  62   0.0470     98.540  0.0320    98.990  378.92
  63   0.0299     99.080  0.0297    99.060  385.00
  64   0.0389     98.720  0.0301    99.072  391.09
  65   0.0432     98.580  0.0296    99.077  397.17
  66   0.0421     98.650  0.0286    99.080  403.24
  67   0.0287     98.960  0.0277    99.138  409.40
  68   0.0292     99.070  0.0306    99.040  415.49
  69   0.0258     99.100  0.0283    99.085  421.55
  70   0.0573     98.040  0.0304    99.035  427.72
  71   0.0461     98.480  0.0297    99.067  433.84
  72   0.0312     98.970  0.0303    99.062  439.89
  73   0.0343     98.880  0.0284    99.095  446.06
  74   0.0281     99.160  0.0276    99.150  452.11
  75   0.0330     98.900  0.0272    99.142  458.19
  76   0.0403     98.710  0.0286    99.117  464.26
  77   0.0369     98.710  0.0283    99.100  470.35
  78   0.0336     98.890  0.0290    99.067  476.53
  79   0.0343     98.750  0.0276    99.135  482.61
  80   0.0342     98.840  0.0292    99.093  488.72
  81   0.0384     98.750  0.0273    99.132  494.81
  82   0.0360     98.830  0.0284    99.127  500.88
  83   0.0386     98.740  0.0266    99.143  506.96
  84   0.0383     98.800  0.0287    99.113  513.10
  85   0.0399     98.750  0.0264    99.197  519.18
  86   0.0380     98.690  0.0266    99.160  525.25
  87   0.0327     98.960  0.0284    99.155  531.34
  88   0.0390     98.720  0.0264    99.145  537.42
  89   0.0326     98.960  0.0284    99.130  543.60
  90   0.0308     98.940  0.0254    99.212  549.70
