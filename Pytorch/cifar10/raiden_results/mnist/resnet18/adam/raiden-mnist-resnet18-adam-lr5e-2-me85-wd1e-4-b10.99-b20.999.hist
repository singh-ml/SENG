Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4204     12.000  2.6029    11.690  7.77
   2   0.8481     75.620  0.8402    71.357  13.89
   3   0.5015     85.810  0.2577    91.930  19.96
   4   0.2721     91.800  0.1844    94.315  26.02
   5   0.4214     86.090  0.1584    95.092  32.10
   6   0.5750     82.790  0.1444    95.463  38.18
   7   0.2698     91.450  0.1347    95.825  44.41
   8   0.3264     88.640  0.1263    96.055  50.47
   9   0.1130     96.270  0.1237    96.102  56.51
  10   0.1796     94.510  0.1220    96.192  62.57
  11   0.2481     92.330  0.1162    96.403  68.66
  12   0.1746     94.260  0.1144    96.510  74.77
  13   0.2631     92.260  0.1130    96.522  80.94
  14   0.1002     96.740  0.1097    96.645  87.02
  15   0.1309     95.780  0.1091    96.587  93.10
  16   0.2370     92.440  0.1052    96.763  99.15
  17   0.1545     94.880  0.1040    96.843  105.25
  18   0.1058     96.460  0.1073    96.660  111.33
  19   0.1318     95.460  0.1047    96.742  117.48
  20   0.2626     91.640  0.1013    96.875  123.54
  21   0.1579     95.150  0.1020    96.805  129.60
  22   0.8178     82.020  0.1003    96.850  135.67
  23   0.2033     93.530  0.0988    96.932  141.72
  24   0.1492     94.920  0.1040    96.712  147.92
  25   0.3300     90.770  0.0980    96.833  154.03
  26   0.1604     94.830  0.0986    96.942  160.09
  27   0.1499     95.190  0.0998    96.888  166.17
  28   0.4828     84.460  0.1006    96.890  172.24
  29   0.1999     93.410  0.0982    96.925  178.35
  30   0.6585     81.300  0.0992    96.983  184.54
  31   0.1916     94.300  0.0998    96.948  190.60
  32   0.7266     80.820  0.0984    96.923  196.69
  33   0.1315     95.940  0.0997    96.892  202.74
  34   0.7641     73.500  0.0998    96.980  208.79
  35   1.0396     69.760  0.0994    96.863  214.94
  36   0.2179     93.700  0.0975    96.983  221.01
  37   0.1865     94.150  0.0990    96.930  227.09
  38   0.1824     94.110  0.0984    96.977  233.17
  39   0.3413     88.840  0.0972    96.955  239.23
  40   0.1794     94.140  0.0949    97.022  245.30
  41   0.1157     96.050  0.0970    96.925  251.49
  42   0.8203     76.250  0.0976    97.023  257.55
  43   0.1646     95.010  0.0989    96.912  263.62
  44   0.2221     92.890  0.0974    96.993  269.74
  45   0.1956     94.190  0.0986    96.855  275.84
  46   0.2096     93.420  0.0990    96.907  281.91
  47   0.7395     81.310  0.0975    97.025  288.11
  48   0.6251     82.270  0.0972    96.925  294.20
  49   1.2882     64.530  0.0997    96.863  300.27
  50   0.2272     93.110  0.0938    97.022  306.38
  51   0.6458     84.140  0.0972    97.003  312.51
  52   0.2337     92.760  0.0935    97.120  318.60
  53   0.1315     95.560  0.0966    97.060  324.81
  54   0.1442     95.540  0.0949    97.092  330.87
  55   0.0979     96.730  0.0959    96.992  336.93
  56   0.0940     97.120  0.0993    96.912  343.00
  57   0.1451     95.440  0.0945    97.087  349.07
  58   0.2104     93.420  0.0948    97.000  355.14
  59   0.1492     95.150  0.0966    97.060  361.32
  60   0.1844     94.360  0.0945    97.058  367.41
  61   0.1361     95.730  0.0950    96.982  373.47
  62   0.2448     92.550  0.0975    97.017  379.54
  63   1.0540     74.070  0.0961    96.945  385.61
  64   0.6146     81.840  0.0944    97.000  391.79
  65   0.5364     85.650  0.0959    96.928  397.85
  66   0.3207     89.900  0.0948    97.010  403.91
  67   0.1996     93.950  0.0950    97.078  410.01
  68   0.0928     97.180  0.0964    96.962  416.08
  69   0.2524     92.860  0.0942    97.022  422.15
  70   0.1551     94.940  0.0972    96.932  428.32
  71   0.3259     92.150  0.0954    97.052  434.41
  72   0.1560     94.810  0.0930    97.090  440.47
  73   0.4509     86.840  0.0971    97.033  446.52
  74   0.6332     81.180  0.0972    97.020  452.61
  75   0.2043     94.010  0.0921    97.178  458.66
  76   0.2044     93.300  0.0981    96.868  464.82
  77   0.6068     83.750  0.0928    97.183  470.90
  78   0.7703     76.030  0.0938    97.055  476.98
  79   0.1295     95.640  0.0964    97.010  483.09
  80   0.2235     93.300  0.0925    97.152  489.17
  81   0.1560     95.050  0.0967    97.067  495.34
  82   0.1405     95.100  0.0936    97.107  501.40
  83   0.9921     79.350  0.0964    96.938  507.47
  84   0.1633     94.980  0.1007    96.877  513.53
  85   0.3460     88.190  0.0936    97.077  519.64
