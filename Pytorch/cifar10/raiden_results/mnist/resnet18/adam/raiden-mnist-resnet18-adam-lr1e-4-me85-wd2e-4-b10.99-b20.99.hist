Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1920     93.920  0.6233    79.837  7.77
   2   0.1003     96.880  0.1375    95.622  14.09
   3   0.0716     97.430  0.0869    97.335  20.32
   4   0.0617     97.870  0.0698    97.848  26.54
   5   0.0559     98.240  0.0568    98.242  32.79
   6   0.0479     98.530  0.0540    98.278  39.09
   7   0.0531     98.350  0.0517    98.345  45.44
   8   0.0499     98.310  0.0489    98.478  51.68
   9   0.0423     98.620  0.0428    98.645  57.91
  10   0.0478     98.450  0.0429    98.605  64.18
  11   0.0503     98.380  0.0392    98.743  70.42
  12   0.0512     98.270  0.0369    98.760  76.65
  13   0.0388     98.730  0.0357    98.885  82.90
  14   0.0355     98.890  0.0353    98.865  89.13
  15   0.0383     98.740  0.0320    99.000  95.38
  16   0.0356     98.870  0.0312    98.992  101.61
  17   0.0414     98.590  0.0331    98.937  107.86
  18   0.0358     98.820  0.0321    98.963  114.20
  19   0.0315     99.000  0.0295    99.095  120.43
  20   0.0333     98.920  0.0304    99.032  126.69
  21   0.0384     98.750  0.0282    99.128  132.96
  22   0.0376     98.710  0.0284    99.092  139.20
  23   0.0401     98.680  0.0287    99.065  145.45
  24   0.0439     98.650  0.0285    99.102  151.77
  25   0.0335     98.880  0.0272    99.125  158.00
  26   0.0381     98.830  0.0253    99.197  164.23
  27   0.0358     98.870  0.0275    99.143  170.47
  28   0.0361     98.830  0.0255    99.168  176.69
  29   0.0282     98.990  0.0243    99.218  182.94
  30   0.0415     98.680  0.0249    99.240  189.27
  31   0.0277     99.090  0.0235    99.280  195.52
  32   0.0359     98.830  0.0243    99.208  201.76
  33   0.0314     98.970  0.0252    99.168  207.98
  34   0.0357     98.910  0.0235    99.265  214.21
  35   0.0331     98.970  0.0215    99.315  220.60
  36   0.0306     99.030  0.0218    99.323  226.85
  37   0.0339     98.890  0.0228    99.287  233.08
  38   0.0304     99.010  0.0223    99.288  239.33
  39   0.0331     99.030  0.0213    99.318  245.56
  40   0.0331     99.020  0.0199    99.343  251.80
  41   0.0405     98.670  0.0202    99.363  258.09
  42   0.0329     99.040  0.0211    99.342  264.33
  43   0.0271     99.130  0.0206    99.367  270.61
  44   0.0367     98.740  0.0189    99.398  276.87
  45   0.0331     98.820  0.0186    99.427  283.14
  46   0.0279     99.170  0.0177    99.430  289.38
  47   0.0282     99.100  0.0190    99.402  295.71
  48   0.0313     99.030  0.0193    99.390  301.94
  49   0.0253     99.230  0.0192    99.375  308.17
  50   0.0368     98.820  0.0195    99.393  314.41
  51   0.0315     99.080  0.0182    99.393  320.67
  52   0.0253     99.180  0.0165    99.483  327.03
  53   0.0305     99.010  0.0176    99.435  333.28
  54   0.0310     99.040  0.0188    99.373  339.56
  55   0.0283     99.100  0.0183    99.450  345.80
  56   0.0411     98.700  0.0180    99.432  352.05
  57   0.0300     99.010  0.0191    99.405  358.44
  58   0.0359     98.680  0.0178    99.493  364.67
  59   0.0225     99.240  0.0179    99.423  370.91
  60   0.0248     99.200  0.0169    99.447  377.14
  61   0.0268     99.200  0.0186    99.448  383.38
  62   0.0254     99.120  0.0146    99.553  389.61
  63   0.0353     98.980  0.0150    99.525  395.92
  64   0.0354     98.890  0.0154    99.528  402.17
  65   0.0291     99.040  0.0160    99.512  408.39
  66   0.0387     98.770  0.0155    99.485  414.63
  67   0.0286     99.050  0.0149    99.542  420.88
  68   0.0310     99.020  0.0154    99.517  427.22
  69   0.0247     99.130  0.0159    99.465  433.46
  70   0.0339     98.930  0.0138    99.565  439.70
  71   0.0335     99.040  0.0134    99.553  445.95
  72   0.0392     98.860  0.0149    99.532  452.18
  73   0.0376     98.840  0.0149    99.525  458.42
  74   0.0337     98.970  0.0149    99.528  464.76
  75   0.0332     99.010  0.0142    99.563  471.02
  76   0.0391     98.790  0.0126    99.605  477.27
  77   0.0305     99.050  0.0137    99.573  483.52
  78   0.0251     99.200  0.0135    99.592  489.77
  79   0.0288     99.140  0.0130    99.588  496.01
  80   0.0352     98.930  0.0140    99.560  502.36
  81   0.0303     99.130  0.0132    99.567  508.61
  82   0.0338     98.940  0.0138    99.535  514.84
  83   0.0388     98.630  0.0151    99.548  521.09
  84   0.0274     99.170  0.0136    99.595  527.33
  85   0.0267     99.150  0.0120    99.633  533.67
