Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1727     94.100  0.4540    84.967  7.78
   2   0.0781     97.290  0.1196    96.258  13.92
   3   0.0608     97.940  0.0813    97.440  20.04
   4   0.0641     97.850  0.0629    98.045  26.16
   5   0.0472     98.400  0.0550    98.248  32.28
   6   0.0376     98.800  0.0479    98.448  38.40
   7   0.0416     98.660  0.0461    98.532  44.66
   8   0.0493     98.400  0.0427    98.668  50.81
   9   0.0554     98.240  0.0442    98.645  56.95
  10   0.0514     98.240  0.0415    98.680  63.13
  11   0.0373     98.710  0.0394    98.765  69.27
  12   0.0362     98.780  0.0350    98.887  75.39
  13   0.0524     98.320  0.0401    98.748  81.63
  14   0.0488     98.410  0.0373    98.855  87.75
  15   0.0415     98.730  0.0364    98.835  93.88
  16   0.0460     98.490  0.0353    98.907  100.00
  17   0.0485     98.320  0.0337    98.923  106.11
  18   0.0415     98.600  0.0304    99.017  112.34
  19   0.0443     98.710  0.0328    98.970  118.47
  20   0.0374     98.800  0.0313    99.042  124.60
  21   0.0359     98.920  0.0298    99.030  130.72
  22   0.0336     98.890  0.0313    98.998  136.86
  23   0.0532     98.190  0.0316    98.992  142.99
  24   0.0423     98.680  0.0288    99.037  149.18
  25   0.0410     98.710  0.0288    99.087  155.32
  26   0.0377     98.740  0.0275    99.095  161.45
  27   0.0549     98.180  0.0291    99.125  167.58
  28   0.0330     98.950  0.0305    99.000  173.70
  29   0.0409     98.660  0.0248    99.202  179.88
  30   0.0380     98.830  0.0254    99.208  186.01
  31   0.0343     98.820  0.0266    99.145  192.14
  32   0.0336     98.930  0.0277    99.092  198.27
  33   0.0485     98.350  0.0272    99.098  204.42
  34   0.0371     98.770  0.0261    99.162  210.55
  35   0.0377     98.760  0.0268    99.143  216.77
  36   0.0329     98.890  0.0239    99.198  222.89
  37   0.0366     98.780  0.0251    99.188  229.05
  38   0.0349     98.930  0.0261    99.153  235.21
  39   0.0346     98.950  0.0241    99.208  241.32
  40   0.0323     98.890  0.0237    99.242  247.46
  41   0.0268     99.060  0.0207    99.313  253.68
  42   0.0254     99.190  0.0233    99.265  259.81
  43   0.0294     99.020  0.0229    99.283  265.93
  44   0.0309     98.990  0.0199    99.377  272.11
  45   0.0297     99.130  0.0218    99.272  278.25
  46   0.0348     98.950  0.0220    99.292  284.44
  47   0.0421     98.540  0.0211    99.338  290.56
  48   0.0330     98.990  0.0214    99.275  296.67
  49   0.0316     98.970  0.0210    99.343  302.81
  50   0.0304     99.050  0.0213    99.285  308.99
  51   0.0407     98.730  0.0196    99.343  315.13
  52   0.0406     98.680  0.0213    99.292  321.32
  53   0.0326     98.860  0.0211    99.320  327.45
  54   0.0236     99.240  0.0195    99.353  333.57
  55   0.0273     99.130  0.0182    99.400  339.69
  56   0.0360     98.890  0.0178    99.402  345.81
  57   0.0377     98.740  0.0209    99.332  351.96
  58   0.0304     99.040  0.0203    99.370  358.17
  59   0.0268     99.190  0.0197    99.377  364.29
  60   0.0302     98.940  0.0177    99.437  370.41
  61   0.0321     98.900  0.0187    99.412  376.50
  62   0.0418     98.700  0.0171    99.440  382.64
  63   0.0309     98.990  0.0170    99.435  388.77
  64   0.0382     98.790  0.0172    99.433  394.98
  65   0.0256     99.140  0.0185    99.407  401.10
  66   0.0287     99.140  0.0177    99.420  407.24
  67   0.0308     98.940  0.0160    99.505  413.36
  68   0.0390     98.740  0.0168    99.460  419.50
  69   0.0335     98.950  0.0173    99.428  425.72
  70   0.0280     99.040  0.0159    99.525  431.85
  71   0.0331     99.010  0.0172    99.433  437.98
  72   0.0298     98.920  0.0163    99.468  444.09
  73   0.0369     98.860  0.0161    99.495  450.26
  74   0.0317     99.030  0.0152    99.500  456.51
  75   0.0292     99.050  0.0165    99.460  462.65
  76   0.0388     98.780  0.0158    99.467  468.78
  77   0.0290     99.100  0.0155    99.495  474.92
  78   0.0284     99.100  0.0167    99.452  481.06
  79   0.0323     99.080  0.0153    99.490  487.20
  80   0.0337     98.960  0.0152    99.505  493.42
  81   0.0331     98.880  0.0151    99.498  499.54
  82   0.0342     98.940  0.0149    99.508  505.69
  83   0.0306     99.110  0.0156    99.497  511.81
  84   0.0272     99.050  0.0145    99.548  517.93
  85   0.0354     98.790  0.0149    99.540  524.15
