Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2323     92.200  0.6473    78.685  7.65
   2   0.0897     97.050  0.1450    95.450  13.88
   3   0.0781     97.580  0.0904    97.145  19.98
   4   0.0528     98.240  0.0705    97.817  26.11
   5   0.0461     98.470  0.0601    98.138  32.23
   6   0.0630     97.890  0.0545    98.305  38.33
   7   0.0492     98.460  0.0484    98.528  44.44
   8   0.0478     98.490  0.0437    98.647  50.61
   9   0.0443     98.530  0.0412    98.722  56.75
  10   0.0394     98.710  0.0399    98.743  62.89
  11   0.0409     98.670  0.0383    98.773  69.04
  12   0.0388     98.650  0.0354    98.862  75.16
  13   0.0465     98.440  0.0355    98.857  81.27
  14   0.0503     98.350  0.0343    98.925  87.43
  15   0.0320     98.910  0.0333    98.960  93.55
  16   0.0418     98.560  0.0322    98.987  99.65
  17   0.0378     98.790  0.0325    98.957  105.77
  18   0.0398     98.650  0.0284    99.087  111.88
  19   0.0364     98.880  0.0298    99.050  118.07
  20   0.0408     98.680  0.0287    99.078  124.18
  21   0.0340     98.980  0.0292    99.082  130.27
  22   0.0372     98.730  0.0284    99.097  136.39
  23   0.0387     98.720  0.0263    99.155  142.50
  24   0.0329     98.900  0.0273    99.138  148.61
  25   0.0375     98.920  0.0250    99.207  154.83
  26   0.0310     99.030  0.0244    99.210  160.94
  27   0.0366     98.940  0.0237    99.237  167.11
  28   0.0411     98.670  0.0246    99.197  173.26
  29   0.0370     98.690  0.0257    99.185  179.37
  30   0.0312     98.880  0.0229    99.253  185.54
  31   0.0336     98.920  0.0235    99.237  191.66
  32   0.0559     98.300  0.0215    99.278  197.77
  33   0.0418     98.720  0.0226    99.293  203.91
  34   0.0352     98.890  0.0198    99.343  210.01
  35   0.0417     98.640  0.0226    99.287  216.12
  36   0.0371     98.810  0.0221    99.300  222.37
  37   0.0359     98.850  0.0208    99.327  228.50
  38   0.0319     98.890  0.0191    99.375  234.64
  39   0.0332     98.950  0.0204    99.340  240.75
  40   0.0389     98.760  0.0206    99.325  246.86
  41   0.0292     99.080  0.0204    99.318  253.08
  42   0.0302     98.980  0.0183    99.392  259.19
  43   0.0290     99.000  0.0163    99.453  265.30
  44   0.0306     99.030  0.0180    99.423  271.41
  45   0.0396     98.660  0.0182    99.382  277.52
  46   0.0374     98.740  0.0191    99.397  283.67
  47   0.0326     98.970  0.0174    99.433  289.77
  48   0.0325     98.940  0.0170    99.435  295.87
  49   0.0392     98.720  0.0173    99.427  301.97
  50   0.0383     98.710  0.0172    99.430  308.07
  51   0.0286     99.070  0.0146    99.525  314.17
  52   0.0320     99.070  0.0156    99.465  320.38
  53   0.0271     99.210  0.0163    99.477  326.49
  54   0.0373     98.810  0.0179    99.410  332.67
  55   0.0356     98.910  0.0171    99.455  338.79
  56   0.0431     98.660  0.0148    99.515  344.95
  57   0.0355     98.950  0.0162    99.475  351.05
  58   0.0301     99.050  0.0173    99.440  357.25
  59   0.0348     98.930  0.0142    99.522  363.36
  60   0.0300     99.120  0.0145    99.518  369.47
  61   0.0325     99.020  0.0149    99.528  375.61
  62   0.0287     99.090  0.0152    99.498  381.74
  63   0.0431     98.530  0.0142    99.555  387.86
  64   0.0232     99.240  0.0145    99.522  394.09
  65   0.0341     99.000  0.0147    99.517  400.21
  66   0.0332     99.020  0.0145    99.537  406.30
  67   0.0397     98.870  0.0127    99.565  412.42
  68   0.0343     98.920  0.0133    99.547  418.53
  69   0.0297     98.980  0.0135    99.562  424.64
  70   0.0289     98.990  0.0137    99.567  430.89
  71   0.0241     99.260  0.0145    99.530  437.02
  72   0.0308     99.160  0.0120    99.590  443.13
  73   0.0360     98.870  0.0117    99.633  449.24
  74   0.0369     98.830  0.0130    99.592  455.36
  75   0.0368     98.780  0.0144    99.515  461.47
  76   0.0336     99.000  0.0147    99.467  467.65
  77   0.0351     98.850  0.0160    99.443  473.75
  78   0.0342     99.010  0.0114    99.618  479.86
  79   0.0303     99.110  0.0108    99.668  486.02
  80   0.0337     99.000  0.0121    99.597  492.14
  81   0.0476     98.570  0.0128    99.558  498.25
  82   0.0424     98.840  0.0133    99.543  504.46
  83   0.0303     99.200  0.0125    99.593  510.56
  84   0.0337     98.970  0.0116    99.617  516.66
  85   0.0303     98.970  0.0103    99.658  522.78
  86   0.0249     99.200  0.0105    99.647  528.88
  87   0.0285     99.120  0.0104    99.670  535.05
  88   0.0322     99.040  0.0115    99.645  541.16
  89   0.0421     98.730  0.0118    99.617  547.29
  90   0.0263     99.140  0.0132    99.557  553.40
