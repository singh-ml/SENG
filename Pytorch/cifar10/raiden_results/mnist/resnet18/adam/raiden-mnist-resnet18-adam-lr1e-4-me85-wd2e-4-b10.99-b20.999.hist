Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2132     93.130  0.6385    78.838  7.70
   2   0.0944     97.060  0.1498    95.327  13.76
   3   0.0858     97.250  0.0950    97.065  19.84
   4   0.0755     97.410  0.0709    97.788  25.94
   5   0.0494     98.400  0.0598    98.173  32.01
   6   0.0562     98.170  0.0503    98.410  38.17
   7   0.0420     98.590  0.0493    98.465  44.27
   8   0.0441     98.620  0.0454    98.567  50.36
   9   0.0441     98.510  0.0441    98.618  56.41
  10   0.0360     98.900  0.0420    98.672  62.48
  11   0.0335     98.920  0.0368    98.840  68.56
  12   0.0404     98.750  0.0363    98.820  74.71
  13   0.0377     98.930  0.0376    98.833  80.77
  14   0.0436     98.510  0.0370    98.843  86.87
  15   0.0301     99.030  0.0341    98.978  92.95
  16   0.0431     98.580  0.0327    98.947  99.01
  17   0.0340     98.890  0.0314    99.020  105.09
  18   0.0581     98.150  0.0325    98.935  111.30
  19   0.0315     99.070  0.0305    99.028  117.38
  20   0.0479     98.420  0.0298    99.092  123.44
  21   0.0374     98.720  0.0312    98.973  129.51
  22   0.0380     98.770  0.0280    99.107  135.59
  23   0.0281     98.990  0.0273    99.103  141.68
  24   0.0286     99.030  0.0280    99.097  147.88
  25   0.0395     98.850  0.0258    99.183  153.97
  26   0.0325     99.020  0.0251    99.185  160.05
  27   0.0282     99.030  0.0265    99.150  166.11
  28   0.0372     98.870  0.0247    99.203  172.18
  29   0.0329     98.930  0.0260    99.162  178.31
  30   0.0330     98.930  0.0239    99.217  184.51
  31   0.0435     98.460  0.0243    99.248  190.58
  32   0.0415     98.760  0.0260    99.132  196.67
  33   0.0320     98.940  0.0229    99.278  202.76
  34   0.0283     99.020  0.0249    99.198  208.81
  35   0.0392     98.730  0.0235    99.242  214.87
  36   0.0280     99.130  0.0237    99.240  221.08
  37   0.0269     99.030  0.0233    99.268  227.20
  38   0.0275     99.060  0.0215    99.337  233.26
  39   0.0287     98.980  0.0214    99.307  239.34
  40   0.0309     99.120  0.0201    99.382  245.42
  41   0.0262     99.150  0.0207    99.362  251.55
  42   0.0310     99.020  0.0199    99.362  257.65
  43   0.0397     98.850  0.0198    99.355  263.72
  44   0.0280     99.000  0.0205    99.367  269.79
  45   0.0284     98.990  0.0197    99.363  275.86
  46   0.0279     99.150  0.0210    99.300  281.95
  47   0.0304     99.050  0.0183    99.415  288.15
  48   0.0305     98.980  0.0206    99.348  294.25
  49   0.0308     99.080  0.0193    99.365  300.33
  50   0.0329     98.870  0.0185    99.393  306.39
  51   0.0329     99.040  0.0194    99.392  312.46
  52   0.0411     98.710  0.0199    99.378  318.66
  53   0.0343     98.970  0.0197    99.377  324.76
  54   0.0369     98.830  0.0179    99.437  330.80
  55   0.0420     98.650  0.0172    99.445  336.86
  56   0.0405     98.780  0.0177    99.432  342.95
  57   0.0306     98.950  0.0182    99.427  349.01
  58   0.0260     99.200  0.0180    99.432  355.15
  59   0.0232     99.220  0.0170    99.458  361.21
  60   0.0398     98.790  0.0197    99.385  367.29
  61   0.0295     99.080  0.0180    99.442  373.37
  62   0.0302     99.040  0.0175    99.427  379.46
  63   0.0320     98.930  0.0170    99.462  385.63
  64   0.0370     98.800  0.0168    99.470  391.69
  65   0.0264     99.180  0.0192    99.393  397.76
  66   0.0338     98.860  0.0170    99.470  403.82
  67   0.0262     99.240  0.0162    99.470  409.90
  68   0.0350     98.900  0.0142    99.577  415.98
  69   0.0349     98.940  0.0140    99.540  422.14
  70   0.0339     98.980  0.0157    99.525  428.22
  71   0.0298     99.010  0.0170    99.473  434.30
  72   0.0287     99.080  0.0174    99.425  440.39
  73   0.0369     98.960  0.0146    99.548  446.47
  74   0.0311     98.990  0.0141    99.573  452.54
  75   0.0427     98.690  0.0136    99.565  458.71
  76   0.0322     99.040  0.0166    99.485  464.80
  77   0.0254     99.230  0.0158    99.492  470.87
  78   0.0318     99.100  0.0154    99.510  476.95
  79   0.0307     99.050  0.0145    99.538  483.03
  80   0.0290     99.170  0.0132    99.592  489.10
  81   0.0248     99.240  0.0140    99.555  495.33
  82   0.0399     98.750  0.0135    99.563  501.41
  83   0.0240     99.240  0.0131    99.563  507.50
  84   0.0314     99.090  0.0151    99.527  513.57
  85   0.0291     99.080  0.0146    99.535  519.63
