Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2136     93.100  0.2614    91.302  7.64
   2   0.1604     94.690  0.1142    96.513  13.90
   3   0.1474     95.660  0.1031    96.907  19.99
   4   0.2545     91.810  0.0913    97.232  26.13
   5   0.1018     96.960  0.0857    97.450  32.20
   6   0.1145     96.650  0.0775    97.695  38.27
   7   0.1534     95.160  0.0731    97.817  44.34
   8   0.1145     96.630  0.0697    97.912  50.52
   9   0.1004     96.770  0.0644    98.032  56.60
  10   0.0626     98.080  0.0616    98.175  62.69
  11   0.0469     98.460  0.0592    98.182  68.79
  12   0.0720     97.820  0.0573    98.350  74.88
  13   0.0698     97.920  0.0554    98.308  81.00
  14   0.0526     98.140  0.0541    98.383  87.18
  15   0.0452     98.590  0.0522    98.472  93.26
  16   0.0506     98.310  0.0496    98.505  99.32
  17   0.0706     97.880  0.0524    98.430  105.40
  18   0.0549     98.270  0.0484    98.528  111.49
  19   0.0455     98.600  0.0493    98.552  117.58
  20   0.0448     98.600  0.0494    98.528  123.82
  21   0.0769     97.470  0.0453    98.653  129.93
  22   0.0689     97.720  0.0458    98.643  136.00
  23   0.0614     98.100  0.0446    98.663  142.09
  24   0.0533     98.320  0.0455    98.590  148.18
  25   0.0548     98.390  0.0435    98.728  154.27
  26   0.0351     98.910  0.0444    98.665  160.45
  27   0.0333     98.970  0.0433    98.682  166.55
  28   0.0398     98.780  0.0422    98.708  172.65
  29   0.0565     98.260  0.0428    98.743  178.72
  30   0.0488     98.510  0.0430    98.667  184.80
  31   0.0422     98.590  0.0417    98.758  190.90
  32   0.0435     98.640  0.0407    98.758  197.09
  33   0.0495     98.480  0.0404    98.798  203.18
  34   0.0458     98.480  0.0420    98.718  209.28
  35   0.0604     98.030  0.0399    98.828  215.36
  36   0.0360     98.810  0.0403    98.822  221.45
  37   0.0466     98.420  0.0409    98.797  227.64
  38   0.0409     98.820  0.0404    98.832  233.72
  39   0.0523     98.410  0.0384    98.842  239.83
  40   0.0518     98.360  0.0391    98.870  245.92
  41   0.0389     98.790  0.0395    98.807  252.01
  42   0.0395     98.750  0.0396    98.798  258.22
  43   0.0329     98.880  0.0385    98.825  264.30
  44   0.0463     98.450  0.0384    98.853  270.38
  45   0.0402     98.760  0.0382    98.888  276.45
  46   0.0449     98.650  0.0386    98.837  282.59
  47   0.0413     98.470  0.0368    98.875  288.72
  48   0.0476     98.430  0.0374    98.853  294.91
  49   0.0504     98.630  0.0359    98.932  301.00
  50   0.0515     98.400  0.0375    98.863  307.07
  51   0.0521     98.410  0.0364    98.915  313.16
  52   0.0380     98.820  0.0373    98.838  319.24
  53   0.0329     98.990  0.0366    98.895  325.43
  54   0.0355     98.970  0.0356    98.962  331.53
  55   0.0337     98.890  0.0380    98.840  337.59
  56   0.0414     98.710  0.0366    98.893  343.67
  57   0.0435     98.700  0.0363    98.865  349.77
  58   0.0658     97.850  0.0356    98.942  355.84
  59   0.0520     98.260  0.0368    98.857  361.92
  60   0.0446     98.500  0.0360    98.923  368.01
  61   0.0545     98.220  0.0357    98.962  374.08
  62   0.0404     98.690  0.0366    98.920  380.17
  63   0.0302     99.030  0.0355    98.897  386.26
  64   0.0625     97.770  0.0364    98.900  392.36
  65   0.0366     98.840  0.0352    98.938  398.45
  66   0.0493     98.440  0.0358    98.905  404.53
  67   0.0561     98.170  0.0354    98.952  410.59
  68   0.0420     98.740  0.0350    98.918  416.65
  69   0.0386     98.810  0.0355    98.970  422.75
  70   0.0408     98.720  0.0340    98.942  428.87
  71   0.0545     98.220  0.0334    99.005  435.06
  72   0.0356     98.860  0.0347    98.970  441.15
  73   0.0443     98.520  0.0351    98.927  447.24
  74   0.0414     98.790  0.0344    98.988  453.35
  75   0.0339     98.980  0.0352    98.887  459.45
  76   0.0321     98.990  0.0351    98.922  465.53
  77   0.0426     98.570  0.0344    98.938  471.70
  78   0.0381     98.780  0.0343    98.960  477.77
  79   0.0457     98.560  0.0346    98.927  483.85
  80   0.0545     98.490  0.0342    98.947  489.92
  81   0.0409     98.760  0.0354    98.923  496.00
  82   0.0325     98.980  0.0350    98.953  502.20
  83   0.0621     97.950  0.0349    98.960  508.29
  84   0.0322     98.950  0.0347    98.963  514.38
  85   0.0313     98.970  0.0345    98.960  520.47
  86   0.0479     98.300  0.0348    98.997  526.55
  87   0.0373     98.910  0.0345    98.943  532.71
  88   0.0405     98.760  0.0332    99.012  538.81
  89   0.0409     98.650  0.0335    98.968  544.91
  90   0.0315     98.880  0.0342    98.942  550.99
