Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1233     95.880  0.3220    89.330  7.87
   2   0.0646     97.930  0.1012    96.823  13.96
   3   0.0672     97.690  0.0735    97.720  20.06
   4   0.0660     97.850  0.0657    97.910  26.17
   5   0.0567     97.990  0.0637    98.040  32.27
   6   0.0382     98.790  0.0622    98.077  38.38
   7   0.0511     98.210  0.0541    98.267  44.60
   8   0.0514     98.360  0.0527    98.383  50.68
   9   0.0593     98.030  0.0492    98.458  56.78
  10   0.0476     98.480  0.0479    98.507  62.93
  11   0.0387     98.750  0.0451    98.617  69.06
  12   0.0498     98.410  0.0483    98.507  75.23
  13   0.0518     98.170  0.0476    98.545  81.36
  14   0.0491     98.260  0.0432    98.617  87.45
  15   0.0445     98.520  0.0459    98.530  93.55
  16   0.0517     98.310  0.0409    98.698  99.64
  17   0.0313     98.880  0.0421    98.657  105.76
  18   0.0376     98.910  0.0429    98.638  111.93
  19   0.0382     98.850  0.0445    98.560  118.05
  20   0.0467     98.470  0.0405    98.745  124.15
  21   0.0287     99.140  0.0375    98.837  130.24
  22   0.0305     98.930  0.0370    98.797  136.38
  23   0.0313     98.980  0.0366    98.823  142.49
  24   0.0362     98.780  0.0353    98.923  148.71
  25   0.0417     98.700  0.0357    98.862  154.81
  26   0.0379     98.860  0.0370    98.798  160.93
  27   0.0375     98.840  0.0355    98.880  167.06
  28   0.0324     99.040  0.0352    98.903  173.16
  29   0.0296     99.080  0.0312    99.008  179.25
  30   0.0289     99.130  0.0314    99.008  185.42
  31   0.0340     98.880  0.0329    98.960  191.52
  32   0.0307     99.030  0.0368    98.822  197.62
  33   0.0414     98.640  0.0335    98.997  203.71
  34   0.0370     98.970  0.0320    98.958  209.80
  35   0.0351     98.840  0.0326    98.965  215.90
  36   0.0345     98.850  0.0305    99.013  222.08
  37   0.0377     98.790  0.0285    99.098  228.18
  38   0.0294     99.040  0.0293    99.102  234.29
  39   0.0350     98.800  0.0284    99.060  240.40
  40   0.0271     99.110  0.0302    99.035  246.51
  41   0.0304     98.970  0.0297    99.030  252.72
  42   0.0271     99.070  0.0270    99.113  258.83
  43   0.0449     98.450  0.0299    99.047  264.93
  44   0.0368     98.860  0.0292    99.090  271.01
  45   0.0282     99.080  0.0248    99.173  277.09
  46   0.0313     98.980  0.0288    99.078  283.32
  47   0.0338     98.820  0.0249    99.172  289.43
  48   0.0337     98.980  0.0259    99.198  295.53
  49   0.0354     98.900  0.0243    99.210  301.63
  50   0.0345     98.930  0.0249    99.160  307.73
  51   0.0317     99.000  0.0234    99.240  313.84
  52   0.0277     99.180  0.0237    99.227  320.03
  53   0.0277     99.060  0.0229    99.287  326.13
  54   0.0281     99.140  0.0236    99.257  332.31
  55   0.0343     98.890  0.0235    99.250  338.42
  56   0.0339     98.860  0.0240    99.230  344.52
  57   0.0354     98.840  0.0237    99.230  350.77
  58   0.0306     98.960  0.0218    99.278  356.90
  59   0.0307     99.000  0.0195    99.388  363.01
  60   0.0262     99.120  0.0217    99.303  369.12
  61   0.0285     99.030  0.0231    99.242  375.23
  62   0.0356     98.890  0.0249    99.198  381.45
  63   0.0220     99.230  0.0218    99.362  387.56
  64   0.0315     98.960  0.0211    99.338  393.70
  65   0.0288     99.140  0.0220    99.282  399.80
  66   0.0415     98.780  0.0203    99.368  405.92
  67   0.0245     99.170  0.0215    99.302  412.02
  68   0.0370     98.900  0.0228    99.228  418.22
  69   0.0342     98.800  0.0208    99.312  424.34
  70   0.0302     99.070  0.0196    99.357  430.45
  71   0.0306     98.960  0.0193    99.383  436.57
  72   0.0264     99.110  0.0199    99.345  442.66
  73   0.0311     99.090  0.0222    99.260  448.78
  74   0.0281     99.020  0.0209    99.348  454.91
  75   0.0262     99.180  0.0202    99.345  461.11
  76   0.0310     99.010  0.0202    99.330  467.22
  77   0.0435     98.650  0.0194    99.375  473.33
  78   0.0363     98.930  0.0219    99.308  479.43
  79   0.0260     99.160  0.0188    99.412  485.57
  80   0.0247     99.130  0.0186    99.427  491.73
  81   0.0298     99.040  0.0187    99.403  497.83
  82   0.0304     99.010  0.0183    99.403  503.92
  83   0.0380     98.720  0.0172    99.435  510.01
  84   0.0311     99.110  0.0174    99.400  516.10
  85   0.0295     99.010  0.0175    99.452  522.22
  86   0.0302     99.010  0.0195    99.343  528.41
  87   0.0246     99.160  0.0159    99.487  534.53
  88   0.0231     99.210  0.0174    99.397  540.65
  89   0.0320     98.910  0.0170    99.413  546.76
  90   0.0268     99.010  0.0183    99.415  552.90
