Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1685     66.580  1.0896    62.157  7.72
   2   0.1948     93.930  0.2338    92.615  13.75
   3   0.1593     94.770  0.1431    95.588  19.79
   4   0.1188     96.050  0.1150    96.367  25.83
   5   0.1072     96.720  0.1059    96.740  31.96
   6   0.1004     96.820  0.0962    97.102  37.99
   7   0.1436     95.190  0.0906    97.188  44.05
   8   0.1820     94.740  0.0868    97.343  50.08
   9   0.2105     93.300  0.0878    97.332  56.14
  10   0.1216     95.880  0.0840    97.452  62.25
  11   0.1501     95.380  0.0826    97.465  68.28
  12   0.2388     92.570  0.0814    97.533  74.32
  13   0.1005     96.800  0.0789    97.623  80.34
  14   0.0904     97.000  0.0771    97.650  86.45
  15   0.1197     96.170  0.0761    97.622  92.49
  16   0.0845     97.290  0.0746    97.692  98.64
  17   0.1006     96.630  0.0779    97.585  104.70
  18   0.1082     96.600  0.0779    97.638  110.75
  19   0.1159     96.380  0.0781    97.607  116.79
  20   0.2001     93.230  0.0771    97.657  122.88
  21   0.1840     94.370  0.0763    97.672  128.92
  22   0.1138     96.420  0.0740    97.713  135.06
  23   0.1112     96.460  0.0782    97.628  141.12
  24   0.1084     96.760  0.0740    97.718  147.18
  25   0.0957     96.880  0.0737    97.772  153.22
  26   0.0898     97.190  0.0734    97.725  159.28
  27   0.0698     97.840  0.0727    97.772  165.33
  28   0.1137     96.660  0.0740    97.735  171.45
  29   0.0679     97.840  0.0724    97.808  177.49
  30   0.0974     96.930  0.0734    97.753  183.55
  31   0.0949     96.860  0.0715    97.823  189.61
  32   0.1074     96.860  0.0703    97.847  195.66
  33   0.0549     98.210  0.0723    97.760  201.70
  34   0.0960     96.900  0.0719    97.805  207.83
  35   0.0939     97.280  0.0705    97.870  213.86
  36   0.1041     96.730  0.0709    97.812  219.94
  37   0.1022     97.000  0.0701    97.798  226.00
  38   0.0738     97.790  0.0718    97.772  232.05
  39   0.0661     97.920  0.0732    97.757  238.20
  40   0.0849     97.350  0.0721    97.808  244.25
  41   0.1065     96.690  0.0716    97.710  250.30
  42   0.0800     97.420  0.0701    97.817  256.34
  43   0.0876     97.140  0.0687    97.845  262.42
  44   0.0987     96.930  0.0711    97.842  268.49
  45   0.0759     97.590  0.0685    97.855  274.65
  46   0.0809     97.410  0.0716    97.793  280.70
  47   0.0897     97.250  0.0700    97.773  286.76
  48   0.1257     95.680  0.0731    97.815  292.80
  49   0.0797     97.550  0.0713    97.838  298.85
  50   0.0744     97.620  0.0693    97.878  305.01
  51   0.0823     97.350  0.0735    97.728  311.06
  52   0.0852     97.250  0.0712    97.812  317.11
  53   0.0784     97.380  0.0710    97.765  323.16
  54   0.0893     97.190  0.0712    97.858  329.21
  55   0.0655     97.790  0.0701    97.797  335.26
  56   0.1147     96.260  0.0740    97.762  341.37
  57   0.0757     97.640  0.0672    97.917  347.43
  58   0.0634     97.860  0.0685    97.933  353.47
  59   0.0892     97.180  0.0693    97.893  359.48
  60   0.0746     97.480  0.0696    97.903  365.54
  61   0.0742     97.660  0.0732    97.712  371.69
  62   0.0778     97.570  0.0700    97.910  377.73
  63   0.1224     96.110  0.0696    97.910  383.78
  64   0.0623     97.950  0.0705    97.847  389.89
  65   0.0595     98.180  0.0708    97.782  395.93
  66   0.0721     97.800  0.0712    97.818  401.98
  67   0.0808     97.540  0.0703    97.837  408.04
  68   0.0845     97.250  0.0684    97.818  414.18
  69   0.1641     94.600  0.0704    97.813  420.21
  70   0.0798     97.410  0.0712    97.828  426.26
  71   0.0706     97.830  0.0694    97.908  432.34
  72   0.0572     97.990  0.0699    97.795  438.38
  73   0.0993     96.790  0.0695    97.872  444.43
  74   0.1320     96.040  0.0726    97.837  450.52
  75   0.1093     96.330  0.0706    97.863  456.57
  76   0.0820     97.430  0.0696    97.890  462.61
  77   0.0771     97.280  0.0721    97.787  468.66
  78   0.0873     97.360  0.0715    97.798  474.73
  79   0.0866     97.280  0.0702    97.882  480.77
  80   0.0713     97.830  0.0698    97.853  486.91
  81   0.0985     96.540  0.0706    97.815  492.93
  82   0.0776     97.650  0.0711    97.838  498.99
  83   0.0873     97.130  0.0726    97.842  505.03
  84   0.1060     96.560  0.0704    97.875  511.07
  85   0.1097     96.470  0.0693    97.863  517.12
