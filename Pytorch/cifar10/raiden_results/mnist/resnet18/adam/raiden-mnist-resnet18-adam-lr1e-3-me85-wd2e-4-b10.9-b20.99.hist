Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.4734     85.660  0.2559    91.588  7.78
   2   0.2168     92.990  0.1021    96.800  13.86
   3   0.3325     89.880  0.0903    97.235  19.93
   4   0.1534     95.100  0.0820    97.480  26.00
   5   0.0781     97.530  0.0751    97.677  32.10
   6   0.0723     97.770  0.0712    97.790  38.26
   7   0.1445     95.500  0.0680    97.945  44.33
   8   0.1720     94.320  0.0628    98.037  50.39
   9   0.0619     98.080  0.0588    98.157  56.53
  10   0.0602     98.220  0.0573    98.263  62.62
  11   0.0444     98.600  0.0541    98.300  68.70
  12   0.0539     98.350  0.0527    98.377  74.85
  13   0.0499     98.480  0.0507    98.458  80.92
  14   0.0426     98.600  0.0497    98.502  87.01
  15   0.0618     98.080  0.0486    98.605  93.09
  16   0.0721     97.900  0.0500    98.443  99.17
  17   0.0627     98.040  0.0463    98.612  105.35
  18   0.0492     98.380  0.0451    98.623  111.43
  19   0.0429     98.700  0.0436    98.640  117.53
  20   0.0529     98.060  0.0425    98.638  123.61
  21   0.0533     98.230  0.0436    98.652  129.72
  22   0.0356     98.820  0.0404    98.735  135.83
  23   0.0551     98.150  0.0390    98.752  141.91
  24   0.0566     98.210  0.0411    98.735  148.02
  25   0.0520     98.400  0.0398    98.815  154.13
  26   0.0509     98.310  0.0380    98.797  160.22
  27   0.0493     98.400  0.0382    98.815  166.30
  28   0.0438     98.580  0.0382    98.852  172.48
  29   0.0374     98.880  0.0372    98.840  178.57
  30   0.0576     98.110  0.0359    98.917  184.68
  31   0.0400     98.610  0.0379    98.840  190.76
  32   0.0451     98.600  0.0352    98.888  196.85
  33   0.0303     99.090  0.0362    98.883  203.02
  34   0.0333     99.020  0.0354    98.870  209.17
  35   0.0343     98.930  0.0337    98.935  215.27
  36   0.0405     98.630  0.0340    98.955  221.35
  37   0.0493     98.540  0.0345    98.908  227.44
  38   0.0534     98.220  0.0340    98.950  233.55
  39   0.0425     98.490  0.0342    98.948  239.64
  40   0.0379     98.710  0.0337    98.978  245.82
  41   0.0425     98.640  0.0345    98.933  251.93
  42   0.0433     98.560  0.0320    99.042  258.02
  43   0.0448     98.550  0.0313    99.017  264.11
  44   0.0382     98.750  0.0342    98.958  270.22
  45   0.0486     98.370  0.0321    99.040  276.31
  46   0.0453     98.510  0.0336    98.927  282.54
  47   0.0392     98.790  0.0317    99.008  288.65
  48   0.0347     98.990  0.0312    99.043  294.74
  49   0.0334     98.880  0.0330    98.980  300.83
  50   0.0384     98.700  0.0306    99.063  306.92
  51   0.0614     97.960  0.0325    98.970  313.03
  52   0.0369     98.810  0.0314    99.030  319.24
  53   0.0702     97.590  0.0313    99.057  325.33
  54   0.0346     98.920  0.0312    99.055  331.43
  55   0.0317     98.920  0.0298    99.075  337.51
  56   0.0387     98.750  0.0297    99.110  343.60
  57   0.0456     98.560  0.0303    99.058  349.79
  58   0.0385     98.810  0.0305    99.030  355.87
  59   0.0433     98.470  0.0315    99.037  361.98
  60   0.0375     98.850  0.0284    99.068  368.08
  61   0.0301     99.050  0.0304    99.065  374.17
  62   0.0680     97.730  0.0300    99.052  380.36
  63   0.0406     98.580  0.0289    99.095  386.45
  64   0.0272     99.150  0.0289    99.080  392.55
  65   0.0458     98.460  0.0294    99.080  398.65
  66   0.0351     98.790  0.0289    99.127  404.72
  67   0.0283     99.100  0.0290    99.108  410.81
  68   0.0324     98.980  0.0292    99.095  417.02
  69   0.0353     98.790  0.0278    99.142  423.12
  70   0.0341     98.920  0.0295    99.090  429.24
  71   0.0446     98.540  0.0285    99.115  435.31
  72   0.0284     99.040  0.0290    99.108  441.41
  73   0.0383     98.720  0.0285    99.102  447.60
  74   0.0364     98.910  0.0281    99.150  453.77
  75   0.0353     98.910  0.0282    99.120  459.89
  76   0.0351     98.810  0.0276    99.177  465.98
  77   0.0313     98.970  0.0276    99.133  472.06
  78   0.0349     98.900  0.0279    99.098  478.15
  79   0.0693     97.820  0.0275    99.122  484.37
  80   0.0336     98.980  0.0274    99.155  490.47
  81   0.0389     98.730  0.0270    99.133  496.60
  82   0.0396     98.730  0.0257    99.213  502.70
  83   0.0322     98.900  0.0266    99.195  508.82
  84   0.0447     98.470  0.0266    99.167  514.99
  85   0.0339     98.870  0.0276    99.115  521.08
