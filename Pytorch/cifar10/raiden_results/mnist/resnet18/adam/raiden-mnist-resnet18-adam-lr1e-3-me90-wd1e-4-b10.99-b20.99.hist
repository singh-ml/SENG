Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1766     94.580  0.3155    89.547  7.65
   2   0.1094     96.590  0.1103    96.538  13.74
   3   0.0833     97.350  0.0928    97.112  19.94
   4   0.0812     97.680  0.0768    97.580  26.02
   5   0.0697     97.880  0.0696    97.845  32.10
   6   0.0736     97.710  0.0676    97.958  38.20
   7   0.0515     98.390  0.0613    98.068  44.30
   8   0.0699     97.860  0.0569    98.222  50.39
   9   0.0648     97.970  0.0571    98.220  56.50
  10   0.0884     97.140  0.0553    98.352  62.60
  11   0.0616     98.170  0.0532    98.392  68.71
  12   0.0578     98.050  0.0514    98.408  74.80
  13   0.0415     98.650  0.0504    98.427  80.87
  14   0.0479     98.420  0.0456    98.562  87.07
  15   0.0329     98.950  0.0425    98.643  93.16
  16   0.0393     98.590  0.0469    98.603  99.24
  17   0.0280     99.050  0.0403    98.770  105.32
  18   0.0378     98.740  0.0393    98.775  111.45
  19   0.0343     98.920  0.0399    98.737  117.62
  20   0.0345     98.830  0.0399    98.722  123.71
  21   0.0422     98.660  0.0397    98.768  129.78
  22   0.0399     98.730  0.0376    98.818  135.88
  23   0.0371     98.760  0.0374    98.853  141.95
  24   0.0470     98.360  0.0377    98.840  148.05
  25   0.0361     98.820  0.0375    98.818  154.23
  26   0.0356     98.800  0.0339    98.947  160.32
  27   0.0307     99.030  0.0347    98.907  166.46
  28   0.0264     99.110  0.0335    98.942  172.57
  29   0.0315     98.960  0.0325    98.982  178.65
  30   0.0321     99.060  0.0329    98.993  184.84
  31   0.0349     98.900  0.0304    99.058  191.00
  32   0.0433     98.490  0.0323    98.982  197.14
  33   0.0301     98.960  0.0314    98.990  203.25
  34   0.0323     98.930  0.0293    99.052  209.35
  35   0.0336     98.910  0.0317    98.955  215.55
  36   0.0314     98.870  0.0306    99.040  221.64
  37   0.0359     98.790  0.0303    99.017  227.73
  38   0.0303     98.880  0.0298    99.088  233.82
  39   0.0329     98.910  0.0292    99.060  239.92
  40   0.0251     99.190  0.0283    99.095  246.02
  41   0.0340     98.870  0.0272    99.150  252.21
  42   0.0320     98.870  0.0275    99.135  258.31
  43   0.0333     99.060  0.0270    99.145  264.38
  44   0.0333     98.870  0.0262    99.202  270.47
  45   0.0362     98.810  0.0279    99.100  276.56
  46   0.0296     99.080  0.0279    99.153  282.66
  47   0.0379     98.700  0.0266    99.140  288.77
  48   0.0460     98.540  0.0270    99.118  294.95
  49   0.0292     99.130  0.0272    99.133  301.03
  50   0.0343     98.990  0.0274    99.137  307.13
  51   0.0384     98.810  0.0260    99.177  313.21
  52   0.0340     98.870  0.0266    99.112  319.33
  53   0.0249     99.180  0.0260    99.167  325.47
  54   0.0252     99.200  0.0258    99.158  331.56
  55   0.0285     99.000  0.0247    99.215  337.64
  56   0.0389     98.720  0.0257    99.167  343.74
  57   0.0401     98.650  0.0237    99.215  349.84
  58   0.0330     98.920  0.0256    99.147  355.92
  59   0.0271     99.110  0.0246    99.208  362.13
  60   0.0350     98.890  0.0237    99.267  368.23
  61   0.0447     98.530  0.0262    99.187  374.33
  62   0.0362     98.860  0.0233    99.267  380.41
  63   0.0380     98.870  0.0229    99.253  386.51
  64   0.0386     98.740  0.0234    99.240  392.74
  65   0.0303     99.060  0.0249    99.222  398.82
  66   0.0306     98.920  0.0230    99.270  404.89
  67   0.0424     98.580  0.0230    99.280  410.96
  68   0.0321     98.930  0.0230    99.262  417.06
  69   0.0322     98.940  0.0226    99.268  423.13
  70   0.0354     98.820  0.0250    99.197  429.29
  71   0.0290     99.070  0.0224    99.265  435.39
  72   0.0297     99.080  0.0231    99.270  441.48
  73   0.0387     98.760  0.0238    99.248  447.59
  74   0.0354     98.790  0.0223    99.252  453.73
  75   0.0272     99.060  0.0228    99.238  459.93
  76   0.0241     99.220  0.0215    99.273  466.06
  77   0.0419     98.650  0.0222    99.290  472.24
  78   0.0467     98.560  0.0212    99.305  478.31
  79   0.0288     99.070  0.0217    99.303  484.42
  80   0.0234     99.190  0.0219    99.290  490.51
  81   0.0318     98.910  0.0221    99.273  496.69
  82   0.0264     99.030  0.0216    99.288  502.79
  83   0.0330     98.920  0.0227    99.285  508.88
  84   0.0305     98.970  0.0215    99.333  514.98
  85   0.0302     98.950  0.0221    99.298  521.06
  86   0.0294     98.990  0.0202    99.350  527.24
  87   0.0330     98.940  0.0198    99.357  533.33
  88   0.0316     99.040  0.0222    99.258  539.42
  89   0.0265     99.220  0.0225    99.297  545.51
  90   0.0339     98.800  0.0215    99.278  551.61
