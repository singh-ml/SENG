Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2856     57.860  0.6347    78.400  7.65
   2   0.2023     93.120  0.1905    93.975  13.72
   3   0.1268     96.120  0.1350    95.798  19.91
   4   0.0989     97.090  0.1096    96.640  25.98
   5   0.2114     93.160  0.0960    97.043  32.06
   6   0.1394     95.360  0.0844    97.442  38.17
   7   0.1064     96.420  0.0842    97.460  44.23
   8   0.0781     97.630  0.0769    97.625  50.30
   9   0.1077     96.660  0.0719    97.817  56.44
  10   0.0693     97.750  0.0678    97.872  62.59
  11   0.0677     97.730  0.0681    97.858  68.67
  12   0.0518     98.370  0.0651    98.040  74.76
  13   0.0609     98.000  0.0618    98.053  80.82
  14   0.0474     98.350  0.0585    98.215  87.01
  15   0.0557     98.210  0.0615    98.110  93.09
  16   0.0704     97.750  0.0583    98.165  99.16
  17   0.0676     97.870  0.0578    98.245  105.25
  18   0.0765     97.840  0.0572    98.207  111.33
  19   0.0631     97.880  0.0577    98.202  117.52
  20   0.0691     97.840  0.0556    98.262  123.57
  21   0.0557     98.280  0.0578    98.200  129.64
  22   0.0499     98.350  0.0571    98.283  135.72
  23   0.0564     98.260  0.0576    98.260  141.82
  24   0.0469     98.380  0.0522    98.418  147.91
  25   0.0902     97.090  0.0574    98.267  154.09
  26   0.0620     98.140  0.0536    98.352  160.18
  27   0.0550     98.110  0.0518    98.363  166.28
  28   0.0669     97.810  0.0530    98.383  172.39
  29   0.0621     98.010  0.0528    98.355  178.49
  30   0.0682     97.830  0.0513    98.452  184.56
  31   0.0519     98.300  0.0515    98.318  190.75
  32   0.0446     98.600  0.0528    98.378  196.82
  33   0.0649     98.080  0.0498    98.467  202.90
  34   0.0704     97.840  0.0513    98.412  208.97
  35   0.0540     98.200  0.0534    98.323  215.08
  36   0.0780     97.590  0.0516    98.368  221.16
  37   0.0629     98.020  0.0485    98.507  227.23
  38   0.0524     98.320  0.0530    98.348  233.42
  39   0.0556     98.270  0.0528    98.363  239.50
  40   0.0449     98.490  0.0483    98.503  245.58
  41   0.0474     98.510  0.0503    98.438  251.65
  42   0.0629     97.920  0.0508    98.383  257.75
  43   0.0482     98.540  0.0483    98.425  263.96
  44   0.0522     98.320  0.0509    98.440  270.03
  45   0.0518     98.340  0.0496    98.495  276.13
  46   0.0577     98.200  0.0484    98.558  282.21
  47   0.0567     98.150  0.0472    98.532  288.28
  48   0.0437     98.530  0.0511    98.415  294.37
  49   0.0444     98.650  0.0476    98.582  300.55
  50   0.0639     97.810  0.0479    98.527  306.63
  51   0.0571     98.160  0.0483    98.522  312.71
  52   0.0401     98.640  0.0486    98.523  318.80
  53   0.0485     98.440  0.0471    98.568  324.88
  54   0.0425     98.540  0.0478    98.550  331.10
  55   0.0465     98.510  0.0494    98.468  337.25
  56   0.0616     98.050  0.0482    98.497  343.34
  57   0.0595     98.240  0.0480    98.512  349.41
  58   0.0464     98.480  0.0500    98.465  355.51
  59   0.0534     98.270  0.0504    98.388  361.60
  60   0.0569     98.170  0.0471    98.513  367.77
  61   0.0530     98.250  0.0484    98.483  373.84
  62   0.0635     97.730  0.0456    98.640  379.93
  63   0.0470     98.500  0.0465    98.568  386.00
  64   0.0488     98.440  0.0485    98.530  392.09
  65   0.0465     98.610  0.0491    98.490  398.24
  66   0.0478     98.510  0.0456    98.588  404.33
  67   0.0547     98.380  0.0458    98.595  410.39
  68   0.0530     98.210  0.0477    98.495  416.46
  69   0.0433     98.530  0.0474    98.528  422.51
  70   0.0603     97.960  0.0448    98.567  428.58
  71   0.0500     98.540  0.0479    98.525  434.66
  72   0.0451     98.590  0.0469    98.558  440.75
  73   0.0422     98.630  0.0457    98.533  446.84
  74   0.0807     97.640  0.0463    98.547  452.91
  75   0.0627     97.920  0.0465    98.558  458.99
  76   0.0473     98.460  0.0475    98.445  465.05
  77   0.0465     98.470  0.0459    98.593  471.24
  78   0.0523     98.270  0.0474    98.537  477.33
  79   0.0641     97.950  0.0471    98.537  483.42
  80   0.0506     98.410  0.0482    98.503  489.51
  81   0.0442     98.590  0.0454    98.547  495.60
  82   0.0468     98.450  0.0452    98.535  501.73
  83   0.0443     98.460  0.0491    98.448  507.80
  84   0.0542     98.290  0.0487    98.513  513.89
  85   0.0415     98.530  0.0467    98.555  519.97
  86   0.0673     97.940  0.0446    98.625  526.06
  87   0.0480     98.450  0.0466    98.528  532.14
  88   0.0403     98.700  0.0475    98.507  538.29
  89   0.0505     98.380  0.0456    98.590  544.36
  90   0.0529     98.300  0.0467    98.535  550.45
