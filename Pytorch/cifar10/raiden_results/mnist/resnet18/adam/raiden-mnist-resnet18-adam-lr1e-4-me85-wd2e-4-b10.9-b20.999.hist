Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1578     94.940  0.5083    83.520  7.67
   2   0.0810     97.340  0.1140    96.420  13.72
   3   0.0765     97.400  0.0809    97.490  19.77
   4   0.0780     97.580  0.0641    98.023  25.83
   5   0.0516     98.250  0.0577    98.217  31.89
   6   0.0527     98.160  0.0523    98.335  37.96
   7   0.0767     97.590  0.0456    98.602  44.09
   8   0.0453     98.500  0.0451    98.548  50.16
   9   0.0597     97.980  0.0420    98.702  56.23
  10   0.0433     98.490  0.0398    98.733  62.28
  11   0.0346     98.800  0.0387    98.772  68.35
  12   0.0549     98.100  0.0391    98.763  74.41
  13   0.0573     98.070  0.0368    98.845  80.55
  14   0.0475     98.380  0.0344    98.933  86.61
  15   0.0438     98.610  0.0346    98.922  92.68
  16   0.0324     98.950  0.0340    98.942  98.72
  17   0.0456     98.560  0.0317    98.993  104.78
  18   0.0622     98.160  0.0334    98.950  110.94
  19   0.0479     98.410  0.0326    98.882  117.00
  20   0.0381     98.750  0.0296    99.035  123.05
  21   0.0367     98.760  0.0281    99.132  129.09
  22   0.0336     98.880  0.0294    99.065  135.16
  23   0.0349     98.770  0.0291    99.065  141.24
  24   0.0509     98.400  0.0288    99.082  147.30
  25   0.0400     98.730  0.0289    99.087  153.37
  26   0.0490     98.510  0.0268    99.135  159.45
  27   0.0395     98.750  0.0260    99.153  165.56
  28   0.0360     98.830  0.0274    99.090  171.63
  29   0.0421     98.550  0.0245    99.212  177.82
  30   0.0412     98.580  0.0247    99.213  183.87
  31   0.0465     98.500  0.0258    99.172  189.93
  32   0.0411     98.670  0.0237    99.248  195.99
  33   0.0302     99.010  0.0235    99.292  202.06
  34   0.0256     99.130  0.0249    99.218  208.15
  35   0.0304     99.140  0.0250    99.187  214.32
  36   0.0350     99.050  0.0227    99.288  220.36
  37   0.0340     98.930  0.0228    99.273  226.44
  38   0.0465     98.390  0.0222    99.305  232.53
  39   0.0401     98.780  0.0225    99.257  238.58
  40   0.0827     97.250  0.0213    99.345  244.77
  41   0.0358     98.940  0.0229    99.283  250.84
  42   0.0308     99.040  0.0227    99.278  256.90
  43   0.0269     99.140  0.0225    99.230  262.96
  44   0.0382     98.870  0.0227    99.248  269.00
  45   0.0271     99.240  0.0211    99.343  275.08
  46   0.0455     98.710  0.0195    99.410  281.25
  47   0.0483     98.520  0.0204    99.327  287.31
  48   0.0362     98.950  0.0196    99.380  293.39
  49   0.0316     98.960  0.0192    99.410  299.49
  50   0.0273     99.090  0.0205    99.340  305.55
  51   0.0430     98.620  0.0194    99.378  311.61
  52   0.0320     99.050  0.0200    99.372  317.77
  53   0.0476     98.590  0.0180    99.433  323.85
  54   0.0464     98.550  0.0199    99.370  329.91
  55   0.0418     98.730  0.0178    99.432  335.99
  56   0.0397     98.810  0.0178    99.443  342.03
  57   0.0456     98.660  0.0199    99.360  348.11
  58   0.0271     99.150  0.0182    99.413  354.24
  59   0.0310     98.930  0.0180    99.415  360.29
  60   0.0245     99.210  0.0181    99.405  366.36
  61   0.0334     98.960  0.0169    99.437  372.42
  62   0.0451     98.540  0.0183    99.425  378.50
  63   0.0325     99.030  0.0165    99.473  384.58
  64   0.0313     98.930  0.0177    99.428  390.79
  65   0.0330     98.920  0.0189    99.413  396.83
  66   0.0230     99.180  0.0163    99.513  402.89
  67   0.0344     98.920  0.0159    99.485  408.97
  68   0.0463     98.580  0.0164    99.482  415.04
  69   0.0456     98.440  0.0158    99.527  421.12
  70   0.0242     99.270  0.0158    99.470  427.29
  71   0.0453     98.700  0.0161    99.475  433.40
  72   0.0378     98.990  0.0157    99.497  439.47
  73   0.0414     98.870  0.0163    99.490  445.52
  74   0.0297     99.110  0.0153    99.523  451.58
  75   0.0304     99.160  0.0152    99.512  457.73
  76   0.0432     98.710  0.0156    99.512  463.78
  77   0.0497     98.420  0.0132    99.587  469.85
  78   0.0306     99.000  0.0153    99.502  475.91
  79   0.0266     99.180  0.0147    99.542  481.98
  80   0.0386     98.810  0.0148    99.532  488.05
  81   0.0415     98.730  0.0146    99.530  494.20
  82   0.0274     99.100  0.0146    99.528  500.26
  83   0.0398     98.720  0.0149    99.550  506.34
  84   0.0444     98.730  0.0155    99.520  512.40
  85   0.0344     98.950  0.0143    99.553  518.48
