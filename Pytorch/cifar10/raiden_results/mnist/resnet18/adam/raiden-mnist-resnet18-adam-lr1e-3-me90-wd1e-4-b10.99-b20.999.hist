Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1038     96.600  0.3183    89.175  7.63
   2   0.1056     96.600  0.1015    96.895  13.69
   3   0.0817     97.440  0.0788    97.515  19.85
   4   0.0886     97.170  0.0750    97.688  25.92
   5   0.0891     97.180  0.0698    97.880  31.98
   6   0.0425     98.640  0.0630    98.053  38.04
   7   0.0729     97.630  0.0606    98.120  44.10
   8   0.0471     98.580  0.0581    98.245  50.24
   9   0.0487     98.530  0.0579    98.197  56.30
  10   0.0460     98.400  0.0565    98.272  62.37
  11   0.0645     98.030  0.0556    98.323  68.43
  12   0.0537     98.250  0.0537    98.317  74.47
  13   0.0644     97.980  0.0528    98.348  80.53
  14   0.0558     98.340  0.0525    98.378  86.68
  15   0.0382     98.690  0.0472    98.543  92.74
  16   0.0605     98.100  0.0466    98.572  98.78
  17   0.0561     98.090  0.0445    98.603  104.84
  18   0.0414     98.810  0.0479    98.520  110.91
  19   0.0453     98.480  0.0464    98.643  116.96
  20   0.0352     98.880  0.0466    98.520  123.10
  21   0.0358     98.770  0.0421    98.730  129.17
  22   0.0422     98.570  0.0396    98.768  135.24
  23   0.0451     98.570  0.0411    98.685  141.32
  24   0.0303     99.050  0.0389    98.778  147.42
  25   0.0368     98.880  0.0379    98.795  153.50
  26   0.0489     98.500  0.0379    98.812  159.65
  27   0.0339     98.860  0.0421    98.682  165.75
  28   0.0344     98.900  0.0369    98.813  171.82
  29   0.0452     98.480  0.0356    98.887  177.87
  30   0.0324     98.890  0.0389    98.762  183.95
  31   0.0360     98.860  0.0349    98.957  190.05
  32   0.0265     99.230  0.0351    98.918  196.22
  33   0.0360     98.860  0.0351    98.920  202.30
  34   0.0333     98.950  0.0345    98.883  208.34
  35   0.0321     98.980  0.0329    98.978  214.41
  36   0.0399     98.530  0.0321    98.947  220.49
  37   0.0356     98.940  0.0308    99.023  226.65
  38   0.0365     98.770  0.0348    98.878  232.72
  39   0.0351     98.820  0.0317    98.970  238.76
  40   0.0353     98.740  0.0309    98.997  244.83
  41   0.0329     98.800  0.0288    99.093  250.90
  42   0.0489     98.310  0.0317    99.035  257.01
  43   0.0296     98.970  0.0311    98.985  263.06
  44   0.0350     98.810  0.0275    99.113  269.12
  45   0.0291     99.040  0.0284    99.107  275.17
  46   0.0324     98.920  0.0277    99.143  281.24
  47   0.0291     98.980  0.0275    99.143  287.35
  48   0.0296     99.050  0.0269    99.148  293.51
  49   0.0413     98.640  0.0272    99.118  299.59
  50   0.0401     98.710  0.0282    99.103  305.64
  51   0.0427     98.630  0.0302    99.028  311.70
  52   0.0288     99.140  0.0273    99.128  317.75
  53   0.0328     98.990  0.0265    99.177  323.90
  54   0.0315     98.900  0.0289    99.092  329.95
  55   0.0348     98.860  0.0251    99.203  336.00
  56   0.0289     99.050  0.0278    99.122  342.07
  57   0.0289     99.040  0.0278    99.142  348.12
  58   0.0308     99.000  0.0264    99.157  354.20
  59   0.0258     99.160  0.0256    99.173  360.35
  60   0.0276     99.100  0.0248    99.232  366.41
  61   0.0307     98.990  0.0236    99.233  372.46
  62   0.0318     98.990  0.0256    99.185  378.52
  63   0.0371     98.780  0.0247    99.198  384.61
  64   0.0276     99.100  0.0222    99.302  390.70
  65   0.0267     99.050  0.0234    99.273  396.89
  66   0.0352     98.920  0.0238    99.262  402.94
  67   0.0375     98.910  0.0247    99.232  408.99
  68   0.0273     99.190  0.0245    99.207  415.05
  69   0.0332     98.940  0.0221    99.303  421.10
  70   0.0281     99.050  0.0239    99.248  427.15
  71   0.0331     98.990  0.0225    99.238  433.31
  72   0.0408     98.690  0.0229    99.238  439.37
  73   0.0307     99.060  0.0219    99.302  445.43
  74   0.0334     98.840  0.0225    99.288  451.49
  75   0.0258     99.130  0.0240    99.215  457.55
  76   0.0365     98.800  0.0243    99.233  463.61
  77   0.0422     98.570  0.0233    99.237  469.76
  78   0.0273     99.090  0.0225    99.272  475.82
  79   0.0355     98.860  0.0217    99.275  481.88
  80   0.0328     98.940  0.0223    99.272  487.93
  81   0.0383     98.750  0.0228    99.318  494.01
  82   0.0402     98.710  0.0229    99.288  500.09
  83   0.0263     99.040  0.0215    99.340  506.27
  84   0.0363     98.840  0.0224    99.253  512.32
  85   0.0266     99.110  0.0203    99.357  518.39
  86   0.0357     98.850  0.0211    99.302  524.45
  87   0.0262     99.160  0.0217    99.285  530.52
  88   0.0268     99.080  0.0225    99.247  536.58
  89   0.0404     98.730  0.0213    99.322  542.68
  90   0.0288     99.020  0.0217    99.290  548.75
