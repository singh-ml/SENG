Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1605     94.870  0.4427    85.403  7.57
   2   0.1042     96.750  0.1144    96.372  13.69
   3   0.0717     97.650  0.0771    97.580  19.92
   4   0.0478     98.420  0.0587    98.133  26.08
   5   0.0475     98.480  0.0511    98.402  32.20
   6   0.0613     98.080  0.0523    98.338  38.31
   7   0.0404     98.720  0.0510    98.435  44.43
   8   0.0468     98.460  0.0464    98.555  50.63
   9   0.0488     98.360  0.0434    98.607  56.76
  10   0.0383     98.710  0.0434    98.622  62.87
  11   0.0434     98.630  0.0407    98.713  68.96
  12   0.0563     98.090  0.0431    98.615  75.07
  13   0.0427     98.590  0.0386    98.753  81.19
  14   0.0413     98.710  0.0373    98.855  87.38
  15   0.0414     98.620  0.0380    98.823  93.51
  16   0.0421     98.620  0.0355    98.877  99.63
  17   0.0392     98.750  0.0378    98.797  105.75
  18   0.0433     98.560  0.0361    98.862  111.87
  19   0.0484     98.580  0.0351    98.880  118.07
  20   0.0337     98.910  0.0335    98.933  124.18
  21   0.0478     98.450  0.0340    98.968  130.30
  22   0.0348     98.920  0.0309    99.045  136.42
  23   0.0478     98.380  0.0343    98.940  142.54
  24   0.0362     98.860  0.0311    99.055  148.65
  25   0.0352     98.840  0.0289    99.048  154.88
  26   0.0365     98.920  0.0328    98.955  161.02
  27   0.0405     98.750  0.0318    98.978  167.12
  28   0.0483     98.530  0.0308    99.047  173.21
  29   0.0337     98.950  0.0299    99.087  179.37
  30   0.0255     99.110  0.0291    99.102  185.53
  31   0.0313     99.020  0.0303    99.052  191.64
  32   0.0334     98.940  0.0296    99.088  197.76
  33   0.0350     99.000  0.0311    99.038  203.86
  34   0.0311     99.040  0.0292    99.042  209.98
  35   0.0443     98.640  0.0270    99.142  216.09
  36   0.0293     99.180  0.0263    99.142  222.23
  37   0.0428     98.540  0.0265    99.172  228.45
  38   0.0255     99.120  0.0281    99.118  234.57
  39   0.0310     98.960  0.0257    99.215  240.76
  40   0.0282     99.080  0.0287    99.095  246.87
  41   0.0316     98.960  0.0259    99.188  252.99
  42   0.0328     98.940  0.0244    99.227  259.10
  43   0.0274     99.080  0.0237    99.253  265.33
  44   0.0279     99.120  0.0242    99.222  271.45
  45   0.0309     99.040  0.0237    99.248  277.58
  46   0.0365     98.830  0.0252    99.212  283.70
  47   0.0361     98.840  0.0226    99.312  289.82
  48   0.0419     98.710  0.0229    99.283  296.03
  49   0.0294     98.970  0.0232    99.267  302.20
  50   0.0313     99.020  0.0222    99.308  308.36
  51   0.0300     99.140  0.0227    99.318  314.49
  52   0.0369     98.770  0.0235    99.272  320.61
  53   0.0418     98.570  0.0240    99.210  326.71
  54   0.0264     99.060  0.0219    99.295  332.94
  55   0.0376     98.920  0.0229    99.263  339.06
  56   0.0292     99.120  0.0218    99.347  345.18
  57   0.0345     98.890  0.0208    99.338  351.30
  58   0.0386     98.730  0.0218    99.307  357.42
  59   0.0245     99.310  0.0204    99.367  363.63
  60   0.0289     99.060  0.0201    99.390  369.75
  61   0.0373     98.830  0.0210    99.333  375.88
  62   0.0310     99.010  0.0228    99.315  382.01
  63   0.0305     98.990  0.0217    99.335  388.12
  64   0.0343     98.760  0.0189    99.393  394.34
  65   0.0291     99.080  0.0185    99.400  400.46
  66   0.0269     99.130  0.0176    99.440  406.57
  67   0.0252     99.210  0.0195    99.408  412.74
  68   0.0303     99.040  0.0219    99.325  418.87
  69   0.0240     99.270  0.0199    99.387  424.97
  70   0.0242     99.180  0.0175    99.458  431.17
  71   0.0339     98.860  0.0176    99.440  437.29
  72   0.0439     98.510  0.0196    99.375  443.40
  73   0.0333     98.930  0.0196    99.358  449.53
  74   0.0303     98.950  0.0197    99.390  455.64
  75   0.0281     99.220  0.0176    99.468  461.85
  76   0.0346     98.840  0.0169    99.457  467.97
  77   0.0313     99.060  0.0184    99.432  474.08
  78   0.0277     99.100  0.0174    99.420  480.19
  79   0.0294     99.070  0.0167    99.472  486.30
  80   0.0368     98.800  0.0178    99.403  492.42
  81   0.0245     99.320  0.0166    99.498  498.64
  82   0.0275     99.050  0.0170    99.425  504.75
  83   0.0256     99.200  0.0176    99.420  510.87
  84   0.0339     98.860  0.0155    99.513  517.00
  85   0.0364     98.930  0.0165    99.447  523.12
  86   0.0318     98.960  0.0174    99.462  529.24
  87   0.0261     99.220  0.0181    99.437  535.44
  88   0.0284     99.070  0.0165    99.488  541.55
  89   0.0327     98.980  0.0154    99.548  547.67
  90   0.0276     99.110  0.0160    99.493  553.79
