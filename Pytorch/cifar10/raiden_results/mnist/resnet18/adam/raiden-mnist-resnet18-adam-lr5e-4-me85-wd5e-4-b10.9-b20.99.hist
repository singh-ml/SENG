Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.3518     88.970  0.2729    90.962  7.67
   2   0.1349     95.600  0.0974    96.930  13.82
   3   0.1429     95.510  0.0841    97.402  19.90
   4   0.1211     95.930  0.0770    97.642  26.01
   5   0.1327     95.570  0.0712    97.842  32.22
   6   0.1156     96.490  0.0700    97.835  38.32
   7   0.0977     96.930  0.0667    98.023  44.43
   8   0.1117     96.650  0.0632    98.083  50.54
   9   0.0971     96.990  0.0613    98.163  56.65
  10   0.0685     97.970  0.0585    98.250  62.81
  11   0.0521     98.410  0.0552    98.393  68.90
  12   0.0723     97.830  0.0542    98.340  75.01
  13   0.0697     97.740  0.0527    98.397  81.10
  14   0.0475     98.720  0.0508    98.482  87.19
  15   0.0728     97.740  0.0504    98.523  93.36
  16   0.0812     97.430  0.0482    98.553  99.54
  17   0.0492     98.460  0.0469    98.607  105.63
  18   0.0422     98.710  0.0474    98.565  111.73
  19   0.0371     98.880  0.0447    98.625  117.81
  20   0.0403     98.780  0.0434    98.710  123.89
  21   0.0500     98.510  0.0435    98.700  130.10
  22   0.0574     98.260  0.0419    98.718  136.23
  23   0.0367     98.910  0.0412    98.755  142.33
  24   0.0592     98.120  0.0386    98.835  148.41
  25   0.0368     98.770  0.0395    98.787  154.49
  26   0.0428     98.710  0.0393    98.818  160.58
  27   0.0526     98.520  0.0401    98.792  166.72
  28   0.0444     98.480  0.0395    98.817  172.80
  29   0.0370     98.710  0.0365    98.890  178.92
  30   0.0542     98.240  0.0381    98.823  185.02
  31   0.0444     98.630  0.0357    98.972  191.12
  32   0.0463     98.590  0.0353    98.965  197.34
  33   0.0455     98.690  0.0338    98.957  203.45
  34   0.0375     98.790  0.0365    98.942  209.55
  35   0.0435     98.650  0.0356    98.917  215.64
  36   0.0364     98.820  0.0332    98.982  221.75
  37   0.0499     98.520  0.0342    98.970  227.84
  38   0.0282     99.100  0.0341    98.930  234.01
  39   0.0426     98.600  0.0354    98.912  240.10
  40   0.0335     98.970  0.0311    99.062  246.21
  41   0.0420     98.720  0.0336    99.015  252.33
  42   0.0414     98.770  0.0324    99.052  258.45
  43   0.0409     98.780  0.0321    99.010  264.56
  44   0.0366     98.820  0.0311    99.083  270.74
  45   0.0380     98.900  0.0328    99.013  276.86
  46   0.0435     98.730  0.0306    99.047  282.97
  47   0.0548     98.210  0.0306    99.092  289.06
  48   0.0389     98.760  0.0325    98.983  295.17
  49   0.0344     98.920  0.0308    99.095  301.39
  50   0.0423     98.650  0.0298    99.128  307.48
  51   0.0313     98.930  0.0299    99.103  313.59
  52   0.0270     99.110  0.0289    99.088  319.75
  53   0.0350     98.850  0.0295    99.123  325.86
  54   0.0375     98.700  0.0304    99.068  331.97
  55   0.0346     98.860  0.0289    99.132  338.21
  56   0.0256     99.130  0.0298    99.130  344.29
  57   0.0400     98.780  0.0292    99.098  350.39
  58   0.0363     98.890  0.0285    99.135  356.50
  59   0.0457     98.640  0.0283    99.157  362.62
  60   0.0295     99.050  0.0290    99.088  368.82
  61   0.0363     98.850  0.0277    99.145  374.92
  62   0.0430     98.640  0.0291    99.147  381.03
  63   0.0377     98.880  0.0286    99.123  387.13
  64   0.0413     98.610  0.0295    99.103  393.24
  65   0.0382     98.810  0.0266    99.228  399.45
  66   0.0265     99.250  0.0277    99.167  405.55
  67   0.0323     98.970  0.0282    99.143  411.63
  68   0.0394     98.700  0.0280    99.175  417.75
  69   0.0324     99.030  0.0286    99.172  423.87
  70   0.0343     98.980  0.0273    99.165  429.99
  71   0.0411     98.680  0.0282    99.130  436.19
  72   0.0340     98.980  0.0275    99.172  442.28
  73   0.0333     98.910  0.0273    99.163  448.38
  74   0.0470     98.460  0.0265    99.193  454.50
  75   0.0399     98.790  0.0287    99.145  460.60
  76   0.0283     99.130  0.0278    99.172  466.72
  77   0.0458     98.630  0.0258    99.232  472.97
  78   0.0428     98.700  0.0265    99.202  479.07
  79   0.0338     98.950  0.0256    99.242  485.17
  80   0.0299     99.030  0.0273    99.203  491.29
  81   0.0372     98.810  0.0262    99.218  497.41
  82   0.0378     98.940  0.0255    99.205  503.65
  83   0.0274     99.130  0.0252    99.223  509.73
  84   0.0407     98.710  0.0265    99.182  515.81
  85   0.0305     99.080  0.0261    99.185  521.92
