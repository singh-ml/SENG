Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2091     92.760  0.2715    91.083  7.57
   2   0.1414     95.330  0.1067    96.708  13.64
   3   0.4340     87.140  0.0944    97.033  19.69
   4   0.1904     93.980  0.0896    97.287  25.85
   5   0.1546     95.620  0.0842    97.483  31.90
   6   0.1212     96.100  0.0840    97.535  37.96
   7   0.2390     92.370  0.0779    97.738  44.01
   8   0.1024     96.740  0.0747    97.777  50.05
   9   0.1002     97.140  0.0705    97.900  56.17
  10   0.0863     97.390  0.0688    97.902  62.25
  11   0.1146     96.580  0.0681    97.958  68.31
  12   0.0595     98.160  0.0639    98.187  74.37
  13   0.0418     98.730  0.0628    98.133  80.41
  14   0.0563     98.200  0.0561    98.307  86.48
  15   0.0771     97.600  0.0574    98.327  92.52
  16   0.0613     98.040  0.0562    98.317  98.72
  17   0.0602     98.100  0.0557    98.353  104.78
  18   0.0477     98.610  0.0543    98.378  110.83
  19   0.0803     97.480  0.0513    98.468  116.89
  20   0.0500     98.450  0.0513    98.508  122.95
  21   0.0455     98.500  0.0484    98.567  129.01
  22   0.0649     98.070  0.0503    98.503  135.17
  23   0.0661     97.830  0.0492    98.532  141.25
  24   0.0396     98.770  0.0475    98.617  147.31
  25   0.0447     98.520  0.0464    98.647  153.39
  26   0.0543     98.410  0.0485    98.570  159.45
  27   0.0549     98.200  0.0466    98.612  165.60
  28   0.0581     98.090  0.0450    98.625  171.66
  29   0.0469     98.590  0.0443    98.667  177.72
  30   0.0576     98.320  0.0437    98.680  183.79
  31   0.0464     98.460  0.0437    98.733  189.85
  32   0.0313     99.070  0.0427    98.730  195.91
  33   0.0411     98.610  0.0427    98.732  202.10
  34   0.0447     98.540  0.0440    98.740  208.21
  35   0.0748     97.720  0.0428    98.745  214.30
  36   0.0653     97.980  0.0431    98.695  220.36
  37   0.0415     98.750  0.0416    98.785  226.43
  38   0.0447     98.690  0.0392    98.837  232.60
  39   0.0575     98.280  0.0408    98.783  238.66
  40   0.0495     98.370  0.0422    98.760  244.74
  41   0.0344     98.880  0.0406    98.722  250.81
  42   0.0548     98.340  0.0395    98.848  256.91
  43   0.0404     98.650  0.0378    98.885  263.02
  44   0.0490     98.470  0.0397    98.790  269.21
  45   0.0329     98.990  0.0384    98.817  275.29
  46   0.0397     98.770  0.0383    98.860  281.39
  47   0.0298     99.010  0.0371    98.872  287.45
  48   0.0385     98.760  0.0409    98.763  293.52
  49   0.0441     98.680  0.0394    98.790  299.68
  50   0.0458     98.610  0.0388    98.843  305.74
  51   0.0421     98.720  0.0377    98.862  311.80
  52   0.0295     98.990  0.0388    98.845  317.87
  53   0.0359     98.880  0.0378    98.840  323.93
  54   0.0426     98.670  0.0380    98.855  330.08
  55   0.0529     98.290  0.0385    98.868  336.17
  56   0.0502     98.410  0.0384    98.868  342.23
  57   0.0398     98.800  0.0378    98.865  348.31
  58   0.0505     98.400  0.0393    98.842  354.39
  59   0.0454     98.490  0.0360    98.895  360.48
  60   0.0358     98.780  0.0392    98.823  366.55
  61   0.0405     98.780  0.0367    98.923  372.66
  62   0.0381     98.730  0.0382    98.878  378.73
  63   0.0358     98.830  0.0372    98.917  384.80
  64   0.0507     98.360  0.0373    98.898  390.87
  65   0.0472     98.610  0.0370    98.887  396.93
  66   0.0438     98.620  0.0357    98.927  402.99
  67   0.0453     98.560  0.0350    98.963  409.15
  68   0.0436     98.620  0.0372    98.885  415.24
  69   0.0421     98.670  0.0350    98.973  421.30
  70   0.0500     98.460  0.0383    98.858  427.38
  71   0.0335     99.030  0.0378    98.838  433.43
  72   0.0405     98.700  0.0360    98.918  439.52
  73   0.0386     98.850  0.0366    98.895  445.67
  74   0.0549     98.280  0.0347    98.993  451.75
  75   0.0375     98.890  0.0355    98.927  457.82
  76   0.0302     99.060  0.0367    98.863  463.90
  77   0.0435     98.610  0.0366    98.917  469.96
  78   0.0339     98.910  0.0360    98.902  476.15
  79   0.0344     98.980  0.0348    98.972  482.27
  80   0.0320     98.970  0.0368    98.932  488.34
  81   0.0416     98.620  0.0364    98.880  494.39
  82   0.0419     98.520  0.0352    98.947  500.48
  83   0.0431     98.790  0.0362    98.913  506.63
  84   0.0399     98.810  0.0369    98.892  512.70
  85   0.0343     98.980  0.0342    98.965  518.76
  86   0.0477     98.440  0.0340    98.993  524.83
  87   0.0348     98.830  0.0339    98.998  530.92
  88   0.0323     99.070  0.0355    98.915  536.99
  89   0.0441     98.590  0.0341    98.973  543.16
  90   0.0331     99.060  0.0352    98.937  549.24
