Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1621     94.270  0.2722    91.117  7.61
   2   0.1200     96.340  0.0937    97.113  13.80
   3   0.1020     96.840  0.0815    97.512  19.88
   4   0.0651     97.830  0.0732    97.780  25.97
   5   0.1230     95.830  0.0718    97.798  32.05
   6   0.0936     97.250  0.0666    97.923  38.13
   7   0.0958     96.920  0.0631    98.108  44.23
   8   0.0806     97.580  0.0606    98.120  50.37
   9   0.0750     97.630  0.0613    98.162  56.46
  10   0.0941     96.980  0.0602    98.155  62.55
  11   0.0986     96.800  0.0586    98.278  68.62
  12   0.0957     97.010  0.0569    98.337  74.71
  13   0.0720     97.820  0.0551    98.362  80.95
  14   0.0814     97.600  0.0555    98.370  87.07
  15   0.0852     97.610  0.0514    98.483  93.15
  16   0.0392     98.830  0.0519    98.490  99.23
  17   0.0682     97.720  0.0516    98.457  105.31
  18   0.0456     98.590  0.0508    98.532  111.47
  19   0.0374     99.000  0.0511    98.480  117.56
  20   0.0561     98.420  0.0473    98.542  123.64
  21   0.0332     98.960  0.0449    98.698  129.73
  22   0.0551     98.270  0.0452    98.665  135.84
  23   0.0461     98.470  0.0443    98.675  141.92
  24   0.0579     98.110  0.0426    98.718  148.10
  25   0.0468     98.600  0.0425    98.775  154.20
  26   0.0481     98.460  0.0426    98.745  160.31
  27   0.0381     98.770  0.0395    98.793  166.43
  28   0.0459     98.520  0.0408    98.765  172.53
  29   0.0333     98.900  0.0402    98.787  178.64
  30   0.0305     99.050  0.0386    98.900  184.83
  31   0.0436     98.590  0.0388    98.833  190.94
  32   0.0369     98.920  0.0384    98.853  197.04
  33   0.0379     98.800  0.0381    98.835  203.14
  34   0.0378     98.810  0.0359    98.913  209.23
  35   0.0521     98.260  0.0362    98.892  215.33
  36   0.0295     99.050  0.0360    98.935  221.51
  37   0.0534     98.250  0.0364    98.870  227.62
  38   0.0315     99.080  0.0362    98.890  233.72
  39   0.0518     98.610  0.0348    98.962  239.83
  40   0.0317     99.060  0.0359    98.940  245.94
  41   0.0344     98.890  0.0346    98.995  252.13
  42   0.0440     98.710  0.0333    99.020  258.23
  43   0.0365     98.870  0.0361    98.943  264.34
  44   0.0393     98.730  0.0330    98.998  270.46
  45   0.0491     98.480  0.0358    98.897  276.57
  46   0.0369     98.980  0.0322    99.053  282.75
  47   0.0274     99.080  0.0323    99.052  288.87
  48   0.0404     98.760  0.0316    99.057  294.99
  49   0.0316     98.970  0.0313    99.072  301.10
  50   0.0344     98.960  0.0311    99.048  307.25
  51   0.0318     99.040  0.0308    99.077  313.35
  52   0.0326     98.880  0.0316    99.047  319.57
  53   0.0432     98.640  0.0305    99.070  325.68
  54   0.0381     98.740  0.0321    99.035  331.78
  55   0.0390     98.800  0.0310    99.070  337.89
  56   0.0370     98.820  0.0309    99.043  344.02
  57   0.0332     98.910  0.0313    99.065  350.21
  58   0.0355     98.860  0.0291    99.137  356.31
  59   0.0760     97.540  0.0286    99.135  362.43
  60   0.0422     98.570  0.0299    99.090  368.54
  61   0.0332     98.900  0.0283    99.137  374.63
  62   0.0514     98.420  0.0312    99.060  380.85
  63   0.0375     98.890  0.0272    99.188  386.96
  64   0.0404     98.770  0.0287    99.128  393.07
  65   0.0437     98.600  0.0295    99.120  399.20
  66   0.0347     98.810  0.0273    99.178  405.32
  67   0.0372     98.790  0.0292    99.133  411.43
  68   0.0286     99.070  0.0282    99.127  417.63
  69   0.0383     98.720  0.0289    99.132  423.74
  70   0.0253     99.210  0.0274    99.205  429.85
  71   0.0462     98.540  0.0279    99.162  435.98
  72   0.0415     98.640  0.0281    99.147  442.08
  73   0.0426     98.710  0.0284    99.112  448.20
  74   0.0394     98.810  0.0278    99.185  454.43
  75   0.0337     98.910  0.0286    99.157  460.56
  76   0.0238     99.240  0.0274    99.127  466.69
  77   0.0354     98.840  0.0263    99.198  472.80
  78   0.0321     98.950  0.0281    99.073  478.95
  79   0.0297     99.070  0.0274    99.173  485.17
  80   0.0312     99.010  0.0254    99.232  491.29
  81   0.0491     98.510  0.0257    99.227  497.41
  82   0.0391     98.800  0.0283    99.148  503.52
  83   0.0364     98.770  0.0257    99.233  509.67
  84   0.0322     98.980  0.0255    99.252  515.79
  85   0.0451     98.690  0.0267    99.158  521.99
