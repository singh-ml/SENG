Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.8549     73.040  0.8376    70.712  7.55
   2   0.2749     91.040  0.2191    93.100  13.62
   3   0.1083     96.420  0.1484    95.393  19.78
   4   0.1236     96.140  0.1074    96.683  25.86
   5   0.0832     97.500  0.0883    97.290  31.97
   6   0.0770     97.490  0.0786    97.528  38.05
   7   0.0797     97.530  0.0701    97.798  44.13
   8   0.0616     98.020  0.0663    97.957  50.24
   9   0.0604     97.880  0.0642    98.008  56.34
  10   0.0627     97.870  0.0610    98.102  62.46
  11   0.0547     98.040  0.0615    98.077  68.55
  12   0.0692     97.740  0.0580    98.165  74.62
  13   0.0653     97.870  0.0592    98.183  80.72
  14   0.0547     98.280  0.0560    98.262  86.91
  15   0.0549     98.400  0.0554    98.322  93.01
  16   0.0543     98.240  0.0532    98.367  99.08
  17   0.0456     98.530  0.0537    98.307  105.15
  18   0.0679     97.660  0.0516    98.420  111.24
  19   0.0667     97.740  0.0539    98.282  117.39
  20   0.0424     98.600  0.0522    98.445  123.57
  21   0.0450     98.490  0.0527    98.367  129.66
  22   0.0613     98.110  0.0505    98.457  135.74
  23   0.0451     98.470  0.0505    98.383  141.82
  24   0.0585     98.050  0.0518    98.423  147.92
  25   0.0558     98.180  0.0504    98.430  154.01
  26   0.0556     98.100  0.0514    98.387  160.19
  27   0.0459     98.540  0.0481    98.512  166.27
  28   0.0465     98.540  0.0504    98.443  172.35
  29   0.0475     98.480  0.0495    98.420  178.43
  30   0.0483     98.400  0.0483    98.498  184.51
  31   0.0697     97.580  0.0487    98.442  190.60
  32   0.0630     97.820  0.0494    98.448  196.79
  33   0.0549     98.360  0.0501    98.393  202.86
  34   0.0458     98.560  0.0476    98.522  208.96
  35   0.0482     98.340  0.0464    98.575  215.06
  36   0.0617     97.980  0.0477    98.522  221.15
  37   0.0549     98.270  0.0477    98.508  227.21
  38   0.0491     98.360  0.0474    98.532  233.38
  39   0.0447     98.540  0.0478    98.545  239.45
  40   0.0553     98.270  0.0487    98.477  245.54
  41   0.0403     98.720  0.0472    98.525  251.61
  42   0.0574     98.190  0.0492    98.478  257.69
  43   0.0433     98.560  0.0468    98.538  263.87
  44   0.0587     98.030  0.0486    98.478  269.96
  45   0.0550     98.140  0.0473    98.517  276.09
  46   0.0524     98.200  0.0458    98.520  282.15
  47   0.0347     98.830  0.0460    98.543  288.22
  48   0.0410     98.630  0.0450    98.620  294.39
  49   0.0559     98.160  0.0485    98.520  300.46
  50   0.0394     98.690  0.0478    98.552  306.54
  51   0.0455     98.410  0.0450    98.555  312.61
  52   0.1152     96.790  0.0463    98.575  318.67
  53   0.0483     98.320  0.0481    98.495  324.77
  54   0.0433     98.440  0.0476    98.532  330.97
  55   0.0484     98.380  0.0457    98.602  337.06
  56   0.0382     98.710  0.0451    98.568  343.16
  57   0.0407     98.730  0.0458    98.612  349.29
  58   0.0539     98.190  0.0468    98.527  355.39
  59   0.0468     98.340  0.0457    98.567  361.47
  60   0.0415     98.640  0.0453    98.612  367.65
  61   0.0396     98.690  0.0468    98.570  373.71
  62   0.0421     98.720  0.0460    98.588  379.77
  63   0.0530     98.420  0.0440    98.620  385.85
  64   0.0438     98.750  0.0461    98.582  391.93
  65   0.0498     98.440  0.0452    98.590  398.03
  66   0.0468     98.450  0.0445    98.603  404.19
  67   0.0447     98.500  0.0466    98.557  410.27
  68   0.0449     98.500  0.0446    98.630  416.36
  69   0.0523     98.250  0.0451    98.547  422.45
  70   0.0521     98.240  0.0440    98.675  428.50
  71   0.0460     98.470  0.0448    98.612  434.58
  72   0.0426     98.610  0.0453    98.568  440.75
  73   0.0555     98.100  0.0445    98.638  446.81
  74   0.0407     98.670  0.0442    98.613  452.89
  75   0.0434     98.490  0.0434    98.652  458.97
  76   0.0521     98.230  0.0451    98.593  465.09
  77   0.0493     98.310  0.0466    98.467  471.19
  78   0.0516     98.420  0.0461    98.563  477.27
  79   0.0475     98.560  0.0448    98.610  483.34
  80   0.0516     98.460  0.0418    98.677  489.44
  81   0.0484     98.380  0.0449    98.548  495.52
  82   0.0550     98.150  0.0451    98.595  501.59
  83   0.0527     98.210  0.0441    98.617  507.73
  84   0.0540     98.260  0.0450    98.600  513.81
  85   0.0491     98.540  0.0446    98.588  519.91
