Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1267     95.650  0.2798    90.708  7.61
   2   0.1655     94.380  0.0825    97.420  13.86
   3   0.0595     98.200  0.0673    97.893  20.03
   4   0.0682     97.860  0.0594    98.110  26.19
   5   0.0627     97.900  0.0571    98.212  32.33
   6   0.0563     98.200  0.0528    98.325  38.49
   7   0.0390     98.700  0.0500    98.410  44.72
   8   0.0483     98.540  0.0497    98.427  50.87
   9   0.0532     98.260  0.0479    98.465  57.02
  10   0.1046     96.560  0.0496    98.447  63.17
  11   0.0523     98.300  0.0460    98.563  69.33
  12   0.1258     95.680  0.0448    98.542  75.48
  13   0.0519     98.190  0.0435    98.602  81.63
  14   0.0591     98.190  0.0425    98.685  87.87
  15   0.0445     98.580  0.0437    98.617  94.03
  16   0.0339     98.990  0.0410    98.690  100.19
  17   0.0364     98.840  0.0397    98.745  106.33
  18   0.0707     97.800  0.0406    98.718  112.49
  19   0.0544     98.200  0.0396    98.775  118.74
  20   0.0416     98.760  0.0375    98.833  124.89
  21   0.0709     97.680  0.0388    98.793  131.06
  22   0.0587     98.070  0.0389    98.785  137.23
  23   0.0408     98.610  0.0372    98.840  143.38
  24   0.0433     98.430  0.0362    98.843  149.53
  25   0.0356     98.820  0.0351    98.915  155.77
  26   0.0347     98.910  0.0347    98.913  161.93
  27   0.0723     97.890  0.0357    98.917  168.06
  28   0.0436     98.630  0.0346    98.955  174.22
  29   0.0533     98.320  0.0347    98.937  180.37
  30   0.0510     98.350  0.0325    98.972  186.64
  31   0.0378     98.780  0.0332    98.888  192.79
  32   0.0533     98.340  0.0331    98.950  198.94
  33   0.0401     98.700  0.0352    98.913  205.10
  34   0.0359     98.770  0.0300    99.030  211.29
  35   0.0314     99.070  0.0308    99.012  217.46
  36   0.0332     98.920  0.0303    99.070  223.73
  37   0.0365     98.870  0.0286    99.088  229.89
  38   0.0356     98.910  0.0297    99.053  236.04
  39   0.0459     98.670  0.0296    99.025  242.20
  40   0.0371     98.750  0.0265    99.145  248.35
  41   0.0310     99.020  0.0290    99.103  254.61
  42   0.0294     99.030  0.0272    99.098  260.77
  43   0.0273     99.080  0.0296    99.092  266.93
  44   0.0389     98.770  0.0273    99.158  273.11
  45   0.0291     99.150  0.0268    99.137  279.34
  46   0.0510     98.440  0.0255    99.198  285.49
  47   0.0313     98.920  0.0272    99.135  291.74
  48   0.0331     98.930  0.0251    99.205  297.91
  49   0.0320     98.920  0.0260    99.168  304.07
  50   0.0348     98.820  0.0247    99.218  310.23
  51   0.0408     98.800  0.0236    99.245  316.39
  52   0.0348     98.920  0.0236    99.257  322.60
  53   0.0445     98.500  0.0244    99.222  328.75
  54   0.0278     99.060  0.0249    99.195  334.91
  55   0.0293     99.110  0.0238    99.227  341.07
  56   0.0335     98.910  0.0236    99.285  347.23
  57   0.0376     98.790  0.0239    99.235  353.41
  58   0.0352     98.810  0.0223    99.285  359.68
  59   0.0322     98.900  0.0229    99.252  365.84
  60   0.0350     98.890  0.0235    99.238  372.03
  61   0.0515     98.410  0.0214    99.328  378.27
  62   0.0331     98.960  0.0221    99.272  384.44
  63   0.0365     98.750  0.0222    99.295  390.61
  64   0.0385     98.690  0.0222    99.287  396.88
  65   0.0395     98.870  0.0224    99.250  403.04
  66   0.0282     99.130  0.0200    99.378  409.21
  67   0.0242     99.210  0.0209    99.327  415.38
  68   0.0276     99.120  0.0212    99.282  421.53
  69   0.0327     98.920  0.0201    99.355  427.81
  70   0.0316     98.980  0.0217    99.307  434.00
  71   0.0354     98.850  0.0190    99.363  440.19
  72   0.0368     98.760  0.0209    99.325  446.36
  73   0.0318     99.010  0.0209    99.323  452.56
  74   0.0308     99.010  0.0191    99.383  458.73
  75   0.0311     98.970  0.0193    99.375  464.99
  76   0.0439     98.600  0.0226    99.310  471.16
  77   0.0282     99.100  0.0204    99.380  477.33
  78   0.0407     98.700  0.0179    99.438  483.52
  79   0.0259     99.150  0.0197    99.373  489.68
  80   0.0391     98.700  0.0166    99.470  495.93
  81   0.0422     98.640  0.0190    99.380  502.09
  82   0.0281     99.110  0.0188    99.398  508.26
  83   0.0324     98.960  0.0170    99.445  514.43
  84   0.0284     99.070  0.0189    99.388  520.59
  85   0.0304     99.000  0.0174    99.468  526.87
  86   0.0294     99.040  0.0188    99.398  533.05
  87   0.0330     98.870  0.0175    99.437  539.25
  88   0.0393     98.760  0.0162    99.452  545.47
  89   0.0236     99.140  0.0179    99.463  551.64
  90   0.0296     98.950  0.0177    99.427  557.82
