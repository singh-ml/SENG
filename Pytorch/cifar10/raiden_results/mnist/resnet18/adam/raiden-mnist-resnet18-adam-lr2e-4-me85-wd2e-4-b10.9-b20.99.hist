Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1018     96.910  0.3523    88.607  7.57
   2   0.1017     96.420  0.0867    97.267  13.79
   3   0.0665     97.750  0.0677    97.882  19.92
   4   0.0708     97.650  0.0603    98.072  26.03
   5   0.0880     97.290  0.0546    98.357  32.16
   6   0.0790     97.560  0.0515    98.400  38.27
   7   0.0605     98.060  0.0501    98.402  44.42
   8   0.0369     98.630  0.0488    98.472  50.53
   9   0.0812     97.360  0.0439    98.647  56.63
  10   0.0433     98.600  0.0413    98.730  62.79
  11   0.0730     97.450  0.0419    98.698  68.92
  12   0.0445     98.610  0.0398    98.752  75.03
  13   0.0497     98.460  0.0387    98.818  81.16
  14   0.0976     97.070  0.0374    98.813  87.36
  15   0.0351     98.860  0.0378    98.805  93.47
  16   0.0595     98.200  0.0365    98.832  99.56
  17   0.0581     98.210  0.0367    98.855  105.68
  18   0.0316     98.970  0.0366    98.867  111.80
  19   0.0539     98.320  0.0344    98.892  117.91
  20   0.0346     98.930  0.0332    99.002  124.10
  21   0.0432     98.670  0.0339    98.927  130.22
  22   0.0448     98.510  0.0321    98.972  136.33
  23   0.0312     98.990  0.0323    99.003  142.44
  24   0.0369     98.790  0.0313    99.033  148.56
  25   0.0495     98.350  0.0299    99.070  154.82
  26   0.0331     98.930  0.0301    99.035  160.95
  27   0.0385     98.790  0.0305    99.072  167.07
  28   0.0415     98.620  0.0307    99.047  173.19
  29   0.0295     99.030  0.0292    99.105  179.27
  30   0.0308     99.010  0.0285    99.132  185.38
  31   0.0425     98.660  0.0280    99.125  191.55
  32   0.0399     98.680  0.0269    99.143  197.66
  33   0.0306     99.040  0.0268    99.160  203.81
  34   0.0403     98.760  0.0271    99.157  209.94
  35   0.0482     98.440  0.0259    99.180  216.04
  36   0.0519     98.410  0.0276    99.170  222.16
  37   0.0398     98.720  0.0250    99.185  228.35
  38   0.0345     98.910  0.0262    99.160  234.46
  39   0.0487     98.510  0.0264    99.157  240.57
  40   0.0430     98.540  0.0249    99.212  246.66
  41   0.0356     98.850  0.0246    99.218  252.76
  42   0.2484     91.100  0.0242    99.255  258.98
  43   0.0417     98.600  0.0237    99.223  265.10
  44   0.0361     98.940  0.0238    99.257  271.24
  45   0.0580     98.140  0.0230    99.303  277.38
  46   0.0237     99.280  0.0237    99.260  283.49
  47   0.0308     99.030  0.0232    99.263  289.67
  48   0.0269     99.090  0.0225    99.317  295.91
  49   0.0289     99.120  0.0223    99.275  302.03
  50   0.0339     98.910  0.0229    99.258  308.14
  51   0.0268     99.090  0.0219    99.323  314.25
  52   0.0288     99.100  0.0217    99.320  320.36
  53   0.0554     98.410  0.0217    99.300  326.56
  54   0.0328     98.950  0.0217    99.353  332.66
  55   0.0390     98.740  0.0222    99.328  338.78
  56   0.0337     98.990  0.0215    99.340  344.88
  57   0.0364     98.760  0.0202    99.380  351.00
  58   0.0262     99.130  0.0202    99.360  357.19
  59   0.0431     98.560  0.0208    99.327  363.31
  60   0.0347     98.910  0.0194    99.388  369.42
  61   0.0297     99.070  0.0199    99.372  375.54
  62   0.0397     98.860  0.0206    99.365  381.65
  63   0.0286     99.040  0.0192    99.422  387.77
  64   0.0239     99.190  0.0203    99.355  394.00
  65   0.0262     99.240  0.0196    99.367  400.13
  66   0.0332     99.010  0.0195    99.390  406.23
  67   0.0339     98.870  0.0193    99.427  412.35
  68   0.0293     99.030  0.0188    99.403  418.47
  69   0.0374     98.870  0.0190    99.430  424.59
  70   0.0345     98.920  0.0181    99.450  430.83
  71   0.0302     99.030  0.0188    99.417  436.94
  72   0.0315     98.910  0.0182    99.427  443.07
  73   0.0389     98.840  0.0193    99.398  449.20
  74   0.0281     99.150  0.0180    99.432  455.30
  75   0.0371     98.830  0.0171    99.422  461.41
  76   0.0358     98.780  0.0188    99.407  467.64
  77   0.0311     98.980  0.0166    99.468  473.78
  78   0.0421     98.750  0.0172    99.448  479.90
  79   0.0420     98.670  0.0169    99.443  486.03
  80   0.0318     99.090  0.0165    99.480  492.15
  81   0.0292     99.160  0.0173    99.447  498.31
  82   0.0290     99.080  0.0163    99.487  504.53
  83   0.0365     98.860  0.0169    99.437  510.65
  84   0.0355     98.970  0.0159    99.487  516.76
  85   0.0302     99.080  0.0165    99.463  522.87
