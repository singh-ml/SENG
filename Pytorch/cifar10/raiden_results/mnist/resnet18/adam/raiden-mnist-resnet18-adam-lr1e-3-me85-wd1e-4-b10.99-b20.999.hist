Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1748     94.250  0.3166    89.497  7.60
   2   0.1064     96.090  0.1069    96.613  13.70
   3   0.0752     97.570  0.0823    97.415  19.80
   4   0.0510     98.340  0.0721    97.727  25.92
   5   0.0586     98.250  0.0688    97.882  32.04
   6   0.0569     98.140  0.0618    98.040  38.17
   7   0.0680     97.850  0.0644    97.990  44.32
   8   0.0558     98.030  0.0548    98.302  50.49
   9   0.0578     98.130  0.0594    98.182  56.62
  10   0.0854     97.280  0.0554    98.257  62.74
  11   0.0774     97.520  0.0564    98.272  68.98
  12   0.0503     98.250  0.0534    98.387  75.12
  13   0.0459     98.560  0.0556    98.293  81.24
  14   0.0480     98.560  0.0490    98.432  87.34
  15   0.0309     99.010  0.0479    98.518  93.47
  16   0.0504     98.380  0.0476    98.550  99.57
  17   0.0515     98.420  0.0467    98.570  105.77
  18   0.0531     98.440  0.0454    98.600  111.89
  19   0.0575     98.060  0.0440    98.660  118.01
  20   0.0394     98.700  0.0436    98.670  124.11
  21   0.0408     98.670  0.0429    98.697  130.24
  22   0.0420     98.650  0.0410    98.735  136.36
  23   0.0325     98.920  0.0391    98.828  142.56
  24   0.0395     98.810  0.0393    98.805  148.67
  25   0.0264     99.210  0.0410    98.750  154.80
  26   0.0299     99.150  0.0384    98.798  160.92
  27   0.0330     98.970  0.0370    98.835  167.03
  28   0.0440     98.650  0.0366    98.847  173.15
  29   0.0438     98.730  0.0362    98.838  179.39
  30   0.0338     98.980  0.0366    98.853  185.51
  31   0.0446     98.570  0.0349    98.917  191.63
  32   0.0321     98.940  0.0358    98.825  197.75
  33   0.0543     98.220  0.0351    98.888  203.87
  34   0.0316     99.060  0.0340    98.947  210.09
  35   0.0425     98.670  0.0324    98.970  216.22
  36   0.0390     98.790  0.0326    98.985  222.36
  37   0.0322     98.980  0.0317    98.978  228.50
  38   0.0421     98.690  0.0307    99.065  234.61
  39   0.0345     98.890  0.0309    99.015  240.71
  40   0.0422     98.640  0.0317    98.980  246.92
  41   0.0287     99.050  0.0313    98.983  253.04
  42   0.0365     98.840  0.0306    99.047  259.17
  43   0.0278     99.060  0.0307    99.003  265.34
  44   0.0273     99.120  0.0283    99.097  271.47
  45   0.0409     98.700  0.0276    99.125  277.68
  46   0.0306     99.060  0.0292    99.095  283.79
  47   0.0327     98.930  0.0278    99.097  289.90
  48   0.0303     98.950  0.0285    99.095  295.99
  49   0.0338     98.840  0.0284    99.107  302.11
  50   0.0369     98.810  0.0285    99.072  308.24
  51   0.0333     98.890  0.0256    99.178  314.47
  52   0.0233     99.210  0.0263    99.185  320.58
  53   0.0315     99.010  0.0284    99.113  326.68
  54   0.0290     99.090  0.0255    99.192  332.80
  55   0.0382     98.760  0.0271    99.130  338.97
  56   0.0338     98.910  0.0275    99.143  345.21
  57   0.0340     98.970  0.0240    99.220  351.30
  58   0.0290     99.140  0.0246    99.167  357.42
  59   0.0427     98.650  0.0243    99.263  363.55
  60   0.0343     98.850  0.0253    99.212  369.67
  61   0.0560     98.300  0.0236    99.257  375.84
  62   0.0354     98.730  0.0239    99.242  381.96
  63   0.0328     98.850  0.0242    99.238  388.09
  64   0.0373     98.790  0.0252    99.198  394.19
  65   0.0267     98.960  0.0245    99.235  400.30
  66   0.0353     98.870  0.0239    99.233  406.43
  67   0.0290     98.900  0.0252    99.197  412.56
  68   0.0326     98.980  0.0243    99.233  418.78
  69   0.0320     98.910  0.0231    99.257  424.90
  70   0.0343     98.840  0.0246    99.197  431.02
  71   0.0306     98.960  0.0232    99.260  437.15
  72   0.0299     98.960  0.0243    99.192  443.29
  73   0.0258     99.080  0.0219    99.315  449.52
  74   0.0300     98.910  0.0223    99.287  455.65
  75   0.0299     98.940  0.0229    99.255  461.78
  76   0.0416     98.580  0.0233    99.258  467.88
  77   0.0328     98.970  0.0250    99.202  474.00
  78   0.0405     98.530  0.0225    99.283  480.12
  79   0.0281     99.060  0.0206    99.325  486.34
  80   0.0276     99.080  0.0222    99.277  492.46
  81   0.0256     99.190  0.0216    99.275  498.58
  82   0.0267     99.100  0.0212    99.308  504.72
  83   0.0273     99.200  0.0219    99.283  510.84
  84   0.0344     98.870  0.0218    99.257  516.95
  85   0.0305     99.010  0.0231    99.285  523.17
