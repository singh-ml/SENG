Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--frac', '0.01', '--bh', '256', '--irho', '1', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2565     66.560  1.8112    38.722  14.99
   2   0.5185     84.490  0.8397    76.445  27.49
   3   0.3141     90.660  0.4324    87.018  39.94
   4   0.3123     89.990  0.3084    90.712  52.57
   5   0.2068     93.630  0.2464    92.673  65.01
   6   0.2243     92.560  0.2054    93.802  77.48
   7   0.1527     95.230  0.1791    94.488  89.98
   8   0.1625     94.910  0.1552    95.213  102.55
   9   0.1277     95.940  0.1434    95.573  115.02
  10   0.1161     96.390  0.1295    96.015  127.53
  11   0.1057     96.700  0.1206    96.295  140.18
  12   0.1165     96.440  0.1121    96.492  152.67
  13   0.1060     96.480  0.1080    96.677  165.15
  14   0.0918     97.030  0.0972    96.985  177.80
  15   0.0946     96.980  0.0939    97.078  190.27
  16   0.0873     97.310  0.0878    97.303  202.74
  17   0.0874     97.160  0.0838    97.365  215.33
  18   0.0761     97.620  0.0806    97.460  227.78
  19   0.0751     97.640  0.0763    97.643  240.24
  20   0.0757     97.630  0.0722    97.772  252.70
  21   0.0701     97.660  0.0708    97.813  265.15
  22   0.0670     97.850  0.0677    97.910  277.61
  23   0.0748     97.670  0.0651    97.995  290.06
  24   0.0715     97.760  0.0651    97.952  302.65
  25   0.0707     97.780  0.0607    98.130  315.11
  26   0.0710     97.740  0.0592    98.198  327.59
  27   0.0657     97.970  0.0569    98.270  340.06
  28   0.0618     98.040  0.0554    98.283  352.54
  29   0.0568     98.080  0.0553    98.333  364.98
  30   0.0582     98.080  0.0522    98.368  377.52
  31   0.0552     98.170  0.0510    98.383  389.97
  32   0.0614     98.020  0.0505    98.452  402.45
  33   0.0533     98.170  0.0493    98.437  414.92
  34   0.0537     98.220  0.0466    98.540  427.35
  35   0.0538     98.230  0.0470    98.523  439.83
  36   0.0519     98.200  0.0453    98.555  452.43
  37   0.0529     98.200  0.0446    98.630  464.88
  38   0.0513     98.330  0.0433    98.697  477.36
  39   0.0483     98.360  0.0426    98.650  489.82
  40   0.0490     98.440  0.0415    98.702  502.36
  41   0.0507     98.330  0.0418    98.683  514.83
  42   0.0497     98.290  0.0413    98.722  527.31
  43   0.0480     98.460  0.0392    98.760  539.81
  44   0.0488     98.410  0.0394    98.765  552.28
  45   0.0415     98.620  0.0386    98.802  564.72
  46   0.0416     98.580  0.0376    98.840  577.28
  47   0.0477     98.410  0.0389    98.778  589.73
  48   0.0493     98.430  0.0368    98.858  602.19
  49   0.0527     98.230  0.0360    98.923  614.79
  50   0.0427     98.550  0.0352    98.923  627.24
  51   0.0440     98.540  0.0362    98.855  639.71
  52   0.0532     98.220  0.0349    98.888  652.31
  53   0.0534     98.320  0.0339    98.977  664.80
  54   0.0414     98.620  0.0340    98.932  677.27
  55   0.0442     98.600  0.0321    99.002  689.72
  56   0.0422     98.600  0.0321    99.040  702.29
  57   0.0403     98.680  0.0314    99.012  714.76
  58   0.0599     98.170  0.0315    99.022  727.22
  59   0.0408     98.580  0.0314    99.040  739.85
  60   0.0501     98.380  0.0308    99.010  752.32
  61   0.0426     98.480  0.0305    99.050  764.80
  62   0.0405     98.720  0.0306    99.023  777.40
  63   0.0406     98.660  0.0289    99.090  789.84
  64   0.0417     98.590  0.0297    99.042  802.29
  65   0.0442     98.570  0.0285    99.125  814.80
  66   0.0389     98.700  0.0289    99.095  827.30
  67   0.0440     98.550  0.0285    99.068  839.81
  68   0.0422     98.480  0.0284    99.110  852.28
  69   0.0361     98.760  0.0288    99.105  864.81
  70   0.0371     98.750  0.0263    99.177  877.27
  71   0.0403     98.670  0.0256    99.223  889.70
  72   0.0358     98.860  0.0267    99.165  902.18
  73   0.0435     98.580  0.0255    99.205  914.64
  74   0.0386     98.770  0.0263    99.127  927.10
  75   0.0465     98.440  0.0256    99.180  939.69
  76   0.0382     98.790  0.0244    99.245  952.20
  77   0.0385     98.760  0.0247    99.170  964.68
  78   0.0441     98.530  0.0248    99.262  977.15
  79   0.0465     98.490  0.0248    99.223  989.73
  80   0.0392     98.780  0.0246    99.195  1002.18
  81   0.0396     98.700  0.0244    99.258  1014.65
  82   0.0357     98.830  0.0237    99.255  1027.13
  83   0.0404     98.680  0.0241    99.250  1039.58
  84   0.0378     98.830  0.0232    99.250  1052.01
  85   0.0392     98.680  0.0236    99.262  1064.48
  86   0.0389     98.800  0.0233    99.268  1077.05
  87   0.0388     98.800  0.0226    99.277  1089.51
  88   0.0408     98.710  0.0221    99.315  1101.93
  89   0.0415     98.670  0.0224    99.263  1114.37
  90   0.0444     98.630  0.0222    99.305  1126.81
