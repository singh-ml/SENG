Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '1', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3495     64.880  1.8271    37.130  14.88
   2   0.5372     85.040  0.9256    74.198  27.41
   3   0.3113     90.810  0.4569    86.842  39.84
   4   0.2638     91.840  0.3104    90.952  52.24
   5   0.1880     94.340  0.2382    92.982  64.73
   6   0.1691     94.740  0.1958    94.163  77.17
   7   0.1500     95.490  0.1647    95.095  89.61
   8   0.1507     95.420  0.1455    95.650  102.15
   9   0.1145     96.410  0.1301    96.077  114.58
  10   0.0977     96.980  0.1181    96.433  127.01
  11   0.1119     96.530  0.1096    96.630  139.54
  12   0.1060     96.680  0.1006    96.962  151.93
  13   0.0847     97.500  0.0963    97.038  164.37
  14   0.0834     97.550  0.0884    97.327  176.78
  15   0.0853     97.250  0.0846    97.378  189.18
  16   0.0780     97.650  0.0775    97.630  201.60
  17   0.0637     98.040  0.0746    97.752  214.08
  18   0.0809     97.520  0.0711    97.837  226.53
  19   0.0663     97.850  0.0679    97.888  238.98
  20   0.0719     97.800  0.0653    97.962  251.41
  21   0.0602     98.120  0.0627    98.035  263.93
  22   0.0609     97.990  0.0610    98.123  276.35
  23   0.0645     97.960  0.0592    98.173  288.75
  24   0.0551     98.230  0.0574    98.247  301.29
  25   0.0543     98.340  0.0559    98.253  313.72
  26   0.0559     98.220  0.0538    98.357  326.15
  27   0.0562     98.210  0.0536    98.352  338.59
  28   0.0544     98.230  0.0512    98.425  351.01
  29   0.0622     98.120  0.0505    98.432  363.44
  30   0.0485     98.460  0.0484    98.495  375.84
  31   0.0481     98.430  0.0494    98.413  388.31
  32   0.0558     98.190  0.0457    98.505  400.72
  33   0.0565     98.150  0.0448    98.587  413.15
  34   0.0481     98.450  0.0443    98.600  425.68
  35   0.0475     98.410  0.0436    98.692  438.09
  36   0.0486     98.380  0.0431    98.687  450.46
  37   0.0485     98.450  0.0425    98.643  462.85
  38   0.0522     98.330  0.0416    98.693  475.30
  39   0.0461     98.420  0.0405    98.757  487.73
  40   0.0500     98.300  0.0396    98.785  500.15
  41   0.0478     98.410  0.0393    98.747  512.76
  42   0.0491     98.330  0.0385    98.838  525.17
  43   0.0429     98.590  0.0386    98.745  537.60
  44   0.0491     98.400  0.0372    98.848  550.02
  45   0.0496     98.450  0.0356    98.897  562.46
  46   0.0503     98.280  0.0356    98.910  574.88
  47   0.0503     98.410  0.0355    98.912  587.33
  48   0.0474     98.450  0.0340    98.932  599.75
  49   0.0441     98.600  0.0341    98.925  612.17
  50   0.0429     98.550  0.0333    98.968  624.78
  51   0.0477     98.420  0.0338    98.940  637.20
  52   0.0460     98.560  0.0329    98.968  649.64
  53   0.0426     98.560  0.0315    99.035  662.17
  54   0.0447     98.510  0.0320    99.007  674.57
  55   0.0422     98.600  0.0308    99.013  686.98
  56   0.0428     98.580  0.0310    99.042  699.42
  57   0.0422     98.620  0.0315    98.983  711.83
  58   0.0450     98.490  0.0296    99.077  724.26
  59   0.0375     98.710  0.0298    99.067  736.69
  60   0.0399     98.730  0.0289    99.147  749.20
  61   0.0425     98.580  0.0298    99.082  761.62
  62   0.0439     98.600  0.0285    99.093  774.04
  63   0.0364     98.800  0.0278    99.117  786.52
  64   0.0423     98.590  0.0274    99.142  798.97
  65   0.0402     98.680  0.0283    99.120  811.39
  66   0.0369     98.730  0.0274    99.167  823.94
  67   0.0514     98.310  0.0270    99.157  836.37
  68   0.0384     98.690  0.0257    99.203  848.80
  69   0.0396     98.740  0.0267    99.128  861.21
  70   0.0392     98.740  0.0252    99.182  873.63
  71   0.0383     98.800  0.0261    99.160  886.06
  72   0.0361     98.780  0.0254    99.173  898.47
  73   0.0424     98.660  0.0259    99.213  910.98
  74   0.0390     98.710  0.0255    99.187  923.41
  75   0.0449     98.470  0.0256    99.133  935.83
  76   0.0343     98.810  0.0245    99.218  948.38
  77   0.0432     98.540  0.0241    99.190  960.83
  78   0.0379     98.650  0.0240    99.248  973.23
  79   0.0452     98.520  0.0233    99.272  985.66
  80   0.0367     98.700  0.0238    99.222  998.07
  81   0.0505     98.230  0.0231    99.285  1010.51
  82   0.0335     98.810  0.0230    99.267  1023.05
  83   0.0374     98.770  0.0230    99.252  1035.49
  84   0.0358     98.780  0.0223    99.320  1047.95
  85   0.0375     98.730  0.0226    99.277  1060.41
