Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5902     81.490  1.4369    53.348  14.59
   2   0.2767     91.450  0.3771    88.712  27.14
   3   0.1929     93.810  0.2354    92.810  39.57
   4   0.1486     95.280  0.1763    94.565  52.00
   5   0.1327     95.800  0.1417    95.622  64.42
   6   0.1007     96.710  0.1222    96.195  76.90
   7   0.1263     95.900  0.1065    96.663  89.31
   8   0.0869     97.320  0.0965    96.987  101.71
   9   0.0819     97.500  0.0858    97.342  114.26
  10   0.0675     97.850  0.0790    97.523  126.66
  11   0.0655     97.960  0.0725    97.738  139.09
  12   0.0607     98.050  0.0686    97.835  151.61
  13   0.0575     98.210  0.0631    98.075  164.03
  14   0.0592     98.200  0.0588    98.145  176.44
  15   0.0632     97.950  0.0561    98.220  188.92
  16   0.0530     98.260  0.0560    98.268  201.37
  17   0.0497     98.320  0.0521    98.408  213.79
  18   0.0534     98.220  0.0501    98.413  226.19
  19   0.0519     98.410  0.0483    98.485  238.63
  20   0.0495     98.230  0.0476    98.447  251.06
  21   0.0413     98.560  0.0456    98.560  263.49
  22   0.0454     98.650  0.0444    98.567  276.07
  23   0.0481     98.350  0.0423    98.653  288.50
  24   0.0514     98.320  0.0406    98.713  300.94
  25   0.0413     98.630  0.0399    98.755  313.56
  26   0.0414     98.740  0.0386    98.748  326.02
  27   0.0555     98.180  0.0381    98.825  338.42
  28   0.0458     98.570  0.0366    98.842  350.92
  29   0.0430     98.590  0.0364    98.825  363.36
  30   0.0382     98.700  0.0345    98.897  375.75
  31   0.0346     98.850  0.0343    98.915  388.31
  32   0.0434     98.660  0.0339    98.928  400.76
  33   0.0350     98.820  0.0331    98.985  413.16
  34   0.0394     98.700  0.0314    98.963  425.61
  35   0.0387     98.670  0.0322    98.992  438.19
  36   0.0483     98.400  0.0300    99.068  450.61
  37   0.0386     98.690  0.0296    99.087  463.03
  38   0.0392     98.680  0.0292    99.057  475.52
  39   0.0466     98.480  0.0289    99.068  487.97
  40   0.0377     98.830  0.0277    99.118  500.40
  41   0.0374     98.700  0.0276    99.080  512.95
  42   0.0335     98.850  0.0273    99.107  525.38
  43   0.0370     98.790  0.0268    99.108  537.78
  44   0.0354     98.760  0.0277    99.132  550.31
  45   0.0359     98.770  0.0260    99.167  562.76
  46   0.0317     98.980  0.0258    99.160  575.17
  47   0.0444     98.620  0.0249    99.167  587.56
  48   0.0349     98.820  0.0256    99.202  599.96
  49   0.0430     98.570  0.0250    99.195  612.40
  50   0.0304     99.000  0.0244    99.210  624.82
  51   0.0306     99.010  0.0234    99.208  637.23
  52   0.0295     99.030  0.0237    99.255  649.66
  53   0.0320     98.910  0.0224    99.272  662.08
  54   0.0314     98.950  0.0224    99.268  674.61
  55   0.0310     99.000  0.0232    99.255  687.02
  56   0.0361     98.750  0.0219    99.288  699.45
  57   0.0341     98.770  0.0222    99.275  711.86
  58   0.0429     98.470  0.0208    99.323  724.31
  59   0.0395     98.700  0.0217    99.292  736.76
  60   0.0333     98.890  0.0207    99.313  749.20
  61   0.0365     98.740  0.0199    99.330  761.78
  62   0.0296     98.920  0.0200    99.373  774.23
  63   0.0322     98.930  0.0196    99.387  786.66
  64   0.0372     98.720  0.0205    99.317  799.10
  65   0.0275     99.120  0.0202    99.345  811.51
  66   0.0291     99.060  0.0199    99.318  823.91
  67   0.0363     98.780  0.0192    99.353  836.46
  68   0.0313     99.010  0.0184    99.395  848.87
  69   0.0387     98.590  0.0185    99.382  861.31
  70   0.0358     98.720  0.0183    99.385  873.89
  71   0.0315     98.910  0.0172    99.453  886.31
  72   0.0361     98.800  0.0175    99.423  898.74
  73   0.0306     98.910  0.0178    99.413  911.28
  74   0.0351     98.820  0.0168    99.462  923.73
  75   0.0334     98.840  0.0170    99.447  936.17
  76   0.0284     99.060  0.0172    99.422  948.60
  77   0.0347     98.820  0.0159    99.488  961.11
  78   0.0440     98.700  0.0167    99.445  973.51
  79   0.0343     98.810  0.0159    99.482  985.92
  80   0.0294     98.980  0.0159    99.473  998.45
  81   0.0411     98.600  0.0164    99.448  1010.86
  82   0.0332     98.840  0.0156    99.487  1023.28
  83   0.0401     98.770  0.0158    99.465  1035.78
  84   0.0387     98.790  0.0156    99.505  1048.21
  85   0.0390     98.710  0.0150    99.513  1060.68
