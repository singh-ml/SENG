Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3022     11.350  2.6820    10.608  14.56
   2   2.3039     11.350  2.3049    10.873  26.96
   3   2.3047      9.560  2.3055    10.388  39.22
   4   2.3023     10.380  2.3052    10.528  51.43
   5   1.8742     28.930  2.1824    16.382  63.64
   6   1.6310     50.560  1.2325    54.297  75.84
   7   0.6106     81.120  0.4139    86.933  88.05
   8   0.1786     94.610  0.2096    93.735  100.47
   9   0.2409     92.020  0.1416    95.783  112.85
  10   0.1726     94.860  0.1102    96.607  125.04
  11   0.1137     96.520  0.0941    97.092  137.19
  12   0.0623     97.940  0.0765    97.575  149.32
  13   0.0953     97.040  0.0698    97.853  161.49
  14   0.0555     97.990  0.0647    97.993  173.64
  15   0.0616     98.040  0.0578    98.163  185.79
  16   0.0521     98.180  0.0541    98.252  198.12
  17   0.0697     97.670  0.0530    98.305  210.50
  18   0.0381     98.870  0.0471    98.550  222.63
  19   0.0595     97.840  0.0474    98.505  234.78
  20   0.0580     97.990  0.0440    98.630  247.11
  21   0.0429     98.640  0.0424    98.683  259.27
  22   0.0604     97.850  0.0420    98.723  271.44
  23   0.0510     98.250  0.0412    98.732  283.81
  24   0.0755     97.610  0.0382    98.812  295.98
  25   0.0377     98.770  0.0372    98.848  308.12
  26   0.0605     98.040  0.0358    98.845  320.40
  27   0.0370     98.810  0.0357    98.833  332.57
  28   0.0341     98.870  0.0330    98.993  344.73
  29   0.0305     98.940  0.0347    98.882  357.09
  30   0.0344     98.800  0.0317    99.008  369.30
  31   0.0352     98.860  0.0309    98.985  381.62
  32   0.0491     98.480  0.0313    99.023  393.79
  33   0.0506     98.380  0.0309    98.978  406.15
  34   0.0387     98.680  0.0293    99.052  418.28
  35   0.0360     98.770  0.0277    99.100  430.60
  36   0.0741     97.560  0.0278    99.122  442.98
  37   0.0408     98.700  0.0265    99.168  455.48
  38   0.0376     98.830  0.0257    99.168  467.47
  39   0.0258     99.160  0.0254    99.153  479.85
  40   0.0370     98.760  0.0249    99.205  492.01
  41   0.0260     99.050  0.0224    99.278  504.53
  42   0.0259     99.100  0.0243    99.227  516.88
  43   0.0277     99.060  0.0227    99.257  529.24
  44   0.0275     99.020  0.0219    99.325  541.72
  45   0.0300     99.020  0.0207    99.322  553.86
  46   0.0291     99.010  0.0211    99.320  566.03
  47   0.0336     98.760  0.0201    99.345  578.52
  48   0.0268     99.080  0.0189    99.397  590.91
  49   0.0297     99.020  0.0191    99.398  603.07
  50   0.0297     99.060  0.0176    99.410  615.44
  51   0.0393     98.690  0.0170    99.435  627.78
  52   0.0425     98.740  0.0165    99.458  639.92
  53   0.0327     98.870  0.0159    99.483  652.27
  54   0.0243     99.200  0.0160    99.470  664.66
  55   0.0259     99.020  0.0144    99.503  677.02
  56   0.0267     99.190  0.0143    99.528  689.39
  57   0.0280     99.040  0.0132    99.547  701.86
  58   0.0277     99.080  0.0132    99.565  714.06
  59   0.0403     98.810  0.0129    99.592  726.44
  60   0.0240     99.170  0.0115    99.623  738.59
  61   0.0260     99.090  0.0119    99.607  750.97
  62   0.0302     99.040  0.0106    99.648  763.34
  63   0.0273     99.140  0.0106    99.655  775.50
  64   0.0361     98.880  0.0094    99.658  787.83
  65   0.0301     99.110  0.0091    99.697  800.19
  66   0.0291     99.060  0.0087    99.723  812.57
  67   0.0269     99.100  0.0082    99.723  824.92
  68   0.0264     99.150  0.0089    99.683  837.28
  69   0.0271     99.170  0.0076    99.758  849.44
  70   0.0267     99.130  0.0070    99.772  861.70
  71   0.0274     99.150  0.0073    99.765  874.07
  72   0.0263     99.170  0.0065    99.802  886.45
  73   0.0295     99.080  0.0066    99.788  898.85
  74   0.0285     99.100  0.0059    99.818  911.02
  75   0.0273     99.130  0.0061    99.818  923.34
  76   0.0263     99.170  0.0063    99.798  935.72
  77   0.0276     99.120  0.0058    99.817  948.00
  78   0.0290     99.180  0.0057    99.818  960.36
  79   0.0288     99.120  0.0055    99.833  972.53
  80   0.0276     99.190  0.0050    99.848  985.00
  81   0.0281     99.170  0.0052    99.842  997.33
  82   0.0278     99.190  0.0049    99.850  1009.50
  83   0.0275     99.180  0.0049    99.847  1021.96
  84   0.0277     99.170  0.0047    99.862  1034.35
  85   0.0296     99.120  0.0046    99.870  1046.74
