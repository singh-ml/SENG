Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--frac', '0.01', '--bh', '256', '--irho', '2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5427     84.940  1.4909    51.913  14.59
   2   0.2482     92.270  0.3996    87.980  27.19
   3   0.1837     94.230  0.2347    92.973  39.72
   4   0.1490     95.330  0.1682    94.897  52.17
   5   0.1296     95.830  0.1338    95.877  64.86
   6   0.1148     96.410  0.1134    96.527  77.31
   7   0.0810     97.390  0.0968    97.072  89.79
   8   0.0826     97.330  0.0869    97.297  102.37
   9   0.0809     97.540  0.0801    97.558  114.81
  10   0.0726     97.650  0.0731    97.762  127.26
  11   0.0636     98.000  0.0688    97.858  139.71
  12   0.0583     98.090  0.0638    97.992  152.12
  13   0.0606     98.010  0.0587    98.220  164.59
  14   0.0574     98.060  0.0566    98.218  177.02
  15   0.0543     98.240  0.0549    98.298  189.54
  16   0.0465     98.520  0.0522    98.400  201.97
  17   0.0581     98.170  0.0501    98.428  214.38
  18   0.0505     98.260  0.0472    98.518  226.98
  19   0.0501     98.390  0.0459    98.533  239.41
  20   0.0486     98.360  0.0444    98.603  251.88
  21   0.0436     98.530  0.0437    98.652  264.44
  22   0.0426     98.610  0.0421    98.672  276.95
  23   0.0457     98.410  0.0411    98.725  289.40
  24   0.0402     98.610  0.0402    98.738  301.99
  25   0.0424     98.550  0.0379    98.828  314.49
  26   0.0373     98.700  0.0375    98.848  326.95
  27   0.0498     98.290  0.0368    98.843  339.43
  28   0.0390     98.660  0.0351    98.892  351.91
  29   0.0350     98.780  0.0348    98.892  364.34
  30   0.0418     98.580  0.0334    98.962  376.81
  31   0.0348     98.770  0.0335    98.968  389.40
  32   0.0371     98.660  0.0322    98.985  401.85
  33   0.0343     98.820  0.0311    99.025  414.32
  34   0.0363     98.660  0.0304    99.050  426.91
  35   0.0377     98.770  0.0305    99.043  439.35
  36   0.0386     98.590  0.0298    99.065  451.81
  37   0.0349     98.810  0.0292    99.083  464.39
  38   0.0344     98.830  0.0282    99.072  476.88
  39   0.0403     98.620  0.0275    99.115  489.34
  40   0.0385     98.650  0.0276    99.127  501.75
  41   0.0425     98.630  0.0264    99.155  514.40
  42   0.0362     98.800  0.0269    99.143  526.87
  43   0.0427     98.570  0.0261    99.158  539.31
  44   0.0359     98.800  0.0257    99.170  551.75
  45   0.0384     98.760  0.0258    99.162  564.20
  46   0.0366     98.640  0.0236    99.267  576.68
  47   0.0317     98.870  0.0251    99.247  589.28
  48   0.0331     98.770  0.0241    99.205  601.75
  49   0.0338     98.830  0.0238    99.213  614.19
  50   0.0313     98.890  0.0228    99.255  626.77
  51   0.0340     98.730  0.0226    99.260  639.23
  52   0.0382     98.600  0.0231    99.280  651.71
  53   0.0373     98.730  0.0220    99.293  664.19
  54   0.0397     98.580  0.0218    99.268  676.65
  55   0.0309     98.850  0.0215    99.318  689.13
  56   0.0358     98.750  0.0213    99.298  701.60
  57   0.0339     98.810  0.0212    99.337  714.17
  58   0.0349     98.750  0.0203    99.347  726.62
  59   0.0298     98.970  0.0195    99.373  739.03
  60   0.0417     98.680  0.0208    99.305  751.60
  61   0.0340     98.880  0.0187    99.417  764.09
  62   0.0364     98.730  0.0197    99.338  776.56
  63   0.0344     98.850  0.0196    99.313  789.00
  64   0.0304     98.950  0.0196    99.360  801.47
  65   0.0391     98.700  0.0188    99.400  813.93
  66   0.0329     98.850  0.0193    99.380  826.39
  67   0.0343     98.840  0.0174    99.443  839.01
  68   0.0420     98.690  0.0176    99.448  851.45
  69   0.0424     98.600  0.0178    99.413  863.89
  70   0.0362     98.770  0.0174    99.443  876.33
  71   0.0351     98.840  0.0180    99.405  888.82
  72   0.0306     98.900  0.0169    99.430  901.26
  73   0.0329     98.900  0.0166    99.468  913.72
  74   0.0353     98.830  0.0163    99.508  926.29
  75   0.0328     98.820  0.0176    99.415  938.76
  76   0.0320     98.930  0.0161    99.505  951.23
  77   0.0323     98.860  0.0155    99.472  963.70
  78   0.0340     98.910  0.0166    99.468  976.14
  79   0.0339     98.740  0.0151    99.508  988.56
  80   0.0290     98.950  0.0155    99.487  1001.04
  81   0.0310     98.970  0.0149    99.530  1013.62
  82   0.0310     98.890  0.0153    99.513  1026.06
  83   0.0247     99.160  0.0150    99.510  1038.49
  84   0.0272     98.980  0.0149    99.503  1051.05
  85   0.0336     98.950  0.0154    99.492  1063.51
  86   0.0316     99.010  0.0149    99.525  1075.93
  87   0.0361     98.810  0.0148    99.500  1088.53
  88   0.0326     98.890  0.0147    99.555  1101.06
  89   0.0362     98.720  0.0144    99.562  1113.53
  90   0.0314     98.940  0.0143    99.548  1126.02
