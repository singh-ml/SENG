Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.6922     78.940  1.4813    51.223  14.76
   2   0.2647     91.570  0.4071    87.935  27.36
   3   0.1962     93.840  0.2354    92.925  39.94
   4   0.1394     95.720  0.1737    94.745  52.49
   5   0.1165     96.180  0.1406    95.702  65.09
   6   0.1106     96.550  0.1175    96.408  77.66
   7   0.1194     96.090  0.0990    96.987  90.24
   8   0.0791     97.560  0.0874    97.245  102.83
   9   0.0764     97.700  0.0801    97.543  115.49
  10   0.0715     97.720  0.0737    97.660  128.06
  11   0.0668     97.870  0.0683    97.882  140.65
  12   0.0670     97.820  0.0639    98.020  153.29
  13   0.0555     98.070  0.0598    98.170  165.88
  14   0.0534     98.240  0.0577    98.172  178.44
  15   0.0533     98.220  0.0545    98.360  191.12
  16   0.0483     98.390  0.0512    98.415  203.71
  17   0.0536     98.250  0.0502    98.430  216.25
  18   0.0481     98.520  0.0491    98.455  228.86
  19   0.0510     98.250  0.0454    98.562  241.43
  20   0.0496     98.320  0.0443    98.572  254.01
  21   0.0410     98.580  0.0431    98.612  266.61
  22   0.0524     98.150  0.0419    98.665  279.17
  23   0.0483     98.410  0.0410    98.665  291.74
  24   0.0469     98.490  0.0388    98.775  304.27
  25   0.0492     98.350  0.0394    98.740  316.94
  26   0.0424     98.500  0.0388    98.745  329.52
  27   0.0386     98.580  0.0371    98.837  342.10
  28   0.0449     98.540  0.0366    98.790  354.78
  29   0.0408     98.580  0.0350    98.875  367.36
  30   0.0371     98.710  0.0362    98.823  379.98
  31   0.0432     98.560  0.0345    98.923  392.67
  32   0.0361     98.780  0.0334    98.932  405.25
  33   0.0384     98.610  0.0327    98.930  417.82
  34   0.0385     98.680  0.0314    99.028  430.47
  35   0.0383     98.660  0.0303    99.030  443.05
  36   0.0439     98.560  0.0305    99.012  455.64
  37   0.0459     98.510  0.0305    99.063  468.20
  38   0.0390     98.710  0.0295    99.053  480.78
  39   0.0441     98.520  0.0288    99.075  493.31
  40   0.0361     98.810  0.0289    99.092  505.91
  41   0.0371     98.780  0.0276    99.113  518.61
  42   0.0417     98.640  0.0269    99.138  531.17
  43   0.0384     98.720  0.0265    99.162  543.74
  44   0.0367     98.850  0.0256    99.212  556.45
  45   0.0381     98.760  0.0255    99.207  569.01
  46   0.0365     98.730  0.0249    99.207  581.57
  47   0.0396     98.620  0.0254    99.192  594.22
  48   0.0394     98.670  0.0233    99.242  606.78
  49   0.0383     98.690  0.0235    99.267  619.35
  50   0.0382     98.700  0.0241    99.227  632.03
  51   0.0398     98.650  0.0226    99.253  644.59
  52   0.0403     98.600  0.0228    99.267  657.17
  53   0.0408     98.640  0.0222    99.287  669.72
  54   0.0352     98.850  0.0224    99.285  682.31
  55   0.0405     98.710  0.0218    99.312  694.89
  56   0.0375     98.680  0.0209    99.322  707.46
  57   0.0354     98.780  0.0203    99.368  720.12
  58   0.0343     98.910  0.0212    99.273  732.70
  59   0.0361     98.770  0.0196    99.343  745.23
  60   0.0376     98.860  0.0199    99.357  757.92
  61   0.0339     98.900  0.0206    99.355  770.46
  62   0.0434     98.540  0.0197    99.357  783.02
  63   0.0359     98.800  0.0194    99.377  795.71
  64   0.0377     98.810  0.0187    99.392  808.30
  65   0.0398     98.760  0.0180    99.412  820.89
  66   0.0389     98.770  0.0186    99.365  833.46
  67   0.0364     98.740  0.0188    99.382  846.05
  68   0.0365     98.780  0.0180    99.423  858.60
  69   0.0379     98.710  0.0183    99.350  871.20
  70   0.0342     98.780  0.0169    99.472  883.78
  71   0.0306     99.050  0.0170    99.433  896.34
  72   0.0396     98.670  0.0175    99.447  908.91
  73   0.0365     98.770  0.0176    99.457  921.49
  74   0.0349     98.850  0.0174    99.443  934.04
  75   0.0400     98.670  0.0168    99.463  946.61
  76   0.0353     98.800  0.0161    99.493  959.34
  77   0.0363     98.790  0.0164    99.465  971.90
  78   0.0404     98.690  0.0162    99.452  984.53
  79   0.0312     98.860  0.0163    99.472  997.33
  80   0.0330     98.940  0.0164    99.450  1009.93
  81   0.0336     98.930  0.0166    99.483  1022.52
  82   0.0365     98.790  0.0144    99.532  1035.23
  83   0.0349     98.900  0.0148    99.523  1047.85
  84   0.0337     98.920  0.0144    99.513  1060.44
  85   0.0366     98.750  0.0145    99.552  1072.99
