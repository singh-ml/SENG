Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '5', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2492     92.540  0.8743    71.537  14.69
   2   0.1469     95.380  0.1863    94.177  27.19
   3   0.1191     96.180  0.1214    96.273  39.75
   4   0.0754     97.550  0.0900    97.163  52.21
   5   0.0924     96.920  0.0752    97.653  64.66
   6   0.0622     97.920  0.0677    97.848  77.13
   7   0.0544     98.220  0.0587    98.115  89.63
   8   0.0801     97.470  0.0551    98.260  102.06
   9   0.0502     98.370  0.0513    98.425  114.53
  10   0.0548     98.240  0.0479    98.485  126.99
  11   0.0452     98.530  0.0440    98.620  139.56
  12   0.0447     98.460  0.0434    98.637  152.03
  13   0.0472     98.510  0.0409    98.688  164.49
  14   0.0382     98.770  0.0382    98.805  177.09
  15   0.0417     98.640  0.0354    98.852  189.56
  16   0.0460     98.450  0.0352    98.882  202.03
  17   0.0393     98.600  0.0339    98.908  214.60
  18   0.0590     98.030  0.0333    98.913  227.07
  19   0.0427     98.580  0.0313    99.040  239.51
  20   0.0408     98.570  0.0305    98.988  251.98
  21   0.0438     98.480  0.0303    99.048  264.60
  22   0.0466     98.400  0.0298    99.015  277.03
  23   0.0402     98.660  0.0287    99.042  289.52
  24   0.0394     98.710  0.0275    99.148  301.98
  25   0.0420     98.610  0.0255    99.210  314.46
  26   0.0484     98.380  0.0244    99.218  326.92
  27   0.0360     98.870  0.0268    99.153  339.47
  28   0.0304     98.970  0.0245    99.178  351.93
  29   0.0404     98.770  0.0236    99.238  364.39
  30   0.0402     98.670  0.0247    99.208  376.96
  31   0.0418     98.570  0.0229    99.235  389.43
  32   0.0531     98.320  0.0228    99.267  401.89
  33   0.0358     98.850  0.0222    99.282  414.46
  34   0.0333     98.900  0.0228    99.272  426.89
  35   0.0302     98.890  0.0217    99.288  439.36
  36   0.0444     98.580  0.0217    99.262  451.81
  37   0.0314     98.940  0.0197    99.388  464.43
  38   0.0355     98.890  0.0199    99.362  476.89
  39   0.0426     98.620  0.0196    99.397  489.35
  40   0.0288     99.070  0.0191    99.372  501.94
  41   0.0339     98.850  0.0193    99.345  514.42
  42   0.0268     99.030  0.0183    99.417  526.88
  43   0.0333     98.930  0.0187    99.365  539.48
  44   0.0316     98.950  0.0182    99.430  551.95
  45   0.0341     98.920  0.0174    99.405  564.45
  46   0.0327     98.930  0.0173    99.415  577.01
  47   0.0353     98.920  0.0167    99.457  589.48
  48   0.0327     98.940  0.0162    99.430  601.95
  49   0.0321     98.900  0.0163    99.475  614.45
  50   0.0300     99.030  0.0165    99.443  626.92
  51   0.0320     99.000  0.0161    99.440  639.39
  52   0.0362     98.880  0.0163    99.477  651.86
  53   0.0362     98.860  0.0150    99.495  664.33
  54   0.0388     98.840  0.0157    99.477  676.79
  55   0.0366     98.860  0.0144    99.523  689.23
  56   0.0310     98.890  0.0152    99.497  701.66
  57   0.0340     98.990  0.0151    99.480  714.14
  58   0.0414     98.720  0.0137    99.545  726.63
  59   0.0260     99.170  0.0129    99.588  739.22
  60   0.0283     99.090  0.0135    99.578  751.67
  61   0.0321     98.970  0.0129    99.580  764.12
  62   0.0358     98.930  0.0142    99.530  776.58
  63   0.0288     99.070  0.0130    99.572  789.05
  64   0.0340     98.900  0.0129    99.568  801.52
  65   0.0328     98.970  0.0131    99.527  813.97
  66   0.0316     98.990  0.0123    99.583  826.45
  67   0.0380     98.810  0.0122    99.610  838.92
  68   0.0273     99.170  0.0126    99.553  851.41
  69   0.0310     98.980  0.0129    99.560  863.86
  70   0.0313     99.090  0.0117    99.615  876.33
  71   0.0326     98.900  0.0124    99.590  888.78
  72   0.0328     98.910  0.0108    99.648  901.41
  73   0.0279     99.080  0.0116    99.617  913.85
  74   0.0378     98.840  0.0110    99.607  926.32
  75   0.0328     98.950  0.0103    99.685  938.89
  76   0.0368     98.870  0.0118    99.615  951.36
  77   0.0413     98.770  0.0107    99.615  963.83
  78   0.0292     99.040  0.0104    99.637  976.37
  79   0.0430     98.710  0.0103    99.645  988.85
  80   0.0430     98.580  0.0102    99.645  1001.32
  81   0.0311     99.130  0.0097    99.658  1013.91
  82   0.0309     99.040  0.0096    99.690  1026.35
  83   0.0344     98.940  0.0099    99.662  1038.83
  84   0.0296     99.110  0.0101    99.642  1051.34
  85   0.0371     98.790  0.0097    99.688  1063.88
