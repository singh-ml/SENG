Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--frac', '0.01', '--bh', '256', '--irho', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2041     14.730  2.7079    10.915  14.60
   2   1.0845     56.250  1.7989    29.792  26.81
   3   0.5833     81.030  0.7907    70.670  38.83
   4   0.3842     87.750  0.3028    90.868  51.03
   5   0.1417     95.630  0.1707    94.867  63.33
   6   0.1604     94.860  0.1281    96.202  75.56
   7   0.1512     95.330  0.1058    96.730  87.79
   8   0.0866     97.150  0.0916    97.193  100.18
   9   0.1641     94.550  0.0822    97.485  112.39
  10   0.0762     97.420  0.0771    97.593  124.58
  11   0.1025     96.630  0.0701    97.837  136.90
  12   0.0953     96.640  0.0683    97.907  149.09
  13   0.0850     97.260  0.0619    98.077  161.31
  14   0.0546     98.100  0.0603    98.177  173.48
  15   0.0640     98.010  0.0557    98.248  186.01
  16   0.0534     98.250  0.0534    98.338  198.23
  17   0.1138     95.990  0.0507    98.430  210.44
  18   0.0387     98.690  0.0511    98.407  222.74
  19   0.0660     97.710  0.0458    98.517  234.94
  20   0.0357     98.750  0.0458    98.583  247.37
  21   0.0398     98.780  0.0411    98.690  259.66
  22   0.0387     98.680  0.0431    98.637  272.08
  23   0.0471     98.380  0.0403    98.750  284.28
  24   0.0375     98.730  0.0399    98.752  296.46
  25   0.0584     98.200  0.0385    98.777  308.73
  26   0.0417     98.700  0.0363    98.875  320.96
  27   0.0372     98.750  0.0354    98.880  333.16
  28   0.0503     98.320  0.0363    98.852  345.47
  29   0.0351     98.860  0.0341    98.917  357.69
  30   0.0328     98.910  0.0344    98.895  369.89
  31   0.0369     98.680  0.0322    99.000  382.22
  32   0.0412     98.700  0.0308    99.035  394.43
  33   0.0395     98.790  0.0301    99.020  406.64
  34   0.0386     98.750  0.0296    99.055  418.86
  35   0.0337     98.900  0.0297    99.045  431.27
  36   0.0329     98.930  0.0284    99.087  443.48
  37   0.0250     99.210  0.0276    99.135  455.89
  38   0.0334     98.900  0.0263    99.153  468.09
  39   0.0411     98.650  0.0256    99.160  480.28
  40   0.0430     98.560  0.0259    99.153  492.49
  41   0.0258     99.220  0.0232    99.257  504.78
  42   0.0383     98.720  0.0231    99.232  517.18
  43   0.0353     98.970  0.0221    99.283  529.58
  44   0.0263     99.160  0.0215    99.312  541.88
  45   0.0282     99.070  0.0215    99.290  554.28
  46   0.0354     98.830  0.0209    99.305  566.68
  47   0.0361     98.820  0.0198    99.347  579.10
  48   0.0323     98.830  0.0201    99.338  591.29
  49   0.0342     98.920  0.0194    99.395  603.71
  50   0.0283     99.060  0.0181    99.408  615.91
  51   0.0316     98.970  0.0170    99.447  628.31
  52   0.0311     99.010  0.0168    99.428  640.53
  53   0.0409     98.710  0.0166    99.482  652.72
  54   0.0338     98.890  0.0160    99.465  665.05
  55   0.0221     99.300  0.0152    99.510  677.44
  56   0.0267     99.120  0.0150    99.505  689.65
  57   0.0317     98.940  0.0141    99.500  702.11
  58   0.0316     99.010  0.0142    99.517  714.32
  59   0.0271     99.090  0.0139    99.555  726.71
  60   0.0311     98.900  0.0134    99.575  738.90
  61   0.0312     99.000  0.0133    99.582  751.23
  62   0.0268     99.080  0.0121    99.610  763.42
  63   0.0289     99.060  0.0108    99.648  775.82
  64   0.0285     99.100  0.0110    99.645  788.14
  65   0.0252     99.190  0.0102    99.665  800.33
  66   0.0257     99.130  0.0102    99.705  812.54
  67   0.0270     99.170  0.0103    99.663  824.84
  68   0.0258     99.210  0.0095    99.700  837.25
  69   0.0323     99.080  0.0094    99.692  849.46
  70   0.0308     99.080  0.0090    99.717  861.87
  71   0.0284     99.140  0.0091    99.723  874.08
  72   0.0273     99.130  0.0087    99.712  886.30
  73   0.0295     99.080  0.0080    99.747  898.50
  74   0.0274     99.150  0.0081    99.753  910.72
  75   0.0279     99.150  0.0080    99.748  922.92
  76   0.0291     99.110  0.0074    99.765  935.10
  77   0.0291     99.090  0.0076    99.775  947.40
  78   0.0280     99.130  0.0074    99.780  959.61
  79   0.0299     99.110  0.0072    99.788  972.02
  80   0.0289     99.050  0.0068    99.802  984.34
  81   0.0285     99.150  0.0071    99.783  996.55
  82   0.0298     99.070  0.0068    99.800  1008.76
  83   0.0284     99.090  0.0073    99.765  1020.96
  84   0.0291     99.100  0.0066    99.795  1033.19
  85   0.0275     99.110  0.0066    99.817  1045.39
