Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--frac', '0.01', '--bh', '256', '--irho', '2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 7852212224 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.5380     84.530  1.4010    54.893  14.70
   2   0.2563     92.050  0.3737    88.917  27.28
   3   0.1996     93.740  0.2337    92.897  40.00
   4   0.1620     94.590  0.1758    94.558  52.56
   5   0.1224     95.930  0.1437    95.560  65.12
   6   0.1115     96.550  0.1231    96.122  77.79
   7   0.0891     97.060  0.1077    96.640  90.33
   8   0.0978     96.900  0.0931    97.135  102.91
   9   0.0968     96.860  0.0851    97.400  115.45
  10   0.0700     97.640  0.0776    97.590  128.01
  11   0.0615     98.010  0.0717    97.772  140.60
  12   0.0624     97.900  0.0675    97.920  153.32
  13   0.0645     97.900  0.0637    98.010  165.90
  14   0.0623     98.040  0.0609    98.097  178.49
  15   0.0583     98.160  0.0570    98.220  191.06
  16   0.0646     97.920  0.0541    98.327  203.82
  17   0.0628     97.990  0.0524    98.395  216.37
  18   0.0547     98.260  0.0505    98.435  228.93
  19   0.0475     98.450  0.0486    98.408  241.65
  20   0.0489     98.400  0.0465    98.555  254.22
  21   0.0456     98.470  0.0450    98.565  266.75
  22   0.0459     98.440  0.0428    98.658  279.44
  23   0.0439     98.510  0.0428    98.643  292.05
  24   0.0516     98.330  0.0408    98.730  304.62
  25   0.0401     98.650  0.0404    98.750  317.17
  26   0.0503     98.260  0.0389    98.737  329.82
  27   0.0392     98.760  0.0392    98.745  342.39
  28   0.0415     98.600  0.0367    98.858  355.04
  29   0.0388     98.720  0.0363    98.892  367.58
  30   0.0380     98.660  0.0357    98.875  380.12
  31   0.0394     98.660  0.0341    98.955  392.66
  32   0.0367     98.810  0.0342    98.893  405.45
  33   0.0360     98.800  0.0327    98.947  418.04
  34   0.0423     98.580  0.0323    98.993  430.62
  35   0.0381     98.780  0.0315    99.010  443.15
  36   0.0388     98.690  0.0303    99.040  455.75
  37   0.0433     98.590  0.0299    99.020  468.30
  38   0.0369     98.730  0.0309    98.995  480.88
  39   0.0417     98.660  0.0298    99.043  493.45
  40   0.0371     98.720  0.0286    99.068  506.04
  41   0.0392     98.730  0.0283    99.077  518.75
  42   0.0401     98.700  0.0282    99.100  531.28
  43   0.0374     98.750  0.0272    99.095  543.85
  44   0.0358     98.850  0.0269    99.147  556.53
  45   0.0317     98.900  0.0268    99.108  569.08
  46   0.0436     98.640  0.0256    99.175  581.64
  47   0.0310     98.940  0.0250    99.175  594.25
  48   0.0389     98.700  0.0246    99.207  606.82
  49   0.0367     98.810  0.0238    99.222  619.39
  50   0.0438     98.510  0.0247    99.223  631.97
  51   0.0305     98.920  0.0251    99.207  644.55
  52   0.0355     98.890  0.0227    99.293  657.13
  53   0.0519     98.450  0.0230    99.280  669.71
  54   0.0339     98.780  0.0229    99.222  682.41
  55   0.0335     98.910  0.0225    99.315  694.98
  56   0.0343     98.810  0.0220    99.297  707.55
  57   0.0352     98.740  0.0217    99.307  720.25
  58   0.0317     98.950  0.0221    99.277  732.83
  59   0.0331     98.790  0.0211    99.302  745.39
  60   0.0365     98.860  0.0210    99.288  758.06
  61   0.0342     98.900  0.0210    99.320  770.65
  62   0.0372     98.760  0.0203    99.310  783.21
  63   0.0357     98.810  0.0202    99.360  795.79
  64   0.0368     98.800  0.0203    99.290  808.48
  65   0.0313     98.970  0.0203    99.310  821.07
  66   0.0357     98.880  0.0196    99.355  833.68
  67   0.0336     98.760  0.0189    99.355  846.23
  68   0.0382     98.690  0.0192    99.353  858.82
  69   0.0348     98.740  0.0178    99.425  871.40
  70   0.0347     98.810  0.0188    99.392  883.98
  71   0.0350     98.790  0.0189    99.372  896.61
  72   0.0326     98.870  0.0177    99.392  909.17
  73   0.0293     98.970  0.0171    99.462  921.74
  74   0.0316     98.920  0.0174    99.453  934.32
  75   0.0396     98.750  0.0167    99.410  946.90
  76   0.0334     98.970  0.0176    99.397  959.52
  77   0.0322     98.920  0.0174    99.407  972.13
  78   0.0329     98.950  0.0168    99.472  984.82
  79   0.0368     98.720  0.0163    99.465  997.37
  80   0.0312     98.950  0.0151    99.487  1009.95
  81   0.0380     98.740  0.0159    99.497  1022.65
  82   0.0390     98.720  0.0163    99.478  1035.25
  83   0.0335     98.990  0.0155    99.478  1047.86
  84   0.0272     99.090  0.0161    99.477  1060.44
  85   0.0338     98.940  0.0149    99.493  1073.02
  86   0.0327     98.930  0.0154    99.457  1085.60
  87   0.0311     98.980  0.0153    99.477  1098.17
  88   0.0355     98.830  0.0153    99.492  1110.89
  89   0.0314     98.960  0.0148    99.527  1123.46
  90   0.0365     98.780  0.0147    99.547  1136.07
