Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6916054016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2234     70.870  1.8366    36.417  8.91
   2   0.3820     89.620  0.7573    79.718  16.04
   3   0.2381     93.070  0.3475    90.093  23.12
   4   0.1754     94.740  0.2392    92.942  30.31
   5   0.1529     95.350  0.1909    94.362  37.42
   6   0.1239     96.130  0.1585    95.273  44.62
   7   0.1109     96.610  0.1364    95.958  51.74
   8   0.1027     96.770  0.1212    96.298  58.86
   9   0.0904     97.130  0.1119    96.593  66.06
  10   0.0841     97.370  0.1000    96.975  73.18
  11   0.0755     97.570  0.0918    97.143  80.30
  12   0.0764     97.630  0.0853    97.420  87.54
  13   0.0727     97.640  0.0797    97.562  94.67
  14   0.0636     97.870  0.0753    97.670  101.83
  15   0.0610     98.020  0.0704    97.880  108.95
  16   0.0626     97.950  0.0678    97.945  116.06
  17   0.0636     97.910  0.0632    98.038  123.18
  18   0.0564     98.250  0.0607    98.137  130.49
  19   0.0526     98.350  0.0591    98.185  137.62
  20   0.0589     98.080  0.0568    98.177  144.73
  21   0.0528     98.180  0.0550    98.322  151.85
  22   0.0533     98.120  0.0522    98.408  158.97
  23   0.0499     98.240  0.0509    98.420  166.29
  24   0.0463     98.380  0.0506    98.418  173.38
  25   0.0492     98.320  0.0488    98.450  180.48
  26   0.0474     98.440  0.0472    98.502  187.61
  27   0.0482     98.330  0.0451    98.597  194.73
  28   0.0451     98.540  0.0444    98.603  201.94
  29   0.0425     98.580  0.0431    98.675  209.19
  30   0.0470     98.410  0.0420    98.663  216.30
  31   0.0464     98.530  0.0405    98.757  223.41
  32   0.0471     98.380  0.0399    98.732  230.52
  33   0.0433     98.540  0.0394    98.735  237.76
  34   0.0447     98.520  0.0375    98.842  244.90
  35   0.0439     98.490  0.0378    98.857  252.14
  36   0.0437     98.620  0.0379    98.797  259.26
  37   0.0447     98.460  0.0361    98.847  266.35
  38   0.0388     98.660  0.0363    98.825  273.57
  39   0.0437     98.540  0.0350    98.878  280.67
  40   0.0417     98.520  0.0347    98.892  287.81
  41   0.0385     98.740  0.0338    98.980  295.03
  42   0.0398     98.640  0.0338    98.952  302.25
  43   0.0382     98.730  0.0329    98.947  309.39
  44   0.0396     98.680  0.0317    98.998  316.50
  45   0.0436     98.560  0.0321    99.017  323.61
  46   0.0397     98.740  0.0312    99.017  330.85
  47   0.0419     98.500  0.0307    99.027  338.05
  48   0.0418     98.510  0.0295    99.047  345.16
  49   0.0412     98.560  0.0294    99.077  352.28
  50   0.0399     98.600  0.0294    99.093  359.38
  51   0.0356     98.810  0.0289    99.070  366.55
  52   0.0393     98.660  0.0286    99.062  373.79
  53   0.0369     98.730  0.0275    99.150  380.96
  54   0.0390     98.620  0.0274    99.140  388.08
  55   0.0383     98.700  0.0274    99.153  395.20
  56   0.0371     98.720  0.0268    99.142  402.29
  57   0.0356     98.750  0.0269    99.138  409.52
  58   0.0355     98.780  0.0271    99.143  416.75
  59   0.0362     98.720  0.0256    99.190  423.86
  60   0.0428     98.590  0.0258    99.170  430.98
  61   0.0381     98.720  0.0261    99.170  438.09
  62   0.0337     98.860  0.0251    99.163  445.29
  63   0.0349     98.810  0.0248    99.247  452.50
  64   0.0339     98.870  0.0237    99.225  459.61
  65   0.0350     98.950  0.0239    99.248  466.71
  66   0.0330     98.920  0.0230    99.255  473.85
  67   0.0358     98.830  0.0231    99.243  480.97
  68   0.0373     98.800  0.0234    99.247  488.12
  69   0.0347     98.850  0.0226    99.270  495.36
  70   0.0336     98.830  0.0226    99.263  502.47
  71   0.0331     98.900  0.0220    99.287  509.61
  72   0.0409     98.510  0.0224    99.303  516.82
  73   0.0369     98.750  0.0224    99.267  523.92
  74   0.0345     98.780  0.0208    99.328  531.03
  75   0.0345     98.830  0.0203    99.380  538.23
  76   0.0337     98.900  0.0204    99.345  545.37
  77   0.0371     98.850  0.0209    99.332  552.60
  78   0.0331     98.930  0.0209    99.287  559.76
  79   0.0373     98.840  0.0206    99.342  566.87
  80   0.0344     98.880  0.0206    99.352  574.01
  81   0.0318     98.990  0.0208    99.343  581.24
  82   0.0339     98.910  0.0187    99.360  588.44
  83   0.0362     98.760  0.0188    99.403  595.58
  84   0.0402     98.760  0.0197    99.327  602.70
  85   0.0375     98.810  0.0186    99.408  609.81
  86   0.0386     98.810  0.0184    99.382  617.10
  87   0.0440     98.510  0.0189    99.405  624.22
  88   0.0370     98.820  0.0191    99.375  631.30
  89   0.0370     98.740  0.0176    99.435  638.42
  90   0.0321     98.930  0.0177    99.438  645.53
