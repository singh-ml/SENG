Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6916054016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4764     58.790  1.9354    31.373  9.02
   2   0.5515     84.930  0.9937    73.558  16.14
   3   0.3378     89.750  0.4745    86.410  23.28
   4   0.2442     92.710  0.3232    90.572  30.50
   5   0.1945     94.180  0.2497    92.530  37.65
   6   0.1587     95.130  0.1987    94.037  44.90
   7   0.1426     95.580  0.1706    94.897  52.03
   8   0.1174     96.530  0.1500    95.527  59.16
   9   0.1067     96.690  0.1340    95.935  66.36
  10   0.0980     97.020  0.1211    96.302  73.47
  11   0.0926     97.170  0.1099    96.655  80.64
  12   0.0899     97.290  0.1032    96.835  87.84
  13   0.0807     97.490  0.0961    97.020  95.05
  14   0.0804     97.460  0.0895    97.283  102.18
  15   0.0760     97.570  0.0856    97.373  109.29
  16   0.0703     97.810  0.0812    97.547  116.42
  17   0.0686     97.840  0.0771    97.637  123.54
  18   0.0686     97.900  0.0731    97.713  130.89
  19   0.0666     97.930  0.0692    97.857  138.02
  20   0.0615     98.010  0.0666    97.900  145.16
  21   0.0645     97.950  0.0636    98.070  152.27
  22   0.0589     98.140  0.0606    98.157  159.44
  23   0.0585     98.170  0.0604    98.103  166.67
  24   0.0576     98.170  0.0584    98.175  173.81
  25   0.0556     98.180  0.0563    98.260  180.92
  26   0.0537     98.260  0.0538    98.373  188.05
  27   0.0528     98.290  0.0532    98.328  195.17
  28   0.0544     98.260  0.0515    98.383  202.40
  29   0.0547     98.250  0.0498    98.500  209.59
  30   0.0546     98.230  0.0490    98.445  216.74
  31   0.0502     98.420  0.0475    98.485  223.88
  32   0.0527     98.300  0.0474    98.525  231.01
  33   0.0530     98.310  0.0463    98.548  238.22
  34   0.0491     98.400  0.0449    98.607  245.38
  35   0.0491     98.350  0.0422    98.692  252.63
  36   0.0468     98.390  0.0429    98.673  259.78
  37   0.0475     98.420  0.0412    98.703  266.88
  38   0.0455     98.400  0.0415    98.678  274.13
  39   0.0456     98.390  0.0396    98.767  281.32
  40   0.0447     98.440  0.0384    98.807  288.48
  41   0.0468     98.410  0.0381    98.825  295.72
  42   0.0490     98.310  0.0385    98.735  302.86
  43   0.0429     98.540  0.0367    98.848  310.11
  44   0.0433     98.440  0.0377    98.808  317.22
  45   0.0422     98.530  0.0356    98.908  324.35
  46   0.0439     98.470  0.0353    98.912  331.56
  47   0.0426     98.580  0.0346    98.940  338.67
  48   0.0434     98.530  0.0349    98.933  345.80
  49   0.0442     98.380  0.0335    98.947  352.93
  50   0.0440     98.520  0.0324    99.013  360.07
  51   0.0434     98.550  0.0322    98.968  367.20
  52   0.0434     98.450  0.0316    99.002  374.53
  53   0.0401     98.670  0.0327    98.972  381.68
  54   0.0400     98.550  0.0315    98.972  388.83
  55   0.0416     98.560  0.0313    99.037  395.96
  56   0.0437     98.470  0.0305    99.028  403.09
  57   0.0403     98.540  0.0295    99.045  410.33
  58   0.0412     98.600  0.0294    99.040  417.56
  59   0.0391     98.600  0.0289    99.110  424.72
  60   0.0379     98.670  0.0275    99.117  431.87
  61   0.0379     98.680  0.0288    99.095  439.01
  62   0.0402     98.590  0.0295    99.038  446.27
  63   0.0390     98.670  0.0278    99.155  453.55
  64   0.0382     98.770  0.0279    99.105  460.68
  65   0.0440     98.460  0.0273    99.152  467.80
  66   0.0384     98.660  0.0268    99.125  474.96
  67   0.0378     98.710  0.0260    99.177  482.19
  68   0.0403     98.560  0.0264    99.142  489.32
  69   0.0423     98.550  0.0258    99.165  496.57
  70   0.0383     98.680  0.0248    99.217  503.71
  71   0.0370     98.710  0.0244    99.225  510.84
  72   0.0372     98.700  0.0249    99.200  518.04
  73   0.0397     98.720  0.0249    99.212  525.18
  74   0.0379     98.650  0.0235    99.278  532.31
  75   0.0338     98.830  0.0237    99.245  539.53
  76   0.0366     98.750  0.0238    99.238  546.63
  77   0.0327     98.810  0.0232    99.248  553.87
  78   0.0370     98.720  0.0239    99.192  561.01
  79   0.0334     98.920  0.0230    99.285  568.17
  80   0.0358     98.840  0.0225    99.282  575.32
  81   0.0348     98.740  0.0233    99.242  582.55
  82   0.0382     98.590  0.0216    99.355  589.77
  83   0.0365     98.760  0.0230    99.293  596.90
  84   0.0322     98.800  0.0219    99.307  604.04
  85   0.0361     98.820  0.0213    99.328  611.16
  86   0.0361     98.790  0.0203    99.345  618.42
  87   0.0350     98.820  0.0212    99.318  625.63
  88   0.0379     98.740  0.0219    99.320  632.76
  89   0.0415     98.590  0.0212    99.302  639.91
  90   0.0346     98.780  0.0203    99.365  647.05
