Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6916054016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.2680     91.680  1.0117    67.027  8.91
   2   0.1414     95.650  0.2134    93.515  15.99
   3   0.1043     96.660  0.1386    95.697  23.06
   4   0.0819     97.390  0.1045    96.695  30.14
   5   0.0753     97.580  0.0872    97.272  37.31
   6   0.0694     97.800  0.0761    97.497  44.52
   7   0.0605     98.210  0.0671    97.932  51.67
   8   0.0550     98.230  0.0598    98.138  58.75
   9   0.0559     98.190  0.0566    98.137  65.94
  10   0.0521     98.250  0.0515    98.368  73.06
  11   0.0434     98.580  0.0486    98.465  80.13
  12   0.0456     98.530  0.0450    98.585  87.36
  13   0.0509     98.400  0.0432    98.675  94.49
  14   0.0441     98.560  0.0410    98.688  101.67
  15   0.0447     98.680  0.0399    98.745  108.77
  16   0.0436     98.580  0.0379    98.867  115.87
  17   0.0390     98.710  0.0356    98.863  122.97
  18   0.0365     98.840  0.0364    98.828  130.19
  19   0.0412     98.710  0.0340    98.965  137.44
  20   0.0407     98.620  0.0338    98.928  144.55
  21   0.0374     98.800  0.0315    98.963  151.66
  22   0.0414     98.730  0.0311    98.985  158.79
  23   0.0429     98.540  0.0289    99.085  166.01
  24   0.0361     98.820  0.0288    99.103  173.17
  25   0.0312     99.070  0.0275    99.142  180.27
  26   0.0415     98.610  0.0267    99.128  187.37
  27   0.0303     99.030  0.0264    99.162  194.43
  28   0.0323     98.950  0.0257    99.170  201.49
  29   0.0423     98.610  0.0263    99.147  208.71
  30   0.0393     98.760  0.0250    99.185  215.83
  31   0.0360     98.930  0.0231    99.230  222.94
  32   0.0349     98.810  0.0237    99.217  230.01
  33   0.0378     98.760  0.0223    99.280  237.11
  34   0.0373     98.810  0.0222    99.297  244.32
  35   0.0305     99.040  0.0219    99.337  251.53
  36   0.0283     99.090  0.0208    99.337  258.67
  37   0.0300     98.930  0.0203    99.342  265.80
  38   0.0289     99.070  0.0214    99.312  272.91
  39   0.0325     99.010  0.0203    99.368  280.00
  40   0.0307     99.040  0.0197    99.350  287.06
  41   0.0321     98.940  0.0191    99.397  294.25
  42   0.0288     99.140  0.0196    99.368  301.40
  43   0.0323     98.970  0.0187    99.418  308.54
  44   0.0327     98.980  0.0172    99.443  315.73
  45   0.0322     99.030  0.0180    99.413  322.84
  46   0.0290     99.080  0.0171    99.465  330.05
  47   0.0280     99.160  0.0164    99.498  337.15
  48   0.0299     99.110  0.0172    99.462  344.23
  49   0.0268     99.140  0.0166    99.468  351.43
  50   0.0330     99.060  0.0158    99.512  358.51
  51   0.0288     99.040  0.0151    99.515  365.60
  52   0.0296     99.010  0.0155    99.517  372.83
  53   0.0297     99.020  0.0155    99.507  379.97
  54   0.0271     99.180  0.0145    99.550  387.15
  55   0.0270     99.140  0.0146    99.537  394.24
  56   0.0298     99.080  0.0150    99.533  401.34
  57   0.0277     99.130  0.0139    99.560  408.43
  58   0.0292     99.060  0.0142    99.547  415.63
  59   0.0310     99.060  0.0139    99.557  422.74
  60   0.0288     99.040  0.0127    99.600  429.84
  61   0.0288     99.090  0.0133    99.612  436.99
  62   0.0288     99.030  0.0132    99.583  444.11
  63   0.0303     99.060  0.0125    99.603  451.42
  64   0.0284     99.130  0.0129    99.603  458.52
  65   0.0303     99.100  0.0118    99.642  465.66
  66   0.0300     99.050  0.0119    99.608  472.75
  67   0.0277     99.180  0.0120    99.625  479.88
  68   0.0300     99.050  0.0120    99.618  487.08
  69   0.0300     99.090  0.0109    99.642  494.27
  70   0.0280     99.190  0.0112    99.657  501.38
  71   0.0227     99.300  0.0113    99.653  508.47
  72   0.0278     99.210  0.0111    99.675  515.58
  73   0.0297     99.160  0.0111    99.658  522.75
  74   0.0270     99.220  0.0107    99.687  529.85
  75   0.0260     99.230  0.0105    99.675  537.06
  76   0.0272     99.190  0.0109    99.663  544.16
  77   0.0280     99.140  0.0101    99.678  551.23
  78   0.0290     99.170  0.0106    99.678  558.45
  79   0.0281     99.130  0.0107    99.673  565.53
  80   0.0277     99.150  0.0101    99.697  572.65
  81   0.0259     99.300  0.0100    99.703  579.89
  82   0.0316     99.040  0.0100    99.680  587.01
  83   0.0307     99.010  0.0105    99.648  594.21
  84   0.0281     99.190  0.0102    99.695  601.31
  85   0.0272     99.220  0.0098    99.682  608.44
