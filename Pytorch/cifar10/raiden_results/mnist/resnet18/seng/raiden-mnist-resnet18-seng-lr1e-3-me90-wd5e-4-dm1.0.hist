Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6919986176 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4095     64.390  1.9340    33.725  8.94
   2   0.5038     85.370  0.9211    75.118  16.08
   3   0.3193     89.930  0.4459    86.792  23.22
   4   0.2370     92.600  0.3101    90.678  30.31
   5   0.1958     93.970  0.2404    92.812  37.43
   6   0.1585     95.040  0.1971    94.180  44.63
   7   0.1384     95.750  0.1691    94.928  51.74
   8   0.1174     96.350  0.1484    95.497  58.95
   9   0.1133     96.510  0.1328    96.057  66.05
  10   0.1028     96.780  0.1211    96.298  73.15
  11   0.0997     96.910  0.1106    96.605  80.27
  12   0.0922     97.170  0.1034    96.877  87.47
  13   0.0843     97.360  0.0952    97.148  94.64
  14   0.0767     97.670  0.0903    97.240  101.74
  15   0.0753     97.700  0.0854    97.393  108.90
  16   0.0744     97.790  0.0804    97.548  116.05
  17   0.0710     97.770  0.0773    97.658  123.15
  18   0.0643     98.050  0.0738    97.738  130.44
  19   0.0713     97.760  0.0695    97.945  137.56
  20   0.0600     98.270  0.0669    97.978  144.64
  21   0.0607     98.180  0.0637    98.095  151.74
  22   0.0558     98.300  0.0614    98.103  158.86
  23   0.0585     98.230  0.0606    98.122  166.18
  24   0.0574     98.260  0.0578    98.232  173.26
  25   0.0527     98.320  0.0570    98.257  180.35
  26   0.0526     98.430  0.0535    98.380  187.44
  27   0.0504     98.410  0.0540    98.298  194.63
  28   0.0499     98.450  0.0515    98.438  201.74
  29   0.0543     98.310  0.0505    98.423  208.96
  30   0.0479     98.410  0.0487    98.465  216.05
  31   0.0485     98.470  0.0469    98.550  223.13
  32   0.0499     98.460  0.0464    98.610  230.36
  33   0.0477     98.410  0.0459    98.635  237.46
  34   0.0451     98.540  0.0449    98.603  244.63
  35   0.0462     98.600  0.0442    98.657  251.84
  36   0.0467     98.530  0.0429    98.627  258.92
  37   0.0472     98.430  0.0418    98.723  266.12
  38   0.0414     98.640  0.0405    98.737  273.21
  39   0.0395     98.700  0.0403    98.745  280.33
  40   0.0467     98.530  0.0397    98.773  287.45
  41   0.0443     98.510  0.0389    98.787  294.67
  42   0.0423     98.580  0.0386    98.758  301.78
  43   0.0430     98.590  0.0366    98.887  308.98
  44   0.0430     98.700  0.0371    98.867  316.07
  45   0.0375     98.740  0.0356    98.872  323.14
  46   0.0431     98.580  0.0358    98.920  330.36
  47   0.0405     98.600  0.0341    98.968  337.43
  48   0.0432     98.700  0.0340    98.942  344.63
  49   0.0388     98.790  0.0336    98.977  351.76
  50   0.0373     98.780  0.0324    98.993  358.88
  51   0.0342     98.920  0.0321    99.013  365.96
  52   0.0362     98.830  0.0323    99.010  373.18
  53   0.0380     98.790  0.0327    98.960  380.37
  54   0.0367     98.850  0.0313    99.045  387.46
  55   0.0381     98.750  0.0310    99.030  394.57
  56   0.0367     98.810  0.0306    99.045  401.66
  57   0.0358     98.800  0.0299    99.038  408.74
  58   0.0358     98.880  0.0295    99.038  415.98
  59   0.0362     98.840  0.0290    99.103  423.06
  60   0.0370     98.830  0.0287    99.070  430.15
  61   0.0358     98.880  0.0277    99.123  437.25
  62   0.0351     98.840  0.0291    99.068  444.42
  63   0.0350     98.880  0.0272    99.135  451.63
  64   0.0361     98.770  0.0280    99.137  458.74
  65   0.0350     98.910  0.0264    99.168  465.86
  66   0.0374     98.790  0.0268    99.170  473.04
  67   0.0369     98.780  0.0255    99.198  480.23
  68   0.0345     98.940  0.0276    99.125  487.31
  69   0.0409     98.620  0.0251    99.188  494.49
  70   0.0381     98.690  0.0255    99.185  501.59
  71   0.0345     98.830  0.0238    99.237  508.68
  72   0.0372     98.720  0.0250    99.208  515.92
  73   0.0325     98.880  0.0245    99.213  523.03
  74   0.0378     98.760  0.0244    99.242  530.10
  75   0.0356     98.750  0.0241    99.212  537.32
  76   0.0353     98.770  0.0239    99.260  544.45
  77   0.0347     98.850  0.0230    99.247  551.67
  78   0.0316     98.960  0.0231    99.262  558.80
  79   0.0341     98.900  0.0225    99.282  565.92
  80   0.0351     98.810  0.0226    99.323  573.04
  81   0.0348     98.770  0.0219    99.330  580.24
  82   0.0343     98.910  0.0227    99.280  587.46
  83   0.0371     98.850  0.0223    99.277  594.56
  84   0.0331     98.840  0.0210    99.348  601.67
  85   0.0355     98.850  0.0210    99.367  608.76
  86   0.0317     98.930  0.0215    99.328  615.99
  87   0.0330     98.900  0.0210    99.315  623.16
  88   0.0335     98.900  0.0211    99.373  630.25
  89   0.0305     99.010  0.0203    99.363  637.38
  90   0.0296     98.970  0.0202    99.325  644.46
