Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6916054016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5568     58.120  1.9504    30.965  8.98
   2   0.6616     82.400  1.1619    68.475  16.05
   3   0.4017     87.840  0.5725    83.392  23.10
   4   0.2919     91.230  0.3910    88.305  30.16
   5   0.2289     93.190  0.3037    91.012  37.23
   6   0.1952     94.360  0.2474    92.678  44.51
   7   0.1654     95.010  0.2105    93.718  51.58
   8   0.1508     95.380  0.1834    94.487  58.66
   9   0.1444     95.550  0.1666    95.003  65.72
  10   0.1257     96.150  0.1507    95.448  72.78
  11   0.1149     96.620  0.1388    95.763  79.95
  12   0.1113     96.580  0.1286    96.118  87.14
  13   0.0997     96.670  0.1211    96.262  94.20
  14   0.0956     96.930  0.1124    96.520  101.26
  15   0.0922     96.950  0.1063    96.760  108.41
  16   0.0889     97.110  0.1001    96.935  115.50
  17   0.0850     97.300  0.0949    97.133  122.58
  18   0.0857     97.260  0.0908    97.243  129.81
  19   0.0778     97.480  0.0854    97.430  136.89
  20   0.0755     97.480  0.0823    97.472  144.07
  21   0.0719     97.580  0.0782    97.560  151.16
  22   0.0700     97.800  0.0732    97.740  158.22
  23   0.0697     97.820  0.0715    97.793  165.39
  24   0.0655     97.860  0.0703    97.880  172.47
  25   0.0660     97.930  0.0676    97.940  179.59
  26   0.0621     98.060  0.0654    97.995  186.76
  27   0.0656     97.770  0.0623    98.058  193.84
  28   0.0584     98.140  0.0610    98.158  200.91
  29   0.0604     98.040  0.0593    98.220  208.08
  30   0.0584     98.060  0.0574    98.223  215.15
  31   0.0594     98.030  0.0560    98.265  222.33
  32   0.0582     98.020  0.0534    98.392  229.39
  33   0.0567     98.110  0.0536    98.393  236.49
  34   0.0554     98.160  0.0516    98.383  243.57
  35   0.0548     98.130  0.0500    98.473  250.73
  36   0.0520     98.300  0.0503    98.428  257.92
  37   0.0528     98.240  0.0495    98.470  265.06
  38   0.0496     98.350  0.0475    98.497  272.16
  39   0.0502     98.290  0.0476    98.522  279.27
  40   0.0466     98.400  0.0443    98.628  286.35
  41   0.0505     98.240  0.0443    98.650  293.62
  42   0.0501     98.350  0.0449    98.615  300.70
  43   0.0513     98.180  0.0442    98.640  307.78
  44   0.0512     98.210  0.0417    98.695  314.86
  45   0.0470     98.300  0.0413    98.750  321.94
  46   0.0491     98.290  0.0406    98.758  329.22
  47   0.0452     98.460  0.0404    98.745  336.29
  48   0.0497     98.350  0.0398    98.762  343.37
  49   0.0446     98.400  0.0396    98.738  350.44
  50   0.0489     98.360  0.0377    98.817  357.50
  51   0.0426     98.460  0.0376    98.797  364.66
  52   0.0421     98.550  0.0368    98.888  371.84
  53   0.0449     98.510  0.0364    98.875  378.90
  54   0.0440     98.560  0.0368    98.842  385.96
  55   0.0485     98.400  0.0356    98.928  393.02
  56   0.0423     98.530  0.0348    98.895  400.13
  57   0.0472     98.370  0.0350    98.912  407.23
  58   0.0473     98.410  0.0343    98.903  414.40
  59   0.0429     98.500  0.0342    98.948  421.47
  60   0.0423     98.510  0.0331    98.953  428.67
  61   0.0447     98.410  0.0326    98.968  435.73
  62   0.0435     98.500  0.0323    99.003  442.78
  63   0.0406     98.540  0.0324    98.995  449.96
  64   0.0412     98.580  0.0314    99.023  457.03
  65   0.0436     98.570  0.0318    99.027  464.20
  66   0.0422     98.490  0.0323    98.970  471.26
  67   0.0436     98.500  0.0306    99.038  478.37
  68   0.0424     98.440  0.0305    99.050  485.42
  69   0.0428     98.570  0.0299    99.060  492.59
  70   0.0433     98.460  0.0295    99.032  499.78
  71   0.0396     98.600  0.0290    99.062  506.88
  72   0.0396     98.600  0.0283    99.125  513.94
  73   0.0370     98.660  0.0283    99.138  520.99
  74   0.0392     98.560  0.0282    99.090  528.07
  75   0.0350     98.810  0.0277    99.118  535.25
  76   0.0386     98.710  0.0281    99.113  542.33
  77   0.0406     98.560  0.0273    99.167  549.42
  78   0.0393     98.590  0.0268    99.180  556.50
  79   0.0367     98.670  0.0258    99.195  563.59
  80   0.0411     98.540  0.0259    99.165  570.79
  81   0.0364     98.740  0.0264    99.112  577.96
  82   0.0402     98.630  0.0264    99.213  585.03
  83   0.0368     98.750  0.0260    99.195  592.10
  84   0.0396     98.610  0.0257    99.185  599.18
  85   0.0377     98.720  0.0250    99.208  606.31
  86   0.0381     98.670  0.0248    99.228  613.52
  87   0.0378     98.680  0.0251    99.215  620.60
  88   0.0371     98.790  0.0252    99.202  627.68
  89   0.0365     98.820  0.0248    99.187  634.80
  90   0.0382     98.750  0.0239    99.232  641.99
