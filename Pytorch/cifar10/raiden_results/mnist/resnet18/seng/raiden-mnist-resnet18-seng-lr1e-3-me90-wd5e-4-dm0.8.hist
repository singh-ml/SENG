Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6919986176 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.0452     73.700  1.7927    40.130  8.97
   2   0.3855     88.630  0.6868    80.722  16.22
   3   0.2559     92.280  0.3567    89.127  23.34
   4   0.2021     93.680  0.2584    92.198  30.43
   5   0.1616     94.660  0.2036    93.820  37.55
   6   0.1296     95.840  0.1676    94.888  44.73
   7   0.1160     96.280  0.1444    95.508  51.96
   8   0.1029     96.810  0.1241    96.323  59.11
   9   0.0958     96.870  0.1108    96.635  66.24
  10   0.0874     97.230  0.1016    96.883  73.38
  11   0.0762     97.550  0.0926    97.140  80.53
  12   0.0733     97.670  0.0850    97.350  87.88
  13   0.0695     97.770  0.0813    97.462  95.08
  14   0.0692     97.750  0.0753    97.692  102.20
  15   0.0652     97.880  0.0709    97.855  109.29
  16   0.0659     97.880  0.0679    97.932  116.38
  17   0.0603     97.990  0.0642    98.018  123.60
  18   0.0567     98.070  0.0619    98.077  130.82
  19   0.0542     98.220  0.0582    98.223  137.95
  20   0.0539     98.200  0.0574    98.283  145.07
  21   0.0490     98.430  0.0553    98.295  152.19
  22   0.0510     98.320  0.0525    98.437  159.42
  23   0.0524     98.230  0.0506    98.472  166.66
  24   0.0480     98.340  0.0493    98.472  173.80
  25   0.0478     98.400  0.0471    98.508  180.91
  26   0.0512     98.300  0.0468    98.547  188.02
  27   0.0467     98.460  0.0454    98.615  195.27
  28   0.0433     98.530  0.0444    98.587  202.45
  29   0.0485     98.390  0.0426    98.673  209.69
  30   0.0448     98.510  0.0414    98.693  216.85
  31   0.0438     98.510  0.0409    98.718  224.06
  32   0.0412     98.630  0.0393    98.803  231.20
  33   0.0434     98.610  0.0394    98.795  238.33
  34   0.0494     98.400  0.0380    98.827  245.45
  35   0.0437     98.540  0.0371    98.857  252.67
  36   0.0409     98.730  0.0364    98.853  259.95
  37   0.0431     98.480  0.0358    98.860  267.08
  38   0.0384     98.740  0.0350    98.882  274.19
  39   0.0406     98.670  0.0357    98.918  281.31
  40   0.0396     98.660  0.0336    98.953  288.41
  41   0.0369     98.840  0.0332    98.965  295.74
  42   0.0446     98.600  0.0328    98.948  302.86
  43   0.0424     98.610  0.0323    98.978  310.02
  44   0.0391     98.690  0.0307    99.047  317.14
  45   0.0383     98.740  0.0315    99.013  324.28
  46   0.0379     98.760  0.0293    99.093  331.56
  47   0.0412     98.700  0.0299    99.065  338.70
  48   0.0389     98.720  0.0295    99.085  345.82
  49   0.0434     98.550  0.0286    99.060  352.93
  50   0.0367     98.700  0.0282    99.118  360.07
  51   0.0392     98.700  0.0280    99.095  367.27
  52   0.0371     98.750  0.0279    99.123  374.51
  53   0.0367     98.870  0.0269    99.152  381.66
  54   0.0373     98.760  0.0263    99.145  388.76
  55   0.0352     98.860  0.0265    99.183  395.90
  56   0.0339     98.860  0.0252    99.225  403.13
  57   0.0361     98.870  0.0260    99.175  410.27
  58   0.0310     98.980  0.0252    99.172  417.48
  59   0.0385     98.640  0.0247    99.245  424.59
  60   0.0357     98.830  0.0241    99.238  431.73
  61   0.0350     98.860  0.0239    99.273  438.96
  62   0.0374     98.750  0.0239    99.232  446.09
  63   0.0347     98.860  0.0229    99.262  453.32
  64   0.0353     98.810  0.0236    99.232  460.42
  65   0.0356     98.850  0.0225    99.277  467.55
  66   0.0344     98.910  0.0238    99.253  474.77
  67   0.0359     98.770  0.0226    99.237  481.90
  68   0.0360     98.840  0.0217    99.270  489.01
  69   0.0384     98.780  0.0217    99.295  496.24
  70   0.0356     98.920  0.0216    99.335  503.36
  71   0.0365     98.800  0.0209    99.345  510.59
  72   0.0336     98.980  0.0207    99.365  517.73
  73   0.0395     98.780  0.0209    99.348  524.83
  74   0.0318     98.970  0.0214    99.292  531.96
  75   0.0377     98.770  0.0197    99.387  539.18
  76   0.0457     98.590  0.0207    99.357  546.40
  77   0.0361     98.830  0.0201    99.348  553.53
  78   0.0321     98.950  0.0198    99.345  560.62
  79   0.0319     98.940  0.0197    99.363  567.81
  80   0.0315     98.960  0.0186    99.402  574.93
  81   0.0305     98.890  0.0179    99.412  582.28
  82   0.0331     98.830  0.0180    99.415  589.37
  83   0.0315     98.980  0.0187    99.415  596.52
  84   0.0362     98.820  0.0183    99.410  603.62
  85   0.0330     98.910  0.0178    99.467  610.75
  86   0.0358     98.830  0.0188    99.383  617.98
  87   0.0344     98.730  0.0182    99.415  625.09
  88   0.0327     98.930  0.0176    99.435  632.19
  89   0.0370     98.790  0.0177    99.437  639.31
  90   0.0330     98.910  0.0176    99.455  646.45
