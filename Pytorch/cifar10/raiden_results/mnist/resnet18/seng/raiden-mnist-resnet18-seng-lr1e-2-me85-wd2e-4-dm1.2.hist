Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6922345472 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   0.1718     94.790  0.7320    75.993  9.07
   2   0.0900     97.080  0.1377    95.768  16.27
   3   0.0677     97.800  0.0890    97.270  23.40
   4   0.0640     97.910  0.0728    97.753  30.48
   5   0.0474     98.380  0.0609    98.107  37.56
   6   0.0557     98.180  0.0558    98.275  44.79
   7   0.0551     98.030  0.0500    98.435  51.88
   8   0.0518     98.380  0.0465    98.528  59.10
   9   0.0440     98.630  0.0431    98.625  66.21
  10   0.0387     98.690  0.0409    98.737  73.33
  11   0.0393     98.650  0.0396    98.703  80.45
  12   0.0369     98.700  0.0368    98.828  87.76
  13   0.0466     98.310  0.0354    98.863  94.85
  14   0.0311     98.970  0.0328    98.972  101.96
  15   0.0323     98.850  0.0328    98.937  109.06
  16   0.0323     98.870  0.0312    98.985  116.18
  17   0.0369     98.750  0.0298    99.030  123.38
  18   0.0335     98.880  0.0292    99.047  130.61
  19   0.0376     98.820  0.0279    99.103  137.72
  20   0.0374     98.850  0.0257    99.183  144.80
  21   0.0336     98.910  0.0251    99.188  151.92
  22   0.0285     98.960  0.0252    99.253  159.12
  23   0.0338     98.860  0.0243    99.208  166.33
  24   0.0345     98.840  0.0219    99.307  173.42
  25   0.0317     98.990  0.0230    99.197  180.58
  26   0.0304     99.010  0.0217    99.268  187.66
  27   0.0263     99.100  0.0204    99.347  194.86
  28   0.0352     98.790  0.0209    99.322  201.92
  29   0.0353     98.880  0.0201    99.377  209.13
  30   0.0339     98.930  0.0194    99.365  216.23
  31   0.0303     98.980  0.0183    99.433  223.32
  32   0.0314     98.900  0.0180    99.417  230.57
  33   0.0313     98.920  0.0175    99.443  237.66
  34   0.0306     98.980  0.0180    99.430  244.78
  35   0.0303     98.940  0.0183    99.400  251.96
  36   0.0353     98.880  0.0168    99.483  259.14
  37   0.0268     99.150  0.0160    99.513  266.24
  38   0.0302     98.990  0.0147    99.545  273.35
  39   0.0309     98.980  0.0154    99.500  280.44
  40   0.0285     99.030  0.0144    99.530  287.51
  41   0.0266     99.050  0.0142    99.537  294.73
  42   0.0297     99.040  0.0145    99.543  301.86
  43   0.0308     98.940  0.0141    99.535  308.95
  44   0.0289     99.060  0.0130    99.605  316.05
  45   0.0271     98.990  0.0131    99.592  323.15
  46   0.0282     99.030  0.0125    99.592  330.34
  47   0.0303     98.990  0.0127    99.627  337.52
  48   0.0311     99.040  0.0119    99.617  344.61
  49   0.0277     99.010  0.0115    99.647  351.72
  50   0.0288     99.010  0.0113    99.663  358.86
  51   0.0340     98.820  0.0108    99.667  365.92
  52   0.0306     98.940  0.0110    99.675  373.21
  53   0.0326     98.860  0.0097    99.707  380.31
  54   0.0259     99.140  0.0109    99.660  387.44
  55   0.0319     98.990  0.0100    99.675  394.56
  56   0.0289     98.950  0.0099    99.693  401.64
  57   0.0321     98.890  0.0099    99.700  408.86
  58   0.0291     98.980  0.0096    99.722  416.09
  59   0.0326     98.770  0.0092    99.730  423.18
  60   0.0294     98.960  0.0084    99.755  430.30
  61   0.0296     98.980  0.0095    99.730  437.38
  62   0.0264     99.080  0.0083    99.747  444.54
  63   0.0268     99.090  0.0084    99.760  451.73
  64   0.0256     99.160  0.0073    99.793  458.81
  65   0.0290     98.960  0.0080    99.762  465.91
  66   0.0284     98.990  0.0080    99.770  473.03
  67   0.0257     99.090  0.0076    99.773  480.22
  68   0.0288     99.030  0.0074    99.780  487.34
  69   0.0280     98.970  0.0071    99.823  494.56
  70   0.0323     98.940  0.0070    99.800  501.67
  71   0.0280     99.030  0.0068    99.807  508.87
  72   0.0252     99.140  0.0067    99.793  515.98
  73   0.0307     99.000  0.0073    99.783  523.11
  74   0.0277     99.050  0.0067    99.807  530.20
  75   0.0258     99.100  0.0063    99.825  537.41
  76   0.0278     99.080  0.0065    99.807  544.61
  77   0.0294     99.010  0.0066    99.830  551.68
  78   0.0288     99.030  0.0060    99.827  558.79
  79   0.0291     98.980  0.0059    99.832  565.87
  80   0.0286     99.030  0.0062    99.823  572.97
  81   0.0299     99.020  0.0060    99.840  580.27
  82   0.0303     98.950  0.0063    99.828  587.36
  83   0.0260     99.070  0.0057    99.835  594.48
  84   0.0299     98.950  0.0063    99.818  601.60
  85   0.0274     99.080  0.0060    99.832  608.78
