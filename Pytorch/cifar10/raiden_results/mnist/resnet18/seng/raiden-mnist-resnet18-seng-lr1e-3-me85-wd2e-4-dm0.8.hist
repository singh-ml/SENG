Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 6916054016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.0743     75.250  1.8044    40.268  9.19
   2   0.3784     88.950  0.6931    81.062  16.30
   3   0.2496     92.630  0.3518    89.600  23.39
   4   0.1884     94.360  0.2516    92.592  30.49
   5   0.1549     95.240  0.1990    94.098  37.70
   6   0.1310     95.940  0.1654    94.988  44.93
   7   0.1138     96.440  0.1427    95.775  52.00
   8   0.0985     96.960  0.1260    96.208  59.08
   9   0.0950     97.070  0.1140    96.550  66.18
  10   0.0867     97.470  0.1039    96.840  73.40
  11   0.0780     97.550  0.0943    97.140  80.46
  12   0.0727     97.850  0.0885    97.260  87.68
  13   0.0697     98.000  0.0809    97.475  94.77
  14   0.0636     97.970  0.0775    97.623  101.90
  15   0.0625     98.100  0.0743    97.682  109.15
  16   0.0628     97.980  0.0698    97.768  116.27
  17   0.0606     98.140  0.0673    97.948  123.39
  18   0.0566     98.200  0.0629    98.067  130.60
  19   0.0566     98.320  0.0619    98.075  137.79
  20   0.0540     98.300  0.0582    98.203  144.89
  21   0.0508     98.420  0.0565    98.243  151.99
  22   0.0530     98.350  0.0547    98.322  159.08
  23   0.0469     98.460  0.0528    98.358  166.25
  24   0.0480     98.490  0.0503    98.448  173.46
  25   0.0467     98.450  0.0494    98.422  180.62
  26   0.0465     98.530  0.0485    98.462  187.73
  27   0.0450     98.520  0.0462    98.597  194.84
  28   0.0466     98.460  0.0452    98.598  201.95
  29   0.0482     98.470  0.0452    98.548  209.24
  30   0.0459     98.590  0.0436    98.637  216.34
  31   0.0481     98.320  0.0426    98.688  223.45
  32   0.0443     98.560  0.0424    98.657  230.54
  33   0.0501     98.350  0.0398    98.742  237.63
  34   0.0412     98.620  0.0402    98.695  244.73
  35   0.0458     98.470  0.0395    98.780  252.01
  36   0.0388     98.670  0.0371    98.863  259.12
  37   0.0424     98.510  0.0374    98.793  266.20
  38   0.0433     98.570  0.0372    98.837  273.30
  39   0.0451     98.600  0.0359    98.857  280.49
  40   0.0378     98.720  0.0344    98.912  287.57
  41   0.0417     98.490  0.0348    98.932  294.77
  42   0.0389     98.640  0.0336    98.923  301.86
  43   0.0379     98.650  0.0342    98.950  308.95
  44   0.0381     98.760  0.0328    98.950  316.06
  45   0.0418     98.610  0.0324    98.958  323.27
  46   0.0419     98.480  0.0309    99.038  330.48
  47   0.0402     98.600  0.0316    98.995  337.58
  48   0.0390     98.620  0.0307    98.988  344.67
  49   0.0367     98.710  0.0301    99.078  351.79
  50   0.0390     98.590  0.0290    99.082  358.99
  51   0.0389     98.710  0.0298    99.062  366.11
  52   0.0407     98.670  0.0286    99.097  373.29
  53   0.0385     98.730  0.0284    99.068  380.43
  54   0.0343     98.720  0.0280    99.115  387.60
  55   0.0398     98.630  0.0272    99.133  394.67
  56   0.0329     98.810  0.0271    99.127  401.76
  57   0.0330     98.860  0.0264    99.177  408.91
  58   0.0383     98.640  0.0256    99.173  416.12
  59   0.0381     98.700  0.0262    99.145  423.28
  60   0.0367     98.710  0.0267    99.125  430.37
  61   0.0341     98.820  0.0262    99.165  437.46
  62   0.0396     98.730  0.0252    99.195  444.57
  63   0.0365     98.740  0.0252    99.193  451.78
  64   0.0370     98.730  0.0249    99.220  458.95
  65   0.0379     98.710  0.0246    99.185  466.07
  66   0.0370     98.780  0.0250    99.195  473.17
  67   0.0349     98.850  0.0245    99.213  480.26
  68   0.0367     98.750  0.0231    99.287  487.44
  69   0.0333     98.850  0.0223    99.280  494.60
  70   0.0359     98.760  0.0222    99.262  501.67
  71   0.0382     98.670  0.0229    99.295  508.72
  72   0.0389     98.710  0.0221    99.262  515.85
  73   0.0349     98.770  0.0225    99.285  522.96
  74   0.0348     98.850  0.0220    99.310  530.14
  75   0.0343     98.820  0.0221    99.248  537.35
  76   0.0323     98.900  0.0212    99.292  544.47
  77   0.0305     98.950  0.0216    99.338  551.54
  78   0.0316     98.940  0.0214    99.305  558.75
  79   0.0328     98.820  0.0207    99.347  565.86
  80   0.0340     98.750  0.0209    99.338  572.96
  81   0.0318     98.820  0.0193    99.382  580.17
  82   0.0317     98.840  0.0200    99.335  587.27
  83   0.0353     98.830  0.0187    99.402  594.39
  84   0.0355     98.690  0.0190    99.402  601.52
  85   0.0340     98.720  0.0187    99.408  608.61
