Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3842544128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4815     10.670  8.7139    10.808  10.12
   2   2.4809     10.680  8.7136    10.697  18.74
   3   2.4815     10.710  8.7132    10.747  27.12
   4   2.4796     10.700  8.7127    10.672  35.68
   5   2.4815     10.740  8.7133    10.867  43.92
   6   2.4816     10.740  8.7122    10.828  52.18
   7   2.4824     10.600  8.7125    10.878  60.50
   8   2.4797     10.690  8.7137    10.733  68.76
   9   2.4795     10.760  8.7121    10.920  76.97
  10   2.4809     10.770  8.7128    10.677  85.28
  11   2.4805     10.760  8.7126    10.653  93.55
  12   2.4800     10.730  8.7133    10.663  101.98
  13   2.4810     10.750  8.7128    10.758  110.28
  14   2.4816     10.770  8.7130    10.780  118.66
  15   2.4806     10.760  8.7129    10.758  126.88
  16   2.4822     10.720  8.7133    10.710  135.24
  17   2.4803     10.670  8.7139    10.843  143.71
  18   2.4795     10.690  8.7135    10.673  152.16
  19   2.4802     10.750  8.7121    10.787  160.50
  20   2.4805     10.730  8.7131    10.833  168.80
  21   2.4800     10.720  8.7126    10.767  177.19
  22   2.4812     10.770  8.7142    10.635  185.42
  23   2.4828     10.690  8.7138    10.700  193.68
  24   2.4814     10.680  8.7128    10.720  201.96
  25   2.4805     10.760  8.7133    10.802  210.29
  26   2.4804     10.700  8.7123    10.890  218.59
  27   2.4807     10.720  8.7135    10.697  226.94
  28   2.4817     10.680  8.7121    10.687  235.32
  29   2.4794     10.790  8.7132    10.708  243.70
  30   2.4807     10.740  8.7130    10.823  252.02
  31   2.4801     10.750  8.7125    10.698  260.59
  32   2.4831     10.620  8.7124    10.753  268.97
  33   2.4804     10.670  8.7123    10.817  277.46
  34   2.4803     10.740  8.7122    10.763  285.76
  35   2.4798     10.720  8.7133    10.582  294.06
  36   2.4819     10.700  8.7129    10.920  302.24
  37   2.4809     10.670  8.7126    10.800  310.73
  38   2.4831     10.630  8.7138    10.687  319.05
  39   2.4787     10.770  8.7132    10.802  327.23
  40   2.4800     10.700  8.7130    10.840  335.56
  41   2.4808     10.650  8.7126    10.865  344.36
  42   2.4806     10.650  8.7126    10.700  352.64
  43   2.4805     10.670  8.7133    10.750  360.95
  44   2.4810     10.710  8.7142    10.643  369.32
  45   2.4804     10.750  8.7131    10.717  377.86
  46   2.4799     10.710  8.7139    10.620  386.23
  47   2.4819     10.680  8.7141    10.680  394.50
  48   2.4806     10.800  8.7129    10.677  402.89
  49   2.4808     10.720  8.7145    10.695  411.24
  50   2.4796     10.700  8.7139    10.568  419.67
  51   2.4815     10.730  8.7143    10.802  427.94
  52   2.4815     10.710  8.7132    10.782  436.23
  53   2.4821     10.670  8.7138    10.838  444.57
  54   2.4802     10.740  8.7132    10.760  452.93
  55   2.4809     10.700  8.7119    10.773  461.30
  56   2.4817     10.770  8.7143    10.702  469.60
  57   2.4787     10.810  8.7121    10.847  477.96
  58   2.4802     10.740  8.7140    10.813  486.41
  59   2.4813     10.650  8.7135    10.920  494.69
  60   2.4831     10.640  8.7133    10.643  503.01
  61   2.4802     10.740  8.7129    10.662  511.31
  62   2.4814     10.720  8.7133    10.772  519.66
  63   2.4788     10.790  8.7127    10.765  527.83
  64   2.4806     10.770  8.7130    10.708  536.12
  65   2.4813     10.670  8.7125    10.840  544.30
  66   2.4797     10.690  8.7121    10.892  552.70
  67   2.4788     10.760  8.7142    10.680  561.06
  68   2.4794     10.810  8.7130    10.702  569.41
  69   2.4790     10.730  8.7140    10.800  577.69
  70   2.4810     10.700  8.7132    10.952  586.01
  71   2.4796     10.690  8.7129    10.885  594.47
  72   2.4791     10.700  8.7136    10.672  602.75
  73   2.4802     10.700  8.7129    10.795  611.04
  74   2.4817     10.690  8.7128    10.858  619.34
  75   2.4790     10.710  8.7130    10.822  627.72
  76   2.4817     10.660  8.7136    10.662  636.17
  77   2.4809     10.620  8.7127    10.862  644.51
  78   2.4815     10.670  8.7132    10.727  652.74
  79   2.4785     10.750  8.7132    10.815  661.10
  80   2.4811     10.740  8.7121    10.837  669.47
  81   2.4816     10.720  8.7129    10.755  677.69
  82   2.4805     10.750  8.7129    10.860  685.98
  83   2.4817     10.710  8.7141    10.615  694.31
  84   2.4798     10.780  8.7133    10.765  702.71
  85   2.4802     10.740  8.7130    10.730  710.99
  86   2.4806     10.720  8.7134    10.710  719.39
  87   2.4812     10.770  8.7137    10.710  727.68
  88   2.4817     10.730  8.7123    10.775  736.47
  89   2.4816     10.690  8.7136    10.747  744.77
  90   2.4809     10.770  8.7122    10.822  753.12
