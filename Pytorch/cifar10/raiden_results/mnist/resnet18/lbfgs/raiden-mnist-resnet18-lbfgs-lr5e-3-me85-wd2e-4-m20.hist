Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3842544128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3912      9.290  4.8962     8.517  9.39
   2   2.3911      9.210  4.8959     8.585  17.19
   3   2.3911      9.230  4.8967     8.535  24.93
   4   2.3916      9.200  4.8960     8.475  32.79
   5   2.3908      9.270  4.8971     8.527  40.60
   6   2.3911      9.220  4.8965     8.550  48.39
   7   2.3911      9.220  4.8965     8.573  56.33
   8   2.3916      9.210  4.8964     8.522  64.20
   9   2.3908      9.290  4.8963     8.530  72.24
  10   2.3908      9.250  4.8969     8.400  80.05
  11   2.3909      9.280  4.8960     8.558  87.95
  12   2.3914      9.210  4.8970     8.577  95.81
  13   2.3906      9.250  4.8955     8.533  103.65
  14   2.3909      9.260  4.8960     8.528  111.49
  15   2.3911      9.260  4.8961     8.458  119.49
  16   2.3909      9.210  4.8963     8.607  127.19
  17   2.3912      9.200  4.8968     8.498  134.97
  18   2.3903      9.270  4.8956     8.607  142.84
  19   2.3911      9.260  4.8963     8.570  150.54
  20   2.3906      9.230  4.8970     8.527  158.49
  21   2.3907      9.260  4.8958     8.508  166.23
  22   2.3912      9.150  4.8964     8.432  174.08
  23   2.3906      9.210  4.8962     8.487  182.05
  24   2.3912      9.250  4.8965     8.477  190.03
  25   2.3912      9.250  4.8966     8.393  197.80
  26   2.3912      9.300  4.8965     8.507  205.54
  27   2.3906      9.220  4.8963     8.547  213.36
  28   2.3909      9.230  4.8962     8.475  221.25
  29   2.3906      9.250  4.8975     8.470  229.12
  30   2.3910      9.200  4.8965     8.542  237.30
  31   2.3908      9.230  4.8963     8.485  245.13
  32   2.3912      9.300  4.8959     8.607  252.98
  33   2.3918      9.180  4.8965     8.452  260.97
  34   2.3911      9.310  4.8968     8.427  268.80
  35   2.3905      9.240  4.8967     8.485  276.72
  36   2.3909      9.290  4.8952     8.527  284.58
  37   2.3915      9.260  4.8972     8.513  292.43
  38   2.3904      9.250  4.8965     8.448  300.45
  39   2.3908      9.190  4.8962     8.517  308.28
  40   2.3909      9.290  4.8962     8.503  316.10
  41   2.3905      9.230  4.8964     8.513  323.89
  42   2.3912      9.210  4.8957     8.548  331.85
  43   2.3909      9.260  4.8974     8.465  339.67
  44   2.3916      9.270  4.8966     8.500  347.55
  45   2.3914      9.250  4.8962     8.513  355.41
  46   2.3910      9.130  4.8966     8.463  363.32
  47   2.3913      9.220  4.8969     8.433  371.10
  48   2.3915      9.210  4.8962     8.490  378.98
  49   2.3907      9.250  4.8963     8.538  386.81
  50   2.3905      9.250  4.8966     8.507  394.82
  51   2.3902      9.330  4.8957     8.595  402.74
  52   2.3917      9.260  4.8962     8.457  410.51
  53   2.3908      9.270  4.8967     8.462  418.40
  54   2.3906      9.210  4.8956     8.547  426.29
  55   2.3910      9.230  4.8973     8.432  434.23
  56   2.3908      9.270  4.8966     8.352  442.04
  57   2.3913      9.290  4.8965     8.477  449.90
  58   2.3919      9.180  4.8961     8.518  457.77
  59   2.3909      9.210  4.8967     8.463  465.74
  60   2.3913      9.220  4.8962     8.552  473.58
  61   2.3904      9.230  4.8963     8.528  481.44
  62   2.3907      9.170  4.8964     8.518  489.19
  63   2.3906      9.260  4.8969     8.525  497.09
  64   2.3909      9.240  4.8963     8.500  505.07
  65   2.3906      9.240  4.8969     8.495  512.90
  66   2.3907      9.240  4.8965     8.498  520.77
  67   2.3916      9.270  4.8951     8.562  528.63
  68   2.3916      9.220  4.8960     8.550  536.56
  69   2.3905      9.250  4.8962     8.423  544.41
  70   2.3907      9.270  4.8970     8.527  552.27
  71   2.3909      9.290  4.8963     8.533  560.11
  72   2.3913      9.270  4.8966     8.445  567.94
  73   2.3906      9.260  4.8961     8.542  576.03
  74   2.3906      9.330  4.8969     8.533  583.80
  75   2.3907      9.230  4.8960     8.617  591.62
  76   2.3906      9.260  4.8961     8.623  599.40
  77   2.3914      9.160  4.8960     8.545  607.31
  78   2.3905      9.240  4.8966     8.462  615.09
  79   2.3914      9.180  4.8956     8.533  622.94
  80   2.3916      9.240  4.8954     8.577  630.69
  81   2.3908      9.210  4.8969     8.430  638.58
  82   2.3911      9.280  4.8967     8.442  646.58
  83   2.3912      9.280  4.8969     8.413  654.31
  84   2.3909      9.250  4.8968     8.548  662.04
  85   2.3912      9.180  4.8962     8.555  669.84
