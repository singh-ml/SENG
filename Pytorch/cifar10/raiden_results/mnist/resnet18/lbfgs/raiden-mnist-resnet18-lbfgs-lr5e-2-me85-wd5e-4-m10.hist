Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3842544128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3295      9.990  8.5939     9.110  9.78
   2   2.3289     10.220  8.5733     9.355  17.91
   3   2.3293     10.110  8.5734     9.377  25.94
   4   2.3291     10.140  8.5735     9.270  34.00
   5   2.3294     10.090  8.5731     9.327  41.96
   6   2.3294      9.970  8.5736     9.270  49.95
   7   2.3294     10.060  8.5743     8.997  57.93
   8   2.3298     10.040  8.5738     9.305  65.92
   9   2.3292     10.120  8.5736     9.252  74.13
  10   2.3286     10.120  8.5733     9.250  82.06
  11   2.3290     10.080  8.5739     9.167  90.10
  12   2.3290     10.170  8.5736     9.173  98.12
  13   2.3293     10.090  8.5736     9.188  106.65
  14   2.3292     10.070  8.5740     9.295  114.71
  15   2.3291     10.080  8.5737     9.152  122.72
  16   2.3293     10.030  8.5744     9.158  130.76
  17   2.3291     10.100  8.5743     9.223  139.06
  18   2.3289     10.130  8.5740     9.478  147.03
  19   2.3291     10.080  8.5741     9.170  155.06
  20   2.3291     10.170  8.5735     9.237  163.01
  21   2.3290     10.020  8.5737     9.252  171.20
  22   2.3293     10.080  8.5737     9.235  179.41
  23   2.3296     10.030  8.5745     9.300  187.44
  24   2.3292     10.020  8.5741     9.200  195.37
  25   2.3297     10.010  8.5740     9.075  203.35
  26   2.3292     10.070  8.5731     9.202  211.46
  27   2.3292      9.970  8.5732     9.152  219.38
  28   2.3294     10.090  8.5735     9.277  227.40
  29   2.3296     10.030  8.5735     9.147  235.35
  30   2.3293     10.180  8.5744     9.182  243.50
  31   2.3291     10.130  8.5736     9.137  251.45
  32   2.3294     10.040  8.5736     9.170  259.40
  33   2.3293     10.030  8.5729     9.270  267.48
  34   2.3292     10.050  8.5733     9.148  275.44
  35   2.3291     10.130  8.5734     9.230  283.43
  36   2.3293     10.040  8.5737     9.168  291.49
  37   2.3294     10.060  8.5732     9.233  299.42
  38   2.3295     10.100  8.5738     9.157  307.36
  39   2.3297     10.050  8.5731     9.372  315.50
  40   2.3291     10.080  8.5733     9.303  323.47
  41   2.3294     10.020  8.5737     9.068  331.50
  42   2.3291     10.150  8.5727     9.245  339.54
  43   2.3293     10.110  8.5738     9.223  347.55
  44   2.3295     10.060  8.5743     9.135  355.66
  45   2.3290     10.090  8.5743     9.120  363.64
  46   2.3295     10.050  8.5742     9.273  371.71
  47   2.3291     10.110  8.5738     9.070  379.77
  48   2.3294      9.970  8.5731     9.265  387.82
  49   2.3296     10.000  8.5747     9.120  395.77
  50   2.3291     10.030  8.5739     9.202  403.84
  51   2.3294     10.030  8.5736     9.165  411.89
  52   2.3293     10.120  8.5742     9.242  420.02
  53   2.3291     10.090  8.5737     9.315  428.02
  54   2.3295     10.090  8.5730     9.208  436.06
  55   2.3294     10.110  8.5733     8.960  444.01
  56   2.3289     10.120  8.5734     9.337  452.07
  57   2.3286     10.210  8.5740     9.145  460.07
  58   2.3293      9.990  8.5735     9.275  468.09
  59   2.3289     10.170  8.5739     9.287  476.14
  60   2.3289     10.040  8.5737     9.265  484.05
  61   2.3295     10.070  8.5728     9.350  491.97
  62   2.3294     10.110  8.5726     9.232  499.97
  63   2.3294     10.060  8.5734     9.270  507.89
  64   2.3293     10.070  8.5728     9.220  515.98
  65   2.3291     10.170  8.5737     9.237  524.18
  66   2.3298     10.100  8.5735     9.465  532.23
  67   2.3292     10.080  8.5736     9.235  540.28
  68   2.3297     10.010  8.5737     9.278  548.28
  69   2.3288     10.190  8.5738     8.950  556.32
  70   2.3292     10.080  8.5741     9.247  564.51
  71   2.3291     10.050  8.5733     9.295  572.58
  72   2.3293     10.080  8.5736     9.228  580.62
  73   2.3296     10.030  8.5729     9.240  588.67
  74   2.3294     10.010  8.5742     9.210  596.81
  75   2.3293      9.980  8.5732     9.240  605.00
  76   2.3292     10.040  8.5734     9.255  613.00
  77   2.3295     10.030  8.5741     9.023  620.98
  78   2.3294     10.090  8.5748     9.152  628.94
  79   2.3292     10.130  8.5734     9.138  637.13
  80   2.3293     10.110  8.5734     9.173  645.10
  81   2.3291     10.130  8.5733     9.262  653.43
  82   2.3289     10.070  8.5726     9.088  661.52
  83   2.3294     10.080  8.5734     9.188  669.52
  84   2.3301     10.050  8.5740     9.142  677.77
  85   2.3294     10.000  8.5731     9.180  685.93
