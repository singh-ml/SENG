Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3842544128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4775     10.350  4.9716    10.010  9.40
   2   2.4761     10.380  4.9717     9.978  16.94
   3   2.4776     10.340  4.9716    10.007  24.50
   4   2.4770     10.340  4.9722     9.997  32.18
   5   2.4783     10.320  4.9727     9.997  39.89
   6   2.4772     10.360  4.9714    10.088  47.55
   7   2.4777     10.390  4.9719    10.020  55.07
   8   2.4766     10.360  4.9729     9.927  63.06
   9   2.4778     10.340  4.9723     9.922  70.72
  10   2.4771     10.380  4.9728     9.972  78.44
  11   2.4772     10.380  4.9713     9.978  86.12
  12   2.4776     10.360  4.9726     9.958  93.78
  13   2.4769     10.360  4.9710     9.982  101.45
  14   2.4770     10.370  4.9713    10.030  109.28
  15   2.4768     10.350  4.9725     9.958  116.81
  16   2.4771     10.370  4.9731     9.960  124.36
  17   2.4762     10.360  4.9721     9.958  131.99
  18   2.4763     10.380  4.9725     9.953  139.75
  19   2.4771     10.380  4.9718     9.977  147.87
  20   2.4773     10.350  4.9715     9.952  155.51
  21   2.4764     10.390  4.9720     9.973  163.48
  22   2.4768     10.410  4.9718    10.000  171.14
  23   2.4757     10.380  4.9719     9.982  178.95
  24   2.4766     10.380  4.9721     9.967  186.55
  25   2.4775     10.380  4.9716     9.943  194.05
  26   2.4768     10.390  4.9716     9.930  201.61
  27   2.4763     10.400  4.9719     9.957  209.25
  28   2.4783     10.400  4.9716    10.035  216.97
  29   2.4776     10.350  4.9723     9.977  224.55
  30   2.4772     10.360  4.9725     9.953  232.18
  31   2.4772     10.360  4.9713    10.020  239.84
  32   2.4770     10.400  4.9718     9.962  247.36
  33   2.4767     10.320  4.9722    10.067  254.99
  34   2.4770     10.360  4.9722    10.000  262.59
  35   2.4769     10.360  4.9722     9.953  270.12
  36   2.4768     10.410  4.9732     9.922  277.75
  37   2.4771     10.360  4.9718     9.927  285.43
  38   2.4782     10.360  4.9718     9.985  292.91
  39   2.4773     10.360  4.9716     9.973  300.56
  40   2.4768     10.360  4.9710    10.082  308.15
  41   2.4784     10.340  4.9719     9.958  315.67
  42   2.4782     10.350  4.9722     9.965  323.41
  43   2.4776     10.350  4.9721    10.042  331.10
  44   2.4769     10.380  4.9724     9.957  339.12
  45   2.4773     10.360  4.9717     9.998  346.75
  46   2.4761     10.370  4.9719    10.010  354.31
  47   2.4764     10.370  4.9727     9.938  361.95
  48   2.4759     10.350  4.9722    10.040  369.50
  49   2.4773     10.400  4.9723     9.948  377.15
  50   2.4779     10.340  4.9725     9.933  384.78
  51   2.4775     10.370  4.9721     9.922  392.56
  52   2.4759     10.350  4.9726     9.943  400.19
  53   2.4778     10.360  4.9726     9.912  407.82
  54   2.4780     10.390  4.9721     9.968  415.53
  55   2.4775     10.380  4.9719     9.997  423.24
  56   2.4769     10.360  4.9719    10.050  430.84
  57   2.4759     10.390  4.9705     9.993  438.38
  58   2.4779     10.370  4.9728     9.998  446.01
  59   2.4780     10.360  4.9714     9.963  453.61
  60   2.4757     10.420  4.9729     9.990  461.45
  61   2.4770     10.370  4.9718    10.027  469.07
  62   2.4777     10.380  4.9720     9.948  476.69
  63   2.4772     10.390  4.9715    10.007  484.40
  64   2.4777     10.360  4.9718     9.917  492.18
  65   2.4781     10.340  4.9714     9.890  499.79
  66   2.4767     10.360  4.9720     9.982  507.39
  67   2.4755     10.390  4.9713     9.970  515.01
  68   2.4777     10.380  4.9721    10.007  522.67
  69   2.4777     10.370  4.9725     9.913  530.45
  70   2.4775     10.330  4.9717     9.985  538.06
  71   2.4783     10.360  4.9725     9.950  545.82
  72   2.4769     10.360  4.9720     9.955  553.40
  73   2.4773     10.360  4.9722    10.067  561.27
  74   2.4774     10.350  4.9721    10.012  568.80
  75   2.4779     10.360  4.9712    10.018  576.69
  76   2.4789     10.380  4.9713    10.032  584.34
  77   2.4783     10.360  4.9721    10.008  592.01
  78   2.4760     10.370  4.9722    10.005  599.69
  79   2.4774     10.390  4.9723     9.973  607.86
  80   2.4782     10.360  4.9718     9.960  615.42
  81   2.4774     10.380  4.9715    10.013  623.07
  82   2.4781     10.370  4.9721     9.927  630.73
  83   2.4773     10.340  4.9725    10.037  638.23
  84   2.4761     10.390  4.9718     9.955  646.04
  85   2.4780     10.360  4.9721     9.973  653.83
