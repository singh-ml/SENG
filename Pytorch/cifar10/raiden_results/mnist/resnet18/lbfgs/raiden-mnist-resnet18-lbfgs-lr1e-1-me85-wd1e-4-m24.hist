Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 5062267392 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8625     28.070  3.5924    22.877  11.00
   2   13.4956     11.350  3.3390    61.702  20.64
   3   0.4555     84.500  2.7156    72.835  30.28
   4   7.3976     11.410  32.8885    73.353  40.08
   5   0.3130     90.160  1.6289    87.648  49.72
   6   0.2470     92.330  1.5630    90.207  59.34
   7   0.2170     92.940  1.5029    91.990  69.10
   8   0.2078     93.260  1.4784    92.547  78.68
   9   0.1861     94.000  1.4561    93.308  88.65
  10   0.1854     93.860  1.4469    93.557  97.95
  11   0.1853     93.970  1.4474    93.555  107.42
  12   0.1860     93.980  1.4470    93.485  116.63
  13   0.1856     93.910  1.4476    93.597  125.89
  14   0.1856     93.990  1.4472    93.417  135.35
  15   0.1869     94.010  1.4479    93.480  144.64
  16   0.1865     94.030  1.4475    93.502  153.92
  17   0.1847     93.950  1.4476    93.520  163.21
  18   0.1854     94.040  1.4478    93.462  172.65
  19   0.1858     93.940  1.4462    93.560  181.97
  20   0.1857     93.970  1.4479    93.428  191.24
  21   0.1864     94.010  1.4486    93.443  200.50
  22   0.1853     93.910  1.4477    93.475  209.88
  23   0.1848     93.990  1.4493    93.418  219.27
  24   0.1857     93.930  1.4461    93.543  228.57
  25   0.1862     93.950  1.4492    93.518  237.96
  26   0.1860     93.990  1.4475    93.503  247.46
  27   0.1851     93.950  1.4496    93.432  256.98
  28   0.1868     94.000  1.4468    93.477  266.56
  29   0.1860     93.980  1.4480    93.457  276.04
  30   0.1857     93.950  1.4489    93.582  285.39
  31   0.1864     94.000  1.4467    93.433  294.69
  32   0.1865     94.030  1.4489    93.443  303.94
  33   0.1857     94.000  1.4489    93.415  313.38
  34   0.1856     93.980  1.4482    93.437  322.76
  35   0.1856     93.950  1.4498    93.363  332.01
  36   0.1865     94.010  1.4465    93.468  341.31
  37   0.1864     94.010  1.4479    93.352  350.65
  38   0.1857     94.070  1.4481    93.437  360.16
  39   0.1857     93.970  1.4479    93.592  369.45
  40   0.1857     93.960  1.4477    93.495  378.77
  41   0.1854     93.920  1.4494    93.398  388.03
  42   0.1862     93.940  1.4465    93.567  397.48
  43   0.1855     93.960  1.4467    93.568  406.74
  44   0.1857     93.920  1.4465    93.452  416.04
  45   0.1858     93.980  1.4502    93.392  425.32
  46   0.1874     94.000  1.4484    93.508  434.69
  47   0.1854     93.930  1.4481    93.462  444.23
  48   0.1856     93.910  1.4468    93.590  453.55
  49   0.1868     94.020  1.4482    93.550  462.79
  50   0.1857     93.920  1.4467    93.485  472.23
  51   0.1863     94.000  1.4477    93.488  481.54
  52   0.1856     93.950  1.4457    93.547  490.91
  53   0.1863     93.990  1.4476    93.545  500.67
  54   0.1857     93.920  1.4468    93.437  509.99
  55   0.1854     93.920  1.4484    93.440  519.45
  56   0.1852     94.000  1.4488    93.477  528.78
  57   0.1850     93.930  1.4485    93.457  538.27
  58   0.1857     93.890  1.4476    93.525  547.57
  59   0.1858     94.040  1.4471    93.448  557.22
  60   0.1855     93.910  1.4487    93.537  566.59
  61   0.1858     94.010  1.4498    93.430  576.24
  62   0.1866     93.980  1.4494    93.422  585.53
  63   0.1854     93.980  1.4494    93.447  594.84
  64   0.1850     93.900  1.4471    93.545  604.28
  65   0.1862     94.020  1.4481    93.437  613.51
  66   0.1865     94.010  1.4469    93.518  622.74
  67   0.1857     93.910  1.4482    93.535  632.09
  68   0.1859     93.980  1.4487    93.470  641.39
  69   0.1857     93.990  1.4479    93.422  650.81
  70   0.1849     93.910  1.4465    93.593  660.30
  71   0.1858     93.910  1.4484    93.438  669.60
  72   0.1855     93.930  1.4462    93.545  678.99
  73   0.1859     93.970  1.4488    93.518  688.26
  74   0.1868     94.020  1.4475    93.483  697.52
  75   0.1866     93.980  1.4481    93.473  706.86
  76   0.1864     93.970  1.4474    93.528  716.26
  77   0.1853     93.980  1.4493    93.408  725.56
  78   0.1851     93.950  1.4473    93.490  734.84
  79   0.1861     93.920  1.4467    93.533  744.25
  80   0.1860     93.950  1.4493    93.347  753.62
  81   0.1859     93.920  1.4485    93.487  762.95
  82   0.1863     93.970  1.4459    93.652  772.30
  83   0.1852     94.020  1.4467    93.578  781.58
  84   0.1865     94.020  1.4479    93.390  790.97
  85   0.1850     93.960  1.4460    93.582  800.18
