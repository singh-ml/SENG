Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3842544128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4388      7.730  4.9283     8.580  9.71
   2   2.4388      7.650  4.9287     8.522  17.84
   3   2.4386      7.720  4.9286     8.643  26.09
   4   2.4386      7.560  4.9280     8.692  34.46
   5   2.4390      7.650  4.9284     8.793  42.84
   6   2.4393      7.610  4.9290     8.515  51.08
   7   2.4387      7.580  4.9281     8.573  59.34
   8   2.4387      7.620  4.9288     8.495  67.51
   9   2.4378      7.640  4.9282     8.782  75.82
  10   2.4389      7.720  4.9285     8.682  84.11
  11   2.4389      7.630  4.9282     8.632  92.33
  12   2.4383      7.610  4.9284     8.580  100.51
  13   2.4382      7.690  4.9275     8.527  108.67
  14   2.4385      7.750  4.9283     8.670  117.00
  15   2.4383      7.780  4.9281     8.698  125.26
  16   2.4386      7.670  4.9278     8.808  133.51
  17   2.4381      7.680  4.9285     8.613  141.85
  18   2.4390      7.720  4.9278     8.683  150.15
  19   2.4393      7.640  4.9271     8.585  158.30
  20   2.4388      7.660  4.9285     8.423  166.46
  21   2.4391      7.670  4.9282     8.640  174.74
  22   2.4384      7.670  4.9286     8.628  183.13
  23   2.4382      7.680  4.9285     8.537  191.37
  24   2.4390      7.690  4.9286     8.575  199.70
  25   2.4381      7.570  4.9285     8.535  207.96
  26   2.4385      7.710  4.9286     8.470  216.28
  27   2.4378      7.670  4.9270     8.875  224.50
  28   2.4392      7.650  4.9277     8.708  232.75
  29   2.4386      7.520  4.9283     8.637  241.03
  30   2.4396      7.740  4.9277     8.650  249.29
  31   2.4385      7.700  4.9278     8.668  257.56
  32   2.4386      7.630  4.9281     8.655  265.66
  33   2.4389      7.640  4.9282     8.562  273.85
  34   2.4389      7.700  4.9285     8.630  282.23
  35   2.4389      7.610  4.9292     8.780  290.41
  36   2.4390      7.680  4.9292     8.582  298.77
  37   2.4385      7.690  4.9267     8.513  306.82
  38   2.4391      7.600  4.9285     8.690  315.05
  39   2.4387      7.620  4.9290     8.488  323.43
  40   2.4388      7.630  4.9285     8.610  331.64
  41   2.4385      7.620  4.9283     8.772  340.15
  42   2.4388      7.640  4.9289     8.725  348.38
  43   2.4392      7.680  4.9274     8.698  356.78
  44   2.4389      7.640  4.9296     8.677  364.89
  45   2.4388      7.670  4.9289     8.563  373.10
  46   2.4389      7.690  4.9270     8.682  381.33
  47   2.4387      7.650  4.9277     8.565  389.62
  48   2.4382      7.700  4.9282     8.647  397.98
  49   2.4387      7.700  4.9292     8.623  406.11
  50   2.4389      7.680  4.9282     8.660  414.29
  51   2.4383      7.630  4.9280     8.757  422.43
  52   2.4394      7.630  4.9283     8.645  430.73
  53   2.4392      7.610  4.9277     8.622  438.85
  54   2.4392      7.670  4.9280     8.555  447.09
  55   2.4394      7.570  4.9282     8.683  455.27
  56   2.4391      7.720  4.9282     8.777  463.57
  57   2.4399      7.680  4.9280     8.705  471.77
  58   2.4388      7.570  4.9282     8.545  479.88
  59   2.4389      7.670  4.9290     8.552  488.43
  60   2.4383      7.660  4.9282     8.720  497.00
  61   2.4377      7.700  4.9279     8.720  505.22
  62   2.4388      7.660  4.9280     8.668  513.28
  63   2.4387      7.680  4.9290     8.555  521.52
  64   2.4394      7.620  4.9287     8.585  529.91
  65   2.4391      7.610  4.9286     8.742  538.19
  66   2.4384      7.660  4.9282     8.573  546.47
  67   2.4388      7.600  4.9282     8.683  554.82
  68   2.4390      7.540  4.9281     8.620  563.23
  69   2.4392      7.720  4.9283     8.553  571.49
  70   2.4379      7.620  4.9287     8.642  579.67
  71   2.4388      7.700  4.9279     8.705  588.08
  72   2.4393      7.660  4.9281     8.722  596.34
  73   2.4391      7.660  4.9279     8.610  604.62
  74   2.4390      7.740  4.9279     8.615  612.88
  75   2.4394      7.660  4.9280     8.580  621.10
  76   2.4387      7.660  4.9281     8.658  629.28
  77   2.4390      7.730  4.9285     8.708  637.61
  78   2.4386      7.690  4.9285     8.545  645.83
  79   2.4395      7.540  4.9274     8.588  654.39
  80   2.4388      7.640  4.9282     8.503  662.60
  81   2.4391      7.700  4.9269     8.715  670.74
  82   2.4390      7.590  4.9282     8.693  679.17
  83   2.4391      7.620  4.9284     8.770  687.35
  84   2.4391      7.650  4.9283     8.778  695.63
  85   2.4383      7.680  4.9288     8.612  704.13
