Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3470     61.320  1.8286    36.938  7.61
   2   0.5190     85.800  0.8806    76.178  13.45
   3   0.4086     86.920  0.4247    87.935  19.29
   4   0.2269     93.310  0.3007    91.267  25.12
   5   0.1996     93.900  0.2358    93.135  30.96
   6   0.1679     94.990  0.1967    94.075  36.76
   7   0.1384     95.850  0.1663    95.058  42.57
   8   0.1314     96.030  0.1482    95.487  48.50
   9   0.1207     96.340  0.1344    95.880  54.33
  10   0.1175     96.400  0.1219    96.265  60.14
  11   0.1147     96.620  0.1113    96.598  65.98
  12   0.1002     97.040  0.1045    96.852  71.79
  13   0.0894     97.340  0.0962    97.020  77.62
  14   0.0783     97.640  0.0918    97.185  83.50
  15   0.0812     97.520  0.0858    97.382  89.33
  16   0.0751     97.690  0.0821    97.487  95.14
  17   0.0730     97.810  0.0801    97.463  100.96
  18   0.0744     97.820  0.0746    97.722  106.77
  19   0.0759     97.670  0.0715    97.785  112.68
  20   0.0673     97.930  0.0704    97.805  118.50
  21   0.0673     97.950  0.0659    97.977  124.33
  22   0.0609     98.120  0.0645    97.997  130.15
  23   0.0578     98.160  0.0613    98.117  135.97
  24   0.0588     98.230  0.0595    98.165  141.78
  25   0.0643     98.020  0.0593    98.132  147.68
  26   0.0608     98.090  0.0574    98.262  153.51
  27   0.0580     98.110  0.0546    98.292  159.32
  28   0.0643     98.040  0.0542    98.310  165.15
  29   0.0528     98.430  0.0522    98.410  170.96
  30   0.0526     98.360  0.0517    98.410  176.81
  31   0.0556     98.250  0.0508    98.427  182.71
  32   0.0512     98.440  0.0483    98.487  188.53
  33   0.0535     98.330  0.0479    98.523  194.35
  34   0.0464     98.430  0.0465    98.553  200.16
  35   0.0461     98.450  0.0449    98.572  205.98
  36   0.0466     98.530  0.0439    98.610  211.91
  37   0.0469     98.430  0.0433    98.665  217.74
  38   0.0430     98.460  0.0426    98.682  223.55
  39   0.0500     98.370  0.0418    98.687  229.37
  40   0.0489     98.310  0.0413    98.687  235.19
  41   0.0523     98.210  0.0404    98.748  241.04
  42   0.0425     98.530  0.0391    98.762  246.85
  43   0.0446     98.600  0.0386    98.767  252.77
  44   0.0517     98.320  0.0369    98.858  258.59
  45   0.0432     98.640  0.0371    98.798  264.40
  46   0.0512     98.380  0.0372    98.812  270.21
  47   0.0455     98.520  0.0355    98.867  276.01
  48   0.0421     98.570  0.0360    98.908  281.83
  49   0.0413     98.580  0.0345    98.902  287.72
  50   0.0463     98.450  0.0348    98.893  293.54
  51   0.0398     98.620  0.0340    98.913  299.37
  52   0.0416     98.640  0.0344    98.952  305.20
  53   0.0426     98.610  0.0331    98.937  311.03
  54   0.0385     98.700  0.0329    98.965  316.85
  55   0.0407     98.690  0.0330    98.943  322.80
  56   0.0437     98.440  0.0314    99.005  328.62
  57   0.0439     98.610  0.0308    99.048  334.45
  58   0.0412     98.620  0.0307    99.027  340.29
  59   0.0446     98.540  0.0310    98.990  346.12
  60   0.0424     98.640  0.0304    98.997  352.03
  61   0.0375     98.770  0.0298    99.062  357.85
  62   0.0353     98.840  0.0296    99.067  363.69
  63   0.0478     98.400  0.0284    99.095  369.52
  64   0.0397     98.570  0.0287    99.068  375.34
  65   0.0386     98.710  0.0285    99.040  381.17
  66   0.0393     98.730  0.0274    99.148  387.08
  67   0.0339     98.860  0.0274    99.100  392.91
  68   0.0389     98.600  0.0267    99.163  398.73
  69   0.0368     98.730  0.0271    99.173  404.56
  70   0.0390     98.780  0.0269    99.123  410.39
  71   0.0360     98.710  0.0258    99.183  416.28
  72   0.0381     98.710  0.0255    99.182  422.07
  73   0.0334     98.890  0.0255    99.232  427.88
  74   0.0356     98.780  0.0257    99.202  433.71
  75   0.0390     98.740  0.0248    99.213  439.53
  76   0.0436     98.550  0.0244    99.232  445.34
  77   0.0379     98.800  0.0241    99.228  451.22
  78   0.0323     98.910  0.0248    99.245  457.03
  79   0.0416     98.620  0.0238    99.232  462.84
  80   0.0365     98.810  0.0246    99.193  468.67
  81   0.0410     98.670  0.0232    99.293  474.48
  82   0.0392     98.650  0.0229    99.263  480.42
  83   0.0356     98.710  0.0222    99.303  486.25
  84   0.0366     98.770  0.0221    99.322  492.06
  85   0.0358     98.860  0.0226    99.223  497.89
