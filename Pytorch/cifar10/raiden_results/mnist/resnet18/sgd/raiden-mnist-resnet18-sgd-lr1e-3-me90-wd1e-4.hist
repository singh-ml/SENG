Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 3795903488 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3438     60.880  1.8386    36.757  7.35
   2   0.4891     85.640  0.8912    75.277  13.27
   3   0.3115     90.290  0.4305    87.628  19.09
   4   0.2240     93.210  0.3050    91.003  24.91
   5   0.2115     93.280  0.2427    92.767  30.75
   6   0.1620     94.990  0.2011    93.993  36.58
   7   0.1442     95.420  0.1701    94.950  42.50
   8   0.1237     95.990  0.1513    95.395  48.34
   9   0.1093     96.570  0.1351    95.890  54.16
  10   0.0995     96.950  0.1227    96.265  59.99
  11   0.1187     96.210  0.1131    96.558  65.81
  12   0.0908     97.160  0.1056    96.803  71.64
  13   0.0836     97.300  0.0976    96.973  77.46
  14   0.1065     96.750  0.0920    97.153  83.35
  15   0.0769     97.640  0.0864    97.382  89.16
  16   0.0783     97.440  0.0839    97.457  94.99
  17   0.0719     97.690  0.0779    97.647  100.80
  18   0.0736     97.620  0.0751    97.757  106.63
  19   0.0677     97.880  0.0726    97.750  112.46
  20   0.0756     97.550  0.0694    97.917  118.39
  21   0.0686     97.850  0.0674    97.907  124.22
  22   0.0629     98.030  0.0636    98.028  130.03
  23   0.0691     97.900  0.0629    98.103  135.83
  24   0.0666     97.900  0.0603    98.138  141.65
  25   0.0590     98.080  0.0586    98.163  147.47
  26   0.0564     98.200  0.0570    98.183  153.32
  27   0.0568     98.180  0.0560    98.275  159.15
  28   0.0618     98.060  0.0536    98.392  164.98
  29   0.0543     98.300  0.0528    98.373  170.78
  30   0.0526     98.310  0.0515    98.413  176.61
  31   0.0538     98.250  0.0506    98.410  182.52
  32   0.0527     98.280  0.0497    98.470  188.33
  33   0.0522     98.390  0.0475    98.527  194.17
  34   0.0497     98.300  0.0468    98.555  199.99
  35   0.0488     98.470  0.0457    98.535  205.81
  36   0.0490     98.390  0.0449    98.638  211.71
  37   0.0484     98.380  0.0435    98.637  217.54
  38   0.0521     98.330  0.0429    98.657  223.36
  39   0.0426     98.590  0.0420    98.620  229.17
  40   0.0451     98.410  0.0406    98.753  235.00
  41   0.0504     98.350  0.0408    98.727  240.81
  42   0.0480     98.460  0.0395    98.782  246.71
  43   0.0427     98.400  0.0403    98.750  252.55
  44   0.0458     98.400  0.0389    98.788  258.38
  45   0.0442     98.590  0.0382    98.772  264.20
  46   0.0437     98.560  0.0381    98.830  270.04
  47   0.0460     98.490  0.0377    98.827  275.86
  48   0.0434     98.570  0.0359    98.855  281.77
  49   0.0425     98.580  0.0350    98.908  287.60
  50   0.0450     98.480  0.0355    98.857  293.43
  51   0.0403     98.620  0.0354    98.902  299.24
  52   0.0420     98.570  0.0341    98.915  305.07
  53   0.0446     98.560  0.0337    98.920  310.88
  54   0.0414     98.590  0.0319    99.032  316.78
  55   0.0430     98.530  0.0330    98.958  322.60
  56   0.0412     98.540  0.0316    99.010  328.43
  57   0.0425     98.580  0.0318    98.993  334.24
  58   0.0418     98.660  0.0314    98.997  340.06
  59   0.0429     98.620  0.0313    99.028  345.89
  60   0.0409     98.640  0.0306    99.033  351.81
  61   0.0412     98.660  0.0304    99.020  357.61
  62   0.0368     98.870  0.0293    99.082  363.42
  63   0.0390     98.730  0.0300    99.055  369.23
  64   0.0407     98.610  0.0296    99.057  375.07
  65   0.0387     98.590  0.0290    99.097  380.90
  66   0.0390     98.630  0.0281    99.097  386.81
  67   0.0379     98.800  0.0277    99.132  392.69
  68   0.0405     98.580  0.0273    99.157  398.52
  69   0.0388     98.730  0.0269    99.190  404.36
  70   0.0389     98.770  0.0276    99.143  410.20
  71   0.0346     98.770  0.0273    99.160  416.15
  72   0.0363     98.810  0.0271    99.158  421.96
  73   0.0423     98.470  0.0260    99.173  427.84
  74   0.0391     98.680  0.0255    99.175  433.68
  75   0.0446     98.510  0.0254    99.215  439.49
  76   0.0440     98.520  0.0254    99.167  445.31
  77   0.0368     98.800  0.0250    99.202  451.23
  78   0.0356     98.760  0.0240    99.248  457.07
  79   0.0409     98.590  0.0244    99.233  462.89
  80   0.0444     98.500  0.0248    99.188  468.72
  81   0.0445     98.560  0.0252    99.230  474.53
  82   0.0337     98.820  0.0241    99.202  480.38
  83   0.0415     98.590  0.0236    99.263  486.20
  84   0.0444     98.510  0.0225    99.277  492.00
  85   0.0423     98.450  0.0224    99.308  497.82
  86   0.0338     98.850  0.0227    99.295  503.63
  87   0.0368     98.700  0.0230    99.290  509.44
  88   0.0385     98.700  0.0218    99.295  515.33
  89   0.0370     98.700  0.0220    99.332  521.15
  90   0.0375     98.680  0.0218    99.302  526.98
