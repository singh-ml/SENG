Use GPU: 0 for training
==> Running with ['main_kfac.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 4677934080 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2529     63.350  1.9743    32.692  8.83
   2   0.4624     85.070  0.7854    75.472  15.61
   3   0.3205     89.540  0.4331    86.128  22.39
   4   0.2467     92.100  0.3212    89.928  29.24
   5   0.1987     93.680  0.2525    92.190  36.02
   6   0.1652     94.720  0.2101    93.548  43.21
   7   0.1459     95.250  0.1816    94.360  49.96
   8   0.1315     95.840  0.1624    94.907  56.84
   9   0.1243     95.940  0.1477    95.453  63.61
  10   0.1128     96.350  0.1345    95.775  70.37
  11   0.1073     96.580  0.1265    96.078  77.14
  12   0.0987     96.840  0.1169    96.403  84.32
  13   0.0946     97.040  0.1115    96.542  91.17
  14   0.0897     97.100  0.1029    96.723  97.93
  15   0.0880     97.130  0.0986    96.997  104.70
  16   0.0827     97.290  0.0940    97.075  111.47
  17   0.0816     97.260  0.0892    97.153  118.21
  18   0.0780     97.440  0.0842    97.380  125.51
  19   0.0766     97.540  0.0816    97.475  132.27
  20   0.0727     97.650  0.0805    97.467  139.10
  21   0.0716     97.700  0.0763    97.625  145.91
  22   0.0693     97.740  0.0744    97.692  152.66
  23   0.0690     97.810  0.0705    97.753  159.95
  24   0.0658     98.030  0.0676    97.872  166.72
  25   0.0645     98.010  0.0664    97.982  173.50
  26   0.0641     98.010  0.0634    98.047  180.26
  27   0.0629     98.040  0.0624    98.117  187.04
  28   0.0603     98.110  0.0576    98.210  193.91
  29   0.0618     98.020  0.0578    98.195  201.13
  30   0.0601     98.030  0.0569    98.218  207.88
  31   0.0592     98.120  0.0550    98.297  214.61
  32   0.0591     98.150  0.0556    98.275  221.38
  33   0.0584     98.090  0.0519    98.353  228.20
  34   0.0562     98.210  0.0511    98.370  235.12
  35   0.0584     98.050  0.0497    98.482  242.33
  36   0.0561     98.210  0.0491    98.480  249.09
  37   0.0536     98.300  0.0478    98.473  255.86
  38   0.0515     98.350  0.0476    98.545  262.63
  39   0.0522     98.310  0.0456    98.572  269.51
  40   0.0524     98.290  0.0444    98.643  276.33
  41   0.0517     98.330  0.0436    98.650  283.54
  42   0.0505     98.460  0.0440    98.595  290.30
  43   0.0516     98.400  0.0422    98.668  297.06
  44   0.0515     98.310  0.0419    98.707  303.90
  45   0.0501     98.440  0.0397    98.770  310.71
  46   0.0492     98.460  0.0406    98.748  317.92
  47   0.0488     98.400  0.0394    98.758  324.66
  48   0.0479     98.460  0.0383    98.843  331.39
  49   0.0489     98.430  0.0370    98.852  338.24
  50   0.0474     98.480  0.0364    98.917  345.02
  51   0.0486     98.390  0.0361    98.910  351.79
  52   0.0488     98.450  0.0356    98.867  358.94
  53   0.0470     98.520  0.0357    98.888  365.71
  54   0.0473     98.540  0.0342    98.960  372.50
  55   0.0467     98.530  0.0339    98.953  379.39
  56   0.0462     98.580  0.0334    98.955  386.16
  57   0.0475     98.490  0.0326    98.985  392.97
  58   0.0460     98.530  0.0329    98.968  400.16
  59   0.0452     98.510  0.0324    99.022  406.95
  60   0.0443     98.620  0.0303    99.088  413.74
  61   0.0453     98.600  0.0312    99.055  420.50
  62   0.0436     98.660  0.0300    99.072  427.28
  63   0.0432     98.640  0.0292    99.138  434.47
  64   0.0420     98.720  0.0281    99.098  441.32
  65   0.0422     98.680  0.0289    99.087  448.09
  66   0.0412     98.720  0.0287    99.133  454.87
  67   0.0428     98.630  0.0275    99.165  461.66
  68   0.0435     98.650  0.0274    99.140  468.41
  69   0.0414     98.710  0.0267    99.148  475.68
  70   0.0428     98.640  0.0270    99.182  482.46
  71   0.0429     98.640  0.0253    99.213  489.22
  72   0.0435     98.690  0.0248    99.268  495.98
  73   0.0444     98.610  0.0256    99.180  502.75
  74   0.0446     98.590  0.0246    99.245  509.63
  75   0.0441     98.600  0.0248    99.220  516.79
  76   0.0434     98.600  0.0244    99.248  523.56
  77   0.0444     98.600  0.0249    99.225  530.32
  78   0.0443     98.630  0.0234    99.297  537.10
  79   0.0432     98.670  0.0241    99.258  543.97
  80   0.0425     98.730  0.0238    99.305  550.72
  81   0.0435     98.740  0.0224    99.338  557.90
  82   0.0412     98.750  0.0220    99.312  564.71
  83   0.0418     98.630  0.0220    99.375  571.47
  84   0.0422     98.710  0.0219    99.313  578.34
  85   0.0423     98.700  0.0211    99.380  585.11
