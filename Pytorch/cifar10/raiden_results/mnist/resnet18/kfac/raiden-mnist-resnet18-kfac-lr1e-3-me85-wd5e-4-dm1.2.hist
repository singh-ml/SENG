Use GPU: 0 for training
==> Running with ['main_kfac.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'mnist', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Memory peak: 4677934080 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3025     60.580  2.0053    27.757  8.82
   2   0.4692     84.840  0.8434    72.935  15.71
   3   0.3160     89.750  0.4375    85.918  22.47
   4   0.2395     92.390  0.3190    89.987  29.20
   5   0.1932     93.870  0.2507    92.247  35.97
   6   0.1714     94.380  0.2098    93.443  43.14
   7   0.1515     94.950  0.1852    94.258  49.97
   8   0.1384     95.450  0.1672    94.777  56.72
   9   0.1272     95.740  0.1496    95.350  63.46
  10   0.1206     95.910  0.1387    95.602  70.22
  11   0.1138     96.220  0.1281    96.080  76.98
  12   0.1064     96.720  0.1165    96.313  84.24
  13   0.0994     96.750  0.1118    96.447  91.01
  14   0.0955     96.900  0.1043    96.825  97.77
  15   0.0905     97.120  0.0998    96.932  104.54
  16   0.0904     97.180  0.0924    97.192  111.38
  17   0.0847     97.270  0.0914    97.100  118.13
  18   0.0832     97.380  0.0857    97.355  125.31
  19   0.0815     97.400  0.0830    97.480  132.05
  20   0.0782     97.590  0.0793    97.505  138.84
  21   0.0761     97.590  0.0767    97.648  145.59
  22   0.0761     97.640  0.0729    97.762  152.46
  23   0.0738     97.600  0.0714    97.728  159.66
  24   0.0706     97.670  0.0689    97.857  166.43
  25   0.0670     97.780  0.0663    97.917  173.19
  26   0.0692     97.730  0.0645    98.013  180.06
  27   0.0669     97.770  0.0625    98.050  186.80
  28   0.0638     97.920  0.0592    98.130  193.56
  29   0.0640     97.950  0.0596    98.178  200.74
  30   0.0631     97.930  0.0572    98.208  207.50
  31   0.0616     97.980  0.0559    98.273  214.36
  32   0.0622     98.000  0.0537    98.328  221.12
  33   0.0613     98.080  0.0528    98.343  227.87
  34   0.0580     98.130  0.0509    98.438  234.63
  35   0.0589     98.130  0.0498    98.478  241.80
  36   0.0572     98.100  0.0490    98.525  248.61
  37   0.0576     98.150  0.0460    98.553  255.48
  38   0.0561     98.200  0.0467    98.548  262.22
  39   0.0551     98.210  0.0457    98.615  268.96
  40   0.0554     98.320  0.0454    98.600  275.70
  41   0.0546     98.240  0.0434    98.640  282.88
  42   0.0529     98.370  0.0428    98.687  289.77
  43   0.0535     98.340  0.0412    98.718  296.54
  44   0.0529     98.390  0.0397    98.767  303.28
  45   0.0516     98.360  0.0404    98.762  310.05
  46   0.0515     98.330  0.0392    98.792  317.21
  47   0.0517     98.340  0.0379    98.862  324.07
  48   0.0505     98.400  0.0378    98.865  330.82
  49   0.0504     98.350  0.0368    98.890  337.54
  50   0.0492     98.380  0.0374    98.853  344.28
  51   0.0497     98.430  0.0352    98.937  351.03
  52   0.0494     98.440  0.0348    98.942  358.17
  53   0.0490     98.390  0.0344    98.897  365.05
  54   0.0500     98.430  0.0351    98.880  371.82
  55   0.0477     98.440  0.0327    98.973  378.57
  56   0.0493     98.430  0.0321    99.010  385.32
  57   0.0482     98.490  0.0328    98.988  392.09
  58   0.0483     98.440  0.0313    99.043  399.40
  59   0.0491     98.470  0.0312    99.035  406.12
  60   0.0472     98.490  0.0303    99.103  412.89
  61   0.0473     98.500  0.0304    99.072  419.69
  62   0.0445     98.580  0.0309    99.060  426.44
  63   0.0455     98.550  0.0299    99.098  433.73
  64   0.0453     98.580  0.0284    99.143  440.50
  65   0.0463     98.500  0.0290    99.093  447.29
  66   0.0453     98.520  0.0284    99.095  454.08
  67   0.0445     98.590  0.0274    99.180  460.84
  68   0.0452     98.570  0.0270    99.153  467.68
  69   0.0434     98.610  0.0268    99.158  474.85
  70   0.0426     98.640  0.0258    99.233  481.61
  71   0.0431     98.670  0.0264    99.172  488.36
  72   0.0429     98.630  0.0263    99.210  495.29
  73   0.0422     98.640  0.0255    99.235  502.04
  74   0.0431     98.650  0.0256    99.227  508.79
  75   0.0413     98.710  0.0253    99.247  515.95
  76   0.0432     98.580  0.0244    99.258  522.70
  77   0.0420     98.630  0.0235    99.287  529.44
  78   0.0431     98.600  0.0236    99.295  536.32
  79   0.0419     98.660  0.0229    99.290  543.06
  80   0.0438     98.690  0.0219    99.383  549.83
  81   0.0430     98.670  0.0211    99.368  556.98
  82   0.0418     98.650  0.0212    99.375  563.73
  83   0.0405     98.710  0.0221    99.327  570.56
  84   0.0413     98.610  0.0216    99.365  577.32
  85   0.0419     98.690  0.0220    99.373  584.05
