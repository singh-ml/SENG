Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 18597587968 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6652      0.910  9.6573     1.050  17.58
   2   4.6659      0.920  9.6558     1.034  34.09
   3   4.6653      0.880  9.6539     1.072  50.51
   4   4.6653      0.850  9.6552     1.002  67.03
   5   4.6647      0.870  9.6556     1.004  83.45
   6   4.6663      0.900  9.6549     1.004  99.90
   7   4.6650      0.950  9.6552     0.990  116.37
   8   4.6650      0.850  9.6539     0.958  132.74
   9   4.6646      0.910  9.6501     1.020  149.21
  10   4.6657      0.810  9.6554     1.032  165.62
  11   4.6652      0.760  9.6593     0.978  182.11
  12   4.6653      0.810  9.6521     0.966  198.52
  13   4.6648      0.820  9.6555     1.036  214.96
  14   4.6655      0.860  9.6549     1.006  231.49
  15   4.6653      0.830  9.6621     0.986  247.90
  16   4.6648      0.890  9.6520     0.966  264.41
  17   4.6656      0.920  9.6532     1.004  280.82
  18   4.6647      0.860  9.6525     1.014  297.31
  19   4.6636      0.850  9.6579     1.040  313.72
  20   4.6654      0.890  9.6573     0.946  330.18
  21   4.6646      0.920  9.6488     1.124  346.60
  22   4.6653      0.860  9.6492     1.000  363.04
  23   4.6650      0.930  9.6523     1.010  379.47
  24   4.6637      0.890  9.6544     1.066  395.88
  25   4.6640      0.990  9.6526     1.006  412.32
  26   4.6650      0.910  9.6536     1.078  428.72
  27   4.6648      0.850  9.6593     0.964  445.17
  28   4.6649      0.920  9.6564     0.986  461.61
  29   4.6650      0.920  9.6582     0.996  478.06
  30   4.6642      0.930  9.6590     0.966  494.51
  31   4.6647      0.860  9.6531     1.026  510.91
  32   4.6651      0.890  9.6576     1.018  527.40
  33   4.6652      0.840  9.6492     0.966  543.80
  34   4.6653      0.830  9.6589     0.990  560.28
  35   4.6641      0.840  9.6523     0.988  576.68
  36   4.6642      0.900  9.6585     0.962  593.16
  37   4.6652      0.890  9.6527     1.020  609.55
  38   4.6642      0.900  9.6587     0.984  626.03
  39   4.6649      0.870  9.6584     0.986  642.44
  40   4.6660      0.900  9.6546     0.978  658.84
  41   4.6655      0.870  9.6566     0.992  675.35
  42   4.6648      0.840  9.6574     0.988  691.74
  43   4.6650      0.870  9.6542     0.986  708.21
  44   4.6639      0.890  9.6528     1.108  724.65
  45   4.6647      0.830  9.6586     0.986  741.11
  46   4.6653      0.850  9.6543     0.998  757.52
  47   4.6658      0.840  9.6553     1.052  774.02
  48   4.6648      0.900  9.6522     1.000  790.43
  49   4.6650      0.840  9.6586     0.950  806.92
  50   4.6648      0.840  9.6509     1.056  823.34
  51   4.6647      0.910  9.6507     0.998  839.79
  52   4.6648      0.890  9.6571     1.006  856.28
  53   4.6657      0.840  9.6588     0.994  872.69
  54   4.6655      0.880  9.6531     0.916  889.17
  55   4.6651      0.860  9.6482     0.998  905.59
  56   4.6652      0.860  9.6499     1.000  922.10
  57   4.6654      0.850  9.6540     1.022  938.51
  58   4.6647      0.850  9.6536     1.034  955.01
  59   4.6649      0.840  9.6492     1.080  971.44
  60   4.6644      0.870  9.6573     1.032  987.95
  61   4.6659      0.890  9.6494     1.042  1004.36
  62   4.6647      0.900  9.6495     1.048  1020.77
  63   4.6652      0.920  9.6551     0.940  1037.25
  64   4.6658      0.860  9.6565     0.940  1053.68
  65   4.6645      0.840  9.6567     1.016  1070.17
  66   4.6644      0.880  9.6547     1.014  1086.58
  67   4.6659      0.870  9.6542     0.948  1103.06
  68   4.6652      0.890  9.6600     0.970  1119.45
  69   4.6655      0.870  9.6522     0.950  1135.90
  70   4.6645      0.880  9.6520     1.018  1152.34
  71   4.6654      0.850  9.6581     0.966  1168.75
  72   4.6653      0.880  9.6551     0.964  1185.25
  73   4.6646      0.860  9.6495     1.054  1201.66
  74   4.6655      0.860  9.6512     0.968  1218.11
  75   4.6655      0.860  9.6550     1.002  1234.51
  76   4.6654      0.930  9.6564     1.004  1250.97
  77   4.6654      0.810  9.6495     1.042  1267.39
  78   4.6650      0.900  9.6520     0.952  1283.86
  79   4.6646      0.930  9.6559     1.046  1300.26
  80   4.6652      0.820  9.6577     0.976  1316.66
  81   4.6648      0.800  9.6550     1.026  1333.16
  82   4.6649      0.920  9.6527     0.938  1349.55
  83   4.6645      0.870  9.6540     1.042  1366.03
  84   4.6657      0.830  9.6524     1.010  1382.47
  85   4.6649      0.880  9.6577     0.970  1398.96
  86   4.6656      0.860  9.6515     1.024  1415.36
  87   4.6649      0.860  9.6505     1.104  1431.86
  88   4.6654      0.840  9.6591     0.978  1448.26
  89   4.6653      0.910  9.6475     1.074  1464.68
  90   4.6658      0.790  9.6553     1.006  1481.13
