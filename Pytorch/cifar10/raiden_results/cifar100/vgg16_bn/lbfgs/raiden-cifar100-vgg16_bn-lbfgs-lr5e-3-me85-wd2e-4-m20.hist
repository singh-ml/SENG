Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 9981029888 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6688      1.040  9.6705     0.984  12.55
   2   4.6704      1.020  9.6673     1.044  23.35
   3   4.6695      1.070  9.6659     0.956  34.18
   4   4.6695      1.060  9.6689     0.930  44.96
   5   4.6703      1.020  9.6700     0.962  55.75
   6   4.6704      1.020  9.6653     0.966  66.91
   7   4.6708      1.010  9.6642     1.002  77.71
   8   4.6689      1.040  9.6706     0.996  88.48
   9   4.6696      1.020  9.6708     0.924  99.25
  10   4.6692      1.040  9.6713     1.072  110.10
  11   4.6697      1.060  9.6620     1.028  120.89
  12   4.6693      1.030  9.6609     1.040  131.68
  13   4.6702      1.040  9.6665     1.004  142.54
  14   4.6691      1.060  9.6611     0.912  153.31
  15   4.6699      1.040  9.6634     0.960  164.07
  16   4.6705      1.070  9.6691     1.000  174.91
  17   4.6687      1.020  9.6673     0.940  185.71
  18   4.6693      1.080  9.6654     1.106  196.49
  19   4.6698      1.080  9.6655     0.992  207.31
  20   4.6699      1.030  9.6688     1.006  218.07
  21   4.6697      1.030  9.6729     0.998  228.83
  22   4.6698      1.030  9.6663     1.030  239.61
  23   4.6703      1.030  9.6698     1.046  250.36
  24   4.6694      1.040  9.6681     0.994  261.13
  25   4.6695      1.030  9.6667     0.904  271.90
  26   4.6692      1.050  9.6602     0.994  282.76
  27   4.6700      1.060  9.6649     1.036  293.56
  28   4.6706      1.030  9.6623     0.988  304.29
  29   4.6701      1.060  9.6662     0.980  315.04
  30   4.6700      1.020  9.6695     1.018  325.88
  31   4.6700      1.040  9.6711     1.054  336.66
  32   4.6690      1.050  9.6685     0.880  347.44
  33   4.6699      1.010  9.6687     1.016  358.27
  34   4.6684      1.010  9.6602     0.994  369.03
  35   4.6700      1.030  9.6655     0.992  379.79
  36   4.6703      1.040  9.6666     0.992  390.64
  37   4.6707      1.030  9.6704     0.974  401.42
  38   4.6695      1.040  9.6674     0.970  412.21
  39   4.6697      1.060  9.6622     0.992  423.07
  40   4.6697      1.020  9.6666     0.984  433.87
  41   4.6701      1.050  9.6636     0.966  444.64
  42   4.6703      1.020  9.6613     0.960  455.42
  43   4.6700      1.020  9.6673     0.978  466.30
  44   4.6696      1.030  9.6605     1.006  477.08
  45   4.6700      1.020  9.6658     1.006  487.84
  46   4.6708      1.060  9.6660     0.980  498.69
  47   4.6700      1.020  9.6663     0.970  509.45
  48   4.6700      1.060  9.6720     0.938  520.19
  49   4.6705      1.040  9.6630     1.022  530.95
  50   4.6700      1.060  9.6694     0.990  541.81
  51   4.6700      1.050  9.6676     0.986  552.61
  52   4.6695      1.070  9.6687     0.988  563.37
  53   4.6698      1.020  9.6708     0.880  574.23
  54   4.6690      1.030  9.6707     0.922  584.99
  55   4.6690      1.010  9.6721     0.994  595.79
  56   4.6700      1.030  9.6666     1.006  606.65
  57   4.6694      1.030  9.6672     0.970  617.43
  58   4.6696      1.070  9.6642     1.028  628.19
  59   4.6694      1.050  9.6693     0.972  638.99
  60   4.6698      1.060  9.6640     1.048  649.79
  61   4.6693      1.010  9.6678     1.050  660.57
  62   4.6698      1.070  9.6692     0.958  671.33
  63   4.6702      1.010  9.6638     1.008  682.18
  64   4.6700      1.040  9.6678     0.954  692.97
  65   4.6700      1.050  9.6723     1.042  703.73
  66   4.6693      1.080  9.6679     0.982  714.48
  67   4.6698      1.030  9.6605     1.078  725.33
  68   4.6697      1.080  9.6676     1.026  736.07
  69   4.6691      1.040  9.6672     0.936  746.83
  70   4.6701      1.010  9.6667     0.990  757.69
  71   4.6703      1.030  9.6624     1.026  768.44
  72   4.6702      0.980  9.6613     0.978  779.20
  73   4.6704      1.000  9.6663     1.018  790.04
  74   4.6689      1.050  9.6663     0.978  800.82
  75   4.6695      1.040  9.6715     0.920  811.57
  76   4.6693      1.040  9.6667     1.012  822.40
  77   4.6696      1.050  9.6675     0.996  833.18
  78   4.6700      1.030  9.6693     0.992  843.93
  79   4.6698      1.010  9.6693     1.066  854.82
  80   4.6708      1.000  9.6649     0.974  865.59
  81   4.6701      1.010  9.6703     1.004  876.37
  82   4.6694      1.050  9.6679     1.048  887.13
  83   4.6699      1.050  9.6689     0.994  898.00
  84   4.6696      1.030  9.6665     1.034  908.74
  85   4.6693      0.990  9.6671     0.980  919.53
