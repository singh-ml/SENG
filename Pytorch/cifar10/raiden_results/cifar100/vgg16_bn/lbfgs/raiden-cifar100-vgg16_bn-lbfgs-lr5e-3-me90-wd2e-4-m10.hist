Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 10502638592 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6750      0.810  9.6589     1.042  12.37
   2   4.6747      0.820  9.6564     1.000  23.25
   3   4.6737      0.840  9.6505     0.992  34.02
   4   4.6745      0.830  9.6510     0.978  44.82
   5   4.6751      0.830  9.6554     0.988  55.71
   6   4.6751      0.860  9.6503     0.964  66.51
   7   4.6743      0.810  9.6471     1.100  77.25
   8   4.6744      0.790  9.6534     0.948  88.12
   9   4.6740      0.850  9.6525     1.054  98.90
  10   4.6741      0.800  9.6550     0.860  109.71
  11   4.6740      0.830  9.6544     0.988  120.52
  12   4.6747      0.870  9.6566     0.980  131.34
  13   4.6742      0.880  9.6588     0.998  142.09
  14   4.6735      0.870  9.6527     1.026  152.86
  15   4.6734      0.850  9.6459     1.050  163.70
  16   4.6738      0.770  9.6514     0.962  174.47
  17   4.6751      0.880  9.6488     1.030  185.26
  18   4.6751      0.850  9.6520     0.996  196.11
  19   4.6741      0.870  9.6530     0.980  206.89
  20   4.6743      0.860  9.6524     0.984  217.66
  21   4.6733      0.840  9.6517     0.984  228.46
  22   4.6748      0.890  9.6501     1.028  239.30
  23   4.6757      0.830  9.6488     1.020  250.09
  24   4.6755      0.830  9.6574     0.948  260.88
  25   4.6739      0.810  9.6489     1.024  271.73
  26   4.6746      0.830  9.6577     1.010  282.52
  27   4.6738      0.840  9.6562     0.958  293.31
  28   4.6759      0.830  9.6534     1.018  304.20
  29   4.6741      0.850  9.6493     0.968  314.97
  30   4.6752      0.910  9.6522     1.032  325.74
  31   4.6745      0.820  9.6543     1.008  336.57
  32   4.6739      0.850  9.6527     0.942  347.36
  33   4.6741      0.870  9.6524     1.040  358.16
  34   4.6747      0.800  9.6495     1.080  368.92
  35   4.6740      0.770  9.6550     0.976  379.75
  36   4.6757      0.810  9.6515     0.990  390.50
  37   4.6749      0.870  9.6576     0.942  401.26
  38   4.6744      0.760  9.6520     1.028  412.02
  39   4.6742      0.880  9.6519     1.056  422.85
  40   4.6737      0.850  9.6500     1.060  433.61
  41   4.6743      0.810  9.6538     0.968  444.42
  42   4.6742      0.800  9.6518     0.982  455.24
  43   4.6746      0.790  9.6519     1.034  466.01
  44   4.6748      0.880  9.6520     1.038  476.76
  45   4.6754      0.840  9.6545     1.034  487.62
  46   4.6743      0.830  9.6483     0.978  498.38
  47   4.6751      0.890  9.6552     0.922  509.15
  48   4.6736      0.810  9.6502     1.074  519.92
  49   4.6737      0.930  9.6501     0.990  530.78
  50   4.6748      0.770  9.6532     1.038  541.54
  51   4.6732      0.850  9.6553     1.006  552.29
  52   4.6752      0.790  9.6481     0.950  563.17
  53   4.6751      0.830  9.6536     0.990  573.95
  54   4.6751      0.820  9.6569     0.970  584.71
  55   4.6744      0.870  9.6521     1.016  595.55
  56   4.6745      0.790  9.6572     0.868  606.33
  57   4.6740      0.810  9.6557     1.000  617.11
  58   4.6738      0.820  9.6585     0.988  627.86
  59   4.6747      0.880  9.6507     1.024  638.72
  60   4.6747      0.840  9.6488     0.964  649.46
  61   4.6740      0.840  9.6525     1.026  660.22
  62   4.6744      0.870  9.6517     1.042  671.07
  63   4.6744      0.860  9.6615     0.940  681.84
  64   4.6738      0.880  9.6502     1.018  692.61
  65   4.6738      0.860  9.6564     0.940  703.45
  66   4.6750      0.840  9.6521     0.992  714.22
  67   4.6752      0.900  9.6523     1.018  725.00
  68   4.6732      0.920  9.6540     1.018  735.87
  69   4.6741      0.820  9.6541     0.928  746.64
  70   4.6751      0.880  9.6521     0.958  757.40
  71   4.6748      0.860  9.6567     0.982  768.17
  72   4.6739      0.830  9.6528     1.038  779.02
  73   4.6736      0.840  9.6553     0.996  789.80
  74   4.6744      0.860  9.6535     1.002  800.58
  75   4.6744      0.840  9.6537     1.038  811.44
  76   4.6750      0.870  9.6562     0.988  822.21
  77   4.6736      0.870  9.6533     0.920  832.98
  78   4.6741      0.810  9.6480     0.954  843.76
  79   4.6755      0.850  9.6477     1.042  854.59
  80   4.6746      0.900  9.6523     1.044  865.35
  81   4.6738      0.840  9.6512     1.078  876.14
  82   4.6738      0.850  9.6531     0.954  887.00
  83   4.6741      0.870  9.6500     1.010  897.78
  84   4.6744      0.850  9.6547     1.018  908.54
  85   4.6749      0.840  9.6557     0.920  919.34
  86   4.6749      0.810  9.6552     1.018  930.10
  87   4.6748      0.880  9.6547     0.978  940.88
  88   4.6747      0.800  9.6611     1.008  951.75
  89   4.6752      0.790  9.6519     0.984  962.58
  90   4.6746      0.780  9.6558     0.982  973.35
