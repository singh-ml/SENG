Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 32616669184 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6388      0.980  16.7417     0.998  28.15
   2   4.6385      0.980  16.6839     1.076  55.82
   3   4.6385      1.060  16.6894     1.102  82.61
   4   4.6382      1.020  16.6854     1.062  109.36
   5   4.6386      0.990  16.6930     1.058  136.09
   6   4.6383      1.050  16.6929     0.974  162.76
   7   4.6386      0.970  16.6903     1.012  189.53
   8   4.6385      1.010  16.6905     0.988  216.28
   9   4.6388      1.110  16.6978     0.982  243.06
  10   4.6380      1.070  16.6981     1.056  269.72
  11   4.6383      0.990  16.6953     0.972  296.43
  12   4.6390      1.030  16.6926     1.148  323.19
  13   4.6384      1.010  16.6934     0.972  350.03
  14   4.6389      1.090  16.6918     0.958  376.72
  15   4.6388      1.000  16.6924     1.058  403.46
  16   4.6387      1.060  16.6905     1.052  430.20
  17   4.6390      1.010  16.6891     1.018  456.88
  18   4.6384      1.040  16.6912     0.994  483.71
  19   4.6388      0.990  16.6877     1.080  510.47
  20   4.6387      1.000  16.6916     1.046  537.25
  21   4.6375      1.110  16.6886     0.968  563.88
  22   4.6386      1.030  16.6915     1.024  590.54
  23   4.6383      1.000  16.6856     1.034  617.29
  24   4.6378      1.050  16.6878     1.096  644.01
  25   4.6383      1.100  16.6904     1.064  670.68
  26   4.6384      1.000  16.6861     1.086  697.42
  27   4.6388      1.050  16.6918     0.956  724.19
  28   4.6384      1.070  16.6914     0.948  750.95
  29   4.6385      1.060  16.6950     0.980  777.62
  30   4.6382      0.980  16.6941     0.998  804.34
  31   4.6384      1.040  16.6908     1.066  831.12
  32   4.6378      1.020  16.6877     0.992  857.90
  33   4.6383      1.020  16.6889     1.022  884.57
  34   4.6384      1.030  16.6938     1.024  911.31
  35   4.6385      1.060  16.6861     1.010  938.07
  36   4.6390      1.020  16.6938     0.970  964.78
  37   4.6389      1.030  16.6939     0.966  991.44
  38   4.6386      1.020  16.6957     1.056  1018.20
  39   4.6384      0.930  16.6962     0.946  1044.91
  40   4.6382      1.100  16.6867     1.042  1071.65
  41   4.6386      1.100  16.6892     1.010  1098.36
  42   4.6387      1.030  16.6938     0.988  1125.11
  43   4.6385      1.050  16.6928     0.926  1151.87
  44   4.6385      1.000  16.6906     0.982  1178.63
  45   4.6386      0.990  16.6889     1.044  1205.33
  46   4.6388      1.120  16.6929     1.030  1232.09
  47   4.6388      1.110  16.6940     0.962  1258.83
  48   4.6386      1.050  16.6871     0.984  1285.54
  49   4.6385      1.020  16.6892     1.038  1312.22
  50   4.6387      1.010  16.6897     1.040  1338.99
  51   4.6382      0.970  16.6877     1.038  1365.75
  52   4.6381      1.000  16.6954     1.002  1392.40
  53   4.6385      1.030  16.6908     1.042  1419.15
  54   4.6389      1.040  16.6887     1.012  1445.92
  55   4.6385      1.040  16.6887     1.004  1472.70
  56   4.6382      1.090  16.6935     1.016  1499.44
  57   4.6391      0.990  16.6879     0.970  1526.13
  58   4.6387      1.010  16.6911     1.130  1552.88
  59   4.6381      1.080  16.6926     1.112  1579.62
  60   4.6382      1.070  16.6946     1.066  1606.38
  61   4.6391      1.090  16.6888     0.988  1633.01
  62   4.6388      1.090  16.6893     1.046  1659.74
  63   4.6393      0.980  16.6916     0.998  1686.44
  64   4.6384      1.030  16.6963     1.024  1713.18
  65   4.6394      1.000  16.6918     1.034  1739.95
  66   4.6386      0.990  16.6940     1.062  1766.72
  67   4.6383      0.990  16.6933     1.034  1793.50
  68   4.6387      1.090  16.6875     1.066  1820.21
  69   4.6386      1.010  16.6928     1.042  1847.03
  70   4.6386      1.090  16.6816     0.978  1873.79
  71   4.6387      1.010  16.6897     1.074  1900.53
  72   4.6385      1.070  16.6922     1.034  1927.21
  73   4.6387      1.000  16.6843     0.994  1953.95
  74   4.6383      1.040  16.6854     1.008  1980.67
  75   4.6389      1.060  16.6874     1.030  2007.45
  76   4.6386      0.990  16.6891     1.014  2034.10
  77   4.6384      1.010  16.6883     1.028  2060.85
  78   4.6382      1.000  16.6844     0.996  2087.58
  79   4.6386      0.950  16.6920     0.938  2114.32
  80   4.6390      0.990  16.6908     0.954  2141.07
  81   4.6383      1.040  16.6910     1.032  2167.75
  82   4.6380      1.030  16.6922     0.984  2194.50
  83   4.6380      1.040  16.6917     1.176  2221.25
  84   4.6384      1.040  16.6881     0.974  2247.90
  85   4.6383      1.000  16.6904     0.958  2274.68
