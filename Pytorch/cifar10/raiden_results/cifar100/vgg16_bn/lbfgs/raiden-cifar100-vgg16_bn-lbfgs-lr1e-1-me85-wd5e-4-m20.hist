Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 28304789504 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6737      1.010  16.7631     0.968  24.83
   2   4.6733      0.980  16.7617     1.052  48.75
   3   4.6733      1.020  16.7600     1.008  72.43
   4   4.6734      1.000  16.7607     0.984  96.08
   5   4.6731      1.050  16.7633     1.024  119.64
   6   4.6728      1.030  16.7631     1.036  143.24
   7   4.6729      1.030  16.7635     1.036  166.84
   8   4.6732      1.000  16.7619     1.066  190.33
   9   4.6725      0.990  16.7640     0.898  213.93
  10   4.6735      1.000  16.7623     1.112  237.52
  11   4.6740      1.010  16.7616     1.064  261.05
  12   4.6733      1.000  16.7590     1.088  284.63
  13   4.6737      1.060  16.7581     1.038  308.22
  14   4.6729      1.010  16.7602     0.982  331.75
  15   4.6738      0.980  16.7643     1.000  355.35
  16   4.6722      1.040  16.7650     0.966  378.84
  17   4.6719      1.020  16.7602     0.974  402.35
  18   4.6729      1.040  16.7626     0.928  425.94
  19   4.6730      0.980  16.7600     0.980  449.50
  20   4.6722      1.000  16.7646     0.992  473.07
  21   4.6722      1.040  16.7621     1.062  496.67
  22   4.6718      1.020  16.7640     1.046  520.20
  23   4.6731      1.030  16.7564     1.030  543.79
  24   4.6720      1.090  16.7635     0.972  567.37
  25   4.6730      1.040  16.7603     1.080  590.86
  26   4.6725      1.000  16.7662     1.038  614.44
  27   4.6721      0.990  16.7641     1.062  638.03
  28   4.6724      0.990  16.7641     0.894  661.54
  29   4.6733      0.980  16.7642     0.982  685.14
  30   4.6720      1.000  16.7661     1.006  708.66
  31   4.6726      1.010  16.7615     1.082  732.29
  32   4.6727      1.000  16.7606     0.940  755.93
  33   4.6733      1.030  16.7619     1.018  779.46
  34   4.6731      1.050  16.7708     1.024  802.97
  35   4.6729      1.080  16.7646     1.000  826.62
  36   4.6726      1.000  16.7668     0.938  850.12
  37   4.6726      0.990  16.7609     1.052  873.72
  38   4.6725      1.040  16.7589     1.006  897.31
  39   4.6725      1.050  16.7588     1.002  920.81
  40   4.6732      0.980  16.7632     1.060  944.38
  41   4.6738      1.020  16.7700     0.924  968.00
  42   4.6738      1.050  16.7663     0.948  991.55
  43   4.6733      1.080  16.7608     0.976  1015.12
  44   4.6731      0.990  16.7611     1.010  1038.59
  45   4.6726      1.050  16.7626     0.998  1062.17
  46   4.6733      0.990  16.7607     0.964  1085.73
  47   4.6728      1.020  16.7650     1.108  1109.24
  48   4.6731      0.990  16.7644     1.014  1132.78
  49   4.6727      0.920  16.7587     1.112  1156.39
  50   4.6728      1.030  16.7649     1.026  1179.91
  51   4.6733      1.100  16.7673     0.986  1203.48
  52   4.6729      1.040  16.7637     0.978  1227.08
  53   4.6728      1.000  16.7617     1.038  1250.62
  54   4.6722      1.050  16.7608     1.030  1274.21
  55   4.6732      1.030  16.7632     0.994  1297.72
  56   4.6729      1.010  16.7651     1.012  1321.33
  57   4.6729      1.020  16.7654     1.040  1344.90
  58   4.6728      1.040  16.7652     1.032  1368.39
  59   4.6731      1.030  16.7592     1.010  1391.99
  60   4.6729      1.010  16.7636     0.974  1415.58
  61   4.6731      1.040  16.7598     1.058  1439.11
  62   4.6727      1.050  16.7602     0.992  1462.71
  63   4.6738      0.970  16.7657     1.044  1486.28
  64   4.6719      1.000  16.7674     0.990  1509.79
  65   4.6726      0.980  16.7654     1.042  1533.36
  66   4.6729      1.010  16.7646     0.976  1556.98
  67   4.6725      1.060  16.7666     1.024  1580.46
  68   4.6722      1.010  16.7669     0.966  1604.02
  69   4.6735      1.010  16.7587     0.948  1627.61
  70   4.6724      1.050  16.7648     1.034  1651.12
  71   4.6735      0.990  16.7632     1.018  1674.72
  72   4.6727      1.040  16.7571     1.042  1698.22
  73   4.6732      1.030  16.7662     1.054  1721.80
  74   4.6734      1.010  16.7609     1.072  1745.41
  75   4.6729      1.010  16.7642     1.004  1768.94
  76   4.6729      1.070  16.7603     1.012  1792.53
  77   4.6726      1.010  16.7613     1.020  1816.09
  78   4.6730      1.020  16.7671     1.044  1839.62
  79   4.6729      1.030  16.7693     1.022  1863.21
  80   4.6726      1.010  16.7611     1.018  1886.80
  81   4.6743      0.970  16.7645     0.938  1910.29
  82   4.6733      1.010  16.7669     1.014  1933.87
  83   4.6735      1.040  16.7588     1.000  1957.42
  84   4.6730      1.020  16.7635     1.100  1980.99
  85   4.6737      0.980  16.7640     1.038  2004.58
