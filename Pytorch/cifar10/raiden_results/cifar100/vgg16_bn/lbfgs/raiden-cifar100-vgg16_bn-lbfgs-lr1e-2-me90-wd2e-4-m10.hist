Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 12138082304 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6732      0.920  9.6645     1.000  14.44
   2   4.6735      0.900  9.6693     0.888  27.16
   3   4.6723      0.890  9.6633     1.070  39.91
   4   4.6738      0.960  9.6691     1.072  52.42
   5   4.6741      0.970  9.6649     0.948  64.81
   6   4.6732      0.880  9.6639     1.020  77.25
   7   4.6736      0.930  9.6654     0.994  89.64
   8   4.6737      0.920  9.6700     0.976  102.02
   9   4.6728      0.980  9.6674     0.946  114.48
  10   4.6748      0.990  9.6598     1.086  126.86
  11   4.6736      0.930  9.6686     1.040  139.25
  12   4.6729      0.890  9.6644     0.978  151.74
  13   4.6740      0.920  9.6663     0.986  164.14
  14   4.6735      0.940  9.6679     0.998  176.52
  15   4.6731      0.920  9.6659     1.042  188.98
  16   4.6741      0.960  9.6642     1.104  201.36
  17   4.6735      0.890  9.6638     1.050  213.73
  18   4.6742      0.930  9.6738     0.916  226.20
  19   4.6737      0.970  9.6713     0.970  238.57
  20   4.6729      0.920  9.6756     0.950  250.95
  21   4.6738      0.920  9.6667     1.080  263.40
  22   4.6730      0.930  9.6680     1.050  275.79
  23   4.6735      0.910  9.6656     1.038  288.17
  24   4.6741      0.960  9.6686     1.064  300.61
  25   4.6734      0.960  9.6652     0.976  313.02
  26   4.6740      0.890  9.6654     1.024  325.42
  27   4.6733      0.900  9.6674     1.012  337.85
  28   4.6732      1.000  9.6685     1.028  350.23
  29   4.6727      0.900  9.6665     0.972  362.61
  30   4.6738      0.930  9.6764     0.996  375.09
  31   4.6732      0.920  9.6662     1.026  387.49
  32   4.6734      0.970  9.6665     1.008  399.88
  33   4.6729      0.920  9.6659     0.944  412.33
  34   4.6741      0.900  9.6597     0.994  424.68
  35   4.6731      0.920  9.6679     1.036  437.07
  36   4.6721      0.860  9.6687     1.018  449.52
  37   4.6753      1.030  9.6653     1.030  461.90
  38   4.6726      0.890  9.6614     1.006  474.30
  39   4.6725      0.950  9.6753     1.022  486.81
  40   4.6739      0.940  9.6626     1.056  499.20
  41   4.6736      1.010  9.6606     1.056  511.58
  42   4.6737      0.950  9.6660     0.912  524.04
  43   4.6734      0.980  9.6667     1.010  536.44
  44   4.6725      0.920  9.6673     1.050  548.86
  45   4.6746      1.030  9.6632     1.012  561.23
  46   4.6736      0.960  9.6664     1.010  573.62
  47   4.6736      0.900  9.6657     0.988  586.09
  48   4.6741      1.010  9.6679     1.020  598.51
  49   4.6725      0.930  9.6627     1.034  610.87
  50   4.6746      0.960  9.6681     0.964  623.34
  51   4.6740      0.950  9.6644     0.982  635.77
  52   4.6734      0.920  9.6667     1.042  648.20
  53   4.6736      0.920  9.6646     0.954  660.66
  54   4.6735      0.970  9.6660     1.074  673.04
  55   4.6738      1.010  9.6715     0.960  685.44
  56   4.6728      0.900  9.6679     1.054  697.86
  57   4.6738      0.920  9.6631     1.044  710.26
  58   4.6749      0.930  9.6700     1.074  722.62
  59   4.6728      0.900  9.6659     1.020  735.05
  60   4.6733      0.970  9.6633     1.050  747.44
  61   4.6726      1.040  9.6606     1.042  759.85
  62   4.6741      0.920  9.6690     1.024  772.31
  63   4.6742      0.960  9.6584     0.994  784.71
  64   4.6735      0.920  9.6637     1.030  797.11
  65   4.6729      0.900  9.6679     0.990  809.58
  66   4.6736      0.900  9.6661     1.028  821.99
  67   4.6735      0.980  9.6721     0.996  834.43
  68   4.6734      0.990  9.6684     0.942  846.90
  69   4.6743      0.980  9.6664     1.076  859.28
  70   4.6726      0.970  9.6641     0.958  871.67
  71   4.6725      0.960  9.6704     1.022  884.13
  72   4.6754      0.910  9.6704     1.066  896.49
  73   4.6736      1.030  9.6662     1.044  908.88
  74   4.6722      0.940  9.6735     1.004  921.33
  75   4.6741      0.960  9.6638     1.024  933.77
  76   4.6731      0.900  9.6681     1.080  946.14
  77   4.6734      0.930  9.6689     0.974  958.64
  78   4.6742      0.950  9.6705     1.002  971.01
  79   4.6729      0.910  9.6678     1.050  983.41
  80   4.6746      0.990  9.6657     0.988  995.82
  81   4.6739      0.980  9.6721     1.024  1008.23
  82   4.6740      0.910  9.6680     0.944  1020.68
  83   4.6738      0.890  9.6719     1.010  1033.09
  84   4.6729      0.930  9.6658     0.978  1045.48
  85   4.6746      0.940  9.6665     1.000  1057.88
  86   4.6736      0.950  9.6690     0.908  1070.37
  87   4.6726      0.920  9.6715     1.036  1082.77
  88   4.6735      0.910  9.6693     1.020  1095.14
  89   4.6732      0.920  9.6646     0.976  1107.64
  90   4.6731      0.880  9.6682     1.014  1120.07
