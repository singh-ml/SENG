Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 12134159360 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6617      0.930  16.7509     0.988  13.27
   2   4.6625      0.970  16.7561     0.920  24.97
   3   4.6618      0.950  16.7566     1.028  36.60
   4   4.6616      0.950  16.7506     1.016  48.26
   5   4.6616      0.950  16.7493     1.010  59.97
   6   4.6622      0.960  16.7524     1.016  71.60
   7   4.6620      0.930  16.7495     0.944  83.19
   8   4.6623      0.970  16.7537     0.968  94.83
   9   4.6618      0.940  16.7528     0.922  106.45
  10   4.6621      0.930  16.7519     0.988  118.09
  11   4.6622      0.950  16.7542     0.978  129.77
  12   4.6613      0.940  16.7503     1.014  141.37
  13   4.6617      0.910  16.7516     1.026  153.01
  14   4.6614      0.930  16.7564     0.940  164.70
  15   4.6610      0.910  16.7628     0.996  176.36
  16   4.6626      0.940  16.7535     1.002  187.93
  17   4.6613      0.940  16.7490     1.010  199.63
  18   4.6627      0.960  16.7538     1.002  211.32
  19   4.6615      0.970  16.7535     1.030  222.92
  20   4.6610      0.930  16.7614     1.022  234.65
  21   4.6613      0.900  16.7559     0.976  246.35
  22   4.6624      0.920  16.7588     0.954  258.03
  23   4.6616      0.920  16.7543     1.028  269.65
  24   4.6625      0.910  16.7450     1.100  281.35
  25   4.6622      0.940  16.7499     0.970  292.95
  26   4.6610      0.900  16.7544     0.986  304.55
  27   4.6617      0.960  16.7534     0.928  316.29
  28   4.6623      0.950  16.7579     0.904  327.92
  29   4.6620      0.930  16.7530     1.036  339.55
  30   4.6620      0.910  16.7531     0.998  351.27
  31   4.6628      0.970  16.7586     0.968  362.92
  32   4.6621      0.930  16.7514     1.084  374.53
  33   4.6618      0.950  16.7532     0.990  386.23
  34   4.6619      0.940  16.7510     1.012  397.82
  35   4.6620      0.930  16.7459     1.030  409.45
  36   4.6614      0.910  16.7516     0.956  421.16
  37   4.6613      0.890  16.7533     0.958  432.78
  38   4.6611      0.920  16.7581     1.030  444.39
  39   4.6617      0.910  16.7519     1.062  456.06
  40   4.6616      0.930  16.7469     0.990  467.69
  41   4.6618      0.950  16.7549     1.034  479.30
  42   4.6621      0.940  16.7532     0.974  490.98
  43   4.6616      0.930  16.7558     1.008  502.74
  44   4.6616      0.920  16.7538     0.958  514.33
  45   4.6613      0.900  16.7522     0.918  525.94
  46   4.6621      0.950  16.7514     1.006  537.68
  47   4.6611      0.900  16.7488     1.050  549.32
  48   4.6614      0.900  16.7537     0.968  560.94
  49   4.6618      0.930  16.7537     0.950  572.70
  50   4.6621      0.930  16.7477     1.028  584.36
  51   4.6617      0.930  16.7551     0.962  595.98
  52   4.6620      0.970  16.7569     0.972  607.70
  53   4.6614      0.910  16.7584     0.950  619.33
  54   4.6617      0.930  16.7516     0.978  630.93
  55   4.6613      0.940  16.7526     0.982  642.64
  56   4.6620      0.950  16.7510     0.922  654.22
  57   4.6611      0.930  16.7458     0.994  665.85
  58   4.6625      0.940  16.7514     1.024  677.53
  59   4.6623      0.920  16.7525     0.916  689.13
  60   4.6618      0.940  16.7570     0.962  700.79
  61   4.6614      0.920  16.7479     1.124  712.50
  62   4.6619      0.930  16.7549     0.986  724.12
  63   4.6623      0.920  16.7514     1.038  735.73
  64   4.6636      0.950  16.7505     1.008  747.41
  65   4.6624      0.940  16.7452     1.076  759.04
  66   4.6622      0.910  16.7576     1.000  770.64
  67   4.6623      0.960  16.7511     0.952  782.38
  68   4.6618      0.920  16.7468     1.024  794.02
  69   4.6622      0.930  16.7532     0.962  805.65
  70   4.6614      0.950  16.7535     0.990  817.37
  71   4.6614      0.920  16.7585     0.922  829.03
  72   4.6623      0.940  16.7486     0.990  840.64
  73   4.6628      0.930  16.7527     0.960  852.24
  74   4.6628      0.960  16.7528     0.982  863.97
  75   4.6618      0.920  16.7561     0.982  875.63
  76   4.6613      0.930  16.7494     1.046  887.26
  77   4.6617      0.940  16.7537     0.986  898.95
  78   4.6618      0.960  16.7566     0.982  910.58
  79   4.6616      0.930  16.7549     1.038  922.25
  80   4.6621      0.930  16.7538     1.014  933.90
  81   4.6624      0.950  16.7535     0.992  945.53
  82   4.6615      0.920  16.7477     1.014  957.18
  83   4.6611      0.930  16.7541     0.938  968.90
  84   4.6621      0.910  16.7537     0.992  980.49
  85   4.6620      0.910  16.7517     1.008  992.09
