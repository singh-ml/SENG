Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 17525942272 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6315      1.050  16.7297     1.098  18.00
   2   4.6312      1.010  16.6874     1.028  33.68
   3   4.6315      0.990  16.6827     1.022  49.28
   4   4.6309      0.990  16.6818     1.012  64.88
   5   4.6310      0.970  16.6809     1.046  80.55
   6   4.6313      1.040  16.6778     0.976  96.17
   7   4.6311      1.070  16.6824     1.088  111.84
   8   4.6307      1.120  16.6865     1.050  127.43
   9   4.6314      1.030  16.6810     1.050  143.06
  10   4.6312      1.080  16.6838     1.100  158.65
  11   4.6307      1.110  16.6810     0.988  174.25
  12   4.6313      1.010  16.6816     1.078  189.95
  13   4.6309      1.120  16.6799     1.044  205.53
  14   4.6313      0.970  16.6906     1.002  221.19
  15   4.6311      1.000  16.6852     1.066  236.80
  16   4.6314      1.030  16.6898     0.980  252.48
  17   4.6312      1.060  16.6822     1.096  268.11
  18   4.6313      1.070  16.6860     0.986  283.70
  19   4.6311      1.050  16.6771     1.142  299.38
  20   4.6309      1.110  16.6778     1.018  314.98
  21   4.6314      1.100  16.6790     1.030  330.64
  22   4.6307      1.030  16.6783     1.160  346.23
  23   4.6311      1.030  16.6827     0.994  361.84
  24   4.6310      1.080  16.6841     1.142  377.45
  25   4.6313      1.000  16.6891     0.958  393.02
  26   4.6311      1.030  16.6775     1.104  408.71
  27   4.6307      1.100  16.6772     1.114  424.29
  28   4.6307      1.100  16.6787     1.172  439.95
  29   4.6315      1.010  16.6804     1.040  455.55
  30   4.6309      1.080  16.6822     0.988  471.20
  31   4.6316      1.010  16.6810     0.930  486.80
  32   4.6311      1.100  16.6816     1.004  502.39
  33   4.6308      1.040  16.6852     1.084  518.02
  34   4.6307      1.040  16.6853     1.030  533.61
  35   4.6307      1.120  16.6806     0.938  549.25
  36   4.6311      1.070  16.6841     1.024  564.83
  37   4.6308      1.100  16.6862     1.018  580.46
  38   4.6308      1.010  16.6805     1.062  596.02
  39   4.6309      1.070  16.6800     1.016  611.63
  40   4.6313      1.010  16.6842     1.064  627.29
  41   4.6311      1.100  16.6794     1.028  642.87
  42   4.6306      1.110  16.6754     1.010  658.51
  43   4.6311      1.080  16.6845     1.038  674.09
  44   4.6312      1.030  16.6789     1.032  689.76
  45   4.6311      1.040  16.6851     1.064  705.34
  46   4.6309      1.080  16.6778     1.072  720.95
  47   4.6311      1.010  16.6803     0.978  736.61
  48   4.6315      1.010  16.6819     1.064  752.16
  49   4.6309      1.090  16.6818     0.986  767.82
  50   4.6312      0.980  16.6810     1.062  783.40
  51   4.6309      1.080  16.6836     1.020  799.06
  52   4.6312      1.070  16.6821     1.086  814.68
  53   4.6310      1.040  16.6786     1.048  830.26
  54   4.6310      1.060  16.6810     1.012  845.92
  55   4.6314      1.030  16.6809     1.030  861.52
  56   4.6311      1.030  16.6795     1.018  877.21
  57   4.6311      1.080  16.6805     1.012  892.81
  58   4.6311      1.030  16.6805     1.034  908.47
  59   4.6313      1.050  16.6837     1.080  924.06
  60   4.6307      1.100  16.6850     1.028  939.63
  61   4.6308      1.110  16.6802     1.018  955.31
  62   4.6315      0.990  16.6798     1.000  970.90
  63   4.6310      1.020  16.6792     0.996  986.56
  64   4.6313      1.020  16.6825     1.008  1002.18
  65   4.6312      1.130  16.6791     1.018  1017.80
  66   4.6314      1.070  16.6817     1.054  1033.39
  67   4.6314      1.030  16.6835     1.068  1049.06
  68   4.6307      1.030  16.6805     1.036  1064.64
  69   4.6311      1.020  16.6825     1.106  1080.22
  70   4.6310      1.010  16.6789     0.982  1095.92
  71   4.6310      1.110  16.6796     1.098  1111.53
  72   4.6311      1.000  16.6779     1.064  1127.17
  73   4.6313      0.970  16.6813     1.102  1142.77
  74   4.6312      1.030  16.6811     1.074  1158.43
  75   4.6311      1.060  16.6807     1.044  1174.01
  76   4.6311      1.050  16.6788     1.068  1189.59
  77   4.6313      0.980  16.6784     1.056  1205.26
  78   4.6308      1.100  16.6845     0.894  1220.86
  79   4.6311      0.950  16.6785     0.994  1236.51
  80   4.6307      1.040  16.6797     1.070  1252.14
  81   4.6312      1.000  16.6900     1.108  1267.74
  82   4.6312      1.040  16.6822     1.062  1283.39
  83   4.6310      1.100  16.6798     1.084  1298.97
  84   4.6311      0.970  16.6752     1.094  1314.63
  85   4.6308      1.030  16.6797     1.060  1330.20
