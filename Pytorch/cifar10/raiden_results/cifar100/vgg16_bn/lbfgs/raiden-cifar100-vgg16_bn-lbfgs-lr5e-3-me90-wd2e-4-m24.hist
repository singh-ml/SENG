Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 9979464704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6831      1.050  9.6824     0.972  12.60
   2   4.6849      1.040  9.6799     0.942  23.47
   3   4.6845      1.050  9.6757     1.004  34.26
   4   4.6843      1.030  9.6841     1.016  45.05
   5   4.6845      1.040  9.6785     0.968  55.84
   6   4.6843      1.010  9.6842     1.020  66.71
   7   4.6853      1.020  9.6800     0.942  77.51
   8   4.6850      1.040  9.6839     0.938  88.26
   9   4.6839      1.050  9.6827     1.052  99.15
  10   4.6828      1.060  9.6838     0.986  109.93
  11   4.6845      1.070  9.6833     1.018  120.71
  12   4.6835      1.030  9.6824     1.062  131.48
  13   4.6841      1.060  9.6774     1.006  142.34
  14   4.6842      1.040  9.6774     0.974  153.08
  15   4.6846      1.080  9.6779     1.018  163.89
  16   4.6834      1.020  9.6813     1.078  174.75
  17   4.6850      1.040  9.6750     0.994  185.53
  18   4.6841      1.050  9.6785     0.958  196.33
  19   4.6842      1.040  9.6747     1.044  207.20
  20   4.6848      1.030  9.6851     0.934  217.99
  21   4.6836      1.030  9.6772     0.998  228.78
  22   4.6848      1.040  9.6825     1.000  239.62
  23   4.6836      1.050  9.6803     1.002  250.41
  24   4.6847      1.060  9.6825     0.952  261.18
  25   4.6839      1.040  9.6861     1.020  271.93
  26   4.6831      1.040  9.6820     0.962  282.76
  27   4.6841      1.030  9.6847     1.014  293.53
  28   4.6844      1.030  9.6821     0.978  304.28
  29   4.6836      1.020  9.6820     0.986  315.15
  30   4.6841      1.090  9.6808     1.072  325.93
  31   4.6844      1.030  9.6876     0.948  336.70
  32   4.6839      1.050  9.6830     0.990  347.58
  33   4.6829      1.060  9.6821     0.914  358.33
  34   4.6835      1.040  9.6809     0.958  369.11
  35   4.6847      1.050  9.6814     1.018  379.89
  36   4.6843      1.060  9.6807     1.038  390.73
  37   4.6842      1.060  9.6820     1.026  401.51
  38   4.6841      1.070  9.6814     0.946  412.30
  39   4.6844      1.040  9.6848     0.956  423.16
  40   4.6845      1.050  9.6795     1.054  433.94
  41   4.6833      1.050  9.6831     0.946  444.71
  42   4.6851      1.010  9.6794     0.920  455.56
  43   4.6832      1.040  9.6830     0.932  466.34
  44   4.6831      1.050  9.6825     1.036  477.13
  45   4.6841      1.010  9.6785     0.930  487.89
  46   4.6837      1.050  9.6818     1.004  498.74
  47   4.6842      1.020  9.6816     1.004  509.53
  48   4.6841      1.070  9.6817     1.026  520.31
  49   4.6837      1.060  9.6860     0.954  531.15
  50   4.6841      1.040  9.6790     1.070  541.90
  51   4.6847      1.060  9.6803     1.016  552.68
  52   4.6856      1.040  9.6802     1.002  563.43
  53   4.6840      1.050  9.6846     0.966  574.25
  54   4.6828      1.030  9.6824     1.022  585.01
  55   4.6846      1.020  9.6821     1.000  595.78
  56   4.6850      1.040  9.6829     0.972  606.64
  57   4.6843      1.070  9.6861     1.098  617.42
  58   4.6840      1.110  9.6851     0.990  628.20
  59   4.6832      1.050  9.6775     0.996  639.08
  60   4.6843      1.070  9.6795     0.958  649.84
  61   4.6840      1.080  9.6826     1.016  660.60
  62   4.6846      1.060  9.6846     1.002  671.46
  63   4.6836      1.060  9.6817     0.990  682.24
  64   4.6842      1.070  9.6784     0.970  693.02
  65   4.6846      1.060  9.6780     1.000  703.82
  66   4.6843      1.040  9.6828     1.048  714.67
  67   4.6845      1.030  9.6842     1.014  725.44
  68   4.6844      1.050  9.6777     1.010  736.21
  69   4.6843      1.030  9.6796     0.992  747.08
  70   4.6844      1.050  9.6797     1.000  757.85
  71   4.6828      1.090  9.6766     1.004  768.63
  72   4.6838      1.050  9.6812     1.094  779.49
  73   4.6840      1.050  9.6787     0.966  790.25
  74   4.6834      1.050  9.6832     1.024  801.01
  75   4.6840      1.040  9.6799     0.968  811.80
  76   4.6840      1.060  9.6812     0.988  822.65
  77   4.6846      1.050  9.6798     1.024  833.42
  78   4.6837      1.050  9.6812     0.964  844.20
  79   4.6838      1.080  9.6811     0.988  855.09
  80   4.6846      1.010  9.6845     1.048  865.86
  81   4.6842      1.060  9.6828     1.052  876.63
  82   4.6845      1.020  9.6852     0.962  887.49
  83   4.6850      1.040  9.6856     0.972  898.28
  84   4.6848      1.040  9.6859     1.028  909.08
  85   4.6831      1.040  9.6836     1.042  919.86
  86   4.6831      1.060  9.6829     0.964  930.72
  87   4.6847      1.020  9.6801     0.962  941.52
  88   4.6843      1.050  9.6809     1.016  952.31
  89   4.6836      1.050  9.6839     0.972  963.16
  90   4.6839      1.060  9.6756     0.974  973.93
