Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 8901396480 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6706      0.950  16.7646     1.010  12.09
   2   4.6698      1.000  16.7649     1.006  22.40
   3   4.6697      0.970  16.7660     0.942  32.74
   4   4.6698      1.010  16.7648     0.964  43.12
   5   4.6687      0.980  16.7745     0.990  53.45
   6   4.6681      1.000  16.7698     0.954  63.69
   7   4.6698      0.950  16.7669     1.012  74.01
   8   4.6691      0.980  16.7695     1.010  84.35
   9   4.6702      0.970  16.7702     0.946  94.62
  10   4.6699      1.000  16.7736     0.920  104.92
  11   4.6690      0.970  16.7689     0.986  115.33
  12   4.6697      0.940  16.7717     0.982  125.65
  13   4.6690      0.990  16.7673     0.970  135.94
  14   4.6691      1.000  16.7699     0.948  146.24
  15   4.6707      0.980  16.7699     0.968  156.64
  16   4.6691      1.020  16.7706     0.930  166.97
  17   4.6693      0.960  16.7669     0.994  177.28
  18   4.6694      1.010  16.7714     0.956  187.63
  19   4.6710      0.960  16.7671     1.000  197.96
  20   4.6702      0.920  16.7721     0.958  208.27
  21   4.6699      1.020  16.7612     1.038  218.67
  22   4.6695      0.930  16.7697     0.976  228.94
  23   4.6714      1.020  16.7706     1.014  239.19
  24   4.6692      0.970  16.7694     0.986  249.48
  25   4.6703      0.950  16.7689     1.004  259.88
  26   4.6695      0.980  16.7751     1.006  270.20
  27   4.6703      0.940  16.7719     0.922  280.52
  28   4.6699      0.970  16.7727     0.914  290.81
  29   4.6710      0.950  16.7638     1.054  301.19
  30   4.6704      0.950  16.7657     0.892  311.52
  31   4.6700      1.000  16.7723     0.972  321.85
  32   4.6703      0.960  16.7659     1.032  332.29
  33   4.6688      0.960  16.7733     0.992  342.56
  34   4.6698      0.960  16.7691     0.948  352.88
  35   4.6700      0.940  16.7709     0.972  363.25
  36   4.6707      0.930  16.7656     1.050  373.58
  37   4.6688      0.970  16.7697     1.008  383.87
  38   4.6690      0.970  16.7735     1.028  394.18
  39   4.6703      0.990  16.7713     1.026  404.51
  40   4.6692      0.940  16.7699     0.964  414.83
  41   4.6702      0.990  16.7734     0.930  425.15
  42   4.6693      0.980  16.7734     1.042  435.52
  43   4.6698      0.960  16.7678     0.968  445.84
  44   4.6694      0.960  16.7704     0.982  456.17
  45   4.6696      0.980  16.7702     0.982  466.48
  46   4.6698      0.970  16.7716     0.946  476.92
  47   4.6707      0.990  16.7657     0.960  487.24
  48   4.6700      0.990  16.7722     0.904  497.57
  49   4.6702      0.960  16.7711     1.028  507.99
  50   4.6693      0.990  16.7686     0.960  518.26
  51   4.6700      0.990  16.7654     1.044  528.57
  52   4.6701      0.990  16.7695     0.996  538.95
  53   4.6707      1.050  16.7729     1.104  549.26
  54   4.6690      0.990  16.7635     0.990  559.58
  55   4.6698      0.950  16.7697     1.018  569.87
  56   4.6707      0.960  16.7683     1.004  580.26
  57   4.6706      0.950  16.7727     0.932  590.59
  58   4.6691      0.970  16.7694     0.998  600.87
  59   4.6703      1.010  16.7664     0.920  611.28
  60   4.6698      1.000  16.7699     1.068  621.56
  61   4.6694      0.990  16.7739     0.918  631.85
  62   4.6712      0.910  16.7750     1.008  642.14
  63   4.6697      1.050  16.7608     1.060  652.55
  64   4.6699      0.960  16.7737     0.980  662.85
  65   4.6696      1.000  16.7657     0.940  673.13
  66   4.6700      0.990  16.7692     1.002  683.55
  67   4.6697      0.970  16.7710     1.008  693.89
  68   4.6701      1.040  16.7689     1.030  704.21
  69   4.6701      1.010  16.7701     0.980  714.55
  70   4.6701      0.980  16.7704     0.940  724.94
  71   4.6699      0.970  16.7708     0.990  735.24
  72   4.6688      0.990  16.7686     0.960  745.55
  73   4.6692      0.980  16.7669     1.056  755.96
  74   4.6713      0.950  16.7680     1.004  766.27
  75   4.6699      0.970  16.7638     0.890  776.57
  76   4.6694      0.950  16.7678     1.042  786.90
  77   4.6699      0.950  16.7718     0.914  797.19
  78   4.6687      1.040  16.7702     0.938  807.49
  79   4.6698      0.940  16.7680     0.950  817.79
  80   4.6701      1.020  16.7696     0.892  828.21
  81   4.6692      0.990  16.7687     0.986  838.54
  82   4.6703      0.980  16.7712     1.006  848.82
  83   4.6696      0.950  16.7697     1.058  859.21
  84   4.6708      0.970  16.7687     0.962  869.54
  85   4.6700      0.950  16.7739     0.974  879.83
