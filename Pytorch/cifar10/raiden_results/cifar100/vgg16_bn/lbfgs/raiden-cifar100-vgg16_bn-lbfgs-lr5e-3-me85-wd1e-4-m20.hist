Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 11057270784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6742      1.030  7.2987     1.056  12.89
   2   4.6741      1.010  7.2969     1.068  24.16
   3   4.6742      1.060  7.2904     1.068  35.46
   4   4.6747      1.080  7.2946     1.058  46.74
   5   4.6744      1.030  7.2966     1.026  58.00
   6   4.6740      0.980  7.2971     1.010  69.35
   7   4.6736      0.980  7.2967     0.894  80.54
   8   4.6746      1.030  7.2982     1.028  91.77
   9   4.6736      1.050  7.2975     0.984  103.05
  10   4.6744      1.060  7.2915     1.004  114.35
  11   4.6753      1.090  7.2952     0.972  125.64
  12   4.6741      1.060  7.2970     0.930  136.77
  13   4.6748      1.040  7.2927     0.980  147.97
  14   4.6741      1.090  7.2952     1.070  159.17
  15   4.6747      1.030  7.2990     1.016  170.41
  16   4.6754      1.030  7.2982     0.992  181.71
  17   4.6734      1.110  7.2922     1.010  192.96
  18   4.6740      1.060  7.2970     1.050  204.17
  19   4.6739      1.070  7.2979     1.010  215.56
  20   4.6736      1.110  7.2952     0.936  226.82
  21   4.6741      1.080  7.2974     1.002  238.09
  22   4.6741      1.000  7.2980     0.936  249.29
  23   4.6737      1.000  7.2960     0.966  260.64
  24   4.6740      1.010  7.2979     0.982  271.83
  25   4.6746      1.090  7.2971     0.952  283.07
  26   4.6747      1.040  7.2962     1.014  294.42
  27   4.6747      1.030  7.2905     0.926  305.75
  28   4.6744      1.030  7.2994     1.084  317.02
  29   4.6742      1.110  7.2949     0.942  328.37
  30   4.6744      1.040  7.2990     0.962  339.61
  31   4.6743      1.070  7.2921     1.030  350.84
  32   4.6740      1.060  7.2936     1.036  362.20
  33   4.6742      1.030  7.2986     1.042  373.48
  34   4.6746      1.030  7.2956     1.018  384.71
  35   4.6749      1.020  7.2946     1.028  395.98
  36   4.6734      1.060  7.2951     0.996  407.17
  37   4.6740      1.070  7.3016     1.044  418.42
  38   4.6749      1.090  7.2973     1.006  429.73
  39   4.6747      1.070  7.2945     0.894  440.92
  40   4.6741      1.120  7.2985     1.024  452.18
  41   4.6743      1.030  7.3011     0.956  463.36
  42   4.6752      1.070  7.2946     1.068  474.69
  43   4.6740      1.050  7.2980     0.912  486.04
  44   4.6745      1.060  7.3004     0.958  497.29
  45   4.6751      1.030  7.2947     1.046  508.60
  46   4.6747      1.060  7.2974     1.028  519.91
  47   4.6736      1.060  7.2943     1.046  531.15
  48   4.6743      1.110  7.2930     1.012  542.47
  49   4.6745      1.110  7.2915     1.030  553.67
  50   4.6747      1.040  7.2948     1.006  564.92
  51   4.6738      1.020  7.2976     1.004  576.25
  52   4.6744      1.010  7.2964     0.992  587.45
  53   4.6738      1.090  7.2997     0.902  598.76
  54   4.6736      1.020  7.2996     0.962  610.08
  55   4.6744      1.130  7.2915     0.906  621.29
  56   4.6752      1.050  7.2922     0.974  632.50
  57   4.6736      1.080  7.2913     1.030  643.81
  58   4.6739      1.020  7.2946     1.074  655.05
  59   4.6741      1.030  7.2937     0.988  666.31
  60   4.6743      0.970  7.2990     1.018  677.65
  61   4.6738      1.050  7.3025     0.972  688.91
  62   4.6746      1.050  7.2922     1.068  700.24
  63   4.6739      0.990  7.2974     0.980  711.48
  64   4.6745      1.030  7.2987     0.966  722.80
  65   4.6745      1.110  7.2980     0.980  734.03
  66   4.6747      1.040  7.2955     1.006  745.30
  67   4.6742      0.970  7.2901     1.034  756.60
  68   4.6743      1.030  7.2937     0.988  767.79
  69   4.6746      1.060  7.2976     1.010  779.06
  70   4.6741      1.060  7.2929     0.936  790.41
  71   4.6747      1.110  7.2912     1.054  801.57
  72   4.6738      1.020  7.3000     0.962  812.91
  73   4.6735      1.060  7.2928     1.020  824.19
  74   4.6739      1.070  7.2994     0.992  835.42
  75   4.6735      1.050  7.2875     1.038  846.68
  76   4.6739      1.040  7.2962     0.938  857.87
  77   4.6738      1.050  7.2987     0.998  869.22
  78   4.6742      1.000  7.2950     1.006  880.56
  79   4.6743      0.940  7.2916     0.990  891.82
  80   4.6742      1.080  7.2976     0.938  903.17
  81   4.6744      1.020  7.2931     1.048  914.51
  82   4.6746      1.060  7.2973     0.992  925.71
  83   4.6749      1.080  7.2891     1.040  936.99
  84   4.6744      1.090  7.2951     1.014  948.19
  85   4.6739      1.000  7.2955     1.042  959.51
