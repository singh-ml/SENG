Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 17524500480 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6850      1.100  16.7769     1.030  17.39
   2   4.6838      1.030  16.7735     0.964  33.43
   3   4.6842      1.030  16.7734     1.016  49.47
   4   4.6853      1.040  16.7732     1.052  65.60
   5   4.6836      1.000  16.7743     0.998  81.25
   6   4.6851      1.060  16.7752     0.924  96.89
   7   4.6846      1.030  16.7777     1.010  112.63
   8   4.6861      1.070  16.7799     1.008  128.27
   9   4.6839      1.070  16.7795     0.952  144.01
  10   4.6838      1.020  16.7753     1.042  159.69
  11   4.6839      1.010  16.7727     1.046  175.39
  12   4.6851      1.060  16.7700     1.074  191.04
  13   4.6858      1.050  16.7803     0.996  206.69
  14   4.6852      1.040  16.7789     1.034  222.40
  15   4.6852      1.060  16.7726     1.004  238.05
  16   4.6852      1.070  16.7711     1.070  253.76
  17   4.6849      1.040  16.7764     1.052  269.39
  18   4.6853      1.060  16.7748     0.916  285.13
  19   4.6860      1.030  16.7750     1.024  300.76
  20   4.6840      1.000  16.7761     1.058  316.36
  21   4.6854      1.030  16.7746     0.966  332.06
  22   4.6840      1.030  16.7821     1.018  347.70
  23   4.6852      1.010  16.7754     0.992  363.40
  24   4.6865      1.070  16.7799     1.054  379.04
  25   4.6841      1.010  16.7714     1.034  394.65
  26   4.6845      1.060  16.7789     1.028  410.38
  27   4.6849      1.020  16.7780     0.922  426.03
  28   4.6840      1.020  16.7749     0.986  441.76
  29   4.6847      0.980  16.7803     0.942  457.39
  30   4.6860      1.050  16.7774     0.978  473.07
  31   4.6844      1.060  16.7777     1.060  488.68
  32   4.6855      1.050  16.7788     0.990  504.36
  33   4.6833      1.020  16.7778     1.044  519.99
  34   4.6840      1.010  16.7719     1.040  535.58
  35   4.6840      1.010  16.7741     1.020  551.25
  36   4.6849      1.070  16.7739     1.062  566.87
  37   4.6843      1.080  16.7694     0.996  582.56
  38   4.6847      1.050  16.7793     0.960  598.19
  39   4.6850      1.050  16.7833     0.962  613.82
  40   4.6844      1.010  16.7762     1.070  629.56
  41   4.6850      1.040  16.7756     0.954  645.18
  42   4.6842      1.010  16.7735     1.032  660.88
  43   4.6841      1.050  16.7840     0.984  676.51
  44   4.6850      1.010  16.7802     0.938  692.23
  45   4.6857      1.070  16.7749     1.028  707.86
  46   4.6844      1.000  16.7719     0.986  723.44
  47   4.6843      1.090  16.7748     1.056  739.14
  48   4.6844      1.050  16.7778     0.950  754.79
  49   4.6837      1.010  16.7723     1.010  770.52
  50   4.6839      1.050  16.7784     1.066  786.17
  51   4.6832      1.050  16.7827     1.020  801.84
  52   4.6842      1.020  16.7749     1.004  817.48
  53   4.6855      1.060  16.7746     1.042  833.07
  54   4.6852      1.000  16.7788     1.000  848.79
  55   4.6849      1.070  16.7757     0.976  864.36
  56   4.6835      0.970  16.7780     0.966  880.12
  57   4.6857      1.060  16.7758     1.036  895.75
  58   4.6847      1.070  16.7726     0.992  911.38
  59   4.6850      1.050  16.7794     1.016  926.97
  60   4.6852      1.030  16.7803     1.012  942.61
  61   4.6848      1.050  16.7707     1.022  958.30
  62   4.6862      1.050  16.7788     0.970  973.94
  63   4.6838      1.040  16.7828     0.982  989.62
  64   4.6845      1.000  16.7779     1.060  1005.28
  65   4.6853      1.000  16.7743     1.076  1021.02
  66   4.6850      0.990  16.7738     1.002  1036.69
  67   4.6853      1.040  16.7781     1.022  1052.35
  68   4.6836      1.010  16.7729     1.060  1068.11
  69   4.6843      1.070  16.7764     1.038  1083.76
  70   4.6847      1.060  16.7710     0.982  1099.45
  71   4.6838      1.010  16.7771     1.134  1115.14
  72   4.6847      1.030  16.7786     0.996  1130.79
  73   4.6868      1.100  16.7816     0.990  1146.44
  74   4.6859      1.050  16.7765     1.028  1162.11
  75   4.6850      1.040  16.7730     0.942  1177.83
  76   4.6859      1.040  16.7761     0.992  1193.45
  77   4.6847      1.030  16.7748     1.044  1209.15
  78   4.6834      1.010  16.7762     0.988  1224.80
  79   4.6847      1.010  16.7790     1.060  1240.54
  80   4.6853      1.050  16.7752     0.952  1256.19
  81   4.6837      1.040  16.7763     0.998  1271.86
  82   4.6852      1.060  16.7724     1.078  1287.49
  83   4.6839      1.020  16.7799     1.020  1303.14
  84   4.6847      1.010  16.7789     0.958  1318.88
  85   4.6845      1.070  16.7755     1.014  1334.51
