Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 8900741120 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6812      1.000  16.7697     0.998  12.00
   2   4.6802      1.030  16.7671     0.962  22.32
   3   4.6793      1.050  16.7655     1.002  32.70
   4   4.6804      1.050  16.7641     0.902  42.97
   5   4.6796      1.060  16.7629     1.016  53.27
   6   4.6793      1.060  16.7681     0.972  63.61
   7   4.6803      0.980  16.7642     1.008  73.94
   8   4.6814      0.980  16.7672     0.904  84.24
   9   4.6797      1.000  16.7650     0.940  94.52
  10   4.6804      1.060  16.7629     0.960  104.88
  11   4.6800      1.090  16.7671     0.988  115.17
  12   4.6805      1.080  16.7651     0.934  125.45
  13   4.6788      1.020  16.7692     0.992  135.76
  14   4.6817      1.030  16.7678     1.020  146.11
  15   4.6791      0.970  16.7660     0.966  156.37
  16   4.6810      1.040  16.7635     0.896  166.65
  17   4.6794      1.090  16.7641     0.986  176.96
  18   4.6802      1.020  16.7621     1.020  187.34
  19   4.6796      1.040  16.7658     0.918  197.65
  20   4.6800      1.050  16.7631     1.002  207.97
  21   4.6800      0.990  16.7669     1.000  218.36
  22   4.6797      1.030  16.7639     0.954  228.64
  23   4.6789      1.000  16.7650     0.946  238.93
  24   4.6795      1.000  16.7637     1.020  249.31
  25   4.6810      1.020  16.7695     0.998  259.61
  26   4.6798      1.060  16.7688     1.058  269.85
  27   4.6800      1.020  16.7633     0.948  280.12
  28   4.6795      1.010  16.7622     1.024  290.48
  29   4.6799      1.050  16.7636     0.966  300.77
  30   4.6816      1.020  16.7644     1.016  311.03
  31   4.6803      1.000  16.7618     1.038  321.45
  32   4.6799      1.000  16.7689     0.940  331.78
  33   4.6804      1.040  16.7667     1.048  342.10
  34   4.6793      1.000  16.7691     0.878  352.41
  35   4.6804      1.060  16.7637     0.960  362.83
  36   4.6794      1.010  16.7640     1.010  373.14
  37   4.6808      1.010  16.7692     0.992  383.44
  38   4.6813      1.020  16.7649     0.894  393.76
  39   4.6808      0.990  16.7675     0.944  404.16
  40   4.6801      0.990  16.7716     1.032  414.45
  41   4.6796      1.030  16.7697     0.912  424.76
  42   4.6796      0.990  16.7648     0.966  435.12
  43   4.6802      1.010  16.7600     0.944  445.41
  44   4.6811      1.070  16.7697     1.012  455.70
  45   4.6804      1.000  16.7629     1.014  466.06
  46   4.6810      1.020  16.7688     0.996  476.33
  47   4.6798      0.980  16.7667     0.960  486.58
  48   4.6788      1.050  16.7650     1.036  496.85
  49   4.6798      1.010  16.7625     0.994  507.22
  50   4.6809      1.050  16.7679     0.974  517.51
  51   4.6806      1.000  16.7661     0.982  527.79
  52   4.6794      1.060  16.7680     0.946  537.80
  53   4.6803      1.000  16.7681     0.998  547.85
  54   4.6794      0.990  16.7651     1.014  557.81
  55   4.6804      1.020  16.7651     0.964  567.78
  56   4.6796      1.020  16.7639     1.032  577.82
  57   4.6813      1.020  16.7694     0.950  587.79
  58   4.6796      1.020  16.7665     0.990  597.76
  59   4.6805      0.990  16.7682     0.942  607.74
  60   4.6804      1.020  16.7671     0.966  617.79
  61   4.6803      1.020  16.7638     0.930  627.79
  62   4.6810      0.960  16.7643     0.946  637.78
  63   4.6801      1.000  16.7658     0.978  647.81
  64   4.6799      1.030  16.7684     0.980  657.77
  65   4.6802      0.980  16.7641     0.994  667.77
  66   4.6802      1.030  16.7639     1.028  677.76
  67   4.6814      1.020  16.7650     0.924  687.78
  68   4.6789      0.990  16.7675     1.028  697.78
  69   4.6798      0.990  16.7649     0.926  707.74
  70   4.6789      1.020  16.7599     1.030  717.71
  71   4.6806      1.010  16.7634     1.020  727.72
  72   4.6798      1.060  16.7653     0.914  737.68
  73   4.6800      1.000  16.7646     1.036  747.68
  74   4.6811      0.970  16.7665     1.014  757.71
  75   4.6802      1.030  16.7681     0.966  767.66
  76   4.6801      1.010  16.7671     1.052  777.61
  77   4.6804      0.980  16.7661     0.954  787.57
  78   4.6800      0.990  16.7635     0.964  797.59
  79   4.6800      1.020  16.7633     1.018  807.55
  80   4.6802      1.040  16.7691     0.956  817.51
  81   4.6804      1.050  16.7655     0.984  827.56
  82   4.6791      1.020  16.7639     1.038  837.55
  83   4.6801      1.030  16.7705     1.018  847.53
  84   4.6795      1.040  16.7666     0.992  857.51
  85   4.6798      1.040  16.7651     0.936  867.47
  86   4.6801      1.030  16.7678     0.906  877.44
  87   4.6811      1.040  16.7698     0.934  887.42
  88   4.6794      1.050  16.7662     0.980  897.44
  89   4.6797      1.080  16.7654     0.920  907.40
  90   4.6789      1.000  16.7661     0.938  917.36
