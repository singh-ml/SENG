Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '5', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 58825122304 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.3413      2.670  4.5513     1.722  36.10
   2   4.1382      4.370  4.2906     3.214  64.78
   3   4.0092      5.570  4.1547     4.456  93.35
   4   3.7113      9.800  3.9504     6.560  123.76
   5   3.5581     12.400  3.7300     9.498  152.36
   6   3.6305     14.340  3.4791    13.590  181.38
   7   3.1345     20.790  3.2288    18.278  210.31
   8   2.8062     26.560  2.9576    23.192  240.98
   9   2.6727     29.770  2.7336    27.840  269.82
  10   2.5319     32.790  2.5518    31.972  299.02
  11   2.2951     39.030  2.3736    35.802  329.95
  12   2.2650     39.860  2.2442    39.414  358.58
  13   2.4658     37.470  2.0889    42.880  389.36
  14   2.0033     45.320  2.0079    45.204  420.34
  15   2.0403     45.450  1.8750    48.210  449.67
  16   2.1402     44.820  1.8685    48.740  480.47
  17   1.8340     51.010  1.7187    52.460  511.27
  18   1.9354     48.350  1.6188    54.616  542.21
  19   1.7682     52.410  1.5463    56.622  572.99
  20   1.6922     54.030  1.4875    58.170  603.74
  21   1.6335     54.800  1.4215    59.548  635.23
  22   1.6429     55.230  1.3562    61.584  666.30
  23   1.6131     56.820  1.3032    62.944  695.64
  24   1.7094     55.730  1.2530    64.256  726.42
  25   1.5795     58.110  1.1880    65.688  755.75
  26   1.5063     59.580  1.1533    66.934  786.79
  27   1.5756     58.810  1.0971    68.210  817.59
  28   1.5233     59.950  1.0438    69.800  848.38
  29   1.5457     59.410  1.0065    70.704  879.15
  30   1.5763     59.270  0.9717    71.720  910.05
  31   1.5623     60.160  0.9330    72.602  940.98
  32   1.4618     62.080  0.8965    73.590  971.77
  33   1.5348     60.920  0.8448    75.016  1002.48
  34   1.4898     62.630  0.8220    75.688  1033.42
  35   1.5002     62.140  0.7820    76.770  1062.78
  36   1.5352     61.830  0.7448    77.780  1093.57
  37   1.5320     62.810  0.7199    78.452  1124.33
  38   1.5109     62.860  0.6885    79.388  1155.28
  39   1.4933     63.470  0.6541    80.422  1186.05
  40   1.5163     63.260  0.6276    81.020  1216.79
  41   1.4697     63.620  0.5957    82.050  1249.14
  42   1.5555     63.930  0.5654    82.962  1280.12
  43   1.4990     64.540  0.5404    83.552  1311.00
  44   1.4926     64.680  0.5169    84.324  1341.87
  45   1.5462     64.280  0.4851    85.182  1372.69
  46   1.6064     64.990  0.4553    86.026  1403.63
  47   1.5572     64.110  0.4464    86.316  1434.48
