Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '5', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 57208471040 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.0561      5.600  4.3712     3.152  36.38
   2   3.7373      9.600  3.9745     6.920  65.73
   3   3.6848     10.650  3.7516     9.672  94.56
   4   3.2853     18.060  3.5095    13.592  125.59
   5   3.1061     21.280  3.2564    17.730  154.65
   6   2.8884     24.550  3.0583    21.688  185.28
   7   2.6759     29.140  2.8238    26.496  214.04
   8   2.5573     32.980  2.6172    30.844  243.33
   9   2.4143     36.740  2.4476    34.718  272.51
  10   2.3077     38.360  2.2831    38.856  301.98
  11   2.5498     35.490  2.1699    41.344  333.01
  12   2.0659     44.580  2.0396    44.510  362.06
  13   1.8797     48.050  1.9186    47.470  393.22
  14   2.0952     45.500  1.8234    49.812  422.62
  15   2.0306     46.330  1.7169    52.464  453.66
  16   1.7827     51.820  1.6538    53.798  484.64
  17   1.6895     54.020  1.5731    56.038  515.80
  18   2.0538     49.290  1.4968    57.932  544.79
  19   1.7872     52.870  1.4530    59.262  574.27
  20   1.6769     55.240  1.3729    61.116  605.46
  21   1.7039     55.260  1.3075    62.750  636.60
  22   1.5894     57.660  1.2822    63.468  665.88
  23   1.6446     56.790  1.1956    65.908  696.90
  24   1.6209     57.640  1.1635    66.362  726.49
  25   1.4938     60.130  1.0944    68.314  757.47
  26   1.4926     60.080  1.0535    69.442  786.92
  27   1.6216     58.600  1.0099    70.764  818.07
  28   1.5457     59.880  0.9646    71.582  849.21
  29   1.6217     59.500  0.9297    72.700  880.25
  30   1.6337     59.050  0.8834    73.812  908.97
  31   1.5399     60.700  0.8450    74.902  940.16
  32   1.5479     60.730  0.7978    76.026  969.44
  33   1.5449     60.890  0.7669    77.114  1000.47
  34   1.5377     61.860  0.7349    77.904  1031.45
  35   1.5744     61.430  0.7009    78.936  1062.59
  36   1.6280     61.520  0.6626    79.898  1095.35
  37   1.5839     62.140  0.6314    80.826  1126.40
  38   1.6047     62.570  0.6041    81.600  1157.37
  39   1.5779     63.170  0.5756    82.338  1188.59
  40   1.5742     63.000  0.5400    83.458  1219.63
  41   1.6942     62.230  0.5176    84.164  1248.92
  42   1.5950     64.430  0.4985    84.534  1279.92
  43   1.6603     62.540  0.4638    85.600  1311.08
  44   1.6627     63.960  0.4301    86.494  1343.79
  45   1.6060     64.330  0.4094    87.218  1374.78
