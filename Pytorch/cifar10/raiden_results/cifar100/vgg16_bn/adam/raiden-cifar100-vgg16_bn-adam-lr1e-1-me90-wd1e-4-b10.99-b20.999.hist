Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4203317248 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6345      1.000  39631.0472     1.094  7.76
   2   4.6178      1.000  741.8048     0.896  13.80
   3   4.6177      1.000  1398.2529     0.962  19.82
   4   4.6158      1.000  760.4279     0.990  25.83
   5   4.6181      1.000  628.7840     0.988  31.85
   6   4.6195      1.000  499.3696     0.936  37.95
   7   4.6181      1.000  227.8681     1.012  43.99
   8   4.6210      1.000  53.1105     1.042  50.03
   9   4.6167      1.000  39.9847     0.906  56.09
  10   4.6206      1.000  37.3635     0.910  62.10
  11   4.6170      1.000  19.6148     0.874  68.12
  12   4.6240      1.000  38.5618     1.030  74.24
  13   4.6176      1.000  6.6115     0.970  80.26
  14   4.6228      1.000  6.4750     0.914  86.27
  15   4.6180      1.000  5.3795     0.996  92.32
  16   4.6193      1.000  6.8112     0.958  98.36
  17   4.6209      1.000  5.3885     0.996  104.38
  18   9.8156      1.000  4.8745     1.042  110.52
  19   4.6196      1.000  4.6978     0.902  116.54
  20   67.9004      1.000  5.8113     0.930  122.58
  21   129.6711      1.060  5.4788     0.952  128.61
  22   180.4143      1.070  4.6797     0.958  134.64
  23   187.4200      1.060  4.6832     0.960  140.79
  24   69.4998      1.060  4.6685     0.914  146.82
  25   137.8034      1.080  4.6704     0.982  152.85
  26   7.0255      1.000  5.1795     0.966  158.86
  27   9.3990      1.000  4.6938     0.954  164.88
  28   12.4102      1.000  4.6541     0.966  170.90
  29   21.8156      1.000  4.7050     1.028  176.98
  30   14.7071      1.000  4.6731     0.954  182.99
  31   10.2693      1.000  4.6656     1.006  189.01
  32   4.6196      1.000  5.0034     1.014  195.02
  33   14.0874      1.020  4.7968     0.960  201.08
  34   6.9125      1.000  4.6727     0.948  207.12
  35   4.9780      1.000  4.6545     1.014  213.23
  36   4.6213      1.000  4.9260     0.994  219.28
  37   4.6221      1.000  4.8461     0.974  225.31
  38   4.6243      0.990  4.6520     1.022  231.33
  39   6.7693      1.000  4.7485     0.954  237.34
  40   4.6191      1.000  4.6559     0.964  243.37
  41   4.6512      1.000  4.6440     0.974  249.51
  42   4.7383      1.000  4.6460     0.992  255.57
  43   5.0980      1.000  4.6505     0.974  261.62
  44   7.6225      1.000  4.6413     0.878  267.64
  45   4.6201      1.000  4.6572     0.942  273.64
  46   4.6193      1.000  4.6584     0.998  279.68
  47   4.7505      1.000  4.6501     0.992  285.75
  48   5.1345      1.010  4.6457     0.966  291.80
  49   5.8329      0.980  4.6431     0.888  297.85
  50   4.6650      1.000  4.6558     0.974  303.87
  51   4.6199      1.000  4.6388     0.996  309.89
  52   5.8845      1.000  4.6443     1.002  316.03
  53   4.6187      1.000  4.6438     1.020  322.10
  54   4.6172      1.000  4.6377     0.866  328.12
  55   4.7649      1.000  4.6509     0.926  334.16
  56   4.6240      1.000  4.6411     1.032  340.19
