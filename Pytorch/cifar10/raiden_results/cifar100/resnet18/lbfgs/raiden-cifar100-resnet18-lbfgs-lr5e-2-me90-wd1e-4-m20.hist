Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5292304896 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7205      1.000  5.9986     0.962  10.21
   2   4.7205      0.980  6.0004     0.948  18.77
   3   4.7207      0.990  5.9994     0.974  27.28
   4   4.7227      0.980  5.9995     0.984  35.65
   5   4.7218      1.010  5.9986     0.974  43.91
   6   4.7191      0.990  5.9998     0.988  52.34
   7   4.7202      0.980  5.9989     0.970  60.66
   8   4.7199      0.990  5.9998     0.958  69.10
   9   4.7212      0.990  5.9993     0.988  77.48
  10   4.7176      0.990  5.9997     0.974  85.88
  11   4.7180      0.980  6.0013     0.982  94.11
  12   4.7195      0.980  6.0005     0.962  102.48
  13   4.7180      0.970  5.9983     0.990  110.72
  14   4.7194      0.990  6.0005     0.984  119.31
  15   4.7193      1.000  5.9996     0.992  127.60
  16   4.7191      0.950  5.9998     0.986  135.85
  17   4.7202      1.000  5.9998     0.978  144.04
  18   4.7207      0.980  5.9998     0.968  152.37
  19   4.7204      1.000  5.9999     0.994  160.84
  20   4.7197      0.980  6.0001     0.976  169.09
  21   4.7196      0.990  5.9992     0.966  177.40
  22   4.7221      0.960  5.9986     0.976  185.63
  23   4.7191      0.950  5.9998     0.980  194.15
  24   4.7202      1.000  6.0002     0.972  202.51
  25   4.7220      0.990  5.9990     0.954  210.92
  26   4.7213      1.000  6.0012     0.986  219.33
  27   4.7206      0.980  6.0005     0.988  227.78
  28   4.7210      0.960  5.9999     1.022  236.11
  29   4.7175      0.950  5.9997     1.000  244.40
  30   4.7206      0.990  6.0006     1.018  252.74
  31   4.7198      0.990  5.9988     0.978  261.07
  32   4.7209      0.980  6.0002     0.912  269.41
  33   4.7181      0.980  5.9999     0.980  277.81
  34   4.7175      0.980  6.0001     0.948  286.07
  35   4.7188      1.020  5.9990     1.016  294.37
  36   4.7202      0.980  5.9995     1.006  302.79
  37   4.7218      0.990  5.9994     0.990  311.21
  38   4.7208      0.970  5.9993     0.944  319.63
  39   4.7174      0.980  5.9997     1.012  327.89
  40   4.7186      0.970  6.0009     1.012  336.36
  41   4.7210      0.980  5.9997     0.948  344.62
  42   4.7188      0.960  6.0001     0.928  353.03
  43   4.7191      1.000  5.9999     0.930  361.44
  44   4.7195      0.970  6.0002     0.950  369.84
  45   4.7208      1.000  5.9998     0.954  378.15
  46   4.7202      1.010  5.9991     0.978  386.54
  47   4.7199      0.980  6.0010     0.956  394.91
  48   4.7207      1.000  5.9989     0.992  403.31
  49   4.7190      1.000  6.0002     0.972  411.78
  50   4.7185      0.970  5.9998     0.980  420.16
  51   4.7202      0.990  5.9994     0.992  428.48
  52   4.7195      0.980  5.9998     0.950  436.86
  53   4.7200      1.000  5.9999     0.998  445.35
  54   4.7209      0.980  5.9990     0.980  453.75
  55   4.7179      0.970  5.9993     1.008  462.34
  56   4.7190      0.990  6.0001     0.952  470.70
  57   4.7188      0.940  5.9996     0.940  479.11
  58   4.7177      1.010  5.9999     0.998  487.41
  59   4.7182      1.000  5.9996     0.990  495.75
  60   4.7218      0.970  5.9995     1.000  504.05
  61   4.7197      0.990  5.9995     0.954  512.53
  62   4.7213      0.960  5.9999     0.992  521.14
  63   4.7205      1.000  5.9992     0.960  529.72
  64   4.7216      0.970  5.9992     0.964  538.09
  65   4.7182      0.990  6.0007     0.984  546.45
  66   4.7216      0.950  6.0006     0.982  554.98
  67   4.7215      0.960  5.9998     0.994  563.31
  68   4.7202      0.990  6.0003     0.958  571.55
  69   4.7216      1.000  5.9984     0.990  579.88
  70   4.7243      0.980  5.9987     1.010  588.17
  71   4.7178      0.940  5.9991     0.946  596.62
  72   4.7194      0.970  5.9997     0.954  604.99
  73   4.7174      0.960  6.0000     0.938  613.36
  74   4.7209      0.980  5.9987     0.972  621.73
  75   4.7192      0.980  5.9987     0.974  630.18
  76   4.7211      0.960  5.9999     0.978  638.58
  77   4.7203      0.980  5.9999     0.984  646.80
  78   4.7206      0.950  5.9998     0.946  655.14
  79   4.7193      0.980  6.0003     0.966  663.58
  80   4.7220      0.960  6.0001     0.968  671.79
  81   4.7207      0.960  6.0002     0.952  680.17
  82   4.7177      0.950  5.9992     0.966  688.48
  83   4.7205      0.970  5.9988     0.970  697.03
  84   4.7222      0.990  5.9995     0.948  705.33
  85   4.7212      0.980  6.0006     0.978  713.66
  86   4.7177      0.980  5.9992     0.998  721.98
  87   4.7200      0.990  5.9997     0.956  730.31
  88   4.7211      0.970  6.0001     0.940  738.67
  89   4.7183      1.010  5.9994     0.982  746.87
  90   4.7186      0.970  5.9998     0.974  755.10
