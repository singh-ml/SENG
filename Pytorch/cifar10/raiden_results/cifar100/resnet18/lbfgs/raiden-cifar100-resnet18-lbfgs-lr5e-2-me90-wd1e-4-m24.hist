Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5739871744 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7227      0.940  5.9761     1.002  10.51
   2   4.7212      0.980  5.9762     0.962  19.16
   3   4.7236      1.000  5.9756     1.022  27.85
   4   4.7261      0.970  5.9759     0.886  36.62
   5   4.7263      0.960  5.9771     0.918  45.39
   6   4.7248      0.950  5.9750     1.020  54.11
   7   4.7250      0.980  5.9764     0.906  62.82
   8   4.7215      1.010  5.9760     0.958  71.52
   9   4.7230      0.980  5.9744     0.992  80.15
  10   4.7231      0.990  5.9760     1.040  88.80
  11   4.7242      1.000  5.9762     0.950  97.35
  12   4.7204      0.990  5.9748     1.006  105.89
  13   4.7206      0.990  5.9751     0.980  114.70
  14   4.7240      0.960  5.9738     0.924  123.28
  15   4.7227      0.980  5.9762     0.976  131.79
  16   4.7221      0.960  5.9769     0.980  140.29
  17   4.7232      0.980  5.9766     0.982  149.01
  18   4.7223      0.950  5.9760     1.034  157.59
  19   4.7228      1.000  5.9760     1.044  166.16
  20   4.7244      0.930  5.9758     0.974  174.64
  21   4.7217      0.930  5.9766     0.962  183.23
  22   4.7221      0.970  5.9756     0.984  191.84
  23   4.7236      0.960  5.9756     0.986  200.49
  24   4.7222      0.950  5.9764     0.994  209.02
  25   4.7256      0.970  5.9752     0.910  217.66
  26   4.7223      0.940  5.9749     0.918  226.20
  27   4.7217      0.990  5.9757     1.024  234.79
  28   4.7250      0.990  5.9751     0.986  243.29
  29   4.7234      0.960  5.9766     0.914  251.88
  30   4.7221      0.990  5.9758     0.992  260.39
  31   4.7217      0.990  5.9750     0.972  268.96
  32   4.7215      1.000  5.9766     0.966  277.49
  33   4.7224      0.970  5.9776     0.962  286.18
  34   4.7271      0.960  5.9768     1.030  294.97
  35   4.7221      0.970  5.9760     0.958  303.47
  36   4.7247      1.000  5.9763     1.000  312.16
  37   4.7246      0.970  5.9754     0.948  320.79
  38   4.7248      0.970  5.9764     0.988  329.28
  39   4.7217      0.970  5.9748     0.974  337.89
  40   4.7227      0.990  5.9755     0.948  346.41
  41   4.7219      0.960  5.9765     0.980  355.14
  42   4.7228      0.990  5.9768     0.964  363.61
  43   4.7246      0.970  5.9764     0.960  372.12
  44   4.7248      0.990  5.9757     1.060  380.71
  45   4.7245      0.950  5.9765     1.050  389.46
  46   4.7234      0.950  5.9758     0.940  398.14
  47   4.7244      0.960  5.9757     0.950  406.69
  48   4.7229      0.970  5.9761     1.020  415.32
  49   4.7237      0.980  5.9756     0.954  424.01
  50   4.7231      0.970  5.9770     0.998  432.43
  51   4.7259      0.990  5.9753     1.040  441.07
  52   4.7237      0.980  5.9767     0.954  449.62
  53   4.7241      0.970  5.9759     0.918  458.31
  54   4.7233      0.990  5.9769     0.916  466.91
  55   4.7243      0.940  5.9757     0.984  475.51
  56   4.7224      0.940  5.9762     0.950  484.13
  57   4.7223      0.970  5.9766     0.974  492.67
  58   4.7216      0.990  5.9752     0.954  501.40
  59   4.7235      0.960  5.9756     0.950  510.05
  60   4.7226      0.950  5.9767     0.904  518.62
  61   4.7217      0.950  5.9762     0.924  527.37
  62   4.7250      1.000  5.9754     0.986  535.92
  63   4.7234      0.950  5.9759     0.932  544.40
  64   4.7230      0.990  5.9752     0.984  552.96
  65   4.7223      0.980  5.9758     0.958  561.61
  66   4.7225      0.990  5.9767     0.938  570.33
  67   4.7244      0.960  5.9756     0.998  578.86
  68   4.7267      0.970  5.9765     1.018  587.43
  69   4.7250      0.970  5.9762     0.976  596.18
  70   4.7254      0.980  5.9759     0.990  604.70
  71   4.7217      0.970  5.9755     0.956  613.37
  72   4.7239      0.950  5.9762     1.018  621.95
  73   4.7247      0.990  5.9758     0.994  630.68
  74   4.7210      0.990  5.9756     0.972  639.27
  75   4.7241      0.980  5.9746     0.920  647.67
  76   4.7244      0.960  5.9759     0.978  656.39
  77   4.7221      0.960  5.9767     1.026  665.12
  78   4.7223      1.010  5.9754     1.036  673.75
  79   4.7243      0.990  5.9764     1.036  682.57
  80   4.7229      0.950  5.9758     0.924  691.22
  81   4.7243      0.960  5.9760     0.970  699.95
  82   4.7242      0.970  5.9760     0.936  708.61
  83   4.7203      0.960  5.9747     1.008  717.18
  84   4.7233      0.960  5.9763     0.948  725.68
  85   4.7225      0.990  5.9758     1.048  734.18
  86   4.7260      0.960  5.9753     1.006  742.85
  87   4.7277      0.960  5.9748     0.876  751.41
  88   4.7228      0.970  5.9758     1.028  759.96
  89   4.7210      0.990  5.9757     0.990  768.41
  90   4.7264      0.990  5.9765     0.918  777.12
