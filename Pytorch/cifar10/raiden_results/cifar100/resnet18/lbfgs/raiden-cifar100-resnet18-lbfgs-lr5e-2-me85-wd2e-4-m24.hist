Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5739825664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6837      1.000  7.2117     0.948  10.21
   2   4.6841      1.000  7.2127     0.958  19.06
   3   4.6823      1.030  7.2124     1.000  27.99
   4   4.6841      1.020  7.2116     0.990  36.65
   5   4.6846      1.070  7.2117     0.966  45.26
   6   4.6853      1.010  7.2125     0.944  53.78
   7   4.6835      1.030  7.2122     0.986  62.35
   8   4.6835      0.980  7.2112     0.988  70.83
   9   4.6864      1.030  7.2105     0.952  79.35
  10   4.6852      1.020  7.2119     0.938  87.93
  11   4.6801      1.030  7.2130     0.938  96.60
  12   4.6836      1.050  7.2120     0.978  105.15
  13   4.6844      0.980  7.2124     0.968  113.70
  14   4.6830      1.050  7.2109     0.970  122.31
  15   4.6832      1.080  7.2123     0.998  130.92
  16   4.6827      1.060  7.2112     1.006  139.54
  17   4.6836      1.020  7.2122     1.000  148.35
  18   4.6840      1.070  7.2112     0.934  156.88
  19   4.6853      1.020  7.2121     0.990  165.61
  20   4.6851      1.020  7.2123     1.010  174.19
  21   4.6844      1.030  7.2106     1.036  182.80
  22   4.6837      1.060  7.2121     0.982  191.34
  23   4.6850      1.020  7.2115     1.008  200.04
  24   4.6837      1.030  7.2125     0.884  208.63
  25   4.6846      1.050  7.2125     0.972  217.23
  26   4.6848      1.020  7.2114     0.982  225.80
  27   4.6848      1.050  7.2126     0.962  234.49
  28   4.6836      0.990  7.2111     1.032  243.09
  29   4.6830      1.020  7.2105     1.012  251.66
  30   4.6826      1.050  7.2115     0.962  260.26
  31   4.6834      1.000  7.2112     0.926  268.83
  32   4.6846      1.020  7.2123     1.036  277.32
  33   4.6820      1.050  7.2117     1.018  285.85
  34   4.6855      1.050  7.2118     0.894  294.28
  35   4.6830      0.990  7.2116     0.934  302.91
  36   4.6842      1.050  7.2114     0.966  311.51
  37   4.6846      0.990  7.2117     1.004  320.09
  38   4.6830      1.030  7.2113     1.004  328.57
  39   4.6844      1.010  7.2132     0.982  337.17
  40   4.6833      1.110  7.2114     1.006  345.75
  41   4.6859      1.040  7.2115     0.922  354.19
  42   4.6824      1.000  7.2122     1.064  362.71
  43   4.6831      1.020  7.2114     0.946  371.46
  44   4.6840      1.040  7.2121     1.010  379.97
  45   4.6858      1.060  7.2116     0.948  388.39
  46   4.6831      1.040  7.2120     1.038  396.88
  47   4.6848      1.030  7.2106     0.996  405.56
  48   4.6851      1.040  7.2111     0.990  414.13
  49   4.6818      1.010  7.2104     0.930  422.65
  50   4.6837      1.010  7.2108     1.008  431.23
  51   4.6815      1.030  7.2123     0.916  440.03
  52   4.6839      1.060  7.2104     0.958  448.60
  53   4.6838      1.030  7.2113     0.998  457.21
  54   4.6842      0.970  7.2105     0.934  465.82
  55   4.6860      1.040  7.2115     0.984  474.51
  56   4.6852      1.050  7.2117     0.938  482.94
  57   4.6834      1.030  7.2114     1.006  491.48
  58   4.6841      1.070  7.2115     0.936  499.91
  59   4.6823      1.010  7.2115     1.060  508.53
  60   4.6842      1.020  7.2122     0.952  517.12
  61   4.6827      1.030  7.2106     0.974  525.60
  62   4.6849      1.060  7.2111     0.990  534.03
  63   4.6831      1.000  7.2114     0.926  542.57
  64   4.6849      1.050  7.2100     1.026  551.12
  65   4.6852      1.020  7.2106     1.010  559.72
  66   4.6823      1.030  7.2126     0.884  568.29
  67   4.6850      1.010  7.2113     0.980  576.89
  68   4.6857      1.040  7.2125     0.960  585.42
  69   4.6846      1.000  7.2110     1.026  594.02
  70   4.6854      1.020  7.2118     0.976  602.55
  71   4.6824      0.990  7.2113     0.986  611.12
  72   4.6834      1.040  7.2123     1.002  619.88
  73   4.6856      1.060  7.2113     0.970  628.47
  74   4.6843      1.030  7.2127     0.934  637.07
  75   4.6842      1.030  7.2121     0.954  645.58
  76   4.6844      1.050  7.2115     0.966  654.31
  77   4.6824      1.060  7.2103     0.954  662.92
  78   4.6863      1.010  7.2119     0.974  671.51
  79   4.6827      1.030  7.2116     0.934  680.17
  80   4.6854      1.050  7.2110     0.986  688.83
  81   4.6830      1.000  7.2105     0.990  697.35
  82   4.6843      0.990  7.2113     0.986  705.91
  83   4.6839      1.050  7.2114     1.004  714.51
  84   4.6847      1.050  7.2117     0.940  723.15
  85   4.6837      0.990  7.2117     0.926  731.64
