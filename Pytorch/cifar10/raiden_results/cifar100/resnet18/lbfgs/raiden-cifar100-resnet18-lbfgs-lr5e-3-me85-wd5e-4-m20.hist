Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7259      1.000  11.0093     1.024  8.96
   2   4.7241      1.020  11.0092     0.974  16.20
   3   4.7227      1.020  11.0098     0.992  23.17
   4   4.7263      0.950  11.0098     1.038  30.07
   5   4.7243      1.050  11.0102     1.004  37.24
   6   4.7256      0.960  11.0087     1.034  44.21
   7   4.7237      0.990  11.0106     0.966  51.15
   8   4.7238      0.990  11.0095     1.052  58.36
   9   4.7239      0.990  11.0093     0.954  65.31
  10   4.7242      0.970  11.0091     1.016  72.52
  11   4.7242      0.950  11.0105     0.988  79.49
  12   4.7255      1.020  11.0087     0.990  86.56
  13   4.7242      0.970  11.0085     1.044  93.60
  14   4.7251      0.980  11.0100     1.006  100.56
  15   4.7253      0.950  11.0099     0.930  107.75
  16   4.7262      0.990  11.0099     0.982  114.83
  17   4.7247      0.990  11.0100     1.048  121.80
  18   4.7258      0.990  11.0088     0.962  128.86
  19   4.7245      0.960  11.0105     0.990  136.01
  20   4.7237      0.990  11.0105     0.984  142.96
  21   4.7240      1.030  11.0099     1.052  149.95
  22   4.7224      0.990  11.0107     0.992  156.98
  23   4.7229      0.990  11.0089     1.002  163.94
  24   4.7252      0.960  11.0091     1.030  170.89
  25   4.7248      1.000  11.0093     1.080  178.05
  26   4.7253      0.970  11.0105     0.996  185.18
  27   4.7238      0.910  11.0095     1.014  192.26
  28   4.7238      1.020  11.0093     1.028  199.33
  29   4.7244      0.960  11.0095     0.910  206.39
  30   4.7255      0.990  11.0090     1.076  213.45
  31   4.7240      0.990  11.0094     0.974  220.55
  32   4.7254      0.980  11.0103     0.986  227.53
  33   4.7244      0.930  11.0119     1.092  234.64
  34   4.7248      1.010  11.0095     1.038  241.66
  35   4.7245      1.010  11.0101     1.060  248.71
  36   4.7247      0.970  11.0091     0.984  255.96
  37   4.7259      1.000  11.0093     0.986  262.84
  38   4.7251      1.030  11.0107     1.078  270.02
  39   4.7231      1.000  11.0076     0.988  276.97
  40   4.7251      1.040  11.0094     1.048  284.10
  41   4.7246      0.950  11.0095     0.978  291.11
  42   4.7242      1.020  11.0113     1.022  298.16
  43   4.7251      0.970  11.0092     0.960  305.10
  44   4.7246      0.980  11.0100     1.058  312.08
  45   4.7252      1.010  11.0094     1.100  319.07
  46   4.7239      1.000  11.0099     1.036  326.17
  47   4.7255      1.010  11.0107     1.006  333.12
  48   4.7233      0.970  11.0098     1.024  340.11
  49   4.7245      1.030  11.0114     0.968  347.26
  50   4.7243      0.980  11.0086     1.078  354.30
  51   4.7253      0.970  11.0100     1.030  361.42
  52   4.7260      0.980  11.0094     1.012  368.51
  53   4.7249      0.940  11.0099     1.004  375.49
  54   4.7259      0.990  11.0089     0.984  382.40
  55   4.7238      0.990  11.0094     1.014  389.41
  56   4.7240      0.980  11.0105     0.998  396.45
  57   4.7244      1.000  11.0095     1.052  403.43
  58   4.7233      1.020  11.0089     0.926  410.39
  59   4.7234      0.940  11.0089     1.002  417.45
  60   4.7238      1.010  11.0095     0.986  424.55
  61   4.7234      1.010  11.0094     1.004  431.54
  62   4.7256      0.980  11.0101     1.026  438.67
  63   4.7241      1.000  11.0094     0.990  445.66
  64   4.7250      0.970  11.0094     1.012  452.76
  65   4.7258      1.020  11.0110     1.008  459.81
  66   4.7230      0.970  11.0097     0.990  467.34
  67   4.7243      0.980  11.0103     0.996  474.32
  68   4.7244      0.970  11.0099     0.988  481.32
  69   4.7233      0.960  11.0085     1.044  488.22
  70   4.7257      0.980  11.0097     0.968  495.10
  71   4.7240      0.940  11.0098     0.964  502.34
  72   4.7236      0.970  11.0102     1.032  509.39
  73   4.7231      1.000  11.0102     0.998  516.44
  74   4.7241      1.030  11.0088     1.000  523.61
  75   4.7272      0.960  11.0095     0.970  530.53
  76   4.7243      1.010  11.0093     1.018  537.62
  77   4.7255      0.990  11.0091     0.948  544.63
  78   4.7243      0.970  11.0107     1.012  551.68
  79   4.7241      1.020  11.0091     1.022  558.66
  80   4.7251      0.980  11.0087     1.034  565.88
  81   4.7250      0.950  11.0110     1.050  572.99
  82   4.7233      0.990  11.0092     1.000  579.95
  83   4.7240      1.000  11.0105     1.054  587.34
  84   4.7255      0.960  11.0097     1.072  594.38
  85   4.7243      1.000  11.0101     0.936  601.47
