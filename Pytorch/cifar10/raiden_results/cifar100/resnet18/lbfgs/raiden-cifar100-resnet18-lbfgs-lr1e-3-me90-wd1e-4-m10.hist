Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7267      1.000  5.9975     0.964  8.87
   2   4.7280      0.960  5.9979     1.078  15.78
   3   4.7292      1.000  5.9979     1.024  22.61
   4   4.7297      0.980  5.9984     1.008  29.53
   5   4.7287      1.000  5.9981     1.064  36.31
   6   4.7296      0.970  5.9986     1.078  43.30
   7   4.7276      0.990  5.9979     1.100  50.15
   8   4.7251      0.990  5.9975     1.094  57.22
   9   4.7269      0.960  5.9998     1.020  64.03
  10   4.7317      0.990  5.9968     1.006  70.87
  11   4.7276      0.980  5.9976     1.048  77.76
  12   4.7268      0.950  5.9990     0.970  84.69
  13   4.7278      0.970  5.9972     1.072  91.47
  14   4.7269      1.000  5.9984     1.044  98.25
  15   4.7274      1.040  5.9987     1.096  105.38
  16   4.7300      0.990  5.9971     1.034  112.57
  17   4.7266      0.980  5.9976     1.058  119.55
  18   4.7287      0.940  5.9977     1.004  126.43
  19   4.7282      0.980  5.9971     1.064  133.20
  20   4.7288      0.970  5.9973     1.004  140.06
  21   4.7302      0.960  5.9991     1.056  146.80
  22   4.7299      0.970  5.9986     1.036  153.77
  23   4.7264      0.950  5.9969     1.046  160.58
  24   4.7275      0.970  5.9974     1.006  167.33
  25   4.7266      0.990  5.9976     1.044  174.16
  26   4.7301      1.000  5.9983     1.034  181.30
  27   4.7273      0.990  5.9984     0.994  188.29
  28   4.7290      0.990  5.9989     1.042  195.16
  29   4.7255      0.970  5.9973     1.022  202.01
  30   4.7315      1.000  5.9964     0.992  208.81
  31   4.7300      1.020  5.9983     1.036  215.84
  32   4.7271      0.990  5.9964     1.078  222.64
  33   4.7297      0.960  5.9975     1.052  229.50
  34   4.7265      0.950  5.9978     0.996  236.25
  35   4.7286      0.980  5.9973     1.086  243.36
  36   4.7291      1.000  5.9982     0.998  250.31
  37   4.7299      0.990  5.9974     1.026  257.15
  38   4.7263      0.990  5.9984     1.064  263.97
  39   4.7276      0.990  5.9982     1.072  270.83
  40   4.7251      0.980  5.9964     1.038  277.57
  41   4.7284      1.000  5.9966     1.066  284.51
  42   4.7267      0.980  5.9977     1.030  291.30
  43   4.7283      0.940  5.9976     1.038  298.15
  44   4.7268      0.970  5.9968     1.066  304.98
  45   4.7271      0.960  5.9978     0.990  311.86
  46   4.7274      0.990  5.9968     0.984  318.71
  47   4.7276      1.000  5.9977     0.974  325.67
  48   4.7269      0.970  5.9986     0.992  332.51
  49   4.7269      0.950  5.9975     0.958  339.26
  50   4.7278      0.990  5.9981     1.012  346.13
  51   4.7286      0.990  5.9978     0.982  353.18
  52   4.7276      0.990  5.9970     1.048  360.01
  53   4.7261      0.960  5.9973     1.086  366.76
  54   4.7283      0.980  5.9975     1.118  373.60
  55   4.7279      0.970  5.9989     1.050  380.56
  56   4.7294      0.970  5.9976     1.054  387.74
  57   4.7276      0.990  5.9984     1.044  394.51
  58   4.7269      0.950  5.9974     1.040  401.37
  59   4.7293      1.000  5.9984     1.000  408.22
  60   4.7288      0.980  5.9978     1.066  415.10
  61   4.7278      0.970  5.9989     1.074  421.92
  62   4.7305      0.980  5.9981     0.966  428.83
  63   4.7267      1.000  5.9979     1.078  435.61
  64   4.7273      0.960  5.9994     1.004  442.49
  65   4.7284      0.970  5.9986     1.030  449.27
  66   4.7277      0.960  5.9983     1.044  456.12
  67   4.7285      1.020  5.9975     1.048  463.32
  68   4.7289      0.970  5.9982     1.040  470.20
  69   4.7279      1.000  5.9986     1.040  476.93
  70   4.7295      0.980  5.9974     0.976  483.79
  71   4.7280      0.980  5.9985     1.076  490.69
  72   4.7276      0.980  5.9982     1.030  497.63
  73   4.7260      0.940  5.9979     1.086  504.44
  74   4.7271      0.960  5.9978     0.958  511.15
  75   4.7278      0.960  5.9985     0.994  518.01
  76   4.7281      0.980  5.9984     0.996  524.78
  77   4.7296      0.960  5.9986     1.030  531.69
  78   4.7281      0.990  5.9969     1.124  538.54
  79   4.7263      0.950  5.9978     1.002  545.37
  80   4.7280      1.010  5.9976     1.004  552.16
  81   4.7291      0.970  5.9962     1.114  559.02
  82   4.7273      0.960  5.9981     1.054  565.95
  83   4.7266      0.960  5.9979     1.002  572.82
  84   4.7290      0.980  5.9972     1.050  579.70
  85   4.7257      0.950  5.9987     1.050  586.44
  86   4.7269      1.000  5.9988     0.958  593.27
  87   4.7276      1.000  5.9978     0.996  600.32
  88   4.7290      0.980  5.9967     1.020  607.17
  89   4.7262      0.960  5.9995     1.090  614.02
  90   4.7265      0.970  5.9974     1.016  620.75
