Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7164      0.910  7.2185     1.068  8.72
   2   4.7140      0.950  7.2198     0.946  15.69
   3   4.7134      0.970  7.2193     1.028  22.66
   4   4.7151      0.960  7.2197     1.046  29.73
   5   4.7121      0.970  7.2199     0.968  36.77
   6   4.7121      0.990  7.2192     1.020  43.81
   7   4.7167      0.970  7.2192     1.038  50.69
   8   4.7144      0.950  7.2196     1.044  57.73
   9   4.7140      0.970  7.2204     1.012  64.86
  10   4.7167      0.950  7.2203     1.054  71.86
  11   4.7146      0.960  7.2191     1.040  78.72
  12   4.7129      0.970  7.2179     1.034  85.92
  13   4.7148      0.950  7.2195     1.000  92.93
  14   4.7163      0.970  7.2189     1.012  100.14
  15   4.7113      0.950  7.2189     0.956  107.05
  16   4.7151      0.960  7.2189     1.012  114.08
  17   4.7151      0.970  7.2186     0.994  120.98
  18   4.7154      0.980  7.2203     1.016  127.99
  19   4.7137      0.940  7.2202     1.018  135.11
  20   4.7132      0.980  7.2206     1.060  142.18
  21   4.7140      0.960  7.2192     1.008  149.37
  22   4.7160      1.000  7.2184     0.944  156.33
  23   4.7133      0.940  7.2198     1.060  163.35
  24   4.7118      0.950  7.2180     1.010  170.53
  25   4.7151      0.950  7.2191     1.082  177.57
  26   4.7160      0.970  7.2202     1.098  184.57
  27   4.7141      0.960  7.2181     0.964  191.55
  28   4.7153      0.960  7.2194     1.024  198.46
  29   4.7147      0.960  7.2189     1.006  205.44
  30   4.7139      0.940  7.2202     0.948  212.44
  31   4.7105      0.960  7.2206     0.972  219.37
  32   4.7162      1.000  7.2187     1.054  226.33
  33   4.7144      0.950  7.2190     1.106  233.27
  34   4.7153      0.950  7.2191     1.004  240.37
  35   4.7158      0.980  7.2193     1.058  247.53
  36   4.7129      0.920  7.2196     1.034  254.65
  37   4.7132      0.960  7.2192     1.048  261.54
  38   4.7141      0.960  7.2200     0.964  268.60
  39   4.7130      0.950  7.2202     1.000  275.65
  40   4.7149      0.960  7.2189     1.036  282.81
  41   4.7142      0.960  7.2201     1.020  290.05
  42   4.7147      0.960  7.2184     1.002  296.92
  43   4.7142      0.950  7.2190     1.018  303.92
  44   4.7151      0.960  7.2186     1.070  310.96
  45   4.7143      0.960  7.2204     1.006  318.15
  46   4.7131      0.950  7.2199     1.034  325.14
  47   4.7152      0.960  7.2193     0.960  332.16
  48   4.7141      0.970  7.2196     1.024  339.17
  49   4.7152      0.950  7.2183     1.014  346.34
  50   4.7137      0.940  7.2195     1.006  353.38
  51   4.7138      0.950  7.2192     1.044  360.34
  52   4.7134      0.940  7.2195     1.020  367.36
  53   4.7160      0.970  7.2197     1.094  374.43
  54   4.7141      0.970  7.2195     1.040  381.53
  55   4.7144      0.990  7.2203     0.974  388.56
  56   4.7151      0.970  7.2193     1.002  395.58
  57   4.7147      0.960  7.2183     1.074  402.71
  58   4.7130      0.940  7.2189     1.056  409.79
  59   4.7135      0.970  7.2195     0.948  416.76
  60   4.7142      0.950  7.2191     0.994  423.69
  61   4.7146      0.970  7.2196     0.978  430.74
  62   4.7137      0.980  7.2196     1.066  437.80
  63   4.7149      0.950  7.2183     1.032  444.90
  64   4.7120      0.940  7.2197     1.010  452.09
  65   4.7156      0.950  7.2195     0.974  459.12
  66   4.7138      0.990  7.2187     1.024  466.07
  67   4.7165      0.960  7.2197     1.056  473.03
  68   4.7140      0.940  7.2198     1.076  479.99
  69   4.7142      0.960  7.2191     1.028  487.01
  70   4.7127      0.950  7.2187     1.056  494.03
  71   4.7151      0.940  7.2189     1.044  501.00
  72   4.7131      0.980  7.2181     1.004  507.97
  73   4.7160      0.950  7.2193     1.022  515.09
  74   4.7135      0.960  7.2199     1.026  522.27
  75   4.7147      0.980  7.2201     1.010  529.34
  76   4.7164      0.990  7.2201     1.004  536.45
  77   4.7150      0.940  7.2192     1.040  543.56
  78   4.7154      0.970  7.2187     1.048  550.47
  79   4.7145      0.950  7.2186     0.994  557.65
  80   4.7143      0.990  7.2193     1.026  564.68
  81   4.7116      0.970  7.2182     1.004  571.66
  82   4.7141      0.960  7.2185     1.044  578.60
  83   4.7113      0.970  7.2198     0.972  585.60
  84   4.7139      0.980  7.2201     1.024  592.76
  85   4.7119      0.950  7.2194     1.048  599.94
