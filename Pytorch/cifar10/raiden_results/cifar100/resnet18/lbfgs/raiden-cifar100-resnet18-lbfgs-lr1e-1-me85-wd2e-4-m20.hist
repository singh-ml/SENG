Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5380584960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   5.7292      1.700  48.5691     1.446  9.83
   2   4.6173      1.450  8.4845     1.566  18.21
   3   4.6406      1.840  7.1136     1.774  26.99
   4   4.6506      1.880  7.1182     1.712  35.28
   5   4.6158      1.910  7.1191     1.692  43.55
   6   4.6297      1.880  7.1198     1.692  51.75
   7   4.6271      1.890  7.1145     1.704  59.97
   8   4.6249      1.870  7.1169     1.706  68.30
   9   4.6115      1.890  7.1190     1.696  76.53
  10   4.6338      1.890  7.1162     1.744  84.70
  11   4.6423      1.880  7.1167     1.708  92.90
  12   4.6273      1.830  7.1175     1.718  101.32
  13   4.6383      1.880  7.1178     1.646  109.60
  14   4.6270      1.880  7.1161     1.686  117.80
  15   4.6358      1.910  7.1164     1.696  126.04
  16   4.6251      1.830  7.1173     1.682  134.47
  17   4.6323      1.920  7.1193     1.696  142.68
  18   4.6150      1.860  7.1142     1.668  150.90
  19   4.6194      1.900  7.1109     1.742  159.20
  20   4.6382      1.950  7.1131     1.690  167.52
  21   4.6243      1.880  7.1172     1.738  175.80
  22   4.6144      1.860  7.1149     1.708  183.97
  23   4.6240      1.890  7.1130     1.728  192.21
  24   4.6406      1.840  7.1163     1.714  200.52
  25   4.6248      1.950  7.1158     1.720  208.71
  26   4.6249      1.830  7.1151     1.702  216.89
  27   4.6251      1.880  7.1164     1.746  225.13
  28   4.6172      1.890  7.1165     1.674  233.40
  29   4.6276      1.900  7.1182     1.706  241.58
  30   4.6246      1.880  7.1150     1.680  249.75
  31   4.6246      1.880  7.1178     1.688  258.03
  32   4.6327      1.880  7.1159     1.662  266.40
  33   4.6194      1.850  7.1150     1.676  274.53
  34   4.6269      1.870  7.1150     1.642  282.79
  35   4.6356      1.850  7.1190     1.782  290.96
  36   4.6166      1.830  7.1179     1.680  299.17
  37   4.6307      1.880  7.1154     1.700  307.58
  38   4.6232      1.840  7.1172     1.722  315.85
  39   4.6285      1.900  7.1153     1.666  324.09
  40   4.6254      1.860  7.1162     1.642  332.45
  41   4.6188      1.890  7.1171     1.636  340.76
  42   4.6121      1.900  7.1184     1.642  349.04
  43   4.6269      1.870  7.1171     1.594  357.24
  44   4.6308      1.880  7.1190     1.808  365.42
  45   4.6174      1.790  7.1179     1.706  373.75
  46   4.6158      1.870  7.1163     1.704  381.89
  47   4.6222      1.890  7.1150     1.750  390.02
  48   4.6353      1.860  7.1188     1.704  398.23
  49   4.6440      1.850  7.1150     1.736  406.60
  50   4.6415      1.820  7.1148     1.722  414.74
  51   4.6142      1.910  7.1159     1.646  423.00
  52   4.6412      1.840  7.1180     1.616  431.22
  53   4.6306      1.840  7.1165     1.692  439.52
  54   4.6176      1.870  7.1148     1.710  447.79
  55   4.6399      1.840  7.1163     1.726  456.08
  56   4.6461      1.820  7.1154     1.746  464.31
  57   4.6189      1.880  7.1191     1.684  472.59
  58   4.6352      1.880  7.1146     1.714  480.86
  59   4.6156      1.860  7.1136     1.762  489.08
  60   4.6351      1.860  7.1176     1.758  497.28
  61   4.6192      1.840  7.1145     1.680  505.59
  62   4.6328      1.900  7.1133     1.674  513.77
  63   4.6223      1.860  7.1160     1.736  522.21
  64   4.6622      1.820  7.1150     1.792  530.33
  65   4.6503      1.880  7.1168     1.768  538.44
  66   4.6224      1.880  7.1140     1.620  546.77
  67   4.6257      1.860  7.1159     1.670  554.99
  68   4.6145      1.860  7.1181     1.742  563.19
  69   4.6137      1.900  7.1159     1.716  571.32
  70   4.6320      1.830  7.1156     1.706  579.57
  71   4.6278      1.860  7.1174     1.662  587.91
  72   4.6328      1.920  7.1171     1.762  596.20
  73   4.6417      1.850  7.1147     1.710  604.43
  74   4.6289      1.860  7.1157     1.734  612.59
  75   4.6235      1.880  7.1146     1.700  620.93
  76   4.6236      1.900  7.1166     1.724  629.24
  77   4.6187      1.860  7.1154     1.780  637.50
  78   4.6389      1.900  7.1200     1.750  645.59
  79   4.6109      1.930  7.1119     1.728  653.94
  80   4.6190      1.890  7.1163     1.670  662.14
  81   4.6440      1.830  7.1191     1.694  670.51
  82   4.6163      1.880  7.1162     1.708  678.76
  83   4.6306      1.920  7.1201     1.738  687.07
  84   4.6273      1.810  7.1154     1.722  695.45
  85   4.6360      1.850  7.1156     1.708  703.60
