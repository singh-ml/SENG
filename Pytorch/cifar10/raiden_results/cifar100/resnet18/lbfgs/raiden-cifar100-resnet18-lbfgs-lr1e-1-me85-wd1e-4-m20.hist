Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5379536384 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   496.4235      1.000  47935.5177     0.942  9.97
   2   562855.1398      1.490  1958345607.6042     1.104  18.48
   3   5558391.5500      1.000  2660683885.9407     0.936  27.16
   4   2595431.7891      1.120  4139624.0351     1.130  35.70
   5   719149.5088      1.160  5513479.5874     0.994  44.16
   6   939713.7888      1.150  1405953.2404     1.146  52.80
   7   1384880.3306      1.070  1347468.2628     1.028  61.36
   8   1530624.3526      1.050  1327118.6406     0.972  70.08
   9   2597686.6249      1.070  1305599.2462     1.070  78.56
  10   795014.0125      1.040  1323787.2379     1.108  86.77
  11   2302692.2210      1.060  1304059.7516     1.058  95.02
  12   1939137.3371      1.070  1318280.1317     1.062  103.37
  13   1045034.1434      1.060  1305226.0271     1.020  111.66
  14   2065540.9889      1.050  1313793.1920     1.054  119.90
  15   1086218.0715      1.060  1308640.0105     1.004  128.05
  16   1823126.3523      1.060  1315742.6365     1.032  136.51
  17   1054065.8028      1.050  1311919.2930     1.048  144.74
  18   1211330.2525      1.060  1303814.4821     1.054  152.99
  19   1667693.0367      1.070  1295687.9117     1.092  161.20
  20   2807389.3408      1.080  1302268.5555     1.058  169.48
  21   941681.1106      1.040  1319471.7589     1.044  177.86
  22   679577.8543      1.040  1291229.3112     1.020  186.05
  23   2127456.6428      1.080  1306657.6464     1.024  194.38
  24   1096642.0772      1.060  1313332.7765     1.020  202.61
  25   3026074.8423      1.060  1298317.2152     1.094  210.89
  26   1695268.3014      1.080  1324103.0032     1.074  219.18
  27   3575719.5926      1.090  1315132.3211     1.072  227.50
  28   1323641.0971      1.060  1319581.2478     1.072  235.81
  29   2148151.3900      1.050  1289301.9056     1.074  243.98
  30   3432022.7938      1.070  1313528.5010     1.010  252.25
  31   2284914.1844      1.070  1307805.6212     1.032  260.35
  32   1768709.2987      1.080  1303445.1693     1.016  268.53
  33   1695959.9459      1.060  1306178.7567     1.048  276.81
  34   2376407.9703      1.070  1300344.5906     1.048  285.19
  35   645327.0132      1.040  1316824.0163     1.010  293.37
  36   1075165.0141      1.060  1305494.8740     1.082  301.63
  37   1930372.2444      1.050  1328919.5226     1.026  309.93
  38   1276687.4333      1.070  1321209.2943     1.090  318.28
  39   894034.5525      1.050  1322107.7870     1.052  326.45
  40   938437.9209      1.040  1328098.7334     1.050  334.63
  41   1448418.3338      1.060  1306187.5096     1.060  342.81
  42   1107883.2968      1.060  1316276.7031     1.032  351.24
  43   3065906.2936      1.080  1299670.9719     1.044  359.47
  44   931604.7806      1.030  1307877.7551     1.026  367.69
  45   1754006.0341      1.080  1312394.0651     1.070  375.95
  46   1321831.3017      1.070  1302709.5839     1.008  384.26
  47   1327154.7047      1.060  1303984.1588     1.046  392.56
  48   1681886.9380      1.080  1323149.9295     1.016  400.70
  49   1000186.6375      1.050  1324048.2136     1.054  408.97
  50   1898276.4289      1.040  1306868.2073     1.022  417.20
  51   1487913.7724      1.060  1308565.0861     1.080  425.48
  52   1207950.2905      1.070  1303570.3339     1.056  433.67
  53   1090609.1295      1.080  1313696.8964     1.054  441.89
  54   1529686.5938      1.080  1326661.7325     1.064  450.38
  55   1769819.4874      1.050  1327116.8122     1.042  458.71
  56   1766249.1254      1.070  1299759.4018     1.030  466.98
  57   3185343.6664      1.060  1313816.1633     1.052  475.44
  58   1205168.6076      1.060  1297386.3613     1.084  483.66
  59   2826514.0517      1.080  1317864.8852     1.048  491.90
  60   1963252.6128      1.070  1313608.1550     1.044  500.20
  61   1413345.8535      1.090  1308401.6483     1.044  508.54
  62   1367429.5297      1.060  1301715.1974     1.016  516.76
  63   635692.5279      1.030  1330712.8099     1.078  524.94
  64   1514757.1026      1.050  1298372.9043     1.024  533.32
  65   1381502.3320      1.070  1322513.5096     1.068  541.52
  66   753648.8993      1.040  1303510.6693     1.086  549.81
  67   1596342.2532      1.070  1321164.2184     1.090  558.08
  68   1656276.8308      1.060  1326281.9627     1.018  566.33
  69   1593001.7420      1.070  1331178.5303     1.076  574.71
  70   960610.3051      1.040  1319976.0877     1.054  583.04
  71   1673692.0984      1.050  1325483.9554     1.018  591.53
  72   788259.0246      1.030  1318953.5829     1.012  599.73
  73   1918464.3039      1.060  1304496.2519     1.040  608.03
  74   1748444.5744      1.070  1325113.3262     1.046  616.25
  75   1277258.3917      1.070  1302131.9021     1.042  624.44
  76   1814607.8749      1.050  1289941.0670     1.030  632.68
  77   1617336.0062      1.050  1297521.1652     1.058  640.89
  78   1980419.4741      1.070  1303429.7388     1.052  649.14
  79   1179941.4601      1.060  1333859.1722     1.056  657.42
  80   948944.8846      1.070  1314025.4538     1.068  665.67
  81   675567.4262      1.040  1320303.8693     1.038  673.84
  82   1174791.7814      1.060  1318672.4050     1.024  682.20
  83   1880646.9495      1.050  1308698.0934     1.042  690.45
  84   1929886.6693      1.050  1295823.8390     1.072  698.78
  85   1918468.5572      1.070  1314315.8243     1.060  707.01
