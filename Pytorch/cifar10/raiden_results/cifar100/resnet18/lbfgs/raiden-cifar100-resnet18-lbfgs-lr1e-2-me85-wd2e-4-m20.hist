Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7018      1.190  7.2299     1.090  9.58
   2   4.7027      1.230  7.2290     1.128  16.82
   3   4.7020      1.190  7.2298     1.128  23.87
   4   4.7029      1.230  7.2286     1.082  30.98
   5   4.7011      1.190  7.2277     1.114  38.32
   6   4.7042      1.250  7.2278     1.156  45.55
   7   4.7018      1.170  7.2288     1.132  52.68
   8   4.7002      1.200  7.2284     1.148  59.88
   9   4.7026      1.200  7.2302     1.126  67.11
  10   4.7030      1.220  7.2296     1.096  74.25
  11   4.7023      1.190  7.2287     1.066  81.26
  12   4.7010      1.190  7.2297     1.050  88.39
  13   4.7026      1.200  7.2282     1.086  95.62
  14   4.7021      1.180  7.2290     1.090  102.71
  15   4.7026      1.250  7.2277     1.118  109.81
  16   4.7035      1.220  7.2289     1.146  117.18
  17   4.7036      1.250  7.2276     1.022  124.38
  18   4.7018      1.220  7.2288     1.068  131.62
  19   4.7033      1.220  7.2294     1.088  138.72
  20   4.7000      1.210  7.2274     1.080  145.76
  21   4.7019      1.200  7.2286     1.136  152.91
  22   4.7024      1.220  7.2289     1.114  160.11
  23   4.7029      1.210  7.2283     1.072  167.42
  24   4.7036      1.210  7.2285     1.098  174.62
  25   4.7025      1.210  7.2277     1.110  181.81
  26   4.7022      1.200  7.2270     1.032  188.89
  27   4.7025      1.270  7.2284     1.050  196.03
  28   4.7022      1.200  7.2285     1.132  203.36
  29   4.7018      1.240  7.2276     1.044  210.55
  30   4.7031      1.210  7.2281     1.074  217.75
  31   4.7022      1.200  7.2290     1.144  224.97
  32   4.7036      1.220  7.2287     1.104  232.07
  33   4.7022      1.240  7.2280     1.104  239.33
  34   4.7021      1.220  7.2293     1.082  246.47
  35   4.7012      1.170  7.2296     1.062  253.57
  36   4.7041      1.190  7.2288     1.108  260.75
  37   4.7003      1.220  7.2275     1.104  268.07
  38   4.7035      1.250  7.2271     1.072  275.13
  39   4.7030      1.250  7.2283     1.098  282.40
  40   4.7022      1.270  7.2281     1.092  289.62
  41   4.7020      1.240  7.2280     1.102  296.99
  42   4.7012      1.270  7.2276     1.108  304.43
  43   4.7015      1.260  7.2280     1.068  311.62
  44   4.7026      1.230  7.2285     1.128  318.71
  45   4.7025      1.240  7.2284     1.088  325.82
  46   4.7041      1.210  7.2290     1.100  332.90
  47   4.7033      1.220  7.2284     1.080  340.16
  48   4.7007      1.230  7.2289     1.112  347.22
  49   4.7008      1.210  7.2286     1.114  354.26
  50   4.7024      1.190  7.2291     1.108  361.48
  51   4.7016      1.250  7.2289     1.070  368.68
  52   4.7013      1.230  7.2291     1.056  375.90
  53   4.7009      1.210  7.2285     1.120  383.06
  54   4.7018      1.180  7.2279     1.150  390.22
  55   4.7029      1.240  7.2287     1.118  397.40
  56   4.7025      1.230  7.2282     1.078  404.69
  57   4.7027      1.230  7.2277     1.044  411.72
  58   4.7018      1.200  7.2295     1.036  418.90
  59   4.7005      1.190  7.2275     1.120  425.93
  60   4.7006      1.210  7.2310     1.086  433.28
  61   4.7032      1.240  7.2281     1.150  440.56
  62   4.7013      1.220  7.2285     1.026  447.84
  63   4.7001      1.180  7.2280     1.114  455.09
  64   4.7023      1.230  7.2289     1.118  462.38
  65   4.7027      1.200  7.2292     1.128  469.64
  66   4.7034      1.210  7.2284     1.112  476.96
  67   4.7024      1.220  7.2292     1.104  484.02
  68   4.7036      1.250  7.2286     1.112  491.13
  69   4.7028      1.250  7.2282     1.072  498.28
  70   4.7018      1.190  7.2284     1.046  505.39
  71   4.7021      1.250  7.2289     1.098  512.57
  72   4.7030      1.240  7.2287     1.138  519.62
  73   4.7024      1.220  7.2286     1.102  526.69
  74   4.7022      1.180  7.2281     1.142  533.87
  75   4.7037      1.210  7.2270     1.128  541.22
  76   4.7010      1.190  7.2273     1.118  548.32
  77   4.7032      1.210  7.2288     1.072  555.55
  78   4.7026      1.220  7.2284     1.034  562.61
  79   4.7030      1.230  7.2293     1.084  569.72
  80   4.7038      1.210  7.2276     1.136  576.95
  81   4.7036      1.240  7.2290     1.102  584.12
  82   4.7028      1.200  7.2284     1.116  591.25
  83   4.7026      1.230  7.2281     1.110  598.43
  84   4.7048      1.240  7.2293     1.106  605.54
  85   4.7016      1.180  7.2283     1.086  612.79
