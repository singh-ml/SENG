Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5740458496 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6235      1.000  224.3698     1.114  10.53
   2   4.8289      1.220  11.1480     1.134  19.36
   3   4.8078      1.410  10.9955     1.238  28.10
   4   4.7805      1.220  10.9846     1.250  36.98
   5   4.6925      1.710  10.9187     1.618  45.76
   6   4.7984      1.340  10.9071     1.510  54.68
   7   4.6110      1.030  14.7643     1.312  63.42
   8   4.7640      1.480  10.7695     1.472  72.44
   9   4.9913      1.560  10.3165     1.860  81.21
  10   4.5864      2.120  9.5358     1.986  90.06
  11   4.5325      2.720  8.8207     1.646  98.94
  12   4.7703      2.230  61.0296     1.846  107.93
  13   4.3424      3.370  7.2687     2.312  116.71
  14   4.2534      3.760  5.7680     3.282  125.58
  15   5.0936      1.000  179.1393     3.862  134.37
  16   4.2674      4.810  30.7439     3.348  143.29
  17   4.1319      5.290  5.1316     5.176  152.11
  18   4.0365      7.310  5.4355     5.378  160.97
  19   3.9522      7.630  4.8332     6.772  169.88
  20   3.9069      8.770  4.6624     7.704  178.88
  21   3.8838      8.770  4.5352     8.490  187.75
  22   1003.6786      1.000  269.7358     5.438  196.51
  23   99.4070      1.000  146270.6370     1.028  205.20
  24   36.2913      0.860  118.7103     1.012  214.16
  25   14.6966      0.800  72.1765     0.960  222.97
  26   10.1790      0.940  63.2066     0.910  231.73
  27   14.0090      0.790  63.2050     0.902  240.35
  28   14.3631      0.790  63.0542     0.924  248.84
  29   12.5270      0.940  63.1949     0.904  257.49
  30   13.1429      0.860  63.1589     0.908  266.11
  31   10.8096      0.890  63.3156     0.864  274.63
  32   9.4400      0.940  63.1788     0.954  283.19
  33   13.7425      0.800  63.2367     0.914  291.83
  34   11.1135      0.910  63.1517     0.882  300.60
  35   9.8189      0.920  63.2651     0.900  309.19
  36   7.8073      0.920  63.1879     0.846  317.83
  37   11.5253      0.920  63.0846     0.894  326.42
  38   11.8591      0.910  63.3074     0.900  335.14
  39   8.9366      0.960  63.1046     0.890  343.74
  40   13.8062      0.820  63.0101     0.876  352.39
  41   11.9550      0.870  63.0633     0.934  361.12
  42   10.6471      0.950  63.3132     0.922  369.57
  43   8.0862      0.890  63.1290     0.892  378.02
  44   12.6827      0.900  63.1699     0.936  386.50
  45   11.5642      0.900  63.1370     0.944  395.09
  46   11.1084      0.920  63.1693     0.890  403.50
  47   11.8536      0.910  63.2305     0.900  411.96
  48   9.9927      0.890  63.2634     0.900  420.61
  49   12.8835      0.820  63.1889     0.952  429.23
  50   11.5283      0.930  63.1621     0.880  437.80
  51   12.5134      0.860  63.1542     0.902  446.37
  52   11.4911      0.850  63.2253     0.912  455.03
  53   16.0972      0.800  63.4161     0.902  463.43
  54   10.8656      0.930  63.0081     0.946  472.19
  55   9.2907      0.870  63.1360     0.904  480.73
  56   7.7339      0.920  63.1638     0.882  489.51
  57   10.6264      0.840  63.2670     0.816  498.01
  58   12.5729      0.850  63.1216     0.940  506.63
  59   9.4177      0.880  63.2523     0.896  515.32
  60   8.8373      0.920  63.0884     0.870  523.79
  61   10.5613      0.940  63.3658     0.908  532.20
  62   10.3266      0.950  63.1693     0.846  540.65
  63   10.6006      0.950  63.2944     0.938  549.33
  64   9.4650      0.940  63.1863     0.860  558.14
  65   10.9247      0.880  63.1217     0.834  566.72
  66   14.0990      0.750  63.0604     0.894  575.14
  67   10.4767      0.900  63.1711     0.934  583.94
  68   9.2405      0.930  63.1380     0.892  592.49
  69   10.7703      0.920  63.1406     0.898  601.04
  70   9.1612      0.880  63.2344     0.904  609.63
  71   9.4948      0.900  63.1666     0.920  618.27
  72   10.4531      0.900  63.1258     0.920  626.88
  73   10.5349      0.940  63.2677     0.952  635.52
  74   10.4964      0.900  63.1838     0.896  644.32
  75   13.9336      0.850  63.1198     0.898  653.10
  76   10.8542      0.900  63.1236     0.952  661.63
  77   9.9787      0.900  63.2216     0.950  670.25
  78   9.3263      0.900  63.2482     0.896  678.82
  79   10.8141      0.960  63.1873     0.822  687.49
  80   10.8265      0.880  63.0474     0.942  695.96
  81   11.3060      0.840  63.1448     0.924  704.47
  82   9.2580      0.950  63.2332     0.894  713.08
  83   9.4914      0.930  63.2052     0.834  721.67
  84   10.8847      0.920  63.0723     0.846  730.40
  85   8.7496      0.930  63.0026     0.894  739.04
  86   11.7062      0.880  63.1337     0.926  747.74
  87   9.8721      0.920  63.1771     0.860  756.35
  88   14.5033      0.810  63.1283     0.936  765.02
  89   10.7288      0.880  63.3863     0.916  773.71
  90   14.7061      0.820  63.2069     0.846  782.44
