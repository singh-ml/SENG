Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7182      0.900  10.9983     1.034  8.90
   2   4.7164      0.900  10.9991     1.010  16.13
   3   4.7168      0.890  11.0002     1.036  23.31
   4   4.7174      0.920  10.9986     1.024  30.36
   5   4.7180      0.930  10.9990     0.990  37.30
   6   4.7190      0.920  10.9993     0.954  44.23
   7   4.7171      0.900  10.9992     0.996  51.44
   8   4.7160      0.910  11.0006     0.996  58.45
   9   4.7167      0.890  10.9978     1.036  65.75
  10   4.7168      0.920  10.9989     1.014  72.80
  11   4.7165      0.890  10.9992     1.030  79.86
  12   4.7167      0.920  10.9989     1.026  86.97
  13   4.7149      0.940  10.9996     0.982  94.00
  14   4.7180      0.910  10.9984     1.048  100.95
  15   4.7170      0.910  11.0002     1.042  108.02
  16   4.7153      0.910  10.9995     1.048  115.02
  17   4.7167      0.920  10.9984     0.998  122.18
  18   4.7171      0.880  10.9987     1.058  129.22
  19   4.7167      0.920  10.9999     0.954  136.34
  20   4.7154      0.910  10.9986     1.060  143.32
  21   4.7167      0.960  10.9985     1.018  150.39
  22   4.7165      0.940  10.9995     1.010  157.55
  23   4.7192      0.900  10.9989     1.024  164.70
  24   4.7160      0.960  10.9988     1.000  171.80
  25   4.7161      0.920  10.9990     1.028  178.83
  26   4.7173      0.930  10.9992     1.036  185.81
  27   4.7176      0.960  10.9987     1.038  193.05
  28   4.7158      0.910  10.9997     0.976  200.09
  29   4.7161      0.940  10.9988     1.016  207.13
  30   4.7195      0.930  11.0000     1.008  214.21
  31   4.7163      0.930  10.9996     1.010  221.21
  32   4.7187      0.960  10.9990     0.994  228.40
  33   4.7162      0.920  10.9993     1.048  235.58
  34   4.7161      0.930  10.9991     0.994  242.70
  35   4.7154      0.910  11.0002     1.030  249.78
  36   4.7153      0.890  10.9989     1.044  256.87
  37   4.7166      0.910  10.9984     1.026  263.83
  38   4.7194      0.910  10.9988     1.020  270.90
  39   4.7169      0.930  10.9997     1.050  278.09
  40   4.7173      0.930  10.9987     1.008  285.20
  41   4.7169      0.910  10.9993     1.016  292.44
  42   4.7152      0.920  10.9983     0.974  299.50
  43   4.7156      0.920  10.9995     0.998  306.51
  44   4.7163      0.910  10.9989     1.012  313.61
  45   4.7168      0.920  10.9987     1.012  320.65
  46   4.7177      0.920  10.9995     0.986  327.82
  47   4.7154      0.890  10.9991     1.016  334.85
  48   4.7162      0.920  10.9986     0.982  341.88
  49   4.7166      0.890  10.9999     1.062  348.87
  50   4.7165      0.910  10.9986     1.008  355.93
  51   4.7157      0.910  10.9984     1.036  363.05
  52   4.7158      0.910  10.9993     1.014  370.17
  53   4.7176      0.930  10.9990     1.010  377.28
  54   4.7165      0.930  10.9987     1.062  384.39
  55   4.7168      0.900  10.9989     1.022  391.59
  56   4.7184      0.910  10.9980     0.980  398.63
  57   4.7183      0.900  10.9993     0.998  405.74
  58   4.7180      0.930  10.9992     1.002  412.68
  59   4.7165      0.890  10.9984     1.034  419.80
  60   4.7169      0.920  10.9995     1.052  426.85
  61   4.7179      0.900  10.9995     1.002  433.97
  62   4.7177      0.920  10.9986     1.014  441.01
  63   4.7188      0.890  10.9995     1.006  448.03
  64   4.7153      0.930  10.9990     1.014  455.05
  65   4.7159      0.900  10.9996     1.048  462.13
  66   4.7172      0.940  11.0005     0.984  469.32
  67   4.7167      0.930  10.9985     0.990  476.32
  68   4.7162      0.930  10.9991     1.076  483.38
  69   4.7177      0.930  10.9998     1.014  490.42
  70   4.7175      0.910  11.0000     0.986  497.38
  71   4.7176      0.910  10.9990     1.038  504.49
  72   4.7152      0.940  11.0000     0.994  511.59
  73   4.7178      0.910  10.9990     1.016  518.66
  74   4.7173      0.930  10.9999     1.022  525.69
  75   4.7172      0.930  10.9990     1.054  533.01
  76   4.7164      0.930  10.9994     1.004  540.24
  77   4.7170      0.890  10.9995     0.998  547.38
  78   4.7167      0.930  11.0002     1.030  554.49
  79   4.7167      0.910  10.9982     0.992  561.62
  80   4.7185      0.930  10.9995     1.012  568.66
  81   4.7167      0.920  10.9990     0.970  575.76
  82   4.7177      0.910  10.9992     1.006  582.77
  83   4.7199      0.920  10.9978     1.030  589.91
  84   4.7155      0.880  11.0006     1.032  597.11
  85   4.7183      0.900  10.9982     0.930  604.24
  86   4.7152      0.890  10.9987     1.012  611.38
  87   4.7157      0.940  10.9989     0.984  618.52
  88   4.7150      0.910  10.9977     0.994  625.55
  89   4.7157      0.940  10.9991     0.992  632.88
  90   4.7169      0.920  10.9998     0.996  640.06
