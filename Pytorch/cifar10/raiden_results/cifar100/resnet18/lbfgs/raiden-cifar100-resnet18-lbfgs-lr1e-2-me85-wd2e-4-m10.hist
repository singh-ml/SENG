Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7322      1.010  7.2616     1.020  8.96
   2   4.7308      1.020  7.2616     0.976  16.22
   3   4.7354      1.000  7.2600     0.958  23.43
   4   4.7321      1.020  7.2597     0.982  30.73
   5   4.7330      1.010  7.2603     0.942  37.87
   6   4.7330      1.030  7.2601     1.018  45.21
   7   4.7339      1.010  7.2613     0.992  52.33
   8   4.7321      1.010  7.2601     0.988  59.52
   9   4.7334      1.010  7.2591     1.020  66.73
  10   4.7320      1.020  7.2598     0.968  74.21
  11   4.7343      1.010  7.2594     0.986  81.64
  12   4.7364      1.020  7.2604     0.968  88.82
  13   4.7332      1.000  7.2592     1.020  96.14
  14   4.7317      1.010  7.2593     0.988  103.47
  15   4.7337      1.010  7.2604     0.990  110.60
  16   4.7326      1.010  7.2602     0.978  118.01
  17   4.7331      1.000  7.2600     0.974  125.23
  18   4.7337      1.020  7.2599     0.938  132.74
  19   4.7334      1.020  7.2605     0.964  139.91
  20   4.7322      1.010  7.2594     0.972  147.25
  21   4.7322      1.010  7.2607     1.012  154.57
  22   4.7335      1.020  7.2602     1.054  161.89
  23   4.7334      1.020  7.2609     0.988  169.26
  24   4.7330      1.030  7.2601     0.940  176.64
  25   4.7362      1.010  7.2600     1.024  183.94
  26   4.7316      1.010  7.2598     0.966  191.24
  27   4.7347      1.020  7.2605     0.998  198.55
  28   4.7326      1.030  7.2606     1.010  205.79
  29   4.7359      1.000  7.2616     0.980  213.04
  30   4.7326      1.030  7.2604     0.998  220.52
  31   4.7339      1.010  7.2598     0.976  227.77
  32   4.7339      1.000  7.2592     1.040  235.03
  33   4.7344      1.010  7.2599     0.950  242.31
  34   4.7326      1.010  7.2610     0.950  249.60
  35   4.7333      1.020  7.2600     0.990  256.97
  36   4.7342      1.010  7.2601     0.972  264.14
  37   4.7348      1.000  7.2593     1.012  271.48
  38   4.7342      1.010  7.2594     0.988  278.83
  39   4.7335      1.020  7.2606     0.984  286.15
  40   4.7328      1.010  7.2592     0.956  293.41
  41   4.7316      1.040  7.2606     0.970  300.74
  42   4.7319      1.000  7.2602     0.938  307.93
  43   4.7323      1.030  7.2603     0.972  315.13
  44   4.7350      1.000  7.2602     0.986  322.49
  45   4.7325      0.990  7.2598     1.024  329.77
  46   4.7337      1.020  7.2604     0.978  337.10
  47   4.7350      1.020  7.2607     0.984  344.29
  48   4.7342      1.030  7.2601     0.992  351.61
  49   4.7327      1.020  7.2598     0.984  358.88
  50   4.7340      1.010  7.2598     0.986  366.23
  51   4.7334      1.000  7.2609     0.986  373.42
  52   4.7356      0.990  7.2601     0.972  380.64
  53   4.7331      1.020  7.2602     0.964  387.82
  54   4.7321      1.000  7.2597     0.982  395.01
  55   4.7337      1.010  7.2597     0.996  402.40
  56   4.7345      1.020  7.2602     1.028  409.64
  57   4.7359      1.010  7.2603     1.008  416.89
  58   4.7334      1.000  7.2597     0.968  424.08
  59   4.7322      1.010  7.2598     0.990  431.39
  60   4.7334      1.030  7.2599     0.982  438.82
  61   4.7346      1.010  7.2600     0.970  446.05
  62   4.7333      1.010  7.2598     1.002  453.34
  63   4.7351      1.010  7.2591     1.000  460.70
  64   4.7317      1.030  7.2612     0.962  468.03
  65   4.7345      1.000  7.2592     0.988  475.38
  66   4.7311      1.010  7.2615     1.002  482.74
  67   4.7332      1.010  7.2601     0.946  490.15
  68   4.7318      1.030  7.2600     0.968  497.50
  69   4.7306      1.030  7.2608     1.004  504.93
  70   4.7335      1.020  7.2599     0.996  512.22
  71   4.7327      1.030  7.2610     0.980  519.60
  72   4.7328      1.020  7.2603     0.990  526.98
  73   4.7338      1.000  7.2603     0.964  534.35
  74   4.7317      1.030  7.2605     0.946  541.69
  75   4.7338      1.000  7.2601     0.988  549.22
  76   4.7333      1.010  7.2586     1.000  556.60
  77   4.7322      1.010  7.2598     0.956  563.77
  78   4.7345      1.010  7.2622     0.970  571.03
  79   4.7325      1.010  7.2603     0.980  578.49
  80   4.7326      1.020  7.2592     1.018  585.88
  81   4.7321      1.010  7.2597     1.014  593.14
  82   4.7335      1.020  7.2590     1.026  600.44
  83   4.7344      1.010  7.2603     1.002  607.88
  84   4.7309      1.000  7.2598     0.958  615.05
  85   4.7345      1.010  7.2602     0.940  622.33
