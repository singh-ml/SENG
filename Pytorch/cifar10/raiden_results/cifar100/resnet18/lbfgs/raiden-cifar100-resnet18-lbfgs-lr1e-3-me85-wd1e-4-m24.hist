Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6987      1.000  5.9665     1.034  8.72
   2   4.7002      0.940  5.9662     1.106  15.96
   3   4.6989      1.000  5.9666     1.004  23.03
   4   4.6989      0.890  5.9647     1.028  29.94
   5   4.6990      0.980  5.9646     1.118  36.92
   6   4.6992      0.950  5.9671     1.068  43.91
   7   4.7007      0.910  5.9662     1.100  50.98
   8   4.7000      0.940  5.9653     1.082  58.05
   9   4.6992      0.920  5.9663     1.048  65.14
  10   4.6984      0.930  5.9654     1.036  72.06
  11   4.6993      0.970  5.9668     1.088  79.01
  12   4.6982      0.950  5.9663     1.048  85.90
  13   4.6989      0.970  5.9656     1.092  93.00
  14   4.7010      0.920  5.9658     1.110  100.01
  15   4.6999      0.950  5.9646     1.082  107.06
  16   4.7003      0.980  5.9662     1.110  114.03
  17   4.6990      0.970  5.9659     1.036  120.90
  18   4.6997      0.940  5.9662     1.024  128.06
  19   4.6992      0.910  5.9669     1.002  134.96
  20   4.7000      0.940  5.9667     1.104  142.06
  21   4.7000      0.950  5.9677     0.994  149.01
  22   4.6997      1.010  5.9648     1.094  156.02
  23   4.6994      0.980  5.9664     1.052  163.11
  24   4.6993      0.950  5.9666     0.974  169.99
  25   4.6995      0.940  5.9660     1.032  176.94
  26   4.6995      0.980  5.9661     1.070  183.95
  27   4.6993      0.910  5.9669     1.108  191.02
  28   4.6983      0.940  5.9670     1.080  198.05
  29   4.6995      0.950  5.9658     1.040  205.01
  30   4.6990      0.940  5.9664     1.074  211.97
  31   4.6993      0.980  5.9651     1.002  218.90
  32   4.6996      0.960  5.9656     1.010  225.89
  33   4.6995      1.000  5.9662     1.012  233.11
  34   4.7007      0.970  5.9657     1.016  240.14
  35   4.6996      0.950  5.9661     0.990  247.18
  36   4.6991      0.940  5.9650     1.096  254.07
  37   4.6995      0.960  5.9666     1.036  261.13
  38   4.6993      0.940  5.9652     1.060  268.26
  39   4.6993      0.920  5.9670     1.074  275.29
  40   4.6986      0.950  5.9662     1.082  282.25
  41   4.7005      0.920  5.9651     1.068  289.31
  42   4.6999      0.930  5.9663     1.072  296.38
  43   4.6997      0.960  5.9659     1.044  303.48
  44   4.6993      0.960  5.9661     1.140  310.41
  45   4.6995      0.920  5.9654     1.054  317.40
  46   4.6997      0.950  5.9662     1.068  324.37
  47   4.6992      0.940  5.9658     1.084  331.37
  48   4.6988      0.890  5.9658     0.988  338.44
  49   4.6994      0.920  5.9658     1.110  345.38
  50   4.6995      0.930  5.9665     1.082  352.38
  51   4.6995      0.950  5.9659     1.024  359.45
  52   4.6985      0.960  5.9669     1.076  366.44
  53   4.6992      0.940  5.9652     1.046  373.59
  54   4.7001      0.940  5.9666     1.034  380.59
  55   4.6996      0.950  5.9666     0.988  387.64
  56   4.6984      0.970  5.9661     1.050  394.61
  57   4.6999      0.950  5.9663     1.018  401.71
  58   4.6994      0.960  5.9668     1.018  408.79
  59   4.6987      0.970  5.9666     0.982  415.77
  60   4.6992      0.940  5.9670     1.086  422.71
  61   4.6986      0.920  5.9668     1.014  429.75
  62   4.7003      0.940  5.9666     1.026  436.70
  63   4.7001      0.940  5.9666     1.054  443.85
  64   4.6988      0.980  5.9674     1.050  450.80
  65   4.6992      0.970  5.9657     1.038  457.87
  66   4.6997      0.960  5.9662     1.004  464.78
  67   4.6997      0.960  5.9667     1.092  472.01
  68   4.6995      0.930  5.9673     1.096  478.98
  69   4.6989      0.920  5.9662     1.112  485.96
  70   4.6988      0.980  5.9657     1.046  493.00
  71   4.6988      0.960  5.9663     0.998  499.93
  72   4.6985      0.970  5.9665     0.986  506.82
  73   4.6995      0.970  5.9656     1.022  513.99
  74   4.6994      0.940  5.9673     1.016  521.00
  75   4.6988      0.990  5.9660     1.076  528.02
  76   4.6994      0.970  5.9660     1.056  535.01
  77   4.7000      0.940  5.9675     1.070  542.03
  78   4.6997      0.920  5.9657     1.078  549.11
  79   4.7003      0.980  5.9665     1.004  556.14
  80   4.6990      0.920  5.9660     1.050  563.18
  81   4.6998      0.920  5.9679     1.054  570.08
  82   4.6992      0.970  5.9659     1.014  577.14
  83   4.6994      0.970  5.9665     1.028  584.22
  84   4.6987      0.990  5.9664     1.104  591.24
  85   4.6987      0.930  5.9653     1.066  598.32
