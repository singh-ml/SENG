Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5381000704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.5607      1.990  7.4865     1.416  10.06
   2   4.4614      3.210  7.0394     2.578  18.74
   3   4.5341      3.180  16.3871     3.212  27.29
   4   4.2756      6.190  6.8558     5.248  35.91
   5   4.2396      4.930  7.9460     5.418  44.53
   6   4.1361      7.030  6.6711     6.484  53.30
   7   4.0879      7.760  6.6195     7.050  61.93
   8   3.9972      9.370  7.3057     7.814  70.56
   9   4.2383      5.860  6.6461     9.066  79.31
  10   3.8690     11.050  6.6306     9.724  88.12
  11   3.8542     10.460  6.3640    10.964  96.82
  12   3.8418     10.980  6.3519    10.600  105.59
  13   3.8206     11.990  6.3267    11.674  114.34
  14   3.8216     11.930  6.3221    11.870  122.82
  15   3.8228     11.860  6.3234    11.824  131.35
  16   3.8232     11.890  6.3195    11.948  139.78
  17   3.8233     11.920  6.3213    11.924  148.17
  18   3.8190     11.940  6.3224    11.916  156.62
  19   3.8239     11.870  6.3204    12.006  165.12
  20   3.8194     11.880  6.3208    11.974  173.51
  21   3.8215     11.960  6.3209    11.904  181.89
  22   3.8243     11.920  6.3210    11.966  190.30
  23   3.8203     12.020  6.3228    11.836  198.80
  24   3.8200     11.980  6.3202    12.004  207.17
  25   3.8210     11.850  6.3197    11.942  215.56
  26   3.8220     11.950  6.3210    11.950  223.92
  27   3.8220     11.930  6.3201    11.926  232.50
  28   3.8197     12.000  6.3211    12.080  240.96
  29   3.8221     11.910  6.3217    12.050  249.38
  30   3.8207     11.960  6.3222    11.866  257.68
  31   3.8192     11.950  6.3217    11.916  266.18
  32   3.8288     11.790  6.3220    11.816  274.54
  33   3.8211     11.890  6.3221    11.792  282.99
  34   3.8205     11.950  6.3220    11.778  291.27
  35   3.8214     11.850  6.3206    11.814  299.71
  36   3.8197     11.960  6.3220    11.830  308.09
  37   3.8222     11.990  6.3213    11.948  316.57
  38   3.8200     12.040  6.3216    11.990  324.94
  39   3.8212     11.990  6.3229    11.888  333.45
  40   3.8192     11.910  6.3211    11.860  341.91
  41   3.8219     11.880  6.3211    12.098  350.23
  42   3.8226     11.940  6.3218    11.838  358.48
  43   3.8209     11.950  6.3199    11.920  366.73
  44   3.8207     11.850  6.3209    11.988  375.21
  45   3.8207     12.040  6.3212    11.848  383.58
  46   3.8230     11.860  6.3230    11.884  391.90
  47   3.8229     11.940  6.3223    11.930  400.27
  48   3.8215     11.890  6.3218    11.954  408.85
  49   3.8230     11.880  6.3212    11.882  417.27
  50   3.8239     11.960  6.3204    11.954  425.71
  51   3.8209     11.880  6.3211    11.962  434.05
  52   3.8218     11.900  6.3215    11.858  442.40
  53   3.8262     11.870  6.3213    11.970  450.88
  54   3.8216     11.880  6.3215    12.014  459.26
  55   3.8209     11.850  6.3228    11.896  467.61
  56   3.8219     11.950  6.3192    11.892  476.00
  57   3.8205     11.990  6.3212    11.872  484.46
  58   3.8197     11.910  6.3216    11.964  492.90
  59   3.8207     11.930  6.3220    11.972  501.37
  60   3.8229     11.980  6.3209    12.008  509.70
  61   3.8219     11.890  6.3222    11.832  518.18
  62   3.8191     11.890  6.3214    11.864  526.61
  63   3.8221     11.920  6.3217    11.978  535.05
  64   3.8200     11.780  6.3198    11.934  543.50
  65   3.8201     12.030  6.3230    11.840  551.89
  66   3.8217     11.990  6.3192    11.786  560.31
  67   3.8226     11.910  6.3229    11.912  568.58
  68   3.8197     12.080  6.3226    11.920  577.01
  69   3.8224     12.000  6.3211    12.058  585.46
  70   3.8225     11.850  6.3219    11.940  593.96
  71   3.8212     11.890  6.3218    11.768  602.34
  72   3.8206     11.930  6.3202    11.936  610.75
  73   3.8229     11.930  6.3212    11.874  619.13
  74   3.8235     12.020  6.3226    11.906  627.65
  75   3.8224     11.890  6.3225    11.892  636.01
  76   3.8207     11.870  6.3209    11.856  644.48
  77   3.8228     11.980  6.3227    11.984  652.92
  78   3.8220     11.850  6.3223    11.868  661.27
  79   3.8223     11.900  6.3201    11.830  669.72
  80   3.8216     11.950  6.3220    11.868  678.10
  81   3.8215     12.010  6.3202    11.904  686.76
  82   3.8242     11.870  6.3209    11.936  695.28
  83   3.8238     11.920  6.3190    11.936  703.69
  84   3.8208     11.870  6.3213    11.990  712.08
  85   3.8222     11.910  6.3220    11.920  720.44
  86   3.8216     11.960  6.3204    11.974  728.79
  87   3.8195     11.940  6.3228    11.914  737.31
  88   3.8210     11.880  6.3201    11.924  745.73
  89   3.8215     11.970  6.3211    11.910  754.03
  90   3.8215     11.810  6.3234    11.948  762.73
