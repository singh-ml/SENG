Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5738596864 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.5076      3.200  6.9778     1.810  10.36
   2   4.4682      3.860  5.7554     3.198  19.10
   3   4.3775      5.320  6.1417     3.572  27.91
   4   4.2974      5.950  5.5913     5.294  36.79
   5   4.2244      6.660  5.5292     6.044  45.73
   6   4.0744      8.620  5.3848     7.354  54.59
   7   4.0407      8.810  5.3151     8.506  63.40
   8   3.9826      9.910  5.2696     9.076  72.39
   9   3.9768     10.230  5.2357    10.064  81.13
  10   3.9544     10.340  5.2261    10.296  90.07
  11   3.9522     10.420  5.2090    10.182  98.94
  12   3.9430     10.790  5.2064    10.252  107.82
  13   3.9269     11.060  5.1937    10.638  116.79
  14   3.9217     10.900  5.1800    10.698  125.73
  15   3.8941     11.350  5.1675    10.856  134.58
  16   3.8976     11.220  5.1579    11.062  143.38
  17   3.8954     11.220  5.1580    11.180  152.12
  18   3.8951     11.300  5.1573    11.182  160.71
  19   3.8958     11.310  5.1583    10.920  169.37
  20   3.8948     11.220  5.1581    11.088  178.06
  21   3.8943     11.290  5.1566    11.078  186.80
  22   3.8952     11.260  5.1567    11.174  195.44
  23   3.8965     11.230  5.1585    11.014  204.03
  24   3.8950     11.270  5.1586    11.006  212.66
  25   3.8952     11.340  5.1564    11.048  221.50
  26   3.8961     11.220  5.1566    11.136  230.11
  27   3.8937     11.440  5.1597    10.938  238.72
  28   3.8992     11.260  5.1558    11.122  247.42
  29   3.8955     11.200  5.1578    11.034  256.15
  30   3.8941     11.380  5.1577    11.114  264.77
  31   3.8952     11.260  5.1577    11.144  273.50
  32   3.8945     11.450  5.1577    11.122  282.01
  33   3.8945     11.330  5.1575    11.042  291.00
  34   3.8961     11.460  5.1580    10.936  299.77
  35   3.8961     11.380  5.1560    11.116  308.44
  36   3.8945     11.300  5.1578    11.074  317.13
  37   3.8985     11.250  5.1581    11.018  325.65
  38   3.8957     11.260  5.1577    11.132  334.38
  39   3.8960     11.370  5.1545    11.076  342.97
  40   3.8952     11.470  5.1572    11.060  351.65
  41   3.8954     11.310  5.1593    10.984  360.19
  42   3.8944     11.300  5.1584    11.106  368.87
  43   3.8980     11.220  5.1556    11.064  377.43
  44   3.8945     11.270  5.1576    11.016  386.08
  45   3.8938     11.340  5.1583    11.132  394.84
  46   3.8939     11.380  5.1582    11.012  403.61
  47   3.8963     11.300  5.1590    11.090  412.16
  48   3.8957     11.190  5.1574    11.058  420.75
  49   3.8945     11.290  5.1550    11.124  429.33
  50   3.8971     11.290  5.1585    11.054  438.06
  51   3.8952     11.370  5.1572    11.118  446.54
  52   3.8942     11.300  5.1558    11.012  455.22
  53   3.8976     11.210  5.1579    11.170  463.75
  54   3.8945     11.270  5.1549    11.134  472.28
  55   3.8941     11.160  5.1576    10.942  480.91
  56   3.8984     11.250  5.1593    10.978  489.50
  57   3.8940     11.300  5.1560    10.992  498.12
  58   3.8970     11.290  5.1545    11.280  506.73
  59   3.8982     11.260  5.1562    11.234  515.42
  60   3.8957     11.230  5.1580    10.892  524.00
  61   3.8972     11.280  5.1559    11.058  532.66
  62   3.8955     11.160  5.1573    10.984  541.35
  63   3.9004     11.300  5.1565    11.122  550.13
  64   3.8969     11.310  5.1579    11.028  558.82
  65   3.8963     11.370  5.1555    11.048  567.44
  66   3.8963     11.260  5.1588    11.130  576.02
  67   3.8957     11.160  5.1588    11.096  584.74
  68   3.8939     11.280  5.1567    11.124  593.31
  69   3.8946     11.300  5.1575    11.088  601.88
  70   3.8983     11.140  5.1578    11.046  610.54
  71   3.8958     11.240  5.1559    11.214  619.30
  72   3.8935     11.350  5.1581    11.096  627.98
  73   3.8949     11.190  5.1570    11.174  636.54
  74   3.8962     11.090  5.1567    11.202  645.11
  75   3.8948     11.240  5.1581    11.062  653.79
  76   3.8943     11.320  5.1567    11.032  662.37
  77   3.8961     11.220  5.1572    11.002  671.14
  78   3.8939     11.270  5.1565    11.038  679.81
  79   3.8978     11.090  5.1587    11.222  688.51
  80   3.8954     11.280  5.1574    11.046  697.26
  81   3.8956     11.260  5.1574    11.144  705.75
  82   3.8960     11.170  5.1576    11.072  714.21
  83   3.8951     11.450  5.1571    11.032  723.01
  84   3.8941     11.340  5.1568    11.096  731.65
  85   3.8939     11.350  5.1580    11.016  740.41
