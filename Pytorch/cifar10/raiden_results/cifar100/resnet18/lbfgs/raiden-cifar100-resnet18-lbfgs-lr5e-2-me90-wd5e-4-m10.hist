Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4484014592 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6886      1.060  10.9518     0.934  9.28
   2   4.6903      1.060  10.9534     0.922  16.72
   3   4.6897      1.080  10.9526     0.966  24.18
   4   4.6888      1.080  10.9523     0.944  31.68
   5   4.6909      1.050  10.9533     0.950  39.15
   6   4.6907      1.060  10.9526     0.948  46.72
   7   4.6898      1.060  10.9535     0.962  54.23
   8   4.6887      1.090  10.9520     0.928  61.59
   9   4.6904      1.070  10.9524     0.866  69.22
  10   4.6889      1.080  10.9532     0.962  76.77
  11   4.6889      1.070  10.9521     0.890  84.35
  12   4.6897      1.050  10.9517     0.980  91.82
  13   4.6907      1.070  10.9516     0.902  99.34
  14   4.6887      1.060  10.9527     0.976  106.97
  15   4.6908      1.090  10.9528     0.936  114.51
  16   4.6882      1.090  10.9537     0.940  121.99
  17   4.6894      1.020  10.9521     0.948  129.43
  18   4.6913      1.040  10.9541     0.952  137.01
  19   4.6907      1.110  10.9533     1.046  144.47
  20   4.6899      1.090  10.9530     0.996  152.05
  21   4.6900      1.070  10.9523     0.962  159.59
  22   4.6892      1.040  10.9531     0.970  167.12
  23   4.6903      1.070  10.9528     0.950  174.75
  24   4.6906      1.060  10.9538     0.908  182.15
  25   4.6897      1.080  10.9529     0.924  189.62
  26   4.6887      1.070  10.9525     0.998  197.12
  27   4.6905      1.090  10.9522     0.952  204.59
  28   4.6896      1.090  10.9529     0.914  212.49
  29   4.6893      1.090  10.9525     0.912  220.03
  30   4.6906      1.070  10.9529     0.930  227.52
  31   4.6899      1.060  10.9523     0.916  235.09
  32   4.6884      1.090  10.9524     0.932  242.58
  33   4.6901      1.050  10.9524     0.950  250.27
  34   4.6899      1.030  10.9519     0.988  257.62
  35   4.6903      1.090  10.9528     0.980  265.10
  36   4.6895      1.090  10.9529     0.956  272.67
  37   4.6900      1.080  10.9521     0.930  280.30
  38   4.6902      1.090  10.9522     0.940  287.77
  39   4.6895      1.040  10.9538     0.910  295.16
  40   4.6902      1.060  10.9523     0.972  302.57
  41   4.6901      1.070  10.9522     0.892  310.03
  42   4.6885      1.090  10.9533     0.952  317.72
  43   4.6881      1.080  10.9524     1.016  325.31
  44   4.6894      1.050  10.9527     0.956  332.84
  45   4.6900      1.070  10.9522     0.982  340.42
  46   4.6922      1.040  10.9526     0.952  347.86
  47   4.6901      1.070  10.9516     0.956  355.38
  48   4.6887      1.060  10.9525     0.946  362.85
  49   4.6891      1.080  10.9526     0.952  370.34
  50   4.6898      1.080  10.9530     0.944  377.85
  51   4.6899      1.090  10.9512     0.956  385.51
  52   4.6896      1.070  10.9533     0.980  393.02
  53   4.6892      1.080  10.9524     0.916  400.58
  54   4.6900      1.060  10.9526     0.940  408.11
  55   4.6893      1.100  10.9527     0.958  415.64
  56   4.6888      1.070  10.9531     0.924  423.30
  57   4.6894      1.070  10.9530     0.966  430.87
  58   4.6902      1.070  10.9534     0.966  438.36
  59   4.6882      1.110  10.9523     0.938  445.90
  60   4.6891      1.070  10.9534     0.948  453.45
  61   4.6886      1.060  10.9534     0.936  461.00
  62   4.6883      1.050  10.9529     0.958  468.44
  63   4.6897      1.050  10.9527     0.974  476.01
  64   4.6904      1.100  10.9534     0.896  483.43
  65   4.6906      1.040  10.9531     0.966  490.99
  66   4.6884      1.050  10.9524     0.962  498.58
  67   4.6882      1.080  10.9524     0.958  506.02
  68   4.6895      1.070  10.9532     0.996  513.50
  69   4.6901      1.060  10.9531     0.974  520.95
  70   4.6889      1.060  10.9515     0.962  528.63
  71   4.6884      1.060  10.9529     0.978  536.16
  72   4.6893      1.090  10.9540     0.936  543.72
  73   4.6903      1.050  10.9524     0.938  551.16
  74   4.6884      1.090  10.9528     0.920  558.64
  75   4.6904      1.060  10.9522     0.950  566.23
  76   4.6899      1.090  10.9537     0.940  573.70
  77   4.6901      1.100  10.9533     0.960  581.26
  78   4.6873      1.090  10.9517     1.032  588.64
  79   4.6891      1.050  10.9523     1.000  596.07
  80   4.6887      1.080  10.9531     0.982  603.69
  81   4.6901      1.080  10.9520     0.898  611.12
  82   4.6902      1.110  10.9516     0.982  618.55
  83   4.6886      1.070  10.9535     0.926  626.01
  84   4.6891      1.070  10.9531     0.934  633.67
  85   4.6901      1.070  10.9525     0.902  641.12
  86   4.6888      1.080  10.9522     0.920  648.46
  87   4.6887      1.050  10.9525     1.014  655.80
  88   4.6897      1.080  10.9530     1.004  663.32
  89   4.6886      1.080  10.9521     0.918  670.77
  90   4.6885      1.110  10.9522     0.918  678.45
