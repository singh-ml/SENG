Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7021      0.880  7.2279     0.862  8.55
   2   4.7037      0.870  7.2274     0.886  15.43
   3   4.7034      0.890  7.2279     0.914  22.39
   4   4.7030      0.850  7.2274     0.892  29.34
   5   4.7037      0.880  7.2266     0.822  36.41
   6   4.7041      0.890  7.2270     0.866  43.42
   7   4.7028      0.900  7.2277     0.908  50.44
   8   4.7016      0.870  7.2272     0.892  57.54
   9   4.7028      0.890  7.2272     0.930  64.40
  10   4.7031      0.890  7.2276     0.868  71.33
  11   4.7023      0.880  7.2266     0.876  78.29
  12   4.7030      0.920  7.2271     0.854  85.27
  13   4.7029      0.870  7.2263     0.900  92.20
  14   4.7038      0.880  7.2273     0.884  99.23
  15   4.7032      0.940  7.2283     0.866  106.17
  16   4.7039      0.880  7.2271     0.908  113.16
  17   4.7035      0.860  7.2271     0.880  120.28
  18   4.7034      0.890  7.2273     0.848  127.26
  19   4.7029      0.910  7.2271     0.898  134.37
  20   4.7033      0.920  7.2280     0.880  141.31
  21   4.7042      0.900  7.2277     0.896  148.26
  22   4.7022      0.870  7.2270     0.894  155.13
  23   4.7011      0.860  7.2283     0.920  162.00
  24   4.7028      0.870  7.2273     0.878  169.18
  25   4.7034      0.930  7.2279     0.886  176.15
  26   4.7022      0.900  7.2280     0.896  183.19
  27   4.7027      0.880  7.2264     0.874  190.25
  28   4.7003      0.850  7.2281     0.862  197.38
  29   4.7046      0.900  7.2271     0.880  204.39
  30   4.7035      0.870  7.2269     0.936  211.36
  31   4.7010      0.860  7.2268     0.864  218.35
  32   4.7028      0.850  7.2280     0.884  225.20
  33   4.7019      0.910  7.2285     0.880  232.32
  34   4.7040      0.870  7.2270     0.896  239.23
  35   4.7023      0.880  7.2277     0.880  246.27
  36   4.7046      0.940  7.2270     0.816  253.73
  37   4.7025      0.890  7.2270     0.880  260.86
  38   4.7029      0.900  7.2277     0.898  267.94
  39   4.7029      0.890  7.2274     0.872  274.99
  40   4.7037      0.880  7.2269     0.902  281.99
  41   4.7038      0.900  7.2276     0.848  289.19
  42   4.7021      0.880  7.2284     0.830  296.20
  43   4.7032      0.880  7.2273     0.882  303.20
  44   4.7037      0.940  7.2274     0.898  310.17
  45   4.7033      0.890  7.2266     0.894  317.14
  46   4.7042      0.890  7.2273     0.896  324.12
  47   4.7045      0.890  7.2280     0.850  330.99
  48   4.7037      0.880  7.2270     0.878  338.14
  49   4.7011      0.920  7.2280     0.886  345.08
  50   4.7026      0.850  7.2273     0.898  352.00
  51   4.7044      0.880  7.2278     0.854  358.95
  52   4.7013      0.860  7.2276     0.870  365.96
  53   4.7022      0.850  7.2288     0.906  372.92
  54   4.7021      0.840  7.2284     0.900  379.83
  55   4.7027      0.890  7.2275     0.890  386.82
  56   4.7032      0.910  7.2273     0.914  393.81
  57   4.7018      0.880  7.2273     0.902  400.83
  58   4.7021      0.910  7.2275     0.918  407.69
  59   4.7035      0.900  7.2274     0.844  414.71
  60   4.7058      0.870  7.2274     0.866  421.79
  61   4.7027      0.900  7.2281     0.886  428.70
  62   4.7022      0.890  7.2281     0.926  435.61
  63   4.7019      0.900  7.2277     0.832  442.65
  64   4.7042      0.910  7.2280     0.864  449.83
  65   4.7026      0.890  7.2280     0.872  456.68
  66   4.7035      0.880  7.2265     0.870  463.67
  67   4.7016      0.880  7.2274     0.852  470.71
  68   4.7032      0.890  7.2271     0.904  477.78
  69   4.7010      0.870  7.2282     0.886  484.97
  70   4.7043      0.880  7.2276     0.882  491.82
  71   4.7038      0.840  7.2266     0.880  498.89
  72   4.7009      0.910  7.2268     0.924  505.91
  73   4.7025      0.930  7.2273     0.898  512.87
  74   4.7022      0.840  7.2273     0.868  520.05
  75   4.7030      0.900  7.2275     0.884  527.11
  76   4.7038      0.890  7.2279     0.868  534.10
  77   4.7037      0.860  7.2274     0.894  541.13
  78   4.7002      0.860  7.2287     0.888  548.28
  79   4.7031      0.900  7.2267     0.888  555.35
  80   4.7015      0.900  7.2270     0.888  562.38
  81   4.7040      0.880  7.2274     0.840  569.29
  82   4.7038      0.900  7.2274     0.882  576.23
  83   4.7017      0.900  7.2277     0.874  583.29
  84   4.7033      0.870  7.2273     0.810  590.15
  85   4.7020      0.870  7.2282     0.848  597.18
  86   4.7030      0.880  7.2281     0.924  604.14
  87   4.7020      0.910  7.2273     0.852  611.22
  88   4.7033      0.900  7.2257     0.840  618.36
  89   4.7044      0.880  7.2275     0.874  625.38
  90   4.7026      0.860  7.2267     0.896  632.35
