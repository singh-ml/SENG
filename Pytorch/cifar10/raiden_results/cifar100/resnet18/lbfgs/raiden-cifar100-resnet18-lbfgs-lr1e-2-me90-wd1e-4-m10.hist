Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6974      0.950  5.9667     0.892  8.71
   2   4.6989      0.950  5.9674     0.878  15.89
   3   4.6998      0.950  5.9667     0.884  23.07
   4   4.7010      0.910  5.9665     0.874  30.11
   5   4.6989      0.940  5.9666     0.872  37.26
   6   4.7009      0.930  5.9663     0.840  44.30
   7   4.6982      0.910  5.9660     0.818  51.40
   8   4.7013      0.930  5.9668     0.872  58.49
   9   4.6985      0.970  5.9665     0.802  65.82
  10   4.6977      0.940  5.9663     0.876  72.88
  11   4.7004      0.940  5.9661     0.902  79.91
  12   4.6987      0.940  5.9675     0.812  86.97
  13   4.7000      0.920  5.9659     0.828  94.17
  14   4.7004      0.940  5.9666     0.934  101.26
  15   4.6995      0.960  5.9660     0.834  108.32
  16   4.6992      0.960  5.9660     0.852  115.41
  17   4.6986      0.960  5.9670     0.810  122.75
  18   4.6984      0.930  5.9662     0.832  129.92
  19   4.6988      0.960  5.9661     0.948  136.99
  20   4.7006      0.940  5.9661     0.912  144.27
  21   4.7003      0.960  5.9681     0.896  151.27
  22   4.7012      0.920  5.9666     0.868  158.36
  23   4.6986      0.930  5.9671     0.828  165.63
  24   4.6991      0.930  5.9657     0.904  172.75
  25   4.6979      1.000  5.9660     0.870  179.75
  26   4.6996      0.910  5.9666     0.924  186.81
  27   4.7008      0.930  5.9663     0.836  194.09
  28   4.7002      0.900  5.9667     0.894  201.15
  29   4.7004      0.940  5.9664     0.856  208.13
  30   4.6989      0.920  5.9658     0.866  215.22
  31   4.6997      0.940  5.9668     0.860  222.19
  32   4.6988      0.970  5.9673     0.840  229.42
  33   4.6997      0.930  5.9661     0.850  236.47
  34   4.6986      0.970  5.9656     0.894  243.43
  35   4.6974      0.920  5.9668     0.854  250.66
  36   4.7015      0.930  5.9669     0.878  257.80
  37   4.6989      0.890  5.9662     0.880  264.92
  38   4.7009      0.940  5.9667     0.854  271.94
  39   4.6998      0.920  5.9661     0.916  278.95
  40   4.6999      0.930  5.9653     0.860  285.98
  41   4.7011      0.910  5.9663     0.896  292.99
  42   4.6986      0.970  5.9668     0.854  300.33
  43   4.6990      0.920  5.9663     0.862  307.40
  44   4.6997      0.930  5.9667     0.856  314.36
  45   4.7011      0.920  5.9666     0.828  321.47
  46   4.6988      0.950  5.9671     0.842  328.53
  47   4.6990      0.950  5.9666     0.862  335.59
  48   4.6996      0.930  5.9656     0.822  342.76
  49   4.7005      0.940  5.9672     0.816  349.93
  50   4.6987      0.960  5.9666     0.876  357.06
  51   4.7000      0.950  5.9663     0.898  364.04
  52   4.6997      0.910  5.9670     0.882  371.07
  53   4.7012      0.940  5.9655     0.864  378.24
  54   4.6991      0.960  5.9671     0.834  385.42
  55   4.7004      0.940  5.9655     0.826  392.52
  56   4.7000      0.920  5.9664     0.856  399.69
  57   4.6993      0.950  5.9662     0.874  406.67
  58   4.6997      0.950  5.9670     0.846  413.85
  59   4.7008      0.940  5.9660     0.824  420.84
  60   4.6984      0.980  5.9668     0.886  427.82
  61   4.7002      0.930  5.9668     0.866  434.92
  62   4.7008      0.960  5.9657     0.852  441.94
  63   4.7010      0.940  5.9659     0.796  448.99
  64   4.7005      0.930  5.9664     0.884  456.16
  65   4.6981      0.960  5.9664     0.824  463.17
  66   4.6991      0.960  5.9662     0.896  470.32
  67   4.6996      0.950  5.9672     0.854  477.35
  68   4.6990      0.930  5.9675     0.862  484.43
  69   4.7000      0.930  5.9672     0.826  491.54
  70   4.7023      0.930  5.9659     0.834  498.54
  71   4.7008      0.880  5.9670     0.858  505.65
  72   4.6995      0.940  5.9654     0.834  512.63
  73   4.7008      0.930  5.9665     0.876  519.84
  74   4.7001      0.930  5.9665     0.824  526.89
  75   4.6982      0.920  5.9654     0.848  533.94
  76   4.6983      0.910  5.9667     0.856  541.05
  77   4.6977      0.960  5.9655     0.866  548.11
  78   4.7003      0.940  5.9680     0.860  555.29
  79   4.6987      0.960  5.9671     0.834  562.55
  80   4.7005      0.940  5.9654     0.860  569.70
  81   4.6978      0.970  5.9655     0.818  576.74
  82   4.6985      0.930  5.9668     0.814  583.78
  83   4.6982      0.920  5.9668     0.910  590.94
  84   4.6984      0.940  5.9657     0.878  598.05
  85   4.7020      0.930  5.9665     0.830  605.10
  86   4.6995      0.940  5.9657     0.846  612.16
  87   4.6994      0.980  5.9660     0.800  619.15
  88   4.6990      0.950  5.9652     0.864  626.27
  89   4.6994      0.930  5.9664     0.902  633.27
  90   4.6987      0.950  5.9666     0.818  640.32
