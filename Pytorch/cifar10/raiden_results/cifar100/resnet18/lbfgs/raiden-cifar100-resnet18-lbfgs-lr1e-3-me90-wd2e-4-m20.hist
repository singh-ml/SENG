Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7020      0.880  7.2272     0.844  8.62
   2   4.7022      0.830  7.2269     0.856  15.47
   3   4.7020      0.860  7.2280     0.872  22.48
   4   4.7006      0.880  7.2286     0.810  29.35
   5   4.7017      0.880  7.2279     0.814  36.17
   6   4.7040      0.900  7.2273     0.852  43.17
   7   4.7033      0.870  7.2274     0.816  50.07
   8   4.7018      0.850  7.2264     0.806  56.93
   9   4.7020      0.870  7.2284     0.832  63.99
  10   4.7026      0.890  7.2280     0.792  70.89
  11   4.7028      0.790  7.2283     0.866  77.82
  12   4.7014      0.840  7.2274     0.830  84.71
  13   4.7032      0.860  7.2281     0.856  91.56
  14   4.7020      0.850  7.2274     0.842  98.42
  15   4.7018      0.860  7.2280     0.810  105.45
  16   4.7023      0.830  7.2270     0.880  112.39
  17   4.7025      0.860  7.2276     0.838  119.33
  18   4.7029      0.900  7.2292     0.768  126.08
  19   4.7033      0.890  7.2274     0.828  132.97
  20   4.7019      0.850  7.2275     0.838  139.86
  21   4.7045      0.850  7.2274     0.808  146.68
  22   4.7019      0.820  7.2290     0.806  153.63
  23   4.7011      0.860  7.2278     0.836  160.48
  24   4.7007      0.820  7.2287     0.812  167.44
  25   4.7025      0.850  7.2277     0.910  174.30
  26   4.7026      0.860  7.2273     0.812  181.24
  27   4.7029      0.860  7.2275     0.820  188.12
  28   4.7008      0.840  7.2285     0.786  194.93
  29   4.7020      0.910  7.2273     0.868  201.82
  30   4.7035      0.860  7.2267     0.796  208.71
  31   4.7016      0.840  7.2280     0.766  215.67
  32   4.7018      0.920  7.2274     0.804  222.50
  33   4.7019      0.850  7.2271     0.834  229.32
  34   4.7025      0.810  7.2272     0.846  236.31
  35   4.7005      0.800  7.2286     0.836  243.08
  36   4.7017      0.850  7.2275     0.786  249.96
  37   4.7025      0.910  7.2280     0.842  256.75
  38   4.7012      0.870  7.2280     0.826  263.71
  39   4.7035      0.910  7.2275     0.934  270.54
  40   4.7011      0.840  7.2280     0.822  277.48
  41   4.7014      0.810  7.2283     0.828  284.37
  42   4.7032      0.890  7.2288     0.796  291.14
  43   4.7014      0.860  7.2273     0.824  298.00
  44   4.7014      0.860  7.2276     0.810  304.86
  45   4.7025      0.890  7.2279     0.902  311.85
  46   4.7012      0.830  7.2276     0.826  318.80
  47   4.7018      0.800  7.2264     0.818  325.71
  48   4.7026      0.870  7.2271     0.888  332.55
  49   4.7026      0.850  7.2278     0.854  339.42
  50   4.7010      0.860  7.2273     0.820  346.46
  51   4.7000      0.840  7.2275     0.864  353.32
  52   4.7015      0.900  7.2284     0.794  360.18
  53   4.7014      0.860  7.2272     0.894  366.90
  54   4.7021      0.850  7.2271     0.816  373.75
  55   4.7017      0.860  7.2282     0.810  380.71
  56   4.7032      0.850  7.2272     0.852  387.59
  57   4.7016      0.830  7.2280     0.830  394.48
  58   4.7011      0.870  7.2280     0.866  401.46
  59   4.7009      0.870  7.2273     0.828  408.39
  60   4.7022      0.840  7.2280     0.874  415.23
  61   4.7021      0.860  7.2278     0.864  422.19
  62   4.7016      0.900  7.2274     0.778  429.02
  63   4.7037      0.880  7.2277     0.796  435.88
  64   4.7010      0.860  7.2265     0.848  442.67
  65   4.7016      0.860  7.2264     0.776  449.72
  66   4.7032      0.860  7.2265     0.816  456.51
  67   4.7024      0.850  7.2280     0.748  463.40
  68   4.7019      0.840  7.2267     0.830  470.36
  69   4.7011      0.850  7.2282     0.792  477.23
  70   4.7021      0.870  7.2288     0.836  484.11
  71   4.7024      0.880  7.2275     0.828  491.08
  72   4.7037      0.810  7.2268     0.816  498.03
  73   4.7021      0.870  7.2263     0.834  504.84
  74   4.7022      0.860  7.2280     0.802  511.70
  75   4.7029      0.890  7.2269     0.832  518.59
  76   4.7032      0.850  7.2271     0.798  525.56
  77   4.7022      0.830  7.2277     0.780  532.44
  78   4.7023      0.880  7.2276     0.816  539.37
  79   4.7031      0.840  7.2268     0.820  546.25
  80   4.7025      0.910  7.2269     0.824  553.01
  81   4.7003      0.860  7.2278     0.844  560.04
  82   4.7040      0.910  7.2277     0.746  566.99
  83   4.7036      0.900  7.2273     0.778  573.85
  84   4.7027      0.890  7.2274     0.800  580.77
  85   4.7006      0.840  7.2276     0.816  587.87
  86   4.7015      0.850  7.2282     0.790  594.94
  87   4.7041      0.870  7.2274     0.788  601.91
  88   4.7023      0.850  7.2283     0.860  608.87
  89   4.7015      0.840  7.2273     0.814  615.69
  90   4.7000      0.830  7.2275     0.812  622.56
