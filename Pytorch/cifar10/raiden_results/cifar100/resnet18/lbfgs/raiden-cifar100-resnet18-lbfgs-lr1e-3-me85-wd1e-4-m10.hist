Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7193      1.080  5.9923     0.970  8.44
   2   4.7218      1.060  5.9911     1.052  15.68
   3   4.7205      1.140  5.9919     1.002  22.77
   4   4.7208      1.130  5.9923     1.066  29.73
   5   4.7225      1.100  5.9922     0.986  36.60
   6   4.7224      1.100  5.9924     0.998  43.53
   7   4.7207      1.100  5.9936     0.916  50.56
   8   4.7209      1.090  5.9923     0.958  57.50
   9   4.7226      1.120  5.9926     0.928  64.31
  10   4.7236      1.070  5.9931     1.004  71.12
  11   4.7209      1.090  5.9933     1.016  77.97
  12   4.7201      1.100  5.9933     0.946  84.76
  13   4.7221      1.110  5.9933     0.980  91.76
  14   4.7233      1.130  5.9927     0.990  98.75
  15   4.7208      1.080  5.9920     0.988  105.66
  16   4.7211      1.130  5.9928     0.948  112.42
  17   4.7213      1.140  5.9926     0.936  119.27
  18   4.7202      1.060  5.9936     0.928  126.20
  19   4.7212      1.120  5.9920     0.898  132.94
  20   4.7240      1.090  5.9919     0.988  139.80
  21   4.7188      1.090  5.9929     1.026  146.72
  22   4.7219      1.090  5.9925     0.960  153.57
  23   4.7230      1.090  5.9920     0.952  160.43
  24   4.7219      1.100  5.9931     0.904  167.34
  25   4.7202      1.170  5.9926     1.000  174.26
  26   4.7232      1.090  5.9915     0.984  181.09
  27   4.7197      1.130  5.9920     1.028  188.00
  28   4.7218      1.090  5.9914     0.906  195.01
  29   4.7212      1.050  5.9917     1.006  201.89
  30   4.7227      1.090  5.9926     0.926  208.81
  31   4.7245      1.120  5.9928     1.004  216.30
  32   4.7209      1.090  5.9927     0.954  223.18
  33   4.7213      1.120  5.9920     0.956  230.15
  34   4.7211      1.110  5.9923     0.970  236.95
  35   4.7187      1.120  5.9930     1.040  243.81
  36   4.7208      1.130  5.9920     0.998  250.71
  37   4.7201      1.090  5.9925     0.932  257.48
  38   4.7216      1.090  5.9934     0.982  264.51
  39   4.7233      1.120  5.9932     0.950  271.41
  40   4.7201      1.090  5.9929     0.950  278.35
  41   4.7209      1.080  5.9931     1.004  285.19
  42   4.7223      1.110  5.9930     0.954  292.09
  43   4.7228      1.100  5.9926     0.978  299.07
  44   4.7213      1.100  5.9929     0.910  306.03
  45   4.7218      1.060  5.9929     0.974  312.92
  46   4.7219      1.090  5.9930     1.010  320.06
  47   4.7188      1.160  5.9921     1.014  326.86
  48   4.7210      1.110  5.9936     0.906  333.71
  49   4.7193      1.120  5.9924     0.962  340.61
  50   4.7213      1.090  5.9925     0.934  347.46
  51   4.7244      1.090  5.9928     0.994  354.36
  52   4.7243      1.100  5.9926     1.004  361.20
  53   4.7212      1.110  5.9916     1.000  368.00
  54   4.7192      1.080  5.9922     0.930  374.99
  55   4.7197      1.070  5.9925     0.948  381.86
  56   4.7176      1.130  5.9930     1.004  388.74
  57   4.7207      1.090  5.9923     1.060  395.58
  58   4.7214      1.080  5.9922     1.010  402.40
  59   4.7188      1.080  5.9938     0.938  409.45
  60   4.7196      1.100  5.9917     0.962  416.18
  61   4.7201      1.140  5.9923     0.934  423.00
  62   4.7224      1.060  5.9922     0.946  429.83
  63   4.7210      1.070  5.9921     1.020  436.56
  64   4.7196      1.120  5.9927     0.980  443.48
  65   4.7178      1.100  5.9926     0.932  450.27
  66   4.7230      1.110  5.9926     0.958  457.04
  67   4.7204      1.100  5.9934     0.948  463.98
  68   4.7223      1.060  5.9923     0.998  470.68
  69   4.7225      1.080  5.9926     0.956  477.56
  70   4.7214      1.070  5.9917     1.024  484.53
  71   4.7210      1.060  5.9927     1.054  491.32
  72   4.7180      1.090  5.9924     1.012  498.10
  73   4.7241      1.100  5.9927     0.960  504.95
  74   4.7215      1.080  5.9946     0.918  511.83
  75   4.7207      1.060  5.9932     0.968  518.86
  76   4.7253      1.050  5.9920     0.972  525.70
  77   4.7224      1.110  5.9917     1.020  532.59
  78   4.7207      1.100  5.9926     0.964  539.42
  79   4.7195      1.120  5.9930     0.954  546.33
  80   4.7202      1.160  5.9926     0.914  553.37
  81   4.7216      1.100  5.9927     0.936  560.33
  82   4.7220      1.120  5.9910     0.948  567.32
  83   4.7246      1.100  5.9936     0.980  574.15
  84   4.7239      1.140  5.9917     0.976  580.89
  85   4.7225      1.080  5.9922     1.064  587.79
