Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7093      0.920  7.2367     0.936  8.57
   2   4.7116      0.870  7.2350     0.964  15.88
   3   4.7084      0.930  7.2350     0.970  23.00
   4   4.7093      0.900  7.2365     1.030  30.21
   5   4.7122      0.840  7.2349     0.980  37.49
   6   4.7087      0.900  7.2365     0.928  44.60
   7   4.7079      0.900  7.2368     0.936  51.88
   8   4.7094      0.900  7.2366     0.934  59.12
   9   4.7083      0.970  7.2371     1.010  66.29
  10   4.7094      0.890  7.2360     0.966  73.29
  11   4.7060      0.840  7.2346     0.952  80.34
  12   4.7087      0.880  7.2369     0.988  87.58
  13   4.7082      0.930  7.2354     1.048  94.65
  14   4.7077      0.910  7.2366     0.988  101.77
  15   4.7068      0.910  7.2375     1.016  108.78
  16   4.7109      0.830  7.2364     0.972  115.95
  17   4.7097      0.830  7.2364     0.954  123.18
  18   4.7080      0.870  7.2353     0.976  130.37
  19   4.7117      0.840  7.2354     0.972  137.58
  20   4.7088      0.950  7.2357     1.026  145.01
  21   4.7133      0.840  7.2367     0.944  152.15
  22   4.7083      0.940  7.2356     1.044  159.46
  23   4.7094      0.870  7.2365     0.950  166.68
  24   4.7093      0.870  7.2343     0.926  173.78
  25   4.7092      0.900  7.2360     0.942  180.89
  26   4.7092      0.900  7.2357     0.976  187.92
  27   4.7107      0.850  7.2359     0.966  195.10
  28   4.7083      0.900  7.2366     1.010  202.54
  29   4.7080      0.880  7.2359     1.008  209.67
  30   4.7076      0.870  7.2364     0.990  216.76
  31   4.7087      0.900  7.2362     0.970  223.88
  32   4.7089      0.900  7.2367     0.942  231.03
  33   4.7089      0.870  7.2364     1.010  238.26
  34   4.7069      0.910  7.2359     0.956  245.40
  35   4.7103      0.830  7.2364     0.934  252.43
  36   4.7101      0.880  7.2366     0.960  259.67
  37   4.7096      0.930  7.2357     0.956  266.85
  38   4.7087      0.910  7.2358     0.946  274.05
  39   4.7106      0.870  7.2365     1.004  281.28
  40   4.7079      0.950  7.2374     1.000  288.43
  41   4.7075      0.930  7.2357     0.972  295.65
  42   4.7103      0.940  7.2374     1.008  302.97
  43   4.7077      0.930  7.2355     0.986  310.11
  44   4.7108      0.880  7.2354     0.982  317.33
  45   4.7081      0.930  7.2355     0.922  324.46
  46   4.7107      0.840  7.2376     0.896  331.57
  47   4.7090      0.890  7.2365     0.944  338.85
  48   4.7089      0.930  7.2375     1.016  345.97
  49   4.7094      0.860  7.2364     0.994  353.24
  50   4.7082      0.890  7.2348     0.990  360.49
  51   4.7073      0.880  7.2350     1.030  367.56
  52   4.7086      0.880  7.2350     0.986  374.87
  53   4.7088      0.950  7.2361     0.952  382.04
  54   4.7082      0.920  7.2377     0.980  389.15
  55   4.7098      0.850  7.2359     0.924  396.56
  56   4.7096      0.910  7.2351     1.080  403.76
  57   4.7088      0.850  7.2368     1.040  411.02
  58   4.7076      0.900  7.2350     0.996  418.25
  59   4.7086      0.890  7.2360     0.978  425.32
  60   4.7088      0.960  7.2364     0.940  432.34
  61   4.7083      0.870  7.2353     0.942  439.75
  62   4.7097      0.910  7.2369     0.994  447.08
  63   4.7092      0.890  7.2358     0.978  454.23
  64   4.7085      0.930  7.2367     0.976  461.36
  65   4.7124      0.830  7.2358     1.002  468.40
  66   4.7083      0.920  7.2360     0.980  475.54
  67   4.7105      0.860  7.2357     1.008  482.79
  68   4.7087      0.910  7.2344     0.958  489.93
  69   4.7103      0.930  7.2358     0.982  497.09
  70   4.7105      0.890  7.2365     0.986  504.28
  71   4.7087      0.880  7.2370     0.940  511.42
  72   4.7110      0.870  7.2370     0.934  518.75
  73   4.7112      0.840  7.2361     0.982  525.92
  74   4.7077      0.880  7.2348     1.012  532.97
  75   4.7088      0.930  7.2359     1.048  540.13
  76   4.7059      0.890  7.2358     0.984  547.37
  77   4.7106      0.850  7.2365     0.964  554.62
  78   4.7084      0.910  7.2361     0.956  561.82
  79   4.7105      0.920  7.2356     0.908  568.96
  80   4.7106      0.930  7.2358     1.060  576.12
  81   4.7101      0.870  7.2367     0.956  583.50
  82   4.7090      0.870  7.2357     1.030  590.72
  83   4.7084      0.870  7.2357     0.968  597.92
  84   4.7139      0.840  7.2377     0.952  605.03
  85   4.7093      0.880  7.2364     0.988  612.30
  86   4.7099      0.910  7.2355     0.928  619.44
  87   4.7081      0.900  7.2359     1.006  626.59
  88   4.7107      0.930  7.2361     1.002  633.70
  89   4.7114      0.870  7.2349     0.920  640.81
  90   4.7088      0.860  7.2367     0.960  647.97
