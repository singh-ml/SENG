Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239409664 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7141      0.980  7.2368     0.996  8.85
   2   4.7143      0.950  7.2369     0.980  16.12
   3   4.7143      0.960  7.2373     1.006  23.29
   4   4.7146      0.960  7.2360     1.040  30.41
   5   4.7131      0.970  7.2376     1.016  37.94
   6   4.7131      0.970  7.2376     0.998  45.26
   7   4.7145      0.970  7.2369     1.038  52.48
   8   4.7145      0.970  7.2368     1.000  59.80
   9   4.7149      0.990  7.2362     1.020  67.07
  10   4.7153      0.980  7.2373     0.994  74.28
  11   4.7147      0.980  7.2373     1.032  81.68
  12   4.7145      0.970  7.2370     1.006  88.96
  13   4.7152      0.970  7.2369     1.026  96.21
  14   4.7135      0.970  7.2368     1.036  103.42
  15   4.7140      0.970  7.2357     0.998  110.72
  16   4.7153      1.000  7.2364     1.016  118.05
  17   4.7141      0.980  7.2367     1.012  125.38
  18   4.7151      0.990  7.2357     1.016  132.94
  19   4.7149      0.980  7.2374     1.022  140.27
  20   4.7138      0.970  7.2379     1.022  147.74
  21   4.7137      0.970  7.2363     1.016  154.86
  22   4.7130      0.960  7.2379     1.018  162.07
  23   4.7133      0.970  7.2362     1.008  169.22
  24   4.7146      0.930  7.2365     1.014  176.42
  25   4.7128      0.940  7.2369     0.992  183.66
  26   4.7134      0.980  7.2369     1.030  191.15
  27   4.7147      0.970  7.2370     1.010  198.44
  28   4.7146      0.960  7.2368     1.018  205.65
  29   4.7137      0.960  7.2370     1.026  212.88
  30   4.7134      0.960  7.2361     1.026  220.10
  31   4.7146      0.960  7.2365     1.034  227.36
  32   4.7143      0.970  7.2373     1.016  234.65
  33   4.7133      0.980  7.2368     0.998  241.90
  34   4.7145      0.980  7.2366     1.008  249.17
  35   4.7154      0.970  7.2367     0.998  256.33
  36   4.7136      0.970  7.2370     1.010  263.45
  37   4.7146      0.940  7.2364     1.018  270.61
  38   4.7139      0.970  7.2361     1.016  277.89
  39   4.7131      0.960  7.2369     1.002  285.38
  40   4.7140      0.970  7.2354     1.014  292.65
  41   4.7142      0.980  7.2366     1.022  299.84
  42   4.7135      0.990  7.2353     1.010  306.92
  43   4.7142      0.980  7.2374     1.016  314.17
  44   4.7137      0.960  7.2365     0.998  321.34
  45   4.7142      0.940  7.2351     0.988  328.69
  46   4.7138      0.970  7.2359     1.014  335.93
  47   4.7147      0.970  7.2374     1.020  343.06
  48   4.7143      0.980  7.2373     1.004  350.28
  49   4.7130      0.960  7.2361     1.004  357.60
  50   4.7135      0.960  7.2370     1.010  364.85
  51   4.7144      0.970  7.2371     1.012  372.14
  52   4.7142      0.950  7.2368     1.026  379.48
  53   4.7137      0.960  7.2373     1.016  386.74
  54   4.7136      0.930  7.2379     1.018  394.05
  55   4.7121      0.950  7.2382     1.006  401.36
  56   4.7136      0.960  7.2370     1.016  408.76
  57   4.7147      1.000  7.2363     1.024  416.10
  58   4.7144      0.980  7.2367     1.008  423.25
  59   4.7130      0.960  7.2367     0.980  430.52
  60   4.7153      0.960  7.2359     0.996  437.79
  61   4.7136      0.990  7.2368     1.016  444.97
  62   4.7137      0.960  7.2371     0.998  452.27
  63   4.7138      0.970  7.2354     1.004  459.44
  64   4.7128      0.970  7.2371     1.008  466.93
  65   4.7141      0.940  7.2360     0.990  474.31
  66   4.7139      0.980  7.2385     1.022  481.54
  67   4.7149      0.970  7.2366     0.978  488.84
  68   4.7138      0.980  7.2363     1.006  496.16
  69   4.7145      0.980  7.2369     1.004  503.33
  70   4.7136      0.950  7.2373     1.008  510.71
  71   4.7153      0.980  7.2356     1.036  518.00
  72   4.7138      0.980  7.2366     1.000  525.22
  73   4.7139      0.960  7.2367     0.986  532.46
  74   4.7145      0.980  7.2376     1.018  539.80
  75   4.7132      0.970  7.2372     1.020  547.05
  76   4.7138      0.980  7.2367     1.008  554.19
  77   4.7151      0.960  7.2369     0.996  561.35
  78   4.7133      0.940  7.2366     0.998  568.68
  79   4.7135      0.960  7.2374     0.994  576.19
  80   4.7148      0.980  7.2354     1.016  583.40
  81   4.7145      0.980  7.2371     1.016  590.50
  82   4.7136      0.950  7.2359     1.006  597.75
  83   4.7151      0.970  7.2358     1.030  605.02
  84   4.7155      0.980  7.2358     0.984  612.57
  85   4.7136      0.980  7.2370     1.018  619.88
  86   4.7145      0.970  7.2369     1.032  627.22
  87   4.7146      0.960  7.2365     1.012  634.50
  88   4.7151      0.990  7.2358     1.008  641.64
  89   4.7147      0.970  7.2362     1.006  648.96
  90   4.7137      0.970  7.2377     1.000  656.20
