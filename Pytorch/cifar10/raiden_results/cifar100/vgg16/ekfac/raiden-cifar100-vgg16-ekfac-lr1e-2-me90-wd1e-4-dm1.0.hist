Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 14137708544 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.4156      2.080  4.5268     1.672  64.91
   2   4.1561      3.460  4.3148     2.666  127.80
   3   3.9851      5.940  4.0996     4.694  190.68
   4   3.9281      8.290  3.8985     7.424  253.57
   5   3.5821     13.680  3.7111    10.466  316.60
   6   3.3467     16.730  3.5197    13.404  379.57
   7   3.0999     22.420  3.3083    17.232  442.55
   8   3.0144     22.940  3.1510    20.426  505.53
   9   2.8600     27.010  2.9979    23.762  568.50
  10   2.8691     27.130  2.8856    26.520  631.53
  11   2.7155     31.310  2.7853    28.894  694.51
  12   2.6060     33.190  2.6982    30.950  757.53
  13   2.5420     35.960  2.6345    32.634  820.54
  14   2.5592     34.940  2.6209    33.242  883.48
  15   2.4502     37.040  2.6049    33.722  946.54
  16   2.5225     36.730  2.5717    34.552  1009.61
  17   2.5974     35.980  2.5769    34.692  1072.75
  18   2.5549     35.300  2.5875    34.938  1135.73
  19   2.6885     34.150  2.6092    34.880  1198.81
  20   2.6353     34.490  2.6601    33.888  1261.87
  21   2.6947     33.710  2.7205    32.620  1324.89
  22   2.6797     32.880  2.7934    30.674  1387.94
  23   2.8874     30.280  2.8507    29.968  1451.06
  24   2.9362     28.270  2.9676    27.564  1514.07
  25   3.0905     23.930  3.0927    24.738  1577.14
  26   3.2581     20.380  3.2367    21.964  1640.13
  27   3.3976     18.620  3.4138    18.340  1703.21
  28   3.5298     15.470  3.6102    14.306  1766.16
  29   3.9288      8.060  3.8390    10.356  1829.19
  30   3.7330      9.350  3.9674     7.028  1892.23
  31   3.8138      8.100  3.9696     6.812  1955.30
  32   3.9738      7.250  4.0375     6.202  2018.31
  33   3.9631      6.560  4.1167     5.270  2081.30
  34   4.0435      6.020  4.1093     5.306  2144.35
  35   4.0471      5.680  4.0852     5.532  2207.25
  36   4.0705      5.360  4.1500     4.948  2270.33
  37   4.1506      4.900  4.2601     4.008  2333.27
  38   4.3782      2.600  4.3752     3.364  2396.04
  39   238.3057      1.100  55.3111     1.610  2458.78
info: 81
, submat: 103
info: 43158
