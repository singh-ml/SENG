Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 14137708544 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.4319      2.240  4.5043     1.780  64.70
   2   4.1357      3.470  4.2799     2.778  127.13
   3   4.0198      4.860  4.0897     4.794  189.78
   4   3.7735      9.490  3.9235     6.954  252.33
   5   3.6450     11.260  3.7541     9.618  314.90
   6   3.3959     14.950  3.5846    12.428  377.47
   7   3.2832     18.090  3.3787    16.232  440.13
   8   2.9742     23.630  3.1709    20.202  502.82
   9   2.9085     26.620  3.0077    23.368  565.42
  10   2.7869     29.910  2.8740    26.674  628.04
  11   2.6106     32.750  2.7646    29.194  690.62
  12   2.6467     32.200  2.6730    31.448  753.28
  13   2.5510     33.750  2.6306    32.582  815.91
  14   2.5187     36.150  2.5926    33.800  878.46
  15   2.4619     37.910  2.5534    35.216  941.06
  16   2.5363     35.810  2.5317    35.778  1003.64
  17   2.4848     37.820  2.5206    36.336  1066.28
  18   2.4714     37.320  2.5066    36.626  1128.89
  19   2.4580     39.180  2.5064    37.036  1191.48
  20   2.4956     37.060  2.5201    36.900  1254.17
  21   2.5617     35.990  2.5620    36.060  1316.83
  22   2.6093     34.200  2.5978    35.524  1379.45
  23   2.5328     37.470  2.6466    34.118  1442.17
  24   2.6715     34.880  2.7035    33.292  1504.75
  25   2.7208     32.480  2.7535    32.176  1567.44
  26   2.7220     31.720  2.8130    31.016  1630.11
  27   2.8356     30.210  2.8932    28.814  1692.76
  28   3.0172     26.640  3.0194    26.340  1755.42
  29   3.1363     22.910  3.1990    22.872  1818.04
  30   3.3195     18.770  3.3610    19.210  1880.69
  31   3.4227     17.870  3.4679    16.950  1943.31
  32   3.4009     15.700  3.6099    13.606  2006.06
  33   3.5804     13.860  3.6747    12.560  2068.77
  34   3.6804     11.580  3.7816    10.794  2131.43
  35   3.7905      9.400  3.8934     8.460  2194.07
  36   3.8101      9.640  3.9694     7.516  2256.64
  37   3.7172      9.440  3.9358     7.252  2319.35
  38   3.8857      7.440  3.9797     6.484  2381.95
  39   4.2037      4.280  4.1105     5.988  2444.70
info: 126
, submat: 0
info: 4219
