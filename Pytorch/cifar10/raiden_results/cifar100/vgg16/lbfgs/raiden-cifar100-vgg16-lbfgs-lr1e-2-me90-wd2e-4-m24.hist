Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 8745790976 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6053      0.940  8.4907     1.022  11.06
   2   4.6053      0.940  8.4906     1.002  20.36
   3   4.6053      0.940  8.4907     0.976  29.48
   4   4.6053      0.940  8.4906     1.024  38.63
   5   4.6053      0.940  8.4908     0.958  47.78
   6   4.6053      0.940  8.4907     1.010  56.96
   7   4.6053      0.940  8.4906     1.016  66.11
   8   4.6053      0.940  8.4906     1.000  75.24
   9   4.6053      0.940  8.4904     1.004  84.45
  10   4.6053      0.940  8.4907     1.004  93.58
  11   4.6053      0.940  8.4908     1.030  102.71
  12   4.6053      0.940  8.4908     0.996  111.86
  13   4.6053      0.940  8.4905     0.986  121.04
  14   4.6053      0.940  8.4905     0.976  130.15
  15   4.6053      0.940  8.4907     1.008  139.28
  16   4.6053      0.940  8.4904     1.044  148.40
  17   4.6053      0.940  8.4907     0.910  157.59
  18   4.6053      0.940  8.4904     0.970  166.74
  19   4.6053      0.940  8.4906     0.980  175.90
  20   4.6053      0.940  8.4907     0.972  185.01
  21   4.6053      0.940  8.4906     1.016  194.22
  22   4.6053      0.940  8.4906     0.998  203.34
  23   4.6053      0.940  8.4904     1.028  212.46
  24   4.6053      0.940  8.4906     0.998  221.61
  25   4.6053      0.940  8.4906     0.950  230.82
  26   4.6053      0.940  8.4904     1.018  239.95
  27   4.6053      0.940  8.4906     0.962  249.09
  28   4.6053      0.940  8.4908     0.990  258.27
  29   4.6053      0.940  8.4907     1.040  267.41
  30   4.6053      0.940  8.4907     0.966  276.54
  31   4.6053      0.940  8.4908     1.010  285.67
  32   4.6053      0.940  8.4907     0.958  294.92
  33   4.6053      0.940  8.4907     0.970  304.04
  34   4.6053      0.940  8.4906     0.958  313.14
  35   4.6053      0.940  8.4908     0.944  322.27
  36   4.6053      0.940  8.4906     0.990  331.48
  37   4.6053      0.940  8.4906     0.974  340.61
  38   4.6053      0.940  8.4906     1.012  349.74
  39   4.6053      0.940  8.4911     0.998  358.99
  40   4.6053      0.940  8.4907     0.920  368.15
  41   4.6053      0.940  8.4904     1.062  377.27
  42   4.6053      0.940  8.4905     0.968  386.43
  43   4.6053      0.940  8.4906     0.956  395.63
  44   4.6053      0.940  8.4908     1.030  404.76
  45   4.6053      0.940  8.4906     0.990  413.93
  46   4.6053      0.940  8.4907     1.068  423.09
  47   4.6053      0.940  8.4907     0.994  432.27
  48   4.6053      0.940  8.4908     1.020  441.41
  49   4.6053      0.940  8.4909     1.044  450.53
  50   4.6053      0.940  8.4907     0.932  459.66
  51   4.6053      0.940  8.4904     1.050  468.90
  52   4.6053      0.940  8.4906     0.988  478.05
  53   4.6053      0.940  8.4908     0.954  487.16
  54   4.6053      0.940  8.4906     0.958  496.32
  55   4.6053      0.940  8.4905     1.014  505.49
  56   4.6053      0.940  8.4904     1.110  514.63
  57   4.6053      0.940  8.4906     0.910  523.78
  58   4.6053      0.940  8.4908     0.992  532.95
  59   4.6053      0.940  8.4906     0.920  542.08
  60   4.6053      0.940  8.4909     0.968  551.23
  61   4.6053      0.940  8.4905     0.962  560.34
  62   4.6053      0.940  8.4909     0.962  569.57
  63   4.6053      0.940  8.4906     0.974  578.71
  64   4.6053      0.940  8.4909     0.950  587.84
  65   4.6053      0.940  8.4906     1.062  597.02
  66   4.6053      0.940  8.4906     0.988  606.27
  67   4.6053      0.940  8.4906     0.984  615.44
  68   4.6053      0.940  8.4907     0.940  624.59
  69   4.6053      0.940  8.4907     1.004  633.79
  70   4.6053      0.940  8.4905     0.966  642.91
  71   4.6053      0.940  8.4908     0.980  652.04
  72   4.6053      0.940  8.4907     0.968  661.19
  73   4.6053      0.940  8.4910     0.992  670.42
  74   4.6053      0.940  8.4908     1.048  679.58
  75   4.6053      0.940  8.4906     0.988  688.69
  76   4.6053      0.940  8.4906     1.038  697.84
  77   4.6053      0.940  8.4909     0.876  707.03
  78   4.6053      0.940  8.4906     0.930  716.19
  79   4.6053      0.940  8.4908     1.038  725.32
  80   4.6053      0.940  8.4907     0.962  734.44
  81   4.6053      0.940  8.4905     0.988  743.66
  82   4.6053      0.940  8.4906     0.958  752.79
  83   4.6053      0.940  8.4907     0.966  761.95
  84   4.6053      0.940  8.4906     1.044  771.16
  85   4.6053      0.940  8.4907     0.942  780.31
  86   4.6053      0.940  8.4907     0.990  789.44
  87   4.6053      0.940  8.4905     1.046  798.59
  88   4.6053      0.940  8.4907     0.936  807.83
  89   4.6053      0.940  8.4907     1.006  816.98
  90   4.6053      0.940  8.4904     0.996  826.11
