Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7668664832 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6052      1.020  14.3215     1.054  10.46
   2   4.6052      1.020  14.3216     0.900  19.00
   3   4.6052      1.020  14.3213     0.998  27.57
   4   4.6052      1.020  14.3213     1.012  36.10
   5   4.6052      1.020  14.3216     0.950  44.59
   6   4.6052      1.020  14.3212     0.864  53.12
   7   4.6052      1.020  14.3211     1.016  61.67
   8   4.6052      1.020  14.3211     1.034  70.12
   9   4.6052      1.020  14.3209     0.974  78.59
  10   4.6052      1.020  14.3215     0.964  87.10
  11   4.6052      1.020  14.3214     0.994  95.68
  12   4.6052      1.020  14.3214     0.932  104.15
  13   4.6052      1.020  14.3210     0.934  112.66
  14   4.6052      1.020  14.3213     0.980  121.17
  15   4.6052      1.020  14.3214     0.974  129.78
  16   4.6052      1.020  14.3211     0.974  138.29
  17   4.6052      1.020  14.3210     0.978  146.82
  18   4.6052      1.020  14.3214     0.940  155.31
  19   4.6052      1.020  14.3215     0.946  163.88
  20   4.6052      1.020  14.3213     0.968  172.39
  21   4.6052      1.020  14.3212     1.050  180.92
  22   4.6052      1.020  14.3211     0.946  189.38
  23   4.6052      1.020  14.3213     0.952  197.92
  24   4.6052      1.020  14.3213     0.922  206.44
  25   4.6052      1.020  14.3212     1.000  214.95
  26   4.6052      1.020  14.3208     0.958  223.41
  27   4.6052      1.020  14.3209     1.012  231.98
  28   4.6052      1.020  14.3212     1.056  240.48
  29   4.6052      1.020  14.3210     1.032  248.99
  30   4.6052      1.020  14.3210     0.964  257.57
  31   4.6052      1.020  14.3212     0.932  266.12
  32   4.6052      1.020  14.3212     0.954  274.64
  33   4.6052      1.020  14.3213     1.016  283.11
  34   4.6052      1.020  14.3213     0.964  291.68
  35   4.6052      1.020  14.3213     0.914  300.16
  36   4.6052      1.020  14.3214     0.968  308.67
  37   4.6052      1.020  14.3211     1.034  317.15
  38   4.6052      1.020  14.3215     0.912  325.69
  39   4.6052      1.020  14.3214     0.998  334.27
  40   4.6052      1.020  14.3215     0.990  342.80
  41   4.6052      1.020  14.3215     0.994  351.27
  42   4.6052      1.020  14.3215     1.006  359.81
  43   4.6052      1.020  14.3213     0.952  368.41
  44   4.6052      1.020  14.3211     1.008  376.90
  45   4.6052      1.020  14.3214     0.970  385.41
  46   4.6052      1.020  14.3214     0.942  393.91
  47   4.6052      1.020  14.3213     0.948  402.46
  48   4.6052      1.020  14.3216     0.964  410.93
  49   4.6052      1.020  14.3210     0.932  419.45
  50   4.6052      1.020  14.3209     0.948  427.99
  51   4.6052      1.020  14.3210     0.990  436.58
  52   4.6052      1.020  14.3214     0.946  445.13
  53   4.6052      1.020  14.3210     0.986  453.64
  54   4.6052      1.020  14.3211     0.974  462.13
  55   4.6052      1.020  14.3212     0.958  470.71
  56   4.6052      1.020  14.3212     0.970  479.16
  57   4.6052      1.020  14.3214     0.918  487.69
  58   4.6052      1.020  14.3212     1.006  496.20
  59   4.6052      1.020  14.3212     1.036  504.84
  60   4.6052      1.020  14.3213     0.880  513.39
  61   4.6052      1.020  14.3210     0.956  521.90
  62   4.6052      1.020  14.3215     0.982  530.41
  63   4.6052      1.020  14.3211     1.064  538.91
  64   4.6052      1.020  14.3209     1.012  547.41
  65   4.6052      1.020  14.3214     1.048  555.91
  66   4.6052      1.020  14.3211     1.012  564.42
  67   4.6052      1.020  14.3211     0.954  573.02
  68   4.6052      1.020  14.3212     0.910  581.51
  69   4.6052      1.020  14.3212     1.028  590.02
  70   4.6052      1.020  14.3212     1.036  598.51
  71   4.6052      1.020  14.3212     0.978  607.04
  72   4.6052      1.020  14.3213     0.998  615.63
  73   4.6052      1.020  14.3212     1.036  624.09
  74   4.6052      1.020  14.3214     0.998  632.62
  75   4.6052      1.020  14.3211     0.996  641.14
  76   4.6052      1.020  14.3212     0.962  649.71
  77   4.6052      1.020  14.3212     1.014  658.20
  78   4.6052      1.020  14.3211     0.898  666.74
  79   4.6052      1.020  14.3211     1.010  675.20
  80   4.6052      1.020  14.3212     0.938  683.73
  81   4.6052      1.020  14.3212     0.962  692.27
  82   4.6052      1.020  14.3211     0.968  700.77
  83   4.6052      1.020  14.3213     0.908  709.31
  84   4.6052      1.020  14.3210     0.996  717.87
  85   4.6052      1.020  14.3208     0.950  726.36
  86   4.6052      1.020  14.3214     0.980  734.88
  87   4.6052      1.020  14.3212     0.974  743.39
  88   4.6052      1.020  14.3213     0.946  751.93
  89   4.6052      1.020  14.3213     1.022  760.42
  90   4.6052      1.020  14.3213     1.020  768.94
