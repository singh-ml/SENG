Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 16292401152 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6053      0.980  6.5481     0.946  16.36
   2   4.6053      0.980  6.5476     1.004  31.26
   3   4.6053      0.980  6.5479     0.898  46.06
   4   4.6053      0.980  6.5479     1.008  60.87
   5   4.6053      0.980  6.5481     0.988  75.71
   6   4.6053      0.980  6.5480     1.018  90.52
   7   4.6053      0.980  6.5475     1.098  105.40
   8   4.6053      0.980  6.5477     0.986  120.18
   9   4.6053      0.980  6.5477     0.928  135.03
  10   4.6053      0.980  6.5479     1.018  149.86
  11   4.6053      0.980  6.5479     1.050  164.66
  12   4.6053      0.980  6.5478     0.974  179.50
  13   4.6053      0.980  6.5478     0.992  194.31
  14   4.6053      0.980  6.5478     0.996  209.20
  15   4.6053      0.980  6.5478     0.958  224.01
  16   4.6053      0.980  6.5479     0.934  238.84
  17   4.6053      0.980  6.5479     1.020  253.73
  18   4.6053      0.980  6.5479     0.976  268.53
  19   4.6053      0.980  6.5478     0.998  283.43
  20   4.6053      0.980  6.5480     0.944  298.26
  21   4.6053      0.980  6.5476     1.058  313.08
  22   4.6053      0.980  6.5479     1.050  327.91
  23   4.6053      0.980  6.5478     0.994  342.70
  24   4.6053      0.980  6.5478     0.976  357.56
  25   4.6053      0.980  6.5478     0.960  372.34
  26   4.6053      0.980  6.5478     0.900  387.15
  27   4.6053      0.980  6.5478     0.938  401.97
  28   4.6053      0.980  6.5478     0.990  416.81
  29   4.6053      0.980  6.5477     1.058  431.74
  30   4.6053      0.980  6.5479     0.940  446.54
  31   4.6053      0.980  6.5478     0.902  461.42
  32   4.6053      0.980  6.5477     0.982  476.24
  33   4.6053      0.980  6.5479     0.996  491.06
  34   4.6053      0.980  6.5477     1.024  505.91
  35   4.6053      0.980  6.5480     1.006  520.73
  36   4.6053      0.980  6.5476     0.986  535.57
  37   4.6053      0.980  6.5479     0.988  550.39
  38   4.6053      0.980  6.5480     0.960  565.18
  39   4.6053      0.980  6.5479     1.060  580.07
  40   4.6053      0.980  6.5478     1.000  594.88
  41   4.6053      0.980  6.5477     1.024  609.76
  42   4.6053      0.980  6.5479     0.950  624.58
  43   4.6053      0.980  6.5479     0.976  639.48
  44   4.6053      0.980  6.5478     1.038  654.28
  45   4.6053      0.980  6.5481     1.000  669.09
  46   4.6053      0.980  6.5478     1.016  683.98
  47   4.6053      0.980  6.5480     0.998  698.81
  48   4.6053      0.980  6.5480     0.952  713.68
  49   4.6053      0.980  6.5478     1.020  728.47
  50   4.6053      0.980  6.5477     0.934  743.31
  51   4.6053      0.980  6.5479     0.964  758.19
  52   4.6053      0.980  6.5478     1.070  772.99
  53   4.6053      0.980  6.5481     0.952  787.83
  54   4.6053      0.980  6.5478     1.012  802.61
  55   4.6053      0.980  6.5478     0.998  817.41
  56   4.6053      0.980  6.5477     0.962  832.22
  57   4.6053      0.980  6.5479     0.930  847.02
  58   4.6053      0.980  6.5480     0.948  861.89
  59   4.6053      0.980  6.5477     0.964  876.67
  60   4.6053      0.980  6.5478     0.986  891.47
  61   4.6053      0.980  6.5479     1.016  906.34
  62   4.6053      0.980  6.5477     0.902  921.13
  63   4.6053      0.980  6.5481     0.992  936.00
  64   4.6053      0.980  6.5477     1.002  950.76
  65   4.6053      0.980  6.5480     0.998  965.62
  66   4.6053      0.980  6.5477     1.008  980.43
  67   4.6053      0.980  6.5479     1.026  995.22
  68   4.6053      0.980  6.5479     0.968  1010.07
  69   4.6053      0.980  6.5481     0.916  1024.87
  70   4.6053      0.980  6.5477     0.952  1039.73
  71   4.6053      0.980  6.5480     1.042  1054.51
  72   4.6053      0.980  6.5479     0.970  1069.31
  73   4.6053      0.980  6.5479     0.986  1084.18
  74   4.6053      0.980  6.5476     1.048  1099.00
  75   4.6053      0.980  6.5477     1.038  1113.86
  76   4.6053      0.980  6.5477     1.044  1128.67
  77   4.6053      0.980  6.5479     0.944  1143.52
  78   4.6053      0.980  6.5479     0.964  1158.32
  79   4.6053      0.980  6.5479     0.986  1173.12
  80   4.6053      0.980  6.5481     0.960  1187.98
  81   4.6053      0.980  6.5479     0.892  1202.77
  82   4.6053      0.980  6.5479     1.026  1217.63
  83   4.6053      0.980  6.5479     0.962  1232.41
  84   4.6053      0.980  6.5480     0.966  1247.24
  85   4.6053      0.980  6.5476     0.984  1262.12
  86   4.6053      0.980  6.5478     1.012  1276.93
  87   4.6053      0.980  6.5478     1.006  1291.79
  88   4.6053      0.980  6.5478     1.006  1306.59
  89   4.6053      0.980  6.5480     0.970  1321.46
  90   4.6053      0.980  6.5478     1.008  1336.25
