Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 16291352576 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6052      1.100  6.5492     1.000  16.25
   2   4.6052      1.100  6.5492     0.946  31.11
   3   4.6052      1.100  6.5489     0.962  46.77
   4   4.6052      1.100  6.5491     1.016  62.37
   5   4.6052      1.100  6.5492     0.990  78.07
   6   4.6052      1.100  6.5491     0.972  93.71
   7   4.6052      1.100  6.5491     1.054  109.38
   8   4.6052      1.100  6.5491     0.978  124.98
   9   4.6052      1.100  6.5496     0.944  140.63
  10   4.6052      1.100  6.5493     0.946  156.29
  11   4.6052      1.100  6.5490     1.004  171.93
  12   4.6052      1.100  6.5488     1.008  187.61
  13   4.6052      1.100  6.5492     0.962  203.24
  14   4.6052      1.100  6.5493     1.062  218.91
  15   4.6052      1.100  6.5495     0.966  234.51
  16   4.6052      1.100  6.5492     1.052  250.10
  17   4.6052      1.100  6.5492     1.030  265.75
  18   4.6052      1.100  6.5490     0.972  281.41
  19   4.6052      1.100  6.5491     0.994  297.07
  20   4.6052      1.100  6.5492     0.990  312.69
  21   4.6052      1.100  6.5493     1.058  328.35
  22   4.6052      1.100  6.5489     0.966  343.97
  23   4.6052      1.100  6.5489     0.940  359.55
  24   4.6052      1.100  6.5491     0.976  375.22
  25   4.6052      1.100  6.5492     1.000  390.86
  26   4.6052      1.100  6.5490     1.014  406.53
  27   4.6052      1.100  6.5488     1.024  422.13
  28   4.6052      1.100  6.5488     1.052  437.75
  29   4.6052      1.100  6.5492     1.046  453.41
  30   4.6052      1.100  6.5492     0.998  469.01
  31   4.6052      1.100  6.5491     1.084  484.68
  32   4.6052      1.100  6.5494     1.022  500.32
  33   4.6052      1.100  6.5490     1.036  515.99
  34   4.6052      1.100  6.5489     1.040  531.62
  35   4.6052      1.100  6.5488     1.024  547.28
  36   4.6052      1.100  6.5488     1.040  562.91
  37   4.6052      1.100  6.5489     1.026  578.55
  38   4.6052      1.100  6.5495     0.940  594.20
  39   4.6052      1.100  6.5492     0.922  609.81
  40   4.6052      1.100  6.5490     1.090  625.47
  41   4.6052      1.100  6.5491     1.000  641.09
  42   4.6052      1.100  6.5491     0.978  656.75
  43   4.6052      1.100  6.5492     0.990  672.37
  44   4.6052      1.100  6.5491     1.048  687.98
  45   4.6052      1.100  6.5486     1.034  703.67
  46   4.6052      1.100  6.5490     0.942  719.30
  47   4.6052      1.100  6.5492     0.948  734.95
  48   4.6052      1.100  6.5487     1.018  750.56
  49   4.6052      1.100  6.5490     1.016  766.27
  50   4.6052      1.100  6.5491     0.998  781.91
  51   4.6052      1.100  6.5493     1.004  797.52
  52   4.6052      1.100  6.5490     1.034  813.18
  53   4.6052      1.100  6.5492     1.036  828.82
  54   4.6052      1.100  6.5488     1.034  844.55
  55   4.6052      1.100  6.5492     0.984  860.16
  56   4.6052      1.100  6.5491     0.996  875.83
  57   4.6052      1.100  6.5492     0.978  891.45
  58   4.6052      1.100  6.5490     1.014  907.06
  59   4.6052      1.100  6.5491     1.016  922.74
  60   4.6052      1.100  6.5491     1.030  938.36
  61   4.6052      1.100  6.5490     1.008  954.05
  62   4.6052      1.100  6.5492     1.082  969.66
  63   4.6052      1.100  6.5493     0.984  985.35
  64   4.6052      1.100  6.5489     1.010  1000.93
  65   4.6052      1.100  6.5492     1.034  1016.58
  66   4.6052      1.100  6.5494     0.994  1032.25
  67   4.6052      1.100  6.5490     1.086  1047.86
  68   4.6052      1.100  6.5492     1.038  1063.49
  69   4.6052      1.100  6.5490     1.020  1079.13
  70   4.6052      1.100  6.5487     1.046  1094.84
  71   4.6052      1.100  6.5492     0.996  1110.46
  72   4.6052      1.100  6.5493     0.958  1126.06
  73   4.6052      1.100  6.5489     0.942  1141.72
  74   4.6052      1.100  6.5491     0.974  1157.33
  75   4.6052      1.100  6.5489     0.978  1172.97
  76   4.6052      1.100  6.5492     1.004  1188.60
  77   4.6052      1.100  6.5494     1.036  1204.27
  78   4.6052      1.100  6.5490     0.956  1219.91
  79   4.6052      1.100  6.5488     0.990  1235.54
  80   4.6052      1.100  6.5488     1.008  1251.22
  81   4.6052      1.100  6.5489     0.966  1266.85
  82   4.6052      1.100  6.5491     1.000  1282.51
  83   4.6052      1.100  6.5488     1.036  1298.11
  84   4.6052      1.100  6.5493     1.000  1313.79
  85   4.6052      1.100  6.5493     0.988  1329.41
