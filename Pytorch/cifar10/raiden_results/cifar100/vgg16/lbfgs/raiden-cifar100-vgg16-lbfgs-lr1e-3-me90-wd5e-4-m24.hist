Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7667853824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6055      0.930  14.3223     1.076  10.31
   2   4.6055      0.930  14.3227     1.010  18.96
   3   4.6055      0.930  14.3226     0.990  27.52
   4   4.6055      0.930  14.3228     1.064  36.10
   5   4.6055      0.930  14.3225     1.026  44.65
   6   4.6055      0.930  14.3227     0.958  53.23
   7   4.6055      0.930  14.3227     0.904  61.86
   8   4.6055      0.930  14.3224     1.018  70.41
   9   4.6055      0.930  14.3227     0.974  78.95
  10   4.6055      0.930  14.3222     1.020  87.52
  11   4.6055      0.930  14.3223     1.024  96.12
  12   4.6055      0.930  14.3227     1.002  104.69
  13   4.6055      0.930  14.3225     1.028  113.22
  14   4.6055      0.930  14.3225     0.960  121.72
  15   4.6055      0.930  14.3224     0.920  130.29
  16   4.6055      0.930  14.3226     0.990  138.80
  17   4.6055      0.930  14.3225     0.988  147.41
  18   4.6055      0.930  14.3224     0.990  155.97
  19   4.6055      0.930  14.3226     1.038  164.57
  20   4.6055      0.930  14.3229     0.994  173.19
  21   4.6055      0.930  14.3224     0.980  181.69
  22   4.6055      0.930  14.3228     0.994  190.21
  23   4.6055      0.930  14.3224     0.972  198.81
  24   4.6055      0.930  14.3223     0.992  207.38
  25   4.6055      0.930  14.3225     0.992  215.87
  26   4.6055      0.930  14.3227     0.942  224.44
  27   4.6055      0.930  14.3228     1.090  233.12
  28   4.6055      0.930  14.3225     0.958  241.66
  29   4.6055      0.930  14.3226     0.968  250.14
  30   4.6055      0.930  14.3227     1.024  258.65
  31   4.6055      0.930  14.3224     1.012  267.27
  32   4.6055      0.930  14.3223     1.000  275.79
  33   4.6055      0.930  14.3225     1.002  284.32
  34   4.6055      0.930  14.3228     0.930  292.91
  35   4.6055      0.930  14.3228     1.034  301.44
  36   4.6055      0.930  14.3226     1.022  309.95
  37   4.6055      0.930  14.3224     1.060  318.53
  38   4.6055      0.930  14.3228     1.006  327.13
  39   4.6055      0.930  14.3224     0.980  335.72
  40   4.6055      0.930  14.3227     0.944  344.25
  41   4.6055      0.930  14.3226     1.024  352.82
  42   4.6055      0.930  14.3224     1.000  361.34
  43   4.6055      0.930  14.3224     1.008  369.97
  44   4.6055      0.930  14.3226     0.958  378.46
  45   4.6055      0.930  14.3224     1.024  387.00
  46   4.6055      0.930  14.3226     0.790  395.56
  47   4.6055      0.930  14.3228     0.958  404.23
  48   4.6055      0.930  14.3225     0.916  412.86
  49   4.6055      0.930  14.3225     0.968  421.43
  50   4.6055      0.930  14.3224     0.988  429.98
  51   4.6055      0.930  14.3224     1.064  438.61
  52   4.6055      0.930  14.3222     0.964  447.09
  53   4.6055      0.930  14.3227     0.940  455.63
  54   4.6055      0.930  14.3227     0.976  464.19
  55   4.6055      0.930  14.3226     0.946  472.76
  56   4.6055      0.930  14.3227     0.974  481.33
  57   4.6055      0.930  14.3227     1.030  489.83
  58   4.6055      0.930  14.3226     0.950  498.34
  59   4.6055      0.930  14.3225     0.932  506.97
  60   4.6055      0.930  14.3228     0.926  515.48
  61   4.6055      0.930  14.3225     0.954  523.99
  62   4.6055      0.930  14.3226     1.018  532.52
  63   4.6055      0.930  14.3225     0.956  541.12
  64   4.6055      0.930  14.3227     1.010  549.64
  65   4.6055      0.930  14.3225     1.014  558.20
  66   4.6055      0.930  14.3227     0.932  566.77
  67   4.6055      0.930  14.3226     0.978  575.43
  68   4.6055      0.930  14.3224     0.882  584.00
  69   4.6055      0.930  14.3224     0.998  592.57
  70   4.6055      0.930  14.3224     1.016  601.13
  71   4.6055      0.930  14.3224     0.944  609.68
  72   4.6055      0.930  14.3226     1.036  618.23
  73   4.6055      0.930  14.3224     0.974  626.76
  74   4.6055      0.930  14.3223     1.032  635.32
  75   4.6055      0.930  14.3228     1.058  643.90
  76   4.6055      0.930  14.3226     0.994  652.50
  77   4.6055      0.930  14.3225     0.998  661.06
  78   4.6055      0.930  14.3227     1.018  669.62
  79   4.6055      0.930  14.3224     1.020  678.15
  80   4.6055      0.930  14.3226     1.050  686.80
  81   4.6055      0.930  14.3229     0.972  695.38
  82   4.6055      0.930  14.3226     0.930  703.93
  83   4.6055      0.930  14.3228     0.962  712.44
  84   4.6055      0.930  14.3225     1.054  721.11
  85   4.6055      0.930  14.3225     0.946  729.64
  86   4.6055      0.930  14.3224     1.042  738.15
  87   4.6055      0.930  14.3226     0.966  746.66
  88   4.6055      0.930  14.3226     1.050  755.21
  89   4.6055      0.930  14.3226     1.040  763.77
  90   4.6055      0.930  14.3226     1.016  772.25
