Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7667853824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6054      0.990  8.4906     1.044  10.34
   2   4.6054      0.990  8.4907     1.054  18.65
   3   4.6054      0.990  8.4909     1.012  26.97
   4   4.6054      0.990  8.4909     1.018  35.39
   5   4.6054      0.990  8.4906     1.034  43.70
   6   4.6054      0.990  8.4908     1.032  52.04
   7   4.6054      0.990  8.4909     0.986  60.36
   8   4.6054      0.990  8.4910     0.996  68.73
   9   4.6054      0.990  8.4907     1.016  77.04
  10   4.6054      0.990  8.4910     0.994  85.40
  11   4.6054      0.990  8.4907     1.094  93.73
  12   4.6054      0.990  8.4908     1.008  102.14
  13   4.6054      0.990  8.4908     1.004  110.46
  14   4.6054      0.990  8.4906     1.042  118.80
  15   4.6054      0.990  8.4907     0.994  127.14
  16   4.6054      0.990  8.4907     0.978  135.52
  17   4.6054      0.990  8.4908     0.998  143.82
  18   4.6054      0.990  8.4909     0.950  152.16
  19   4.6054      0.990  8.4907     1.032  160.45
  20   4.6054      0.990  8.4907     1.068  168.77
  21   4.6054      0.990  8.4909     0.896  177.18
  22   4.6054      0.990  8.4909     1.032  185.52
  23   4.6054      0.990  8.4908     1.014  193.86
  24   4.6054      0.990  8.4907     0.994  202.19
  25   4.6054      0.990  8.4906     1.084  210.60
  26   4.6054      0.990  8.4907     0.996  218.92
  27   4.6054      0.990  8.4907     1.062  227.22
  28   4.6054      0.990  8.4907     0.992  235.54
  29   4.6054      0.990  8.4908     1.016  243.91
  30   4.6054      0.990  8.4906     1.074  252.22
  31   4.6054      0.990  8.4909     0.978  260.52
  32   4.6054      0.990  8.4909     1.006  268.86
  33   4.6054      0.990  8.4909     1.052  277.23
  34   4.6054      0.990  8.4907     0.956  285.57
  35   4.6054      0.990  8.4908     0.962  293.89
  36   4.6054      0.990  8.4907     1.084  302.20
  37   4.6054      0.990  8.4908     1.020  310.59
  38   4.6054      0.990  8.4910     0.914  318.90
  39   4.6054      0.990  8.4908     0.988  327.23
  40   4.6054      0.990  8.4909     0.978  335.57
  41   4.6054      0.990  8.4908     1.054  343.98
  42   4.6054      0.990  8.4909     1.046  352.31
  43   4.6054      0.990  8.4908     1.006  360.64
  44   4.6054      0.990  8.4907     0.922  368.95
  45   4.6054      0.990  8.4907     0.986  377.27
  46   4.6054      0.990  8.4908     0.998  385.70
  47   4.6054      0.990  8.4909     0.922  394.01
  48   4.6054      0.990  8.4909     1.028  402.32
  49   4.6054      0.990  8.4907     0.958  410.62
  50   4.6054      0.990  8.4907     0.972  419.06
  51   4.6054      0.990  8.4906     0.960  427.38
  52   4.6054      0.990  8.4910     1.050  435.68
  53   4.6054      0.990  8.4907     0.988  444.02
  54   4.6054      0.990  8.4910     0.972  452.38
  55   4.6054      0.990  8.4908     1.014  460.70
  56   4.6054      0.990  8.4909     1.070  469.04
  57   4.6054      0.990  8.4909     1.020  477.34
  58   4.6054      0.990  8.4909     1.052  485.71
  59   4.6054      0.990  8.4906     1.090  494.02
  60   4.6054      0.990  8.4908     1.006  502.33
  61   4.6054      0.990  8.4907     0.998  510.66
  62   4.6054      0.990  8.4909     1.010  519.04
  63   4.6054      0.990  8.4906     0.988  527.35
  64   4.6054      0.990  8.4909     0.992  535.69
  65   4.6054      0.990  8.4907     1.020  543.98
  66   4.6054      0.990  8.4905     1.002  552.36
  67   4.6054      0.990  8.4909     1.000  560.68
  68   4.6054      0.990  8.4908     0.980  569.01
  69   4.6054      0.990  8.4907     0.978  577.31
  70   4.6054      0.990  8.4905     0.978  585.70
  71   4.6054      0.990  8.4906     0.944  594.04
  72   4.6054      0.990  8.4906     1.002  602.36
  73   4.6054      0.990  8.4908     1.052  610.72
  74   4.6054      0.990  8.4906     0.912  619.12
  75   4.6054      0.990  8.4908     1.066  627.42
  76   4.6054      0.990  8.4907     1.000  635.76
  77   4.6054      0.990  8.4907     1.002  644.09
  78   4.6054      0.990  8.4910     0.992  652.38
  79   4.6054      0.990  8.4909     1.012  660.75
  80   4.6054      0.990  8.4907     1.014  669.07
  81   4.6054      0.990  8.4908     0.996  677.39
  82   4.6054      0.990  8.4907     0.940  685.69
  83   4.6054      0.990  8.4909     0.984  694.08
  84   4.6054      0.990  8.4911     0.936  702.38
  85   4.6054      0.990  8.4908     1.012  710.71
