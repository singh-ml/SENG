Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 11980414976 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6054      0.970  8.4908     0.878  13.24
   2   4.6054      0.970  8.4908     0.980  24.85
   3   4.6054      0.970  8.4906     0.972  36.44
   4   4.6054      0.970  8.4908     1.042  47.98
   5   4.6054      0.970  8.4907     1.014  59.51
   6   4.6054      0.970  8.4907     0.978  71.12
   7   4.6054      0.970  8.4908     0.948  82.64
   8   4.6054      0.970  8.4906     0.974  94.18
   9   4.6054      0.970  8.4908     0.976  105.76
  10   4.6054      0.970  8.4907     1.110  117.27
  11   4.6054      0.970  8.4909     1.044  128.85
  12   4.6054      0.970  8.4908     0.952  140.39
  13   4.6054      0.970  8.4908     0.974  151.99
  14   4.6054      0.970  8.4909     0.910  163.52
  15   4.6054      0.970  8.4909     0.936  175.08
  16   4.6054      0.970  8.4906     0.986  186.71
  17   4.6054      0.970  8.4908     0.962  198.24
  18   4.6054      0.970  8.4904     0.968  209.86
  19   4.6054      0.970  8.4907     0.954  221.38
  20   4.6054      0.970  8.4907     0.934  232.93
  21   4.6054      0.970  8.4909     0.912  244.50
  22   4.6054      0.970  8.4907     0.966  256.03
  23   4.6054      0.970  8.4908     1.060  267.55
  24   4.6054      0.970  8.4907     0.988  279.15
  25   4.6054      0.970  8.4909     1.016  290.68
  26   4.6054      0.970  8.4906     1.042  302.19
  27   4.6054      0.970  8.4906     0.988  313.73
  28   4.6054      0.970  8.4906     0.938  325.33
  29   4.6054      0.970  8.4906     1.074  336.87
  30   4.6054      0.970  8.4906     0.970  348.41
  31   4.6054      0.970  8.4906     1.010  360.01
  32   4.6054      0.970  8.4906     0.990  371.54
  33   4.6054      0.970  8.4908     0.966  383.10
  34   4.6054      0.970  8.4909     1.008  394.71
  35   4.6054      0.970  8.4907     1.022  406.26
  36   4.6054      0.970  8.4905     1.102  417.81
  37   4.6054      0.970  8.4908     1.092  429.41
  38   4.6054      0.970  8.4910     0.998  440.94
  39   4.6054      0.970  8.4906     0.986  452.47
  40   4.6054      0.970  8.4908     0.978  464.09
  41   4.6054      0.970  8.4906     0.938  475.61
  42   4.6054      0.970  8.4907     0.992  487.12
  43   4.6054      0.970  8.4905     0.972  498.73
  44   4.6054      0.970  8.4906     0.970  510.25
  45   4.6054      0.970  8.4906     1.056  521.81
  46   4.6054      0.970  8.4908     0.966  533.39
  47   4.6054      0.970  8.4904     1.110  544.91
  48   4.6054      0.970  8.4908     0.960  556.44
  49   4.6054      0.970  8.4906     0.960  568.07
  50   4.6054      0.970  8.4905     0.966  579.61
  51   4.6054      0.970  8.4908     1.048  591.14
  52   4.6054      0.970  8.4907     0.942  602.71
  53   4.6054      0.970  8.4909     1.028  614.22
  54   4.6054      0.970  8.4908     1.002  625.78
  55   4.6054      0.970  8.4905     0.974  637.35
  56   4.6054      0.970  8.4908     0.996  648.87
  57   4.6054      0.970  8.4905     1.094  660.43
  58   4.6054      0.970  8.4906     0.954  672.01
  59   4.6054      0.970  8.4908     0.978  683.52
  60   4.6054      0.970  8.4909     0.912  695.09
  61   4.6054      0.970  8.4906     1.052  706.71
  62   4.6054      0.970  8.4907     0.980  718.23
  63   4.6054      0.970  8.4907     1.004  729.77
  64   4.6054      0.970  8.4907     1.062  741.35
  65   4.6054      0.970  8.4908     1.010  752.90
  66   4.6054      0.970  8.4907     0.978  764.42
  67   4.6054      0.970  8.4907     0.926  776.00
  68   4.6054      0.970  8.4906     1.056  787.52
  69   4.6054      0.970  8.4908     0.992  799.04
  70   4.6054      0.970  8.4908     1.002  810.69
  71   4.6054      0.970  8.4907     0.922  822.20
  72   4.6054      0.970  8.4906     0.976  833.74
  73   4.6054      0.970  8.4903     1.018  845.33
  74   4.6054      0.970  8.4906     1.082  856.86
  75   4.6054      0.970  8.4908     1.012  868.38
  76   4.6054      0.970  8.4907     0.972  880.01
  77   4.6054      0.970  8.4908     1.080  891.53
  78   4.6054      0.970  8.4907     1.042  903.06
  79   4.6054      0.970  8.4908     0.920  914.65
  80   4.6054      0.970  8.4907     0.966  926.17
  81   4.6054      0.970  8.4907     0.946  937.72
  82   4.6054      0.970  8.4906     0.968  949.29
  83   4.6054      0.970  8.4907     0.948  960.83
  84   4.6054      0.970  8.4908     0.946  972.36
  85   4.6054      0.970  8.4907     0.986  983.97
