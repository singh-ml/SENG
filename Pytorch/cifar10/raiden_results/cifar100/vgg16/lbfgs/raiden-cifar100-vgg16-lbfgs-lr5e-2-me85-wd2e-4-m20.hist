Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 11978947072 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6056      1.220  8.4909     1.020  12.34
   2   4.6056      1.220  8.4909     0.972  23.12
   3   4.6056      1.220  8.4907     0.988  33.89
   4   4.6056      1.220  8.4909     0.930  44.64
   5   4.6056      1.220  8.4909     1.088  55.47
   6   4.6056      1.220  8.4909     1.048  66.21
   7   4.6056      1.220  8.4909     1.064  76.95
   8   4.6056      1.220  8.4910     1.004  87.70
   9   4.6056      1.220  8.4908     0.994  98.43
  10   4.6056      1.220  8.4909     1.120  109.16
  11   4.6056      1.220  8.4908     1.026  119.89
  12   4.6056      1.220  8.4913     1.038  130.73
  13   4.6056      1.220  8.4910     1.068  141.47
  14   4.6056      1.220  8.4907     1.068  152.22
  15   4.6056      1.220  8.4907     0.912  163.04
  16   4.6056      1.220  8.4909     0.982  173.78
  17   4.6056      1.220  8.4910     0.974  184.51
  18   4.6056      1.220  8.4911     1.010  195.32
  19   4.6056      1.220  8.4910     1.046  206.05
  20   4.6056      1.220  8.4908     0.970  216.79
  21   4.6056      1.220  8.4910     1.056  227.56
  22   4.6056      1.220  8.4908     1.058  238.36
  23   4.6056      1.220  8.4910     1.010  249.10
  24   4.6056      1.220  8.4910     1.010  259.87
  25   4.6056      1.220  8.4910     0.996  270.65
  26   4.6056      1.220  8.4908     0.982  281.41
  27   4.6056      1.220  8.4912     0.972  292.14
  28   4.6056      1.220  8.4907     1.044  302.93
  29   4.6056      1.220  8.4912     1.024  313.70
  30   4.6056      1.220  8.4907     1.038  324.43
  31   4.6056      1.220  8.4911     0.950  335.23
  32   4.6056      1.220  8.4909     1.022  345.94
  33   4.6056      1.220  8.4909     0.934  356.66
  34   4.6056      1.220  8.4911     0.976  367.45
  35   4.6056      1.220  8.4908     0.990  378.18
  36   4.6056      1.220  8.4908     1.064  388.90
  37   4.6056      1.220  8.4907     1.026  399.63
  38   4.6056      1.220  8.4909     1.012  410.47
  39   4.6056      1.220  8.4909     0.994  421.22
  40   4.6056      1.220  8.4907     1.022  431.93
  41   4.6056      1.220  8.4913     0.972  442.69
  42   4.6056      1.220  8.4909     1.012  453.42
  43   4.6056      1.220  8.4911     1.000  464.15
  44   4.6056      1.220  8.4908     1.074  474.96
  45   4.6056      1.220  8.4910     0.964  485.68
  46   4.6056      1.220  8.4913     1.004  496.42
  47   4.6056      1.220  8.4912     1.020  507.20
  48   4.6056      1.220  8.4911     0.972  517.93
  49   4.6056      1.220  8.4908     1.022  528.65
  50   4.6056      1.220  8.4908     0.968  539.41
  51   4.6056      1.220  8.4911     0.960  550.19
  52   4.6056      1.220  8.4910     0.970  560.93
  53   4.6056      1.220  8.4909     0.990  571.64
  54   4.6056      1.220  8.4908     0.956  582.45
  55   4.6056      1.220  8.4913     0.950  593.16
  56   4.6056      1.220  8.4910     1.056  603.90
  57   4.6056      1.220  8.4910     1.012  614.69
  58   4.6056      1.220  8.4909     1.042  625.43
  59   4.6056      1.220  8.4910     0.960  636.15
  60   4.6056      1.220  8.4909     1.076  646.94
  61   4.6056      1.220  8.4908     1.032  657.68
  62   4.6056      1.220  8.4909     1.006  668.42
  63   4.6056      1.220  8.4911     1.024  679.23
  64   4.6056      1.220  8.4910     1.010  689.98
  65   4.6056      1.220  8.4908     1.098  700.72
  66   4.6056      1.220  8.4908     1.000  711.46
  67   4.6056      1.220  8.4911     0.998  722.28
  68   4.6056      1.220  8.4910     0.948  733.02
  69   4.6056      1.220  8.4909     0.946  743.75
  70   4.6056      1.220  8.4909     0.978  754.58
  71   4.6056      1.220  8.4912     1.016  765.31
  72   4.6056      1.220  8.4908     0.972  776.06
  73   4.6056      1.220  8.4909     0.966  786.81
  74   4.6056      1.220  8.4909     1.048  797.63
  75   4.6056      1.220  8.4910     0.958  808.40
  76   4.6056      1.220  8.4908     1.010  819.12
  77   4.6056      1.220  8.4912     0.988  829.95
  78   4.6056      1.220  8.4910     1.092  840.67
  79   4.6056      1.220  8.4910     0.890  851.39
  80   4.6056      1.220  8.4911     0.944  862.17
  81   4.6056      1.220  8.4910     0.930  872.91
  82   4.6056      1.220  8.4909     1.002  883.67
  83   4.6056      1.220  8.4912     1.042  894.48
  84   4.6056      1.220  8.4910     0.964  905.22
  85   4.6056      1.220  8.4911     1.030  915.96
