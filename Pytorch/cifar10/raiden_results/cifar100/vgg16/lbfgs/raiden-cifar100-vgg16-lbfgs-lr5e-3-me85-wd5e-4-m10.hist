Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 8746601984 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6061      0.720  14.3192     0.904  11.21
   2   4.6061      0.720  14.3192     0.972  20.73
   3   4.6061      0.720  14.3193     0.974  30.20
   4   4.6061      0.720  14.3192     1.008  39.67
   5   4.6061      0.720  14.3193     0.938  49.17
   6   4.6061      0.720  14.3192     0.914  58.71
   7   4.6061      0.720  14.3194     0.992  68.15
   8   4.6061      0.720  14.3195     0.930  77.60
   9   4.6061      0.720  14.3194     0.926  87.12
  10   4.6061      0.720  14.3193     0.950  96.59
  11   4.6061      0.720  14.3193     0.972  106.04
  12   4.6061      0.720  14.3195     0.968  115.48
  13   4.6061      0.720  14.3194     0.924  124.98
  14   4.6061      0.720  14.3195     0.914  134.44
  15   4.6061      0.720  14.3190     0.994  143.89
  16   4.6061      0.720  14.3192     0.968  153.36
  17   4.6061      0.720  14.3193     0.996  162.90
  18   4.6061      0.720  14.3191     0.982  172.35
  19   4.6061      0.720  14.3192     0.976  181.78
  20   4.6061      0.720  14.3194     0.948  191.31
  21   4.6061      0.720  14.3198     0.918  200.74
  22   4.6061      0.720  14.3192     0.984  210.25
  23   4.6061      0.720  14.3191     1.010  219.68
  24   4.6061      0.720  14.3194     0.950  229.19
  25   4.6061      0.720  14.3196     0.894  238.66
  26   4.6061      0.720  14.3192     0.934  248.10
  27   4.6061      0.720  14.3194     0.992  257.63
  28   4.6061      0.720  14.3191     1.016  267.11
  29   4.6061      0.720  14.3193     0.964  276.54
  30   4.6061      0.720  14.3192     0.966  285.98
  31   4.6061      0.720  14.3192     1.024  295.49
  32   4.6061      0.720  14.3193     0.960  304.94
  33   4.6061      0.720  14.3193     0.922  314.38
  34   4.6061      0.720  14.3192     0.946  323.80
  35   4.6061      0.720  14.3193     1.034  333.30
  36   4.6061      0.720  14.3192     1.002  342.74
  37   4.6061      0.720  14.3194     0.948  352.20
  38   4.6061      0.720  14.3193     0.984  361.72
  39   4.6061      0.720  14.3189     1.022  371.18
  40   4.6061      0.720  14.3193     0.994  380.61
  41   4.6061      0.720  14.3195     0.812  390.06
  42   4.6061      0.720  14.3192     0.954  399.57
  43   4.6061      0.720  14.3192     0.978  409.06
  44   4.6061      0.720  14.3195     0.898  418.52
  45   4.6061      0.720  14.3192     1.014  427.95
  46   4.6061      0.720  14.3192     0.966  437.46
  47   4.6061      0.720  14.3194     0.958  446.88
  48   4.6061      0.720  14.3192     1.038  456.33
  49   4.6061      0.720  14.3192     1.006  465.90
  50   4.6061      0.720  14.3192     0.970  475.37
  51   4.6061      0.720  14.3191     1.008  484.81
  52   4.6061      0.720  14.3193     0.980  494.27
  53   4.6061      0.720  14.3195     0.928  503.80
  54   4.6061      0.720  14.3194     0.984  513.27
  55   4.6061      0.720  14.3193     1.008  522.72
  56   4.6061      0.720  14.3192     1.022  532.21
  57   4.6061      0.720  14.3190     0.906  541.78
  58   4.6061      0.720  14.3192     1.046  551.23
  59   4.6061      0.720  14.3196     1.010  560.70
  60   4.6061      0.720  14.3194     0.994  570.18
  61   4.6061      0.720  14.3193     0.976  579.69
  62   4.6061      0.720  14.3195     0.944  589.14
  63   4.6061      0.720  14.3194     1.024  598.62
  64   4.6061      0.720  14.3194     0.968  608.15
  65   4.6061      0.720  14.3192     1.026  617.62
  66   4.6061      0.720  14.3194     1.024  627.06
  67   4.6061      0.720  14.3192     0.962  636.49
  68   4.6061      0.720  14.3192     1.022  646.03
  69   4.6061      0.720  14.3191     0.986  655.47
  70   4.6061      0.720  14.3195     0.946  664.91
  71   4.6061      0.720  14.3192     1.024  674.34
  72   4.6061      0.720  14.3193     0.990  683.89
  73   4.6061      0.720  14.3193     0.928  693.35
  74   4.6061      0.720  14.3194     0.926  702.78
  75   4.6061      0.720  14.3194     0.972  712.30
  76   4.6061      0.720  14.3191     0.986  721.79
  77   4.6061      0.720  14.3191     0.936  731.24
  78   4.6061      0.720  14.3193     1.006  740.69
  79   4.6061      0.720  14.3193     1.070  750.21
  80   4.6061      0.720  14.3191     1.004  759.67
  81   4.6061      0.720  14.3192     1.026  769.12
  82   4.6061      0.720  14.3191     0.986  778.62
  83   4.6061      0.720  14.3194     0.942  788.03
  84   4.6061      0.720  14.3194     0.948  797.51
  85   4.6061      0.720  14.3191     0.958  806.98
