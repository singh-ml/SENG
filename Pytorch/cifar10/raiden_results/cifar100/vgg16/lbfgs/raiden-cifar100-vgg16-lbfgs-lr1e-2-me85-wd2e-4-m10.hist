Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 8746601984 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6052      1.070  8.4900     1.064  11.07
   2   4.6052      1.060  8.4904     0.986  20.50
   3   4.6052      1.060  8.4903     0.928  30.05
   4   4.6052      1.060  8.4904     1.022  39.47
   5   4.6052      1.060  8.4902     1.018  48.93
   6   4.6052      1.070  8.4904     0.940  58.41
   7   4.6052      1.070  8.4904     1.002  67.54
   8   4.6052      1.070  8.4904     0.932  76.68
   9   4.6052      1.070  8.4904     1.004  85.82
  10   4.6052      1.070  8.4904     0.998  94.98
  11   4.6052      1.070  8.4906     1.042  104.11
  12   4.6052      1.070  8.4903     0.912  113.26
  13   4.6052      1.070  8.4902     1.036  122.35
  14   4.6052      1.070  8.4904     1.040  131.53
  15   4.6052      1.070  8.4905     1.014  140.65
  16   4.6052      1.070  8.4906     0.978  149.77
  17   4.6052      1.070  8.4904     0.996  158.95
  18   4.6052      1.070  8.4903     1.024  168.06
  19   4.6052      1.070  8.4905     0.986  177.16
  20   4.6052      1.070  8.4905     0.924  186.31
  21   4.6052      1.070  8.4901     0.992  195.49
  22   4.6052      1.070  8.4901     1.008  204.60
  23   4.6052      1.070  8.4903     1.004  213.73
  24   4.6052      1.070  8.4903     0.976  222.86
  25   4.6052      1.070  8.4905     1.008  232.09
  26   4.6052      1.070  8.4905     0.942  241.25
  27   4.6052      1.070  8.4902     1.004  250.39
  28   4.6052      1.070  8.4907     0.984  259.57
  29   4.6052      1.070  8.4903     0.998  268.69
  30   4.6052      1.070  8.4905     0.998  277.85
  31   4.6052      1.070  8.4904     1.048  286.96
  32   4.6052      1.070  8.4905     0.942  296.17
  33   4.6052      1.070  8.4902     1.082  305.33
  34   4.6052      1.070  8.4905     0.990  314.49
  35   4.6052      1.070  8.4904     1.038  323.60
  36   4.6052      1.070  8.4903     1.014  332.79
  37   4.6052      1.070  8.4905     0.978  341.90
  38   4.6052      1.070  8.4902     1.020  351.04
  39   4.6052      1.070  8.4903     1.052  360.14
  40   4.6052      1.070  8.4905     1.026  369.36
  41   4.6052      1.070  8.4903     0.934  378.48
  42   4.6052      1.070  8.4903     1.042  387.60
  43   4.6052      1.070  8.4905     0.972  396.71
  44   4.6052      1.070  8.4903     0.942  405.91
  45   4.6052      1.070  8.4903     0.960  415.02
  46   4.6052      1.070  8.4905     0.952  424.11
  47   4.6052      1.070  8.4904     1.022  433.29
  48   4.6052      1.070  8.4902     1.054  442.41
  49   4.6052      1.070  8.4903     0.936  451.55
  50   4.6052      1.070  8.4904     0.882  460.70
  51   4.6052      1.070  8.4903     0.980  469.91
  52   4.6052      1.070  8.4904     0.980  479.05
  53   4.6052      1.070  8.4903     0.960  488.16
  54   4.6052      1.070  8.4902     1.004  497.27
  55   4.6052      1.070  8.4904     1.076  506.42
  56   4.6052      1.070  8.4903     0.934  515.56
  57   4.6052      1.070  8.4903     1.028  524.67
  58   4.6052      1.070  8.4905     1.034  533.82
  59   4.6052      1.070  8.4903     0.954  542.99
  60   4.6052      1.070  8.4902     1.020  552.10
  61   4.6052      1.070  8.4906     0.998  561.21
  62   4.6052      1.070  8.4905     0.952  570.39
  63   4.6052      1.070  8.4904     1.034  579.55
  64   4.6052      1.070  8.4904     0.950  588.67
  65   4.6052      1.070  8.4904     1.026  597.79
  66   4.6052      1.070  8.4902     1.028  606.98
  67   4.6052      1.070  8.4903     1.012  616.08
  68   4.6052      1.070  8.4906     0.882  625.18
  69   4.6052      1.070  8.4905     0.998  634.29
  70   4.6052      1.070  8.4905     0.932  643.45
  71   4.6052      1.070  8.4905     1.078  652.59
  72   4.6052      1.070  8.4904     1.012  661.70
  73   4.6052      1.070  8.4902     1.026  670.85
  74   4.6052      1.070  8.4905     1.012  680.07
  75   4.6052      1.070  8.4903     0.928  689.17
  76   4.6052      1.070  8.4904     1.014  698.28
  77   4.6052      1.070  8.4904     0.872  707.42
  78   4.6052      1.070  8.4903     1.026  716.62
  79   4.6052      1.070  8.4903     0.920  725.72
  80   4.6052      1.070  8.4905     1.040  734.85
  81   4.6052      1.070  8.4902     1.058  743.95
  82   4.6052      1.070  8.4904     0.922  753.17
  83   4.6052      1.070  8.4903     0.982  762.31
  84   4.6052      1.070  8.4902     1.088  771.42
  85   4.6052      1.070  8.4904     0.958  780.60
