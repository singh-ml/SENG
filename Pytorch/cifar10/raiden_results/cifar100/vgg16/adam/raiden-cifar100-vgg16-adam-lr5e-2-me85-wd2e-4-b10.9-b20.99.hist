Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4048930304 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6079      1.000  6614648326537505792.0000     0.992  7.18
   2   4.6114      1.000  152148.8495     1.006  12.53
   3   4.6104      1.000  2610.0497     0.938  17.86
   4   4.6106      1.000  59.8306     0.944  23.20
   5   4.6118      1.000  80.0987     0.976  28.51
   6   4.6123      1.000  103.3305     0.912  33.87
   7   4.6123      1.000  1092.5365     0.920  39.19
   8   4.6107      1.000  5.2592     0.994  44.51
   9   4.6127      1.000  5.8503     0.966  49.87
  10   4.6130      1.000  15981708.6434     1.048  55.19
  11   4.6127      1.000  869679257.3829     0.996  60.51
  12   4.6112      1.000  40351024.4252     0.958  65.86
  13   4.6126      1.000  182270874.4184     0.922  71.17
  14   4.6139      1.000  4284418.3002     0.980  76.58
  15   4.6110      1.000  42946.8712     1.004  81.93
  16   4.6125      1.000  1149819.5962     0.988  87.25
  17   4.6212      1.000  944583.8239     0.894  92.58
  18   4.6110      1.000  253.3994     0.954  97.92
  19   4.6479      1.000  13899.4780     0.928  103.26
  20   4.6234      1.000  1221.6533     0.954  108.69
  21   4.6098      1.000  3501718292990.0942     0.934  114.05
  22   4.6123      1.000  112790145.0597     0.966  119.37
  23   4.6131      1.000  806206939.7060     0.940  124.73
  24   4.6109      1.000  12450157500.4457     0.946  130.07
  25   4.6130      1.000  6377555708.4017     0.944  135.40
  26   4.6118      1.000  3946303.2262     0.996  140.80
  27   4.6108      1.000  25607810.9168     0.962  146.11
  28   4.6366      1.000  47695361.1207     0.904  151.43
  29   4.6339      1.000  14665789.7766     0.956  156.77
  30   4.6635      1.000  1179606805578.7671     1.002  162.12
  31   4.6110      1.000  1956656.7777     0.986  167.48
  32   4.6125      1.000  8949223.6953     0.952  172.85
  33   4.6123      1.000  98050.9547     1.010  178.18
  34   4.6125      1.000  53868587.8713     0.996  183.50
  35   4.6120      1.000  1147495.6917     0.958  188.84
  36   4.6110      1.000  2315598853.7128     0.960  194.19
  37   4.6108      1.000  94003.6808     0.964  199.51
  38   4.6108      1.000  15983013.3548     1.002  204.93
  39   4.6103      1.000  548913642427.9905     0.870  210.29
  40   4.6122      1.000  751166591.3330     0.984  215.60
  41   4.6134      1.000  601136352.3290     0.960  220.94
  42   4.6119      1.000  36268833.9887     0.956  226.30
  43   4.6106      1.000  17254870.2116     0.980  231.63
  44   4.6141      1.000  3352050.0947     0.924  236.96
  45   15562759.2500      1.000  448790644.1246     1.054  242.27
  46   4.6135      1.000  52271139657.3376     0.964  247.70
  47   4.6110      1.000  538814169.7008     0.956  253.04
  48   4.6133      1.000  31553214.5693     0.914  258.38
  49   4.6101      1.000  82992573.1943     1.016  263.75
  50   4.6119      1.000  4645856042.1611     0.986  269.10
  51   4.6102      1.000  1640776462779969.7500     0.974  274.43
  52   4.6106      1.000  2444202804994.2046     0.956  279.78
  53   4.6144      1.000  3430608071.6297     0.996  285.16
  54   4.6132      1.000  2057135855.4591     0.978  290.50
  55   4.6143      1.000  219653187670.9664     0.952  295.83
  56   4.6125      1.000  64004567.4100     0.942  301.16
  57   4.6109      1.000  722572297.7771     0.972  306.46
  58   4.6116      1.000  307383857.0838     0.996  311.79
  59   4.6124      1.000  13872158.0949     0.986  317.19
  60   4.6138      1.000  10328313.1674     1.010  322.49
  61   4.6118      1.000  3102064131.4909     0.950  327.83
  62   4.6128      1.000  21755015.3274     0.964  333.17
  63   4.6121      1.000  14253853.4733     0.916  338.47
  64   4.6106      1.000  1699831.1435     0.892  343.80
  65   4.6126      1.000  1992974.5800     0.916  349.13
  66   4.6112      1.000  6977271.1423     0.940  354.54
  67   4.6097      1.000  1029539223285973.3750     0.942  359.89
  68   4.6100      1.000  695729553985.6340     0.924  365.20
  69   4.6110      1.000  975188535.3722     0.972  370.54
  70   4.6101      1.000  87115995.1162     0.926  375.90
  71   4.6136      1.000  284031038136.1530     0.934  381.21
  72   4.6123      1.000  1102269886.2596     0.910  386.62
  73   4.6128      1.000  551665874.4251     0.992  391.94
  74   4.6100      1.000  404359653.9651     0.966  397.26
  75   4.6098      1.000  13050809.5793     0.930  402.60
  76   4.6114      1.000  924974239.9569     1.024  407.94
  77   4.6118      1.000  813995287.0684     1.024  413.26
  78   4.6106      1.000  43586063840933.5703     0.888  418.65
  79   4.6110      1.000  83143312960.9888     0.948  423.96
  80   4.6127      1.000  45760632.5581     0.994  429.28
  81   4.6098      1.000  18534585049587.8945     0.914  434.61
  82   4.6130      1.000  1358085498823439.5000     1.002  439.93
  83   4.6123      1.000  74862970174766.6406     0.922  445.28
  84   4.6118      1.000  506175354031.5888     1.100  450.60
  85   4.6109      1.000  551606749579.2201     0.996  455.98
