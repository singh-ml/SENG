Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4048930304 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6104      1.000  8452216937071806464.0000     0.964  6.99
   2   4.6103      1.000  45.2802     1.036  12.31
   3   4.6114      1.000  25.1124     0.892  17.64
   4   4.6095      1.000  62.7649     0.980  23.01
   5   4.6118      1.000  27.2278     0.896  28.42
   6   4.6108      1.000  17.3590     0.902  33.76
   7   4.6111      1.000  35.0032     0.942  39.08
   8   4.6123      1.000  18.0967     0.994  44.41
   9   4.6110      1.000  6173.5988     0.898  49.77
  10   4.6186      1.000  252974.8004     0.986  55.10
  11   4.6287      1.000  102111.8822     1.000  60.52
  12   4.6198      1.000  578.5788     1.002  65.87
  13   4.6114      1.000  148.3194     0.980  71.25
  14   4.6131      1.000  62.2569     1.044  76.58
  15   4.6106      1.000  34.8138     1.030  81.94
  16   4.6119      1.000  3012.8703     0.958  87.29
  17   4.6152      1.000  33197564.2958     0.978  92.71
  18   4.6110      1.000  10078677971.1380     0.984  98.07
  19   122.9724      1.000  743262.2448     0.948  103.43
  20   4.6154      1.000  123667.7463     0.998  108.77
  21   4.6100      1.000  37016.7347     0.946  114.09
  22   4.6153      1.000  24331.1011     0.936  119.45
  23   4.6101      1.000  320593905.2487     0.948  124.90
  24   4.6156      1.000  27902674.8513     0.918  130.25
  25   4.6197      1.000  7371490.4816     0.934  135.58
  26   4.6132      1.000  5301431.2355     0.966  140.95
  27   4.6149      1.000  38633660.0562     0.928  146.33
  28   4.6117      1.000  4352587370.3238     0.866  151.70
  29   4.6136      1.000  2103557967.0092     0.946  157.11
  30   4.6113      1.000  9917515.3086     0.982  162.44
  31   4.6093      1.000  15757978.2845     0.886  167.78
  32   4.6127      1.000  568167182.0201     0.918  173.16
  33   4.6121      1.000  14088858.3991     1.016  178.50
  34   4.6131      1.000  410428.6250     0.910  183.84
  35   4.6112      1.000  6288525.5047     0.960  189.18
  36   4.6131      1.000  1410951835.6103     0.954  194.59
  37   4.6122      1.000  3533231.1840     0.928  199.95
  38   4.6090      1.000  228651.9899     0.928  205.28
  39   4.6116      1.000  906987280389.5260     0.964  210.63
  40   4.6128      1.000  10034597.5447     0.986  215.96
  41   4.6173      1.000  127706977.4053     0.938  221.30
  42   4.6132      1.000  1585763512.8817     1.042  226.71
  43   4.6108      1.000  7929094006652.2490     1.046  232.03
  44   4.6120      1.000  573375731.8498     0.920  237.36
  45   4.6221      1.000  45955186.5627     1.044  242.70
  46   4.6121      1.000  6798691349146.0908     0.958  248.06
  47   4.6251      1.000  10858141362597.7441     0.920  253.40
  48   4.6118      1.000  5628932480.1187     0.966  258.78
  49   4.6131      1.000  5868018748.3219     1.006  264.22
  50   4.6110      1.000  732908869.1739     0.976  269.56
  51   4.6120      1.000  15071631.6797     0.954  274.93
  52   4.6140      1.000  921832073.6707     0.956  280.25
  53   4.6113      1.000  1470511.4804     0.982  285.60
  54   4.6138      1.000  3141150682.0247     0.918  290.95
  55   4.6098      1.000  335505171.2239     0.922  296.39
  56   4.6101      1.000  1127637303.0375     0.952  301.71
  57   4.6099      1.000  23037112.3855     0.878  307.09
  58   4.6100      1.000  849856.8643     0.864  312.41
  59   4.6142      1.000  18318.2387     1.072  317.77
  60   4.6125      1.000  4688.9383     0.950  323.09
  61   4.6137      1.000  2041.0458     0.906  328.48
  62   4.6128      1.000  348500.8267     0.972  333.82
  63   4.6142      1.000  4102235823887091.0000     0.954  339.19
  64   4.6113      1.000  91479188503.9737     0.818  344.56
  65   4.6128      1.000  438337759178.1819     0.998  349.92
  66   4.6128      1.000  70946880.6202     0.966  355.27
  67   4.6118      1.000  2347945288.1662     0.986  360.68
  68   4.6120      1.000  2280371978129.2612     0.958  366.01
  69   4.6112      1.000  5489150.7073     1.056  371.38
  70   4.6141      1.000  89160477803.0894     0.972  376.74
  71   4.6128      1.000  15327649.6410     0.978  382.08
  72   4.6128      1.000  229829112296.0405     0.990  387.46
  73   4.6097      1.000  501859607.0202     0.890  392.91
  74   4.6116      1.000  1360691030.1076     1.030  398.28
  75   4.6098      1.000  61275027633.3405     1.002  403.66
  76   4.6149      1.000  2715666022300.8584     0.886  409.01
  77   4.6091      1.000  932149472.9346     0.918  414.34
  78   4.6159      1.000  265634980441137.9688     1.002  419.69
  79   4.6123      1.000  160446056032.1842     0.922  425.08
  80   4.6121      1.000  748173297964.3678     0.926  430.41
  81   4.6131      1.000  162946181577.8263     0.930  435.76
  82   4.6116      1.000  29723937790.9965     0.952  441.13
  83   4.6104      1.000  4562348813.6515     0.948  446.48
  84   4.6117      1.000  18106131.1177     1.000  451.83
  85   4.6126      1.000  12601196.3213     0.926  457.18
  86   4.6121      1.000  9728203.6153     0.982  462.63
  87   4.6127      1.000  127405000.9914     0.986  467.96
  88   4.6135      1.000  948307.6806     0.890  473.29
  89   4.6129      1.000  999556.5359     0.980  478.63
  90   4.6117      1.000  1246136.8796     0.966  484.01
