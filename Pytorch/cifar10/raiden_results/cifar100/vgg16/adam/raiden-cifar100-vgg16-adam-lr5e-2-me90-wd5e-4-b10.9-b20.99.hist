Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4048930304 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6092      1.000  16639275754735340.0000     0.974  7.06
   2   4.6101      1.000  1490878881.1581     0.924  12.42
   3   4.6109      1.000  45519918.3150     0.970  17.73
   4   4.6129      1.000  181347958.1043     0.966  23.07
   5   4.6122      1.000  118753426025.3155     1.006  28.41
   6   4.6109      1.000  513783364.5183     0.956  33.79
   7   4.6116      1.000  496512.0176     1.008  39.13
   8   4.6120      1.000  4.6131     0.966  44.47
   9   4.6105      1.000  5541.7396     0.934  49.81
  10   4.6104      1.000  6.2775     0.940  55.16
  11   4.6128      1.000  8.2160     0.946  60.54
  12   4.6104      1.000  5.5788     1.036  65.94
  13   4.6093      1.000  5.6587     0.948  71.31
  14   4.6135      1.000  166.4875     0.938  76.64
  15   4.6107      1.000  150939925339.4334     1.008  81.95
  16   4.6092      1.000  4932650052.5157     0.906  87.27
  17   4.6131      1.000  35.6679     0.964  92.62
  18   4.6210      1.000  2469.8621     0.976  97.99
  19   6.1278      1.000  6986.0193     0.946  103.38
  20   4.6897      1.000  9527.8431     1.052  108.72
  21   4.6120      1.000  4705.8860     0.996  114.06
  22   4.6148      1.000  774.2093     0.920  119.38
  23   4.6194      1.000  547.8498     0.958  124.73
  24   4.6216      1.000  23080467431.4942     0.976  130.09
  25   4.6215      1.000  10451637.0524     0.982  135.41
  26   4.6103      1.000  5637508537.5223     0.962  140.74
  27   4.6304      1.000  854785060240184.6250     0.994  146.07
  28   4.6118      1.000  31494430.9394     0.916  151.39
  29   4.6149      1.000  2227264098410.2104     0.902  156.74
  30   4.6179      1.000  93912205580.1178     0.998  162.09
  31   4.6173      1.000  13990263719.2031     0.952  167.44
  32   4.6134      1.000  34902262099.1680     0.936  172.82
  33   4.6106      1.000  6685133732.2822     1.024  178.27
  34   4.6261      1.000  161051831670.6572     1.022  183.60
  35   4.6109      1.000  3059092748.8868     0.954  188.94
  36   4.6102      1.000  9624669870.8188     0.934  194.29
  37   4.6155      1.000  4896600696387.8223     0.996  199.62
  38   4.6157      1.000  84243528181.5187     0.982  204.97
  39   4.6104      1.000  192671243448.8362     1.002  210.37
  40   4.6126      1.000  7516042761.4248     1.024  215.73
  41   4.6108      1.000  45990601.6647     1.034  221.07
  42   4.6096      1.000  263280.7418     0.968  226.41
  43   4.6115      1.000  659878079980925.0000     1.012  231.75
  44   4.6123      1.000  552826120258470.6250     0.878  237.07
  45   4.6114      1.000  2508874221525.4863     1.030  242.50
  46   4.6120      1.000  12445230003710.0762     0.936  247.85
  47   4.6106      1.000  7734428804.8423     0.966  253.22
  48   4.6112      1.000  26145173462.5757     0.922  258.55
  49   4.6131      1.000  680258978083736.1250     1.036  263.87
  50   4.6143      1.000  170230818936.5899     0.930  269.22
  51   4.6121      1.000  1085943371953.8705     1.050  274.55
  52   4.6100      1.000  858462208.4149     0.984  279.96
  53   4.6112      1.000  8109298665.9628     0.988  285.29
  54   4.6111      1.000  2376802766.8579     1.040  290.62
  55   4.6134      1.000  32680450055.0069     0.974  295.94
  56   4.6120      1.000  53703361926.0835     0.962  301.31
  57   4.6118      1.000  123585378663.7622     0.958  306.64
  58   4.6112      1.000  14318481233.4691     0.950  312.04
  59   4.6119      1.000  7500174292749.4668     0.934  317.38
  60   4.6132      1.000  145911809184.4707     0.988  322.72
  61   4.6096      1.000  1582376424.2657     1.020  328.10
  62   4.6106      1.000  29364995417.0260     1.018  333.46
  63   2090577897062.3999      1.000  2335900994.6690     0.956  338.81
  64   4.6097      1.000  40796121884730.6875     0.972  344.23
  65   4.6100      1.000  302360214.5342     0.900  349.59
  66   4.6124      1.000  59461655016746.3984     0.938  354.95
  67   4.6121      1.000  177536667041.3428     0.978  360.29
  68   4.6134      1.000  257854329834.1010     0.960  365.63
  69   4.6105      1.000  42073580886.7506     0.982  370.99
  70   4.6123      1.000  256775371535966.1562     0.918  376.35
  71   4.6106      1.000  53948199533.1208     1.018  381.77
  72   4.6118      1.000  87117896348.5144     0.962  387.11
  73   4.6131      1.000  8668343752.5583     0.900  392.46
  74   4.6110      1.000  2125890372.4807     0.890  397.82
  75   4.6113      1.000  185147801030890.6562     0.976  403.20
  76   4.6113      1.000  47407330968286.8984     1.026  408.52
  77   4.6130      1.000  118382526492.1551     0.936  413.85
  78   4.6097      1.000  48128755.9778     0.942  419.25
  79   4.6126      1.000  14694626717366110.0000     0.914  424.60
  80   4.6147      1.000  335008956547.7107     1.006  429.97
  81   4.6107      1.000  227791898810172.7500     0.978  435.32
  82   4.6115      1.000  1763059734897658368.0000     1.020  440.65
  83   4.6143      1.000  397584022014.5558     0.848  446.03
  84   4.6112      1.000  25167778406210.7539     0.932  451.38
  85   4.6108      1.000  696576818119.8916     0.954  456.71
  86   4.6130      1.000  1119807392180.9209     0.972  462.04
  87   4.6121      1.000  7518597741.0132     0.954  467.39
  88   4.6113      1.000  1643016812072.4824     0.952  472.76
  89   4.6124      1.000  5109647383.1159     0.992  478.12
  90   4.6097      1.000  4151052792.6281     0.972  483.53
