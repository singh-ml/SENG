Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 22461106688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7996      0.920  40.6601     0.952  30.21
   2   4.7948      1.060  40.6588     1.008  58.18
   3   4.7809      0.960  40.6575     1.000  86.18
   4   4.7674      1.080  40.6596     0.950  114.15
   5   4.8409      0.850  40.6603     1.034  142.13
   6   4.8442      0.930  40.6585     0.958  170.16
   7   4.8230      0.920  40.6590     0.994  198.15
   8   4.8012      0.990  40.6594     0.912  226.11
   9   4.8288      0.970  40.6593     0.986  254.07
  10   4.8496      0.850  40.6579     0.912  282.07
  11   4.8446      0.920  40.6581     0.946  310.09
  12   4.8029      1.040  40.6564     1.072  337.86
  13   4.7745      1.000  40.6586     0.960  365.75
  14   4.7952      1.020  40.6585     1.034  393.70
  15   4.7616      0.970  40.6593     0.950  421.72
  16   4.8305      0.890  40.6589     0.992  449.67
  17   4.7929      1.020  40.6596     0.948  477.65
  18   4.8225      0.980  40.6601     0.996  505.68
  19   4.7906      0.950  40.6581     0.956  533.67
  20   4.8526      0.970  40.6588     0.962  561.68
  21   4.8214      1.020  40.6593     0.970  589.69
  22   4.7933      1.050  40.6594     0.968  617.65
  23   4.8288      1.020  40.6603     0.940  645.68
  24   4.8060      1.050  40.6596     0.942  673.68
  25   4.7923      1.120  40.6585     0.916  701.69
  26   4.8196      0.960  40.6600     0.992  729.67
  27   4.7952      1.060  40.6586     0.962  757.61
  28   4.7969      0.920  40.6588     0.946  785.61
  29   4.7696      0.920  40.6588     0.940  813.61
  30   4.8072      0.990  40.6600     0.942  841.60
  31   4.7814      0.960  40.6584     1.036  869.59
  32   4.7754      1.040  40.6579     0.954  897.61
  33   4.8091      0.960  40.6592     0.958  925.56
  34   4.7743      1.000  40.6593     0.950  953.45
  35   4.8061      1.010  40.6593     0.886  981.46
  36   4.8100      0.880  40.6598     0.934  1009.47
  37   4.7965      0.890  40.6574     1.034  1037.49
  38   4.8038      0.860  40.6590     0.990  1065.32
  39   4.7657      1.030  40.6572     0.938  1093.18
  40   4.7856      0.970  40.6581     0.916  1121.20
  41   4.8355      0.930  40.6579     0.988  1149.10
  42   4.7873      1.110  40.6581     0.964  1177.12
  43   4.8809      1.020  40.6616     0.990  1205.07
  44   4.8268      0.950  40.6591     0.966  1233.01
  45   4.8216      0.820  40.6574     0.940  1260.87
  46   4.8178      0.920  40.6601     0.982  1288.89
  47   4.7604      0.980  40.6585     0.994  1316.80
  48   4.8478      0.970  40.6585     0.980  1344.78
  49   4.8119      1.020  40.6586     0.892  1372.75
  50   4.7816      1.060  40.6594     0.948  1400.77
  51   4.8368      1.110  40.6584     0.902  1428.77
  52   4.8233      1.080  40.6589     0.974  1456.62
  53   4.8128      1.130  40.6585     0.962  1484.60
  54   4.8592      1.040  40.6570     0.936  1512.49
  55   4.8103      0.950  40.6584     0.930  1540.44
  56   4.8603      0.960  40.6609     0.962  1568.38
  57   4.8034      1.100  40.6580     0.950  1596.37
  58   4.7649      0.880  40.6584     0.930  1624.39
  59   4.7855      0.880  40.6616     0.988  1652.40
  60   4.8282      1.020  40.6577     0.974  1680.34
  61   4.8207      1.080  40.6603     0.936  1708.38
  62   4.8642      0.940  40.6589     0.924  1736.36
  63   4.8074      0.900  40.6582     0.928  1764.34
  64   4.8107      1.060  40.6610     0.948  1792.30
  65   4.7976      1.090  40.6581     0.912  1820.22
  66   4.8266      1.020  40.6579     0.974  1848.26
  67   4.8326      0.940  40.6591     0.976  1876.27
  68   4.8410      0.980  40.6590     1.030  1904.13
  69   4.7579      1.020  40.6582     0.974  1932.14
  70   4.8107      1.040  40.6586     0.922  1960.01
  71   4.8234      1.010  40.6585     0.972  1987.99
  72   4.7543      0.940  40.6592     0.988  2016.01
  73   4.8101      1.040  40.6598     1.014  2044.03
  74   4.8194      0.910  40.6587     0.984  2071.99
  75   4.7756      0.930  40.6592     0.998  2099.85
  76   4.8494      1.010  40.6580     0.932  2127.74
  77   4.7858      1.000  40.6590     0.992  2155.76
  78   4.8452      1.020  40.6585     0.930  2183.68
  79   4.8302      0.980  40.6605     0.924  2211.70
  80   4.7784      0.920  40.6602     0.938  2239.69
  81   4.7533      0.800  40.6594     0.958  2267.66
  82   4.8774      1.000  40.6588     1.012  2295.67
  83   4.7449      1.000  40.6612     0.966  2323.71
  84   4.7924      0.900  40.6595     0.914  2351.70
  85   4.8226      0.960  40.6590     1.016  2379.71
  86   4.8169      0.980  40.6585     0.950  2407.67
  87   4.8255      1.040  40.6582     0.904  2435.64
  88   4.8375      0.890  40.6600     0.968  2463.67
  89   4.8219      0.880  40.6591     1.010  2491.68
  90   4.8260      0.930  40.6589     0.918  2519.65
