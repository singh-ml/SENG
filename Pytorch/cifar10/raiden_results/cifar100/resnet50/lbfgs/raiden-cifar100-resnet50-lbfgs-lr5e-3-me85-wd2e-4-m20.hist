Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 19045158912 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7403      0.770  19.1115     0.752  27.66
   2   4.7246      0.650  19.1101     0.766  52.77
   3   4.7263      0.720  19.1110     0.678  77.87
   4   4.7211      0.590  19.1099     0.762  102.97
   5   4.7223      0.660  19.1112     0.750  128.01
   6   4.7310      0.670  19.1126     0.750  153.10
   7   4.7209      0.720  19.1120     0.720  178.14
   8   4.7234      0.660  19.1108     0.774  203.17
   9   4.7464      0.590  19.1117     0.690  228.33
  10   4.7300      0.650  19.1110     0.758  253.45
  11   4.7298      0.720  19.1130     0.770  278.44
  12   4.7453      0.670  19.1128     0.724  303.54
  13   4.7389      0.630  19.1118     0.788  328.62
  14   4.7324      0.720  19.1114     0.754  353.71
  15   4.7407      0.720  19.1104     0.772  378.87
  16   4.7810      0.520  19.1116     0.716  404.00
  17   4.7490      0.690  19.1136     0.772  429.13
  18   4.7340      0.640  19.1110     0.712  454.22
  19   4.7262      0.690  19.1104     0.736  479.41
  20   4.7315      0.690  19.1097     0.728  504.57
  21   4.7509      0.620  19.1112     0.776  529.52
  22   4.7392      0.660  19.1126     0.706  554.51
  23   4.7457      0.570  19.1106     0.798  579.55
  24   4.7583      0.730  19.1116     0.736  604.68
  25   4.7306      0.690  19.1106     0.706  629.78
  26   4.7287      0.720  19.1109     0.754  654.85
  27   4.7112      0.830  19.1095     0.752  679.98
  28   4.7240      0.610  19.1109     0.678  705.12
  29   4.7182      0.670  19.1112     0.720  730.24
  30   4.7054      0.650  19.1114     0.756  755.28
  31   4.7435      0.620  19.1121     0.754  780.41
  32   4.7392      0.680  19.1113     0.760  805.53
  33   4.7263      0.720  19.1117     0.770  830.55
  34   4.7727      0.630  19.1101     0.690  855.73
  35   4.7320      0.650  19.1117     0.756  880.89
  36   4.7439      0.750  19.1120     0.730  906.01
  37   4.7303      0.730  19.1110     0.762  930.99
  38   4.7168      0.800  19.1112     0.730  956.12
  39   4.7265      0.550  19.1096     0.766  981.16
  40   4.7299      0.710  19.1109     0.724  1006.28
  41   4.7591      0.540  19.1113     0.740  1031.31
  42   4.7284      0.690  19.1119     0.754  1056.43
  43   4.7385      0.550  19.1106     0.768  1081.56
  44   4.7380      0.680  19.1089     0.732  1106.69
  45   4.7322      0.700  19.1116     0.772  1131.79
  46   4.7201      0.670  19.1108     0.704  1156.89
  47   4.7272      0.660  19.1106     0.756  1181.92
  48   4.7155      0.670  19.1118     0.756  1206.98
  49   4.7407      0.750  19.1110     0.726  1232.07
  50   4.7083      0.660  19.1135     0.756  1257.09
  51   4.7166      0.610  19.1118     0.708  1282.19
  52   4.7157      0.510  19.1121     0.744  1307.27
  53   4.7288      0.690  19.1109     0.732  1332.37
  54   4.7396      0.670  19.1115     0.762  1357.38
  55   4.7230      0.740  19.1102     0.722  1382.45
  56   4.7353      0.680  19.1102     0.770  1407.49
  57   4.7264      0.590  19.1108     0.742  1432.47
  58   4.7152      0.690  19.1121     0.804  1457.59
  59   4.7319      0.690  19.1106     0.756  1482.67
  60   4.7253      0.600  19.1117     0.726  1507.64
  61   4.7574      0.630  19.1103     0.750  1532.64
  62   4.7270      0.680  19.1100     0.758  1557.62
  63   4.7176      0.670  19.1117     0.738  1582.61
  64   4.7227      0.670  19.1110     0.728  1607.67
  65   4.7390      0.670  19.1108     0.756  1632.77
  66   4.7373      0.730  19.1111     0.800  1657.87
  67   4.7527      0.700  19.1107     0.702  1683.06
  68   4.7391      0.630  19.1095     0.788  1708.09
  69   4.7419      0.680  19.1112     0.760  1733.23
  70   4.7534      0.690  19.1114     0.730  1758.40
  71   4.7185      0.650  19.1102     0.776  1783.51
  72   4.7369      0.690  19.1106     0.688  1808.59
  73   4.7310      0.640  19.1125     0.728  1833.74
  74   4.7279      0.870  19.1105     0.734  1858.77
  75   4.7220      0.660  19.1115     0.696  1883.85
  76   4.7170      0.640  19.1113     0.746  1908.96
  77   4.7076      0.670  19.1112     0.708  1934.10
  78   4.7471      0.710  19.1120     0.742  1959.28
  79   4.7333      0.680  19.1113     0.764  1984.43
  80   4.7282      0.650  19.1110     0.694  2009.52
  81   4.7098      0.710  19.1105     0.782  2034.55
  82   4.7585      0.800  19.1120     0.730  2059.52
  83   4.7359      0.670  19.1109     0.726  2084.56
  84   4.7646      0.700  19.1129     0.732  2109.67
  85   4.7407      0.620  19.1102     0.766  2134.81
