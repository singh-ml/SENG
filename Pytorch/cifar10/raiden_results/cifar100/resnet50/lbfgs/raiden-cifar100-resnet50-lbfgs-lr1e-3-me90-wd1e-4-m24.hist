Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 18670027776 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7483      0.810  11.9726     1.040  27.29
   2   4.7572      0.960  11.9716     0.972  52.21
   3   4.7611      0.880  11.9706     1.014  77.13
   4   4.7405      1.000  11.9723     0.966  101.92
   5   4.7435      0.900  11.9737     1.038  126.83
   6   4.7513      0.970  11.9713     1.016  151.69
   7   4.7493      0.910  11.9727     0.992  176.60
   8   4.7565      0.980  11.9726     0.990  201.47
   9   4.7611      0.950  11.9736     1.020  226.36
  10   4.7464      1.020  11.9722     0.964  251.27
  11   4.7653      0.950  11.9709     0.960  276.14
  12   4.7558      0.840  11.9726     1.006  300.91
  13   4.7754      0.950  11.9716     1.020  325.70
  14   4.7601      1.010  11.9731     0.992  350.55
  15   4.7496      0.970  11.9713     0.946  375.42
  16   4.7573      0.930  11.9742     0.940  400.38
  17   4.7611      0.910  11.9727     1.006  425.33
  18   4.7486      1.010  11.9720     1.060  450.06
  19   4.7670      0.910  11.9724     1.034  474.90
  20   4.7518      0.970  11.9714     1.020  499.89
  21   4.7627      0.950  11.9716     0.988  524.74
  22   4.7668      1.030  11.9717     1.008  549.61
  23   4.7399      0.950  11.9754     1.032  574.41
  24   4.7590      0.960  11.9742     0.994  599.31
  25   4.7457      1.000  11.9715     1.036  624.20
  26   4.7554      0.960  11.9729     0.976  649.10
  27   4.7432      0.970  11.9718     0.958  673.99
  28   4.7482      0.870  11.9730     0.988  698.85
  29   4.7446      1.010  11.9741     1.008  723.78
  30   4.7641      0.950  11.9713     1.016  748.70
  31   4.7460      0.990  11.9737     0.972  773.55
  32   4.7707      0.940  11.9740     0.980  798.43
  33   4.7730      0.810  11.9732     1.032  823.38
  34   4.7381      1.000  11.9730     0.972  848.25
  35   4.7586      0.990  11.9715     1.016  873.18
  36   4.7613      0.920  11.9722     1.000  898.12
  37   4.7723      0.930  11.9755     0.966  923.01
  38   4.7558      1.010  11.9732     0.990  947.86
  39   4.7523      0.790  11.9714     1.026  972.78
  40   4.7584      0.840  11.9731     0.974  997.75
  41   4.7616      0.870  11.9713     0.986  1022.56
  42   4.7432      0.930  11.9727     0.978  1047.50
  43   4.7617      0.860  11.9733     1.024  1072.42
  44   4.7612      1.000  11.9730     0.962  1097.32
  45   4.7439      1.010  11.9732     0.982  1122.28
  46   4.7473      0.950  11.9722     0.992  1147.19
  47   4.7622      0.920  11.9723     1.030  1171.91
  48   4.7659      0.870  11.9727     1.000  1196.79
  49   4.7548      0.840  11.9728     0.994  1221.58
  50   4.7584      0.880  11.9728     1.020  1246.46
  51   4.7561      0.850  11.9731     1.004  1271.28
  52   4.7531      1.050  11.9735     0.988  1296.12
  53   4.7672      0.830  11.9736     0.966  1321.00
  54   4.7539      1.030  11.9724     0.972  1345.87
  55   4.7577      0.960  11.9699     1.088  1370.72
  56   4.7481      0.990  11.9718     1.040  1395.62
  57   4.7653      0.950  11.9737     0.974  1420.49
  58   4.7749      0.820  11.9733     0.998  1445.26
  59   4.7488      0.920  11.9721     1.038  1470.09
  60   4.7724      0.980  11.9726     0.970  1495.02
  61   4.7441      0.980  11.9722     1.034  1519.74
  62   4.7439      0.960  11.9722     1.006  1544.59
  63   4.7615      0.930  11.9721     0.978  1569.51
  64   4.7513      0.920  11.9713     1.026  1594.33
  65   4.7576      0.880  11.9731     0.994  1619.27
  66   4.7557      0.940  11.9715     1.024  1644.21
  67   4.7615      1.010  11.9732     1.008  1669.15
  68   4.7499      0.900  11.9715     0.990  1693.98
  69   4.7570      1.010  11.9726     1.032  1718.93
  70   4.7508      0.970  11.9710     0.994  1743.82
  71   4.7478      0.890  11.9727     1.028  1768.54
  72   4.7451      0.850  11.9730     1.010  1793.29
  73   4.7565      0.820  11.9729     0.974  1818.19
  74   4.7497      0.940  11.9721     1.034  1843.10
  75   4.7413      0.960  11.9716     0.978  1868.01
  76   4.7480      0.960  11.9725     1.010  1892.95
  77   4.7500      0.960  11.9726     0.992  1917.86
  78   4.7529      0.800  11.9724     0.962  1942.75
  79   4.7692      0.950  11.9727     0.968  1967.69
  80   4.7486      1.030  11.9709     1.004  1992.51
  81   4.7679      0.860  11.9727     0.940  2017.36
  82   4.7506      0.930  11.9740     0.998  2042.23
  83   4.7496      0.920  11.9743     0.960  2067.18
  84   4.7422      0.960  11.9726     0.982  2092.08
  85   4.7574      0.890  11.9719     0.984  2117.02
  86   4.7485      0.970  11.9718     0.990  2141.94
  87   4.7770      0.820  11.9723     0.976  2166.85
  88   4.7654      0.990  11.9736     1.000  2191.72
  89   4.7441      0.870  11.9721     0.996  2216.60
  90   4.7758      0.940  11.9724     1.076  2241.53
