Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 21887604736 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7972      0.990  19.1602     0.974  29.69
   2   4.8135      1.060  19.1613     0.952  57.09
   3   4.8198      1.030  19.1611     0.934  84.44
   4   4.7867      0.960  19.1617     0.966  111.68
   5   4.8367      0.880  19.1601     0.958  139.06
   6   4.8083      0.890  19.1605     0.970  166.29
   7   4.8267      1.020  19.1620     0.960  193.68
   8   4.7985      0.890  19.1617     0.928  221.03
   9   4.8081      0.950  19.1613     0.994  248.39
  10   4.7943      1.010  19.1609     0.962  275.78
  11   4.7815      1.130  19.1603     1.016  303.17
  12   4.8550      1.020  19.1605     0.964  330.48
  13   4.8050      1.000  19.1624     0.956  357.89
  14   4.8241      1.100  19.1610     1.020  385.28
  15   4.8375      0.960  19.1605     0.980  412.59
  16   4.8387      1.100  19.1604     1.004  440.00
  17   4.8024      0.950  19.1616     0.952  467.36
  18   4.8077      1.000  19.1600     0.992  494.73
  19   4.8378      1.100  19.1605     0.924  522.05
  20   4.8145      0.970  19.1624     0.888  549.40
  21   4.8314      1.080  19.1627     0.948  576.67
  22   4.8436      1.070  19.1605     0.986  603.89
  23   4.8124      1.060  19.1615     0.968  631.30
  24   4.7952      0.890  19.1608     1.006  658.72
  25   4.7963      0.960  19.1623     0.964  686.12
  26   4.8389      1.030  19.1598     0.978  713.35
  27   4.8507      0.890  19.1624     0.986  740.65
  28   4.7986      1.030  19.1630     0.964  768.14
  29   4.8212      1.070  19.1606     0.988  795.38
  30   4.8542      0.970  19.1609     0.954  822.77
  31   4.8464      0.990  19.1614     0.968  850.06
  32   4.7850      0.950  19.1610     0.952  877.29
  33   4.7937      0.970  19.1616     1.012  904.69
  34   4.8516      0.930  19.1601     0.986  932.08
  35   4.8336      1.170  19.1595     1.016  959.44
  36   4.8286      1.070  19.1611     0.974  986.78
  37   4.7882      1.010  19.1612     1.014  1014.14
  38   4.8396      0.990  19.1616     0.960  1041.45
  39   4.8199      0.860  19.1605     0.972  1068.83
  40   4.8485      1.040  19.1597     0.986  1096.21
  41   4.8321      1.050  19.1592     0.998  1123.62
  42   4.8666      0.940  19.1618     0.998  1150.98
  43   4.7999      1.080  19.1591     0.968  1178.25
  44   4.8179      1.030  19.1604     1.010  1205.62
  45   4.8154      0.950  19.1593     1.022  1232.83
  46   4.8387      0.990  19.1605     1.014  1260.17
  47   4.8434      1.030  19.1601     0.954  1287.53
  48   4.8103      0.970  19.1611     1.046  1314.94
  49   4.8759      0.960  19.1607     0.986  1342.35
  50   4.8114      1.080  19.1603     0.964  1369.73
  51   4.8023      1.060  19.1615     0.964  1397.06
  52   4.8089      1.020  19.1608     0.942  1424.47
  53   4.7719      0.980  19.1600     0.932  1451.69
  54   4.8206      1.020  19.1602     0.998  1479.09
  55   4.8073      0.890  19.1614     0.946  1506.46
  56   4.8284      0.980  19.1618     0.980  1533.80
  57   4.7790      1.020  19.1615     0.960  1561.17
  58   4.8104      1.020  19.1599     0.958  1588.53
  59   4.8245      1.010  19.1604     0.910  1615.93
  60   4.7957      0.920  19.1614     0.968  1643.34
  61   4.7919      1.050  19.1605     1.000  1670.72
  62   4.7859      0.910  19.1613     0.978  1698.08
  63   4.7796      0.960  19.1612     0.916  1725.49
  64   4.8292      0.940  19.1599     0.974  1752.88
  65   4.8110      0.990  19.1615     0.954  1780.30
  66   4.8137      0.930  19.1626     1.016  1807.63
  67   4.8259      1.030  19.1620     0.966  1835.00
  68   4.8492      1.000  19.1619     0.980  1862.41
  69   4.7833      1.050  19.1619     0.996  1889.79
  70   4.8341      0.960  19.1611     0.984  1917.20
  71   4.8636      1.000  19.1613     1.020  1944.57
  72   4.8030      0.940  19.1605     0.960  1971.87
  73   4.7979      1.100  19.1600     0.954  1999.29
  74   4.8228      1.010  19.1630     0.942  2026.72
  75   4.8229      0.960  19.1605     1.002  2054.12
  76   4.8355      1.030  19.1612     1.014  2081.47
  77   4.7903      1.060  19.1600     0.974  2108.85
  78   4.8444      0.980  19.1603     0.976  2136.27
  79   4.8126      1.040  19.1612     0.970  2163.67
  80   4.8144      1.070  19.1613     0.994  2191.04
  81   4.8092      0.980  19.1611     0.960  2218.26
  82   4.8004      1.030  19.1619     0.992  2245.67
  83   4.8364      1.050  19.1616     0.934  2272.90
  84   4.8088      0.960  19.1615     0.910  2300.23
  85   4.8427      1.090  19.1602     0.980  2327.64
  86   4.8780      1.060  19.1608     0.994  2354.99
  87   4.8340      1.010  19.1610     0.978  2382.36
  88   4.8342      0.990  19.1615     0.968  2409.77
  89   4.8200      0.970  19.1603     1.000  2437.15
  90   4.8079      1.010  19.1604     0.964  2464.52
