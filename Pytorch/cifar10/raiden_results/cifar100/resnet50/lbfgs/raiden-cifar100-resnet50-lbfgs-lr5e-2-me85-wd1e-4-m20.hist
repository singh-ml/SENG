Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 21131238400 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.8458      0.860  12.0308     0.860  29.04
   2   4.8789      0.870  12.0320     0.854  55.82
   3   4.9089      0.830  12.0311     0.902  82.67
   4   4.8459      0.810  12.0320     0.902  109.40
   5   4.9297      0.920  12.0308     0.876  136.21
   6   4.9224      0.990  12.0316     0.864  163.09
   7   4.8674      1.030  12.0307     0.862  189.78
   8   4.8505      0.830  12.0322     0.882  216.68
   9   4.8259      0.950  12.0309     0.856  243.59
  10   4.8158      1.020  12.0309     0.888  270.49
  11   4.9077      0.870  12.0309     0.886  297.29
  12   4.8897      0.900  12.0295     0.830  324.14
  13   4.8581      0.910  12.0305     0.834  350.96
  14   4.9103      0.920  12.0318     0.826  377.89
  15   4.9004      1.100  12.0316     0.834  404.65
  16   4.9402      0.780  12.0295     0.866  431.35
  17   4.8215      0.940  12.0319     0.844  458.23
  18   4.8430      0.950  12.0318     0.856  485.29
  19   4.8366      0.930  12.0319     0.896  512.33
  20   4.8368      0.940  12.0305     0.842  539.37
  21   4.9049      0.920  12.0300     0.880  566.37
  22   4.8647      0.940  12.0317     0.866  593.35
  23   4.8797      0.940  12.0300     0.902  620.40
  24   4.8368      0.930  12.0298     0.868  647.45
  25   4.8504      0.910  12.0321     0.856  674.28
  26   4.9374      0.880  12.0323     0.798  701.26
  27   4.8802      0.930  12.0320     0.814  728.14
  28   4.8775      0.930  12.0323     0.912  755.19
  29   4.8801      0.930  12.0306     0.894  782.26
  30   4.8830      0.820  12.0306     0.836  809.17
  31   4.8560      0.870  12.0329     0.848  836.19
  32   4.8539      0.890  12.0316     0.876  863.24
  33   4.8429      0.910  12.0322     0.874  890.31
  34   4.8565      0.950  12.0303     0.872  917.36
  35   4.8721      0.940  12.0304     0.848  944.36
  36   4.8728      0.920  12.0315     0.832  971.39
  37   4.8550      0.820  12.0311     0.846  998.45
  38   4.9536      0.910  12.0312     0.908  1025.48
  39   4.8847      0.980  12.0323     0.880  1052.40
  40   4.8471      0.810  12.0315     0.824  1079.39
  41   4.9431      0.900  12.0319     0.872  1106.30
  42   4.8865      0.940  12.0326     0.894  1133.19
  43   4.8682      0.900  12.0304     0.902  1160.15
  44   4.8523      0.910  12.0307     0.808  1187.15
  45   4.8483      0.990  12.0317     0.856  1214.19
  46   4.8744      0.890  12.0324     0.892  1241.26
  47   4.8902      0.820  12.0326     0.876  1268.24
  48   4.8990      0.860  12.0307     0.852  1295.30
  49   4.9110      0.980  12.0308     0.852  1322.29
  50   4.8427      0.980  12.0314     0.892  1349.26
  51   4.8640      0.990  12.0316     0.848  1376.29
  52   4.8903      0.910  12.0320     0.808  1403.29
  53   4.9556      0.800  12.0316     0.894  1430.17
  54   4.9286      0.890  12.0302     0.948  1457.22
  55   4.8622      0.850  12.0295     0.890  1484.28
  56   4.8349      0.750  12.0314     0.862  1511.21
  57   4.9256      0.830  12.0299     0.866  1538.25
  58   4.8400      0.840  12.0321     0.878  1565.10
  59   4.8992      0.960  12.0305     0.874  1592.04
  60   4.9038      0.910  12.0315     0.854  1618.93
  61   4.8642      0.890  12.0307     0.814  1645.93
  62   4.8573      0.960  12.0313     0.840  1672.79
  63   4.9295      0.970  12.0334     0.824  1699.69
  64   4.8550      0.910  12.0308     0.876  1726.75
  65   4.9242      0.870  12.0312     0.824  1753.80
  66   4.8307      0.910  12.0302     0.922  1780.88
  67   4.8188      0.910  12.0312     0.878  1807.86
  68   4.8807      0.900  12.0307     0.912  1834.90
  69   4.8479      0.910  12.0303     0.854  1861.92
  70   4.8747      0.830  12.0311     0.908  1888.95
  71   4.8118      0.880  12.0291     0.826  1916.00
  72   4.8777      0.930  12.0302     0.876  1942.85
  73   4.8596      0.960  12.0318     0.872  1969.77
  74   4.8338      0.870  12.0319     0.908  1996.83
  75   4.8268      0.980  12.0323     0.858  2023.88
  76   4.8444      0.880  12.0320     0.848  2050.88
  77   4.8527      0.930  12.0323     0.858  2077.86
  78   4.8469      0.810  12.0319     0.866  2104.90
  79   4.8994      0.880  12.0300     0.878  2131.83
  80   4.9205      0.980  12.0323     0.838  2158.78
  81   4.8566      0.910  12.0306     0.894  2185.76
  82   4.8614      0.940  12.0311     0.896  2212.77
  83   4.8340      0.820  12.0304     0.900  2239.85
  84   4.8306      0.820  12.0321     0.878  2266.89
  85   4.8291      0.900  12.0304     0.818  2293.91
