Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 22647565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.8119      0.680  40.6823     0.858  30.13
   2   4.8150      0.780  40.6819     0.822  57.99
   3   4.8008      0.870  40.6812     0.780  85.82
   4   4.8760      1.010  40.6810     0.864  113.71
   5   4.8249      0.950  40.6821     0.802  141.70
   6   4.8532      1.130  40.6826     0.836  169.56
   7   4.8030      0.900  40.6837     0.846  197.50
   8   4.7989      0.810  40.6829     0.798  225.29
   9   4.8209      1.010  40.6823     0.854  253.26
  10   4.7916      0.910  40.6831     0.840  281.25
  11   4.9776      1.040  40.6820     0.804  309.17
  12   4.8946      0.830  40.6806     0.818  336.90
  13   4.8650      0.900  40.6823     0.812  364.88
  14   4.9625      1.200  40.6809     0.844  392.83
  15   4.7795      0.860  40.6828     0.888  420.83
  16   4.8771      0.860  40.6819     0.852  448.79
  17   4.8109      0.950  40.6828     0.854  476.66
  18   4.8322      0.990  40.6816     0.804  504.64
  19   4.9679      0.870  40.6801     0.832  532.61
  20   4.9740      1.030  40.6817     0.776  560.59
  21   4.8253      0.990  40.6812     0.846  588.55
  22   4.8821      0.940  40.6849     0.902  616.50
  23   4.8429      1.040  40.6818     0.754  644.40
  24   4.9023      0.920  40.6826     0.816  672.20
  25   4.8337      1.080  40.6824     0.862  700.14
  26   4.7995      0.860  40.6821     0.792  728.12
  27   4.8113      0.940  40.6819     0.822  756.05
  28   4.9151      1.100  40.6816     0.802  783.85
  29   4.8386      0.790  40.6817     0.760  811.80
  30   4.8061      0.930  40.6814     0.818  839.78
  31   4.8334      0.880  40.6822     0.830  867.76
  32   4.8369      1.030  40.6831     0.798  895.75
  33   4.8579      1.010  40.6828     0.802  923.53
  34   4.8378      0.900  40.6818     0.814  951.50
  35   4.8555      1.030  40.6825     0.838  979.46
  36   4.8515      0.880  40.6818     0.842  1007.42
  37   4.8233      0.890  40.6814     0.846  1035.22
  38   4.8382      0.860  40.6819     0.806  1063.14
  39   4.8639      1.030  40.6825     0.806  1091.06
  40   4.8504      0.900  40.6814     0.864  1118.93
  41   4.9015      1.050  40.6811     0.748  1146.79
  42   4.8260      1.060  40.6819     0.874  1174.64
  43   4.8343      0.940  40.6824     0.822  1202.44
  44   4.8266      0.810  40.6816     0.834  1230.39
  45   4.8008      1.080  40.6821     0.772  1258.36
  46   4.8536      0.890  40.6814     0.858  1286.20
  47   4.8111      0.780  40.6828     0.788  1314.15
  48   4.8384      0.960  40.6821     0.782  1342.14
  49   4.8745      1.090  40.6809     0.820  1370.05
  50   4.8853      0.930  40.6810     0.722  1397.86
  51   4.8433      0.840  40.6817     0.792  1425.83
  52   4.8360      0.920  40.6814     0.812  1453.72
  53   4.8708      0.970  40.6815     0.788  1481.56
  54   4.8844      1.000  40.6803     0.858  1509.43
  55   4.8210      0.800  40.6807     0.848  1537.25
  56   4.7875      0.800  40.6817     0.766  1565.10
  57   4.9151      0.890  40.6815     0.882  1592.89
  58   4.9983      1.130  40.6830     0.838  1620.78
  59   4.7861      0.760  40.6818     0.788  1648.75
  60   4.8133      0.720  40.6804     0.792  1676.68
  61   4.8021      0.920  40.6820     0.804  1704.59
  62   4.9039      1.000  40.6829     0.818  1732.58
  63   4.8626      0.970  40.6808     0.824  1760.50
  64   4.8401      0.890  40.6829     0.816  1788.31
  65   4.8238      0.940  40.6832     0.788  1816.26
  66   4.8718      1.030  40.6829     0.790  1844.14
  67   4.8192      0.810  40.6816     0.822  1872.14
  68   4.8008      0.860  40.6824     0.754  1900.12
  69   4.8600      0.840  40.6822     0.808  1928.03
  70   4.9196      0.950  40.6837     0.828  1955.88
  71   4.8437      0.790  40.6833     0.792  1983.64
  72   4.8320      0.850  40.6817     0.848  2011.58
  73   4.8301      0.920  40.6827     0.850  2039.58
  74   4.7848      0.810  40.6812     0.844  2067.44
  75   4.8915      1.010  40.6828     0.834  2095.39
  76   4.8429      0.940  40.6810     0.836  2123.30
  77   4.7835      0.780  40.6799     0.782  2151.29
  78   4.8779      0.990  40.6822     0.826  2179.11
  79   4.7879      0.830  40.6811     0.778  2207.09
  80   4.8880      1.050  40.6823     0.828  2235.08
  81   4.8452      0.870  40.6822     0.792  2263.01
  82   4.8636      0.960  40.6813     0.834  2290.80
  83   4.8872      0.990  40.6822     0.812  2318.77
  84   4.8192      0.900  40.6810     0.790  2346.74
  85   4.7944      0.890  40.6813     0.808  2374.69
