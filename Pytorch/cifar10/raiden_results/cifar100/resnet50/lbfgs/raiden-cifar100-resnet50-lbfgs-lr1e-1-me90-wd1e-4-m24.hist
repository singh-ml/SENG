Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 22646665216 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7440      0.930  11.9647     0.982  30.28
   2   4.7661      0.790  11.9632     0.922  58.23
   3   4.7283      0.760  11.9647     0.914  86.12
   4   4.7586      0.880  11.9657     0.950  114.18
   5   4.7499      0.980  11.9635     0.966  142.02
   6   4.7951      0.850  11.9643     0.924  170.05
   7   4.7738      1.000  11.9624     0.984  197.97
   8   4.7415      0.940  11.9632     0.932  225.90
   9   4.7600      0.880  11.9637     0.882  253.77
  10   4.7429      0.740  11.9633     0.896  281.81
  11   4.7591      0.730  11.9632     0.942  309.86
  12   4.7710      0.850  11.9626     0.942  337.93
  13   4.7368      0.850  11.9643     0.968  365.84
  14   4.7877      0.940  11.9622     0.892  393.89
  15   4.7510      0.900  11.9640     0.958  421.74
  16   4.7594      0.810  11.9633     0.984  449.79
  17   4.7367      0.850  11.9628     0.964  477.82
  18   4.7612      0.720  11.9626     0.954  505.84
  19   4.8205      0.770  11.9637     0.920  533.86
  20   4.7632      0.890  11.9639     0.950  561.83
  21   4.7367      0.850  11.9641     0.930  589.83
  22   4.7707      0.840  11.9632     0.904  617.84
  23   4.7726      0.960  11.9607     0.952  645.90
  24   4.7607      1.020  11.9643     0.962  673.92
  25   4.7402      0.950  11.9641     0.936  701.86
  26   4.7371      0.970  11.9655     0.896  729.83
  27   4.7458      0.800  11.9633     0.880  757.76
  28   4.7609      0.920  11.9657     0.898  785.81
  29   4.7547      0.980  11.9642     0.902  813.87
  30   4.7467      0.970  11.9610     0.924  841.78
  31   4.7673      0.920  11.9625     0.910  869.73
  32   4.7524      0.870  11.9631     0.848  897.73
  33   4.7452      0.880  11.9662     0.958  925.78
  34   4.7746      0.820  11.9636     0.936  953.61
  35   4.7743      0.930  11.9646     0.900  981.61
  36   4.7233      0.810  11.9635     0.960  1009.66
  37   4.7855      0.800  11.9642     0.970  1037.50
  38   4.7640      0.870  11.9628     0.892  1065.43
  39   4.7443      0.750  11.9640     0.910  1093.47
  40   4.7701      0.760  11.9625     0.966  1121.43
  41   4.7803      0.870  11.9640     0.942  1149.37
  42   4.7600      0.920  11.9639     0.916  1177.19
  43   4.7567      0.870  11.9642     0.924  1205.22
  44   4.7734      0.860  11.9648     0.896  1233.15
  45   4.7520      0.850  11.9634     0.916  1261.19
  46   4.7595      0.900  11.9628     0.934  1289.15
  47   4.8074      0.820  11.9642     0.888  1317.19
  48   4.7705      0.800  11.9642     0.898  1345.19
  49   4.7665      0.770  11.9627     0.964  1373.24
  50   4.7819      0.890  11.9653     0.912  1401.27
  51   4.7444      0.860  11.9630     0.882  1429.28
  52   4.7739      0.850  11.9650     0.930  1457.26
  53   4.7848      0.880  11.9639     0.918  1485.26
  54   4.7554      0.830  11.9633     0.884  1513.29
  55   4.7563      0.860  11.9636     0.960  1541.32
  56   4.7533      1.010  11.9619     0.910  1569.33
  57   4.7252      0.990  11.9647     0.890  1597.37
  58   4.7687      0.770  11.9625     0.920  1625.33
  59   4.7643      0.780  11.9648     0.916  1653.41
  60   4.7454      0.810  11.9629     0.910  1681.31
  61   4.7408      0.930  11.9640     0.868  1709.35
  62   4.7524      0.820  11.9656     0.956  1737.38
  63   4.7426      0.870  11.9626     0.968  1765.44
  64   4.7597      0.820  11.9634     0.960  1793.46
  65   4.7492      0.810  11.9644     0.928  1821.49
  66   4.7406      0.840  11.9617     0.892  1849.55
  67   4.7492      0.950  11.9631     0.922  1877.57
  68   4.7429      0.820  11.9620     0.934  1905.40
  69   4.7568      0.920  11.9629     0.936  1933.35
  70   4.7769      0.850  11.9629     0.960  1961.40
  71   4.7838      0.870  11.9649     0.878  1989.36
  72   4.7298      0.950  11.9628     0.934  2017.29
  73   4.7492      1.000  11.9642     0.928  2045.34
  74   4.7634      0.860  11.9638     0.946  2073.30
  75   4.7796      0.830  11.9637     0.914  2101.24
  76   4.7775      1.030  11.9644     0.882  2129.14
  77   4.7723      0.790  11.9627     0.936  2157.11
  78   4.7589      0.910  11.9636     0.962  2185.12
  79   4.7361      0.950  11.9633     0.950  2212.99
  80   4.7773      0.900  11.9654     0.930  2240.93
  81   4.7518      0.720  11.9644     0.986  2268.98
  82   4.7440      0.870  11.9620     0.960  2296.90
  83   4.7766      0.800  11.9635     0.904  2324.80
  84   4.7847      0.870  11.9628     0.942  2352.70
  85   4.7407      0.900  11.9642     0.932  2380.68
  86   4.7214      0.890  11.9636     0.900  2408.65
  87   4.7635      0.760  11.9628     0.956  2436.69
  88   4.7444      0.930  11.9618     0.902  2464.71
  89   4.7458      0.700  11.9637     0.936  2492.61
  90   4.7617      0.950  11.9634     0.922  2520.62
