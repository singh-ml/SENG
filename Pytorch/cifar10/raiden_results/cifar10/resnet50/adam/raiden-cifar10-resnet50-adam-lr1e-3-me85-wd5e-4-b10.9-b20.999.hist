Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 17946863104 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4926     46.820  1.6342    41.838  25.90
   2   0.9925     64.950  1.0890    61.130  49.35
   3   0.8072     71.780  0.8771    69.056  72.86
   4   0.7505     74.320  0.7453    74.102  96.36
   5   0.7225     75.290  0.6631    77.160  119.82
   6   0.6563     78.390  0.6160    79.062  143.30
   7   0.5901     80.100  0.5727    80.432  166.79
   8   0.5910     80.730  0.5461    81.326  190.28
   9   0.5327     81.940  0.5245    82.164  213.77
  10   0.5285     81.890  0.4966    82.998  237.27
  11   0.5066     83.160  0.4727    83.802  260.75
  12   0.5771     80.250  0.4551    84.620  284.25
  13   0.4709     84.360  0.4377    85.250  307.76
  14   0.4807     84.010  0.4293    85.468  331.20
  15   0.4898     84.310  0.4077    86.094  354.68
  16   0.5103     82.640  0.3994    86.408  378.20
  17   0.4424     84.750  0.3894    86.802  401.68
  18   0.4595     84.540  0.3762    87.194  425.17
  19   0.4314     85.700  0.3531    87.952  448.66
  20   0.4262     86.370  0.3546    87.786  472.13
  21   0.4030     86.370  0.3450    88.180  495.64
  22   0.4837     85.130  0.3301    88.768  519.14
  23   0.4247     85.910  0.3298    88.660  542.61
  24   0.3914     86.870  0.3248    88.804  566.10
  25   0.4283     86.100  0.3100    89.270  589.61
  26   0.3968     86.980  0.3087    89.330  613.10
  27   0.3808     86.940  0.3021    89.710  636.59
  28   0.4117     86.530  0.2977    89.726  660.08
  29   0.4175     86.320  0.2944    89.854  683.56
  30   0.3696     87.700  0.2881    90.026  707.08
  31   0.3507     88.690  0.2795    90.392  730.59
  32   0.3938     87.130  0.2769    90.670  754.08
  33   0.3533     88.510  0.2750    90.714  777.58
  34   0.3894     87.220  0.2723    90.674  801.10
  35   0.4495     85.680  0.2672    90.730  824.60
  36   0.3367     88.790  0.2631    90.942  848.12
  37   0.4444     86.270  0.2582    91.034  871.61
  38   0.3769     88.020  0.2547    91.208  895.14
  39   0.3402     88.740  0.2558    91.194  918.65
  40   0.3417     88.510  0.2505    91.366  942.14
  41   0.3703     87.710  0.2439    91.572  965.63
  42   0.3330     88.910  0.2386    91.786  989.14
  43   0.4054     87.430  0.2408    91.626  1012.65
  44   0.4020     87.110  0.2402    91.698  1036.15
  45   0.3671     88.620  0.2327    91.992  1059.69
  46   0.3439     89.010  0.2294    92.208  1083.18
  47   0.3688     88.270  0.2290    92.148  1106.71
  48   0.3293     88.880  0.2280    92.226  1130.24
  49   0.3354     89.150  0.2222    92.344  1153.76
  50   0.3980     87.680  0.2238    92.300  1177.32
  51   0.3500     88.870  0.2239    92.332  1200.88
  52   0.3565     88.410  0.2160    92.576  1224.38
  53   0.3934     87.340  0.2200    92.478  1247.91
  54   0.4061     87.230  0.2143    92.566  1271.43
  55   0.3736     88.370  0.2155    92.606  1294.94
  56   0.3436     89.010  0.2107    92.868  1318.43
  57   0.3583     88.780  0.2084    92.866  1341.95
  58   0.3290     89.200  0.2118    92.686  1365.48
  59   0.3472     89.030  0.2063    92.796  1388.98
  60   0.3361     89.290  0.2011    93.092  1412.50
  61   0.3194     89.780  0.2055    92.866  1436.00
  62   0.3394     89.000  0.2019    92.968  1459.51
  63   0.3374     89.440  0.2002    93.108  1483.04
  64   0.3831     87.770  0.2031    93.036  1506.57
  65   0.3076     90.000  0.1983    93.170  1530.11
  66   0.3346     89.190  0.2004    93.026  1553.66
  67   0.3399     89.010  0.1946    93.284  1577.18
  68   0.4006     88.130  0.1940    93.416  1600.73
  69   0.3614     88.580  0.1964    93.262  1624.27
  70   0.3265     89.640  0.1901    93.478  1647.80
  71   0.3477     89.130  0.1899    93.414  1671.31
  72   0.3465     88.710  0.1899    93.522  1694.84
  73   0.3346     88.960  0.1918    93.428  1718.36
  74   0.3366     89.320  0.1873    93.464  1741.89
  75   0.3169     89.700  0.1882    93.580  1765.43
  76   0.3594     89.030  0.1819    93.734  1788.95
  77   0.3270     89.750  0.1892    93.400  1812.48
  78   0.3423     89.570  0.1829    93.532  1836.01
  79   0.3071     90.580  0.1821    93.718  1859.50
  80   0.3999     87.810  0.1851    93.604  1883.05
  81   0.3512     88.880  0.1793    93.814  1906.57
  82   0.3288     89.680  0.1863    93.488  1930.07
  83   0.3321     89.830  0.1799    93.730  1953.62
  84   0.2993     90.400  0.1823    93.706  1977.16
  85   0.3120     90.330  0.1751    94.014  2000.70
