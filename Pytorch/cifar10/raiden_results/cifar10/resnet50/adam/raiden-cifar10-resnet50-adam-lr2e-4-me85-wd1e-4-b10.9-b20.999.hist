Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 17946863104 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5155     43.430  1.7864    33.574  25.91
   2   1.2794     53.920  1.4270    47.532  49.31
   3   1.1183     59.450  1.2330    55.308  72.72
   4   1.0396     63.410  1.0942    60.724  96.12
   5   0.9729     65.870  0.9656    65.530  119.52
   6   0.8809     69.500  0.8769    69.012  142.94
   7   0.8226     71.270  0.7994    71.730  166.35
   8   0.8208     72.030  0.7312    74.128  189.70
   9   0.7515     74.520  0.6727    76.216  213.14
  10   0.7125     75.840  0.6113    78.418  236.52
  11   0.6693     77.040  0.5675    80.006  259.93
  12   0.6898     77.210  0.5257    81.684  283.32
  13   0.6496     79.020  0.4852    83.014  306.74
  14   0.6172     79.110  0.4444    84.476  330.11
  15   0.5909     81.190  0.4127    85.488  353.53
  16   0.5748     81.120  0.3900    86.318  376.95
  17   0.5740     80.960  0.3572    87.524  400.37
  18   0.5033     83.250  0.3356    88.234  423.77
  19   0.5822     82.310  0.3124    89.062  447.20
  20   0.5703     82.210  0.2981    89.538  470.57
  21   0.4880     84.650  0.2829    90.124  493.99
  22   0.4897     85.200  0.2671    90.666  517.41
  23   0.5270     84.160  0.2489    91.258  540.82
  24   0.5247     84.980  0.2391    91.596  564.24
  25   0.4979     85.010  0.2233    92.058  587.63
  26   0.5187     85.020  0.2082    92.668  611.05
  27   0.5186     84.820  0.2006    92.932  634.48
  28   0.4995     85.610  0.1907    93.362  657.87
  29   0.5117     85.570  0.1770    93.818  681.30
  30   0.4929     86.010  0.1761    93.806  704.76
  31   0.4709     86.810  0.1656    94.154  728.17
  32   0.5153     85.740  0.1591    94.418  751.63
  33   0.4801     86.520  0.1538    94.476  775.03
  34   0.4790     86.990  0.1503    94.580  798.41
  35   0.4920     86.610  0.1411    94.960  821.84
  36   0.4600     87.330  0.1371    95.132  845.28
  37   0.5364     86.240  0.1334    95.214  868.67
  38   0.4729     87.650  0.1193    95.734  892.11
  39   0.5553     85.920  0.1173    95.880  915.54
  40   0.4799     87.670  0.1162    95.948  938.93
  41   0.5207     86.640  0.1170    95.832  962.31
  42   0.5154     86.820  0.1109    96.078  985.72
  43   0.5194     86.920  0.1066    96.198  1009.12
  44   0.4579     87.670  0.1105    96.152  1032.52
  45   0.4853     87.900  0.0926    96.678  1055.89
  46   0.4996     87.480  0.0974    96.584  1079.32
  47   0.4761     87.730  0.0978    96.608  1102.74
  48   0.5027     87.650  0.0943    96.740  1126.16
  49   0.4828     87.520  0.0916    96.778  1149.53
  50   0.5159     87.410  0.0952    96.748  1172.94
  51   0.5106     87.320  0.0898    96.848  1196.36
  52   0.5171     87.360  0.0838    97.020  1219.73
  53   0.4889     87.720  0.0851    97.030  1243.09
  54   0.5339     87.290  0.0823    97.090  1266.50
  55   0.4767     88.060  0.0823    97.128  1289.93
  56   0.4968     88.080  0.0798    97.232  1313.35
  57   0.4858     88.350  0.0742    97.382  1336.74
  58   0.4593     88.320  0.0790    97.220  1360.11
  59   0.4699     87.780  0.0732    97.406  1383.51
  60   0.4304     88.960  0.0783    97.332  1406.93
  61   0.4922     88.020  0.0730    97.444  1430.29
  62   0.4919     88.450  0.0709    97.512  1453.69
  63   0.4843     88.260  0.0664    97.712  1477.07
  64   0.5035     88.030  0.0684    97.698  1500.46
  65   0.4873     88.530  0.0714    97.546  1523.88
  66   0.5008     88.020  0.0701    97.576  1547.29
  67   0.4979     88.120  0.0690    97.616  1570.72
  68   0.5779     87.400  0.0593    97.922  1594.12
  69   0.5127     88.000  0.0660    97.704  1617.46
  70   0.4396     88.990  0.0713    97.532  1640.85
  71   0.4704     89.020  0.0670    97.690  1664.25
  72   0.5123     87.910  0.0656    97.762  1687.66
  73   0.4517     89.240  0.0632    97.778  1711.09
  74   0.5158     87.910  0.0592    97.988  1734.48
  75   0.4651     88.760  0.0573    98.020  1757.86
  76   0.4657     88.680  0.0620    97.872  1781.24
  77   0.5500     88.140  0.0640    97.830  1804.63
  78   0.4468     88.870  0.0565    98.006  1828.01
  79   0.5268     88.320  0.0590    98.016  1851.44
  80   0.4994     88.790  0.0610    97.862  1874.83
  81   0.5309     88.740  0.0570    98.016  1898.21
  82   0.4559     89.540  0.0583    98.022  1921.61
  83   0.5019     88.640  0.0600    97.886  1945.03
  84   0.5174     88.270  0.0536    98.138  1968.41
  85   0.4649     89.040  0.0614    97.810  1991.81
