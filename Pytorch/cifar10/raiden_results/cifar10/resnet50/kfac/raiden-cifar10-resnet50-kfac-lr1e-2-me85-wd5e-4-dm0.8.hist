Use GPU: 0 for training
==> Running with ['main_kfac.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 22152161280 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6535     39.770  1.9247    28.790  27.85
   2   1.4124     49.740  1.5323    43.908  53.20
   3   1.2637     55.120  1.3474    51.288  78.56
   4   1.2030     57.360  1.2216    56.394  103.90
   5   1.0858     61.390  1.1214    59.730  129.28
   6   1.0715     62.770  1.0350    63.054  154.68
   7   1.0202     65.110  0.9620    65.890  180.03
   8   0.9159     67.720  0.8871    68.546  205.41
   9   0.8557     70.270  0.8255    70.552  230.77
  10   0.8439     71.650  0.7691    72.810  256.12
  11   0.7790     73.050  0.7146    74.864  281.48
  12   0.7388     74.870  0.6617    76.730  306.86
  13   0.7554     74.720  0.6215    78.132  332.25
  14   0.7231     76.420  0.5805    79.616  357.60
  15   0.6711     77.470  0.5344    81.074  382.97
  16   0.6969     77.040  0.4940    82.506  408.37
  17   0.6511     78.910  0.4601    83.930  433.71
  18   0.6140     80.470  0.4314    84.822  459.08
  19   0.6183     80.310  0.3865    86.426  484.45
  20   0.6400     80.840  0.3630    87.214  509.81
  21   0.6167     81.660  0.3398    88.090  535.16
  22   0.6120     82.250  0.3099    89.096  560.61
  23   0.6137     81.750  0.2846    89.918  585.98
  24   0.6281     82.260  0.2606    90.742  611.32
  25   0.6068     83.440  0.2442    91.348  636.70
  26   0.6158     82.810  0.2194    92.286  662.05
  27   0.6296     82.740  0.2015    92.908  687.41
  28   0.6216     83.360  0.1882    93.294  712.86
  29   0.6298     83.300  0.1727    93.942  738.24
  30   0.6491     84.050  0.1578    94.396  763.63
  31   0.6490     83.730  0.1453    94.820  788.99
  32   0.6690     83.660  0.1286    95.440  814.33
  33   0.6721     83.570  0.1244    95.630  839.67
  34   0.6386     84.550  0.1096    96.166  865.04
  35   0.6954     83.720  0.1014    96.450  890.41
  36   0.7001     84.020  0.0956    96.766  915.78
  37   0.7213     84.280  0.0843    97.072  941.12
  38   0.6679     84.760  0.0775    97.292  966.46
  39   0.6900     84.780  0.0737    97.444  991.81
  40   0.7794     83.930  0.0645    97.770  1017.22
  41   0.7234     84.730  0.0605    97.878  1042.66
  42   0.7148     84.930  0.0521    98.212  1068.03
  43   0.7015     85.990  0.0507    98.270  1093.41
  44   0.7486     84.680  0.0457    98.442  1118.77
  45   0.7465     85.530  0.0421    98.574  1144.11
  46   0.7287     85.450  0.0371    98.754  1169.53
  47   0.7666     85.090  0.0367    98.770  1194.89
  48   0.7417     85.840  0.0316    98.960  1220.26
  49   0.7493     85.550  0.0271    99.110  1245.62
  50   0.7730     85.620  0.0271    99.110  1270.18
  51   0.7349     86.080  0.0239    99.250  1295.54
