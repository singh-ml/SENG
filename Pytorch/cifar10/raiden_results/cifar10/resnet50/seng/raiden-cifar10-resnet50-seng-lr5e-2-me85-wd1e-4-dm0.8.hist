Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 29436831232 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3261     53.720  1.6712    39.492  28.45
   2   1.0106     65.510  1.1259    59.740  54.18
   3   0.8028     72.440  0.8851    68.732  79.90
   4   0.7020     75.690  0.7386    73.830  105.64
   5   0.6458     78.070  0.6196    78.362  131.37
   6   0.5654     80.780  0.5377    81.292  157.08
   7   0.5345     82.270  0.4683    83.790  182.81
   8   0.4848     84.040  0.4290    85.188  208.55
   9   0.5031     83.470  0.3910    86.494  234.29
  10   0.4466     85.620  0.3596    87.518  260.02
  11   0.4192     85.870  0.3232    88.818  285.75
  12   0.4439     86.260  0.2979    89.610  311.50
  13   0.4551     86.040  0.2854    90.042  337.25
  14   0.4324     86.740  0.2639    90.756  362.98
  15   0.3844     88.100  0.2485    91.318  388.72
  16   0.3932     87.590  0.2276    92.018  414.46
  17   0.4187     87.390  0.2153    92.462  440.21
  18   0.3910     87.860  0.1984    93.036  465.93
  19   0.4177     88.060  0.1792    93.592  491.66
  20   0.4237     88.290  0.1796    93.722  517.41
  21   0.4241     88.060  0.1697    94.110  543.15
  22   0.4224     88.110  0.1445    94.896  568.89
  23   0.3988     89.360  0.1374    95.148  594.61
  24   0.4124     89.320  0.1359    95.180  620.33
  25   0.4502     88.530  0.1282    95.442  646.05
  26   0.4340     89.280  0.1210    95.802  671.79
  27   0.4380     89.100  0.1147    95.946  697.53
  28   0.4577     88.920  0.1061    96.308  723.31
  29   0.4437     89.210  0.0933    96.788  749.03
  30   0.4277     89.920  0.0950    96.658  774.73
  31   0.4526     89.420  0.0832    97.102  800.46
  32   0.6086     87.500  0.0809    97.164  826.20
  33   0.4379     89.780  0.0761    97.276  851.95
  34   0.4189     90.290  0.0691    97.540  877.68
  35   0.4846     89.650  0.0690    97.646  903.40
  36   0.4683     89.900  0.0576    97.944  929.15
  37   0.5040     89.660  0.0585    97.928  954.90
  38   0.4583     90.060  0.0457    98.412  980.63
  39   0.5168     89.830  0.0491    98.292  1006.37
  40   0.4626     90.250  0.0473    98.280  1032.09
  41   0.4827     90.600  0.0372    98.700  1057.92
  42   0.4709     90.490  0.0328    98.858  1083.65
  43   0.5310     90.690  0.0284    99.016  1109.40
  44   0.5399     90.370  0.0251    99.118  1135.13
  45   0.4785     91.110  0.0244    99.120  1160.85
  46   0.5106     90.490  0.0222    99.180  1186.56
  47   0.4842     91.250  0.0222    99.206  1212.28
  48   0.4995     91.070  0.0169    99.398  1238.00
  49   0.5173     91.230  0.0161    99.458  1263.71
  50   0.5113     91.400  0.0123    99.590  1289.18
  51   0.5334     91.500  0.0118    99.576  1314.91
  52   0.5513     90.780  0.0107    99.628  1340.64
  53   0.4809     91.590  0.0085    99.708  1366.38
  54   0.5136     91.250  0.0068    99.756  1392.12
  55   0.4748     91.990  0.0057    99.820  1417.85
  56   0.5053     91.810  0.0052    99.838  1443.59
  57   0.4769     92.050  0.0052    99.820  1469.34
  58   0.5361     91.580  0.0038    99.882  1495.08
  59   0.5349     91.480  0.0029    99.926  1520.81
  60   0.5292     91.760  0.0033    99.908  1546.57
  61   0.5177     91.600  0.0035    99.892  1572.31
  62   0.4893     92.380  0.0020    99.936  1598.04
  63   0.5272     91.610  0.0018    99.952  1623.77
  64   0.4930     91.900  0.0018    99.946  1649.53
  65   0.5228     91.620  0.0015    99.958  1675.27
  66   0.5087     91.860  0.0013    99.962  1701.01
  67   0.4999     92.150  0.0013    99.966  1726.77
  68   0.4945     92.140  0.0010    99.978  1752.52
  69   0.4971     92.290  0.0011    99.976  1778.26
  70   0.5085     92.110  0.0008    99.976  1803.98
  71   0.5189     91.800  0.0013    99.980  1829.71
  72   0.5056     92.160  0.0009    99.988  1855.45
  73   0.4913     92.220  0.0007    99.990  1881.17
  74   0.4979     92.280  0.0008    99.980  1906.92
  75   0.5022     91.730  0.0010    99.970  1932.66
  76   0.5286     91.820  0.0009    99.978  1958.41
  77   0.5452     91.940  0.0007    99.988  1984.14
  78   0.5047     92.410  0.0007    99.982  2009.88
  79   0.5106     92.060  0.0007    99.994  2035.64
  80   0.5025     92.420  0.0007    99.990  2061.37
  81   0.4831     92.220  0.0005    99.992  2087.11
  82   0.5084     92.420  0.0005    99.998  2112.83
  83   0.5149     92.040  0.0005    99.996  2138.58
  84   0.4887     92.280  0.0006    99.986  2164.38
  85   0.5288     92.210  0.0006    99.992  2190.11
