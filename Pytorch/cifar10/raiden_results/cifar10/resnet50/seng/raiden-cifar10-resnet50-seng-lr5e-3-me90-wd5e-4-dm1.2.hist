Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet50', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 29436831232 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7720     34.170  2.0021    25.826  28.58
   2   1.5053     44.920  1.6287    39.300  54.36
   3   1.3539     51.010  1.4467    46.726  80.12
   4   1.2293     55.460  1.3183    51.956  105.89
   5   1.1514     58.910  1.2175    56.056  131.63
   6   1.1032     61.570  1.1216    59.494  157.40
   7   1.0357     63.620  1.0478    62.418  183.17
   8   0.9842     65.400  0.9795    65.054  208.95
   9   0.9199     67.440  0.9155    67.386  234.73
  10   0.8833     69.140  0.8633    69.274  260.49
  11   0.8622     70.310  0.8114    71.266  286.23
  12   0.8324     71.330  0.7704    72.632  312.00
  13   0.7794     72.450  0.7233    74.356  337.75
  14   0.7998     72.420  0.6930    75.284  363.51
  15   0.8790     72.290  0.6586    76.448  389.27
  16   0.7351     74.800  0.6244    77.802  415.02
  17   0.7245     75.480  0.6008    78.744  440.80
  18   0.6653     77.130  0.5723    79.676  466.57
  19   0.6959     76.160  0.5404    80.782  492.33
  20   0.6591     78.310  0.5126    81.768  518.11
  21   0.6555     78.310  0.4935    82.420  543.89
  22   0.6581     78.300  0.4701    83.448  569.68
  23   0.6226     79.840  0.4469    84.100  595.43
  24   0.6129     79.950  0.4307    84.698  621.18
  25   0.6128     79.920  0.4107    85.432  646.94
  26   0.6275     80.340  0.3886    86.346  672.69
  27   0.6288     80.350  0.3743    86.856  698.46
  28   0.6119     81.080  0.3609    87.270  724.22
  29   0.6043     81.280  0.3444    87.736  750.00
  30   0.6244     81.490  0.3277    88.342  775.79
  31   0.5693     82.160  0.3075    89.150  801.57
  32   0.6237     81.650  0.2999    89.374  827.36
  33   0.5959     82.780  0.2817    89.988  853.15
  34   0.6459     81.620  0.2658    90.644  878.91
  35   0.5880     82.240  0.2573    90.832  904.66
  36   0.6368     81.600  0.2414    91.352  930.39
  37   0.6281     82.140  0.2345    91.726  956.19
  38   0.5908     82.830  0.2230    92.042  981.93
  39   0.5964     82.910  0.2153    92.448  1007.71
  40   0.6244     83.100  0.2040    92.684  1033.48
  41   0.6121     83.140  0.1921    93.194  1059.25
  42   0.6339     83.240  0.1814    93.636  1085.03
  43   0.6464     83.370  0.1747    93.742  1110.78
  44   0.7050     82.500  0.1670    94.086  1136.55
  45   0.6434     83.910  0.1576    94.424  1162.31
  46   0.6829     83.160  0.1490    94.798  1188.07
  47   0.7003     83.570  0.1445    94.856  1213.84
  48   0.7168     83.300  0.1400    95.002  1239.58
  49   0.7091     83.020  0.1263    95.508  1265.34
  50   0.7502     82.540  0.1237    95.594  1290.82
  51   0.7842     82.540  0.1181    95.850  1316.60
  52   0.6981     83.430  0.1121    96.118  1342.35
  53   0.6888     84.490  0.1066    96.162  1368.14
  54   0.7233     83.670  0.1030    96.262  1393.94
  55   0.6756     84.150  0.0971    96.602  1419.70
  56   0.7233     84.030  0.0876    96.982  1445.47
  57   0.7352     84.400  0.0844    97.028  1471.24
  58   0.7567     84.590  0.0816    97.086  1497.02
  59   0.7566     84.030  0.0778    97.290  1522.79
  60   0.7432     84.500  0.0718    97.464  1548.55
  61   0.7425     84.580  0.0681    97.610  1574.32
  62   0.7954     83.730  0.0653    97.734  1600.08
  63   0.7688     84.210  0.0588    98.010  1625.86
  64   0.7946     84.650  0.0580    97.958  1651.62
  65   0.7952     84.290  0.0534    98.226  1677.40
  66   0.8498     84.230  0.0529    98.208  1703.17
  67   0.7738     84.710  0.0502    98.282  1728.92
  68   0.7698     85.390  0.0441    98.546  1754.67
  69   0.7836     85.060  0.0413    98.616  1780.47
  70   0.8617     84.070  0.0410    98.608  1806.25
  71   0.8116     84.650  0.0382    98.720  1832.03
  72   0.7663     85.220  0.0382    98.744  1857.78
  73   0.7874     85.250  0.0347    98.882  1883.56
  74   0.8786     84.230  0.0358    98.760  1909.34
  75   0.8246     84.890  0.0322    98.938  1935.11
  76   0.8275     85.220  0.0328    98.864  1960.87
  77   0.8138     84.970  0.0300    99.040  1986.63
  78   0.8503     84.750  0.0270    99.156  2012.39
  79   0.7843     85.340  0.0300    99.024  2038.17
  80   0.7922     85.720  0.0259    99.170  2063.94
  81   0.8340     85.000  0.0249    99.232  2089.71
  82   0.8857     84.760  0.0245    99.230  2115.49
  83   0.8737     85.020  0.0242    99.258  2141.22
  84   0.8742     85.240  0.0241    99.206  2166.99
  85   0.8517     85.080  0.0214    99.306  2192.73
  86   0.9133     84.640  0.0211    99.376  2218.49
  87   0.9496     83.990  0.0208    99.352  2244.27
  88   0.9813     84.510  0.0213    99.340  2270.09
  89   0.8801     85.050  0.0187    99.428  2295.86
  90   0.9828     84.340  0.0197    99.378  2321.61
