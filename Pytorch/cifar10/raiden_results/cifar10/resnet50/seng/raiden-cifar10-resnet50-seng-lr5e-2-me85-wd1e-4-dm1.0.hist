Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 29436831232 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3278     52.850  1.6349    40.492  28.72
   2   0.9662     65.270  1.1198    60.078  54.51
   3   0.7849     72.170  0.8765    69.028  80.35
   4   0.7090     75.630  0.7195    74.924  106.13
   5   0.6657     77.450  0.5990    79.004  131.94
   6   0.5673     81.410  0.5199    82.008  157.70
   7   0.5142     82.250  0.4743    83.522  183.49
   8   0.5368     82.720  0.4212    85.278  209.29
   9   0.4816     84.840  0.3845    86.642  235.07
  10   0.4720     85.000  0.3532    87.696  260.85
  11   0.4118     87.140  0.3369    88.268  286.61
  12   0.4805     85.830  0.2988    89.764  312.40
  13   0.5028     83.930  0.2810    90.256  338.21
  14   0.4374     86.560  0.2634    90.870  364.00
  15   0.4008     87.450  0.2392    91.810  389.76
  16   0.3977     87.490  0.2234    92.238  415.54
  17   0.4188     87.710  0.2083    92.670  441.31
  18   0.3981     87.880  0.1988    93.006  467.10
  19   0.4400     87.750  0.1815    93.652  492.87
  20   0.4701     87.380  0.1923    93.260  518.66
  21   0.3979     89.060  0.1655    94.066  544.44
  22   0.3975     88.960  0.1478    94.696  570.26
  23   0.4468     88.720  0.1384    95.128  596.05
  24   0.4262     88.740  0.1367    95.184  621.83
  25   0.4383     89.280  0.1357    95.206  647.65
  26   0.4320     89.440  0.1224    95.638  673.42
  27   0.4228     89.200  0.1228    95.732  699.21
  28   0.4379     89.580  0.1091    96.190  724.98
  29   0.4233     89.440  0.0903    96.882  750.75
  30   0.4123     90.000  0.0845    97.012  776.53
  31   0.4335     89.770  0.0783    97.234  802.30
  32   0.5014     89.450  0.0913    96.788  828.08
  33   0.4602     89.910  0.0786    97.230  853.87
  34   0.4283     90.530  0.0787    97.182  879.68
  35   0.4731     90.570  0.0597    97.892  905.48
  36   0.4625     89.690  0.0589    98.078  931.28
  37   0.4844     90.130  0.0536    98.152  957.06
  38   0.5076     89.960  0.0455    98.398  982.85
  39   0.4896     90.190  0.0390    98.630  1008.66
  40   0.4317     91.130  0.0369    98.744  1034.42
  41   0.4541     91.120  0.0348    98.780  1060.22
  42   0.5323     90.570  0.0354    98.792  1086.01
  43   0.4368     91.240  0.0298    98.984  1111.79
  44   0.4970     90.550  0.0337    98.838  1137.60
  45   0.4884     90.760  0.0250    99.126  1163.37
  46   0.4404     91.770  0.0230    99.260  1189.18
  47   0.5204     90.890  0.0167    99.464  1214.94
  48   0.4486     91.500  0.0147    99.512  1240.71
  49   0.4663     91.870  0.0167    99.432  1266.49
  50   0.5102     91.350  0.0112    99.644  1291.98
  51   0.4989     91.800  0.0100    99.650  1317.78
  52   0.4738     91.600  0.0069    99.782  1343.57
  53   0.5048     92.070  0.0072    99.770  1369.36
  54   0.4934     91.650  0.0088    99.708  1395.18
  55   0.4688     92.310  0.0052    99.836  1420.98
  56   0.4832     91.780  0.0046    99.862  1446.78
  57   0.4689     92.190  0.0032    99.908  1472.59
  58   0.4508     92.580  0.0031    99.906  1498.40
  59   0.4487     92.560  0.0025    99.926  1524.18
  60   0.5145     91.760  0.0018    99.960  1549.95
  61   0.4782     92.530  0.0021    99.944  1575.75
  62   0.5243     91.820  0.0021    99.936  1601.55
  63   0.4849     92.260  0.0021    99.948  1627.33
  64   0.4495     92.540  0.0023    99.952  1653.13
  65   0.4538     92.530  0.0016    99.972  1678.91
  66   0.4790     92.490  0.0013    99.976  1704.69
  67   0.5107     92.170  0.0012    99.980  1730.50
  68   0.4573     92.320  0.0012    99.966  1756.27
  69   0.4613     92.510  0.0011    99.972  1782.04
  70   0.4826     92.490  0.0010    99.978  1807.85
  71   0.4637     92.580  0.0011    99.982  1833.66
  72   0.4739     92.650  0.0009    99.986  1859.45
  73   0.4889     92.340  0.0008    99.980  1885.24
  74   0.4601     92.470  0.0009    99.984  1911.04
  75   0.4659     92.860  0.0009    99.984  1936.83
  76   0.4717     92.730  0.0009    99.978  1962.62
  77   0.5055     92.340  0.0009    99.986  1988.41
  78   0.4719     92.570  0.0006    99.996  2014.21
  79   0.4926     92.550  0.0009    99.982  2040.04
  80   0.4907     92.240  0.0008    99.988  2065.83
  81   0.4726     92.640  0.0007    99.988  2091.63
  82   0.4622     92.600  0.0005    99.998  2117.42
  83   0.5027     92.690  0.0007    99.990  2143.21
  84   0.4618     92.540  0.0005    99.994  2169.00
  85   0.4513     92.760  0.0006    99.992  2194.76
