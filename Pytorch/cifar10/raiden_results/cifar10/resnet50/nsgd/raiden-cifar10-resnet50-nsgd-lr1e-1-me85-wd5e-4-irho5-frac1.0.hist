Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet50', '--lr-decay-epoch', '85', '--frac', '1.0', '--bh', '256', '--irho', '5', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 40265972736 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3325     10.000  4.2171    10.062  2394.46
   2   2.3089     10.000  2.3085    10.080  4779.73
   3   2.3078     10.000  2.3085    10.068  7164.90
   4   2.3108     10.010  2.3068    10.074  9550.13
   5   2.3291     10.060  2.3070     9.656  11935.05
   6   2.3075      9.980  2.3078     9.856  14320.22
   7   2.3078     10.000  2.3069     9.958  16705.13
   8   2.3500     10.010  2.3074    10.048  19090.11
   9   2.3079     10.000  2.3073     9.806  21475.17
  10   2.3299     10.010  2.3068    10.094  23860.42
  11   2.3061     10.000  2.3069    10.098  26245.80
  12   2.3088     10.000  2.3075     9.782  28630.82
  13   2.3425      9.900  2.3069     9.968  31015.97
  14   2.3193     12.860  2.3062    10.104  33401.23
  15   2.1905     19.350  2.0964    18.636  35786.34
  16   1.8050     31.170  1.9153    23.854  38177.11
  17   1.6927     38.540  1.7082    34.666  40563.18
  18   1.4702     45.760  1.5326    42.642  42948.41
  19   1.2516     54.680  1.3584    50.312  45333.69
  20   1.1762     57.790  1.2128    56.152  47719.33
  21   1.0534     63.260  1.0740    61.572  50104.47
  22   0.9134     68.570  0.9440    66.552  52489.71
  23   0.7698     73.600  0.8500    70.180  54874.75
  24   0.7884     73.300  0.7441    74.104  57259.97
  25   0.6415     77.790  0.6705    76.504  59648.34
  26   0.6610     77.980  0.6196    78.650  62034.52
  27   0.6252     78.790  0.5780    80.310  64420.94
  28   0.5989     79.540  0.5378    81.272  66807.61
  29   0.5124     82.900  0.5144    82.232  69194.59
  30   0.5483     80.960  0.4866    83.182  71581.50
  31   0.5051     83.040  0.4600    84.230  73965.95
  32   0.5440     81.630  0.4423    84.846  76352.41
  33   0.5158     82.650  0.4266    85.122  78737.04
  34   0.4641     84.340  0.4069    85.952  81123.47
  35   0.4575     84.890  0.3914    86.432  83509.33
  36   0.4883     83.690  0.3783    86.930  85895.66
