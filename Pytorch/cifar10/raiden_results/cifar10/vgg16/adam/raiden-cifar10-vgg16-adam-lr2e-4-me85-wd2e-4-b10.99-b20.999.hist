Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8381     26.560  2.0475    18.332  6.95
   2   1.6478     34.090  1.7647    29.144  12.29
   3   1.4976     42.440  1.5979    36.928  17.63
   4   1.4148     45.840  1.4830    43.370  22.96
   5   1.2649     53.160  1.3375    49.554  28.32
   6   1.1263     58.910  1.1972    55.720  33.64
   7   1.0695     61.640  1.0782    61.270  38.96
   8   0.9537     65.650  1.0020    64.446  44.28
   9   0.8738     69.390  0.9082    67.992  49.60
  10   0.7847     72.490  0.8182    71.318  54.93
  11   0.7946     72.970  0.7701    73.450  60.32
  12   0.7513     74.620  0.7222    75.104  65.68
  13   0.6932     76.620  0.6904    76.354  70.99
  14   0.6753     77.420  0.6291    78.482  76.32
  15   0.6548     78.110  0.5975    79.732  81.67
  16   0.6361     79.240  0.5702    80.766  86.99
  17   0.6212     79.340  0.5312    82.000  92.40
  18   0.6056     79.430  0.5190    82.528  97.74
  19   0.5897     81.460  0.4880    83.642  103.06
  20   0.5625     82.330  0.4646    84.432  108.41
  21   0.5501     82.610  0.4389    85.444  113.73
  22   0.5638     82.180  0.4258    85.904  119.05
  23   0.5374     82.770  0.4168    86.016  124.38
  24   0.5329     82.960  0.3785    87.458  129.77
  25   0.5497     83.330  0.3628    87.964  135.13
  26   0.5339     83.260  0.3661    87.766  140.45
  27   0.5010     83.850  0.3520    88.480  145.78
  28   0.5197     84.330  0.3218    89.272  151.10
  29   0.5214     84.850  0.3150    89.578  156.42
  30   0.4932     84.800  0.3095    89.708  161.84
  31   0.4741     85.740  0.2819    90.666  167.18
  32   0.5326     84.250  0.2932    90.132  172.51
  33   0.4861     85.180  0.2758    90.868  177.86
  34   0.5013     84.890  0.2724    91.020  183.19
  35   0.5252     84.410  0.2515    91.680  188.52
  36   0.5091     85.460  0.2395    91.954  193.91
  37   0.5403     84.510  0.2529    91.706  199.24
  38   0.5639     84.040  0.2433    91.976  204.58
  39   0.5244     85.050  0.2338    92.278  209.90
  40   0.5118     85.910  0.2161    92.922  215.22
  41   0.5153     85.360  0.1998    93.492  220.54
  42   0.5085     86.200  0.2047    93.348  225.86
  43   0.5131     85.830  0.1939    93.560  231.26
  44   0.5246     85.930  0.1913    93.650  236.58
  45   0.5253     85.620  0.1868    93.790  241.92
  46   0.5330     86.130  0.1762    94.224  247.26
  47   0.5135     86.550  0.1646    94.636  252.57
  48   0.5322     86.230  0.1626    94.740  257.92
  49   0.5061     86.330  0.1664    94.632  263.26
  50   0.5263     85.520  0.1626    94.650  268.63
  51   0.5501     86.280  0.1550    94.956  273.95
  52   0.5111     86.540  0.1542    94.950  279.28
  53   0.5277     86.360  0.1498    95.082  284.64
  54   0.5435     86.980  0.1389    95.440  289.97
  55   0.5155     86.780  0.1318    95.656  295.29
  56   0.5484     86.760  0.1354    95.584  300.61
  57   0.5269     86.760  0.1308    95.768  306.05
  58   0.5161     86.750  0.1259    95.922  311.36
  59   0.5548     86.880  0.1151    96.356  316.70
  60   0.5427     86.540  0.1171    96.186  322.04
  61   0.5556     86.820  0.1275    95.944  327.36
  62   0.5196     86.920  0.1334    95.702  332.67
  63   0.5351     87.210  0.1126    96.304  338.09
  64   0.5880     86.740  0.1126    96.358  343.44
  65   0.5647     86.600  0.1090    96.424  348.76
  66   0.5729     86.000  0.1093    96.398  354.10
  67   0.5631     86.800  0.1110    96.366  359.45
  68   0.5532     86.690  0.1114    96.418  364.79
  69   0.5242     87.290  0.1021    96.776  370.16
  70   0.5658     86.890  0.1047    96.682  375.51
  71   0.5710     86.830  0.1054    96.520  380.88
  72   0.5540     87.000  0.0964    96.812  386.24
  73   0.5296     86.780  0.0879    97.082  391.56
  74   0.5296     87.290  0.0910    97.046  396.91
  75   0.5794     86.880  0.0821    97.300  402.31
  76   0.5459     87.490  0.0840    97.310  407.65
  77   0.5487     87.270  0.0926    97.074  413.00
  78   0.5220     87.750  0.0914    97.168  418.32
  79   0.5486     86.860  0.0815    97.254  423.67
  80   0.5375     87.270  0.0887    97.078  429.01
  81   0.5403     87.590  0.0804    97.392  434.34
  82   0.5625     87.230  0.0788    97.478  439.67
  83   0.5468     87.620  0.0911    97.034  445.01
  84   0.5696     87.720  0.0768    97.502  450.37
  85   0.5662     87.410  0.0810    97.406  455.72
