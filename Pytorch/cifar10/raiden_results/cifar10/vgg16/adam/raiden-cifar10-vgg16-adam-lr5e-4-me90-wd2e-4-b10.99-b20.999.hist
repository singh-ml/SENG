Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0417     18.570  2.2310    15.036  6.91
   2   1.8874     21.970  1.9552    19.742  12.27
   3   1.7911     28.170  1.8577    23.428  17.72
   4   1.6687     35.000  1.7504    30.266  23.07
   5   1.5452     41.030  1.6332    35.784  28.40
   6   1.4599     45.170  1.5227    41.490  33.77
   7   1.3566     48.870  1.4245    46.310  39.10
   8   1.2703     53.110  1.3552    49.426  44.43
   9   1.2217     56.190  1.2541    53.864  49.83
  10   1.1511     58.950  1.1621    58.184  55.20
  11   1.0186     64.920  1.0745    61.846  60.52
  12   0.9457     66.540  0.9851    65.206  65.87
  13   0.8823     69.350  0.9100    67.964  71.20
  14   0.8388     71.480  0.8646    69.508  76.56
  15   0.8205     71.620  0.8094    71.950  81.92
  16   0.7476     74.000  0.7692    73.410  87.35
  17   0.7564     74.680  0.7203    75.234  92.67
  18   0.6861     77.010  0.6909    76.406  97.99
  19   0.6829     77.430  0.6681    77.284  103.34
  20   0.6510     78.360  0.6204    78.870  108.73
  21   0.6220     79.680  0.6296    78.940  114.10
  22   0.6220     79.960  0.5846    80.346  119.49
  23   0.6090     80.560  0.5653    81.120  124.87
  24   0.5868     80.620  0.5306    82.190  130.19
  25   0.6160     80.290  0.5268    82.428  135.52
  26   0.5757     81.240  0.4986    83.476  140.93
  27   0.5788     81.500  0.4737    84.274  146.30
  28   0.5390     82.450  0.4824    83.914  151.72
  29   0.5270     82.640  0.4594    84.762  157.06
  30   0.5471     82.480  0.4427    85.092  162.38
  31   0.5706     81.570  0.4198    86.138  167.74
  32   0.5127     83.610  0.4167    86.228  173.08
  33   0.5146     84.000  0.3984    86.884  178.40
  34   0.5152     83.680  0.4098    86.584  183.73
  35   0.5132     83.590  0.4015    86.816  189.11
  36   0.5443     83.240  0.3907    87.298  194.46
  37   0.5325     83.710  0.3825    87.448  199.80
  38   0.5125     84.240  0.3632    88.174  205.15
  39   0.4982     84.660  0.3612    88.156  210.51
  40   0.5292     84.420  0.3497    88.382  215.86
  41   0.4717     85.110  0.3377    89.082  221.29
  42   0.5144     84.310  0.3333    89.044  226.62
  43   0.4943     84.850  0.3272    89.032  231.96
  44   0.4780     85.570  0.3127    89.694  237.30
  45   0.5142     84.250  0.3113    89.782  242.65
  46   0.4924     85.320  0.3054    90.058  247.97
  47   0.4945     85.610  0.3038    89.886  253.33
  48   0.4940     85.430  0.2993    90.126  258.73
  49   0.4884     85.260  0.2904    90.314  264.09
  50   0.5052     84.680  0.2880    90.610  269.45
  51   0.4959     85.300  0.2847    90.724  274.78
  52   0.4908     85.300  0.2785    90.872  280.10
  53   0.4822     85.830  0.2701    91.162  285.48
  54   0.4700     85.660  0.2766    90.924  290.81
  55   0.4838     85.810  0.2726    91.178  296.23
  56   0.4515     86.350  0.2673    91.180  301.60
  57   0.4776     85.510  0.2574    91.674  306.92
  58   0.4680     86.400  0.2495    91.874  312.30
  59   0.4776     85.870  0.2510    91.816  317.64
  60   0.4691     85.740  0.2487    91.924  323.00
  61   0.4834     85.520  0.2546    91.722  328.42
  62   0.4516     86.630  0.2516    91.706  333.76
  63   0.4570     86.710  0.2330    92.404  339.10
  64   0.4814     86.120  0.2400    92.110  344.47
  65   0.4706     86.020  0.2344    92.260  349.85
  66   0.4771     86.870  0.2362    92.246  355.21
  67   0.4629     86.270  0.2235    92.794  360.65
  68   0.4557     86.170  0.2377    92.384  366.02
  69   0.4905     85.740  0.2232    92.782  371.39
  70   0.4600     86.540  0.2112    93.168  376.74
  71   0.5059     86.320  0.2107    93.048  382.10
  72   0.4577     86.630  0.2260    92.584  387.47
  73   0.4956     86.850  0.2173    92.944  392.79
  74   0.4822     86.850  0.2088    93.276  398.22
  75   0.4871     85.770  0.2102    93.126  403.58
  76   0.4804     86.630  0.2118    92.938  408.93
  77   0.4824     86.650  0.2108    93.164  414.26
  78   0.5224     86.840  0.1930    93.748  419.62
  79   0.5015     86.440  0.2001    93.460  425.00
  80   0.4925     86.310  0.1965    93.688  430.42
  81   0.5332     86.330  0.2048    93.434  435.76
  82   0.4558     87.100  0.1898    93.762  441.10
  83   0.4839     86.520  0.1888    93.944  446.48
  84   0.5097     86.420  0.1842    93.976  451.80
  85   0.4896     86.890  0.1818    94.160  457.15
  86   0.5066     86.020  0.1868    93.936  462.57
  87   0.5276     86.750  0.1833    94.082  467.93
  88   0.5149     87.080  0.1800    94.212  473.31
  89   0.4818     86.680  0.1786    94.196  478.67
  90   0.5135     86.540  0.1754    94.242  484.01
