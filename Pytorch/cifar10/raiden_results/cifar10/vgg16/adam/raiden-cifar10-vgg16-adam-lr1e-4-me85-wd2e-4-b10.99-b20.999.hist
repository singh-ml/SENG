Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8304     26.540  2.0855    18.794  7.12
   2   1.5938     38.590  1.7403    30.648  12.47
   3   1.5676     37.830  1.5703    38.660  17.83
   4   1.3743     47.040  1.4748    42.918  23.17
   5   1.2542     52.390  1.3518    48.810  28.49
   6   1.2275     54.740  1.2912    51.770  33.93
   7   1.0844     60.600  1.1874    56.454  39.24
   8   1.0239     63.450  1.0958    59.996  44.58
   9   0.9992     64.770  1.0174    63.492  49.90
  10   0.9338     66.720  0.9532    65.796  55.24
  11   0.8742     68.860  0.8945    68.044  60.55
  12   0.8303     70.650  0.8319    70.448  65.94
  13   0.8040     71.720  0.7959    71.772  71.28
  14   0.8151     71.940  0.7754    72.746  76.62
  15   0.7881     72.810  0.7580    73.728  81.93
  16   0.7321     74.790  0.7263    74.676  87.25
  17   0.7245     75.430  0.6624    77.090  92.56
  18   0.6885     76.590  0.6345    78.154  97.99
  19   0.6503     77.610  0.6088    79.042  103.34
  20   0.6543     78.150  0.5962    79.530  108.67
  21   0.6261     78.770  0.5623    80.736  113.99
  22   0.6145     79.230  0.5416    81.516  119.34
  23   0.6336     78.630  0.5243    81.934  124.67
  24   0.5943     80.290  0.5002    82.946  130.03
  25   0.6313     78.850  0.4656    83.962  135.46
  26   0.5796     80.510  0.4651    84.226  140.80
  27   0.6027     80.450  0.4451    84.846  146.16
  28   0.5774     81.320  0.4237    85.664  151.51
  29   0.5543     81.960  0.4014    86.342  156.82
  30   0.5615     81.980  0.3819    86.918  162.17
  31   0.5672     81.820  0.3683    87.566  167.52
  32   0.5745     81.240  0.3533    87.910  172.93
  33   0.5488     82.370  0.3414    88.360  178.31
  34   0.5505     82.410  0.3196    89.198  183.65
  35   0.5712     82.110  0.3309    88.806  188.98
  36   0.5643     81.920  0.3173    89.222  194.30
  37   0.5631     83.250  0.2923    90.180  199.62
  38   0.5672     82.680  0.2788    90.458  205.02
  39   0.5363     83.220  0.2770    90.576  210.36
  40   0.5769     83.300  0.2582    91.234  215.71
  41   0.5507     83.200  0.2520    91.418  221.06
  42   0.5481     82.880  0.2397    91.844  226.36
  43   0.6046     82.600  0.2342    91.938  231.69
  44   0.5765     83.250  0.2244    92.234  237.07
  45   0.5692     82.860  0.2199    92.578  242.39
  46   0.5713     83.400  0.2045    93.080  247.70
  47   0.5758     83.530  0.2036    93.152  253.03
  48   0.5694     83.530  0.2121    93.032  258.33
  49   0.5892     83.140  0.1971    93.264  263.68
  50   0.6086     84.020  0.1800    93.914  269.00
  51   0.5675     84.000  0.1791    93.916  274.41
  52   0.5705     83.830  0.1658    94.360  279.74
  53   0.6057     83.750  0.1555    94.782  285.11
  54   0.5995     83.970  0.1603    94.556  290.47
  55   0.6140     82.920  0.1564    94.722  295.77
  56   0.6132     84.350  0.1417    95.230  301.14
  57   0.6283     83.760  0.1395    95.228  306.46
  58   0.6192     84.450  0.1351    95.496  311.84
  59   0.6094     84.810  0.1432    95.232  317.16
  60   0.5506     84.600  0.1381    95.352  322.52
  61   0.6310     83.800  0.1402    95.426  327.89
  62   0.5885     84.630  0.1328    95.524  333.25
  63   0.6459     83.520  0.1224    95.912  338.59
  64   0.6327     84.210  0.1119    96.352  343.97
  65   0.6201     84.700  0.1064    96.376  349.31
  66   0.6377     84.280  0.1084    96.404  354.64
  67   0.6445     84.260  0.1051    96.460  359.98
  68   0.6758     84.430  0.1086    96.370  365.32
  69   0.6180     84.950  0.1027    96.498  370.63
  70   0.6196     84.600  0.1002    96.666  375.96
  71   0.6457     84.660  0.1036    96.530  381.36
  72   0.6368     84.650  0.1057    96.520  386.68
  73   0.6587     84.420  0.0885    97.064  392.03
  74   0.6298     84.800  0.0899    96.890  397.38
  75   0.6274     84.980  0.0895    97.140  402.74
  76   0.6485     84.950  0.0881    97.112  408.06
  77   0.7034     84.440  0.0838    97.126  413.48
  78   0.6527     85.180  0.0915    96.926  418.82
  79   0.6694     84.670  0.0911    96.946  424.16
  80   0.6757     84.970  0.0836    97.236  429.51
  81   0.6645     85.490  0.0808    97.368  434.87
  82   0.6401     85.260  0.0828    97.342  440.20
  83   0.6470     84.190  0.0795    97.398  445.63
  84   0.6408     84.670  0.0812    97.296  450.96
  85   0.6176     85.290  0.0756    97.446  456.30
