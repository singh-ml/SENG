Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8950     23.690  2.2002    14.056  6.93
   2   1.5719     38.150  1.7574    29.940  12.24
   3   1.4142     45.550  1.5329    39.688  17.59
   4   1.2593     54.040  1.3605    48.508  22.99
   5   1.0960     61.940  1.1868    56.580  28.34
   6   1.0146     64.380  1.0463    62.764  33.65
   7   0.8891     68.770  0.9073    68.300  38.97
   8   0.8348     71.050  0.8173    71.748  44.31
   9   0.7553     74.460  0.7586    73.794  49.64
  10   0.6625     77.220  0.6771    76.738  54.98
  11   0.6338     78.730  0.6336    78.738  60.44
  12   0.6121     79.390  0.5851    80.288  65.80
  13   0.5911     79.920  0.5509    81.472  71.15
  14   0.6016     80.150  0.5271    82.612  76.48
  15   0.5516     81.740  0.4905    83.706  81.83
  16   0.5423     82.020  0.4653    84.560  87.18
  17   0.5748     82.020  0.4376    85.544  92.62
  18   0.5417     82.230  0.4186    86.126  97.99
  19   0.5365     82.720  0.3909    87.208  103.34
  20   0.5249     83.400  0.3803    87.450  108.68
  21   0.5029     83.870  0.3626    88.062  114.06
  22   0.5045     84.160  0.3401    88.844  119.40
  23   0.5508     83.800  0.3201    89.580  124.78
  24   0.5279     84.410  0.3083    89.882  130.19
  25   0.5071     84.240  0.3001    90.104  135.55
  26   0.5011     84.870  0.2834    90.646  140.90
  27   0.5455     84.480  0.2741    91.010  146.24
  28   0.4765     85.850  0.2685    91.200  151.61
  29   0.4847     85.280  0.2540    91.618  156.96
  30   0.5005     85.120  0.2454    92.014  162.34
  31   0.5269     85.000  0.2379    92.354  167.76
  32   0.5310     85.500  0.2220    92.752  173.13
  33   0.4808     86.170  0.2123    93.172  178.49
  34   0.5144     85.310  0.2017    93.426  183.83
  35   0.6180     84.100  0.2078    93.216  189.18
  36   0.4988     85.890  0.1948    93.732  194.55
  37   0.5446     85.300  0.1840    94.040  199.97
  38   0.5367     85.320  0.1814    94.210  205.34
  39   0.4957     86.290  0.1652    94.544  210.71
  40   0.5008     86.710  0.1679    94.560  216.05
  41   0.5060     86.340  0.1600    94.738  221.40
  42   0.5918     85.590  0.1585    94.906  226.77
  43   0.5854     85.330  0.1554    94.972  232.23
  44   0.5094     86.540  0.1499    95.316  237.60
  45   0.5551     86.120  0.1459    95.328  242.97
  46   0.5799     86.180  0.1322    95.772  248.30
  47   0.5376     86.530  0.1302    95.812  253.69
  48   0.5319     86.150  0.1349    95.654  259.08
  49   0.5363     86.740  0.1309    95.772  264.53
  50   0.5725     85.860  0.1269    95.818  269.86
  51   0.5471     86.640  0.1261    95.934  275.23
  52   0.6048     86.280  0.1155    96.288  280.55
  53   0.5700     85.960  0.1176    96.252  285.89
  54   0.5986     85.930  0.1051    96.692  291.24
  55   0.5772     87.060  0.1084    96.528  296.60
  56   0.6200     85.530  0.1125    96.388  302.02
  57   0.5946     86.580  0.1095    96.470  307.37
  58   0.5426     87.160  0.1057    96.656  312.71
  59   0.5587     86.240  0.1093    96.566  318.05
  60   0.5590     86.580  0.1018    96.744  323.39
  61   0.5789     86.940  0.0960    96.928  328.78
  62   0.6298     86.300  0.0937    97.040  334.14
  63   0.5267     87.030  0.0998    96.760  339.58
  64   0.5634     87.140  0.0896    97.194  344.92
  65   0.5820     86.860  0.0879    97.288  350.27
  66   0.6550     85.940  0.0867    97.216  355.60
  67   0.5797     86.900  0.0855    97.284  360.95
  68   0.5665     86.480  0.0826    97.440  366.30
  69   0.6355     86.930  0.0809    97.444  371.72
  70   0.5966     87.170  0.0845    97.324  377.06
  71   0.5917     87.070  0.0866    97.354  382.41
  72   0.6468     86.890  0.0821    97.428  387.75
  73   0.6129     86.310  0.0878    97.268  393.10
  74   0.6545     86.260  0.0792    97.548  398.46
  75   0.6129     87.160  0.0777    97.660  403.88
  76   0.6361     87.020  0.0749    97.662  409.25
  77   0.5687     87.410  0.0776    97.654  414.62
  78   0.5761     87.760  0.0780    97.516  419.98
  79   0.5597     87.820  0.0698    97.826  425.31
  80   0.5978     86.740  0.0764    97.736  430.67
  81   0.5992     86.690  0.0707    97.832  436.04
  82   0.5825     87.290  0.0702    97.848  441.48
  83   0.6365     86.930  0.0697    97.862  446.84
  84   0.6128     87.390  0.0672    97.868  452.18
  85   0.5590     87.760  0.0713    97.760  457.51
  86   0.7197     86.130  0.0690    97.804  462.88
  87   0.5986     86.380  0.0684    97.888  468.24
  88   0.6228     87.140  0.0656    97.938  473.67
  89   0.6134     87.560  0.0622    98.092  479.00
  90   0.6334     87.210  0.0698    97.788  484.35
