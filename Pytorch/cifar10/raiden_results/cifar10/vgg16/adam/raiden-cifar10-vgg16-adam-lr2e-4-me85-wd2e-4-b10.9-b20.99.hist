Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9051     19.970  2.0539    16.842  6.94
   2   1.5580     38.020  1.7695    27.940  12.31
   3   1.4844     44.250  1.4977    42.728  17.65
   4   1.2447     55.600  1.2806    52.516  22.97
   5   1.0633     62.500  1.1203    59.626  28.27
   6   0.9688     66.200  1.0095    63.782  33.58
   7   0.9162     67.610  0.9117    67.780  38.92
   8   0.7661     73.800  0.8435    70.274  44.33
   9   0.7941     73.290  0.7764    73.102  49.64
  10   0.7047     75.590  0.7292    74.864  54.95
  11   0.7088     76.310  0.6810    76.560  60.25
  12   0.7202     76.470  0.6536    77.766  65.59
  13   0.6709     78.540  0.6042    79.490  70.91
  14   0.6846     77.460  0.5764    80.608  76.33
  15   0.6350     78.770  0.5472    81.366  81.64
  16   0.5942     80.850  0.5185    82.582  86.98
  17   0.5821     80.960  0.4999    83.302  92.29
  18   0.5572     82.170  0.4719    84.198  97.66
  19   0.6013     81.740  0.4432    84.940  103.00
  20   0.5499     82.310  0.4287    85.642  108.32
  21   0.5492     82.520  0.4147    86.224  113.73
  22   0.5249     83.240  0.3911    86.814  119.07
  23   0.5287     83.360  0.3738    87.770  124.39
  24   0.5156     83.950  0.3563    88.096  129.75
  25   0.5024     84.140  0.3444    88.516  135.10
  26   0.5329     83.410  0.3261    89.332  140.44
  27   0.5207     84.140  0.3150    89.440  145.76
  28   0.5275     83.780  0.3017    90.012  151.17
  29   0.5218     84.550  0.2882    90.408  156.52
  30   0.5079     84.700  0.2802    90.704  161.85
  31   0.5154     84.600  0.2666    91.180  167.20
  32   0.5821     83.030  0.2529    91.650  172.51
  33   0.5534     84.430  0.2427    91.904  177.83
  34   0.5161     85.280  0.2408    92.136  183.17
  35   0.5571     84.750  0.2230    92.558  188.62
  36   0.5544     85.060  0.2228    92.710  193.96
  37   0.5259     85.320  0.2095    93.108  199.31
  38   0.4735     86.180  0.2097    93.030  204.68
  39   0.4996     85.490  0.1981    93.418  210.02
  40   0.4833     85.780  0.1910    93.710  215.34
  41   0.5312     85.640  0.1910    93.784  220.72
  42   0.5223     85.690  0.1801    94.222  226.04
  43   0.5484     85.210  0.1767    94.252  231.38
  44   0.5228     85.650  0.1682    94.538  236.71
  45   0.5333     86.170  0.1600    94.736  242.03
  46   0.5720     85.860  0.1658    94.656  247.34
  47   0.5542     85.630  0.1553    94.946  252.75
  48   0.5623     85.770  0.1451    95.274  258.09
  49   0.4959     86.800  0.1487    95.158  263.43
  50   0.5296     86.420  0.1373    95.492  268.76
  51   0.5532     85.380  0.1350    95.676  274.08
  52   0.5737     85.930  0.1286    95.804  279.39
  53   0.5621     86.160  0.1332    95.740  284.83
  54   0.5455     86.240  0.1280    95.932  290.15
  55   0.5644     86.160  0.1235    95.936  295.47
  56   0.5581     85.990  0.1145    96.262  300.80
  57   0.5551     86.450  0.1151    96.162  306.12
  58   0.5568     86.640  0.1103    96.416  311.47
  59   0.5285     86.720  0.1140    96.266  316.83
  60   0.5630     86.480  0.1076    96.536  322.25
  61   0.6020     86.840  0.1101    96.508  327.56
  62   0.5818     86.190  0.1041    96.560  332.88
  63   0.5374     87.390  0.0992    96.814  338.21
  64   0.5740     86.820  0.1061    96.496  343.54
  65   0.6171     86.080  0.0980    96.828  348.84
  66   0.6066     85.760  0.0927    97.050  354.23
  67   0.5634     86.850  0.0984    96.860  359.56
  68   0.5923     87.090  0.0971    96.906  364.88
  69   0.6042     86.270  0.0892    97.096  370.23
  70   0.6084     86.620  0.0861    97.240  375.55
  71   0.5718     86.540  0.0890    97.148  380.88
  72   0.6123     87.020  0.0899    97.148  386.19
  73   0.5814     87.110  0.0880    97.182  391.62
  74   0.5655     87.250  0.0818    97.356  396.95
  75   0.6018     86.140  0.0877    97.280  402.27
  76   0.5722     87.130  0.0872    97.296  407.58
  77   0.5542     87.310  0.0795    97.412  412.93
  78   0.5584     87.180  0.0841    97.416  418.26
  79   0.5729     87.630  0.0728    97.680  423.63
  80   0.6061     86.260  0.0778    97.500  428.97
  81   0.6123     86.840  0.0700    97.744  434.30
  82   0.6419     86.640  0.0767    97.514  439.61
  83   0.6386     86.590  0.0740    97.592  444.92
  84   0.5632     87.440  0.0756    97.640  450.29
  85   0.5501     87.860  0.0669    97.822  455.69
