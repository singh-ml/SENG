Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4041537024 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9940     18.550  2.2668    13.332  7.07
   2   1.8625     21.890  1.9231    20.058  12.40
   3   1.8163     24.990  1.8654    23.088  17.74
   4   1.7734     27.580  1.8162    25.504  23.06
   5   1.7294     32.390  1.7726    28.320  28.37
   6   1.5431     40.730  1.6193    36.446  33.71
   7   1.5029     42.920  1.5190    41.100  39.14
   8   1.4780     44.490  1.4352    44.952  44.46
   9   1.2720     52.080  1.3486    48.572  49.78
  10   1.2799     51.390  1.3072    50.436  55.12
  11   1.1820     57.310  1.2250    54.516  60.46
  12   1.1241     60.110  1.1370    58.720  65.77
  13   1.0689     62.570  1.0949    60.720  71.11
  14   1.0256     63.340  1.0376    63.022  76.43
  15   0.9779     65.710  0.9864    64.880  81.74
  16   0.9409     67.860  0.9371    67.054  87.08
  17   0.9103     68.760  0.9027    68.634  92.39
  18   0.9065     69.170  0.8926    69.344  97.73
  19   0.9461     67.880  0.8851    69.750  103.08
  20   0.8343     71.350  0.8149    71.888  108.49
  21   0.8198     72.500  0.7736    73.348  113.83
  22   0.7738     74.240  0.7604    73.934  119.14
  23   0.7167     75.910  0.7012    76.056  124.48
  24   0.7227     76.230  0.6825    76.696  129.83
  25   0.6948     76.680  0.6657    77.596  135.19
  26   0.6994     76.560  0.6344    78.764  140.57
  27   0.6760     77.490  0.6143    79.472  145.89
  28   0.6793     78.250  0.5919    80.248  151.22
  29   0.6314     79.300  0.5776    80.802  156.59
  30   0.6223     79.470  0.5521    81.708  161.95
  31   0.6376     79.160  0.5556    81.688  167.27
  32   0.5893     80.920  0.5281    82.534  172.66
  33   0.5713     81.230  0.5060    83.138  177.98
  34   0.5977     80.890  0.4905    83.900  183.28
  35   0.5893     80.760  0.4910    83.954  188.60
  36   0.5728     81.470  0.4686    84.612  193.93
  37   0.5702     81.320  0.4518    85.296  199.28
  38   0.5681     82.260  0.4577    84.974  204.60
  39   0.5373     83.070  0.4377    85.874  210.02
  40   0.5606     82.330  0.4211    86.180  215.34
  41   0.5259     83.600  0.4088    86.602  220.68
  42   0.5463     83.080  0.4100    86.630  226.01
  43   0.5109     84.190  0.4013    86.818  231.31
  44   0.5280     83.930  0.3887    87.326  236.62
  45   0.5265     83.700  0.3730    87.842  241.94
  46   0.5384     83.750  0.3790    87.524  247.36
  47   0.5245     84.330  0.3702    88.166  252.71
  48   0.5116     84.340  0.3713    87.824  258.01
  49   0.5033     84.780  0.3557    88.258  263.35
  50   0.4873     85.130  0.3364    88.940  268.66
  51   0.4766     85.150  0.3346    88.970  273.98
  52   0.4883     85.230  0.3270    89.372  279.37
  53   0.5136     84.490  0.3246    89.506  284.71
  54   0.5102     84.860  0.3275    89.270  290.05
  55   0.5360     84.460  0.3214    89.608  295.39
  56   0.4933     85.250  0.3124    89.720  300.72
  57   0.5038     85.390  0.3051    90.026  306.09
  58   0.4900     85.060  0.3039    90.144  311.52
  59   0.4794     85.320  0.2980    90.344  316.86
  60   0.5112     84.780  0.2951    90.280  322.18
  61   0.4839     85.360  0.2903    90.466  327.51
  62   0.5192     85.900  0.2805    90.876  332.86
  63   0.5046     85.600  0.2830    90.860  338.18
  64   0.4877     85.690  0.2726    91.190  343.61
  65   0.5145     85.660  0.2648    91.476  348.93
  66   0.4898     85.730  0.2609    91.578  354.26
  67   0.4813     85.990  0.2550    91.710  359.58
  68   0.4835     85.850  0.2564    91.700  364.90
  69   0.4824     85.480  0.2629    91.446  370.23
  70   0.4771     86.170  0.2600    91.570  375.57
  71   0.4864     86.040  0.2448    92.062  380.98
  72   0.4971     85.350  0.2468    91.914  386.33
  73   0.4960     86.070  0.2477    91.834  391.63
  74   0.4985     86.280  0.2383    92.300  396.95
  75   0.4730     86.370  0.2369    92.360  402.28
  76   0.4956     86.160  0.2336    92.372  407.60
  77   0.4893     86.250  0.2377    92.326  412.95
  78   0.4711     86.700  0.2332    92.424  418.34
  79   0.4872     85.860  0.2230    92.784  423.66
  80   0.5351     85.120  0.2235    92.782  428.97
  81   0.4975     86.160  0.2153    92.966  434.30
  82   0.4542     87.060  0.2182    92.908  439.69
  83   0.5099     86.030  0.2240    92.702  445.05
  84   0.5030     87.160  0.2187    92.966  450.41
  85   0.4924     86.820  0.2116    93.220  455.80
