Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7798     27.930  2.0383    17.838  6.95
   2   1.4978     43.240  1.6751    34.404  12.27
   3   1.2262     54.740  1.4114    46.886  17.58
   4   1.1049     59.830  1.1918    56.538  22.90
   5   0.9736     65.850  1.0445    62.942  28.34
   6   0.8964     69.170  0.9277    67.354  33.69
   7   0.7886     72.790  0.8406    70.508  39.01
   8   0.7637     73.720  0.7647    73.466  44.31
   9   0.6937     76.410  0.7135    75.448  49.66
  10   0.6783     77.370  0.6653    77.420  54.98
  11   0.6583     78.350  0.6247    78.810  60.32
  12   0.6052     80.050  0.5835    80.210  65.76
  13   0.5661     81.350  0.5458    81.610  71.12
  14   0.5889     80.770  0.5182    82.610  76.45
  15   0.5848     81.330  0.4859    83.780  81.76
  16   0.5961     80.870  0.4698    84.256  87.12
  17   0.5676     82.440  0.4393    85.386  92.43
  18   0.5360     82.520  0.4164    86.116  97.82
  19   0.5505     83.070  0.3902    86.996  103.15
  20   0.5294     82.790  0.3760    87.514  108.51
  21   0.5092     83.820  0.3547    88.082  113.84
  22   0.5380     82.930  0.3506    88.320  119.18
  23   0.5035     84.420  0.3226    89.326  124.50
  24   0.5125     84.720  0.3094    89.732  129.90
  25   0.5018     84.650  0.3000    89.976  135.21
  26   0.5425     84.250  0.2838    90.598  140.54
  27   0.5198     84.760  0.2701    90.992  145.90
  28   0.5125     85.000  0.2611    91.354  151.21
  29   0.5655     84.290  0.2461    91.846  156.56
  30   0.5039     85.790  0.2404    92.060  161.87
  31   0.5505     85.350  0.2277    92.422  167.18
  32   0.4905     85.320  0.2128    93.048  172.55
  33   0.5140     85.890  0.2087    93.086  177.88
  34   0.5054     85.560  0.2000    93.420  183.19
  35   0.5493     84.760  0.1961    93.566  188.52
  36   0.5350     85.580  0.1901    93.678  193.88
  37   0.5265     85.760  0.1759    94.090  199.20
  38   0.5429     85.180  0.1728    94.224  204.62
  39   0.5561     85.770  0.1666    94.454  209.97
  40   0.5596     85.920  0.1588    94.758  215.29
  41   0.5610     86.050  0.1558    94.848  220.62
  42   0.5585     85.760  0.1521    94.856  225.96
  43   0.5222     85.750  0.1477    95.100  231.31
  44   0.5471     86.200  0.1426    95.282  236.71
  45   0.5228     86.550  0.1343    95.596  242.05
  46   0.5245     86.120  0.1319    95.632  247.37
  47   0.5395     86.410  0.1237    95.886  252.70
  48   0.5533     86.290  0.1260    95.896  258.03
  49   0.5567     86.120  0.1138    96.230  263.39
  50   0.5257     86.570  0.1162    96.220  268.78
  51   0.5573     86.600  0.1136    96.326  274.15
  52   0.5480     86.690  0.1120    96.418  279.48
  53   0.5544     86.400  0.1074    96.596  284.84
  54   0.6203     85.440  0.1057    96.592  290.17
  55   0.5600     86.150  0.1097    96.472  295.50
  56   0.5776     86.340  0.1039    96.670  300.90
  57   0.5665     86.560  0.0955    96.924  306.21
  58   0.5499     87.030  0.0991    96.720  311.54
  59   0.6062     86.870  0.0900    97.064  316.89
  60   0.5823     86.290  0.0888    97.090  322.22
  61   0.5243     86.970  0.0890    97.168  327.56
  62   0.5963     86.930  0.0892    97.168  332.94
  63   0.5952     86.900  0.0886    97.198  338.32
  64   0.7009     85.970  0.0820    97.358  343.67
  65   0.6193     86.460  0.0839    97.216  348.99
  66   0.5930     86.600  0.0840    97.300  354.37
  67   0.6428     86.210  0.0755    97.558  359.72
  68   0.6178     86.810  0.0785    97.510  365.07
  69   0.5610     87.010  0.0750    97.636  370.40
  70   0.5441     87.240  0.0741    97.582  375.73
  71   0.6031     86.980  0.0735    97.630  381.13
  72   0.6040     86.720  0.0757    97.564  386.49
  73   0.6204     86.910  0.0681    97.806  391.82
  74   0.5577     87.470  0.0779    97.568  397.17
  75   0.5653     87.370  0.0718    97.752  402.53
  76   0.6366     86.520  0.0661    97.842  407.86
  77   0.5356     87.090  0.0682    97.868  413.17
  78   0.5640     86.550  0.0683    97.830  418.49
  79   0.6113     87.240  0.0724    97.680  423.83
  80   0.6244     86.810  0.0684    97.824  429.17
  81   0.5884     86.950  0.0691    97.814  434.51
  82   0.6238     86.340  0.0656    97.910  439.83
  83   0.6294     86.750  0.0620    98.098  445.22
  84   0.5700     87.240  0.0602    98.070  450.54
  85   0.6072     86.650  0.0661    97.844  455.89
