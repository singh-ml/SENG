Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7909     28.500  2.0482    19.054  6.99
   2   1.6456     34.490  1.7690    29.202  12.36
   3   1.5165     41.490  1.6173    36.696  17.68
   4   1.4625     44.240  1.5074    41.990  22.99
   5   1.2656     52.700  1.3886    47.598  28.32
   6   1.2141     55.340  1.2696    52.766  33.65
   7   1.1461     58.210  1.2270    54.958  38.98
   8   1.0963     60.220  1.1300    58.600  44.29
   9   0.9965     64.420  1.0512    61.756  49.72
  10   0.9641     65.580  0.9908    64.384  55.06
  11   0.9058     67.550  0.9317    66.544  60.36
  12   0.8902     69.210  0.8890    68.300  65.67
  13   0.7990     72.070  0.8440    70.320  70.99
  14   0.7859     72.400  0.8030    71.632  76.32
  15   0.7887     72.560  0.7620    73.080  81.72
  16   0.7350     74.700  0.7281    74.502  87.04
  17   0.7164     75.190  0.6856    76.068  92.36
  18   0.6999     75.900  0.6855    75.970  97.67
  19   0.6829     77.080  0.6416    77.872  102.99
  20   0.6386     78.110  0.5927    79.556  108.31
  21   0.6522     77.830  0.5805    80.056  113.62
  22   0.6362     78.670  0.5576    80.846  119.05
  23   0.6347     78.460  0.5195    82.054  124.38
  24   0.5983     79.920  0.5194    82.032  129.70
  25   0.5919     80.250  0.4983    82.864  135.01
  26   0.5894     80.790  0.4913    83.162  140.34
  27   0.6167     79.310  0.4616    84.068  145.66
  28   0.5766     81.080  0.4509    84.350  151.06
  29   0.5534     81.520  0.4142    85.728  156.38
  30   0.5827     81.320  0.4035    86.152  161.72
  31   0.5492     82.340  0.3989    86.238  167.05
  32   0.5432     82.380  0.3709    87.238  172.40
  33   0.5625     81.610  0.3612    87.608  177.71
  34   0.5427     82.980  0.3395    88.356  183.12
  35   0.5408     82.550  0.3410    88.284  188.44
  36   0.5530     82.470  0.3225    88.962  193.80
  37   0.5491     82.970  0.3174    89.100  199.16
  38   0.5581     82.300  0.2940    90.010  204.51
  39   0.5557     82.490  0.2933    89.998  209.83
  40   0.5485     82.750  0.2800    90.470  215.15
  41   0.5678     82.920  0.2703    90.616  220.56
  42   0.5580     83.650  0.2572    91.320  225.89
  43   0.5309     84.000  0.2430    91.630  231.23
  44   0.5420     83.710  0.2337    91.918  236.58
  45   0.5432     83.450  0.2265    92.316  241.94
  46   0.5604     83.440  0.2247    92.338  247.25
  47   0.5765     83.500  0.2149    92.642  252.65
  48   0.5695     84.050  0.2075    92.866  257.97
  49   0.5493     83.930  0.1961    93.334  263.32
  50   0.5599     84.430  0.1852    93.702  268.64
  51   0.5799     83.970  0.1896    93.494  273.99
  52   0.5648     83.950  0.1800    93.824  279.35
  53   0.5456     84.290  0.1719    94.002  284.71
  54   0.5843     84.410  0.1634    94.544  290.07
  55   0.5693     83.690  0.1701    94.236  295.43
  56   0.5722     83.910  0.1650    94.436  300.77
  57   0.5808     84.570  0.1517    94.834  306.12
  58   0.5899     83.970  0.1591    94.598  311.48
  59   0.6115     84.410  0.1431    95.078  316.82
  60   0.6040     84.150  0.1483    94.878  322.21
  61   0.6281     84.120  0.1404    95.252  327.53
  62   0.6109     84.690  0.1362    95.448  332.85
  63   0.6023     84.620  0.1267    95.676  338.17
  64   0.5921     84.520  0.1287    95.628  343.53
  65   0.6311     84.250  0.1242    95.728  348.86
  66   0.6188     84.820  0.1185    95.988  354.18
  67   0.6182     84.890  0.1228    95.888  359.50
  68   0.6222     84.740  0.1250    95.754  364.87
  69   0.6418     84.230  0.1153    96.082  370.22
  70   0.6294     85.140  0.1095    96.280  375.58
  71   0.6056     84.710  0.1057    96.404  380.90
  72   0.6177     84.870  0.0991    96.618  386.31
  73   0.6538     84.870  0.1002    96.642  391.65
  74   0.6554     85.080  0.0971    96.672  397.00
  75   0.6339     84.850  0.0924    96.844  402.33
  76   0.6504     85.220  0.0909    96.886  407.65
  77   0.6178     85.090  0.0899    96.918  412.99
  78   0.6250     84.990  0.0892    97.018  418.38
  79   0.6845     85.080  0.0917    96.940  423.71
  80   0.6284     85.090  0.0838    97.122  429.07
  81   0.6338     85.480  0.0824    97.182  434.43
  82   0.6118     85.350  0.0879    96.990  439.75
  83   0.6235     85.500  0.0776    97.374  445.08
  84   0.6503     85.490  0.0785    97.368  450.40
  85   0.6173     85.440  0.0849    97.150  455.80
  86   0.6525     84.820  0.0744    97.472  461.14
  87   0.6614     85.220  0.0750    97.520  466.49
  88   0.6371     85.270  0.0751    97.550  471.81
  89   0.6554     84.880  0.0705    97.648  477.15
  90   0.6679     85.280  0.0761    97.384  482.49
