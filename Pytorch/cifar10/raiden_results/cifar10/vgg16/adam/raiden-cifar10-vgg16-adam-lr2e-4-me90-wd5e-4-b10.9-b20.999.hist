Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8163     25.890  2.0147    18.680  6.89
   2   1.5509     38.530  1.7021    32.630  12.28
   3   1.4124     46.620  1.4827    42.788  17.62
   4   1.1492     58.300  1.2858    52.308  22.95
   5   0.9878     64.630  1.1115    60.056  28.28
   6   0.9082     68.500  0.9846    64.994  33.59
   7   0.8522     70.750  0.8767    69.064  38.92
   8   0.8270     71.860  0.8153    71.696  44.26
   9   0.7985     72.300  0.7438    74.532  49.58
  10   0.7291     75.570  0.6971    76.234  54.90
  11   0.6982     76.130  0.6552    77.704  60.25
  12   0.6162     79.320  0.6051    79.680  65.61
  13   0.6898     77.650  0.5770    80.468  70.93
  14   0.5641     81.270  0.5536    81.346  76.30
  15   0.6344     78.770  0.5260    82.516  81.63
  16   0.5992     80.510  0.4949    83.508  86.99
  17   0.5991     81.110  0.4733    84.344  92.34
  18   0.5176     83.180  0.4517    84.880  97.68
  19   0.5542     81.870  0.4248    85.808  103.03
  20   0.5297     83.650  0.4063    86.582  108.46
  21   0.5378     82.960  0.3936    86.994  113.78
  22   0.5289     83.490  0.3690    87.812  119.13
  23   0.5292     83.680  0.3671    87.984  124.47
  24   0.5459     83.090  0.3387    88.954  129.80
  25   0.4846     85.010  0.3305    89.106  135.13
  26   0.4776     84.960  0.3170    89.640  140.47
  27   0.5294     84.370  0.3019    90.068  145.81
  28   0.5166     84.050  0.2992    90.200  151.16
  29   0.5186     84.400  0.2743    91.006  156.50
  30   0.5604     83.540  0.2701    91.158  161.86
  31   0.4634     86.050  0.2617    91.616  167.19
  32   0.4913     85.450  0.2614    91.362  172.56
  33   0.5048     85.270  0.2423    92.162  177.99
  34   0.5075     85.220  0.2351    92.334  183.32
  35   0.4879     85.400  0.2261    92.690  188.68
  36   0.5368     85.430  0.2264    92.636  194.03
  37   0.5027     85.790  0.2064    93.240  199.36
  38   0.5283     85.300  0.2076    93.280  204.73
  39   0.5811     84.460  0.2045    93.424  210.15
  40   0.5315     85.020  0.1957    93.632  215.51
  41   0.5267     85.320  0.1852    94.034  220.85
  42   0.5436     84.980  0.1911    93.902  226.18
  43   0.5298     85.700  0.1737    94.424  231.52
  44   0.4668     86.540  0.1775    94.310  236.90
  45   0.5246     85.990  0.1691    94.588  242.23
  46   0.4970     86.110  0.1728    94.394  247.70
  47   0.4953     86.650  0.1662    94.748  253.06
  48   0.5278     85.540  0.1522    95.016  258.40
  49   0.5490     86.630  0.1521    95.132  263.76
  50   0.5225     86.750  0.1417    95.454  269.11
  51   0.5006     86.280  0.1441    95.380  274.44
  52   0.5970     85.470  0.1428    95.462  279.87
  53   0.5156     86.580  0.1415    95.438  285.20
  54   0.5620     86.630  0.1313    95.740  290.51
  55   0.5647     86.400  0.1375    95.538  295.84
  56   0.5310     86.690  0.1284    95.832  301.18
  57   0.5121     86.740  0.1357    95.652  306.53
  58   0.5168     86.890  0.1313    95.802  311.92
  59   0.5487     86.500  0.1217    96.218  317.29
  60   0.5789     86.350  0.1194    96.110  322.64
  61   0.5480     86.570  0.1239    96.128  328.00
  62   0.5492     86.420  0.1206    96.186  333.37
  63   0.5613     87.120  0.1110    96.454  338.70
  64   0.5216     87.370  0.1151    96.438  344.03
  65   0.5590     86.780  0.1169    96.342  349.43
  66   0.5252     86.980  0.1107    96.504  354.75
  67   0.5102     87.230  0.1065    96.594  360.09
  68   0.5551     86.800  0.1046    96.736  365.45
  69   0.5306     86.960  0.1048    96.682  370.80
  70   0.5524     86.420  0.0992    96.850  376.14
  71   0.5260     87.660  0.0988    96.804  381.49
  72   0.5487     87.150  0.0973    96.958  386.86
  73   0.5454     87.450  0.0993    96.906  392.20
  74   0.5866     86.400  0.0928    97.044  397.56
  75   0.5312     87.450  0.0911    97.124  402.90
  76   0.5150     87.520  0.0965    97.016  408.23
  77   0.5727     86.620  0.0918    97.144  413.57
  78   0.5709     86.870  0.0965    96.932  418.96
  79   0.5894     86.050  0.0913    97.138  424.29
  80   0.5464     87.150  0.0876    97.244  429.67
  81   0.5850     86.360  0.0925    97.192  435.03
  82   0.5658     87.540  0.0863    97.320  440.37
  83   0.5861     86.560  0.0888    97.256  445.73
  84   0.5927     87.320  0.0920    97.180  451.17
  85   0.5613     87.510  0.0897    97.216  456.51
  86   0.5491     86.950  0.0909    97.148  461.84
  87   0.5509     87.210  0.0819    97.460  467.17
  88   0.5901     86.670  0.0829    97.460  472.51
  89   0.5737     87.170  0.0820    97.438  477.88
  90   0.5800     87.330  0.0798    97.596  483.31
