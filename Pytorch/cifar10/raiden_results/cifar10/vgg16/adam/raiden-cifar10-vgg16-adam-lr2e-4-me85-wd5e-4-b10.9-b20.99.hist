Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9011     20.300  2.1604    14.688  7.13
   2   1.7709     31.610  1.8427    23.946  12.49
   3   1.6295     37.740  1.6195    35.590  17.83
   4   1.3302     49.340  1.4678    43.116  23.18
   5   1.3954     51.400  1.2981    51.304  28.54
   6   1.0936     61.110  1.1504    58.014  33.87
   7   0.9752     65.710  1.0294    62.984  39.34
   8   0.9195     67.300  0.9299    66.956  44.68
   9   0.7900     72.680  0.8533    70.038  50.02
  10   0.9180     70.030  0.7949    72.426  55.38
  11   0.7748     73.270  0.7456    74.456  60.74
  12   0.7569     75.140  0.6942    76.332  66.08
  13   0.7460     74.780  0.6653    77.388  71.49
  14   0.6653     77.380  0.6245    78.878  76.83
  15   0.6066     80.040  0.5859    80.224  82.20
  16   0.6511     78.840  0.5642    81.198  87.55
  17   0.7299     77.230  0.5350    82.344  92.90
  18   0.5825     81.240  0.5069    83.230  98.28
  19   0.5747     81.630  0.4815    83.840  103.68
  20   0.5520     82.700  0.4599    84.794  109.03
  21   0.5650     82.430  0.4353    85.426  114.37
  22   0.5344     83.050  0.4116    86.404  119.74
  23   0.5150     83.690  0.3969    86.814  125.10
  24   0.5659     82.320  0.3908    87.180  130.44
  25   0.5185     84.060  0.3713    87.704  135.77
  26   0.5136     83.670  0.3510    88.570  141.14
  27   0.5559     83.800  0.3387    88.784  146.56
  28   0.5549     84.480  0.3234    89.396  151.90
  29   0.5086     84.600  0.3144    89.744  157.27
  30   0.5228     84.220  0.2908    90.442  162.66
  31   0.5243     83.630  0.2865    90.640  168.04
  32   0.5315     84.550  0.2783    90.826  173.39
  33   0.4897     84.790  0.2707    91.178  178.74
  34   0.4977     84.630  0.2622    91.364  184.18
  35   0.5178     85.010  0.2578    91.510  189.54
  36   0.4915     85.660  0.2379    92.226  194.89
  37   0.5250     84.800  0.2301    92.522  200.22
  38   0.5121     86.020  0.2252    92.684  205.56
  39   0.4946     85.600  0.2188    92.826  210.90
  40   0.4956     85.450  0.2133    93.108  216.33
  41   0.5207     86.030  0.2065    93.276  221.66
  42   0.5132     85.790  0.2078    93.286  227.01
  43   0.5261     85.130  0.1899    93.826  232.35
  44   0.4881     86.370  0.1853    93.978  237.72
  45   0.4749     85.940  0.1853    94.040  243.07
  46   0.5142     86.040  0.1815    94.194  248.47
  47   0.5189     86.070  0.1747    94.308  253.84
  48   0.5237     86.490  0.1661    94.520  259.18
  49   0.5237     86.490  0.1685    94.450  264.52
  50   0.5525     86.150  0.1524    95.032  269.88
  51   0.5148     86.080  0.1571    94.958  275.25
  52   0.4992     86.590  0.1502    95.168  280.68
  53   0.5330     86.510  0.1472    95.298  286.04
  54   0.6014     86.150  0.1424    95.420  291.43
  55   0.6089     85.480  0.1439    95.352  296.79
  56   0.4990     87.240  0.1406    95.486  302.17
  57   0.5366     86.500  0.1336    95.652  307.50
  58   0.4834     87.270  0.1314    95.798  312.87
  59   0.5412     86.790  0.1342    95.746  318.27
  60   0.5772     86.610  0.1308    95.876  323.67
  61   0.5748     86.550  0.1258    95.918  329.06
  62   0.5487     86.940  0.1263    95.954  334.42
  63   0.5180     87.010  0.1217    96.126  339.78
  64   0.5595     86.900  0.1184    96.306  345.12
  65   0.5875     87.000  0.1174    96.284  350.48
  66   0.5467     86.850  0.1172    96.306  355.87
  67   0.5781     86.500  0.1117    96.406  361.23
  68   0.5198     86.620  0.1116    96.364  366.56
  69   0.6074     86.490  0.1101    96.498  371.89
  70   0.5240     86.370  0.1077    96.554  377.22
  71   0.5614     86.590  0.1037    96.678  382.60
  72   0.5759     87.170  0.1028    96.712  388.05
  73   0.4829     87.820  0.1033    96.778  393.40
  74   0.6077     86.490  0.0997    96.876  398.77
  75   0.5425     87.260  0.0975    97.074  404.09
  76   0.5373     87.750  0.0991    96.800  409.45
  77   0.5433     87.690  0.1009    96.872  414.81
  78   0.5389     88.000  0.0901    97.122  420.28
  79   0.5522     87.050  0.0946    97.000  425.66
  80   0.5293     87.650  0.0988    96.922  431.03
  81   0.5665     87.000  0.0921    97.028  436.39
  82   0.5483     87.360  0.0959    96.976  441.73
  83   0.6126     86.860  0.0867    97.262  447.06
  84   0.5548     87.850  0.0902    97.110  452.40
  85   0.5969     87.030  0.0922    97.056  457.84
