Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9488     20.350  2.6458    14.646  7.09
   2   1.8270     25.620  1.9175    21.312  12.43
   3   1.7707     29.440  1.8411    24.670  17.79
   4   1.7445     31.030  1.7508    30.026  23.16
   5   1.6321     39.600  1.5908    38.592  28.51
   6   1.4088     46.370  1.4052    47.166  33.85
   7   1.0933     61.030  1.2294    55.046  39.19
   8   1.0778     61.210  1.0752    61.796  44.55
   9   0.9340     68.230  0.9791    65.832  49.93
  10   0.9014     69.830  0.8951    68.930  55.31
  11   0.8677     70.400  0.8513    70.750  60.64
  12   0.7691     74.110  0.7972    73.156  65.97
  13   0.7443     75.310  0.7630    74.312  71.35
  14   0.6973     77.360  0.7192    76.318  76.72
  15   0.7666     75.260  0.6815    77.542  82.06
  16   0.6450     78.790  0.6559    78.622  87.47
  17   0.6825     78.530  0.6294    79.746  92.82
  18   0.7392     77.190  0.6125    80.282  98.17
  19   0.6385     79.880  0.5822    81.364  103.50
  20   0.6231     80.150  0.5636    81.960  108.84
  21   0.5924     81.600  0.5474    82.558  114.19
  22   0.6186     81.890  0.5290    83.236  119.55
  23   0.6156     80.620  0.5192    83.660  124.95
  24   0.5909     81.460  0.5073    83.960  130.29
  25   0.5564     82.410  0.4891    84.734  135.63
  26   0.5467     83.750  0.4781    85.018  141.00
  27   0.5368     83.810  0.4735    85.074  146.36
  28   0.5788     83.490  0.4570    85.858  151.73
  29   0.5959     82.490  0.4546    85.746  157.09
  30   0.5510     83.120  0.4385    86.274  162.52
  31   0.5647     83.130  0.4311    86.516  167.85
  32   0.5557     83.460  0.4280    86.762  173.20
  33   0.5546     83.560  0.4290    86.722  178.54
  34   0.5059     84.620  0.4017    87.748  183.92
  35   0.4829     85.650  0.4030    87.274  189.27
  36   0.5099     84.820  0.3813    88.056  194.69
  37   0.5352     83.710  0.3825    88.062  200.06
  38   0.5160     84.520  0.3767    88.134  205.43
  39   0.5483     84.170  0.3815    88.170  210.78
  40   0.5250     84.850  0.3648    88.750  216.17
  41   0.4687     86.390  0.3628    88.814  221.53
  42   0.5379     83.990  0.3552    89.052  226.93
  43   0.5003     85.170  0.3560    88.974  232.28
  44   0.5379     84.560  0.3525    89.182  237.64
  45   0.5219     85.300  0.3452    89.404  243.01
  46   0.4561     86.690  0.3404    89.450  248.37
  47   0.4956     85.520  0.3405    89.556  253.71
  48   0.5113     85.250  0.3312    89.806  259.04
  49   0.4851     86.110  0.3316    89.804  264.45
  50   0.4566     87.220  0.3254    90.044  269.83
  51   0.4957     85.680  0.3146    90.436  275.18
  52   0.4591     86.680  0.3219    90.096  280.55
  53   0.4885     86.280  0.3157    90.304  285.91
  54   0.4917     85.670  0.3153    90.406  291.25
  55   0.4492     86.840  0.2994    90.728  296.64
  56   0.5552     85.110  0.3060    90.504  302.00
  57   0.5244     84.580  0.3050    90.634  307.37
  58   0.5054     85.390  0.3207    90.296  312.73
  59   0.5146     85.720  0.2985    90.908  318.07
  60   0.4694     86.500  0.3046    90.760  323.43
  61   0.4596     86.810  0.3017    90.920  328.77
  62   0.4575     86.800  0.2994    90.848  334.21
  63   0.5328     85.280  0.2881    91.174  339.53
  64   0.4300     87.600  0.2879    91.224  344.91
  65   0.4679     87.120  0.2846    91.252  350.24
  66   0.5243     86.540  0.2820    91.420  355.56
  67   0.4911     86.610  0.2882    91.200  360.90
  68   0.4881     86.590  0.2759    91.460  366.28
  69   0.4678     87.120  0.2721    91.690  371.65
  70   0.4332     87.290  0.2799    91.524  377.01
  71   0.4587     87.030  0.2812    91.602  382.33
  72   0.4537     87.280  0.2761    91.514  387.68
  73   0.4702     86.910  0.2701    91.722  393.01
  74   0.5188     86.430  0.2716    91.744  398.45
  75   0.4355     87.410  0.2773    91.546  403.78
  76   0.4703     86.450  0.2601    92.044  409.13
  77   0.5179     86.290  0.2654    91.852  414.48
  78   0.5472     86.310  0.2749    91.666  419.85
  79   0.5137     85.630  0.2702    91.812  425.17
  80   0.4970     86.260  0.2677    91.826  430.52
  81   0.4965     87.070  0.2496    92.366  435.94
  82   0.5213     85.760  0.2553    92.202  441.32
  83   0.4805     87.390  0.2542    92.228  446.66
  84   0.4898     86.730  0.2532    92.254  452.03
  85   0.4584     87.410  0.2590    92.136  457.40
  86   0.4560     87.900  0.2604    92.042  462.73
  87   0.5118     86.300  0.2494    92.312  468.09
  88   0.4885     86.560  0.2570    92.262  473.45
  89   0.4204     87.870  0.2421    92.670  478.77
  90   0.5014     87.010  0.2442    92.640  484.15
