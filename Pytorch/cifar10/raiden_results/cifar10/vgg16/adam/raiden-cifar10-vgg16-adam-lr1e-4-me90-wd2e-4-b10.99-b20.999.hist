Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8105     26.150  2.0521    18.930  7.04
   2   1.6104     38.340  1.7492    29.700  12.34
   3   1.4752     43.140  1.5703    38.988  17.67
   4   1.3580     47.860  1.4564    44.414  22.99
   5   1.2099     54.930  1.3225    50.416  28.42
   6   1.1115     58.960  1.2113    55.498  33.77
   7   1.0670     60.950  1.1101    59.564  39.12
   8   1.0141     63.110  1.0578    61.672  44.47
   9   1.0164     62.790  1.0076    64.068  49.81
  10   0.9185     67.490  0.9206    67.336  55.14
  11   0.8881     69.320  0.8681    69.110  60.55
  12   0.8417     70.430  0.8258    70.956  65.86
  13   0.7680     73.300  0.7815    72.640  71.21
  14   0.7837     72.670  0.7393    74.232  76.55
  15   0.7541     73.730  0.7174    75.126  81.89
  16   0.7218     75.290  0.6949    75.828  87.20
  17   0.6861     76.660  0.6498    77.490  92.62
  18   0.6757     76.530  0.6177    78.422  97.94
  19   0.6444     77.890  0.5913    79.766  103.27
  20   0.6380     78.050  0.5749    80.200  108.63
  21   0.6318     78.740  0.5574    80.792  113.94
  22   0.6289     78.150  0.5169    82.302  119.27
  23   0.5979     79.740  0.5022    82.634  124.59
  24   0.5934     80.100  0.4718    83.674  129.99
  25   0.5988     80.110  0.4773    83.640  135.34
  26   0.5617     81.220  0.4529    84.374  140.69
  27   0.5795     80.890  0.4330    85.060  146.00
  28   0.5745     81.150  0.4311    85.254  151.34
  29   0.6051     80.600  0.4026    86.194  156.70
  30   0.5731     81.720  0.3823    86.798  162.07
  31   0.5512     81.800  0.3603    87.586  167.50
  32   0.5828     81.370  0.3465    88.080  172.85
  33   0.5562     81.960  0.3390    88.392  178.21
  34   0.5413     82.290  0.3344    88.540  183.56
  35   0.5602     82.430  0.3148    89.228  188.87
  36   0.5649     82.590  0.2920    90.078  194.22
  37   0.5570     83.340  0.2896    90.056  199.56
  38   0.5352     82.680  0.2780    90.550  205.00
  39   0.5818     82.370  0.2653    90.890  210.33
  40   0.5922     82.830  0.2699    90.788  215.68
  41   0.5638     82.980  0.2571    91.344  221.04
  42   0.5690     83.020  0.2464    91.606  226.38
  43   0.5657     83.610  0.2350    91.998  231.74
  44   0.5606     83.300  0.2330    92.072  237.18
  45   0.5599     83.190  0.2099    92.836  242.51
  46   0.5554     83.550  0.2062    93.014  247.87
  47   0.5854     83.580  0.2131    92.854  253.22
  48   0.5705     83.550  0.1965    93.342  258.54
  49   0.5562     83.700  0.1896    93.632  263.89
  50   0.5832     83.880  0.1732    94.080  269.29
  51   0.5690     83.740  0.1703    94.312  274.62
  52   0.6042     83.840  0.1797    94.044  279.95
  53   0.5938     83.510  0.1680    94.332  285.27
  54   0.5963     83.820  0.1552    94.780  290.61
  55   0.5890     83.490  0.1475    95.014  295.97
  56   0.6408     83.360  0.1481    94.970  301.39
  57   0.5977     83.800  0.1404    95.278  306.72
  58   0.5911     83.980  0.1443    95.122  312.07
  59   0.6075     84.120  0.1322    95.574  317.42
  60   0.6248     84.360  0.1155    96.068  322.78
  61   0.6227     84.360  0.1190    95.946  328.13
  62   0.5711     84.800  0.1178    96.004  333.47
  63   0.6134     84.010  0.1179    96.004  338.82
  64   0.6023     83.760  0.1182    95.972  344.20
  65   0.6135     84.530  0.1215    95.832  349.56
  66   0.6345     83.820  0.1186    96.014  354.90
  67   0.6559     84.230  0.1101    96.282  360.22
  68   0.5948     84.770  0.1053    96.364  365.54
  69   0.6398     84.530  0.0967    96.802  370.89
  70   0.6338     85.060  0.0971    96.682  376.33
  71   0.6080     84.300  0.1002    96.614  381.67
  72   0.6761     84.180  0.0968    96.772  387.01
  73   0.6603     84.750  0.0973    96.768  392.35
  74   0.6258     84.720  0.0930    96.948  397.70
  75   0.6251     84.770  0.0913    97.030  403.03
  76   0.6320     84.820  0.0852    97.086  408.47
  77   0.6719     84.140  0.0884    97.050  413.79
  78   0.6191     84.940  0.0890    97.016  419.15
  79   0.6715     84.490  0.0805    97.290  424.51
  80   0.6458     84.890  0.0828    97.298  429.86
  81   0.6405     85.500  0.0704    97.732  435.19
  82   0.6895     84.740  0.0674    97.760  440.66
  83   0.6299     84.950  0.0724    97.546  446.00
  84   0.6826     84.400  0.0785    97.422  451.34
  85   0.6408     85.640  0.0706    97.672  456.68
  86   0.6535     85.080  0.0722    97.596  462.00
  87   0.6567     84.670  0.0694    97.686  467.33
  88   0.6916     84.030  0.0756    97.504  472.66
  89   0.6882     85.320  0.0733    97.608  478.09
  90   0.6453     85.700  0.0685    97.712  483.46
