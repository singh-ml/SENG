Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3026     10.000  2.3332    10.068  6.91
   2   2.3025     10.010  2.3027    10.010  12.28
   3   2.0973     17.540  2.2580    13.536  17.59
   4   1.9547     20.920  2.0341    19.342  22.91
   5   1.8401     24.650  1.9059    21.632  28.22
   6   1.8295     25.810  1.8394    24.566  33.53
   7   1.7351     28.910  1.7933    27.130  38.85
   8   1.5917     39.070  1.7055    32.628  44.27
   9   1.4259     45.820  1.5305    40.846  49.57
  10   1.3629     48.000  1.3930    47.124  54.92
  11   1.2184     54.760  1.2968    51.380  60.23
  12   1.1773     56.970  1.1886    56.240  65.54
  13   1.0732     60.830  1.1193    59.188  70.86
  14   0.9849     64.080  1.0389    62.726  76.27
  15   0.9850     64.710  0.9613    65.466  81.60
  16   0.9039     67.730  0.9166    67.342  86.95
  17   0.8662     69.500  0.8533    69.702  92.29
  18   0.8649     70.220  0.8133    71.210  97.60
  19   0.8062     72.090  0.8093    71.676  102.93
  20   0.8281     71.980  0.7384    74.148  108.33
  21   0.7529     73.330  0.7331    74.278  113.66
  22   0.7378     75.220  0.6939    76.140  118.96
  23   0.7116     75.110  0.6977    76.116  124.32
  24   0.7108     76.680  0.6625    77.454  129.63
  25   0.6861     76.480  0.6387    78.476  134.96
  26   0.6356     78.750  0.6169    79.420  140.29
  27   0.6601     78.380  0.6018    79.904  145.67
  28   0.6479     79.060  0.5756    80.942  150.98
  29   0.6350     79.460  0.5493    81.600  156.34
  30   0.6486     79.150  0.5430    82.100  161.66
  31   0.5844     80.970  0.5281    82.610  167.00
  32   0.5984     81.030  0.5045    83.276  172.30
  33   0.5738     81.420  0.4886    83.724  177.64
  34   0.5741     81.920  0.4731    84.346  183.06
  35   0.5445     82.630  0.4655    84.752  188.40
  36   0.5853     81.860  0.4549    85.242  193.76
  37   0.5389     82.610  0.4489    85.390  199.10
  38   0.5600     81.970  0.4411    85.692  204.45
  39   0.5982     81.420  0.4516    85.222  209.76
  40   0.5561     82.690  0.4219    86.324  215.09
  41   0.5826     82.440  0.4057    86.778  220.41
  42   0.5405     83.140  0.4083    86.784  225.75
  43   0.5370     83.090  0.4012    86.966  231.09
  44   0.5370     83.770  0.3896    87.296  236.44
  45   0.5408     82.710  0.3896    87.366  241.78
  46   0.5715     82.100  0.3937    87.262  247.18
  47   0.5693     83.060  0.3789    87.650  252.50
  48   0.5098     83.820  0.3690    88.142  257.83
  49   0.5161     84.180  0.3593    88.470  263.17
  50   0.5239     84.770  0.3360    89.178  268.49
  51   0.5242     84.430  0.3411    88.990  273.80
  52   0.5338     84.450  0.3437    88.906  279.14
  53   0.5018     84.690  0.3469    88.848  284.57
  54   0.5116     84.860  0.3459    88.920  289.95
  55   0.5058     84.910  0.3270    89.480  295.25
  56   0.5212     84.240  0.3296    89.284  300.57
  57   0.4978     85.180  0.3269    89.486  305.89
  58   0.5026     84.850  0.3084    90.060  311.20
  59   0.5238     85.040  0.3185    89.830  316.56
  60   0.5029     84.800  0.3085    90.082  321.87
  61   0.4864     85.120  0.3199    89.710  327.19
  62   0.5202     85.080  0.3142    89.872  332.52
  63   0.5037     85.750  0.3012    90.346  337.85
  64   0.4885     85.550  0.2995    90.308  343.15
  65   0.4912     85.970  0.2891    90.698  348.46
  66   0.5295     85.160  0.2915    90.782  353.82
  67   0.5264     85.340  0.3028    90.388  359.15
  68   0.5249     85.550  0.2696    91.396  364.50
  69   0.4974     86.170  0.2783    91.094  369.86
  70   0.4921     86.430  0.2706    91.266  375.18
  71   0.4965     85.650  0.2773    91.218  380.50
  72   0.5686     84.850  0.2667    91.484  385.88
  73   0.5070     86.100  0.2715    91.284  391.23
  74   0.4925     86.000  0.2593    91.584  396.52
  75   0.5095     85.480  0.2597    91.676  401.85
  76   0.5369     85.390  0.2659    91.466  407.16
  77   0.5350     85.390  0.2633    91.506  412.48
  78   0.4916     86.360  0.2571    91.778  417.82
  79   0.4766     86.810  0.2498    92.044  423.22
  80   0.4960     86.490  0.2441    92.186  428.55
  81   0.4995     86.290  0.2475    92.092  433.87
  82   0.4720     86.010  0.2465    92.108  439.21
  83   0.5353     85.530  0.2434    92.212  444.58
  84   0.4757     86.850  0.2435    92.152  449.89
  85   0.5056     86.270  0.2337    92.452  455.31
