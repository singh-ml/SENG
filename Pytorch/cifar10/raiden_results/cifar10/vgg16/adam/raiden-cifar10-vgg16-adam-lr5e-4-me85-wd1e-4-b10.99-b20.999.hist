Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9042     19.650  2.1282    16.392  7.00
   2   1.8003     27.760  1.8692    22.808  12.40
   3   1.6625     33.470  1.7551    29.568  17.76
   4   1.5544     39.230  1.6230    35.398  23.08
   5   1.4299     45.050  1.5409    40.260  28.42
   6   1.4370     46.800  1.4324    45.260  33.77
   7   1.2359     53.360  1.3289    49.954  39.11
   8   1.2054     57.460  1.2371    54.236  44.56
   9   1.1706     59.370  1.1419    58.438  49.90
  10   1.0521     62.410  1.0732    61.648  55.26
  11   0.9699     65.840  0.9890    65.350  60.61
  12   0.9006     69.010  0.9383    67.372  65.99
  13   0.8611     70.100  0.8635    70.198  71.31
  14   0.8079     73.010  0.8239    71.854  76.71
  15   0.7750     74.560  0.7611    74.062  82.07
  16   0.7438     74.960  0.7098    75.612  87.43
  17   0.7431     75.100  0.6889    76.606  92.76
  18   0.6916     76.890  0.6520    78.012  98.08
  19   0.6641     77.770  0.6317    78.766  103.43
  20   0.6315     79.450  0.5858    80.138  108.75
  21   0.6093     79.950  0.5849    80.442  114.16
  22   0.6095     80.230  0.5490    81.728  119.48
  23   0.6166     80.320  0.5318    82.238  124.82
  24   0.6111     81.150  0.5151    82.934  130.15
  25   0.5662     81.520  0.4967    83.526  135.49
  26   0.5483     81.930  0.4802    84.060  140.83
  27   0.5381     82.780  0.4538    84.828  146.17
  28   0.5497     82.740  0.4338    85.754  151.56
  29   0.5618     82.280  0.4427    85.436  156.97
  30   0.5183     83.050  0.4316    85.840  162.31
  31   0.5289     83.670  0.4175    86.152  167.66
  32   0.5342     83.530  0.3971    86.858  173.01
  33   0.5047     83.750  0.3977    86.938  178.35
  34   0.5424     83.270  0.3719    87.602  183.69
  35   0.5145     83.780  0.3662    87.762  189.10
  36   0.4884     84.670  0.3621    87.944  194.45
  37   0.5298     83.640  0.3550    88.292  199.78
  38   0.4924     84.670  0.3659    88.066  205.13
  39   0.4830     84.960  0.3366    89.096  210.49
  40   0.5248     84.680  0.3270    89.312  215.82
  41   0.5011     85.040  0.3135    89.786  221.26
  42   0.5013     85.520  0.3126    89.604  226.58
  43   0.4975     85.400  0.2975    90.250  231.93
  44   0.5216     84.540  0.2979    90.158  237.30
  45   0.4923     85.320  0.2928    90.400  242.64
  46   0.4850     85.630  0.2841    90.742  247.97
  47   0.5014     85.540  0.2817    90.764  253.37
  48   0.5109     86.210  0.2658    91.218  258.75
  49   0.4912     86.180  0.2710    91.368  264.09
  50   0.4947     85.820  0.2565    91.484  269.43
  51   0.4935     85.660  0.2592    91.536  274.78
  52   0.4971     85.950  0.2498    91.842  280.14
  53   0.4881     86.490  0.2439    91.906  285.56
  54   0.4815     86.230  0.2380    92.188  290.94
  55   0.4926     86.140  0.2355    92.258  296.30
  56   0.4631     86.660  0.2355    92.282  301.63
  57   0.5155     86.460  0.2217    92.782  306.99
  58   0.4787     86.550  0.2253    92.628  312.33
  59   0.5083     86.890  0.2183    92.790  317.75
  60   0.4864     86.690  0.2153    93.026  323.11
  61   0.4832     86.690  0.2207    92.690  328.48
  62   0.5042     86.810  0.2134    92.958  333.83
  63   0.5079     86.920  0.2075    93.140  339.17
  64   0.5043     86.340  0.2127    93.028  344.49
  65   0.5117     86.990  0.2066    93.310  349.84
  66   0.4826     86.650  0.1969    93.644  355.28
  67   0.5094     86.960  0.1932    93.620  360.62
  68   0.5120     86.310  0.2013    93.354  365.97
  69   0.4859     86.650  0.2137    93.174  371.33
  70   0.4873     87.080  0.1843    93.988  376.68
  71   0.5191     86.760  0.1888    94.016  382.02
  72   0.5105     87.330  0.1842    93.934  387.39
  73   0.4886     87.190  0.1900    93.774  392.79
  74   0.5137     86.570  0.1831    94.044  398.15
  75   0.4831     87.280  0.1846    94.010  403.50
  76   0.5014     87.150  0.1780    94.158  408.85
  77   0.5228     86.940  0.1719    94.314  414.21
  78   0.5249     86.990  0.1777    94.184  419.57
  79   0.5114     86.870  0.1844    94.144  424.98
  80   0.5349     87.010  0.1799    94.248  430.31
  81   0.5176     87.240  0.1730    94.398  435.70
  82   0.5083     87.010  0.1627    94.688  441.02
  83   0.4818     87.380  0.1656    94.678  446.37
  84   0.5294     87.480  0.1581    95.018  451.73
  85   0.4969     86.320  0.1664    94.602  457.14
