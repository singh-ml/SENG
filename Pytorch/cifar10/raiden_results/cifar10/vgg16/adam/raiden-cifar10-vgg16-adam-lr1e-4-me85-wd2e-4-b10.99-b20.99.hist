Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9519     19.360  2.1682    15.914  7.02
   2   1.8020     26.140  1.8807    22.772  12.34
   3   1.6717     31.950  1.7574    29.086  17.69
   4   1.5181     41.320  1.6248    34.978  23.03
   5   1.4716     45.660  1.5270    41.122  28.37
   6   1.3102     52.070  1.4080    46.842  33.70
   7   1.2731     53.350  1.2891    52.312  39.05
   8   1.1181     59.690  1.2181    55.260  44.47
   9   1.1184     59.250  1.1290    59.038  49.82
  10   1.0160     63.640  1.0719    60.832  55.14
  11   1.0314     64.230  0.9996    63.970  60.45
  12   0.9318     67.030  0.9517    65.614  65.80
  13   0.8582     69.790  0.8911    68.008  71.12
  14   0.8306     70.940  0.8452    70.008  76.51
  15   0.8474     70.190  0.8200    70.972  81.86
  16   0.7959     72.030  0.7928    71.868  87.20
  17   0.8001     72.200  0.7459    74.154  92.52
  18   0.7634     74.240  0.7100    75.198  97.87
  19   0.7132     75.770  0.6791    76.348  103.19
  20   0.6903     76.100  0.6617    77.130  108.59
  21   0.6949     76.370  0.6322    78.236  113.91
  22   0.6850     76.730  0.6101    79.102  119.24
  23   0.6553     77.680  0.5874    79.850  124.57
  24   0.6434     78.430  0.5632    80.644  129.91
  25   0.6275     78.890  0.5461    81.406  135.27
  26   0.6711     77.410  0.5206    82.118  140.62
  27   0.6117     79.550  0.5124    82.566  146.02
  28   0.5876     80.480  0.4826    83.620  151.35
  29   0.6120     80.280  0.4746    83.648  156.66
  30   0.5877     80.510  0.4557    84.654  162.00
  31   0.5678     81.420  0.4300    85.358  167.35
  32   0.5843     80.810  0.4136    85.972  172.70
  33   0.5698     81.870  0.4032    86.430  178.05
  34   0.5701     81.800  0.3882    86.798  183.47
  35   0.5632     81.700  0.3616    87.808  188.82
  36   0.5618     82.350  0.3643    87.638  194.15
  37   0.5691     82.440  0.3359    88.570  199.48
  38   0.5837     81.960  0.3421    88.370  204.79
  39   0.5465     82.700  0.3334    88.790  210.14
  40   0.5305     83.130  0.3260    88.870  215.49
  41   0.5665     83.380  0.2955    90.054  220.91
  42   0.5488     82.700  0.2892    90.124  226.23
  43   0.5488     83.700  0.2772    90.668  231.58
  44   0.5663     83.630  0.2671    91.002  236.93
  45   0.5582     83.080  0.2612    91.152  242.28
  46   0.5652     83.260  0.2462    91.764  247.68
  47   0.5580     83.740  0.2470    91.716  253.06
  48   0.5783     83.210  0.2431    91.692  258.38
  49   0.5827     83.150  0.2230    92.512  263.71
  50   0.5916     83.190  0.2218    92.508  269.02
  51   0.5736     83.620  0.2096    92.890  274.35
  52   0.5638     83.650  0.2163    92.784  279.70
  53   0.5523     84.280  0.2053    93.086  285.12
  54   0.5668     83.940  0.1883    93.670  290.45
  55   0.5890     84.050  0.1847    93.800  295.80
  56   0.5508     84.290  0.1789    93.990  301.15
  57   0.5932     84.280  0.1791    94.058  306.49
  58   0.5974     83.780  0.1726    94.210  311.80
  59   0.5509     84.940  0.1665    94.422  317.23
  60   0.6009     83.720  0.1600    94.636  322.57
  61   0.5995     84.230  0.1521    94.896  327.90
  62   0.5942     84.000  0.1447    95.030  333.22
  63   0.5975     84.670  0.1508    94.938  338.57
  64   0.5922     84.410  0.1414    95.278  343.94
  65   0.6268     84.250  0.1427    95.188  349.28
  66   0.6197     84.240  0.1424    95.272  354.71
  67   0.5615     85.060  0.1391    95.374  360.02
  68   0.6334     85.050  0.1229    95.884  365.35
  69   0.6165     84.290  0.1119    96.182  370.71
  70   0.6190     85.170  0.1137    96.176  376.05
  71   0.5971     84.960  0.1164    96.134  381.37
  72   0.5971     84.870  0.1128    96.184  386.69
  73   0.5819     84.880  0.1183    96.074  392.12
  74   0.6164     84.620  0.1208    95.948  397.48
  75   0.6009     84.990  0.1136    96.222  402.82
  76   0.5892     85.140  0.1078    96.422  408.16
  77   0.6023     84.890  0.1113    96.300  413.49
  78   0.5987     84.980  0.0956    96.754  418.83
  79   0.6086     84.880  0.0996    96.746  424.15
  80   0.6357     84.610  0.0989    96.674  429.55
  81   0.5991     85.540  0.0874    97.098  434.89
  82   0.6142     84.950  0.0957    96.746  440.24
  83   0.6357     85.240  0.0878    97.058  445.55
  84   0.6429     85.510  0.0844    97.148  450.89
  85   0.6181     85.500  0.0921    96.856  456.25
