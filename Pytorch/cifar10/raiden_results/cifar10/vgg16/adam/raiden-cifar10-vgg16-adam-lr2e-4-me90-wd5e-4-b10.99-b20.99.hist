Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9653     18.200  2.1402    16.420  6.88
   2   1.8740     22.100  1.8866    20.864  12.18
   3   1.7705     28.240  1.8282    25.318  17.50
   4   1.5836     38.080  1.6791    32.304  22.85
   5   1.4477     43.230  1.5207    40.698  28.31
   6   1.3392     49.100  1.3986    46.552  33.63
   7   1.2790     52.020  1.3137    50.560  38.96
   8   1.1813     57.290  1.1992    55.250  44.30
   9   1.0924     61.190  1.0902    59.730  49.64
  10   0.9502     65.980  1.0036    63.466  55.02
  11   0.9096     68.410  0.9349    66.318  60.44
  12   0.8611     69.730  0.8700    69.004  65.76
  13   0.8686     68.800  0.8372    70.614  71.08
  14   0.7949     72.180  0.8059    71.750  76.40
  15   0.7476     74.310  0.7395    74.240  81.72
  16   0.7599     73.370  0.7127    75.214  87.07
  17   0.7395     75.510  0.6907    76.286  92.39
  18   0.6808     77.010  0.6632    77.456  97.78
  19   0.6595     77.630  0.6117    78.916  103.12
  20   0.6335     78.540  0.5814    80.254  108.47
  21   0.6178     79.490  0.5608    80.848  113.78
  22   0.6577     78.500  0.5485    81.602  119.12
  23   0.5864     80.870  0.5277    82.472  124.45
  24   0.5636     82.150  0.5049    83.084  129.89
  25   0.5642     81.590  0.4844    83.942  135.22
  26   0.5548     82.610  0.4577    84.958  140.57
  27   0.5621     82.260  0.4346    85.652  145.90
  28   0.5513     82.710  0.4230    85.964  151.24
  29   0.5305     83.230  0.4075    86.518  156.57
  30   0.5078     83.760  0.3924    87.046  161.98
  31   0.5279     83.680  0.3847    87.412  167.33
  32   0.5022     83.690  0.3730    87.804  172.68
  33   0.4966     84.500  0.3499    88.396  178.01
  34   0.5166     84.070  0.3452    88.610  183.35
  35   0.4818     84.600  0.3398    88.758  188.68
  36   0.4588     85.760  0.3199    89.356  194.03
  37   0.5005     85.110  0.3015    90.086  199.45
  38   0.4914     84.920  0.3135    89.724  204.78
  39   0.5114     84.840  0.2949    90.268  210.13
  40   0.4978     85.370  0.2786    90.852  215.47
  41   0.4937     85.470  0.2618    91.452  220.82
  42   0.4686     85.830  0.2651    91.214  226.18
  43   0.4678     86.190  0.2452    91.846  231.56
  44   0.4788     85.860  0.2435    91.970  236.90
  45   0.4793     86.350  0.2430    92.120  242.25
  46   0.4847     86.030  0.2326    92.484  247.57
  47   0.4770     86.250  0.2232    92.684  252.89
  48   0.4808     86.160  0.2259    92.546  258.24
  49   0.4798     86.190  0.2142    93.042  263.63
  50   0.4717     86.030  0.2126    93.032  268.94
  51   0.4756     86.340  0.2097    93.184  274.28
  52   0.4886     86.360  0.1986    93.480  279.60
  53   0.5175     86.090  0.1959    93.730  284.93
  54   0.4829     86.230  0.1949    93.646  290.27
  55   0.4915     86.330  0.1877    93.826  295.60
  56   0.4887     86.590  0.1777    94.204  300.97
  57   0.4819     86.360  0.1735    94.332  306.29
  58   0.5145     86.450  0.1693    94.428  311.64
  59   0.4822     86.960  0.1675    94.590  316.94
  60   0.4986     86.520  0.1647    94.706  322.30
  61   0.4949     87.410  0.1558    94.946  327.64
  62   0.4727     87.650  0.1492    95.212  333.07
  63   0.5485     87.050  0.1517    95.046  338.42
  64   0.5225     86.640  0.1657    94.488  343.76
  65   0.4925     87.200  0.1422    95.380  349.08
  66   0.5220     86.590  0.1416    95.516  354.41
  67   0.5371     87.190  0.1486    95.110  359.76
  68   0.5176     87.020  0.1432    95.510  365.08
  69   0.5228     86.940  0.1509    95.136  370.48
  70   0.4783     87.190  0.1301    95.866  375.79
  71   0.5614     86.830  0.1281    95.862  381.12
  72   0.5089     87.220  0.1318    95.808  386.44
  73   0.5156     87.650  0.1158    96.248  391.78
  74   0.5046     86.630  0.1217    96.134  397.11
  75   0.5316     87.390  0.1217    95.936  402.49
  76   0.5183     87.200  0.1165    96.206  407.84
  77   0.5141     87.220  0.1172    96.306  413.17
  78   0.4746     87.190  0.1129    96.390  418.49
  79   0.5036     87.410  0.1054    96.614  423.84
  80   0.5192     86.500  0.1103    96.454  429.17
  81   0.5053     87.160  0.1189    96.178  434.59
  82   0.5046     86.920  0.1081    96.536  439.93
  83   0.5079     86.860  0.1125    96.470  445.25
  84   0.4731     87.900  0.1077    96.522  450.62
  85   0.5020     87.680  0.0960    96.920  455.94
  86   0.4960     88.030  0.0927    97.058  461.26
  87   0.5296     87.520  0.1044    96.634  466.61
  88   0.5165     88.070  0.0951    97.018  472.00
  89   0.4938     87.570  0.1017    96.740  477.33
  90   0.5330     87.750  0.0918    97.020  482.64
