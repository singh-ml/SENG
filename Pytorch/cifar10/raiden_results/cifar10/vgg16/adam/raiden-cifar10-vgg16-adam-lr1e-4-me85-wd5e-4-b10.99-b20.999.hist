Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8371     26.670  2.1101    18.426  7.13
   2   1.6745     32.910  1.7623    29.216  12.46
   3   1.5345     40.210  1.6363    35.080  17.77
   4   1.4597     44.660  1.5422    40.044  23.08
   5   1.3962     47.260  1.4467    45.006  28.38
   6   1.2227     54.160  1.3220    50.480  33.71
   7   1.2056     55.610  1.2334    54.420  39.13
   8   1.0921     61.040  1.1534    58.504  44.44
   9   1.0002     64.980  1.0506    62.164  49.76
  10   0.9414     66.380  0.9942    64.094  55.06
  11   0.9555     66.700  0.9230    66.964  60.42
  12   0.9079     68.420  0.8881    68.412  65.74
  13   0.8397     70.850  0.8391    70.238  71.13
  14   0.7729     72.850  0.7723    72.888  76.48
  15   0.7347     74.950  0.7201    74.574  81.81
  16   0.7326     75.050  0.7044    75.544  87.15
  17   0.7598     73.870  0.7026    75.802  92.46
  18   0.6859     77.080  0.6635    76.996  97.78
  19   0.6659     77.650  0.6099    78.976  103.17
  20   0.6715     77.530  0.5966    79.628  108.47
  21   0.6629     77.800  0.5674    80.626  113.80
  22   0.6174     79.090  0.5655    80.614  119.12
  23   0.6130     79.750  0.5322    81.882  124.44
  24   0.6155     80.000  0.5095    82.924  129.76
  25   0.5958     80.830  0.4889    83.504  135.05
  26   0.6025     80.410  0.4682    84.118  140.45
  27   0.5876     81.180  0.4526    84.784  145.78
  28   0.5830     81.680  0.4230    85.626  151.10
  29   0.5664     82.050  0.4154    85.908  156.45
  30   0.5617     81.960  0.3955    86.752  161.77
  31   0.5744     82.030  0.4056    86.398  167.09
  32   0.5474     82.240  0.3808    87.182  172.40
  33   0.5837     82.070  0.3546    87.996  177.80
  34   0.5757     82.320  0.3448    88.426  183.11
  35   0.5748     82.370  0.3496    88.212  188.42
  36   0.5805     82.260  0.3351    88.888  193.77
  37   0.5594     82.790  0.3060    89.806  199.07
  38   0.5745     82.270  0.3131    89.410  204.38
  39   0.5553     82.830  0.3143    89.368  209.70
  40   0.5672     83.090  0.2945    90.024  215.11
  41   0.5813     83.030  0.2584    91.298  220.43
  42   0.5564     84.030  0.2551    91.436  225.74
  43   0.5644     83.170  0.2672    91.010  231.06
  44   0.5626     82.860  0.2550    91.632  236.39
  45   0.5591     83.820  0.2319    92.296  241.70
  46   0.5820     83.650  0.2280    92.412  247.09
  47   0.5949     83.500  0.2133    92.812  252.40
  48   0.6333     82.960  0.2277    92.390  257.71
  49   0.6524     82.690  0.2267    92.504  263.01
  50   0.5978     83.460  0.2187    92.724  268.36
  51   0.6020     83.940  0.2280    92.434  273.66
  52   0.5951     83.510  0.1983    93.336  279.00
  53   0.6062     83.320  0.1978    93.420  284.35
  54   0.5674     84.030  0.1768    94.052  289.69
  55   0.5588     84.200  0.1706    94.310  295.01
  56   0.5885     84.030  0.1766    94.128  300.35
  57   0.5961     84.440  0.1599    94.630  305.65
  58   0.5913     84.480  0.1542    94.814  311.00
  59   0.6276     83.830  0.1563    94.846  316.33
  60   0.5922     84.220  0.1570    94.736  321.65
  61   0.6023     84.460  0.1463    95.178  326.97
  62   0.5936     84.720  0.1348    95.524  332.31
  63   0.6600     83.290  0.1409    95.346  337.65
  64   0.5834     84.700  0.1457    95.110  342.99
  65   0.6171     84.510  0.1324    95.658  348.31
  66   0.6143     84.290  0.1342    95.586  353.72
  67   0.6299     85.020  0.1210    96.042  359.04
  68   0.6262     84.320  0.1194    96.038  364.35
  69   0.5809     84.870  0.1288    95.790  369.67
  70   0.5922     85.210  0.1154    96.114  375.00
  71   0.6186     84.800  0.1123    96.256  380.35
  72   0.6466     84.570  0.1119    96.316  385.75
  73   0.6417     84.450  0.1087    96.358  391.08
  74   0.6545     85.170  0.1009    96.686  396.40
  75   0.6503     84.710  0.1067    96.502  401.71
  76   0.6333     84.980  0.1032    96.530  407.02
  77   0.6282     85.490  0.1108    96.370  412.34
  78   0.6454     85.260  0.0991    96.738  417.72
  79   0.6779     85.090  0.0974    96.702  423.04
  80   0.7049     84.770  0.0925    96.896  428.37
  81   0.6739     85.430  0.0959    96.892  433.72
  82   0.6419     84.790  0.0887    97.166  439.06
  83   0.6889     84.940  0.0878    97.076  444.40
  84   0.6598     84.910  0.0841    97.244  449.80
  85   0.6752     85.300  0.0818    97.400  455.12
