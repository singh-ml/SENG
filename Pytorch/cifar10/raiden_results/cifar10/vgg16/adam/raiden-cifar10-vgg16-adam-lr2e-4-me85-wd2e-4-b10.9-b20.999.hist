Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9190     20.820  2.2201    13.424  6.92
   2   1.7158     32.680  1.8681    23.530  12.23
   3   1.4968     40.560  1.6628    34.308  17.57
   4   1.3494     47.610  1.4662    43.244  22.91
   5   1.2396     53.410  1.3072    50.520  28.33
   6   1.0912     60.570  1.1793    56.886  33.68
   7   0.9702     65.410  1.0241    63.272  39.02
   8   0.8869     69.320  0.9193    67.414  44.34
   9   0.7581     73.990  0.8244    71.064  49.66
  10   0.7714     73.920  0.7628    73.654  54.99
  11   0.7051     75.650  0.7167    75.510  60.34
  12   0.6429     78.240  0.6612    77.378  65.72
  13   0.6213     78.710  0.6094    79.356  71.09
  14   0.6607     78.400  0.5761    80.384  76.44
  15   0.6175     79.770  0.5581    81.298  81.77
  16   0.5878     80.860  0.5165    82.688  87.12
  17   0.5679     80.990  0.4907    83.688  92.45
  18   0.5510     82.580  0.4705    84.310  97.87
  19   0.5290     82.900  0.4400    85.142  103.23
  20   0.5375     82.590  0.4285    85.724  108.55
  21   0.5270     82.780  0.4099    86.292  113.89
  22   0.5599     81.760  0.3890    86.960  119.21
  23   0.5026     84.000  0.3751    87.610  124.54
  24   0.5993     81.760  0.3555    88.252  129.88
  25   0.5296     84.360  0.3426    88.516  135.28
  26   0.5181     84.130  0.3213    89.320  140.61
  27   0.5012     85.260  0.3124    89.730  145.95
  28   0.4869     85.600  0.3005    89.902  151.30
  29   0.5243     84.070  0.2841    90.552  156.67
  30   0.5190     84.260  0.2744    90.976  162.01
  31   0.5413     84.860  0.2707    91.220  167.47
  32   0.5054     84.520  0.2530    91.636  172.83
  33   0.5540     84.100  0.2448    91.800  178.22
  34   0.5437     85.440  0.2405    92.152  183.54
  35   0.5032     85.780  0.2279    92.398  188.91
  36   0.5586     85.150  0.2130    93.096  194.27
  37   0.5061     85.660  0.2153    92.952  199.71
  38   0.5358     85.770  0.1982    93.442  205.08
  39   0.4966     86.300  0.1958    93.630  210.44
  40   0.5081     85.590  0.1938    93.722  215.75
  41   0.4885     85.900  0.1866    93.830  221.11
  42   0.4920     85.820  0.1799    94.162  226.46
  43   0.6033     84.520  0.1628    94.662  231.81
  44   0.5215     86.840  0.1646    94.506  237.23
  45   0.5517     86.020  0.1608    94.784  242.58
  46   0.5432     85.940  0.1561    94.942  247.93
  47   0.5485     86.060  0.1570    94.828  253.29
  48   0.5439     86.250  0.1450    95.304  258.65
  49   0.5255     86.600  0.1420    95.438  264.00
  50   0.5211     86.560  0.1452    95.310  269.42
  51   0.5352     86.710  0.1387    95.520  274.78
  52   0.5180     86.420  0.1288    95.838  280.11
  53   0.5580     86.540  0.1264    95.894  285.49
  54   0.5149     87.070  0.1257    95.974  290.88
  55   0.5553     86.300  0.1250    95.998  296.24
  56   0.6028     85.720  0.1190    96.118  301.59
  57   0.5415     86.500  0.1185    96.074  306.95
  58   0.5651     86.760  0.1164    96.218  312.29
  59   0.5070     87.430  0.1120    96.280  317.64
  60   0.4925     87.360  0.1093    96.424  323.02
  61   0.5370     86.960  0.1070    96.528  328.40
  62   0.5708     86.620  0.1041    96.718  333.73
  63   0.5740     86.930  0.0972    96.860  339.08
  64   0.5457     86.870  0.0951    96.938  344.42
  65   0.5790     86.890  0.0988    96.904  349.76
  66   0.5818     87.300  0.0926    97.014  355.09
  67   0.5455     86.850  0.1042    96.718  360.42
  68   0.5672     86.930  0.0951    97.004  365.75
  69   0.5555     86.790  0.0881    97.134  371.18
  70   0.6136     87.120  0.0853    97.278  376.51
  71   0.6462     86.450  0.0907    97.118  381.87
  72   0.5453     86.870  0.0863    97.272  387.21
  73   0.5369     87.500  0.0899    97.104  392.54
  74   0.5667     87.600  0.0814    97.380  397.91
  75   0.6248     86.760  0.0860    97.202  403.25
  76   0.5508     87.490  0.0789    97.544  408.64
  77   0.5629     87.150  0.0805    97.496  413.97
  78   0.5526     87.430  0.0860    97.294  419.32
  79   0.5383     87.430  0.0751    97.650  424.70
  80   0.5664     87.770  0.0792    97.436  430.05
  81   0.5901     87.240  0.0743    97.664  435.41
  82   0.5537     87.240  0.0793    97.486  440.84
  83   0.5996     87.240  0.0787    97.496  446.17
  84   0.6382     87.630  0.0683    97.830  451.52
  85   0.5827     87.170  0.0691    97.868  456.87
