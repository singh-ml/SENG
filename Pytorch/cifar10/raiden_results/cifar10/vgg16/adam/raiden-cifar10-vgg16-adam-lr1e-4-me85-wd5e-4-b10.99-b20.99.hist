Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8027     28.770  2.0604    19.552  7.01
   2   1.7088     33.010  1.7994    28.322  12.33
   3   1.5549     38.630  1.6264    36.750  17.73
   4   1.4186     45.730  1.5230    40.710  23.07
   5   1.3651     48.670  1.4267    45.760  28.39
   6   1.2401     53.940  1.3447    49.406  33.72
   7   1.1507     57.740  1.2537    53.502  39.05
   8   1.1358     59.280  1.1665    57.122  44.37
   9   1.0657     61.610  1.0874    60.606  49.72
  10   0.9755     64.770  1.0172    63.234  55.13
  11   0.9378     66.900  0.9480    65.982  60.47
  12   0.9189     67.870  0.9088    67.466  65.78
  13   0.8938     68.660  0.8816    68.614  71.13
  14   0.8644     69.690  0.8613    69.458  76.43
  15   0.8344     71.350  0.7929    71.974  81.75
  16   0.7572     73.960  0.7633    73.280  87.15
  17   0.7455     74.550  0.7073    75.258  92.50
  18   0.7965     73.460  0.6949    75.866  97.85
  19   0.7325     75.530  0.6746    76.490  103.17
  20   0.7038     76.490  0.6403    77.856  108.50
  21   0.6937     77.220  0.6157    78.940  113.81
  22   0.6905     77.340  0.5868    79.970  119.20
  23   0.6682     78.230  0.5658    80.880  124.53
  24   0.6825     77.550  0.5448    81.560  129.83
  25   0.6208     79.450  0.5405    81.662  135.16
  26   0.6151     80.180  0.5122    82.686  140.48
  27   0.6049     80.260  0.4845    83.580  145.82
  28   0.5957     80.400  0.4736    84.034  151.24
  29   0.6033     80.740  0.4538    84.594  156.60
  30   0.5842     81.310  0.4308    85.404  161.93
  31   0.5921     81.280  0.4077    86.230  167.27
  32   0.5388     83.010  0.4091    86.302  172.59
  33   0.5733     82.130  0.3932    86.744  177.91
  34   0.5368     83.020  0.3754    87.352  183.25
  35   0.5370     82.600  0.3705    87.424  188.62
  36   0.5528     82.700  0.3536    87.990  194.00
  37   0.5502     82.680  0.3535    88.022  199.34
  38   0.5575     82.400  0.3463    88.460  204.65
  39   0.5422     83.130  0.3174    89.294  209.97
  40   0.5232     83.650  0.3043    89.848  215.30
  41   0.5601     83.210  0.2961    90.018  220.64
  42   0.5366     83.580  0.2805    90.556  226.04
  43   0.5363     83.650  0.2710    90.914  231.35
  44   0.5521     83.610  0.2724    90.790  236.68
  45   0.5381     84.000  0.2703    90.946  242.00
  46   0.5631     83.640  0.2601    91.268  247.30
  47   0.5425     83.800  0.2488    91.784  252.62
  48   0.5599     84.160  0.2312    92.446  258.06
  49   0.5482     84.040  0.2201    92.764  263.42
  50   0.5815     83.850  0.2094    93.036  268.73
  51   0.5399     84.590  0.2064    93.186  274.06
  52   0.5755     83.970  0.2006    93.284  279.40
  53   0.5671     84.160  0.2033    93.282  284.74
  54   0.5616     84.230  0.1876    93.662  290.15
  55   0.5917     84.020  0.1866    93.912  295.46
  56   0.5635     84.290  0.1902    93.640  300.79
  57   0.5573     84.790  0.1803    93.990  306.11
  58   0.5829     84.430  0.1733    94.244  311.47
  59   0.5642     85.050  0.1644    94.428  316.82
  60   0.5598     85.200  0.1632    94.516  322.18
  61   0.5666     84.900  0.1604    94.622  327.50
  62   0.6216     84.450  0.1506    94.946  332.82
  63   0.5454     85.410  0.1467    95.054  338.15
  64   0.5632     85.080  0.1456    95.008  343.47
  65   0.5658     84.830  0.1444    95.108  348.80
  66   0.6054     85.440  0.1314    95.686  354.13
  67   0.5970     85.100  0.1291    95.762  359.52
  68   0.5918     84.860  0.1247    95.876  364.83
  69   0.5789     85.020  0.1233    95.952  370.18
  70   0.5539     85.660  0.1271    95.778  375.50
  71   0.6032     84.930  0.1270    95.870  380.82
  72   0.6193     84.870  0.1241    95.754  386.15
  73   0.6475     85.540  0.1140    96.294  391.47
  74   0.5762     85.420  0.1086    96.486  396.84
  75   0.6138     85.150  0.1061    96.496  402.19
  76   0.5882     85.630  0.0980    96.734  407.54
  77   0.6241     85.330  0.1012    96.756  412.88
  78   0.5690     85.810  0.1072    96.466  418.22
  79   0.5778     85.380  0.1089    96.482  423.53
  80   0.5997     84.990  0.1090    96.518  428.93
  81   0.5904     85.810  0.0950    96.816  434.24
  82   0.6057     85.540  0.0906    97.018  439.57
  83   0.5984     85.740  0.0875    97.110  444.92
  84   0.6132     85.510  0.0893    97.030  450.25
  85   0.6090     85.900  0.0894    97.078  455.58
