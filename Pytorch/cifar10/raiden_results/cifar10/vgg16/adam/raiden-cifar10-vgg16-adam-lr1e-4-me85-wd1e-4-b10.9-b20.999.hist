Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6363     36.830  1.9504    23.280  7.04
   2   1.4412     45.980  1.5674    40.234  12.37
   3   1.2345     54.940  1.3644    49.632  17.73
   4   1.1272     59.750  1.2231    55.484  23.05
   5   1.0208     63.360  1.1168    59.820  28.41
   6   0.9743     65.620  1.0292    63.186  33.73
   7   0.9470     66.280  0.9463    66.220  39.07
   8   0.8953     68.470  0.8890    68.556  44.44
   9   0.8195     71.460  0.8330    70.634  49.82
  10   0.7832     72.520  0.7852    72.472  55.14
  11   0.7788     73.470  0.7398    74.240  60.46
  12   0.7087     75.660  0.6994    75.748  65.80
  13   0.6994     76.480  0.6621    76.850  71.12
  14   0.6814     76.870  0.6341    77.968  76.43
  15   0.6589     77.890  0.5967    79.496  81.75
  16   0.6801     77.220  0.5843    79.840  87.15
  17   0.6599     77.480  0.5494    80.954  92.48
  18   0.6212     79.200  0.5293    81.788  97.79
  19   0.5925     79.980  0.5097    82.408  103.14
  20   0.6232     79.100  0.4844    83.324  108.50
  21   0.6184     79.730  0.4650    83.970  113.82
  22   0.5846     80.520  0.4414    84.778  119.24
  23   0.5924     80.570  0.4320    85.214  124.62
  24   0.5844     81.660  0.4127    86.002  129.94
  25   0.5797     81.490  0.3913    86.512  135.28
  26   0.5973     80.850  0.3864    86.842  140.61
  27   0.5427     82.400  0.3619    87.666  145.95
  28   0.5878     81.470  0.3466    88.112  151.30
  29   0.5422     83.010  0.3367    88.500  156.71
  30   0.5809     81.900  0.3218    89.066  162.08
  31   0.5817     82.450  0.3097    89.388  167.43
  32   0.5519     82.850  0.2992    89.832  172.76
  33   0.5684     82.990  0.2900    89.982  178.08
  34   0.5605     82.820  0.2758    90.544  183.41
  35   0.5357     83.290  0.2617    91.112  188.76
  36   0.5574     83.100  0.2549    91.344  194.20
  37   0.5715     83.270  0.2377    91.834  199.53
  38   0.6505     81.210  0.2316    92.040  204.87
  39   0.5621     83.780  0.2259    92.298  210.23
  40   0.5752     83.670  0.2144    92.668  215.57
  41   0.5962     83.460  0.2043    92.930  220.91
  42   0.5771     84.020  0.1960    93.402  226.29
  43   0.6496     83.170  0.1891    93.592  231.61
  44   0.6131     83.630  0.1857    93.708  236.94
  45   0.5979     83.690  0.1826    93.780  242.29
  46   0.6181     83.280  0.1736    94.072  247.64
  47   0.6235     83.530  0.1637    94.352  252.97
  48   0.6074     84.310  0.1591    94.532  258.30
  49   0.6031     83.800  0.1561    94.644  263.72
  50   0.6161     84.120  0.1516    94.728  269.10
  51   0.6198     84.630  0.1465    95.026  274.46
  52   0.6367     83.800  0.1378    95.248  279.84
  53   0.6421     83.960  0.1373    95.392  285.17
  54   0.6526     83.810  0.1334    95.480  290.50
  55   0.6446     84.050  0.1294    95.630  295.88
  56   0.6475     84.130  0.1218    95.914  301.21
  57   0.6811     83.310  0.1244    95.682  306.58
  58   0.6488     83.910  0.1197    95.874  311.94
  59   0.6219     84.670  0.1108    96.168  317.29
  60   0.6168     84.670  0.1133    96.148  322.65
  61   0.6179     84.170  0.1112    96.184  327.98
  62   0.6814     83.780  0.1006    96.596  333.38
  63   0.7083     83.220  0.1077    96.430  338.73
  64   0.6831     84.680  0.1015    96.518  344.05
  65   0.6546     84.520  0.0987    96.596  349.40
  66   0.6190     84.390  0.0976    96.684  354.72
  67   0.6668     85.040  0.0917    96.866  360.07
  68   0.6814     83.840  0.0916    96.874  365.47
  69   0.6825     83.990  0.0914    96.948  370.80
  70   0.7225     84.540  0.0910    96.944  376.18
  71   0.6471     84.680  0.0880    97.032  381.52
  72   0.6950     84.360  0.0803    97.312  386.89
  73   0.6282     84.960  0.0857    97.082  392.25
  74   0.6691     84.460  0.0833    97.174  397.59
  75   0.6729     85.110  0.0778    97.368  402.99
  76   0.6773     84.780  0.0795    97.276  408.34
  77   0.7014     84.830  0.0778    97.340  413.72
  78   0.7094     84.660  0.0799    97.312  419.06
  79   0.7639     84.460  0.0703    97.674  424.41
  80   0.6423     84.690  0.0777    97.512  429.76
  81   0.7059     84.980  0.0700    97.674  435.20
  82   0.6680     84.930  0.0700    97.732  440.55
  83   0.6903     85.200  0.0732    97.510  445.90
  84   0.6981     84.840  0.0702    97.704  451.23
  85   0.6775     85.050  0.0701    97.642  456.57
