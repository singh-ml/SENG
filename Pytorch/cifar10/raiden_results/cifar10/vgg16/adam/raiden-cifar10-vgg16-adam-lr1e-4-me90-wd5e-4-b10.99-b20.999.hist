Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4041537024 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9266     20.930  2.1308    16.262  7.08
   2   1.8032     26.230  1.9034    21.938  12.41
   3   1.6348     35.490  1.7657    28.730  17.76
   4   1.5204     40.160  1.6091    35.832  23.11
   5   1.4482     43.160  1.5039    41.440  28.46
   6   1.3780     45.800  1.4301    45.346  33.79
   7   1.2656     52.450  1.3660    48.068  39.23
   8   1.1705     56.390  1.2661    52.744  44.60
   9   1.1518     58.430  1.2030    55.508  49.94
  10   1.0861     60.770  1.1252    59.032  55.27
  11   0.9720     65.250  1.0328    62.720  60.60
  12   0.9487     66.250  0.9730    65.262  65.94
  13   0.9259     67.390  0.9192    67.424  71.27
  14   0.8855     69.060  0.8798    68.976  76.66
  15   0.8191     71.210  0.8312    70.752  82.01
  16   0.7861     72.280  0.7758    72.736  87.34
  17   0.7460     74.200  0.7288    74.734  92.66
  18   0.7238     74.850  0.6969    75.890  97.99
  19   0.7173     75.940  0.6589    77.168  103.33
  20   0.6874     76.750  0.6366    77.948  108.70
  21   0.6646     77.370  0.6075    78.974  114.05
  22   0.6825     77.110  0.5924    79.718  119.37
  23   0.6688     78.200  0.5647    80.826  124.70
  24   0.6096     79.400  0.5449    81.582  130.03
  25   0.5799     80.840  0.5230    82.236  135.38
  26   0.6009     80.790  0.4903    83.412  140.71
  27   0.5969     79.790  0.4836    83.616  146.13
  28   0.5920     80.710  0.4790    83.866  151.48
  29   0.6013     80.540  0.4858    83.528  156.84
  30   0.5587     82.290  0.4339    85.464  162.15
  31   0.5636     82.240  0.4109    86.202  167.49
  32   0.5458     82.620  0.3954    86.858  172.81
  33   0.5636     81.520  0.3831    87.226  178.15
  34   0.5771     81.730  0.3714    87.528  183.57
  35   0.5519     82.290  0.3561    87.966  188.90
  36   0.5753     82.590  0.3569    88.038  194.24
  37   0.5332     83.490  0.3372    88.810  199.60
  38   0.5497     82.820  0.3372    88.782  204.92
  39   0.5493     83.290  0.3394    88.574  210.29
  40   0.5666     83.000  0.3137    89.480  215.74
  41   0.5493     83.490  0.2917    90.338  221.06
  42   0.5549     83.560  0.2746    90.846  226.39
  43   0.5465     83.740  0.2752    90.802  231.73
  44   0.5469     83.950  0.2678    91.008  237.06
  45   0.5681     83.720  0.2535    91.476  242.41
  46   0.5436     84.150  0.2430    91.818  247.80
  47   0.5760     83.720  0.2356    92.114  253.13
  48   0.5512     84.400  0.2340    92.208  258.46
  49   0.6083     84.030  0.2301    92.414  263.81
  50   0.5844     84.460  0.2215    92.786  269.12
  51   0.5506     83.940  0.2047    93.270  274.45
  52   0.5452     84.830  0.2065    93.170  279.82
  53   0.5687     84.260  0.1942    93.472  285.19
  54   0.5721     84.260  0.1912    93.654  290.54
  55   0.5597     84.570  0.1848    93.810  295.86
  56   0.5592     84.600  0.1804    94.112  301.21
  57   0.5802     84.350  0.1774    94.120  306.54
  58   0.6007     84.530  0.1744    94.120  311.87
  59   0.5651     84.540  0.1679    94.360  317.20
  60   0.5786     84.140  0.1720    94.244  322.63
  61   0.6262     84.740  0.1764    94.182  327.96
  62   0.6071     84.780  0.1683    94.492  333.29
  63   0.6070     84.320  0.1548    94.966  338.64
  64   0.5802     84.870  0.1553    94.984  343.98
  65   0.5675     85.100  0.1458    95.116  349.33
  66   0.5914     85.310  0.1302    95.754  354.74
  67   0.6136     84.830  0.1356    95.506  360.11
  68   0.6261     84.660  0.1412    95.374  365.44
  69   0.6142     85.200  0.1322    95.670  370.78
  70   0.6355     84.800  0.1220    95.864  376.10
  71   0.5918     85.420  0.1221    95.992  381.42
  72   0.6124     85.400  0.1217    95.892  386.79
  73   0.5920     85.160  0.1153    96.162  392.12
  74   0.5845     85.710  0.1293    95.766  397.44
  75   0.5680     85.590  0.1167    96.168  402.77
  76   0.6179     85.530  0.1003    96.578  408.10
  77   0.5986     85.930  0.1040    96.494  413.47
  78   0.6030     85.520  0.0992    96.714  418.88
  79   0.6600     85.080  0.0977    96.788  424.24
  80   0.6263     85.490  0.0944    96.922  429.58
  81   0.6406     85.230  0.0916    96.968  434.93
  82   0.6313     85.660  0.0945    96.894  440.29
  83   0.6241     85.450  0.0974    96.684  445.63
  84   0.6322     85.510  0.0990    96.742  450.98
  85   0.6708     84.710  0.0882    97.130  456.39
  86   0.6807     85.510  0.0880    97.128  461.77
  87   0.6465     85.260  0.0950    96.920  467.12
  88   0.6672     85.490  0.0846    97.332  472.45
  89   0.6119     85.270  0.0878    97.034  477.77
  90   0.5922     85.240  0.1043    96.588  483.09
