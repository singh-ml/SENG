Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7162     31.390  1.9791    20.702  6.91
   2   1.5281     41.830  1.6332    35.280  12.22
   3   1.2487     52.830  1.3782    47.790  17.51
   4   1.1756     56.700  1.2027    55.756  22.85
   5   0.9629     65.660  1.0821    61.036  28.20
   6   0.9304     68.300  0.9775    65.078  33.60
   7   0.9206     68.220  0.8831    69.014  38.89
   8   0.8046     71.520  0.8254    71.354  44.21
   9   0.7498     75.040  0.7622    73.538  49.55
  10   0.6838     77.000  0.7028    75.966  54.87
  11   0.7297     75.410  0.6614    77.340  60.18
  12   0.6358     79.230  0.6281    78.860  65.50
  13   0.6626     77.700  0.5870    80.112  70.91
  14   0.6059     79.930  0.5532    81.202  76.28
  15   0.5798     81.220  0.5302    82.168  81.58
  16   0.6023     80.620  0.5031    83.086  86.88
  17   0.5584     82.080  0.4752    84.178  92.20
  18   0.5887     81.800  0.4542    84.844  97.53
  19   0.5643     82.880  0.4310    85.658  102.92
  20   0.5478     82.920  0.4050    86.508  108.24
  21   0.4996     83.980  0.3905    87.100  113.58
  22   0.5090     83.370  0.3736    87.520  118.90
  23   0.5284     83.620  0.3532    88.328  124.24
  24   0.5583     83.590  0.3382    88.862  129.57
  25   0.4889     84.490  0.3294    89.056  134.98
  26   0.5714     83.480  0.3034    89.818  140.30
  27   0.5137     84.190  0.3006    89.994  145.65
  28   0.4797     85.660  0.2818    90.680  150.96
  29   0.5199     85.070  0.2727    91.032  156.32
  30   0.4719     85.760  0.2593    91.350  161.66
  31   0.4813     85.570  0.2550    91.584  167.07
  32   0.5202     85.050  0.2465    91.944  172.38
  33   0.5091     84.210  0.2343    92.242  177.70
  34   0.4960     85.930  0.2246    92.616  183.02
  35   0.4979     85.630  0.2172    92.938  188.36
  36   0.4812     85.850  0.1993    93.440  193.71
  37   0.5625     85.660  0.2057    93.406  199.06
  38   0.5067     86.090  0.1870    93.942  204.46
  39   0.4943     86.770  0.1929    93.752  209.77
  40   0.5051     86.030  0.1783    94.172  215.11
  41   0.5295     85.510  0.1759    94.216  220.45
  42   0.5369     86.090  0.1676    94.432  225.81
  43   0.5202     86.230  0.1611    94.782  231.15
  44   0.5225     86.530  0.1585    94.932  236.61
  45   0.4787     87.120  0.1498    95.200  241.93
  46   0.4922     86.170  0.1467    95.140  247.24
  47   0.4835     86.800  0.1435    95.392  252.58
  48   0.5055     86.570  0.1361    95.584  257.89
  49   0.4923     86.800  0.1350    95.614  263.22
  50   0.5098     86.300  0.1253    95.958  268.53
  51   0.5096     87.410  0.1231    95.948  273.85
  52   0.5046     87.720  0.1240    95.958  279.20
  53   0.5529     86.290  0.1207    96.104  284.51
  54   0.5494     86.110  0.1116    96.346  289.82
  55   0.5496     86.220  0.1215    96.154  295.16
  56   0.4997     87.500  0.1042    96.582  300.52
  57   0.5559     87.520  0.1092    96.480  305.91
  58   0.5308     87.130  0.1127    96.364  311.27
  59   0.5324     86.560  0.1007    96.772  316.58
  60   0.5455     87.050  0.1048    96.710  321.89
  61   0.5536     87.100  0.0969    96.942  327.25
  62   0.5128     87.410  0.0997    96.880  332.55
  63   0.5242     87.200  0.0956    96.912  337.92
  64   0.5407     86.830  0.1016    96.804  343.24
  65   0.5006     87.970  0.0934    97.002  348.59
  66   0.5124     87.830  0.0880    97.196  353.94
  67   0.5219     87.380  0.0915    97.112  359.28
  68   0.5561     86.350  0.0849    97.328  364.62
  69   0.5222     87.780  0.0845    97.332  369.97
  70   0.5640     87.350  0.0884    97.224  375.36
  71   0.5380     87.300  0.0865    97.268  380.68
  72   0.5125     87.870  0.0796    97.448  385.99
  73   0.5307     87.580  0.0773    97.434  391.31
  74   0.4853     88.260  0.0823    97.430  396.64
  75   0.5847     86.690  0.0772    97.516  401.99
  76   0.5248     87.940  0.0802    97.434  407.30
  77   0.5180     88.080  0.0771    97.498  412.76
  78   0.5590     87.350  0.0690    97.782  418.08
  79   0.5182     87.860  0.0755    97.550  423.40
  80   0.5385     87.950  0.0791    97.590  428.73
  81   0.5183     87.360  0.0715    97.684  434.07
  82   0.5673     87.510  0.0753    97.666  439.38
  83   0.5997     87.140  0.0702    97.792  444.72
  84   0.5326     87.880  0.0724    97.696  450.05
  85   0.5604     87.230  0.0731    97.648  455.39
  86   0.5157     87.710  0.0665    97.886  460.76
  87   0.5327     87.500  0.0698    97.846  466.08
  88   0.6210     87.650  0.0687    97.812  471.42
  89   0.5337     88.080  0.0620    98.016  476.74
  90   0.5386     87.900  0.0682    97.862  482.12
