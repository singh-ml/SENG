Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8375     22.830  2.0872    16.730  7.04
   2   1.5444     40.110  1.7242    31.134  12.49
   3   1.3290     49.610  1.4443    45.234  17.81
   4   1.2128     56.530  1.2563    53.892  23.12
   5   1.0295     63.350  1.1063    59.922  28.44
   6   0.9930     64.920  1.0073    64.236  33.75
   7   0.9254     67.520  0.9149    67.610  39.08
   8   0.8608     70.100  0.8423    70.656  44.47
   9   0.7457     74.150  0.7796    72.936  49.79
  10   0.7495     74.660  0.7201    75.238  55.16
  11   0.7715     74.740  0.6824    76.432  60.46
  12   0.6853     76.490  0.6352    78.420  65.76
  13   0.6703     77.780  0.6068    79.406  71.08
  14   0.6046     79.660  0.5697    80.628  76.47
  15   0.6147     79.670  0.5413    81.904  81.80
  16   0.6170     79.450  0.5144    83.042  87.12
  17   0.5463     81.710  0.4935    83.368  92.42
  18   0.5971     80.910  0.4585    84.656  97.75
  19   0.6354     79.440  0.4382    85.296  103.09
  20   0.6028     80.940  0.4190    86.068  108.43
  21   0.5617     82.030  0.4033    86.426  113.81
  22   0.5375     83.110  0.3795    87.330  119.14
  23   0.5568     82.580  0.3571    88.024  124.47
  24   0.5156     84.060  0.3475    88.340  129.78
  25   0.5248     83.140  0.3284    89.158  135.15
  26   0.5318     84.000  0.3181    89.412  140.54
  27   0.5269     83.710  0.2978    90.136  145.85
  28   0.5574     83.980  0.2855    90.382  151.20
  29   0.5018     84.500  0.2712    90.916  156.53
  30   0.5396     83.840  0.2638    91.304  161.83
  31   0.5463     84.330  0.2595    91.312  167.20
  32   0.5060     85.320  0.2445    91.880  172.56
  33   0.5165     85.500  0.2366    92.158  177.96
  34   0.5288     85.290  0.2235    92.554  183.30
  35   0.5142     85.440  0.2239    92.628  188.63
  36   0.5232     85.290  0.2069    93.072  193.96
  37   0.4978     85.650  0.1960    93.566  199.27
  38   0.5007     85.580  0.1941    93.672  204.57
  39   0.5847     85.270  0.1896    93.784  209.90
  40   0.5460     85.310  0.1782    94.066  215.32
  41   0.5830     85.930  0.1673    94.434  220.65
  42   0.5373     85.940  0.1723    94.208  225.98
  43   0.5771     85.190  0.1590    94.766  231.29
  44   0.5431     86.250  0.1542    94.992  236.61
  45   0.5711     86.120  0.1539    94.966  241.92
  46   0.5514     86.310  0.1428    95.320  247.31
  47   0.5406     86.250  0.1456    95.282  252.66
  48   0.5466     86.410  0.1410    95.396  257.99
  49   0.5756     85.590  0.1275    95.820  263.35
  50   0.5312     85.980  0.1310    95.632  268.69
  51   0.5264     86.280  0.1276    95.816  274.00
  52   0.5447     87.070  0.1189    96.142  279.34
  53   0.5606     85.890  0.1124    96.304  284.72
  54   0.5491     86.970  0.1130    96.282  290.06
  55   0.6071     86.490  0.1066    96.486  295.43
  56   0.5877     86.110  0.1173    96.246  300.76
  57   0.5697     87.020  0.1059    96.500  306.08
  58   0.5618     86.400  0.1026    96.718  311.39
  59   0.6229     85.700  0.1048    96.590  316.81
  60   0.5699     86.280  0.0979    96.792  322.14
  61   0.5905     86.770  0.0990    96.800  327.46
  62   0.6048     85.960  0.0936    97.074  332.78
  63   0.6585     86.010  0.0924    97.022  338.09
  64   0.6263     86.510  0.0864    97.220  343.42
  65   0.5426     86.750  0.0919    97.130  348.81
  66   0.5596     86.690  0.0835    97.294  354.12
  67   0.5595     87.420  0.0877    97.216  359.42
  68   0.6289     86.950  0.0857    97.322  364.73
  69   0.5703     86.760  0.0833    97.318  370.04
  70   0.6118     87.160  0.0802    97.514  375.37
  71   0.6326     86.790  0.0823    97.380  380.69
  72   0.5782     87.050  0.0789    97.566  386.08
  73   0.5245     87.470  0.0799    97.404  391.41
  74   0.5835     87.550  0.0787    97.554  396.77
  75   0.6257     87.210  0.0762    97.502  402.08
  76   0.5566     87.210  0.0789    97.474  407.40
  77   0.5743     87.160  0.0688    97.802  412.73
  78   0.5624     86.940  0.0736    97.692  418.06
  79   0.6185     86.940  0.0705    97.698  423.47
  80   0.6484     87.420  0.0683    97.862  428.82
  81   0.5808     87.290  0.0700    97.770  434.17
  82   0.6511     87.220  0.0715    97.740  439.50
  83   0.5862     87.380  0.0668    97.876  444.82
  84   0.6098     86.710  0.0645    97.974  450.14
  85   0.5944     86.650  0.0666    97.860  455.47
