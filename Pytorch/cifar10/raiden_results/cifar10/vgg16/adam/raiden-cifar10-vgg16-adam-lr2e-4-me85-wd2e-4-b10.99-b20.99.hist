Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8735     23.240  2.0927    17.654  7.00
   2   1.7764     30.760  1.8662    24.188  12.40
   3   1.5451     38.880  1.6872    33.172  17.75
   4   1.4191     45.920  1.5020    41.882  23.10
   5   1.3366     50.640  1.3653    48.194  28.44
   6   1.1989     54.880  1.2786    52.172  33.76
   7   1.1251     59.150  1.1633    57.070  39.10
   8   1.0243     63.810  1.0773    60.752  44.41
   9   0.9320     66.730  0.9937    64.304  49.82
  10   0.8894     69.090  0.9209    67.244  55.15
  11   0.8942     68.990  0.8614    69.282  60.50
  12   0.7986     72.140  0.8010    71.980  65.80
  13   0.7688     73.500  0.7685    73.240  71.13
  14   0.7189     75.880  0.7087    75.318  76.56
  15   0.7137     76.230  0.6837    76.264  81.87
  16   0.6565     78.380  0.6325    77.934  87.18
  17   0.6447     78.690  0.6111    79.096  92.49
  18   0.6393     78.180  0.5780    80.352  97.80
  19   0.6326     79.160  0.5644    80.916  103.12
  20   0.5877     80.420  0.5478    81.266  108.49
  21   0.5693     80.970  0.5181    82.642  113.80
  22   0.6223     79.650  0.4892    83.506  119.15
  23   0.6165     80.550  0.4708    84.184  124.48
  24   0.5721     81.910  0.4614    84.346  129.82
  25   0.5635     82.120  0.4355    85.286  135.15
  26   0.5764     81.730  0.4295    85.554  140.49
  27   0.5637     82.240  0.4165    86.128  145.90
  28   0.5420     83.450  0.3775    87.144  151.21
  29   0.5309     83.460  0.3721    87.482  156.55
  30   0.5528     82.760  0.3561    88.146  161.85
  31   0.5367     83.680  0.3573    88.038  167.16
  32   0.5487     83.360  0.3351    88.956  172.49
  33   0.5384     83.910  0.3257    89.006  177.79
  34   0.5365     84.330  0.3157    89.546  183.18
  35   0.5254     84.240  0.3027    89.882  188.51
  36   0.5445     83.860  0.3002    90.132  193.85
  37   0.5081     84.490  0.2817    90.608  199.15
  38   0.5277     84.240  0.2667    91.206  204.48
  39   0.5058     84.800  0.2758    90.726  209.78
  40   0.5082     84.870  0.2653    91.144  215.18
  41   0.4930     85.610  0.2490    91.780  220.55
  42   0.5039     85.080  0.2294    92.332  225.86
  43   0.5063     85.130  0.2331    92.304  231.21
  44   0.5051     85.220  0.2358    92.170  236.55
  45   0.5079     86.170  0.2301    92.546  241.90
  46   0.5274     85.030  0.2098    93.166  247.35
  47   0.5076     85.700  0.2078    93.194  252.67
  48   0.5917     85.000  0.2168    92.730  258.00
  49   0.5089     85.990  0.2005    93.446  263.30
  50   0.5414     86.140  0.1792    94.054  268.60
  51   0.5101     86.550  0.1753    94.202  273.95
  52   0.5720     85.350  0.1803    94.092  279.26
  53   0.5152     86.330  0.1704    94.378  284.68
  54   0.5273     86.240  0.1657    94.558  290.00
  55   0.4812     86.270  0.1686    94.482  295.33
  56   0.5563     86.100  0.1692    94.546  300.67
  57   0.5421     86.010  0.1527    94.976  306.00
  58   0.5361     86.060  0.1615    94.706  311.35
  59   0.5450     86.210  0.1616    94.638  316.76
  60   0.5481     86.630  0.1441    95.344  322.07
  61   0.5137     86.740  0.1525    95.028  327.38
  62   0.5188     86.440  0.1420    95.370  332.70
  63   0.5408     86.930  0.1309    95.730  338.06
  64   0.5483     86.560  0.1311    95.676  343.38
  65   0.5370     86.460  0.1335    95.682  348.72
  66   0.5236     86.340  0.1258    95.876  354.09
  67   0.5242     86.540  0.1330    95.744  359.44
  68   0.5474     86.030  0.1257    95.790  364.76
  69   0.5499     86.410  0.1277    95.876  370.12
  70   0.5072     86.820  0.1244    95.912  375.53
  71   0.5933     86.890  0.1122    96.276  380.85
  72   0.5487     86.190  0.1208    96.044  386.26
  73   0.5446     87.160  0.1072    96.534  391.62
  74   0.5865     86.860  0.1042    96.622  396.95
  75   0.5449     87.220  0.1006    96.738  402.27
  76   0.5607     85.870  0.1127    96.366  407.60
  77   0.5785     86.830  0.1170    96.236  412.89
  78   0.5738     86.650  0.1025    96.634  418.32
  79   0.5491     87.180  0.1016    96.680  423.68
  80   0.5480     87.380  0.0999    96.802  429.02
  81   0.5519     87.220  0.0974    96.838  434.36
  82   0.5392     87.600  0.0986    96.814  439.68
  83   0.5589     87.540  0.0915    97.146  444.99
  84   0.5477     87.440  0.0949    96.906  450.36
  85   0.5251     87.370  0.0864    97.246  455.75
