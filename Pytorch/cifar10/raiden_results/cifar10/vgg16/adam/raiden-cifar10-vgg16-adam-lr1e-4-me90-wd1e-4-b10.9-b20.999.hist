Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6778     34.370  1.9498    22.716  6.93
   2   1.4069     47.130  1.5860    38.962  12.25
   3   1.3301     50.060  1.3805    48.584  17.63
   4   1.3063     52.980  1.2457    54.496  22.94
   5   1.0403     62.850  1.1345    59.064  28.28
   6   1.0100     63.590  1.0503    62.216  33.62
   7   0.9981     64.930  0.9745    65.254  38.94
   8   0.8613     69.870  0.9075    67.766  44.25
   9   0.8481     70.720  0.8471    70.044  49.62
  10   0.8315     71.540  0.8045    71.672  54.97
  11   0.7501     74.140  0.7529    73.552  60.30
  12   0.7139     75.160  0.7178    75.080  65.62
  13   0.7171     75.410  0.6773    76.488  70.97
  14   0.6955     76.200  0.6474    77.414  76.29
  15   0.6624     77.030  0.6161    78.768  81.68
  16   0.6621     77.510  0.5960    79.540  87.01
  17   0.6275     78.200  0.5648    80.626  92.37
  18   0.5992     79.520  0.5468    81.170  97.70
  19   0.6041     79.520  0.5223    81.980  103.06
  20   0.5944     79.730  0.5000    82.644  108.40
  21   0.6271     79.560  0.4829    83.432  113.85
  22   0.5856     80.750  0.4620    84.188  119.19
  23   0.6120     79.960  0.4348    85.150  124.52
  24   0.5653     81.030  0.4265    85.328  129.85
  25   0.5818     80.910  0.4044    86.068  135.20
  26   0.5524     81.760  0.3926    86.520  140.57
  27   0.5641     81.340  0.3743    87.108  145.90
  28   0.5662     81.690  0.3681    87.424  151.28
  29   0.6022     81.020  0.3407    88.252  156.62
  30   0.5669     82.070  0.3321    88.510  161.99
  31   0.5528     82.610  0.3191    89.138  167.34
  32   0.5587     82.520  0.3157    89.276  172.71
  33   0.5829     81.990  0.2949    89.812  178.06
  34   0.5617     83.150  0.2847    90.312  183.41
  35   0.5266     83.550  0.2705    90.654  188.73
  36   0.5713     82.920  0.2585    91.166  194.10
  37   0.5808     82.810  0.2567    91.198  199.45
  38   0.6058     82.800  0.2395    91.826  204.82
  39   0.5698     83.700  0.2326    92.090  210.15
  40   0.6050     82.730  0.2227    92.268  215.49
  41   0.5985     82.630  0.2150    92.616  220.88
  42   0.5898     83.230  0.2033    93.110  226.32
  43   0.5773     83.350  0.1935    93.420  231.63
  44   0.5959     83.410  0.1965    93.270  236.98
  45   0.5987     83.200  0.1811    93.794  242.30
  46   0.6189     84.100  0.1741    94.034  247.63
  47   0.5996     83.270  0.1726    94.084  252.97
  48   0.6000     83.180  0.1620    94.512  258.37
  49   0.6170     83.910  0.1579    94.598  263.69
  50   0.6107     83.890  0.1542    94.660  269.03
  51   0.6436     84.050  0.1475    95.042  274.35
  52   0.6090     83.200  0.1462    95.012  279.68
  53   0.6366     83.980  0.1394    95.248  285.00
  54   0.6788     82.410  0.1330    95.564  290.40
  55   0.6244     83.640  0.1346    95.354  295.75
  56   0.6540     83.620  0.1258    95.730  301.07
  57   0.6190     84.300  0.1204    95.862  306.39
  58   0.6299     83.740  0.1175    96.056  311.71
  59   0.6454     84.000  0.1117    96.344  317.07
  60   0.6256     83.930  0.1089    96.256  322.47
  61   0.6723     83.990  0.1071    96.406  327.79
  62   0.6701     83.610  0.1081    96.380  333.17
  63   0.6892     83.580  0.1113    96.290  338.49
  64   0.6313     84.480  0.1032    96.514  343.86
  65   0.6705     83.990  0.0978    96.728  349.22
  66   0.6358     84.820  0.0971    96.786  354.57
  67   0.6353     84.160  0.1005    96.718  359.93
  68   0.7112     83.250  0.0957    96.800  365.27
  69   0.6878     83.340  0.0909    96.846  370.61
  70   0.6770     83.900  0.0904    96.868  375.94
  71   0.6888     84.600  0.0903    96.936  381.31
  72   0.6645     84.170  0.0854    97.086  386.65
  73   0.6469     84.130  0.0883    97.018  391.99
  74   0.6455     85.010  0.0814    97.300  397.34
  75   0.7024     84.220  0.0778    97.386  402.74
  76   0.6102     84.520  0.0786    97.348  408.09
  77   0.6546     84.700  0.0760    97.408  413.41
  78   0.6556     84.480  0.0824    97.182  418.76
  79   0.6725     85.000  0.0773    97.426  424.10
  80   0.6916     84.400  0.0696    97.668  429.43
  81   0.6838     84.380  0.0715    97.594  434.84
  82   0.6761     84.880  0.0741    97.588  440.21
  83   0.6805     85.060  0.0714    97.648  445.54
  84   0.6619     84.340  0.0714    97.618  450.89
  85   0.6958     84.780  0.0688    97.700  456.22
  86   0.6809     84.760  0.0712    97.664  461.57
  87   0.6922     84.730  0.0619    97.886  467.02
  88   0.7358     84.860  0.0627    97.922  472.39
  89   0.6724     84.690  0.0711    97.618  477.72
  90   0.6915     84.960  0.0618    97.942  483.08
