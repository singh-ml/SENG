Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4041537024 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1617     17.850  2.6267    13.168  6.98
   2   1.9661     23.070  2.0864    19.286  12.31
   3   1.8568     27.340  1.9389    22.840  17.65
   4   1.8045     29.780  1.8294    27.694  23.00
   5   1.6600     34.400  1.7456    31.836  28.32
   6   1.5845     37.370  1.6571    34.898  33.73
   7   1.5012     41.190  1.5699    38.662  39.07
   8   1.4240     45.170  1.4746    43.002  44.44
   9   1.3146     50.710  1.3936    47.320  49.82
  10   1.2279     54.750  1.3067    51.706  55.16
  11   1.1180     59.770  1.1945    56.896  60.47
  12   1.0640     61.840  1.1015    60.432  65.89
  13   0.9881     64.160  1.0676    61.898  71.20
  14   0.9437     66.710  0.9871    64.782  76.54
  15   0.9057     68.270  0.9438    66.626  81.89
  16   0.8903     69.120  0.8735    69.190  87.23
  17   0.8509     71.090  0.8561    69.806  92.55
  18   0.8491     69.720  0.8259    71.202  97.86
  19   0.7682     73.570  0.7830    72.820  103.27
  20   0.7789     74.170  0.7503    73.936  108.59
  21   0.7276     75.920  0.7258    74.938  113.94
  22   0.7100     75.630  0.7043    75.752  119.29
  23   0.6998     77.080  0.6763    77.008  124.61
  24   0.7238     76.310  0.6670    77.536  129.98
  25   0.6986     76.830  0.6369    78.480  135.30
  26   0.6596     78.990  0.6174    79.378  140.72
  27   0.6372     79.080  0.6082    79.800  146.04
  28   0.6562     78.630  0.5974    80.124  151.39
  29   0.6616     78.600  0.5868    80.484  156.74
  30   0.6232     79.860  0.5666    81.386  162.05
  31   0.6509     79.700  0.5520    81.618  167.40
  32   0.6240     79.660  0.5496    82.092  172.73
  33   0.6020     80.760  0.5325    82.500  178.06
  34   0.5899     81.360  0.5272    82.722  183.40
  35   0.5860     81.720  0.5251    82.792  188.74
  36   0.5896     80.900  0.5090    83.218  194.08
  37   0.6359     80.280  0.5004    83.682  199.42
  38   0.5829     80.880  0.4941    83.872  204.74
  39   0.5555     81.990  0.4850    84.458  210.13
  40   0.5490     82.590  0.4815    84.276  215.45
  41   0.5909     81.420  0.4777    84.480  220.78
  42   0.5813     81.450  0.4581    85.016  226.11
  43   0.5426     82.510  0.4563    85.144  231.45
  44   0.5492     83.200  0.4500    85.466  236.78
  45   0.5228     82.810  0.4499    85.354  242.17
  46   0.5740     82.400  0.4494    85.264  247.49
  47   0.5526     83.280  0.4331    85.740  252.81
  48   0.5278     83.170  0.4381    85.838  258.13
  49   0.5690     83.120  0.4312    86.002  263.47
  50   0.5714     82.280  0.4317    86.020  268.80
  51   0.4987     84.320  0.4224    86.342  274.20
  52   0.5301     83.290  0.4162    86.532  279.55
  53   0.5086     84.060  0.4009    86.886  284.91
  54   0.5128     84.380  0.4062    86.862  290.24
  55   0.5290     84.120  0.4034    86.802  295.57
  56   0.5694     83.010  0.3983    87.164  300.90
  57   0.5289     84.330  0.4029    87.092  306.22
  58   0.5194     83.940  0.3873    87.380  311.54
  59   0.5256     84.030  0.3872    87.408  316.96
  60   0.5189     84.080  0.3904    87.448  322.29
  61   0.5252     84.310  0.3865    87.478  327.63
  62   0.5197     84.070  0.3851    87.522  332.98
  63   0.4956     84.290  0.3772    87.734  338.30
  64   0.5136     84.220  0.3767    87.832  343.62
  65   0.5100     84.780  0.3658    87.948  349.04
  66   0.5304     84.270  0.3665    88.270  354.36
  67   0.5027     84.700  0.3660    88.236  359.69
  68   0.5040     84.980  0.3708    87.882  365.01
  69   0.4947     84.900  0.3698    88.368  370.37
  70   0.4974     84.890  0.3555    88.582  375.71
  71   0.5092     85.450  0.3566    88.512  381.12
  72   0.4953     85.240  0.3633    88.402  386.44
  73   0.4930     85.190  0.3474    88.838  391.81
  74   0.4873     85.030  0.3478    88.814  397.14
  75   0.4870     85.430  0.3449    88.854  402.46
  76   0.5201     84.720  0.3591    88.378  407.82
  77   0.5105     84.920  0.3443    88.910  413.16
  78   0.5000     84.700  0.3467    88.804  418.58
  79   0.4903     85.360  0.3491    88.752  423.90
  80   0.4841     85.310  0.3266    89.486  429.25
  81   0.4817     85.150  0.3446    88.816  434.58
  82   0.5035     85.520  0.3362    89.288  439.89
  83   0.5018     85.200  0.3371    89.148  445.26
  84   0.5050     84.970  0.3404    89.322  450.67
  85   0.4748     85.570  0.3342    89.466  455.98
