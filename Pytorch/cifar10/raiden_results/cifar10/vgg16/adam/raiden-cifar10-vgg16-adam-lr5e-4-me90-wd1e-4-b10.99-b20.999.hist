Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0037     18.900  2.2413    15.686  6.92
   2   1.8768     22.980  1.9459    20.968  12.24
   3   1.7849     28.410  1.8495    24.576  17.60
   4   1.6110     36.040  1.7208    31.056  22.96
   5   1.5363     39.410  1.6230    35.322  28.29
   6   1.4462     42.890  1.5295    40.262  33.63
   7   1.3465     48.910  1.4265    45.220  38.95
   8   1.2738     52.720  1.3043    50.966  44.28
   9   1.1998     56.530  1.2557    53.400  49.62
  10   1.1815     57.460  1.1652    57.184  54.93
  11   1.0184     63.170  1.0794    60.756  60.35
  12   0.9422     66.490  0.9897    64.608  65.72
  13   0.9656     65.780  0.9549    65.982  71.09
  14   0.9859     66.320  0.9552    66.782  76.45
  15   0.8862     69.310  0.9136    68.488  81.83
  16   0.8486     71.200  0.8540    70.700  87.18
  17   0.7933     72.860  0.8104    72.390  92.51
  18   0.7534     75.070  0.7544    74.492  97.84
  19   0.7685     74.560  0.7237    75.474  103.22
  20   0.7023     76.830  0.6777    77.300  108.57
  21   0.6600     78.440  0.6573    77.956  113.89
  22   0.6712     77.870  0.6206    79.150  119.22
  23   0.6528     79.290  0.5962    80.112  124.57
  24   0.6213     79.650  0.5696    81.134  129.93
  25   0.6204     79.990  0.5704    81.254  135.32
  26   0.6097     80.360  0.5640    81.290  140.64
  27   0.6030     80.770  0.5197    82.732  145.96
  28   0.5789     81.630  0.5069    83.294  151.28
  29   0.5711     81.510  0.4922    83.646  156.61
  30   0.5551     82.150  0.4694    84.466  161.94
  31   0.5336     82.940  0.4565    85.078  167.28
  32   0.5813     81.760  0.4413    85.398  172.68
  33   0.5700     83.050  0.4480    85.226  178.04
  34   0.5016     84.130  0.4184    86.282  183.37
  35   0.5519     83.260  0.4028    86.758  188.74
  36   0.5307     83.320  0.4099    86.506  194.07
  37   0.5284     83.320  0.3956    87.022  199.39
  38   0.4915     84.700  0.3678    87.724  204.79
  39   0.5049     84.210  0.3655    87.952  210.10
  40   0.5183     83.840  0.3754    87.738  215.42
  41   0.4890     84.960  0.3598    88.300  220.79
  42   0.5073     84.460  0.3352    88.918  226.11
  43   0.5092     85.080  0.3374    88.984  231.41
  44   0.4952     85.120  0.3170    89.716  236.82
  45   0.4830     85.670  0.3191    89.438  242.15
  46   0.4889     85.290  0.3185    89.566  247.50
  47   0.4952     85.230  0.3136    89.772  252.88
  48   0.4681     85.710  0.2978    90.228  258.22
  49   0.4877     85.350  0.2900    90.556  263.53
  50   0.4990     85.140  0.2895    90.524  268.89
  51   0.4898     85.950  0.2801    90.824  274.35
  52   0.4691     86.030  0.2827    90.816  279.70
  53   0.4910     85.510  0.2729    91.048  285.05
  54   0.4700     86.300  0.2587    91.542  290.39
  55   0.4647     86.190  0.2617    91.330  295.74
  56   0.4856     86.110  0.2555    91.526  301.05
  57   0.4662     86.130  0.2552    91.772  306.38
  58   0.4689     86.500  0.2448    91.954  311.81
  59   0.4702     86.430  0.2414    91.982  317.13
  60   0.4662     85.720  0.2429    92.058  322.45
  61   0.4835     85.700  0.2394    92.128  327.83
  62   0.4858     86.330  0.2317    92.474  333.17
  63   0.4758     86.750  0.2274    92.620  338.51
  64   0.5015     86.280  0.2218    92.756  343.86
  65   0.4775     86.920  0.2278    92.464  349.26
  66   0.4789     86.340  0.2258    92.410  354.62
  67   0.5117     86.300  0.2192    92.938  359.98
  68   0.4716     85.920  0.2146    92.952  365.32
  69   0.4775     86.480  0.2201    92.688  370.67
  70   0.4677     86.840  0.2056    93.298  376.04
  71   0.4733     87.090  0.2074    93.080  381.40
  72   0.4868     86.810  0.2006    93.486  386.78
  73   0.4628     87.080  0.2020    93.470  392.15
  74   0.4894     86.640  0.1948    93.568  397.53
  75   0.4488     87.210  0.1973    93.488  402.86
  76   0.4686     87.380  0.1894    93.740  408.19
  77   0.4573     87.360  0.1846    93.962  413.56
  78   0.4516     87.340  0.1930    93.724  418.94
  79   0.4717     87.440  0.1834    93.962  424.26
  80   0.4556     87.260  0.1875    93.758  429.59
  81   0.4801     87.000  0.1855    93.976  434.92
  82   0.4748     87.160  0.1801    94.084  440.25
  83   0.4917     86.790  0.1849    94.062  445.58
  84   0.4839     87.260  0.1814    94.038  450.92
  85   0.4455     87.360  0.1740    94.386  456.33
  86   0.5021     87.230  0.1687    94.512  461.68
  87   0.4793     87.260  0.1683    94.566  467.04
  88   0.4809     87.170  0.1693    94.450  472.40
  89   0.4701     87.480  0.1722    94.456  477.72
  90   0.4745     87.200  0.1571    94.884  483.04
