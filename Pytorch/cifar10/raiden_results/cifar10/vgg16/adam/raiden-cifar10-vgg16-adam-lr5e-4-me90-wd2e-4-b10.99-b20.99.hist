Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9939     19.910  2.1759    15.320  7.00
   2   1.8120     25.820  1.9064    22.298  12.32
   3   1.7632     29.340  1.8276    26.096  17.67
   4   1.6648     35.470  1.7582    30.536  22.99
   5   1.5638     39.640  1.6115    36.758  28.34
   6   1.4391     44.650  1.4935    41.894  33.67
   7   1.3657     49.530  1.3989    46.792  38.99
   8   1.2040     55.450  1.2905    51.896  44.32
   9   1.1561     57.410  1.1973    56.246  49.64
  10   1.1051     60.480  1.1104    60.244  55.04
  11   0.9893     64.230  1.0376    62.804  60.40
  12   0.9767     65.160  0.9663    65.616  65.71
  13   0.8472     69.870  0.9054    67.922  71.07
  14   0.8487     70.300  0.8338    70.436  76.40
  15   0.8478     70.470  0.8104    71.348  81.73
  16   0.7353     74.350  0.7559    73.826  87.09
  17   0.7141     75.450  0.7253    74.834  92.49
  18   0.7043     76.130  0.6842    76.246  97.83
  19   0.7076     76.470  0.6617    77.426  103.15
  20   0.6581     77.760  0.6524    77.848  108.50
  21   0.6445     78.670  0.6176    79.162  113.82
  22   0.6352     78.650  0.5954    79.842  119.18
  23   0.6232     79.790  0.5779    80.354  124.62
  24   0.6156     80.010  0.5624    80.886  129.94
  25   0.5860     81.010  0.5395    81.780  135.30
  26   0.5605     81.640  0.5185    82.848  140.64
  27   0.5875     81.240  0.4984    83.544  145.97
  28   0.5503     82.210  0.4710    84.194  151.29
  29   0.5677     81.880  0.4688    84.380  156.70
  30   0.5280     82.700  0.4605    84.666  162.04
  31   0.5538     81.930  0.4528    84.916  167.36
  32   0.5542     82.760  0.4382    85.472  172.71
  33   0.5100     83.760  0.4250    86.038  178.06
  34   0.5337     83.510  0.4164    86.102  183.39
  35   0.4976     83.700  0.4037    86.500  188.74
  36   0.5338     83.510  0.4018    86.606  194.16
  37   0.5261     83.640  0.4007    86.696  199.52
  38   0.4983     84.070  0.3899    87.172  204.86
  39   0.5217     83.820  0.3665    88.002  210.18
  40   0.5132     84.200  0.3737    87.750  215.50
  41   0.4967     84.450  0.3687    87.954  220.86
  42   0.5212     84.980  0.3395    88.784  226.25
  43   0.5080     84.300  0.3417    88.704  231.57
  44   0.5120     85.300  0.3510    88.428  236.93
  45   0.4720     85.440  0.3289    89.222  242.29
  46   0.4816     85.570  0.3261    89.124  247.64
  47   0.4703     86.210  0.3216    89.250  252.99
  48   0.4775     85.710  0.3160    89.596  258.42
  49   0.4879     85.110  0.3124    89.736  263.75
  50   0.4696     85.440  0.3210    89.374  269.08
  51   0.4862     85.490  0.2990    90.114  274.43
  52   0.4763     85.380  0.2968    90.230  279.75
  53   0.4991     85.100  0.2849    90.746  285.09
  54   0.4889     85.820  0.2904    90.422  290.41
  55   0.4676     85.850  0.2794    90.774  295.78
  56   0.4485     86.090  0.2880    90.626  301.14
  57   0.4627     86.170  0.2707    91.080  306.48
  58   0.4464     86.840  0.2709    91.038  311.79
  59   0.4592     86.200  0.2788    90.896  317.11
  60   0.4906     86.250  0.2665    91.226  322.42
  61   0.4884     85.590  0.2673    91.426  327.77
  62   0.4841     85.430  0.2582    91.428  333.16
  63   0.4929     85.910  0.2565    91.526  338.47
  64   0.4704     86.130  0.2511    91.868  343.79
  65   0.4769     86.150  0.2621    91.636  349.13
  66   0.4769     86.490  0.2553    91.600  354.47
  67   0.4880     85.740  0.2391    92.296  359.82
  68   0.4656     86.960  0.2451    92.004  365.18
  69   0.4344     86.870  0.2449    91.986  370.57
  70   0.4357     86.330  0.2386    92.268  375.93
  71   0.4596     86.130  0.2378    92.124  381.29
  72   0.4754     86.360  0.2318    92.416  386.64
  73   0.4824     86.390  0.2228    92.688  392.01
  74   0.4569     86.630  0.2245    92.802  397.32
  75   0.4406     87.380  0.2331    92.350  402.72
  76   0.4614     86.920  0.2164    93.032  408.08
  77   0.5103     85.540  0.2261    92.692  413.40
  78   0.4513     86.860  0.2157    93.032  418.71
  79   0.4686     86.830  0.2141    93.020  424.05
  80   0.4621     87.290  0.2061    93.304  429.42
  81   0.4405     87.370  0.2071    93.298  434.82
  82   0.4681     87.280  0.2062    93.270  440.14
  83   0.4653     86.480  0.2106    93.246  445.47
  84   0.4750     86.580  0.2061    93.220  450.79
  85   0.4902     86.820  0.1987    93.572  456.14
  86   0.4720     86.940  0.1948    93.680  461.48
  87   0.4489     87.130  0.1971    93.618  466.91
  88   0.4503     87.490  0.1880    93.886  472.23
  89   0.4612     87.030  0.1968    93.558  477.55
  90   0.4879     86.550  0.1974    93.594  482.91
