Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8500     26.010  2.1058    18.110  7.08
   2   1.6417     35.630  1.7715    29.730  12.40
   3   1.5136     40.190  1.5990    37.126  17.72
   4   1.4191     44.830  1.4818    42.762  23.06
   5   1.2896     52.020  1.3735    48.052  28.45
   6   1.1507     58.260  1.2555    53.518  33.81
   7   1.1540     58.050  1.1899    56.366  39.14
   8   1.0148     63.610  1.1091    59.928  44.47
   9   0.9713     65.140  1.0371    62.568  49.78
  10   0.9586     66.140  0.9656    65.684  55.14
  11   0.9235     67.580  0.9211    67.106  60.48
  12   0.8285     71.130  0.8715    69.018  65.84
  13   0.7990     71.560  0.8188    71.076  71.19
  14   0.8292     71.710  0.7696    72.958  76.53
  15   0.7450     74.200  0.7504    73.724  81.87
  16   0.7442     74.400  0.7158    75.088  87.23
  17   0.7238     75.490  0.6828    76.242  92.57
  18   0.7028     75.860  0.6606    77.124  97.99
  19   0.6573     77.490  0.6183    78.662  103.31
  20   0.6652     77.770  0.5952    79.544  108.66
  21   0.6649     77.870  0.5743    80.200  113.98
  22   0.6638     77.730  0.5505    81.152  119.34
  23   0.5995     79.560  0.5416    81.468  124.67
  24   0.6117     79.660  0.5171    82.350  130.01
  25   0.5802     80.940  0.4914    83.244  135.41
  26   0.6013     79.650  0.4890    82.982  140.72
  27   0.5869     80.530  0.4700    83.818  146.06
  28   0.5771     80.860  0.4615    84.252  151.39
  29   0.5651     81.820  0.4202    85.712  156.70
  30   0.5503     82.070  0.3983    86.378  162.07
  31   0.5551     82.380  0.3894    86.720  167.46
  32   0.5632     81.670  0.3842    86.858  172.79
  33   0.5487     82.490  0.3564    87.924  178.13
  34   0.5743     81.790  0.3546    88.040  183.46
  35   0.5640     82.390  0.3275    88.962  188.78
  36   0.5850     82.240  0.3247    88.892  194.12
  37   0.5625     82.330  0.3113    89.366  199.46
  38   0.5603     83.090  0.2961    89.858  204.80
  39   0.5524     82.740  0.2921    90.058  210.14
  40   0.5553     83.630  0.2797    90.466  215.47
  41   0.5523     83.490  0.2740    90.688  220.80
  42   0.5823     83.010  0.2668    91.066  226.16
  43   0.5403     84.300  0.2618    91.196  231.53
  44   0.5556     83.190  0.2357    91.908  236.97
  45   0.5632     83.900  0.2176    92.696  242.29
  46   0.5722     83.740  0.2210    92.404  247.67
  47   0.5465     84.490  0.2091    92.846  252.99
  48   0.5627     83.680  0.2059    92.902  258.35
  49   0.5773     83.560  0.2067    92.810  263.67
  50   0.5966     84.140  0.2002    93.188  269.00
  51   0.5869     84.170  0.1883    93.646  274.40
  52   0.5748     83.850  0.1752    94.034  279.77
  53   0.5666     83.940  0.1719    94.250  285.10
  54   0.5600     84.600  0.1668    94.276  290.43
  55   0.5801     84.660  0.1655    94.360  295.77
  56   0.5880     84.820  0.1581    94.640  301.11
  57   0.5487     84.970  0.1532    94.904  306.49
  58   0.5776     84.840  0.1470    95.110  311.82
  59   0.5911     84.860  0.1431    95.070  317.14
  60   0.5762     85.010  0.1410    95.240  322.49
  61   0.6168     84.050  0.1373    95.352  327.83
  62   0.6108     84.800  0.1315    95.624  333.19
  63   0.6032     84.780  0.1295    95.732  338.51
  64   0.5796     84.900  0.1182    96.006  343.86
  65   0.6525     84.480  0.1226    95.810  349.19
  66   0.6006     85.170  0.1224    95.794  354.55
  67   0.6036     85.440  0.1139    96.172  359.88
  68   0.6144     84.800  0.1027    96.528  365.23
  69   0.6169     84.460  0.1078    96.346  370.59
  70   0.6246     84.600  0.1112    96.292  376.04
  71   0.6168     85.140  0.1052    96.526  381.36
  72   0.6708     84.790  0.0980    96.710  386.68
  73   0.6726     84.210  0.1034    96.520  392.00
  74   0.6030     84.950  0.1037    96.562  397.36
  75   0.5903     84.830  0.0939    96.856  402.73
  76   0.6178     84.810  0.0975    96.740  408.07
  77   0.6491     85.140  0.0961    96.772  413.47
  78   0.6454     84.990  0.0886    97.040  418.79
  79   0.5862     85.420  0.0980    96.656  424.11
  80   0.6011     85.360  0.0829    97.194  429.47
  81   0.6205     85.510  0.0765    97.470  434.81
  82   0.6254     85.260  0.0848    97.196  440.15
  83   0.6182     85.070  0.0863    97.174  445.49
  84   0.6117     85.560  0.0880    97.022  450.91
  85   0.6367     85.610  0.0748    97.476  456.23
  86   0.6383     85.760  0.0673    97.736  461.60
  87   0.6665     85.720  0.0676    97.700  466.95
  88   0.6456     85.960  0.0787    97.380  472.30
  89   0.6615     85.440  0.0751    97.558  477.69
  90   0.6487     85.610  0.0807    97.304  483.10
