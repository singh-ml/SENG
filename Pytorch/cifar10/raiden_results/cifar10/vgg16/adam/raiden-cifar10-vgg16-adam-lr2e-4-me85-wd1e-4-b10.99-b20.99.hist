Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9269     19.570  2.1173    16.114  6.98
   2   1.8392     23.240  1.8870    21.226  12.27
   3   1.7250     31.040  1.7945    26.584  17.66
   4   1.5523     39.330  1.6738    33.908  22.96
   5   1.4313     45.010  1.4519    44.288  28.27
   6   1.2871     52.040  1.3226    50.558  33.59
   7   1.1493     58.430  1.2218    54.914  38.92
   8   1.0757     60.960  1.1167    59.620  44.24
   9   1.0063     64.760  1.0325    63.184  49.54
  10   0.9650     65.910  0.9859    64.946  54.92
  11   0.8742     68.980  0.9128    67.364  60.24
  12   0.8587     69.450  0.8459    70.150  65.54
  13   0.7827     72.950  0.7969    71.834  70.83
  14   0.7778     74.110  0.7361    74.316  76.17
  15   0.7364     75.080  0.6872    76.160  81.51
  16   0.6857     76.600  0.6596    77.262  86.81
  17   0.6654     77.710  0.6106    78.868  92.21
  18   0.6460     78.470  0.5867    79.898  97.55
  19   0.6181     79.690  0.5615    80.700  102.89
  20   0.5850     80.450  0.5352    81.850  108.21
  21   0.5590     81.830  0.4992    83.068  113.52
  22   0.5917     80.500  0.4882    83.452  118.86
  23   0.5940     80.880  0.4717    84.090  124.27
  24   0.5753     82.410  0.4422    85.156  129.57
  25   0.5488     82.930  0.4237    85.808  134.89
  26   0.5560     81.650  0.4187    86.030  140.23
  27   0.5443     82.840  0.3987    86.690  145.54
  28   0.5124     83.480  0.3694    87.644  150.86
  29   0.5167     83.560  0.3499    88.292  156.28
  30   0.5370     82.790  0.3348    88.754  161.61
  31   0.5373     83.770  0.3245    89.056  166.94
  32   0.5406     83.780  0.3211    89.252  172.26
  33   0.5365     83.670  0.3228    89.098  177.57
  34   0.5131     83.960  0.3022    90.010  182.87
  35   0.5065     84.920  0.2837    90.706  188.28
  36   0.5258     84.640  0.2694    91.082  193.60
  37   0.5369     84.490  0.2603    91.330  198.93
  38   0.4865     84.970  0.2601    91.382  204.28
  39   0.5055     85.060  0.2467    91.876  209.63
  40   0.4887     85.790  0.2306    92.326  214.97
  41   0.5335     85.150  0.2332    92.230  220.30
  42   0.5492     84.640  0.2316    92.322  225.73
  43   0.4814     85.720  0.2203    92.614  231.07
  44   0.4759     85.740  0.2110    92.954  236.41
  45   0.5282     85.390  0.2009    93.250  241.74
  46   0.5229     85.520  0.1872    93.856  247.07
  47   0.5327     85.820  0.1857    93.744  252.37
  48   0.5909     84.760  0.1867    93.782  257.79
  49   0.5470     85.900  0.1812    94.086  263.13
  50   0.5213     86.050  0.1851    93.980  268.43
  51   0.5086     86.410  0.1720    94.298  273.73
  52   0.5108     86.710  0.1534    94.902  279.05
  53   0.5642     85.710  0.1464    95.068  284.38
  54   0.5226     85.900  0.1397    95.314  289.68
  55   0.5174     86.790  0.1407    95.356  295.07
  56   0.5558     85.790  0.1404    95.362  300.40
  57   0.5894     85.610  0.1386    95.410  305.74
  58   0.5524     86.050  0.1345    95.528  311.08
  59   0.4965     87.320  0.1334    95.602  316.40
  60   0.5197     86.680  0.1333    95.596  321.73
  61   0.5398     86.680  0.1227    95.936  327.13
  62   0.5435     87.270  0.1106    96.306  332.44
  63   0.5777     85.940  0.1215    96.038  337.76
  64   0.5494     86.600  0.1295    95.798  343.09
  65   0.5230     86.520  0.1139    96.312  348.41
  66   0.5471     86.840  0.1116    96.324  353.75
  67   0.5256     86.450  0.1116    96.334  359.08
  68   0.5544     86.320  0.1051    96.578  364.50
  69   0.5990     86.020  0.1058    96.486  369.83
  70   0.5964     86.880  0.1058    96.500  375.18
  71   0.5539     86.470  0.1021    96.712  380.51
  72   0.5581     87.290  0.1066    96.530  385.81
  73   0.5394     87.210  0.0938    96.946  391.13
  74   0.5287     87.350  0.0918    96.920  396.52
  75   0.5181     87.550  0.0974    96.876  401.87
  76   0.5942     86.730  0.0853    97.196  407.19
  77   0.5596     86.590  0.0960    96.932  412.49
  78   0.5671     87.010  0.0872    97.166  417.84
  79   0.5800     86.820  0.0863    97.272  423.14
  80   0.5608     86.980  0.0930    97.068  428.52
  81   0.5576     87.240  0.0786    97.376  433.83
  82   0.6293     86.630  0.0816    97.364  439.16
  83   0.5893     87.260  0.0805    97.368  444.49
  84   0.5978     87.170  0.0807    97.394  449.83
  85   0.5330     87.120  0.0813    97.400  455.13
