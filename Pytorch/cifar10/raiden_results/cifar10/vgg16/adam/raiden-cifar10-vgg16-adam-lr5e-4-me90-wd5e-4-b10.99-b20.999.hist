Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1727     17.990  2.3269    12.490  7.09
   2   1.9258     20.450  2.0674    19.162  12.57
   3   1.8515     24.080  1.9047    21.762  17.90
   4   1.8264     26.630  1.8511    24.304  23.23
   5   1.6857     33.030  1.7843    28.522  28.58
   6   1.5531     37.700  1.6346    35.324  33.92
   7   1.4310     43.200  1.5613    38.558  39.27
   8   1.3703     47.470  1.4181    45.122  44.64
   9   1.3083     51.120  1.3362    49.024  49.99
  10   1.1854     55.580  1.2351    53.598  55.32
  11   1.1511     57.870  1.1502    57.490  60.68
  12   1.0050     63.370  1.0742    60.438  66.00
  13   0.9880     64.830  0.9741    64.382  71.40
  14   0.9505     66.190  0.9445    65.970  76.76
  15   0.8812     68.450  0.8852    68.356  82.11
  16   0.8657     69.870  0.8332    70.616  87.46
  17   0.8081     72.050  0.7823    72.768  92.81
  18   0.7325     74.160  0.7356    74.498  98.15
  19   0.7235     75.480  0.6957    76.112  103.48
  20   0.7223     75.860  0.6851    76.662  108.90
  21   0.6900     76.590  0.6425    78.228  114.24
  22   0.6461     78.520  0.6296    78.692  119.56
  23   0.6748     77.400  0.6054    79.822  124.90
  24   0.6560     78.980  0.5942    80.222  130.26
  25   0.6313     79.400  0.5644    81.136  135.58
  26   0.6522     78.590  0.5559    81.532  140.91
  27   0.6143     79.620  0.5329    82.208  146.32
  28   0.6049     80.850  0.5230    82.628  151.66
  29   0.5710     81.220  0.5249    82.746  156.98
  30   0.6092     80.410  0.5052    83.496  162.35
  31   0.5707     81.470  0.4778    84.364  167.68
  32   0.5780     81.490  0.4756    84.614  173.03
  33   0.5674     82.160  0.4541    85.108  178.42
  34   0.5938     81.390  0.4524    85.350  183.80
  35   0.5486     82.880  0.4399    85.756  189.13
  36   0.5362     83.430  0.4168    86.330  194.44
  37   0.5275     83.580  0.4167    86.400  199.79
  38   0.5396     83.810  0.4093    86.786  205.11
  39   0.5426     83.230  0.4031    87.020  210.45
  40   0.5204     84.210  0.3941    87.100  215.82
  41   0.5614     83.320  0.3831    87.556  221.14
  42   0.5034     84.880  0.3831    87.616  226.46
  43   0.5384     84.300  0.3757    87.774  231.79
  44   0.4927     84.910  0.3611    88.292  237.12
  45   0.5178     85.000  0.3533    88.750  242.44
  46   0.5001     85.390  0.3436    88.882  247.88
  47   0.5110     84.320  0.3394    89.000  253.24
  48   0.5124     83.920  0.3431    88.900  258.61
  49   0.5288     84.950  0.3314    89.246  263.98
  50   0.4659     85.690  0.3147    89.822  269.31
  51   0.5256     84.950  0.3179    89.562  274.65
  52   0.4950     85.110  0.3155    89.812  280.07
  53   0.4749     85.180  0.3165    89.616  285.40
  54   0.4890     85.630  0.3068    90.084  290.75
  55   0.4950     85.050  0.3043    90.110  296.11
  56   0.5021     85.990  0.3039    90.254  301.47
  57   0.4789     85.490  0.2966    90.458  306.83
  58   0.5045     85.660  0.2903    90.522  312.16
  59   0.5154     85.360  0.2861    90.794  317.57
  60   0.4742     85.790  0.2924    90.490  322.94
  61   0.5412     84.810  0.2835    90.948  328.29
  62   0.4906     85.700  0.2746    91.154  333.63
  63   0.5095     85.620  0.2756    91.098  338.99
  64   0.5454     85.240  0.2720    91.226  344.37
  65   0.4947     85.850  0.2709    91.266  349.75
  66   0.4895     86.600  0.2682    91.426  355.15
  67   0.4973     86.380  0.2682    91.368  360.49
  68   0.4803     86.180  0.2591    91.734  365.86
  69   0.5124     85.730  0.2646    91.670  371.19
  70   0.4508     86.710  0.2560    91.864  376.53
  71   0.4770     86.790  0.2534    91.802  381.87
  72   0.4911     86.290  0.2576    91.830  387.26
  73   0.5072     85.740  0.2639    91.518  392.65
  74   0.4718     86.600  0.2616    91.670  398.02
  75   0.4691     86.290  0.2457    92.130  403.39
  76   0.4869     86.520  0.2386    92.392  408.76
  77   0.4725     86.490  0.2447    92.100  414.11
  78   0.4709     87.040  0.2424    92.338  419.45
  79   0.5137     86.660  0.2265    92.798  424.91
  80   0.5002     85.660  0.2333    92.502  430.28
  81   0.4644     86.820  0.2296    92.658  435.65
  82   0.4575     87.440  0.2225    92.836  441.03
  83   0.4921     86.930  0.2273    92.688  446.37
  84   0.4969     86.060  0.2312    92.514  451.72
  85   0.4618     86.850  0.2272    92.694  457.13
  86   0.4690     86.730  0.2161    92.996  462.47
  87   0.4640     86.810  0.2168    93.112  467.81
  88   0.4611     87.190  0.2071    93.388  473.17
  89   0.4467     87.100  0.2137    93.216  478.52
  90   0.4950     86.230  0.2121    93.228  483.88
