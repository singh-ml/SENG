Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9479     17.810  2.6922    14.822  7.01
   2   1.7770     29.320  1.8901    23.186  12.42
   3   1.5523     38.580  1.7083    32.288  17.74
   4   1.5358     44.050  1.5385    40.436  23.07
   5   1.2422     54.560  1.3548    50.064  28.43
   6   1.0515     62.800  1.1656    58.330  33.74
   7   0.9115     68.150  1.0238    64.068  39.08
   8   0.8344     71.170  0.9116    68.570  44.41
   9   0.7660     74.760  0.8222    72.038  49.85
  10   0.7017     76.350  0.7625    74.330  55.20
  11   0.7090     77.520  0.6946    76.954  60.53
  12   0.6453     79.280  0.6437    78.672  65.89
  13   0.6794     78.500  0.6164    79.908  71.22
  14   0.6195     80.190  0.5805    81.090  76.56
  15   0.5937     80.470  0.5543    81.982  81.99
  16   0.6135     81.530  0.5243    82.856  87.33
  17   0.5433     82.930  0.4995    83.818  92.68
  18   0.5879     81.870  0.4855    84.320  98.01
  19   0.5730     81.670  0.4711    84.942  103.33
  20   0.5037     83.970  0.4357    86.176  108.67
  21   0.5618     82.980  0.4375    86.160  114.09
  22   0.5816     82.910  0.4150    86.646  119.43
  23   0.5006     85.230  0.4064    87.064  124.78
  24   0.5416     83.230  0.3973    87.440  130.13
  25   0.5242     84.490  0.3781    87.962  135.46
  26   0.5637     82.930  0.3670    88.432  140.81
  27   0.5189     84.400  0.3639    88.402  146.19
  28   0.4778     85.200  0.3521    88.770  151.55
  29   0.5074     85.080  0.3428    89.306  156.88
  30   0.4559     86.760  0.3354    89.438  162.21
  31   0.5108     85.980  0.3243    89.780  167.59
  32   0.4998     85.790  0.3136    90.132  172.94
  33   0.4640     85.800  0.3123    90.152  178.31
  34   0.5141     85.130  0.3016    90.470  183.75
  35   0.4227     87.160  0.2997    90.482  189.11
  36   0.4740     85.680  0.2917    90.854  194.48
  37   0.4920     85.660  0.2829    91.076  199.81
  38   0.4859     86.580  0.2829    91.046  205.17
  39   0.4263     87.720  0.2776    91.440  210.50
  40   0.4710     85.890  0.2695    91.650  215.85
  41   0.5065     86.470  0.2694    91.558  221.25
  42   0.4382     87.000  0.2639    91.812  226.60
  43   0.5174     87.190  0.2617    91.984  231.93
  44   0.4868     85.940  0.2497    92.212  237.30
  45   0.4235     87.710  0.2466    92.368  242.63
  46   0.4437     87.250  0.2427    92.520  247.95
  47   0.4650     86.990  0.2445    92.494  253.37
  48   0.4905     86.910  0.2344    92.712  258.74
  49   0.5258     85.680  0.2359    92.718  264.06
  50   0.4482     87.860  0.2312    92.742  269.44
  51   0.4086     88.010  0.2260    92.982  274.77
  52   0.4943     87.870  0.2193    93.192  280.11
  53   0.5305     86.810  0.2179    93.168  285.43
  54   0.4927     86.780  0.2304    93.050  290.76
  55   0.4825     87.380  0.2268    93.036  296.11
  56   0.4494     88.100  0.2181    93.192  301.49
  57   0.4402     88.290  0.2138    93.464  306.81
  58   0.4604     87.840  0.2092    93.372  312.14
  59   0.4924     87.970  0.2030    93.660  317.55
  60   0.4809     87.960  0.2047    93.700  322.90
  61   0.4683     87.820  0.2017    93.830  328.26
  62   0.5026     87.130  0.2003    93.796  333.57
  63   0.5229     87.100  0.1999    93.858  338.92
  64   0.4501     87.620  0.1985    93.924  344.29
  65   0.4619     88.270  0.1970    94.112  349.63
  66   0.4688     88.050  0.1926    94.038  355.05
  67   0.4885     87.990  0.1994    93.974  360.38
  68   0.4273     88.890  0.1891    94.200  365.71
  69   0.4464     88.440  0.1890    94.086  371.07
  70   0.4981     88.120  0.1871    94.296  376.42
  71   0.4866     87.800  0.1904    94.270  381.76
  72   0.4753     88.120  0.1877    94.196  387.10
  73   0.4641     88.070  0.1869    94.350  392.50
  74   0.5309     86.580  0.1874    94.348  397.82
  75   0.4334     88.560  0.1797    94.464  403.16
  76   0.5035     88.310  0.1806    94.480  408.49
  77   0.4432     88.490  0.1738    94.706  413.80
  78   0.4598     87.810  0.1768    94.570  419.15
  79   0.4847     88.360  0.1768    94.562  424.48
  80   0.5039     88.510  0.1785    94.522  429.89
  81   0.4606     89.010  0.1684    94.878  435.25
  82   0.4880     88.180  0.1682    94.882  440.57
  83   0.4830     87.640  0.1742    94.718  445.90
  84   0.4371     88.640  0.1698    94.780  451.24
  85   0.5130     87.990  0.1645    95.010  456.60
