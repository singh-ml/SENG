Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0526     20.610  2.2236    14.546  6.98
   2   1.8719     23.950  1.9772    21.038  12.32
   3   1.8397     25.020  1.8959    23.034  17.68
   4   1.7670     28.630  1.8337    25.930  23.04
   5   1.6930     33.430  1.7724    29.288  28.37
   6   1.5766     38.190  1.6749    33.824  33.79
   7   1.4780     43.390  1.5673    39.368  39.15
   8   1.4353     44.670  1.4509    44.752  44.50
   9   1.2316     54.420  1.3314    50.208  49.84
  10   1.1595     58.180  1.2245    55.112  55.18
  11   1.0784     61.540  1.1243    59.370  60.53
  12   1.0230     63.590  1.0681    61.724  65.92
  13   0.9694     65.720  0.9881    64.774  71.26
  14   0.8793     68.630  0.9275    67.052  76.62
  15   0.8433     70.470  0.8762    68.820  81.95
  16   0.8609     70.350  0.7983    71.438  87.32
  17   0.7834     72.760  0.7842    72.352  92.65
  18   0.7189     75.160  0.7412    73.822  98.03
  19   0.7010     75.500  0.7056    75.358  103.37
  20   0.7615     73.550  0.6832    76.076  108.69
  21   0.7299     75.280  0.6672    76.762  114.05
  22   0.6362     78.770  0.6474    77.562  119.42
  23   0.6703     77.940  0.6070    79.308  124.77
  24   0.6359     78.760  0.5930    79.656  130.11
  25   0.6138     79.740  0.5701    80.584  135.48
  26   0.5978     80.570  0.5410    81.702  140.82
  27   0.6125     79.670  0.5241    82.440  146.19
  28   0.5832     80.900  0.5197    82.294  151.57
  29   0.5612     81.960  0.5073    83.012  156.91
  30   0.5443     81.900  0.5065    83.054  162.26
  31   0.5590     82.160  0.4778    83.932  167.65
  32   0.5507     81.880  0.4627    84.584  173.00
  33   0.5344     83.300  0.4521    85.028  178.33
  34   0.5336     82.360  0.4285    85.626  183.70
  35   0.5283     82.830  0.4262    85.868  189.07
  36   0.5026     83.560  0.4185    86.156  194.40
  37   0.5092     84.160  0.4107    86.260  199.74
  38   0.5409     82.190  0.4032    86.570  205.06
  39   0.5100     84.210  0.3920    86.920  210.39
  40   0.5084     84.500  0.3829    87.408  215.73
  41   0.4942     84.420  0.3661    87.892  221.05
  42   0.5242     84.280  0.3567    88.132  226.42
  43   0.4827     84.620  0.3644    87.864  231.75
  44   0.5150     83.970  0.3486    88.518  237.18
  45   0.5074     84.420  0.3616    88.032  242.51
  46   0.4966     84.490  0.3591    88.260  247.86
  47   0.4825     85.010  0.3300    88.954  253.21
  48   0.4738     85.550  0.3313    89.024  258.52
  49   0.5107     85.360  0.3195    89.550  263.88
  50   0.4623     85.830  0.3072    89.874  269.21
  51   0.4713     85.300  0.3066    89.746  274.62
  52   0.4858     85.710  0.3023    90.004  279.99
  53   0.4783     85.700  0.3070    89.870  285.33
  54   0.4634     85.790  0.2918    90.370  290.67
  55   0.5305     84.740  0.2882    90.458  296.01
  56   0.4765     86.110  0.2882    90.380  301.36
  57   0.4921     85.780  0.2736    90.926  306.83
  58   0.4808     86.260  0.2850    90.546  312.15
  59   0.4582     86.230  0.2658    91.232  317.50
  60   0.5022     85.330  0.2611    91.298  322.84
  61   0.5227     85.500  0.2700    91.092  328.16
  62   0.4957     85.730  0.2620    91.358  333.48
  63   0.4769     86.050  0.2663    91.214  338.82
  64   0.4579     86.270  0.2584    91.432  344.20
  65   0.4717     86.250  0.2505    91.668  349.54
  66   0.4764     86.030  0.2529    91.774  354.87
  67   0.4620     86.730  0.2499    91.872  360.20
  68   0.4766     86.590  0.2420    92.098  365.54
  69   0.4884     86.100  0.2371    92.230  370.95
  70   0.4925     85.950  0.2273    92.520  376.29
  71   0.4854     86.420  0.2313    92.392  381.66
  72   0.4853     86.830  0.2225    92.630  387.03
  73   0.4674     86.350  0.2295    92.470  392.40
  74   0.4666     86.370  0.2295    92.386  397.76
  75   0.4652     86.920  0.2261    92.500  403.09
  76   0.4749     87.180  0.2172    92.818  408.44
  77   0.4976     86.240  0.2280    92.546  413.79
  78   0.4968     86.770  0.2140    92.888  419.12
  79   0.5542     86.210  0.2229    92.808  424.46
  80   0.4667     87.200  0.2081    92.986  429.81
  81   0.4877     87.050  0.2056    93.170  435.14
  82   0.5042     86.500  0.2089    93.148  440.47
  83   0.4880     86.760  0.1992    93.460  445.83
  84   0.4740     86.930  0.2057    93.308  451.22
  85   0.4901     87.160  0.1992    93.370  456.59
