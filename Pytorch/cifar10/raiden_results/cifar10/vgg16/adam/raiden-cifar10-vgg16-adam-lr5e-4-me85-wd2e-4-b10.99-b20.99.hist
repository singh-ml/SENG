Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0565     18.510  2.2218    14.624  6.96
   2   1.8745     21.120  1.9460    19.540  12.34
   3   1.8306     23.720  1.8696    22.306  17.67
   4   1.8197     25.650  1.8395    24.338  23.01
   5   1.7288     31.270  1.7877    27.826  28.31
   6   1.6120     36.750  1.6998    32.548  33.62
   7   1.4946     42.260  1.5767    38.566  38.93
   8   1.3745     47.640  1.4642    43.842  44.25
   9   1.2693     53.450  1.3087    50.834  49.64
  10   1.1791     56.780  1.2270    54.936  54.96
  11   1.1325     58.260  1.1240    59.390  60.29
  12   0.9637     65.060  1.0430    62.610  65.67
  13   0.9915     64.870  0.9546    65.662  71.00
  14   0.8923     68.560  0.9281    67.300  76.31
  15   0.8925     69.280  0.8834    69.140  81.65
  16   0.8568     70.290  0.8488    70.174  87.03
  17   0.8263     71.470  0.8138    71.290  92.35
  18   0.8374     70.910  0.7931    72.266  97.65
  19   0.7308     74.540  0.7559    74.084  102.97
  20   0.7409     74.520  0.7161    75.238  108.31
  21   0.7061     76.150  0.6943    76.146  113.64
  22   0.6859     76.390  0.6547    77.722  118.95
  23   0.6816     77.200  0.6405    78.308  124.30
  24   0.6662     78.130  0.6073    79.480  129.65
  25   0.6387     78.660  0.6117    79.628  134.95
  26   0.6319     79.160  0.5810    80.366  140.29
  27   0.6271     79.560  0.5689    80.982  145.64
  28   0.6445     79.520  0.5559    81.382  151.02
  29   0.5820     80.730  0.5362    82.058  156.37
  30   0.5836     81.220  0.5224    82.752  161.68
  31   0.5791     81.010  0.5112    83.044  167.02
  32   0.5678     81.510  0.4746    84.190  172.35
  33   0.5244     82.440  0.4730    84.370  177.65
  34   0.5648     81.550  0.4620    84.750  182.97
  35   0.5406     82.750  0.4606    84.810  188.40
  36   0.5412     82.560  0.4456    85.290  193.75
  37   0.5432     83.090  0.4335    85.640  199.06
  38   0.5529     83.030  0.4322    85.556  204.38
  39   0.5020     83.890  0.4132    86.370  209.70
  40   0.5371     83.430  0.4124    86.356  215.02
  41   0.5351     83.460  0.4070    86.614  220.45
  42   0.4940     84.480  0.3947    86.992  225.75
  43   0.5192     84.180  0.3818    87.468  231.07
  44   0.5288     83.590  0.3849    87.326  236.40
  45   0.4901     85.030  0.3794    87.544  241.74
  46   0.4869     84.540  0.3636    88.016  247.07
  47   0.4986     84.750  0.3443    88.670  252.40
  48   0.4852     84.690  0.3592    88.258  257.79
  49   0.4899     85.370  0.3497    88.640  263.10
  50   0.4986     85.100  0.3428    88.828  268.42
  51   0.4970     84.520  0.3414    88.750  273.76
  52   0.5138     84.450  0.3290    89.028  279.06
  53   0.4993     85.260  0.3307    89.248  284.40
  54   0.4853     85.470  0.3193    89.518  289.71
  55   0.4949     84.610  0.3161    89.696  295.11
  56   0.4869     85.090  0.3190    89.536  300.44
  57   0.4657     85.700  0.3125    89.736  305.77
  58   0.4899     85.800  0.3005    90.178  311.12
  59   0.5096     84.300  0.2972    90.160  316.46
  60   0.4716     85.080  0.3087    89.916  321.77
  61   0.4968     85.480  0.2902    90.538  327.14
  62   0.4639     86.010  0.2768    90.918  332.57
  63   0.4689     85.720  0.2791    90.840  337.92
  64   0.4907     85.680  0.2685    91.168  343.23
  65   0.5053     85.480  0.2690    91.092  348.53
  66   0.4902     86.460  0.2781    90.888  353.86
  67   0.4563     86.100  0.2742    91.060  359.23
  68   0.4535     86.070  0.2684    91.338  364.65
  69   0.4682     86.200  0.2613    91.558  369.98
  70   0.4846     86.200  0.2662    91.356  375.30
  71   0.4784     85.990  0.2618    91.372  380.63
  72   0.4682     86.840  0.2584    91.612  385.94
  73   0.4333     86.940  0.2493    91.764  391.26
  74   0.4775     86.590  0.2451    92.074  396.65
  75   0.5004     85.900  0.2500    91.868  401.98
  76   0.4879     86.620  0.2456    92.042  407.31
  77   0.4560     86.350  0.2484    92.008  412.65
  78   0.4598     86.660  0.2443    92.062  417.97
  79   0.4812     86.370  0.2404    92.256  423.31
  80   0.4444     87.070  0.2308    92.484  428.65
  81   0.4636     86.910  0.2360    92.256  433.97
  82   0.4661     86.930  0.2250    92.798  439.28
  83   0.4919     86.290  0.2365    92.152  444.62
  84   0.4646     86.930  0.2291    92.612  449.91
  85   0.4717     87.180  0.2199    92.756  455.25
