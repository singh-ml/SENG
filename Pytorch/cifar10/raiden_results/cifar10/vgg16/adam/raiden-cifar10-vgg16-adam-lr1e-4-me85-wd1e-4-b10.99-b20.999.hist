Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9164     20.050  2.1360    16.204  7.01
   2   1.7368     29.800  1.8584    23.998  12.32
   3   1.5837     36.970  1.7072    31.310  17.65
   4   1.4325     44.830  1.5567    38.892  22.96
   5   1.3117     50.450  1.4039    46.336  28.30
   6   1.2469     53.420  1.3145    50.656  33.69
   7   1.1250     58.470  1.2087    55.464  39.04
   8   1.0710     60.870  1.1159    59.312  44.37
   9   0.9894     64.580  1.0323    62.522  49.69
  10   0.9247     66.980  0.9640    65.220  54.99
  11   0.8739     68.780  0.8798    68.446  60.30
  12   0.8256     70.730  0.8503    69.874  65.72
  13   0.8352     71.110  0.8020    71.828  71.04
  14   0.7622     73.610  0.7745    72.650  76.40
  15   0.7679     73.150  0.7358    74.168  81.71
  16   0.7232     75.360  0.6988    75.638  87.03
  17   0.7182     75.850  0.6722    76.510  92.37
  18   0.7207     75.380  0.6324    78.178  97.77
  19   0.6905     76.420  0.6358    78.042  103.08
  20   0.7056     75.950  0.6451    77.816  108.45
  21   0.6726     77.240  0.5736    80.140  113.81
  22   0.6460     78.500  0.5516    81.198  119.15
  23   0.6572     77.950  0.5227    81.950  124.46
  24   0.5895     79.960  0.5066    82.554  129.77
  25   0.6318     79.050  0.4755    83.598  135.15
  26   0.6380     79.050  0.4695    83.966  140.48
  27   0.5985     80.270  0.4460    84.678  145.80
  28   0.5961     80.750  0.4364    85.064  151.14
  29   0.5688     81.550  0.4158    85.654  156.47
  30   0.5707     81.630  0.4028    86.344  161.80
  31   0.5633     81.610  0.3873    86.792  167.23
  32   0.5845     81.320  0.3786    87.226  172.58
  33   0.5788     81.580  0.3457    88.294  177.91
  34   0.5584     81.620  0.3413    88.358  183.20
  35   0.5666     82.070  0.3342    88.724  188.52
  36   0.5990     81.480  0.3254    88.918  193.86
  37   0.5842     82.140  0.3062    89.474  199.20
  38   0.5794     81.740  0.3096    89.400  204.63
  39   0.5701     82.780  0.2961    89.936  209.94
  40   0.5522     83.330  0.2765    90.614  215.25
  41   0.5828     82.660  0.2537    91.342  220.61
  42   0.5618     83.220  0.2621    90.898  225.93
  43   0.5750     83.320  0.2405    91.798  231.26
  44   0.5659     83.560  0.2352    91.988  236.57
  45   0.5809     83.470  0.2266    92.312  241.97
  46   0.5673     82.600  0.2305    92.034  247.28
  47   0.5836     83.850  0.2178    92.614  252.64
  48   0.5812     83.580  0.2082    92.904  257.98
  49   0.6052     83.590  0.2071    93.094  263.29
  50   0.5749     83.520  0.1914    93.466  268.61
  51   0.5876     83.400  0.1839    93.728  274.01
  52   0.5710     83.980  0.1716    94.174  279.32
  53   0.6195     84.000  0.1677    94.286  284.69
  54   0.6061     83.530  0.1636    94.512  289.99
  55   0.5683     84.560  0.1593    94.752  295.31
  56   0.5929     83.950  0.1536    94.720  300.67
  57   0.6325     84.110  0.1512    94.984  306.06
  58   0.6104     83.590  0.1444    95.094  311.41
  59   0.6275     84.040  0.1398    95.224  316.73
  60   0.6152     84.310  0.1309    95.614  322.06
  61   0.6225     83.980  0.1361    95.422  327.40
  62   0.6318     84.010  0.1287    95.682  332.71
  63   0.6494     83.800  0.1393    95.368  338.10
  64   0.6530     84.020  0.1207    95.974  343.42
  65   0.6282     83.980  0.1193    95.908  348.74
  66   0.6629     84.590  0.1144    96.216  354.05
  67   0.6260     84.420  0.1105    96.280  359.35
  68   0.6690     84.890  0.1018    96.576  364.71
  69   0.6717     84.750  0.0958    96.646  370.05
  70   0.6486     84.740  0.1023    96.556  375.48
  71   0.6675     84.700  0.1112    96.268  380.79
  72   0.6910     84.830  0.0949    96.846  386.15
  73   0.7100     83.740  0.0894    97.000  391.47
  74   0.6512     84.300  0.0916    96.888  396.80
  75   0.6697     85.120  0.0890    96.982  402.14
  76   0.6837     84.560  0.0914    96.874  407.45
  77   0.6633     84.910  0.0906    96.976  412.90
  78   0.6623     84.900  0.0885    97.028  418.21
  79   0.6453     85.580  0.0837    97.196  423.54
  80   0.6513     85.200  0.0870    97.142  428.89
  81   0.6713     84.480  0.0849    97.174  434.24
  82   0.6518     85.150  0.0760    97.396  439.58
  83   0.6986     84.820  0.0751    97.460  444.98
  84   0.6950     84.390  0.0778    97.462  450.33
  85   0.7125     85.120  0.0751    97.472  455.64
