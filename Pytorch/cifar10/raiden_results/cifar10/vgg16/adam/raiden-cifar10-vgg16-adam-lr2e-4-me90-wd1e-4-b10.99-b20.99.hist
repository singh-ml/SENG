Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4041537024 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8785     21.900  2.0749    16.970  6.99
   2   1.6996     30.110  1.8163    25.796  12.43
   3   1.5404     39.790  1.6545    33.908  17.74
   4   1.4782     42.960  1.5142    41.118  23.06
   5   1.3449     48.950  1.4256    46.040  28.38
   6   1.2596     53.850  1.2967    51.250  33.72
   7   1.1108     60.360  1.1587    57.290  39.06
   8   0.9806     65.310  1.0530    61.958  44.36
   9   0.9707     65.010  0.9740    64.934  49.66
  10   0.9092     68.190  0.9394    66.776  55.09
  11   0.8446     70.560  0.8434    70.374  60.43
  12   0.8012     72.840  0.7853    72.178  65.75
  13   0.7723     73.800  0.7412    73.976  71.09
  14   0.7227     74.890  0.7021    75.518  76.42
  15   0.7464     75.060  0.6651    76.996  81.72
  16   0.6871     76.880  0.6356    78.190  87.10
  17   0.6437     78.580  0.5930    79.624  92.41
  18   0.6266     79.270  0.5737    80.312  97.76
  19   0.6185     79.880  0.5392    81.664  103.11
  20   0.5967     80.750  0.5104    82.470  108.46
  21   0.5779     80.910  0.4974    83.052  113.84
  22   0.6156     80.400  0.4626    84.196  119.20
  23   0.5599     81.270  0.4502    84.782  124.55
  24   0.5464     82.250  0.4365    85.078  129.87
  25   0.5712     81.600  0.4154    85.822  135.20
  26   0.5263     83.200  0.4013    86.520  140.54
  27   0.5113     83.240  0.3861    86.890  145.90
  28   0.5218     82.900  0.3577    87.904  151.29
  29   0.5636     82.720  0.3663    87.674  156.64
  30   0.5166     83.700  0.3303    88.912  161.97
  31   0.5368     82.810  0.3241    88.976  167.33
  32   0.5032     84.570  0.3195    89.302  172.69
  33   0.5127     83.990  0.3054    89.652  178.04
  34   0.5023     84.470  0.3046    89.728  183.34
  35   0.5152     84.610  0.2746    90.806  188.72
  36   0.5256     84.020  0.2728    90.824  194.05
  37   0.5027     84.760  0.2673    91.030  199.38
  38   0.5350     83.900  0.2507    91.726  204.70
  39   0.5169     84.720  0.2482    91.698  210.07
  40   0.5113     85.180  0.2379    92.008  215.38
  41   0.5364     84.580  0.2325    92.218  220.78
  42   0.4935     85.690  0.2306    92.300  226.13
  43   0.4848     85.580  0.2181    92.638  231.44
  44   0.5327     85.310  0.2046    93.304  236.79
  45   0.5010     85.360  0.2052    93.126  242.13
  46   0.5247     85.260  0.1955    93.382  247.48
  47   0.5040     85.920  0.2003    93.398  252.81
  48   0.5194     86.070  0.1870    93.772  258.20
  49   0.5208     85.050  0.1764    94.072  263.51
  50   0.5342     85.980  0.1663    94.460  268.82
  51   0.5413     85.660  0.1669    94.506  274.13
  52   0.5472     85.900  0.1596    94.766  279.43
  53   0.5047     86.000  0.1579    94.632  284.79
  54   0.5114     86.460  0.1578    94.682  290.21
  55   0.5199     86.070  0.1476    95.098  295.54
  56   0.5578     86.250  0.1427    95.256  300.86
  57   0.5254     85.880  0.1399    95.346  306.21
  58   0.5455     85.980  0.1414    95.238  311.52
  59   0.5279     86.510  0.1417    95.344  316.94
  60   0.5430     86.890  0.1268    95.804  322.31
  61   0.5438     86.670  0.1220    95.872  327.65
  62   0.5437     86.270  0.1260    95.882  332.98
  63   0.5431     86.340  0.1190    96.134  338.32
  64   0.5484     86.300  0.1163    96.180  343.65
  65   0.5401     86.800  0.1283    95.828  348.97
  66   0.5002     86.760  0.1118    96.326  354.31
  67   0.5664     86.270  0.1061    96.504  359.70
  68   0.5465     87.090  0.1000    96.700  365.03
  69   0.5351     86.680  0.1022    96.606  370.37
  70   0.5726     86.640  0.0989    96.692  375.69
  71   0.5276     87.270  0.1056    96.534  381.04
  72   0.5817     86.730  0.1012    96.678  386.36
  73   0.5526     86.640  0.0957    96.808  391.77
  74   0.5392     87.060  0.1028    96.574  397.10
  75   0.5447     86.970  0.0932    96.904  402.41
  76   0.5558     86.650  0.0842    97.148  407.74
  77   0.5285     87.370  0.0937    97.042  413.06
  78   0.5866     87.130  0.0928    96.932  418.39
  79   0.5558     87.120  0.0851    97.186  423.72
  80   0.5405     87.260  0.0824    97.202  429.15
  81   0.5541     87.110  0.0871    97.102  434.49
  82   0.5901     86.430  0.0791    97.432  439.85
  83   0.5988     86.580  0.0785    97.406  445.16
  84   0.6056     87.080  0.0876    97.136  450.52
  85   0.5465     87.110  0.0756    97.500  455.84
  86   0.5990     87.220  0.0772    97.476  461.28
  87   0.5992     87.390  0.0826    97.336  466.60
  88   0.6020     87.230  0.0690    97.734  471.94
  89   0.5926     86.940  0.0769    97.586  477.25
  90   0.5807     86.930  0.0852    97.260  482.55
