Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7684     28.810  2.0294    19.996  7.18
   2   1.6422     34.780  1.7214    30.844  12.50
   3   1.5151     42.330  1.6317    35.860  17.80
   4   1.3730     47.090  1.4935    42.694  23.13
   5   1.2811     51.960  1.3693    48.264  28.46
   6   1.1630     56.550  1.2561    53.352  33.80
   7   1.0898     59.940  1.1673    56.926  39.16
   8   1.0280     62.960  1.0719    60.946  44.55
   9   0.9774     64.890  0.9990    64.198  49.91
  10   0.8910     68.230  0.9312    66.670  55.23
  11   0.8640     69.570  0.9004    67.824  60.56
  12   0.8080     71.350  0.8313    70.468  65.90
  13   0.7962     72.350  0.7899    72.130  71.28
  14   0.7316     74.430  0.7536    73.402  76.65
  15   0.7579     73.100  0.7176    74.938  81.97
  16   0.7341     74.650  0.7019    75.292  87.29
  17   0.7022     75.910  0.6744    76.602  92.61
  18   0.6936     75.860  0.6286    78.218  97.93
  19   0.6456     78.140  0.5971    79.278  103.27
  20   0.6423     77.970  0.5797    80.022  108.70
  21   0.6316     78.880  0.5552    80.898  114.02
  22   0.6194     78.700  0.5312    81.708  119.35
  23   0.6153     79.430  0.5277    81.842  124.72
  24   0.5902     80.150  0.5102    82.600  130.06
  25   0.6087     80.170  0.4650    83.916  135.38
  26   0.5664     81.320  0.4490    84.630  140.79
  27   0.6066     80.420  0.4308    85.232  146.11
  28   0.5668     81.220  0.4147    85.590  151.42
  29   0.5966     80.980  0.3986    86.364  156.75
  30   0.5837     81.960  0.3847    86.826  162.08
  31   0.5661     82.150  0.3788    87.086  167.42
  32   0.5455     82.460  0.3587    87.842  172.74
  33   0.5474     82.390  0.3417    88.312  178.16
  34   0.5809     81.910  0.3373    88.460  183.48
  35   0.5661     82.330  0.3209    88.994  188.86
  36   0.5567     82.620  0.3113    89.406  194.19
  37   0.5456     82.900  0.3074    89.502  199.55
  38   0.5428     83.320  0.2887    90.216  204.86
  39   0.5823     83.170  0.2646    91.014  210.19
  40   0.5725     82.660  0.2662    90.920  215.60
  41   0.5739     82.250  0.2689    90.738  220.94
  42   0.5514     83.420  0.2579    91.172  226.29
  43   0.5450     83.620  0.2331    91.970  231.62
  44   0.5620     83.370  0.2305    92.212  236.96
  45   0.5561     83.970  0.2147    92.674  242.35
  46   0.5558     84.060  0.2059    92.956  247.75
  47   0.5806     83.870  0.1904    93.460  253.06
  48   0.5838     83.070  0.1903    93.508  258.41
  49   0.5807     84.300  0.1929    93.556  263.77
  50   0.6034     83.300  0.1845    93.762  269.14
  51   0.5972     84.150  0.1849    93.802  274.47
  52   0.5889     83.970  0.1646    94.388  279.82
  53   0.6062     83.760  0.1635    94.356  285.19
  54   0.5847     83.970  0.1665    94.446  290.54
  55   0.6014     83.650  0.1526    94.866  295.87
  56   0.6089     83.990  0.1485    95.018  301.19
  57   0.6321     83.180  0.1510    94.710  306.55
  58   0.5987     84.170  0.1404    95.248  311.98
  59   0.6373     83.510  0.1335    95.442  317.33
  60   0.6054     84.060  0.1360    95.342  322.67
  61   0.6668     84.090  0.1264    95.716  328.02
  62   0.6158     83.870  0.1201    96.034  333.38
  63   0.6255     84.040  0.1189    95.906  338.70
  64   0.6612     83.840  0.1237    95.858  344.07
  65   0.6144     83.850  0.1260    95.760  349.50
  66   0.6158     84.660  0.1181    96.070  354.85
  67   0.6421     84.620  0.1038    96.480  360.22
  68   0.6281     84.960  0.1080    96.424  365.57
  69   0.6343     84.360  0.1012    96.608  370.91
  70   0.6337     84.060  0.1051    96.396  376.23
  71   0.6434     84.500  0.0979    96.670  381.59
  72   0.6958     84.150  0.0990    96.656  387.00
  73   0.6489     84.270  0.1059    96.462  392.35
  74   0.5849     84.200  0.1042    96.536  397.70
  75   0.6720     84.490  0.0937    96.900  403.02
  76   0.6458     84.740  0.0828    97.184  408.34
  77   0.6373     84.960  0.0858    97.102  413.67
  78   0.6512     85.080  0.0819    97.220  419.02
  79   0.6751     84.530  0.0741    97.530  424.43
  80   0.6453     84.580  0.0774    97.306  429.81
  81   0.6816     84.350  0.0836    97.162  435.17
  82   0.6666     84.310  0.0857    97.070  440.50
  83   0.6909     84.640  0.0845    97.156  445.81
  84   0.6724     84.410  0.0880    97.038  451.15
  85   0.6421     85.390  0.0806    97.274  456.47
  86   0.6517     84.820  0.0738    97.434  461.90
  87   0.6662     84.470  0.0736    97.504  467.22
  88   0.6348     85.140  0.0751    97.452  472.55
  89   0.6579     84.910  0.0674    97.738  477.89
  90   0.6703     85.110  0.0677    97.760  483.21
