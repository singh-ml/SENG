Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9585     19.200  2.1691    15.146  6.98
   2   1.8396     23.450  1.9292    20.804  12.31
   3   1.6968     31.870  1.7963    28.018  17.68
   4   1.5970     37.260  1.6782    33.404  23.01
   5   1.4608     42.960  1.5654    39.162  28.37
   6   1.3192     49.780  1.4361    45.092  33.71
   7   1.2622     53.540  1.3334    50.006  39.03
   8   1.1544     57.150  1.2322    54.980  44.38
   9   1.0953     61.310  1.1457    58.680  49.69
  10   1.0034     64.030  1.0690    61.698  55.02
  11   0.9611     65.560  0.9965    64.462  60.36
  12   0.8628     69.350  0.9283    67.242  65.75
  13   0.8753     69.080  0.8747    68.974  71.11
  14   0.8173     70.770  0.8446    70.338  76.44
  15   0.7807     73.020  0.7875    72.404  81.78
  16   0.7491     74.650  0.7521    73.880  87.11
  17   0.7176     75.400  0.7113    75.402  92.46
  18   0.6750     77.080  0.6901    76.324  97.88
  19   0.6630     77.800  0.6498    77.692  103.23
  20   0.7051     76.480  0.6460    78.044  108.55
  21   0.6379     78.910  0.6071    79.422  113.89
  22   0.6104     79.750  0.5734    80.550  119.21
  23   0.6035     80.090  0.5678    80.866  124.54
  24   0.5691     80.970  0.5403    81.816  129.87
  25   0.5981     81.350  0.5171    82.588  135.23
  26   0.6160     80.180  0.5165    82.630  140.55
  27   0.5618     81.850  0.5092    83.434  145.92
  28   0.5553     81.920  0.4824    83.956  151.27
  29   0.5485     82.360  0.4776    83.992  156.63
  30   0.5416     82.440  0.4628    84.738  161.95
  31   0.5504     82.190  0.4353    85.328  167.28
  32   0.5251     83.140  0.4392    85.452  172.72
  33   0.5177     83.810  0.4148    86.176  178.06
  34   0.5227     83.180  0.4148    86.216  183.39
  35   0.5018     84.130  0.4011    86.342  188.71
  36   0.5124     83.630  0.3902    87.054  194.04
  37   0.4844     84.770  0.3877    87.226  199.39
  38   0.4849     84.450  0.3819    87.408  204.79
  39   0.5028     84.390  0.3683    87.720  210.11
  40   0.5044     84.420  0.3657    87.882  215.45
  41   0.4801     85.260  0.3462    88.588  220.77
  42   0.5089     84.600  0.3394    88.810  226.10
  43   0.4879     84.530  0.3407    88.774  231.47
  44   0.4613     85.790  0.3276    89.148  236.80
  45   0.4816     85.160  0.3249    89.160  242.21
  46   0.5092     84.650  0.3130    89.634  247.56
  47   0.4703     85.220  0.3124    89.812  252.89
  48   0.4867     85.170  0.3026    89.930  258.22
  49   0.4851     85.520  0.2949    90.186  263.54
  50   0.4842     85.670  0.2879    90.464  268.91
  51   0.4683     85.840  0.2940    90.198  274.29
  52   0.4867     85.480  0.2782    90.808  279.64
  53   0.4773     85.530  0.2751    90.866  284.96
  54   0.4611     86.250  0.2665    91.108  290.34
  55   0.4845     85.070  0.2719    90.960  295.67
  56   0.4709     85.760  0.2692    91.074  301.01
  57   0.4488     86.540  0.2642    91.248  306.44
  58   0.4794     86.470  0.2525    91.666  311.77
  59   0.4773     85.900  0.2493    91.712  317.13
  60   0.4567     86.510  0.2470    91.782  322.46
  61   0.4475     86.780  0.2471    91.816  327.80
  62   0.4743     86.910  0.2306    92.274  333.12
  63   0.4552     86.090  0.2432    91.970  338.44
  64   0.4619     87.040  0.2316    92.314  343.88
  65   0.4748     86.550  0.2198    92.718  349.23
  66   0.4443     86.350  0.2322    92.360  354.58
  67   0.4445     86.760  0.2305    92.392  359.96
  68   0.4877     86.250  0.2284    92.546  365.33
  69   0.4723     86.860  0.2189    92.756  370.66
  70   0.4525     87.060  0.2222    92.804  376.05
  71   0.4536     87.230  0.2113    93.014  381.38
  72   0.4787     86.040  0.2082    93.178  386.70
  73   0.4874     86.570  0.2119    92.978  392.04
  74   0.4554     86.780  0.2052    93.302  397.37
  75   0.4880     86.500  0.1959    93.416  402.69
  76   0.4711     86.770  0.1971    93.554  408.03
  77   0.4727     86.770  0.2033    93.386  413.45
  78   0.4484     87.230  0.2005    93.400  418.80
  79   0.4776     86.980  0.1997    93.462  424.14
  80   0.4603     87.070  0.1930    93.632  429.47
  81   0.4604     87.080  0.1872    93.834  434.82
  82   0.4918     86.870  0.1837    93.938  440.18
  83   0.5018     86.440  0.1862    93.942  445.54
  84   0.4567     87.290  0.1820    94.134  450.86
  85   0.4913     86.870  0.1765    94.266  456.19
  86   0.4704     86.800  0.1834    93.878  461.56
  87   0.4462     87.070  0.1796    94.234  466.90
  88   0.4586     87.840  0.1758    94.312  472.22
  89   0.4671     87.510  0.1701    94.476  477.56
  90   0.4708     87.250  0.1779    94.112  482.99
