Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8864     20.930  2.0559    17.098  7.13
   2   1.7533     27.620  1.8512    22.758  12.44
   3   1.6063     36.110  1.7521    29.026  17.96
   4   1.4327     44.960  1.5724    38.440  23.31
   5   1.3180     49.340  1.4142    45.598  28.66
   6   1.1840     57.160  1.2660    52.706  34.02
   7   1.0693     61.630  1.1449    58.180  39.44
   8   0.9611     65.080  1.0142    63.212  44.76
   9   0.9006     68.530  0.9502    66.110  50.11
  10   0.8252     70.270  0.8638    69.306  55.46
  11   0.8192     72.020  0.8213    71.022  60.80
  12   0.7630     73.500  0.7604    73.284  66.17
  13   0.7356     74.620  0.7292    74.396  71.50
  14   0.6738     76.830  0.6445    77.634  76.92
  15   0.6593     77.580  0.6213    78.524  82.26
  16   0.6352     78.660  0.5926    79.800  87.59
  17   0.6084     79.740  0.5532    81.118  92.92
  18   0.6084     79.290  0.5399    81.786  98.24
  19   0.5821     80.670  0.5104    82.636  103.59
  20   0.5802     81.000  0.4803    83.870  109.00
  21   0.5632     81.160  0.4570    84.382  114.31
  22   0.5365     82.320  0.4367    85.266  119.64
  23   0.5315     82.490  0.4278    85.556  125.00
  24   0.5313     83.160  0.3947    86.686  130.34
  25   0.5321     82.910  0.3824    87.026  135.68
  26   0.5043     83.420  0.3575    87.974  141.08
  27   0.5265     82.920  0.3510    88.160  146.43
  28   0.5193     83.700  0.3425    88.570  151.75
  29   0.5174     84.060  0.3296    88.922  157.10
  30   0.5191     83.870  0.3128    89.440  162.41
  31   0.5222     83.510  0.2949    90.214  167.75
  32   0.5154     84.300  0.2852    90.254  173.14
  33   0.5137     84.890  0.2847    90.376  178.47
  34   0.4943     85.040  0.2578    91.158  183.79
  35   0.5011     84.720  0.2451    91.818  189.12
  36   0.4938     84.960  0.2434    91.822  194.46
  37   0.5535     84.460  0.2336    92.202  199.78
  38   0.5613     84.150  0.2322    92.226  205.10
  39   0.4961     85.320  0.2175    92.760  210.50
  40   0.5144     85.040  0.2124    92.918  215.82
  41   0.5115     84.800  0.2056    93.156  221.15
  42   0.5317     84.460  0.1977    93.354  226.50
  43   0.4956     86.070  0.2006    93.254  231.84
  44   0.5061     85.530  0.1779    93.992  237.16
  45   0.5212     85.740  0.1772    94.132  242.51
  46   0.5382     85.740  0.1738    94.262  247.84
  47   0.5112     85.990  0.1749    94.254  253.17
  48   0.5256     85.400  0.1737    94.226  258.49
  49   0.5459     85.340  0.1635    94.526  263.85
  50   0.5019     86.040  0.1579    94.700  269.16
  51   0.5456     86.240  0.1497    94.886  274.48
  52   0.5652     86.330  0.1366    95.600  279.91
  53   0.5391     85.750  0.1396    95.416  285.25
  54   0.5446     85.940  0.1340    95.556  290.58
  55   0.5785     86.070  0.1390    95.414  295.92
  56   0.5517     85.870  0.1337    95.526  301.25
  57   0.5943     86.030  0.1257    95.866  306.58
  58   0.5356     85.780  0.1295    95.776  311.97
  59   0.5712     85.760  0.1179    96.116  317.29
  60   0.5780     86.210  0.1094    96.472  322.66
  61   0.5757     86.100  0.1101    96.358  327.99
  62   0.5317     86.300  0.1105    96.258  333.32
  63   0.6233     86.320  0.0972    96.732  338.64
  64   0.5789     86.060  0.1093    96.416  344.03
  65   0.5924     86.250  0.1075    96.604  349.37
  66   0.5962     85.750  0.1110    96.340  354.72
  67   0.5606     86.570  0.1090    96.442  360.04
  68   0.5645     86.730  0.0942    96.906  365.39
  69   0.5487     87.180  0.0911    97.040  370.75
  70   0.5528     86.870  0.0880    97.102  376.09
  71   0.5605     86.360  0.0960    96.872  381.49
  72   0.5437     86.540  0.0969    96.860  386.81
  73   0.5985     86.280  0.0895    97.038  392.18
  74   0.6019     86.010  0.0996    96.724  397.49
  75   0.5790     86.240  0.0948    96.906  402.82
  76   0.6014     86.440  0.0807    97.408  408.15
  77   0.5410     87.100  0.0820    97.306  413.54
  78   0.5960     86.440  0.0775    97.422  418.89
  79   0.5948     86.570  0.0797    97.428  424.22
  80   0.5881     86.880  0.0791    97.456  429.54
  81   0.5712     86.850  0.0835    97.290  434.86
  82   0.5959     87.070  0.0795    97.406  440.21
  83   0.5931     86.600  0.0759    97.500  445.58
  84   0.5826     86.160  0.0776    97.450  450.95
  85   0.5814     86.750  0.0775    97.514  456.29
