Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042585600 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2846     13.680  2.5328    10.714  6.96
   2   2.2417     16.270  2.2624    13.308  12.32
   3   2.0140     21.730  2.1217    18.214  17.66
   4   1.8897     25.700  1.9797    22.412  23.00
   5   1.7926     30.870  1.8566    26.444  28.35
   6   1.6900     34.020  1.7741    30.856  33.68
   7   1.5953     38.870  1.6903    34.474  39.04
   8   1.5367     41.130  1.6154    38.218  44.47
   9   1.4344     46.330  1.5303    42.006  49.79
  10   1.3832     48.300  1.4515    46.024  55.14
  11   1.3390     50.520  1.3810    49.022  60.51
  12   1.2731     53.750  1.3021    52.504  65.89
  13   1.1768     58.110  1.2536    54.844  71.25
  14   1.1570     58.960  1.1690    58.486  76.65
  15   1.0437     63.180  1.1145    60.360  82.00
  16   1.0142     63.810  1.0548    62.806  87.32
  17   0.9811     65.490  0.9977    64.620  92.65
  18   0.9821     65.780  0.9835    65.068  98.00
  19   0.8951     68.600  0.9341    67.092  103.33
  20   0.8970     68.470  0.9022    67.984  108.67
  21   0.8802     68.630  0.8764    69.374  114.06
  22   0.8548     69.430  0.8737    69.458  119.42
  23   0.8459     71.360  0.8523    70.218  124.74
  24   0.8344     71.510  0.8339    71.196  130.09
  25   0.7783     72.990  0.7993    72.364  135.41
  26   0.7729     74.050  0.7727    73.492  140.73
  27   0.7694     74.150  0.7601    74.176  146.15
  28   0.7765     74.380  0.7476    74.666  151.52
  29   0.7273     75.780  0.7196    75.416  156.89
  30   0.7199     75.780  0.7058    75.764  162.27
  31   0.7009     76.940  0.6954    76.394  167.59
  32   0.6993     76.770  0.6731    77.114  172.93
  33   0.6722     77.680  0.6584    77.808  178.30
  34   0.6896     77.580  0.6580    77.904  183.68
  35   0.6808     77.100  0.6380    78.750  189.02
  36   0.6463     78.760  0.6336    78.864  194.36
  37   0.6565     78.730  0.6157    79.418  199.71
  38   0.6307     78.960  0.6148    79.446  205.04
  39   0.6285     79.720  0.6024    79.772  210.35
  40   0.6467     79.160  0.5915    80.332  215.75
  41   0.6477     79.190  0.5748    80.862  221.10
  42   0.6186     80.420  0.5832    80.732  226.43
  43   0.6177     79.730  0.5645    81.220  231.77
  44   0.6227     79.490  0.5566    81.510  237.10
  45   0.5958     80.350  0.5482    81.846  242.45
  46   0.5940     80.500  0.5556    81.372  247.84
  47   0.5929     80.780  0.5388    81.922  253.16
  48   0.5995     80.440  0.5282    82.426  258.54
  49   0.5942     80.970  0.5299    82.576  263.84
  50   0.5643     81.860  0.5212    82.704  269.22
  51   0.5692     82.020  0.5147    82.900  274.58
  52   0.5650     81.560  0.5026    83.274  279.91
  53   0.5717     81.600  0.5035    83.320  285.30
  54   0.5685     81.710  0.4953    83.346  290.64
  55   0.5550     82.120  0.4900    83.890  296.01
  56   0.5536     82.050  0.4828    84.044  301.36
  57   0.5655     81.760  0.4841    83.928  306.70
  58   0.5568     82.500  0.4956    83.850  312.04
  59   0.5380     82.830  0.4776    84.284  317.37
  60   0.5821     81.890  0.4674    84.734  322.80
  61   0.5684     82.080  0.4808    84.232  328.16
  62   0.5536     82.440  0.4619    84.828  333.49
  63   0.5617     82.250  0.4642    84.536  338.85
  64   0.5350     83.130  0.4654    84.438  344.18
  65   0.5337     82.850  0.4566    84.750  349.50
  66   0.5807     82.260  0.4476    85.382  354.92
  67   0.5485     82.530  0.4561    85.048  360.24
  68   0.5566     83.010  0.4503    85.108  365.60
  69   0.5313     83.470  0.4412    85.484  370.95
  70   0.5238     83.150  0.4263    86.046  376.30
  71   0.5363     83.030  0.4346    85.750  381.64
  72   0.5473     82.850  0.4324    85.878  387.03
  73   0.5411     82.710  0.4319    85.776  392.40
  74   0.5556     83.230  0.4333    85.874  397.75
  75   0.5427     82.950  0.4251    85.866  403.09
  76   0.5309     83.490  0.4207    86.158  408.45
  77   0.5609     82.200  0.4244    85.954  413.80
  78   0.5278     83.050  0.4252    86.190  419.18
  79   0.5292     83.510  0.4237    86.222  424.54
  80   0.5511     82.660  0.4152    86.568  429.89
  81   0.5231     83.520  0.4050    86.678  435.24
  82   0.5297     83.180  0.4101    86.374  440.57
  83   0.5377     83.180  0.4092    86.446  445.89
  84   0.5443     83.710  0.4028    86.760  451.23
  85   0.5215     83.820  0.3988    87.054  456.62
