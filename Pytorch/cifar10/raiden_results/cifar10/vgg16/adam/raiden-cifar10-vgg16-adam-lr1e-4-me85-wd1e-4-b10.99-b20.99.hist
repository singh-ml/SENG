Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8242     27.170  2.0979    19.028  6.92
   2   1.6027     36.650  1.7599    30.086  12.34
   3   1.5179     40.340  1.6130    36.900  17.68
   4   1.3814     47.410  1.4904    42.512  22.98
   5   1.2816     52.180  1.3655    48.124  28.33
   6   1.1512     57.920  1.2460    53.846  33.68
   7   1.0948     60.040  1.1413    58.466  38.98
   8   1.0256     63.340  1.0625    61.764  44.37
   9   1.0261     64.080  1.0004    64.122  49.70
  10   0.8986     68.360  0.9515    65.888  55.02
  11   0.9084     68.550  0.8901    68.204  60.32
  12   0.8585     69.790  0.8595    69.524  65.63
  13   0.7870     72.650  0.8030    71.696  70.96
  14   0.7921     72.900  0.7634    73.098  76.30
  15   0.7526     74.370  0.7284    74.450  81.66
  16   0.7138     75.420  0.6907    75.980  86.99
  17   0.6862     76.400  0.6624    76.744  92.31
  18   0.6975     76.870  0.6368    77.640  97.67
  19   0.7073     75.990  0.6083    79.018  103.00
  20   0.6643     77.550  0.5945    79.542  108.30
  21   0.6446     77.590  0.5541    80.798  113.63
  22   0.6188     78.750  0.5342    81.610  119.01
  23   0.6343     78.910  0.5151    82.164  124.34
  24   0.5855     79.950  0.5022    82.666  129.66
  25   0.5938     79.780  0.4675    83.862  134.98
  26   0.6026     80.460  0.4515    84.490  140.28
  27   0.5721     80.890  0.4416    84.822  145.62
  28   0.5970     80.320  0.4324    85.292  151.00
  29   0.5708     80.710  0.4117    86.026  156.34
  30   0.5526     81.690  0.3914    86.692  161.65
  31   0.5882     80.730  0.3806    87.046  166.96
  32   0.5729     82.070  0.3694    87.498  172.26
  33   0.5574     82.220  0.3581    87.760  177.60
  34   0.5401     82.660  0.3420    88.276  182.99
  35   0.5602     82.570  0.3152    89.216  188.29
  36   0.5260     82.860  0.3092    89.464  193.60
  37   0.5670     82.030  0.3021    89.600  198.90
  38   0.5813     82.410  0.2754    90.572  204.20
  39   0.5370     83.280  0.2670    90.896  209.50
  40   0.5719     82.690  0.2623    91.014  214.92
  41   0.5957     82.410  0.2740    90.538  220.24
  42   0.5526     82.960  0.2591    91.270  225.60
  43   0.5828     83.740  0.2329    92.036  230.94
  44   0.5789     82.500  0.2326    92.072  236.27
  45   0.5878     83.760  0.2264    92.250  241.61
  46   0.6024     82.840  0.2148    92.590  246.93
  47   0.5562     83.570  0.2073    92.932  252.33
  48   0.5845     83.570  0.2072    92.922  257.65
  49   0.5944     83.950  0.1872    93.528  263.01
  50   0.5894     83.280  0.1796    93.898  268.33
  51   0.5948     84.340  0.1725    94.098  273.69
  52   0.6097     83.860  0.1714    94.240  279.01
  53   0.5861     84.070  0.1727    94.084  284.35
  54   0.5910     84.320  0.1618    94.544  289.65
  55   0.6086     83.710  0.1525    94.760  294.98
  56   0.5966     83.950  0.1608    94.568  300.32
  57   0.5591     84.370  0.1501    95.024  305.65
  58   0.5813     83.900  0.1459    95.036  310.96
  59   0.6308     84.680  0.1319    95.628  316.30
  60   0.5813     84.530  0.1281    95.732  321.70
  61   0.5849     84.110  0.1311    95.500  327.05
  62   0.5928     84.450  0.1188    96.034  332.37
  63   0.6161     84.130  0.1227    95.854  337.68
  64   0.6270     84.950  0.1217    95.866  343.00
  65   0.5979     84.260  0.1255    95.780  348.33
  66   0.5936     85.420  0.1094    96.344  353.72
  67   0.6022     84.250  0.1082    96.366  359.04
  68   0.6351     84.880  0.1099    96.282  364.36
  69   0.6157     84.930  0.1049    96.520  369.66
  70   0.6347     83.950  0.0996    96.610  374.97
  71   0.6141     84.630  0.1039    96.554  380.29
  72   0.6278     84.520  0.0967    96.732  385.68
  73   0.6208     84.690  0.0955    96.746  390.98
  74   0.6250     84.730  0.0918    96.926  396.31
  75   0.6565     84.760  0.0950    96.792  401.62
  76   0.6712     84.780  0.0862    97.146  406.93
  77   0.6707     84.840  0.0919    96.956  412.28
  78   0.6324     84.890  0.0840    97.156  417.63
  79   0.6000     85.080  0.0841    97.118  423.01
  80   0.6455     84.800  0.0805    97.202  428.33
  81   0.6353     85.310  0.0830    97.146  433.64
  82   0.6782     85.310  0.0843    97.104  438.96
  83   0.7178     84.430  0.0814    97.300  444.29
  84   0.6828     85.220  0.0788    97.284  449.64
  85   0.6609     85.550  0.0801    97.262  454.97
