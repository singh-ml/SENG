Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8042     26.050  2.0282    18.630  6.99
   2   1.6086     36.100  1.6671    33.638  12.31
   3   1.4227     47.920  1.4532    44.188  17.63
   4   1.1145     59.840  1.2564    53.406  22.98
   5   1.0238     64.050  1.0892    60.364  28.37
   6   0.8921     68.630  0.9761    65.260  33.72
   7   0.9194     69.050  0.8900    68.748  39.05
   8   0.8005     72.850  0.8031    71.962  44.42
   9   0.8073     72.340  0.7537    74.326  49.77
  10   0.7757     73.870  0.6968    75.940  55.12
  11   0.7855     75.020  0.6427    78.090  60.46
  12   0.6747     78.260  0.6099    79.548  65.93
  13   0.7516     76.660  0.5799    80.528  71.26
  14   0.6862     78.360  0.5539    81.486  76.61
  15   0.5516     82.030  0.5195    82.650  81.97
  16   0.5733     81.140  0.4835    83.942  87.31
  17   0.5502     82.160  0.4612    84.730  92.68
  18   0.6054     81.020  0.4400    85.476  98.11
  19   0.5583     82.210  0.4264    85.892  103.44
  20   0.5331     83.480  0.4030    86.670  108.78
  21   0.5205     83.900  0.3807    87.346  114.14
  22   0.5230     83.450  0.3726    87.734  119.46
  23   0.5271     83.630  0.3531    88.426  124.82
  24   0.5236     83.730  0.3358    88.918  130.21
  25   0.5404     83.870  0.3285    89.372  135.55
  26   0.5382     83.800  0.3103    89.796  140.94
  27   0.4802     85.340  0.2918    90.434  146.27
  28   0.5222     85.070  0.2820    90.600  151.61
  29   0.4970     85.190  0.2740    91.060  156.97
  30   0.5057     85.070  0.2640    91.460  162.34
  31   0.5187     85.290  0.2647    91.226  167.74
  32   0.4772     85.970  0.2426    92.070  173.11
  33   0.5966     83.850  0.2383    92.164  178.46
  34   0.5025     85.750  0.2407    92.192  183.80
  35   0.4798     85.700  0.2148    92.916  189.16
  36   0.4867     85.900  0.2191    92.892  194.48
  37   0.4620     86.920  0.2105    93.196  199.87
  38   0.5298     85.870  0.1991    93.440  205.21
  39   0.5738     85.440  0.1973    93.558  210.57
  40   0.4870     85.780  0.1866    93.808  215.95
  41   0.4691     86.330  0.1825    94.076  221.30
  42   0.4786     86.540  0.1750    94.310  226.66
  43   0.4821     87.050  0.1762    94.220  232.04
  44   0.5047     86.350  0.1586    94.810  237.77
  45   0.5430     85.710  0.1691    94.514  243.14
  46   0.5306     86.900  0.1553    95.024  248.46
  47   0.5024     86.980  0.1515    95.072  253.79
  48   0.5037     86.850  0.1459    95.258  259.14
  49   0.5175     86.900  0.1369    95.532  264.49
  50   0.5751     86.750  0.1372    95.546  269.93
  51   0.5315     86.540  0.1471    95.204  275.27
  52   0.5613     86.340  0.1409    95.562  280.63
  53   0.5576     85.660  0.1317    95.730  285.96
  54   0.5152     87.310  0.1263    95.912  291.31
  55   0.5207     87.320  0.1317    95.678  296.65
  56   0.5135     87.470  0.1299    95.776  301.98
  57   0.5705     86.700  0.1150    96.308  307.43
  58   0.4991     87.240  0.1179    96.214  312.78
  59   0.5327     86.580  0.1222    96.214  318.12
  60   0.5356     87.440  0.1120    96.264  323.49
  61   0.5315     87.170  0.1069    96.542  328.85
  62   0.5139     87.090  0.1048    96.716  334.22
  63   0.4970     87.800  0.1096    96.482  339.64
  64   0.5578     87.330  0.1088    96.434  345.01
  65   0.5509     86.870  0.1088    96.460  350.37
  66   0.5311     87.530  0.1047    96.620  355.71
  67   0.5079     87.700  0.0983    96.788  361.04
  68   0.5048     87.820  0.1022    96.690  366.39
  69   0.5900     86.300  0.0899    97.116  371.80
  70   0.5458     87.640  0.1029    96.738  377.15
  71   0.5099     87.710  0.0943    96.986  382.49
  72   0.5244     87.730  0.0978    96.790  387.83
  73   0.5417     86.770  0.0934    97.004  393.20
  74   0.5733     87.260  0.0936    97.022  398.56
  75   0.4962     87.760  0.0962    96.950  403.98
  76   0.5129     87.640  0.0913    97.074  409.34
  77   0.5643     87.600  0.0869    97.272  414.67
  78   0.5699     87.560  0.0891    97.164  420.01
  79   0.5532     87.200  0.0864    97.264  425.35
  80   0.5640     87.350  0.0803    97.498  430.73
  81   0.5532     87.740  0.0835    97.370  436.10
  82   0.5881     87.300  0.0858    97.276  441.54
  83   0.5298     87.780  0.0804    97.506  446.90
  84   0.5017     88.110  0.0788    97.482  452.29
  85   0.5301     87.890  0.0820    97.436  457.65
