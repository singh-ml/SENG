Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4041537024 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6262     36.440  1.9332    24.566  6.92
   2   1.4599     44.540  1.5531    40.322  12.22
   3   1.2490     54.530  1.3666    49.410  17.64
   4   1.1052     60.300  1.2205    55.538  22.94
   5   1.0375     62.270  1.1108    60.044  28.26
   6   0.9392     66.200  1.0217    63.304  33.57
   7   0.9540     66.960  0.9425    66.492  38.89
   8   0.8458     70.070  0.8892    68.584  44.22
   9   0.7670     73.510  0.8245    71.072  49.64
  10   0.7635     73.870  0.7719    72.996  54.96
  11   0.7128     75.170  0.7345    74.312  60.26
  12   0.7242     75.490  0.6951    76.146  65.57
  13   0.6668     77.230  0.6649    77.038  70.88
  14   0.6475     77.730  0.6177    78.716  76.21
  15   0.6472     77.000  0.6035    79.250  81.50
  16   0.6195     79.120  0.5686    80.440  86.93
  17   0.6144     79.220  0.5314    81.594  92.26
  18   0.5859     80.100  0.5193    82.154  97.56
  19   0.5992     80.280  0.4935    83.070  102.88
  20   0.5815     80.350  0.4792    83.444  108.19
  21   0.5597     81.710  0.4573    84.384  113.53
  22   0.5660     80.660  0.4356    85.172  118.87
  23   0.5797     81.010  0.4221    85.622  124.19
  24   0.5662     81.010  0.4010    86.272  129.53
  25   0.5661     81.520  0.3786    87.042  134.85
  26   0.5491     82.080  0.3696    87.428  140.15
  27   0.5699     82.070  0.3532    87.970  145.50
  28   0.6346     80.370  0.3446    88.202  150.90
  29   0.5273     83.160  0.3320    88.780  156.24
  30   0.5490     82.130  0.3107    89.318  161.60
  31   0.5311     82.860  0.3009    89.790  166.94
  32   0.5513     82.440  0.2805    90.432  172.30
  33   0.5704     82.700  0.2751    90.806  177.61
  34   0.5325     83.070  0.2613    91.054  182.96
  35   0.5128     83.240  0.2545    91.346  188.33
  36   0.6007     82.800  0.2449    91.738  193.64
  37   0.5531     82.980  0.2401    91.874  198.97
  38   0.5708     83.410  0.2326    92.080  204.29
  39   0.6006     83.360  0.2091    92.988  209.65
  40   0.5384     84.050  0.2061    92.974  214.95
  41   0.5943     83.690  0.1956    93.462  220.28
  42   0.5399     84.020  0.1942    93.366  225.67
  43   0.5930     83.570  0.1755    94.022  230.98
  44   0.6266     82.810  0.1784    94.026  236.32
  45   0.5621     83.650  0.1722    94.150  241.63
  46   0.5927     83.330  0.1644    94.370  246.97
  47   0.5724     84.180  0.1629    94.486  252.30
  48   0.6088     84.010  0.1543    94.750  257.71
  49   0.5926     84.260  0.1493    95.034  263.04
  50   0.6231     83.810  0.1437    95.060  268.37
  51   0.5840     84.280  0.1398    95.318  273.70
  52   0.6067     84.100  0.1360    95.528  279.05
  53   0.5709     84.540  0.1292    95.680  284.37
  54   0.5976     84.500  0.1256    95.772  289.71
  55   0.5883     84.510  0.1243    95.790  295.11
  56   0.6315     84.430  0.1189    96.026  300.44
  57   0.6157     84.860  0.1215    96.002  305.77
  58   0.6395     84.380  0.1157    96.120  311.11
  59   0.6156     85.080  0.1097    96.266  316.43
  60   0.6278     84.720  0.1050    96.388  321.74
  61   0.5985     84.420  0.1073    96.388  327.14
  62   0.6470     83.780  0.1025    96.580  332.49
  63   0.5942     84.490  0.1039    96.458  337.81
  64   0.5929     84.850  0.0990    96.608  343.13
  65   0.6630     83.630  0.0970    96.740  348.45
  66   0.6157     85.070  0.0892    96.942  353.78
  67   0.6214     84.510  0.0944    96.890  359.15
  68   0.6303     84.540  0.0892    96.966  364.54
  69   0.6141     85.030  0.0889    96.972  369.87
  70   0.6407     84.360  0.0812    97.334  375.20
  71   0.6341     83.950  0.0828    97.276  380.52
  72   0.6352     85.930  0.0842    97.264  385.86
  73   0.6348     84.980  0.0811    97.308  391.20
  74   0.6462     84.530  0.0799    97.286  396.59
  75   0.6885     84.660  0.0801    97.290  401.93
  76   0.6633     84.750  0.0749    97.480  407.24
  77   0.6480     84.890  0.0739    97.518  412.55
  78   0.6508     85.470  0.0771    97.458  417.88
  79   0.6252     85.540  0.0793    97.410  423.23
  80   0.6652     85.270  0.0732    97.556  428.56
  81   0.6586     85.470  0.0703    97.680  433.98
  82   0.6503     84.720  0.0696    97.682  439.31
  83   0.6479     84.680  0.0695    97.686  444.62
  84   0.6595     84.700  0.0688    97.714  449.95
  85   0.6626     84.730  0.0652    97.770  455.28
