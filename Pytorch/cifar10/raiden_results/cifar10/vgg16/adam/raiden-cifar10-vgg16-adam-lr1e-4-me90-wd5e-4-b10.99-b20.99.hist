Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8468     25.530  2.1060    18.094  7.04
   2   1.7120     32.340  1.7809    28.302  12.35
   3   1.5178     41.020  1.6474    35.436  17.70
   4   1.4095     45.770  1.5102    41.524  23.04
   5   1.3539     48.990  1.4176    45.760  28.39
   6   1.2699     52.750  1.3287    50.216  33.73
   7   1.1461     58.480  1.2438    53.944  39.13
   8   1.0911     61.350  1.1731    57.310  44.45
   9   1.0252     63.870  1.0774    61.230  49.80
  10   0.9772     64.380  1.0056    63.806  55.17
  11   0.9127     67.470  0.9649    65.606  60.49
  12   0.9078     68.590  0.9202    67.516  65.84
  13   0.8465     70.470  0.8738    69.132  71.16
  14   0.8242     71.260  0.8252    70.796  76.53
  15   0.8094     71.790  0.7811    72.458  81.86
  16   0.7547     73.170  0.7342    74.372  87.19
  17   0.7172     75.170  0.6990    75.584  92.55
  18   0.7063     75.830  0.6782    76.468  97.89
  19   0.7123     75.780  0.6630    76.942  103.23
  20   0.7061     76.320  0.6492    77.594  108.65
  21   0.6734     77.240  0.6133    78.836  114.02
  22   0.6512     77.850  0.5805    79.838  119.35
  23   0.6834     77.160  0.5794    80.020  124.69
  24   0.6190     79.090  0.5509    81.054  130.04
  25   0.6058     79.570  0.5387    81.720  135.38
  26   0.6220     78.780  0.5000    82.852  140.72
  27   0.5913     80.140  0.5062    82.836  146.16
  28   0.5963     80.000  0.4651    84.350  151.51
  29   0.6169     80.150  0.4514    84.798  156.84
  30   0.5790     81.160  0.4382    85.198  162.15
  31   0.6063     80.300  0.4230    85.584  167.49
  32   0.5983     81.190  0.4120    86.156  172.82
  33   0.5719     81.860  0.3918    86.640  178.19
  34   0.5589     82.210  0.3766    87.232  183.63
  35   0.5580     82.140  0.3497    88.134  188.96
  36   0.5627     82.690  0.3347    88.630  194.28
  37   0.5646     82.520  0.3287    88.804  199.61
  38   0.5570     82.430  0.3255    89.142  204.93
  39   0.5713     82.430  0.3120    89.376  210.28
  40   0.5676     82.670  0.3140    89.458  215.65
  41   0.5726     82.560  0.2904    90.270  220.98
  42   0.5618     82.890  0.2925    90.018  226.33
  43   0.5565     83.260  0.2652    91.056  231.69
  44   0.5670     82.980  0.2783    90.710  237.03
  45   0.5564     83.940  0.2609    91.216  242.35
  46   0.5759     83.170  0.2476    91.664  247.69
  47   0.5816     83.500  0.2582    91.324  253.11
  48   0.5613     83.760  0.2435    91.918  258.46
  49   0.5854     82.880  0.2282    92.310  263.80
  50   0.5714     84.620  0.2202    92.630  269.14
  51   0.5549     83.820  0.2165    92.734  274.49
  52   0.5654     83.740  0.2194    92.592  279.81
  53   0.5745     84.060  0.2100    92.898  285.22
  54   0.6283     83.630  0.2094    93.040  290.53
  55   0.5873     84.280  0.1993    93.446  295.88
  56   0.6373     83.580  0.1768    93.970  301.27
  57   0.5404     84.470  0.1807    94.090  306.62
  58   0.6284     84.010  0.1805    93.856  311.98
  59   0.6095     84.370  0.1753    94.222  317.40
  60   0.5813     84.470  0.1581    94.826  322.73
  61   0.5953     84.370  0.1551    94.802  328.07
  62   0.6338     84.240  0.1515    95.028  333.42
  63   0.5736     85.060  0.1431    95.180  338.80
  64   0.5818     84.810  0.1440    95.178  344.12
  65   0.5647     84.640  0.1412    95.378  349.48
  66   0.6046     85.010  0.1358    95.520  354.91
  67   0.6252     84.700  0.1346    95.530  360.27
  68   0.6301     84.960  0.1339    95.574  365.64
  69   0.6171     84.640  0.1191    96.078  371.02
  70   0.6191     84.680  0.1236    96.008  376.34
  71   0.5957     84.790  0.1205    95.988  381.68
  72   0.6081     85.360  0.1149    96.246  387.04
  73   0.6260     85.160  0.1120    96.230  392.47
  74   0.6459     84.480  0.1179    96.142  397.81
  75   0.6215     84.790  0.1111    96.316  403.17
  76   0.6250     84.690  0.1128    96.256  408.50
  77   0.6358     85.140  0.1129    96.290  413.84
  78   0.5922     85.550  0.1018    96.696  419.20
  79   0.6110     85.110  0.0988    96.794  424.53
  80   0.6186     85.590  0.0941    96.878  429.94
  81   0.6250     84.840  0.0982    96.764  435.27
  82   0.6116     84.650  0.1005    96.732  440.63
  83   0.6315     85.090  0.0921    97.004  446.01
  84   0.6318     85.420  0.0925    96.906  451.35
  85   0.6847     84.330  0.0927    96.990  456.69
  86   0.6339     85.290  0.0966    96.778  462.11
  87   0.5949     85.740  0.0835    97.238  467.45
  88   0.6228     85.180  0.0828    97.290  472.78
  89   0.6441     85.680  0.0890    97.096  478.12
  90   0.5958     85.750  0.0904    97.046  483.44
