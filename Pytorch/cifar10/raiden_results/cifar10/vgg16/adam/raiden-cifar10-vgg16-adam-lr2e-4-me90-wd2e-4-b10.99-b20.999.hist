Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4042061312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8857     20.840  2.1006    16.872  6.93
   2   1.8029     25.070  1.8620    21.632  12.32
   3   1.7070     30.880  1.7927    26.020  17.66
   4   1.4819     42.230  1.6325    34.898  22.98
   5   1.3922     47.740  1.4860    42.146  28.33
   6   1.2592     53.120  1.3416    48.784  33.71
   7   1.1765     56.150  1.2510    52.930  39.06
   8   1.0975     59.340  1.1576    56.608  44.53
   9   0.9750     65.000  1.0400    61.708  49.85
  10   0.9078     68.000  0.9575    65.574  55.22
  11   0.9072     67.670  0.8937    68.138  60.56
  12   0.8507     69.300  0.8404    70.224  65.89
  13   0.7719     73.010  0.7851    72.486  71.25
  14   0.7613     74.290  0.7362    74.768  76.66
  15   0.7012     76.230  0.6903    76.184  81.97
  16   0.6777     77.220  0.6467    77.934  87.32
  17   0.6563     78.300  0.5971    79.640  92.64
  18   0.6430     78.070  0.5870    79.956  97.97
  19   0.6301     78.880  0.5617    81.132  103.32
  20   0.5965     80.170  0.5214    82.588  108.64
  21   0.5768     81.120  0.4939    83.522  114.09
  22   0.5683     81.430  0.4844    83.966  119.43
  23   0.5745     81.500  0.4726    84.430  124.75
  24   0.5269     83.060  0.4343    85.574  130.10
  25   0.5324     83.520  0.4071    86.306  135.45
  26   0.5379     82.790  0.3844    87.168  140.79
  27   0.5208     83.340  0.3832    87.214  146.13
  28   0.5195     83.650  0.3698    87.782  151.60
  29   0.5213     83.930  0.3469    88.516  156.92
  30   0.5346     83.710  0.3435    88.630  162.25
  31   0.5178     83.970  0.3339    88.916  167.58
  32   0.5062     84.160  0.3114    89.876  172.90
  33   0.4943     84.790  0.3004    90.052  178.24
  34   0.5255     84.300  0.2941    90.368  183.61
  35   0.5464     84.410  0.2919    90.288  188.94
  36   0.4888     84.990  0.2711    91.068  194.26
  37   0.5018     85.480  0.2657    91.168  199.60
  38   0.4690     85.970  0.2462    91.892  204.97
  39   0.4918     85.400  0.2390    92.100  210.33
  40   0.4843     85.780  0.2398    92.126  215.73
  41   0.5187     85.570  0.2317    92.510  221.09
  42   0.5238     85.150  0.2254    92.662  226.43
  43   0.5149     85.170  0.2146    92.988  231.78
  44   0.4831     86.530  0.2078    93.048  237.11
  45   0.5285     86.170  0.2086    93.246  242.48
  46   0.5050     86.240  0.2144    92.948  247.82
  47   0.5359     85.430  0.1980    93.524  253.18
  48   0.5657     85.850  0.1950    93.670  258.52
  49   0.5347     85.540  0.1948    93.676  263.88
  50   0.5160     86.510  0.1859    93.972  269.21
  51   0.5086     86.450  0.1694    94.358  274.56
  52   0.5023     86.350  0.1797    94.132  279.93
  53   0.5209     85.860  0.1610    94.720  285.33
  54   0.5428     86.340  0.1633    94.708  290.64
  55   0.5242     86.390  0.1595    94.868  295.99
  56   0.5397     86.350  0.1527    95.070  301.33
  57   0.5158     86.750  0.1577    94.820  306.66
  58   0.5021     87.050  0.1432    95.336  312.01
  59   0.5955     86.240  0.1543    94.986  317.35
  60   0.5378     86.600  0.1404    95.424  322.76
  61   0.5332     86.450  0.1369    95.538  328.09
  62   0.5538     86.160  0.1320    95.710  333.43
  63   0.5162     86.660  0.1244    95.904  338.78
  64   0.5378     86.900  0.1342    95.682  344.10
  65   0.5022     86.420  0.1354    95.536  349.47
  66   0.5348     87.000  0.1229    96.036  354.88
  67   0.5482     86.320  0.1266    95.916  360.24
  68   0.5506     86.640  0.1271    95.888  365.57
  69   0.5772     86.860  0.1239    95.942  370.94
  70   0.5861     86.650  0.1174    96.234  376.29
  71   0.5279     86.770  0.1314    95.754  381.63
  72   0.5835     86.600  0.1137    96.368  387.07
  73   0.5632     86.910  0.1106    96.314  392.42
  74   0.5555     86.950  0.1001    96.742  397.74
  75   0.5698     86.310  0.1109    96.390  403.07
  76   0.5963     86.770  0.1013    96.730  408.43
  77   0.6206     86.130  0.1066    96.562  413.75
  78   0.5393     87.080  0.1038    96.704  419.19
  79   0.5496     87.450  0.0891    97.054  424.52
  80   0.5431     87.520  0.0970    96.878  429.85
  81   0.6108     86.790  0.0964    96.938  435.24
  82   0.6102     87.100  0.0988    96.786  440.57
  83   0.5686     87.050  0.0903    97.014  445.92
  84   0.5580     86.830  0.0928    97.030  451.33
  85   0.5837     87.060  0.0921    97.044  456.68
  86   0.5557     86.700  0.0895    97.198  462.02
  87   0.5828     86.730  0.0957    96.872  467.35
  88   0.6072     86.750  0.0901    97.068  472.70
  89   0.5817     87.230  0.0909    97.064  478.03
  90   0.5834     87.130  0.0809    97.424  483.35
