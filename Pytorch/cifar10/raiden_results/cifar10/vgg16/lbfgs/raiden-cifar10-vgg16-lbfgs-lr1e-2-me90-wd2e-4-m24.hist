Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 9793988096 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3032      9.850  6.1807     9.954  10.97
   2   2.3032      9.850  6.1806     9.952  20.17
   3   2.3032      9.850  6.1806     9.810  29.40
   4   2.3032      9.850  6.1806     9.962  38.73
   5   2.3032      9.850  6.1805     9.870  47.96
   6   2.3032      9.850  6.1806    10.184  57.20
   7   2.3032      9.850  6.1804    10.024  66.43
   8   2.3032      9.850  6.1804    10.188  75.72
   9   2.3032      9.850  6.1805     9.802  84.96
  10   2.3032      9.850  6.1806    10.010  94.25
  11   2.3032      9.850  6.1805     9.962  103.41
  12   2.3032      9.850  6.1806     9.942  112.73
  13   2.3032      9.850  6.1807     9.990  121.93
  14   2.3032      9.850  6.1807    10.066  131.14
  15   2.3032      9.850  6.1806     9.984  140.49
  16   2.3032      9.850  6.1806    10.024  149.74
  17   2.3032      9.850  6.1806    10.046  158.92
  18   2.3032      9.850  6.1805    10.034  168.18
  19   2.3032      9.850  6.1804    10.144  177.49
  20   2.3032      9.850  6.1804    10.142  186.73
  21   2.3032      9.850  6.1805     9.962  195.97
  22   2.3032      9.850  6.1804    10.092  205.25
  23   2.3032      9.850  6.1803    10.166  214.50
  24   2.3032      9.850  6.1805     9.868  223.68
  25   2.3032      9.850  6.1805     9.988  232.88
  26   2.3032      9.850  6.1806     9.902  242.19
  27   2.3032      9.850  6.1806     9.984  251.42
  28   2.3032      9.850  6.1804     9.856  260.68
  29   2.3032      9.850  6.1806    10.118  269.91
  30   2.3032      9.850  6.1806     9.956  279.24
  31   2.3032      9.850  6.1806    10.086  288.50
  32   2.3032      9.850  6.1804    10.120  297.72
  33   2.3032      9.850  6.1807     9.974  307.10
  34   2.3032      9.850  6.1806     9.908  316.31
  35   2.3032      9.850  6.1804    10.064  325.56
  36   2.3032      9.850  6.1806     9.834  334.81
  37   2.3032      9.850  6.1809     9.908  344.13
  38   2.3032      9.850  6.1804    10.064  353.33
  39   2.3032      9.850  6.1804     9.986  362.56
  40   2.3032      9.850  6.1808    10.110  371.77
  41   2.3032      9.850  6.1806    10.030  381.09
  42   2.3032      9.850  6.1806     9.894  390.37
  43   2.3032      9.850  6.1807     9.950  399.61
  44   2.3032      9.850  6.1805     9.966  408.96
  45   2.3032      9.860  6.1806     9.974  418.21
  46   2.3032      9.860  6.1805     9.856  427.40
  47   2.3032      9.860  6.1805    10.016  436.62
  48   2.3032      9.860  6.1807     9.844  445.91
  49   2.3032      9.860  6.1804    10.266  455.14
  50   2.3032      9.860  6.1806     9.866  464.42
  51   2.3032      9.860  6.1804    10.226  473.68
  52   2.3032      9.860  6.1806     9.898  482.99
  53   2.3032      9.860  6.1805    10.038  492.21
  54   2.3032      9.860  6.1806    10.094  501.42
  55   2.3032      9.860  6.1807     9.736  510.66
  56   2.3032      9.860  6.1806     9.674  519.97
  57   2.3032      9.860  6.1806    10.000  529.22
  58   2.3032      9.860  6.1806     9.996  538.45
  59   2.3032      9.860  6.1806    10.062  547.76
  60   2.3032      9.860  6.1804     9.966  557.00
  61   2.3032      9.860  6.1806    10.006  566.26
  62   2.3032      9.850  6.1806     9.792  575.48
  63   2.3032      9.850  6.1807     9.844  584.81
  64   2.3032      9.850  6.1807    10.074  594.00
  65   2.3032      9.850  6.1806     9.942  603.27
  66   2.3032      9.850  6.1803    10.168  612.59
  67   2.3032      9.850  6.1807    10.004  621.84
  68   2.3032      9.850  6.1805     9.960  631.12
  69   2.3032      9.850  6.1806     9.956  640.36
  70   2.3032      9.850  6.1806    10.050  649.70
  71   2.3032      9.850  6.1805    10.090  658.93
  72   2.3032      9.850  6.1806    10.152  668.13
  73   2.3032      9.850  6.1804    10.132  677.36
  74   2.3032      9.850  6.1806    10.128  686.66
  75   2.3032      9.850  6.1806     9.902  695.88
  76   2.3032      9.850  6.1808     9.994  705.13
  77   2.3032      9.850  6.1807    10.036  714.45
  78   2.3032      9.850  6.1806    10.204  723.68
  79   2.3032      9.850  6.1807     9.898  732.94
  80   2.3032      9.850  6.1806     9.954  742.19
  81   2.3032      9.850  6.1808     9.862  751.41
  82   2.3032      9.850  6.1806     9.878  760.66
  83   2.3032      9.850  6.1804    10.086  769.88
  84   2.3032      9.850  6.1806     9.942  779.18
  85   2.3032      9.850  6.1805     9.894  788.51
  86   2.3032      9.850  6.1806     9.896  797.77
  87   2.3032      9.850  6.1804    10.104  807.04
  88   2.3032      9.850  6.1805    10.112  816.30
  89   2.3032      9.850  6.1806     9.960  825.65
  90   2.3032      9.850  6.1805     9.838  834.88
