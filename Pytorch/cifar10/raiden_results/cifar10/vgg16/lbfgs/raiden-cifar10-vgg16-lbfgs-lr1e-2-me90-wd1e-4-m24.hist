Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 9791759872 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3029     10.070  4.2421    10.320  11.05
   2   2.3029     10.070  4.2425    10.064  20.37
   3   2.3029     10.070  4.2425     9.962  29.67
   4   2.3029     10.070  4.2424    10.002  38.90
   5   2.3029     10.070  4.2423    10.206  48.14
   6   2.3029     10.070  4.2423    10.330  57.51
   7   2.3029     10.070  4.2426     9.984  66.75
   8   2.3029     10.070  4.2425     9.694  75.97
   9   2.3029     10.070  4.2425    10.032  85.18
  10   2.3029     10.070  4.2424    10.150  94.59
  11   2.3029     10.070  4.2423    10.102  103.83
  12   2.3029     10.070  4.2424    10.030  113.01
  13   2.3029     10.070  4.2427     9.844  122.25
  14   2.3029     10.070  4.2423    10.062  131.44
  15   2.3029     10.070  4.2423     9.912  140.69
  16   2.3029     10.070  4.2423    10.090  149.92
  17   2.3029     10.070  4.2424    10.152  159.21
  18   2.3029     10.070  4.2426     9.984  168.45
  19   2.3029     10.070  4.2425    10.300  177.72
  20   2.3029     10.070  4.2426     9.960  186.96
  21   2.3029     10.070  4.2422    10.128  196.33
  22   2.3029     10.070  4.2423     9.962  205.59
  23   2.3029     10.070  4.2426     9.806  214.82
  24   2.3029     10.070  4.2423    10.232  224.13
  25   2.3029     10.070  4.2423     9.830  233.38
  26   2.3029     10.070  4.2424     9.950  242.58
  27   2.3029     10.070  4.2423    10.074  251.85
  28   2.3029     10.070  4.2423    10.128  261.17
  29   2.3029     10.070  4.2424    10.072  270.44
  30   2.3029     10.070  4.2426    10.034  279.64
  31   2.3029     10.070  4.2422    10.102  288.90
  32   2.3029     10.070  4.2425     9.740  298.25
  33   2.3029     10.070  4.2423    10.100  307.48
  34   2.3029     10.070  4.2424    10.006  316.72
  35   2.3029     10.070  4.2424    10.006  326.08
  36   2.3029     10.070  4.2425    10.146  335.35
  37   2.3029     10.070  4.2426    10.162  344.58
  38   2.3029     10.070  4.2425    10.094  353.78
  39   2.3029     10.070  4.2424     9.818  363.06
  40   2.3029     10.070  4.2426    10.070  372.27
  41   2.3029     10.070  4.2425     9.972  381.54
  42   2.3029     10.070  4.2422    10.144  390.77
  43   2.3029     10.070  4.2425    10.088  400.13
  44   2.3029     10.070  4.2423    10.018  409.41
  45   2.3029     10.070  4.2424    10.074  418.68
  46   2.3029     10.070  4.2425    10.022  427.90
  47   2.3029     10.070  4.2423    10.040  437.24
  48   2.3029     10.070  4.2425     9.878  446.44
  49   2.3029     10.070  4.2426     9.916  455.67
  50   2.3029     10.070  4.2424    10.324  464.90
  51   2.3029     10.070  4.2424    10.150  474.22
  52   2.3029     10.070  4.2423    10.092  483.50
  53   2.3029     10.070  4.2426     9.926  492.74
  54   2.3029     10.070  4.2425    10.122  502.05
  55   2.3029     10.070  4.2425     9.918  511.25
  56   2.3029     10.070  4.2423    10.016  520.50
  57   2.3029     10.070  4.2427     9.820  529.72
  58   2.3029     10.070  4.2424     9.874  539.05
  59   2.3029     10.070  4.2424     9.802  548.26
  60   2.3029     10.070  4.2423    10.126  557.54
  61   2.3029     10.070  4.2425    10.110  566.83
  62   2.3029     10.070  4.2426     9.990  576.08
  63   2.3029     10.070  4.2423    10.144  585.33
  64   2.3029     10.070  4.2426    10.062  594.58
  65   2.3029     10.070  4.2423     9.926  603.91
  66   2.3029     10.070  4.2424    10.090  613.14
  67   2.3029     10.070  4.2424    10.110  622.36
  68   2.3029     10.070  4.2423     9.850  631.61
  69   2.3029     10.070  4.2424    10.124  640.89
  70   2.3029     10.070  4.2422    10.096  650.13
  71   2.3029     10.070  4.2423     9.996  659.41
  72   2.3029     10.070  4.2423     9.832  668.62
  73   2.3029     10.070  4.2426     9.998  677.94
  74   2.3029     10.070  4.2426    10.016  687.20
  75   2.3029     10.070  4.2424     9.892  696.49
  76   2.3029     10.070  4.2425    10.032  705.72
  77   2.3029     10.070  4.2423     9.958  715.01
  78   2.3029     10.070  4.2423    10.178  724.24
  79   2.3029     10.070  4.2428     9.778  733.54
  80   2.3029     10.070  4.2426     9.770  742.84
  81   2.3029     10.070  4.2425    10.232  752.04
  82   2.3029     10.070  4.2425    10.200  761.30
  83   2.3029     10.070  4.2426    10.060  770.55
  84   2.3029     10.070  4.2427     9.924  779.86
  85   2.3029     10.070  4.2428     9.730  789.10
  86   2.3029     10.070  4.2425     9.930  798.31
  87   2.3029     10.070  4.2424     9.994  807.59
  88   2.3029     10.070  4.2423    10.150  816.90
  89   2.3029     10.070  4.2424    10.186  826.16
  90   2.3029     10.070  4.2427     9.878  835.37
