Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7646602752 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3029      8.120  4.2415    10.148  10.30
   2   2.3029      8.120  4.2414    10.204  18.92
   3   2.3029      8.120  4.2415     9.856  27.51
   4   2.3029      8.120  4.2416     9.866  36.05
   5   2.3029      8.120  4.2416     9.904  44.64
   6   2.3029      8.120  4.2414    10.284  53.33
   7   2.3029      8.120  4.2415    10.148  61.91
   8   2.3029      8.120  4.2415    10.166  70.43
   9   2.3029      8.120  4.2414    10.092  78.99
  10   2.3029      8.120  4.2417     9.784  87.58
  11   2.3029      8.120  4.2415    10.150  96.11
  12   2.3029      8.120  4.2413    10.204  104.65
  13   2.3029      8.120  4.2412    10.048  113.16
  14   2.3029      8.120  4.2416    10.126  121.78
  15   2.3029      8.120  4.2415     9.984  130.34
  16   2.3029      8.120  4.2416     9.890  138.89
  17   2.3029      8.120  4.2413    10.132  147.45
  18   2.3029      8.120  4.2414    10.140  156.02
  19   2.3029      8.120  4.2413    10.176  164.67
  20   2.3029      8.120  4.2415    10.070  173.22
  21   2.3029      8.120  4.2416     9.910  181.72
  22   2.3029      8.120  4.2412    10.188  190.30
  23   2.3029      8.120  4.2415     9.962  198.94
  24   2.3029      8.120  4.2415    10.036  207.52
  25   2.3029      8.120  4.2412    10.148  216.03
  26   2.3029      8.120  4.2415     9.910  224.62
  27   2.3029      8.120  4.2415    10.098  233.23
  28   2.3029      8.120  4.2415    10.206  241.82
  29   2.3029      8.120  4.2415    10.092  250.32
  30   2.3029      8.120  4.2413    10.078  258.91
  31   2.3029      8.120  4.2416     9.950  267.52
  32   2.3029      8.120  4.2415    10.114  276.09
  33   2.3029      8.120  4.2414    10.088  284.61
  34   2.3029      8.120  4.2416     9.900  293.13
  35   2.3029      8.120  4.2413    10.186  301.70
  36   2.3029      8.120  4.2414     9.992  310.27
  37   2.3029      8.120  4.2419     9.826  318.80
  38   2.3029      8.120  4.2417     9.940  327.36
  39   2.3029      8.120  4.2417     9.864  336.07
  40   2.3029      8.120  4.2412    10.106  344.58
  41   2.3029      8.120  4.2415     9.874  353.08
  42   2.3029      8.120  4.2416     9.878  361.68
  43   2.3029      8.120  4.2415     9.912  370.26
  44   2.3029      8.120  4.2414    10.194  378.82
  45   2.3029      8.120  4.2417     9.924  387.47
  46   2.3029      8.120  4.2416     9.894  396.11
  47   2.3029      8.120  4.2415    10.052  404.66
  48   2.3029      8.120  4.2418     9.978  413.16
  49   2.3029      8.120  4.2413    10.122  421.70
  50   2.3029      8.120  4.2415    10.122  430.23
  51   2.3029      8.120  4.2415    10.128  438.92
  52   2.3029      8.120  4.2415    10.028  447.45
  53   2.3029      8.120  4.2414    10.092  456.06
  54   2.3029      8.120  4.2416     9.902  464.57
  55   2.3029      8.120  4.2418     9.898  473.26
  56   2.3029      8.120  4.2413    10.180  481.84
  57   2.3029      8.120  4.2414    10.222  490.38
  58   2.3029      8.120  4.2416     9.980  498.93
  59   2.3029      8.120  4.2416     9.840  507.56
  60   2.3029      8.120  4.2413    10.102  516.12
  61   2.3029      8.120  4.2414     9.934  524.64
  62   2.3029      8.120  4.2415     9.972  533.23
  63   2.3029      8.120  4.2415    10.138  541.88
  64   2.3029      8.120  4.2414    10.186  550.42
  65   2.3029      8.120  4.2414    10.098  558.95
  66   2.3029      8.120  4.2415    10.082  567.54
  67   2.3029      8.120  4.2415    10.144  576.15
  68   2.3029      8.120  4.2416     9.924  584.70
  69   2.3029      8.120  4.2415     9.832  593.19
  70   2.3029      8.120  4.2416     9.752  601.72
  71   2.3029      8.120  4.2415     9.978  610.31
  72   2.3029      8.120  4.2415     9.936  618.82
  73   2.3029      8.120  4.2413     9.974  627.33
  74   2.3029      8.120  4.2415    10.188  635.90
  75   2.3029      8.120  4.2416     9.808  644.44
  76   2.3029      8.120  4.2418     9.934  653.05
  77   2.3029      8.120  4.2416    10.052  661.59
  78   2.3029      8.120  4.2412    10.114  670.16
  79   2.3029      8.120  4.2415     9.868  678.75
  80   2.3029      8.120  4.2414    10.128  687.32
  81   2.3029      8.120  4.2416     9.812  695.90
  82   2.3029      8.120  4.2415    10.138  704.48
  83   2.3029      8.120  4.2417     9.950  713.14
  84   2.3029      8.120  4.2418     9.826  721.71
  85   2.3029      8.120  4.2417     9.984  730.27
