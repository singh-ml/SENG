Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7646602752 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3032      9.990  6.1822    10.310  10.37
   2   2.3032      9.990  6.1825     9.948  19.02
   3   2.3032      9.990  6.1825     9.968  27.62
   4   2.3032      9.990  6.1825     9.888  36.26
   5   2.3032      9.990  6.1822    10.130  44.93
   6   2.3032      9.990  6.1823     9.994  53.52
   7   2.3032      9.990  6.1825    10.084  62.09
   8   2.3032      9.990  6.1826     9.862  70.81
   9   2.3032      9.990  6.1822    10.160  79.45
  10   2.3032      9.990  6.1824    10.106  88.07
  11   2.3032      9.990  6.1823    10.200  96.73
  12   2.3032      9.990  6.1824     9.986  105.39
  13   2.3032      9.990  6.1826    10.122  114.00
  14   2.3032      9.990  6.1829     9.920  122.66
  15   2.3032      9.990  6.1825    10.050  131.30
  16   2.3032      9.990  6.1824     9.972  139.94
  17   2.3032      9.990  6.1823     9.900  148.56
  18   2.3032      9.990  6.1824    10.032  157.17
  19   2.3032      9.990  6.1823    10.294  165.79
  20   2.3032      9.990  6.1821    10.050  174.38
  21   2.3032      9.990  6.1826     9.846  182.97
  22   2.3032      9.990  6.1825    10.002  191.57
  23   2.3032      9.990  6.1824     9.906  200.26
  24   2.3032      9.990  6.1823     9.864  208.87
  25   2.3032      9.990  6.1823    10.174  217.47
  26   2.3032      9.990  6.1822    10.208  226.08
  27   2.3032      9.990  6.1824     9.896  234.69
  28   2.3032      9.990  6.1825     9.874  243.43
  29   2.3032      9.990  6.1827     9.922  252.05
  30   2.3032      9.990  6.1826     9.994  260.65
  31   2.3032      9.990  6.1825     9.978  269.25
  32   2.3032      9.990  6.1824    10.126  277.98
  33   2.3032      9.990  6.1822    10.190  286.57
  34   2.3032      9.990  6.1824     9.904  295.19
  35   2.3032      9.990  6.1826    10.144  303.83
  36   2.3032      9.990  6.1825     9.872  312.55
  37   2.3032      9.990  6.1824    10.116  321.16
  38   2.3032      9.990  6.1824    10.056  329.86
  39   2.3032      9.990  6.1824    10.130  338.54
  40   2.3032      9.990  6.1824    10.012  347.15
  41   2.3032      9.990  6.1826     9.916  355.75
  42   2.3032      9.990  6.1827     9.800  364.35
  43   2.3032      9.990  6.1823     9.970  372.91
  44   2.3032      9.990  6.1825     9.998  381.58
  45   2.3032      9.990  6.1819    10.276  390.14
  46   2.3032      9.990  6.1824     9.992  398.78
  47   2.3032      9.990  6.1823    10.032  407.50
  48   2.3032      9.990  6.1825    10.100  416.12
  49   2.3032      9.990  6.1824    10.070  424.74
  50   2.3032      9.990  6.1825    10.138  433.35
  51   2.3032      9.990  6.1822    10.252  442.06
  52   2.3032      9.990  6.1824    10.358  450.68
  53   2.3032      9.990  6.1825    10.028  459.32
  54   2.3032      9.990  6.1825     9.798  467.92
  55   2.3032      9.990  6.1824     9.844  476.70
  56   2.3032      9.990  6.1825     9.978  485.32
  57   2.3032      9.990  6.1824     9.984  493.96
  58   2.3032      9.990  6.1822    10.166  502.53
  59   2.3032      9.990  6.1823    10.078  511.16
  60   2.3032      9.990  6.1822    10.066  519.75
  61   2.3032      9.990  6.1824     9.892  528.33
  62   2.3032      9.990  6.1823    10.042  536.98
  63   2.3032      9.990  6.1826     9.982  545.69
  64   2.3032      9.990  6.1825    10.004  554.27
  65   2.3032      9.990  6.1822    10.116  562.88
  66   2.3032      9.990  6.1823    10.016  571.55
  67   2.3032      9.990  6.1823    10.194  580.14
  68   2.3032      9.990  6.1825    10.058  588.86
  69   2.3032      9.990  6.1822    10.370  597.42
  70   2.3032      9.990  6.1823    10.104  606.00
  71   2.3032      9.990  6.1822    10.212  614.67
  72   2.3032      9.990  6.1827     9.806  623.31
  73   2.3032      9.990  6.1823    10.016  631.95
  74   2.3032      9.990  6.1821    10.110  640.53
  75   2.3032      9.990  6.1827     9.974  649.25
  76   2.3032      9.990  6.1825     9.988  657.88
  77   2.3032      9.990  6.1824     9.968  666.49
  78   2.3032      9.990  6.1826     9.974  675.10
  79   2.3032      9.990  6.1822    10.012  683.78
  80   2.3032      9.990  6.1825    10.250  692.40
  81   2.3032      9.990  6.1826     9.758  701.05
  82   2.3032      9.990  6.1824     9.928  709.63
  83   2.3032      9.990  6.1824    10.016  718.36
  84   2.3032      9.990  6.1825     9.954  726.99
  85   2.3032      9.990  6.1824     9.980  735.63
