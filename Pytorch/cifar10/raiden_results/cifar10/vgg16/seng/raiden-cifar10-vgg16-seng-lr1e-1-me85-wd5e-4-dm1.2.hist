Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2264     14.690  2.2803    12.026  7.65
   2   2.3034     10.000  2.2986    10.594  13.45
   3   2.1248     17.550  2.2919    11.226  19.32
   4   1.9518     20.710  2.0472    18.990  25.11
   5   1.7845     30.300  1.8681    24.904  30.92
   6   1.6376     38.980  1.6916    34.018  36.74
   7   1.4233     47.100  1.5326    40.648  42.57
   8   1.1915     57.550  1.3582    50.406  48.39
   9   1.0040     65.530  1.1504    59.720  54.26
  10   0.9753     67.610  1.0410    64.758  60.08
  11   0.8486     72.030  0.9586    67.986  65.88
  12   0.8354     72.760  0.9096    70.620  71.69
  13   0.7431     76.620  0.7920    74.678  77.50
  14   0.7825     75.200  0.7565    75.554  83.30
  15   0.6518     79.550  0.7151    77.412  89.22
  16   0.6845     78.420  0.6760    78.346  95.01
  17   0.6233     80.190  0.6263    80.210  100.82
  18   0.6593     79.210  0.6014    81.228  106.65
  19   0.6268     80.550  0.5586    82.290  112.45
  20   0.6528     78.950  0.5555    82.506  118.30
  21   0.5948     81.420  0.5298    83.226  124.19
  22   0.5707     82.090  0.5124    83.826  130.01
  23   0.5486     83.300  0.4983    84.262  135.81
  24   0.5041     84.210  0.4701    85.206  141.63
  25   0.5259     82.810  0.4687    85.080  147.46
  26   0.6158     82.190  0.4398    86.146  153.27
  27   0.4853     84.830  0.4295    86.354  159.14
  28   0.4758     85.270  0.4145    86.962  164.93
  29   0.6902     81.310  0.3959    87.246  170.74
  30   0.4821     85.430  0.4109    86.880  176.55
  31   0.5221     84.470  0.3761    88.010  182.35
  32   0.4309     86.200  0.3644    88.408  188.18
  33   0.4559     86.050  0.3617    88.552  194.05
  34   0.4676     85.320  0.3414    89.196  199.86
  35   0.4727     85.020  0.3327    89.252  205.67
  36   0.4262     87.360  0.3118    90.050  211.47
  37   0.4224     86.990  0.3087    90.124  217.28
  38   0.4087     87.240  0.2936    90.580  223.16
  39   0.4113     86.970  0.2924    90.664  228.99
  40   0.4279     87.280  0.2739    91.274  234.82
  41   0.3863     87.710  0.2557    91.838  240.65
  42   0.4611     86.840  0.2415    92.218  246.49
  43   0.3833     88.800  0.2349    92.326  252.29
  44   0.4465     87.180  0.2283    92.540  258.20
  45   0.3901     87.820  0.2151    93.094  264.01
  46   0.3669     88.470  0.2047    93.256  269.80
  47   0.3693     88.830  0.2057    93.440  275.61
  48   0.3830     88.390  0.1975    93.628  281.42
  49   0.3795     88.780  0.1832    93.934  287.25
  50   0.3812     89.000  0.1749    94.288  292.99
  51   0.3824     89.240  0.1603    94.682  298.81
  52   0.3602     89.260  0.1491    95.084  304.62
  53   0.3688     88.420  0.1558    94.876  310.41
  54   0.3735     89.400  0.1455    95.152  316.24
  55   0.3612     89.690  0.1267    95.824  322.13
  56   0.3811     89.550  0.1200    96.036  327.93
  57   0.3877     89.810  0.1097    96.400  333.76
  58   0.3575     90.050  0.1013    96.758  339.59
  59   0.3829     90.140  0.0950    96.952  345.38
  60   0.3704     90.020  0.0913    97.068  351.19
  61   0.3400     90.380  0.0790    97.348  357.07
  62   0.3702     90.410  0.0683    97.708  362.87
  63   0.3620     90.460  0.0637    97.828  368.69
  64   0.3623     90.280  0.0631    97.920  374.53
  65   0.3608     90.790  0.0563    98.140  380.35
  66   0.3754     90.780  0.0458    98.518  386.27
  67   0.3605     91.060  0.0371    98.816  392.09
  68   0.3749     90.670  0.0325    98.936  397.87
  69   0.3863     91.070  0.0255    99.144  403.68
  70   0.4028     90.910  0.0263    99.146  409.48
  71   0.3894     91.200  0.0230    99.292  415.29
  72   0.3741     91.380  0.0179    99.444  421.16
  73   0.3707     91.590  0.0136    99.586  426.96
  74   0.3768     91.450  0.0133    99.602  432.77
  75   0.3799     91.440  0.0122    99.624  438.58
  76   0.3817     91.450  0.0101    99.738  444.40
  77   0.3819     91.550  0.0090    99.746  450.26
  78   0.3773     91.710  0.0089    99.754  456.10
  79   0.3800     91.650  0.0062    99.846  461.91
  80   0.3792     91.810  0.0065    99.832  467.71
  81   0.3855     91.570  0.0062    99.858  473.50
  82   0.3770     91.670  0.0066    99.838  479.31
  83   0.3812     91.770  0.0050    99.878  485.17
  84   0.3809     91.720  0.0053    99.864  490.97
  85   0.3810     91.870  0.0056    99.876  496.77
