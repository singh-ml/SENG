Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8569     30.650  2.1545    18.380  7.83
   2   1.5554     40.990  1.8158    30.558  13.69
   3   1.3438     49.600  1.5067    42.792  19.52
   4   1.1195     59.690  1.2896    52.332  25.36
   5   1.0085     64.130  1.0925    60.436  31.17
   6   0.8900     68.200  0.9455    65.870  37.02
   7   0.8458     70.200  0.8436    70.230  42.92
   8   0.6883     75.910  0.7534    73.622  48.74
   9   0.7124     75.970  0.6911    75.838  54.57
  10   0.6625     77.170  0.6374    77.914  60.42
  11   0.5807     79.710  0.6008    79.196  66.23
  12   0.5626     81.310  0.5717    80.240  72.07
  13   0.5609     81.210  0.5230    82.056  77.90
  14   0.5296     82.220  0.5008    82.746  83.75
  15   0.5363     81.860  0.4707    83.794  89.62
  16   0.5502     82.330  0.4452    84.730  95.44
  17   0.4968     83.610  0.4208    85.450  101.27
  18   0.4685     84.690  0.4018    86.334  107.16
  19   0.4664     84.430  0.3867    86.704  112.97
  20   0.4758     84.600  0.3655    87.542  118.79
  21   0.4639     84.240  0.3544    87.792  124.61
  22   0.4498     85.060  0.3389    88.422  130.45
  23   0.4565     85.850  0.3205    89.090  136.37
  24   0.4584     85.390  0.3166    88.950  142.19
  25   0.4476     85.670  0.2965    89.896  148.03
  26   0.4588     85.530  0.2856    90.100  153.84
  27   0.4336     85.930  0.2666    90.892  159.65
  28   0.4544     85.580  0.2548    91.282  165.48
  29   0.4069     86.830  0.2459    91.470  171.30
  30   0.4357     86.420  0.2292    92.116  177.22
  31   0.4490     86.250  0.2278    92.202  183.05
  32   0.4727     86.280  0.2185    92.456  188.90
  33   0.4439     86.360  0.2083    92.842  194.74
  34   0.4385     87.040  0.1958    93.264  200.57
  35   0.4158     87.500  0.1913    93.402  206.40
  36   0.4268     87.170  0.1829    93.636  212.32
  37   0.4271     87.510  0.1725    94.164  218.14
  38   0.4497     87.280  0.1681    94.146  223.98
  39   0.4439     86.960  0.1584    94.564  229.79
  40   0.4430     87.640  0.1523    94.704  235.62
  41   0.4444     87.580  0.1392    95.208  241.44
  42   0.4781     87.360  0.1389    95.112  247.35
  43   0.4621     87.650  0.1260    95.614  253.18
  44   0.4674     87.650  0.1158    96.046  259.03
  45   0.4505     88.290  0.1184    95.902  264.86
  46   0.4635     88.060  0.1102    96.218  270.68
  47   0.4565     87.890  0.1049    96.326  276.58
  48   0.4627     87.720  0.0993    96.608  282.39
  49   0.4832     88.000  0.0905    96.866  288.21
  50   0.4852     87.990  0.0875    96.898  293.98
  51   0.4714     88.270  0.0847    97.010  299.83
  52   0.5006     88.060  0.0759    97.402  305.66
  53   0.4827     88.310  0.0763    97.384  311.58
  54   0.5056     88.140  0.0770    97.290  317.42
  55   0.5010     88.220  0.0652    97.714  323.25
  56   0.5030     88.580  0.0620    97.822  329.06
  57   0.5101     88.680  0.0572    97.944  334.89
  58   0.5239     88.440  0.0533    98.182  340.82
  59   0.5291     88.710  0.0519    98.178  346.66
  60   0.5382     88.860  0.0473    98.380  352.48
  61   0.5438     89.290  0.0433    98.482  358.28
  62   0.5718     88.890  0.0439    98.450  364.10
  63   0.5629     88.710  0.0399    98.596  369.91
  64   0.5841     88.620  0.0355    98.764  375.79
  65   0.5637     88.970  0.0344    98.794  381.62
  66   0.6070     89.070  0.0295    98.984  387.47
  67   0.5804     89.040  0.0305    98.944  393.29
  68   0.5837     89.030  0.0302    98.950  399.10
  69   0.5730     88.840  0.0298    99.000  404.94
  70   0.5806     89.180  0.0269    99.052  410.82
  71   0.5913     88.880  0.0242    99.182  416.62
  72   0.6029     88.910  0.0236    99.198  422.47
  73   0.6150     88.950  0.0235    99.186  428.30
  74   0.6195     88.810  0.0198    99.316  434.12
  75   0.6327     88.810  0.0178    99.432  439.94
  76   0.6286     89.190  0.0180    99.362  445.81
  77   0.6547     89.190  0.0173    99.386  451.64
  78   0.6328     89.330  0.0168    99.438  457.48
  79   0.6519     89.280  0.0147    99.512  463.30
  80   0.6497     89.250  0.0148    99.484  469.14
  81   0.6454     89.360  0.0148    99.492  474.95
  82   0.6526     89.310  0.0139    99.548  480.83
  83   0.6530     89.460  0.0139    99.528  486.66
  84   0.6749     89.470  0.0130    99.532  492.47
  85   0.6825     89.200  0.0121    99.590  498.28
