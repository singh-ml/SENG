Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8537     29.480  2.1488    17.824  7.68
   2   1.5449     40.860  1.7427    32.802  13.49
   3   1.3756     48.600  1.5028    43.178  19.37
   4   1.1449     58.680  1.3007    51.832  25.20
   5   1.0492     62.740  1.1507    57.918  31.00
   6   0.9098     67.730  1.0106    63.386  36.83
   7   0.8813     68.610  0.9164    67.190  42.62
   8   0.8124     70.710  0.8467    69.748  48.43
   9   0.7660     73.940  0.7777    72.410  54.29
  10   0.7359     74.840  0.7137    74.868  60.10
  11   0.6729     77.050  0.6784    76.032  65.90
  12   0.6304     78.900  0.6343    77.808  71.69
  13   0.6281     78.440  0.6022    78.910  77.52
  14   0.6460     78.780  0.5763    79.946  83.40
  15   0.6154     79.720  0.5522    80.830  89.20
  16   0.5479     81.430  0.5236    81.850  95.00
  17   0.5545     81.630  0.5057    82.574  100.81
  18   0.5028     83.110  0.4807    83.372  106.62
  19   0.5119     82.560  0.4612    84.154  112.44
  20   0.5414     82.370  0.4431    84.640  118.29
  21   0.5041     83.700  0.4256    85.314  124.09
  22   0.4781     84.100  0.4152    85.754  129.89
  23   0.4905     83.870  0.3963    86.514  135.69
  24   0.4814     84.330  0.3845    86.892  141.51
  25   0.4675     84.700  0.3697    87.238  147.39
  26   0.4567     84.840  0.3531    87.764  153.34
  27   0.4533     85.110  0.3414    88.248  159.15
  28   0.4550     85.240  0.3320    88.634  164.96
  29   0.4268     85.990  0.3187    89.048  170.75
  30   0.4313     85.920  0.3133    89.256  176.55
  31   0.4544     85.380  0.3033    89.484  182.46
  32   0.4485     85.820  0.2841    90.202  188.26
  33   0.4505     85.570  0.2755    90.432  194.07
  34   0.4629     84.930  0.2639    90.774  199.88
  35   0.4382     86.890  0.2597    91.098  205.67
  36   0.4404     85.980  0.2488    91.432  211.50
  37   0.4675     86.020  0.2364    91.952  217.38
  38   0.4334     86.700  0.2318    92.056  223.19
  39   0.4330     86.920  0.2235    92.394  229.00
  40   0.4489     86.560  0.2195    92.434  234.80
  41   0.4391     87.060  0.2082    92.810  240.64
  42   0.4544     87.120  0.2040    92.876  246.44
  43   0.4396     87.060  0.1953    93.264  252.31
  44   0.4851     86.640  0.1854    93.444  258.10
  45   0.4404     87.280  0.1805    93.734  263.90
  46   0.4618     86.840  0.1788    93.700  269.69
  47   0.4667     86.720  0.1669    94.314  275.50
  48   0.4692     87.380  0.1591    94.486  281.29
  49   0.4663     87.070  0.1577    94.512  287.16
  50   0.4446     87.910  0.1499    94.788  292.93
  51   0.4541     87.720  0.1422    95.010  298.74
  52   0.4737     87.240  0.1383    95.320  304.56
  53   0.4446     87.560  0.1358    95.228  310.40
  54   0.4619     88.350  0.1268    95.622  316.18
  55   0.4754     87.810  0.1210    95.812  322.00
  56   0.4637     87.770  0.1179    95.930  327.83
  57   0.4817     86.800  0.1169    95.894  333.62
  58   0.4537     88.340  0.1112    96.128  339.43
  59   0.4974     87.500  0.1072    96.222  345.24
  60   0.4905     88.040  0.0986    96.486  351.10
  61   0.4795     87.940  0.0944    96.782  356.89
  62   0.4779     88.130  0.0921    96.702  362.68
  63   0.4938     88.040  0.0940    96.726  368.48
  64   0.5241     87.670  0.0880    96.884  374.31
  65   0.5122     87.930  0.0815    97.108  380.15
  66   0.4839     88.100  0.0778    97.270  386.04
  67   0.5004     88.070  0.0738    97.382  391.83
  68   0.5162     88.710  0.0719    97.522  397.62
  69   0.5115     87.870  0.0689    97.664  403.43
  70   0.5179     88.340  0.0696    97.604  409.22
  71   0.5067     88.510  0.0628    97.840  415.04
  72   0.5444     88.350  0.0621    97.868  420.93
  73   0.5375     88.480  0.0597    98.000  426.74
  74   0.5419     88.450  0.0550    98.174  432.57
  75   0.5490     87.970  0.0569    98.032  438.36
  76   0.5512     88.180  0.0521    98.224  444.18
  77   0.5568     88.290  0.0526    98.160  450.06
  78   0.5535     88.610  0.0508    98.264  455.90
  79   0.5542     88.200  0.0499    98.340  461.70
  80   0.5560     88.360  0.0503    98.234  467.52
  81   0.5780     88.360  0.0440    98.468  473.34
  82   0.5559     88.590  0.0457    98.492  479.20
  83   0.5812     88.250  0.0415    98.528  485.02
  84   0.5786     88.250  0.0408    98.650  490.85
  85   0.5712     88.570  0.0453    98.408  496.68
