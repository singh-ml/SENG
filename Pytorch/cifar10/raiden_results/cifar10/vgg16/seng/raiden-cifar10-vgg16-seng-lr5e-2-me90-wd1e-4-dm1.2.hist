Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9785     22.680  2.1489    17.724  8.01
   2   1.6371     38.910  1.7834    31.164  13.82
   3   1.3031     52.450  1.4904    44.272  19.64
   4   1.0738     62.150  1.2061    56.606  25.47
   5   0.9384     67.780  0.9930    65.006  31.29
   6   0.7781     73.560  0.8528    70.726  37.18
   7   0.7715     74.450  0.7596    74.268  43.01
   8   0.6755     77.980  0.6817    77.170  48.84
   9   0.5843     81.090  0.6122    79.618  54.69
  10   0.5810     80.930  0.5819    80.646  60.53
  11   0.6449     79.910  0.5285    82.632  66.42
  12   0.5483     81.820  0.4924    83.706  72.26
  13   0.5026     83.770  0.4622    84.522  78.09
  14   0.5448     82.680  0.4273    85.872  83.94
  15   0.5102     84.230  0.4215    85.852  89.77
  16   0.4778     84.880  0.3849    87.156  95.60
  17   0.4717     85.330  0.3740    87.612  101.42
  18   0.4781     85.330  0.3445    88.634  107.25
  19   0.4832     85.330  0.3335    88.898  113.10
  20   0.4338     86.440  0.3149    89.618  118.91
  21   0.4601     85.990  0.2956    90.078  124.76
  22   0.4523     86.320  0.2893    90.278  130.58
  23   0.4328     86.570  0.2727    90.862  136.47
  24   0.4414     86.530  0.2659    91.234  142.32
  25   0.4248     86.590  0.2431    91.972  148.16
  26   0.4541     86.490  0.2429    91.912  154.00
  27   0.4192     88.230  0.2222    92.626  159.84
  28   0.4379     86.850  0.2120    92.898  165.71
  29   0.4223     86.940  0.2079    93.082  171.56
  30   0.4144     87.710  0.1990    93.422  177.39
  31   0.4543     86.860  0.1895    93.722  183.21
  32   0.4426     87.230  0.1800    93.930  189.06
  33   0.4477     87.760  0.1738    94.172  194.87
  34   0.4210     88.120  0.1686    94.368  200.77
  35   0.4047     88.610  0.1493    95.034  206.59
  36   0.4350     88.360  0.1394    95.270  212.43
  37   0.4504     88.190  0.1344    95.446  218.29
  38   0.4243     88.480  0.1243    95.856  224.11
  39   0.4156     88.390  0.1222    95.946  229.94
  40   0.4355     88.450  0.1150    96.202  235.83
  41   0.4672     88.230  0.1035    96.486  241.69
  42   0.4320     89.140  0.1046    96.474  247.55
  43   0.4299     88.880  0.0974    96.736  253.38
  44   0.4331     89.100  0.0921    96.868  259.22
  45   0.4386     88.990  0.0861    97.090  265.13
  46   0.4477     89.270  0.0771    97.412  270.96
  47   0.4503     89.360  0.0757    97.430  276.77
  48   0.4627     89.360  0.0671    97.756  282.59
  49   0.4649     89.450  0.0633    97.860  288.43
  50   0.4498     89.700  0.0609    98.058  294.18
  51   0.4707     89.240  0.0573    98.092  300.09
  52   0.4734     90.060  0.0514    98.270  305.93
  53   0.4629     90.130  0.0539    98.158  311.77
  54   0.4752     89.760  0.0415    98.578  317.63
  55   0.4607     89.980  0.0429    98.578  323.46
  56   0.5106     89.650  0.0389    98.720  329.36
  57   0.4932     89.890  0.0367    98.776  335.23
  58   0.4865     89.670  0.0353    98.830  341.06
  59   0.4948     89.910  0.0300    98.996  346.88
  60   0.5397     89.720  0.0248    99.154  352.70
  61   0.5405     89.990  0.0225    99.228  358.51
  62   0.5185     89.770  0.0214    99.320  364.33
  63   0.5504     90.240  0.0189    99.378  370.22
  64   0.5527     89.930  0.0182    99.392  376.03
  65   0.5435     89.800  0.0169    99.444  381.87
  66   0.5565     89.650  0.0152    99.508  387.72
  67   0.5788     90.000  0.0134    99.554  393.55
  68   0.5645     90.210  0.0124    99.568  399.37
  69   0.5738     89.970  0.0120    99.588  405.30
  70   0.5598     90.400  0.0114    99.610  411.11
  71   0.5579     90.610  0.0095    99.710  416.96
  72   0.5638     90.430  0.0079    99.742  422.80
  73   0.5837     90.560  0.0063    99.812  428.62
  74   0.5823     90.530  0.0070    99.790  434.50
  75   0.5951     90.580  0.0054    99.826  440.32
  76   0.5968     90.660  0.0059    99.822  446.17
  77   0.5952     90.480  0.0053    99.832  452.02
  78   0.5937     90.630  0.0048    99.848  457.84
  79   0.5851     90.730  0.0048    99.850  463.68
  80   0.5893     90.720  0.0044    99.862  469.58
  81   0.5922     90.610  0.0037    99.890  475.44
  82   0.5936     90.710  0.0037    99.880  481.30
  83   0.5922     90.770  0.0036    99.882  487.12
  84   0.5950     90.780  0.0032    99.900  492.93
  85   0.5977     90.820  0.0026    99.912  498.81
  86   0.5987     90.800  0.0039    99.880  504.67
  87   0.6002     90.780  0.0030    99.912  510.48
  88   0.6050     90.710  0.0026    99.914  516.31
  89   0.6037     90.840  0.0026    99.916  522.14
  90   0.6072     90.860  0.0033    99.904  527.96
