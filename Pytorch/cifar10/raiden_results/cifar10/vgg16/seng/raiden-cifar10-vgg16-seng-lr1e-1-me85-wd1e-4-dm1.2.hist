Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7445683200 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3030     10.000  2.2798    12.564  7.67
   2   2.3013     11.390  2.2984    10.770  13.58
   3   2.2766     14.590  2.2436    13.838  19.39
   4   1.9085     20.520  2.0212    18.954  25.22
   5   1.7992     28.100  1.8779    23.210  31.04
   6   1.6955     31.990  1.8017    28.382  36.88
   7   1.7252     32.490  1.6743    34.538  42.76
   8   1.5940     43.100  1.5595    39.912  48.58
   9   1.2565     56.080  1.3471    50.934  54.41
  10   1.0729     62.450  1.1239    60.670  60.25
  11   0.8769     70.580  1.0082    65.710  66.08
  12   0.8386     73.070  0.9090    69.914  71.91
  13   0.8684     72.590  0.8301    73.158  77.83
  14   0.7794     73.940  0.7726    75.272  83.64
  15   0.7107     76.830  0.7240    76.724  89.48
  16   0.6671     79.200  0.6818    78.508  95.31
  17   0.6559     79.160  0.6282    80.004  101.16
  18   0.6493     78.620  0.5877    81.298  106.97
  19   0.5794     81.710  0.5659    82.236  112.91
  20   0.5420     82.110  0.5420    83.024  118.75
  21   0.5638     82.740  0.4919    84.450  124.60
  22   0.4977     84.350  0.4760    84.848  130.42
  23   0.5145     84.430  0.4525    85.806  136.26
  24   0.5050     84.170  0.4516    85.628  142.08
  25   0.5012     84.340  0.4159    86.628  148.00
  26   0.5115     83.830  0.4130    87.178  153.84
  27   0.4628     85.150  0.3908    87.544  159.65
  28   0.4723     84.930  0.3657    88.482  165.47
  29   0.4451     86.160  0.3540    88.786  171.32
  30   0.4624     85.850  0.3342    89.400  177.16
  31   0.4526     86.010  0.3229    89.594  183.09
  32   0.3981     87.840  0.3018    90.404  188.92
  33   0.4404     87.200  0.2861    90.804  194.74
  34   0.4317     87.290  0.2759    91.208  200.56
  35   0.4380     86.500  0.2641    91.496  206.38
  36   0.4279     87.620  0.2510    91.944  212.24
  37   0.4047     87.920  0.2408    92.284  218.07
  38   0.4238     87.540  0.2257    92.772  223.89
  39   0.4490     87.470  0.2292    92.698  229.72
  40   0.3843     88.360  0.2095    93.288  235.55
  41   0.3821     87.990  0.1961    93.656  241.37
  42   0.3811     88.870  0.1847    94.116  247.28
  43   0.4029     88.620  0.1704    94.422  253.12
  44   0.4102     88.470  0.1663    94.518  258.96
  45   0.4187     88.730  0.1541    95.082  264.80
  46   0.3975     88.390  0.1391    95.510  270.62
  47   0.4034     89.080  0.1377    95.524  276.51
  48   0.3942     89.170  0.1383    95.522  282.35
  49   0.3940     89.290  0.1187    96.128  288.19
  50   0.3766     89.840  0.1204    96.020  293.95
  51   0.4026     89.610  0.1070    96.498  299.80
  52   0.4279     88.960  0.0970    96.860  305.65
  53   0.3944     89.540  0.0888    97.118  311.56
  54   0.4221     89.620  0.0855    97.210  317.41
  55   0.4357     89.460  0.0781    97.422  323.26
  56   0.4025     89.930  0.0727    97.544  329.12
  57   0.4268     89.440  0.0676    97.746  334.94
  58   0.4262     89.880  0.0619    97.954  340.76
  59   0.4430     89.590  0.0576    98.106  346.69
  60   0.4379     89.860  0.0512    98.354  352.51
  61   0.4659     90.130  0.0459    98.434  358.34
  62   0.4377     89.890  0.0451    98.500  364.20
  63   0.4316     90.340  0.0424    98.656  370.02
  64   0.4426     90.330  0.0361    98.822  375.93
  65   0.4678     90.350  0.0317    98.986  381.75
  66   0.4746     90.250  0.0270    99.164  387.60
  67   0.4652     90.410  0.0276    99.124  393.41
  68   0.4756     90.600  0.0241    99.168  399.24
  69   0.4744     90.600  0.0215    99.314  405.07
  70   0.4834     90.690  0.0186    99.402  410.93
  71   0.5029     90.590  0.0171    99.428  416.75
  72   0.4882     90.600  0.0167    99.480  422.58
  73   0.4988     90.820  0.0150    99.548  428.39
  74   0.5070     90.990  0.0121    99.592  434.21
  75   0.5081     90.950  0.0126    99.592  440.05
  76   0.5084     91.190  0.0109    99.674  445.99
  77   0.5113     90.950  0.0109    99.680  451.81
  78   0.5147     90.970  0.0096    99.706  457.64
  79   0.5107     90.980  0.0097    99.690  463.47
  80   0.5156     91.050  0.0098    99.676  469.28
  81   0.5185     90.990  0.0090    99.748  475.14
  82   0.5165     91.020  0.0087    99.738  481.06
  83   0.5195     91.070  0.0077    99.760  486.88
  84   0.5218     91.100  0.0076    99.776  492.70
  85   0.5197     91.070  0.0078    99.778  498.55
