Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9449     26.980  2.2175    15.048  7.73
   2   1.5833     38.560  1.8117    30.406  13.56
   3   1.5309     43.410  1.5322    42.144  19.35
   4   1.2125     55.450  1.3411    50.592  25.15
   5   1.0752     61.420  1.1552    57.722  31.04
   6   0.9794     64.780  1.0309    62.726  36.82
   7   0.8473     69.740  0.9307    66.658  42.63
   8   0.8115     71.110  0.8476    69.878  48.45
   9   0.7652     73.530  0.7878    72.066  54.26
  10   0.6943     75.990  0.7312    74.194  60.13
  11   0.6786     76.200  0.6885    75.772  65.95
  12   0.7037     76.730  0.6518    77.114  71.77
  13   0.6060     79.360  0.6182    78.446  77.61
  14   0.6200     79.070  0.5890    79.590  83.43
  15   0.5831     79.770  0.5520    80.754  89.24
  16   0.5865     80.280  0.5351    81.200  95.09
  17   0.5423     82.030  0.5104    82.248  100.90
  18   0.5997     79.860  0.4846    83.088  106.71
  19   0.5754     80.480  0.4696    83.766  112.50
  20   0.5349     81.620  0.4578    84.294  118.31
  21   0.5072     82.990  0.4326    85.180  124.10
  22   0.5036     82.870  0.4208    85.468  129.97
  23   0.4912     83.530  0.3995    86.180  135.75
  24   0.5026     82.900  0.3828    86.680  141.55
  25   0.4636     84.620  0.3762    86.956  147.35
  26   0.4647     84.830  0.3553    87.678  153.17
  27   0.4838     84.130  0.3466    88.100  158.97
  28   0.4519     84.740  0.3418    88.284  164.83
  29   0.4714     84.710  0.3227    88.980  170.66
  30   0.4978     84.330  0.3120    89.304  176.48
  31   0.4582     84.700  0.2975    89.654  182.29
  32   0.4524     85.320  0.2868    90.178  188.09
  33   0.4420     85.740  0.2799    90.420  193.89
  34   0.4482     85.260  0.2715    90.556  199.68
  35   0.4813     85.450  0.2627    90.884  205.57
  36   0.4392     85.940  0.2564    91.068  211.38
  37   0.4966     85.080  0.2472    91.410  217.19
  38   0.4539     86.070  0.2409    91.608  222.98
  39   0.4766     85.310  0.2249    92.316  228.79
  40   0.4627     86.050  0.2175    92.396  234.68
  41   0.4545     85.670  0.2134    92.570  240.48
  42   0.4528     86.210  0.2033    92.962  246.32
  43   0.4587     87.060  0.1949    93.252  252.14
  44   0.4702     86.110  0.1897    93.444  257.94
  45   0.4537     86.730  0.1870    93.396  263.80
  46   0.4355     87.160  0.1731    94.010  269.60
  47   0.4518     86.750  0.1655    94.230  275.38
  48   0.4535     87.160  0.1623    94.386  281.18
  49   0.4701     86.990  0.1523    94.796  286.99
  50   0.4885     86.820  0.1508    94.804  292.72
  51   0.4984     86.620  0.1464    94.984  298.58
  52   0.4678     87.190  0.1393    95.194  304.40
  53   0.4707     87.070  0.1335    95.356  310.20
  54   0.4782     87.050  0.1273    95.622  316.02
  55   0.5012     86.990  0.1270    95.660  321.82
  56   0.4928     87.360  0.1221    95.736  327.63
  57   0.5104     87.150  0.1205    95.826  333.46
  58   0.5199     87.150  0.1067    96.310  339.26
  59   0.5233     87.580  0.1050    96.488  345.07
  60   0.5035     87.180  0.1006    96.414  350.89
  61   0.4827     87.570  0.0980    96.580  356.69
  62   0.5074     87.600  0.0898    96.884  362.60
  63   0.5112     87.730  0.0878    96.936  368.43
  64   0.5369     87.100  0.0840    97.016  374.23
  65   0.5457     86.880  0.0861    96.984  380.02
  66   0.5232     87.640  0.0789    97.206  385.81
  67   0.5535     87.490  0.0802    97.250  391.62
  68   0.5627     87.550  0.0736    97.454  397.48
  69   0.5357     87.590  0.0723    97.486  403.28
  70   0.5384     87.840  0.0648    97.798  409.08
  71   0.5427     88.050  0.0708    97.500  414.87
  72   0.5855     87.610  0.0643    97.726  420.67
  73   0.5727     87.850  0.0605    97.946  426.48
  74   0.5684     87.920  0.0583    97.982  432.39
  75   0.5636     87.940  0.0574    97.996  438.19
  76   0.5811     87.720  0.0548    98.104  443.99
  77   0.6018     87.760  0.0489    98.356  449.79
  78   0.5607     88.100  0.0490    98.324  455.58
  79   0.5925     87.980  0.0457    98.410  461.39
  80   0.6065     88.000  0.0489    98.234  467.26
  81   0.5840     88.210  0.0445    98.450  473.07
  82   0.6143     88.240  0.0430    98.486  478.88
  83   0.6056     87.960  0.0445    98.478  484.69
  84   0.6067     88.050  0.0427    98.560  490.51
  85   0.6121     88.180  0.0361    98.776  496.32
  86   0.6155     88.010  0.0401    98.666  502.22
  87   0.6287     88.190  0.0403    98.562  508.03
  88   0.6073     88.100  0.0369    98.746  513.82
  89   0.6074     88.010  0.0391    98.648  519.63
  90   0.6250     88.060  0.0338    98.856  525.44
