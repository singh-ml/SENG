Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8868     27.920  2.1701    17.208  7.83
   2   1.5557     40.230  1.7720    31.796  13.66
   3   1.4349     45.930  1.5517    40.774  19.52
   4   1.2421     54.050  1.3627    48.894  25.35
   5   1.0769     60.830  1.1682    56.944  31.19
   6   1.0212     62.720  1.0279    62.650  37.10
   7   0.8485     69.570  0.9403    66.088  42.92
   8   0.8809     69.160  0.8530    69.464  48.80
   9   0.7914     72.480  0.7847    71.992  54.64
  10   0.7332     74.110  0.7359    73.970  60.47
  11   0.6665     76.600  0.6894    75.672  66.30
  12   0.6443     78.070  0.6456    77.446  72.25
  13   0.6197     79.100  0.6125    78.534  78.10
  14   0.6222     78.120  0.5826    79.700  83.92
  15   0.5688     80.740  0.5547    80.652  89.76
  16   0.5979     80.350  0.5305    81.598  95.61
  17   0.5486     81.190  0.5089    82.338  101.52
  18   0.5411     82.190  0.4883    83.158  107.36
  19   0.5355     82.000  0.4668    83.996  113.19
  20   0.5033     83.020  0.4537    84.366  119.05
  21   0.4802     83.840  0.4336    84.954  124.89
  22   0.5193     83.290  0.4148    85.632  130.75
  23   0.4623     84.390  0.3990    86.202  136.67
  24   0.4876     83.630  0.3905    86.292  142.50
  25   0.4821     84.430  0.3771    86.992  148.34
  26   0.4786     84.010  0.3583    87.622  154.16
  27   0.4613     84.930  0.3489    87.762  160.02
  28   0.4844     84.420  0.3381    88.252  165.85
  29   0.4485     85.090  0.3317    88.634  171.79
  30   0.4532     85.340  0.3154    88.980  177.64
  31   0.4408     85.900  0.3035    89.666  183.48
  32   0.4402     86.060  0.2954    89.842  189.32
  33   0.4239     86.170  0.2803    90.274  195.16
  34   0.4396     85.950  0.2750    90.456  201.03
  35   0.4387     85.830  0.2652    90.766  206.97
  36   0.4466     85.750  0.2616    90.978  212.80
  37   0.4111     86.910  0.2506    91.466  218.65
  38   0.4370     86.280  0.2342    91.890  224.48
  39   0.4304     86.500  0.2317    92.038  230.34
  40   0.4565     85.980  0.2209    92.378  236.28
  41   0.4284     87.130  0.2168    92.380  242.12
  42   0.4283     86.950  0.2055    92.886  247.95
  43   0.4464     87.060  0.1986    93.144  253.80
  44   0.4267     86.860  0.1935    93.220  259.66
  45   0.4336     86.380  0.1863    93.574  265.59
  46   0.4813     86.360  0.1814    93.698  271.43
  47   0.4579     86.760  0.1764    93.844  277.25
  48   0.4835     86.230  0.1691    94.242  283.09
  49   0.4645     86.670  0.1654    94.448  288.92
  50   0.4427     87.230  0.1573    94.548  294.68
  51   0.4481     87.350  0.1495    94.784  300.60
  52   0.4739     87.020  0.1424    95.006  306.44
  53   0.4647     87.200  0.1386    95.078  312.28
  54   0.4426     87.580  0.1342    95.366  318.13
  55   0.4646     87.600  0.1245    95.708  323.97
  56   0.5142     86.520  0.1277    95.524  329.81
  57   0.4715     87.470  0.1181    96.008  335.72
  58   0.4707     87.790  0.1183    95.926  341.55
  59   0.4725     87.870  0.1088    96.292  347.38
  60   0.4614     88.250  0.1055    96.330  353.25
  61   0.4679     88.000  0.1036    96.466  359.09
  62   0.4843     87.920  0.0936    96.786  364.92
  63   0.4906     87.450  0.0984    96.594  370.84
  64   0.4865     87.890  0.0873    96.966  376.71
  65   0.4939     88.550  0.0830    97.116  382.56
  66   0.4799     88.250  0.0827    97.108  388.39
  67   0.4913     88.070  0.0784    97.302  394.22
  68   0.5387     87.460  0.0742    97.408  400.12
  69   0.5056     88.050  0.0798    97.122  405.95
  70   0.5161     88.000  0.0705    97.556  411.79
  71   0.5540     87.670  0.0682    97.642  417.63
  72   0.5092     88.280  0.0698    97.594  423.48
  73   0.5359     88.250  0.0634    97.824  429.32
  74   0.5106     88.310  0.0623    97.908  435.26
  75   0.5099     88.300  0.0557    98.036  441.09
  76   0.5287     88.450  0.0553    98.164  446.94
  77   0.5758     87.530  0.0519    98.246  452.76
  78   0.5516     88.440  0.0502    98.276  458.59
  79   0.5638     87.850  0.0492    98.262  464.43
  80   0.5537     88.270  0.0503    98.276  470.35
  81   0.5808     88.470  0.0468    98.378  476.21
  82   0.5417     88.030  0.0444    98.472  482.04
  83   0.5718     87.980  0.0442    98.510  487.88
  84   0.5650     88.560  0.0426    98.520  493.75
  85   0.5990     88.250  0.0396    98.658  499.57
  86   0.5954     88.520  0.0393    98.646  505.51
  87   0.5871     88.390  0.0400    98.654  511.36
  88   0.5970     88.480  0.0408    98.630  517.22
  89   0.5850     88.330  0.0405    98.606  523.07
  90   0.5711     88.780  0.0389    98.690  528.93
