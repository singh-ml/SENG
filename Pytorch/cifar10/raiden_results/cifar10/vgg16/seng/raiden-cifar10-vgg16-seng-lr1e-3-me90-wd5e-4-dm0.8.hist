Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2878     12.360  2.2989    10.380  7.72
   2   2.1032     24.060  2.2487    14.320  13.59
   3   1.8487     30.010  2.0140    24.462  19.39
   4   1.6370     36.780  1.8038    31.110  25.22
   5   1.5205     41.970  1.6552    36.678  31.03
   6   1.4114     46.980  1.5376    41.686  36.84
   7   1.3367     49.880  1.4350    46.018  42.71
   8   1.2487     54.250  1.3478    50.136  48.54
   9   1.1618     57.910  1.2671    53.436  54.37
  10   1.1115     59.480  1.2014    55.956  60.20
  11   1.0823     60.820  1.1445    58.450  66.02
  12   1.0573     61.740  1.0960    60.094  71.84
  13   1.0190     62.930  1.0487    62.002  77.71
  14   0.9371     66.290  1.0089    63.590  83.55
  15   0.9702     65.380  0.9713    64.834  89.38
  16   0.9128     67.380  0.9275    66.562  95.21
  17   0.8529     69.510  0.8962    67.980  101.05
  18   0.8511     69.350  0.8721    68.636  106.87
  19   0.8195     70.970  0.8453    69.652  112.76
  20   0.7916     72.080  0.8228    70.738  118.57
  21   0.7824     72.550  0.7912    71.940  124.37
  22   0.7676     73.000  0.7661    72.790  130.22
  23   0.7246     74.380  0.7466    73.344  136.02
  24   0.7284     74.380  0.7229    74.420  141.94
  25   0.7062     75.350  0.7093    74.770  147.74
  26   0.6907     76.020  0.6850    75.710  153.54
  27   0.6779     76.030  0.6697    76.280  159.36
  28   0.6938     75.970  0.6572    76.908  165.16
  29   0.6542     77.320  0.6401    77.454  170.96
  30   0.6434     77.780  0.6228    78.082  176.81
  31   0.6602     77.460  0.6028    78.858  182.67
  32   0.6530     77.500  0.5979    78.988  188.47
  33   0.6436     77.820  0.5838    79.648  194.29
  34   0.6223     78.540  0.5743    79.854  200.11
  35   0.6183     78.840  0.5607    80.240  205.92
  36   0.5932     79.680  0.5540    80.610  211.74
  37   0.5922     79.720  0.5319    81.412  217.65
  38   0.5779     79.710  0.5299    81.192  223.47
  39   0.5677     80.370  0.5156    81.968  229.28
  40   0.5629     80.340  0.5058    82.256  235.09
  41   0.5839     80.030  0.4927    82.636  240.91
  42   0.5523     81.150  0.4921    82.768  246.82
  43   0.5587     81.050  0.4822    83.212  252.63
  44   0.5591     80.640  0.4725    83.438  258.45
  45   0.5485     81.420  0.4625    83.844  264.29
  46   0.5509     81.310  0.4548    84.240  270.11
  47   0.5413     81.640  0.4498    84.320  275.96
  48   0.5279     82.090  0.4345    84.710  281.85
  49   0.5216     82.410  0.4294    84.986  287.66
  50   0.5301     81.900  0.4310    84.994  293.41
  51   0.5183     82.600  0.4148    85.544  299.26
  52   0.5396     81.710  0.4142    85.504  305.11
  53   0.5400     82.340  0.4066    85.888  311.02
  54   0.4854     83.660  0.4016    85.870  316.82
  55   0.5016     83.290  0.3891    86.410  322.66
  56   0.5195     82.970  0.3815    86.706  328.46
  57   0.4994     83.360  0.3729    86.858  334.28
  58   0.5131     83.200  0.3683    87.324  340.10
  59   0.4979     83.730  0.3593    87.264  346.02
  60   0.4947     83.470  0.3620    87.368  351.83
  61   0.4879     83.660  0.3503    87.820  357.67
  62   0.5358     83.370  0.3435    88.136  363.51
  63   0.5370     83.350  0.3387    88.178  369.37
  64   0.4981     83.960  0.3339    88.298  375.17
  65   0.4984     84.220  0.3253    88.714  381.04
  66   0.5239     83.580  0.3209    88.816  386.86
  67   0.5059     83.470  0.3129    89.182  392.68
  68   0.4998     84.570  0.3065    89.352  398.49
  69   0.4780     84.430  0.3012    89.590  404.33
  70   0.4946     84.190  0.2972    89.632  410.16
  71   0.4941     84.430  0.2981    89.602  416.06
  72   0.4997     83.880  0.2885    89.954  421.88
  73   0.5073     84.190  0.2877    90.066  427.69
  74   0.5088     84.070  0.2755    90.346  433.54
  75   0.4872     84.640  0.2723    90.434  439.36
  76   0.4915     84.590  0.2715    90.536  445.19
  77   0.5010     84.470  0.2649    90.808  451.08
  78   0.4958     84.430  0.2665    90.662  456.89
  79   0.4978     84.710  0.2568    90.944  462.71
  80   0.5061     84.170  0.2537    91.270  468.54
  81   0.4846     84.890  0.2458    91.374  474.38
  82   0.4956     85.350  0.2534    91.058  480.27
  83   0.4998     84.970  0.2400    91.664  486.10
  84   0.4963     85.350  0.2375    91.564  491.90
  85   0.4941     84.870  0.2339    91.876  497.71
  86   0.5627     83.540  0.2267    92.086  503.52
  87   0.5015     85.190  0.2254    92.034  509.35
  88   0.5226     84.610  0.2113    92.712  515.25
  89   0.4963     85.110  0.2173    92.502  521.06
  90   0.5006     85.620  0.2111    92.574  526.91
