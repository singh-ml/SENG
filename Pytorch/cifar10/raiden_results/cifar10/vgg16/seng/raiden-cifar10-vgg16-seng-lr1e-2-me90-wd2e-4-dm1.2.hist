Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8283     29.140  2.1498    17.442  7.65
   2   1.5906     38.890  1.6871    34.746  13.48
   3   1.2909     52.370  1.4421    45.534  19.31
   4   1.0257     63.170  1.2036    55.746  25.13
   5   0.9388     66.350  1.0084    63.230  30.98
   6   0.8494     69.670  0.8978    67.758  36.89
   7   0.7880     72.840  0.8127    71.132  42.71
   8   0.7472     74.820  0.7433    73.878  48.55
   9   0.6503     77.580  0.6801    76.070  54.39
  10   0.6254     78.660  0.6322    78.032  60.22
  11   0.5981     79.450  0.5944    79.438  66.03
  12   0.5732     80.420  0.5610    80.510  71.94
  13   0.5700     80.650  0.5249    82.128  77.75
  14   0.5223     82.260  0.5060    82.530  83.58
  15   0.4939     83.440  0.4779    83.498  89.39
  16   0.5189     82.630  0.4469    84.704  95.22
  17   0.4944     83.530  0.4294    85.262  101.05
  18   0.4776     84.100  0.4115    86.128  106.94
  19   0.4594     84.520  0.3898    86.580  112.77
  20   0.4881     83.830  0.3726    87.274  118.60
  21   0.5139     83.820  0.3580    87.824  124.41
  22   0.4391     85.460  0.3386    88.396  130.28
  23   0.4295     86.040  0.3272    88.792  136.16
  24   0.4337     85.790  0.3126    89.362  141.97
  25   0.4460     85.760  0.3009    89.596  147.80
  26   0.4541     85.350  0.2864    90.290  153.61
  27   0.4132     86.640  0.2790    90.548  159.44
  28   0.4218     87.210  0.2669    90.854  165.28
  29   0.4345     86.810  0.2572    91.156  171.17
  30   0.4227     86.710  0.2413    91.720  176.99
  31   0.4136     87.240  0.2296    92.082  182.83
  32   0.4346     86.590  0.2227    92.480  188.65
  33   0.4201     86.790  0.2174    92.590  194.51
  34   0.4492     86.680  0.2054    92.910  200.43
  35   0.4306     87.310  0.1992    93.176  206.26
  36   0.4328     87.030  0.1891    93.454  212.08
  37   0.4554     87.110  0.1829    93.714  217.89
  38   0.4231     87.530  0.1716    94.168  223.71
  39   0.4271     87.630  0.1604    94.344  229.54
  40   0.4194     87.820  0.1539    94.732  235.42
  41   0.4307     87.790  0.1442    95.124  241.25
  42   0.4385     87.900  0.1441    95.080  247.09
  43   0.4452     87.840  0.1411    95.136  252.93
  44   0.4547     87.500  0.1268    95.582  258.74
  45   0.4372     87.750  0.1240    95.760  264.56
  46   0.4418     88.570  0.1160    95.924  270.46
  47   0.4611     87.550  0.1134    96.020  276.28
  48   0.4475     88.060  0.1066    96.306  282.09
  49   0.4508     88.620  0.0994    96.516  287.93
  50   0.4511     88.530  0.0964    96.750  293.67
  51   0.4938     87.820  0.0882    97.054  299.51
  52   0.4555     88.650  0.0910    96.862  305.39
  53   0.4816     88.370  0.0773    97.394  311.22
  54   0.4765     88.710  0.0796    97.236  317.05
  55   0.4919     88.350  0.0730    97.504  322.87
  56   0.5064     88.280  0.0673    97.654  328.69
  57   0.4894     88.320  0.0686    97.664  334.54
  58   0.4975     88.720  0.0617    97.850  340.43
  59   0.5165     88.920  0.0541    98.130  346.25
  60   0.5279     88.470  0.0530    98.134  352.05
  61   0.5384     88.290  0.0538    98.150  357.89
  62   0.5170     88.470  0.0478    98.356  363.70
  63   0.5469     88.530  0.0476    98.362  369.52
  64   0.5488     88.570  0.0444    98.480  375.41
  65   0.5575     88.410  0.0393    98.700  381.22
  66   0.5267     89.290  0.0379    98.700  387.03
  67   0.5316     89.060  0.0368    98.732  392.85
  68   0.5650     88.530  0.0315    98.932  398.68
  69   0.5744     88.780  0.0294    98.994  404.58
  70   0.5820     89.110  0.0280    99.020  410.46
  71   0.5678     89.220  0.0291    98.974  416.27
  72   0.5646     89.190  0.0268    99.118  422.10
  73   0.5878     88.960  0.0250    99.122  427.93
  74   0.5927     89.120  0.0201    99.334  433.80
  75   0.5912     89.310  0.0218    99.298  439.62
  76   0.5893     89.110  0.0199    99.338  445.48
  77   0.5985     89.070  0.0197    99.370  451.33
  78   0.6207     89.050  0.0166    99.460  457.18
  79   0.6077     89.040  0.0173    99.388  463.00
  80   0.6203     89.170  0.0149    99.510  468.91
  81   0.6253     88.960  0.0146    99.500  474.75
  82   0.6300     89.020  0.0155    99.480  480.60
  83   0.6292     88.870  0.0136    99.514  486.41
  84   0.6292     89.060  0.0153    99.466  492.25
  85   0.6340     89.080  0.0125    99.568  498.07
  86   0.6414     89.400  0.0120    99.628  503.98
  87   0.6417     89.210  0.0119    99.624  509.80
  88   0.6332     89.310  0.0123    99.576  515.63
  89   0.6302     89.330  0.0114    99.612  521.48
  90   0.6351     89.420  0.0128    99.576  527.33
