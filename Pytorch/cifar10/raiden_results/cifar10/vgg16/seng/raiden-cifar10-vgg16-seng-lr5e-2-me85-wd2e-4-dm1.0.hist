Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0312     24.760  2.1800    17.316  7.70
   2   1.6687     35.830  1.8123    29.522  13.52
   3   1.4818     45.200  1.5187    42.290  19.35
   4   1.1180     60.460  1.2662    54.272  25.26
   5   0.9098     66.730  1.0254    63.774  31.07
   6   0.8029     72.970  0.8728    69.696  37.02
   7   0.7310     74.720  0.7808    73.550  42.84
   8   0.6832     77.430  0.7052    76.542  48.68
   9   0.6189     79.490  0.6452    78.508  54.54
  10   0.5737     80.800  0.5872    80.336  60.41
  11   0.5577     81.590  0.5486    81.822  66.24
  12   0.5639     81.900  0.5241    82.670  72.07
  13   0.5767     81.730  0.4928    83.736  77.89
  14   0.5517     82.060  0.4482    85.034  83.71
  15   0.4946     84.580  0.4191    86.204  89.60
  16   0.4996     84.610  0.3967    86.954  95.42
  17   0.4639     84.800  0.3843    87.492  101.25
  18   0.4278     86.240  0.3648    87.828  107.09
  19   0.4365     86.030  0.3432    88.684  112.92
  20   0.4428     86.110  0.3268    89.328  118.75
  21   0.4345     86.010  0.3150    89.492  124.65
  22   0.4382     86.220  0.3005    89.932  130.49
  23   0.4294     86.950  0.2863    90.542  136.33
  24   0.4071     87.570  0.2720    91.102  142.18
  25   0.4233     86.930  0.2614    91.266  148.03
  26   0.4554     86.400  0.2457    91.836  153.97
  27   0.3978     88.230  0.2394    92.036  159.79
  28   0.4165     88.120  0.2232    92.606  165.63
  29   0.4092     86.970  0.2173    92.800  171.46
  30   0.4204     87.780  0.2089    92.960  177.28
  31   0.4204     87.690  0.2017    93.372  183.10
  32   0.4501     87.490  0.1777    93.942  188.99
  33   0.4424     87.770  0.1719    94.230  194.86
  34   0.4217     87.960  0.1655    94.492  200.71
  35   0.4155     88.460  0.1645    94.536  206.56
  36   0.3978     88.870  0.1548    94.874  212.41
  37   0.4412     87.790  0.1457    95.198  218.24
  38   0.3991     88.640  0.1430    95.134  224.15
  39   0.3822     89.460  0.1320    95.696  229.97
  40   0.4548     89.120  0.1234    95.876  235.82
  41   0.4365     88.530  0.1115    96.342  241.67
  42   0.4331     88.640  0.1162    96.090  247.51
  43   0.3980     89.490  0.1021    96.652  253.35
  44   0.4378     89.310  0.0900    96.992  259.26
  45   0.4290     89.470  0.0946    96.912  265.07
  46   0.4596     89.060  0.0842    97.114  270.93
  47   0.4160     89.800  0.0828    97.170  276.75
  48   0.4442     89.050  0.0724    97.594  282.61
  49   0.4559     89.060  0.0671    97.766  288.42
  50   0.4318     89.980  0.0609    97.940  294.26
  51   0.4174     90.000  0.0551    98.148  300.10
  52   0.4637     89.950  0.0509    98.294  305.95
  53   0.4682     89.470  0.0534    98.166  311.80
  54   0.4584     89.800  0.0460    98.420  317.62
  55   0.4510     89.920  0.0419    98.632  323.53
  56   0.4312     90.260  0.0426    98.572  329.37
  57   0.4852     89.970  0.0352    98.832  335.21
  58   0.4927     89.890  0.0296    99.008  341.02
  59   0.4735     89.960  0.0284    99.026  346.86
  60   0.5032     90.220  0.0249    99.224  352.70
  61   0.4678     90.410  0.0224    99.274  358.59
  62   0.4873     90.080  0.0196    99.370  364.43
  63   0.5062     90.710  0.0156    99.502  370.25
  64   0.5083     90.460  0.0168    99.478  376.07
  65   0.4732     90.510  0.0172    99.426  381.88
  66   0.4894     90.790  0.0122    99.590  387.79
  67   0.5002     90.690  0.0107    99.662  393.63
  68   0.5019     90.780  0.0093    99.710  399.44
  69   0.5207     90.710  0.0079    99.720  405.28
  70   0.5207     90.800  0.0077    99.748  411.13
  71   0.5160     90.810  0.0064    99.774  416.93
  72   0.5320     90.690  0.0067    99.780  422.86
  73   0.5299     90.850  0.0058    99.814  428.68
  74   0.5270     90.840  0.0054    99.820  434.52
  75   0.5218     91.010  0.0047    99.866  440.35
  76   0.5277     90.940  0.0046    99.876  446.17
  77   0.5267     90.970  0.0041    99.864  452.01
  78   0.5307     90.910  0.0034    99.908  457.91
  79   0.5372     90.960  0.0034    99.894  463.72
  80   0.5369     91.090  0.0032    99.914  469.56
  81   0.5317     91.110  0.0039    99.882  475.39
  82   0.5334     91.060  0.0036    99.892  481.23
  83   0.5331     91.090  0.0029    99.918  487.03
  84   0.5369     91.020  0.0028    99.932  492.93
  85   0.5355     91.120  0.0028    99.924  498.74
