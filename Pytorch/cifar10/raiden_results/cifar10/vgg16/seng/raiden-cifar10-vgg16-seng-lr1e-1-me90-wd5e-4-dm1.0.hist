Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3027     10.000  2.3030    10.080  7.76
   2   2.3039     11.250  2.2920    10.986  13.57
   3   1.9272     22.390  2.1005    18.286  19.40
   4   1.8579     23.120  1.9040    23.788  25.21
   5   2.0400     29.540  1.7924    28.554  31.08
   6   1.5488     39.410  1.7005    33.164  36.93
   7   1.3468     49.270  1.5248    41.752  42.74
   8   1.2445     54.440  1.3293    51.860  48.58
   9   1.1240     60.830  1.1990    57.970  54.39
  10   1.0445     66.010  1.0856    62.990  60.19
  11   0.9416     68.990  0.9963    66.624  66.08
  12   0.8781     68.530  0.8999    70.488  71.89
  13   0.8217     73.830  0.8393    73.074  77.71
  14   0.7684     75.780  0.8006    74.312  83.51
  15   0.8144     73.930  0.7640    75.732  89.33
  16   0.7570     75.710  0.7060    77.436  95.14
  17   0.6953     78.420  0.6928    78.292  101.02
  18   0.7067     78.380  0.6566    79.242  106.83
  19   0.6319     80.280  0.6342    80.194  112.67
  20   0.6005     80.800  0.5950    81.160  118.48
  21   0.5988     81.590  0.5664    82.182  124.31
  22   0.5515     82.450  0.5633    82.346  130.10
  23   0.5648     82.140  0.5587    82.384  135.96
  24   0.5323     83.410  0.5188    83.688  141.78
  25   0.6298     79.880  0.5191    83.688  147.60
  26   0.5145     83.530  0.4931    84.318  153.42
  27   0.5396     83.130  0.4798    84.898  159.23
  28   0.4719     84.930  0.4537    85.790  165.04
  29   0.5518     82.800  0.4401    86.040  170.91
  30   0.5288     83.390  0.4277    86.380  176.71
  31   0.4703     85.710  0.4238    86.668  182.51
  32   0.4401     86.680  0.3969    87.444  188.31
  33   0.4786     84.850  0.3851    87.792  194.14
  34   0.4558     85.960  0.3753    88.230  200.03
  35   0.4149     86.840  0.3591    88.546  205.84
  36   0.4300     86.600  0.3581    88.606  211.64
  37   0.5078     83.910  0.3525    88.764  217.44
  38   0.4390     86.040  0.3298    89.362  223.27
  39   0.4098     87.110  0.3222    89.718  229.10
  40   0.4033     87.020  0.3027    90.340  234.99
  41   0.3826     88.150  0.2937    90.600  240.82
  42   0.4217     86.630  0.2745    91.132  246.62
  43   0.3755     88.210  0.2721    91.204  252.45
  44   0.4816     86.000  0.2697    91.284  258.27
  45   0.3891     87.990  0.2548    91.904  264.15
  46   0.3869     88.690  0.2438    92.232  269.95
  47   0.3721     88.800  0.2440    92.092  275.79
  48   0.4053     87.640  0.2222    92.814  281.61
  49   0.4230     87.010  0.2208    92.970  287.45
  50   0.3711     88.990  0.2071    93.296  293.24
  51   0.3848     88.700  0.2003    93.556  299.13
  52   0.3693     88.910  0.1951    93.704  304.96
  53   0.3953     88.750  0.1861    94.000  310.76
  54   0.3517     89.480  0.1749    94.412  316.57
  55   0.3927     88.970  0.1568    94.938  322.38
  56   0.3594     90.080  0.1552    94.966  328.21
  57   0.3822     89.230  0.1391    95.502  334.13
  58   0.3880     89.420  0.1459    95.212  339.93
  59   0.3417     90.460  0.1316    95.638  345.75
  60   0.3588     89.870  0.1188    96.116  351.56
  61   0.3421     90.200  0.1155    96.210  357.38
  62   0.3422     90.330  0.1072    96.490  363.20
  63   0.3374     90.830  0.0943    96.978  369.08
  64   0.3396     90.740  0.0867    97.198  374.87
  65   0.3874     89.960  0.0815    97.418  380.68
  66   0.3685     90.180  0.0722    97.656  386.49
  67   0.3624     90.630  0.0640    97.962  392.31
  68   0.3671     90.590  0.0592    98.050  398.17
  69   0.3592     91.040  0.0521    98.330  403.97
  70   0.3808     91.150  0.0463    98.514  409.80
  71   0.3499     91.200  0.0415    98.670  415.60
  72   0.3814     91.190  0.0364    98.810  421.39
  73   0.3639     91.570  0.0318    98.950  427.21
  74   0.3866     91.420  0.0261    99.158  433.08
  75   0.3825     91.730  0.0208    99.366  438.89
  76   0.3763     91.640  0.0214    99.332  444.69
  77   0.3752     91.730  0.0201    99.340  450.50
  78   0.3768     91.800  0.0152    99.522  456.31
  79   0.3797     91.820  0.0122    99.622  462.21
  80   0.3779     92.170  0.0111    99.654  468.03
  81   0.3789     92.050  0.0085    99.742  473.84
  82   0.3800     92.110  0.0095    99.732  479.62
  83   0.3850     92.180  0.0082    99.770  485.46
  84   0.3827     92.250  0.0069    99.798  491.25
  85   0.3889     92.180  0.0065    99.812  497.13
  86   0.3863     92.290  0.0065    99.810  502.95
  87   0.3886     92.310  0.0056    99.858  508.76
  88   0.3903     92.270  0.0058    99.836  514.56
  89   0.3924     92.180  0.0048    99.876  520.37
  90   0.3901     92.290  0.0056    99.838  526.30
