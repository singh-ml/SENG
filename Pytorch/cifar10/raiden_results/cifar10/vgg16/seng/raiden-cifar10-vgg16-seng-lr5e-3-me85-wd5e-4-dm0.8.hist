Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9880     24.100  2.1911    15.186  7.72
   2   1.6072     39.660  1.7884    31.278  13.52
   3   1.3351     51.590  1.4853    43.946  19.34
   4   1.1651     58.260  1.2974    52.202  25.15
   5   0.9774     64.720  1.1093    59.426  31.04
   6   0.9089     67.120  0.9850    64.506  36.83
   7   0.8072     71.100  0.8828    68.400  42.65
   8   0.7648     73.050  0.8035    71.532  48.45
   9   0.7218     74.740  0.7457    73.916  54.27
  10   0.6738     76.900  0.6888    76.042  60.07
  11   0.6336     78.550  0.6458    77.586  65.95
  12   0.6014     79.640  0.6074    78.768  71.78
  13   0.5774     80.360  0.5770    80.042  77.57
  14   0.5443     81.260  0.5415    81.256  83.36
  15   0.5734     80.830  0.5293    81.824  89.17
  16   0.5233     82.940  0.4927    82.974  95.05
  17   0.5019     83.150  0.4760    83.518  100.86
  18   0.4923     83.140  0.4477    84.640  106.69
  19   0.5132     82.780  0.4350    85.012  112.53
  20   0.4883     83.890  0.4140    85.836  118.34
  21   0.4681     84.530  0.3928    86.674  124.12
  22   0.5064     82.950  0.3769    87.086  129.99
  23   0.4495     85.280  0.3658    87.362  135.78
  24   0.4734     84.480  0.3535    87.876  141.59
  25   0.4533     85.010  0.3450    88.060  147.42
  26   0.4315     85.970  0.3311    88.638  153.23
  27   0.4509     85.590  0.3126    89.440  159.10
  28   0.4396     85.570  0.2991    89.754  164.90
  29   0.4190     86.410  0.2932    89.906  170.72
  30   0.4141     86.580  0.2821    90.268  176.53
  31   0.4341     86.510  0.2704    90.628  182.35
  32   0.4506     85.980  0.2585    91.166  188.14
  33   0.4362     86.340  0.2478    91.426  194.02
  34   0.4049     87.000  0.2460    91.478  199.81
  35   0.4091     87.050  0.2293    92.058  205.61
  36   0.4476     86.410  0.2239    92.276  211.41
  37   0.4219     87.300  0.2106    92.780  217.21
  38   0.4490     86.150  0.2038    93.040  223.01
  39   0.4316     86.400  0.2038    92.942  228.90
  40   0.4197     87.290  0.1928    93.302  234.73
  41   0.4572     86.760  0.1816    93.722  240.54
  42   0.4014     87.840  0.1735    94.060  246.34
  43   0.4476     86.980  0.1624    94.442  252.15
  44   0.4227     87.840  0.1639    94.308  257.98
  45   0.4510     87.500  0.1503    94.764  263.77
  46   0.4241     87.460  0.1487    94.862  269.64
  47   0.4383     87.730  0.1457    95.000  275.44
  48   0.4309     88.050  0.1373    95.326  281.24
  49   0.4483     87.910  0.1276    95.666  287.02
  50   0.4626     87.470  0.1216    95.694  292.78
  51   0.4618     87.630  0.1179    95.906  298.67
  52   0.4525     88.440  0.1179    95.800  304.49
  53   0.4636     87.760  0.1087    96.158  310.29
  54   0.4743     88.140  0.1026    96.460  316.08
  55   0.4402     88.290  0.0991    96.602  321.89
  56   0.4597     88.150  0.0920    96.858  327.70
  57   0.4819     87.600  0.0926    96.802  333.53
  58   0.4477     88.460  0.0871    97.026  339.37
  59   0.4447     88.590  0.0810    97.176  345.17
  60   0.4814     88.620  0.0768    97.384  350.99
  61   0.4818     88.390  0.0759    97.360  356.82
  62   0.4945     87.910  0.0706    97.560  362.66
  63   0.5030     88.220  0.0695    97.620  368.55
  64   0.4846     88.710  0.0631    97.838  374.35
  65   0.4835     88.460  0.0655    97.750  380.14
  66   0.4824     88.440  0.0579    97.948  385.94
  67   0.5088     87.930  0.0574    97.968  391.74
  68   0.4864     88.820  0.0553    98.102  397.61
  69   0.5014     88.860  0.0492    98.260  403.42
  70   0.5114     88.730  0.0470    98.438  409.21
  71   0.5230     88.210  0.0451    98.440  415.03
  72   0.5255     88.520  0.0461    98.426  420.85
  73   0.4998     88.710  0.0442    98.450  426.63
  74   0.5236     88.840  0.0405    98.614  432.44
  75   0.5612     88.630  0.0388    98.718  438.31
  76   0.5359     88.520  0.0370    98.734  444.10
  77   0.5390     89.020  0.0346    98.836  449.90
  78   0.5495     88.760  0.0335    98.828  455.69
  79   0.5162     88.940  0.0357    98.808  461.48
  80   0.5399     88.690  0.0295    98.982  467.27
  81   0.5782     88.410  0.0326    98.878  473.15
  82   0.5660     89.040  0.0312    98.946  478.95
  83   0.5627     88.810  0.0321    98.894  484.74
  84   0.5418     88.850  0.0298    99.000  490.55
  85   0.5757     88.470  0.0301    98.962  496.39
