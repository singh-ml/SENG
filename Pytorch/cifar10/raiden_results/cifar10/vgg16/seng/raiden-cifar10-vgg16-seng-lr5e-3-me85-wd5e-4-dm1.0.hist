Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0073     23.510  2.2119    14.542  7.64
   2   1.6093     38.690  1.7968    30.604  13.45
   3   1.3774     48.660  1.5727    40.344  19.25
   4   1.1964     56.460  1.3453    50.216  25.05
   5   1.0338     63.040  1.1527    58.070  30.94
   6   0.9325     66.200  1.0123    63.232  36.73
   7   0.8817     69.440  0.9222    67.130  42.56
   8   0.7888     72.260  0.8361    70.126  48.37
   9   0.7476     74.270  0.7732    72.588  54.15
  10   0.6864     76.050  0.7219    74.436  59.99
  11   0.6710     76.510  0.6785    76.134  65.89
  12   0.6305     78.080  0.6406    77.480  71.71
  13   0.6205     78.280  0.6136    78.570  77.54
  14   0.6022     79.620  0.5775    79.896  83.34
  15   0.5604     80.430  0.5574    80.768  89.15
  16   0.5959     80.550  0.5308    81.520  95.00
  17   0.5400     81.410  0.5139    82.294  100.82
  18   0.5173     82.730  0.4861    83.296  106.63
  19   0.5362     81.790  0.4673    83.914  112.44
  20   0.5106     82.750  0.4558    84.018  118.23
  21   0.5147     82.860  0.4321    85.178  124.03
  22   0.4830     84.250  0.4158    85.528  129.91
  23   0.4682     84.060  0.3987    86.388  135.71
  24   0.4901     83.460  0.3890    86.680  141.52
  25   0.4577     84.820  0.3735    87.108  147.32
  26   0.4714     84.210  0.3553    87.878  153.12
  27   0.4406     85.180  0.3460    88.250  158.99
  28   0.4303     85.710  0.3349    88.360  164.78
  29   0.4431     85.310  0.3226    88.784  170.59
  30   0.4286     85.490  0.3111    89.268  176.41
  31   0.4356     85.790  0.2964    89.746  182.21
  32   0.4159     86.570  0.2892    89.994  188.04
  33   0.4283     85.970  0.2803    90.264  193.91
  34   0.4105     86.500  0.2729    90.672  199.72
  35   0.4285     86.040  0.2650    90.782  205.53
  36   0.4304     86.280  0.2486    91.490  211.34
  37   0.4117     86.660  0.2465    91.560  217.15
  38   0.4320     85.930  0.2369    91.904  222.95
  39   0.4170     86.810  0.2358    91.896  228.79
  40   0.4219     86.560  0.2261    92.242  234.69
  41   0.4136     87.390  0.2115    92.810  240.51
  42   0.4334     87.040  0.2004    93.054  246.35
  43   0.4213     86.960  0.1950    93.270  252.15
  44   0.4300     87.020  0.1950    93.232  257.96
  45   0.4333     86.950  0.1844    93.644  263.88
  46   0.4416     86.790  0.1788    93.844  269.69
  47   0.4390     87.430  0.1703    94.150  275.49
  48   0.4341     87.470  0.1625    94.366  281.28
  49   0.4370     87.370  0.1579    94.624  287.09
  50   0.4136     88.050  0.1535    94.788  292.82
  51   0.4484     87.630  0.1496    94.856  298.74
  52   0.4178     87.920  0.1441    94.994  304.54
  53   0.4303     87.600  0.1312    95.508  310.35
  54   0.4313     87.970  0.1315    95.484  316.19
  55   0.4402     87.790  0.1206    95.874  322.00
  56   0.4433     87.730  0.1173    96.052  327.89
  57   0.4487     87.440  0.1146    96.070  333.70
  58   0.4371     88.040  0.1070    96.354  339.53
  59   0.4390     88.140  0.1041    96.440  345.34
  60   0.4511     88.100  0.1020    96.500  351.16
  61   0.4737     88.160  0.0950    96.680  356.98
  62   0.4932     87.900  0.0910    96.838  362.85
  63   0.4642     88.270  0.0877    96.956  368.68
  64   0.4727     87.670  0.0837    97.192  374.48
  65   0.4967     87.800  0.0805    97.272  380.27
  66   0.4706     87.740  0.0822    97.220  386.07
  67   0.4909     87.970  0.0775    97.292  391.96
  68   0.4625     88.250  0.0753    97.408  397.77
  69   0.4777     88.140  0.0694    97.584  403.56
  70   0.4820     88.470  0.0680    97.676  409.36
  71   0.4957     88.410  0.0604    97.962  415.16
  72   0.5104     88.090  0.0607    97.940  420.96
  73   0.4775     88.560  0.0617    97.924  426.79
  74   0.5048     88.330  0.0569    98.076  432.67
  75   0.4870     88.930  0.0579    98.010  438.49
  76   0.4960     88.470  0.0532    98.192  444.30
  77   0.5363     88.410  0.0506    98.274  450.09
  78   0.5136     88.520  0.0551    98.092  455.92
  79   0.5070     88.530  0.0490    98.310  461.72
  80   0.5271     88.560  0.0465    98.388  467.57
  81   0.5226     88.660  0.0440    98.466  473.37
  82   0.5119     88.430  0.0429    98.480  479.17
  83   0.5098     88.620  0.0438    98.500  484.98
  84   0.5269     88.720  0.0400    98.658  490.78
  85   0.5280     88.600  0.0424    98.520  496.59
