Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9983     23.750  2.2133    15.446  7.64
   2   1.5949     38.310  1.8174    29.308  13.53
   3   1.3466     50.350  1.5154    42.180  19.33
   4   1.1620     58.580  1.2737    53.148  25.14
   5   0.9649     65.800  1.0816    60.854  30.95
   6   0.8721     68.840  0.9331    66.130  36.76
   7   0.9275     67.270  0.8411    70.048  42.57
   8   0.7206     74.580  0.7808    72.412  48.45
   9   0.7668     74.090  0.7021    75.280  54.29
  10   0.6503     77.730  0.6585    77.030  60.12
  11   0.6166     79.330  0.6093    78.968  65.94
  12   0.6025     79.830  0.5767    79.970  71.79
  13   0.6031     79.690  0.5427    81.352  77.63
  14   0.5380     81.840  0.5192    82.168  83.51
  15   0.5483     81.610  0.4925    83.066  89.35
  16   0.5140     82.670  0.4691    83.838  95.18
  17   0.4885     83.440  0.4449    84.794  101.00
  18   0.4826     83.870  0.4183    85.758  106.81
  19   0.4564     84.850  0.4060    86.096  112.69
  20   0.4735     83.890  0.3880    86.728  118.50
  21   0.4677     84.760  0.3686    87.290  124.34
  22   0.4586     84.690  0.3550    87.900  130.17
  23   0.4432     85.410  0.3379    88.362  135.96
  24   0.4563     85.200  0.3190    88.994  141.79
  25   0.4611     85.280  0.3077    89.354  147.71
  26   0.4430     86.150  0.2973    89.786  153.55
  27   0.4386     86.060  0.2846    90.178  159.37
  28   0.4420     86.330  0.2740    90.506  165.22
  29   0.4180     86.090  0.2658    90.896  171.03
  30   0.4778     85.220  0.2491    91.306  176.91
  31   0.4482     86.690  0.2423    91.666  182.75
  32   0.4520     85.470  0.2304    92.024  188.59
  33   0.4819     85.420  0.2222    92.358  194.39
  34   0.4443     86.490  0.2091    92.788  200.20
  35   0.4548     86.850  0.1956    93.240  206.02
  36   0.4177     87.260  0.1945    93.254  211.89
  37   0.4364     87.630  0.1891    93.384  217.71
  38   0.4612     86.360  0.1829    93.744  223.53
  39   0.4352     87.570  0.1737    94.002  229.34
  40   0.4188     87.780  0.1636    94.290  235.18
  41   0.4296     87.460  0.1561    94.688  241.00
  42   0.4413     88.060  0.1471    94.968  246.90
  43   0.4447     87.590  0.1433    95.110  252.76
  44   0.4326     87.770  0.1374    95.186  258.59
  45   0.4468     87.950  0.1270    95.592  264.43
  46   0.4542     87.940  0.1268    95.640  270.25
  47   0.4495     87.680  0.1279    95.612  276.05
  48   0.4457     87.830  0.1132    96.060  281.91
  49   0.4685     87.940  0.1064    96.348  287.71
  50   0.4700     87.870  0.1041    96.462  293.45
  51   0.4677     88.370  0.0998    96.592  299.26
  52   0.4622     88.510  0.0947    96.766  305.08
  53   0.4895     88.260  0.0864    97.016  310.91
  54   0.4560     88.320  0.0807    97.174  316.83
  55   0.4708     88.290  0.0786    97.298  322.64
  56   0.4743     88.610  0.0717    97.492  328.47
  57   0.4752     88.640  0.0711    97.566  334.29
  58   0.5386     88.460  0.0628    97.810  340.10
  59   0.4931     88.370  0.0662    97.650  345.93
  60   0.5149     88.310  0.0607    97.880  351.87
  61   0.5480     87.520  0.0543    98.086  357.67
  62   0.5349     88.760  0.0543    98.080  363.50
  63   0.5205     89.270  0.0529    98.134  369.30
  64   0.5409     88.470  0.0487    98.318  375.12
  65   0.5518     88.480  0.0428    98.570  380.97
  66   0.5392     89.020  0.0428    98.560  386.78
  67   0.5453     88.670  0.0391    98.732  392.60
  68   0.5534     88.880  0.0368    98.734  398.41
  69   0.5425     89.450  0.0361    98.734  404.24
  70   0.5618     89.070  0.0321    98.882  410.06
  71   0.5879     88.790  0.0329    98.866  415.95
  72   0.5764     88.890  0.0306    98.996  421.76
  73   0.5842     89.070  0.0285    99.036  427.59
  74   0.5988     89.180  0.0245    99.172  433.40
  75   0.6005     89.060  0.0241    99.160  439.23
  76   0.6162     88.770  0.0233    99.212  445.14
  77   0.6061     88.990  0.0198    99.330  450.96
  78   0.6227     89.250  0.0199    99.374  456.78
  79   0.6158     89.180  0.0194    99.364  462.64
  80   0.6096     89.240  0.0192    99.376  468.45
  81   0.6150     89.280  0.0178    99.412  474.27
  82   0.6162     89.360  0.0168    99.436  480.16
  83   0.6158     89.190  0.0172    99.426  486.00
  84   0.6367     89.390  0.0146    99.496  491.81
  85   0.6452     89.280  0.0129    99.538  497.65
  86   0.6549     89.150  0.0150    99.520  503.46
  87   0.6444     89.410  0.0144    99.514  509.33
  88   0.6676     89.010  0.0134    99.574  515.14
  89   0.6576     89.210  0.0157    99.486  520.96
  90   0.6580     89.200  0.0137    99.552  526.81
