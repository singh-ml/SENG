Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0020     23.750  2.1565    18.318  7.74
   2   1.6035     38.560  1.8304    29.196  13.54
   3   1.3553     50.500  1.5148    42.666  19.38
   4   1.1532     59.260  1.2730    53.896  25.19
   5   1.0101     66.190  1.0646    62.686  31.07
   6   0.8318     72.130  0.9246    68.124  36.89
   7   0.7172     76.120  0.7951    73.224  42.72
   8   0.7688     74.840  0.7168    75.878  48.53
   9   0.6290     79.260  0.6560    78.268  54.37
  10   0.6508     79.200  0.6060    79.896  60.19
  11   0.5954     80.250  0.5796    80.934  66.12
  12   0.5386     82.840  0.5389    82.490  71.97
  13   0.5375     82.280  0.5112    83.290  77.78
  14   0.5070     83.710  0.4790    84.296  83.63
  15   0.5135     83.540  0.4450    85.284  89.44
  16   0.4997     83.780  0.4323    85.912  95.33
  17   0.4858     85.000  0.4142    86.586  101.14
  18   0.4657     85.120  0.3946    87.114  106.96
  19   0.4476     85.160  0.3742    87.750  112.79
  20   0.4659     85.380  0.3567    88.228  118.61
  21   0.4304     85.940  0.3655    88.002  124.45
  22   0.4044     86.650  0.3395    88.880  130.37
  23   0.4489     86.490  0.3210    89.338  136.18
  24   0.4072     87.210  0.3109    89.820  142.00
  25   0.4082     87.340  0.2962    90.118  147.81
  26   0.4061     86.920  0.2943    90.356  153.61
  27   0.3753     87.790  0.2820    90.702  159.45
  28   0.4217     87.330  0.2558    91.558  165.34
  29   0.4321     86.820  0.2585    91.466  171.15
  30   0.3990     87.860  0.2380    92.254  176.97
  31   0.4056     87.150  0.2366    92.108  182.79
  32   0.3927     88.110  0.2367    92.248  188.61
  33   0.4072     88.000  0.2237    92.636  194.52
  34   0.4072     87.810  0.2138    92.876  200.36
  35   0.4074     88.060  0.2073    93.112  206.19
  36   0.4002     88.060  0.1943    93.556  212.03
  37   0.3954     88.090  0.1913    93.796  217.86
  38   0.4245     87.170  0.1851    93.870  223.67
  39   0.3714     88.870  0.1758    94.256  229.49
  40   0.3800     88.710  0.1701    94.376  235.43
  41   0.4031     88.350  0.1649    94.494  241.27
  42   0.3658     88.470  0.1588    94.714  247.09
  43   0.3958     88.500  0.1475    95.068  252.92
  44   0.3854     89.640  0.1388    95.430  258.73
  45   0.3862     88.520  0.1289    95.772  264.57
  46   0.3980     88.470  0.1279    95.726  270.39
  47   0.3766     89.670  0.1201    95.990  276.21
  48   0.4012     88.850  0.1130    96.180  282.04
  49   0.3912     89.170  0.1154    96.102  287.85
  50   0.3658     89.510  0.1002    96.682  293.59
  51   0.3668     89.740  0.0921    96.962  299.51
  52   0.4149     89.010  0.0909    96.956  305.31
  53   0.4270     89.040  0.0843    97.228  311.12
  54   0.3818     89.990  0.0886    97.058  316.96
  55   0.3636     90.120  0.0778    97.470  322.78
  56   0.4006     89.510  0.0696    97.730  328.59
  57   0.3839     89.840  0.0616    97.924  334.39
  58   0.4153     90.170  0.0604    97.992  340.20
  59   0.4156     90.080  0.0544    98.172  346.03
  60   0.3988     90.410  0.0520    98.206  351.86
  61   0.3968     90.030  0.0463    98.452  357.70
  62   0.4304     90.350  0.0458    98.488  363.59
  63   0.4100     90.490  0.0371    98.772  369.41
  64   0.4271     90.250  0.0357    98.852  375.25
  65   0.4088     90.740  0.0298    98.986  381.06
  66   0.4271     90.650  0.0248    99.198  386.88
  67   0.4119     91.090  0.0212    99.308  392.72
  68   0.4260     90.420  0.0200    99.338  398.60
  69   0.4250     90.830  0.0175    99.464  404.41
  70   0.4469     90.780  0.0169    99.396  410.23
  71   0.4160     91.110  0.0123    99.584  416.03
  72   0.4359     91.260  0.0142    99.536  421.84
  73   0.4286     91.280  0.0107    99.684  427.65
  74   0.4333     91.510  0.0088    99.762  433.47
  75   0.4308     91.390  0.0079    99.764  439.36
  76   0.4311     91.400  0.0069    99.774  445.19
  77   0.4376     91.500  0.0057    99.846  451.03
  78   0.4414     91.490  0.0049    99.878  456.84
  79   0.4331     91.400  0.0051    99.842  462.69
  80   0.4309     91.420  0.0050    99.862  468.58
  81   0.4299     91.380  0.0037    99.914  474.39
  82   0.4342     91.560  0.0033    99.930  480.20
  83   0.4387     91.450  0.0036    99.908  486.05
  84   0.4352     91.490  0.0041    99.900  491.86
  85   0.4293     91.610  0.0032    99.922  497.70
  86   0.4302     91.600  0.0037    99.918  503.56
  87   0.4300     91.610  0.0027    99.952  509.37
  88   0.4350     91.700  0.0032    99.914  515.20
  89   0.4312     91.510  0.0029    99.938  521.04
  90   0.4307     91.530  0.0027    99.946  526.85
