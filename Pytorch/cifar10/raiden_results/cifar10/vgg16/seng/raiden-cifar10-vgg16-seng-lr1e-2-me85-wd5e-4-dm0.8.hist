Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8842     26.450  2.1113    18.836  8.13
   2   1.5162     43.390  1.6736    34.978  14.15
   3   1.2565     53.350  1.3780    48.518  20.20
   4   1.0171     62.860  1.1414    58.428  26.25
   5   0.9036     67.340  0.9634    65.280  32.27
   6   0.7977     72.580  0.8431    70.006  38.38
   7   0.7539     73.860  0.7615    73.226  44.43
   8   0.7144     75.750  0.6925    76.032  50.45
   9   0.6271     78.870  0.6312    78.386  56.47
  10   0.6139     79.030  0.5795    80.058  62.52
  11   0.5504     81.480  0.5477    81.206  68.62
  12   0.5212     82.250  0.5114    82.594  74.64
  13   0.5344     81.710  0.4808    83.644  80.66
  14   0.4857     83.840  0.4459    84.830  86.68
  15   0.4758     84.570  0.4262    85.510  92.72
  16   0.4835     84.110  0.4014    86.404  98.74
  17   0.5021     84.030  0.3796    86.996  104.89
  18   0.5037     84.020  0.3621    87.756  110.91
  19   0.4343     85.100  0.3478    88.116  116.93
  20   0.4665     85.270  0.3348    88.562  122.99
  21   0.4030     86.320  0.3210    89.056  129.00
  22   0.4296     86.180  0.3012    89.810  135.02
  23   0.4636     85.170  0.2906    90.114  141.20
  24   0.4339     86.330  0.2811    90.328  147.23
  25   0.4123     86.940  0.2572    91.242  153.25
  26   0.4196     87.040  0.2434    91.716  159.29
  27   0.3994     87.220  0.2407    91.688  165.30
  28   0.4115     87.570  0.2259    92.278  171.31
  29   0.4185     87.080  0.2148    92.756  177.42
  30   0.4077     87.590  0.2020    93.102  183.42
  31   0.4471     87.230  0.1963    93.340  189.44
  32   0.4309     87.390  0.1812    93.834  195.47
  33   0.4254     87.830  0.1865    93.660  201.48
  34   0.3978     88.000  0.1700    94.194  207.57
  35   0.4626     87.260  0.1663    94.354  213.59
  36   0.4145     87.740  0.1538    94.684  219.62
  37   0.4136     87.970  0.1469    95.058  225.63
  38   0.4354     88.050  0.1358    95.344  231.63
  39   0.4636     87.410  0.1311    95.514  237.73
  40   0.4277     87.310  0.1265    95.728  243.78
  41   0.4255     88.630  0.1201    95.896  249.79
  42   0.4107     88.920  0.1131    96.102  255.81
  43   0.4179     88.780  0.1052    96.416  261.84
  44   0.4135     88.780  0.1110    96.166  267.90
  45   0.4373     88.770  0.0876    97.026  273.97
  46   0.4632     88.380  0.0874    97.000  280.03
  47   0.4205     88.820  0.0872    97.038  286.07
  48   0.4153     88.760  0.0787    97.342  292.12
  49   0.4639     88.130  0.0746    97.430  298.18
  50   0.4554     89.360  0.0642    97.816  304.23
  51   0.4341     89.280  0.0669    97.684  310.26
  52   0.4649     88.710  0.0606    97.960  316.28
  53   0.4522     89.140  0.0589    97.992  322.33
  54   0.4564     89.500  0.0483    98.346  328.35
  55   0.4756     89.070  0.0502    98.266  334.38
  56   0.4712     89.520  0.0512    98.230  340.48
  57   0.4495     89.580  0.0421    98.578  346.62
  58   0.5090     89.470  0.0371    98.720  352.64
  59   0.4833     89.240  0.0393    98.664  358.68
  60   0.4685     89.990  0.0373    98.786  364.72
  61   0.4810     89.830  0.0319    98.948  370.76
  62   0.4863     89.940  0.0283    99.060  376.89
  63   0.4873     89.880  0.0260    99.118  382.92
  64   0.4699     89.960  0.0274    99.062  388.93
  65   0.5004     89.820  0.0264    99.130  395.00
  66   0.5053     89.500  0.0213    99.326  401.08
  67   0.4898     90.170  0.0199    99.314  407.17
  68   0.5171     90.160  0.0162    99.502  413.20
  69   0.5186     90.330  0.0147    99.526  419.21
  70   0.5136     90.270  0.0153    99.488  425.22
  71   0.5263     90.160  0.0146    99.506  431.25
  72   0.5292     90.230  0.0128    99.594  437.29
  73   0.5285     89.970  0.0125    99.592  443.36
  74   0.5307     90.540  0.0107    99.650  449.37
  75   0.5341     90.190  0.0116    99.594  455.40
  76   0.5351     90.160  0.0104    99.684  461.44
  77   0.5507     90.320  0.0090    99.722  467.45
  78   0.5342     90.370  0.0097    99.660  473.46
  79   0.5442     90.170  0.0081    99.758  479.50
  80   0.5411     90.510  0.0066    99.802  485.55
  81   0.5718     90.100  0.0088    99.728  491.57
  82   0.5499     90.220  0.0085    99.752  497.62
  83   0.5591     90.410  0.0063    99.802  503.68
  84   0.5594     90.270  0.0079    99.740  509.79
  85   0.5592     90.390  0.0070    99.794  515.82
