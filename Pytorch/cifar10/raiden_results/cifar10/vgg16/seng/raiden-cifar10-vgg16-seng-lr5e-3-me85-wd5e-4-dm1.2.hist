Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0447     23.140  2.2577    12.870  7.73
   2   1.6250     38.570  1.8605    29.162  13.55
   3   1.5105     45.320  1.5491    41.264  19.37
   4   1.2665     53.860  1.3858    48.314  25.20
   5   1.0915     60.850  1.1976    56.122  31.10
   6   0.9942     64.630  1.0695    61.084  36.90
   7   0.9253     66.910  0.9600    65.456  42.73
   8   0.8208     70.570  0.8843    68.118  48.53
   9   0.7651     72.910  0.8195    70.750  54.34
  10   0.7329     74.620  0.7649    72.784  60.16
  11   0.7080     75.700  0.7182    74.762  66.03
  12   0.6335     77.500  0.6822    76.178  71.86
  13   0.6496     77.720  0.6416    77.484  77.68
  14   0.6320     78.030  0.6118    78.648  83.50
  15   0.5976     79.880  0.5862    79.470  89.31
  16   0.6035     79.250  0.5604    80.628  95.20
  17   0.5581     81.120  0.5373    81.380  101.00
  18   0.5498     81.350  0.5139    82.244  106.83
  19   0.6035     79.720  0.4971    82.756  112.64
  20   0.5232     82.630  0.4839    83.158  118.44
  21   0.5501     81.640  0.4613    84.090  124.25
  22   0.5400     81.830  0.4443    84.724  130.15
  23   0.5298     82.950  0.4256    85.268  135.99
  24   0.4975     83.720  0.4083    85.994  141.83
  25   0.4832     84.020  0.4021    86.232  147.66
  26   0.4901     83.530  0.3882    86.564  153.46
  27   0.4983     84.380  0.3705    87.238  159.30
  28   0.4715     84.740  0.3608    87.498  165.23
  29   0.4978     84.030  0.3430    88.224  171.02
  30   0.4655     85.210  0.3419    88.346  176.83
  31   0.4603     85.110  0.3213    88.940  182.64
  32   0.4631     85.080  0.3194    89.082  188.46
  33   0.4644     85.320  0.3030    89.690  194.30
  34   0.4432     85.040  0.2951    89.906  200.16
  35   0.4606     84.960  0.2923    89.954  205.98
  36   0.4745     85.570  0.2748    90.570  211.79
  37   0.4218     86.570  0.2691    90.922  217.62
  38   0.4479     86.400  0.2532    91.218  223.43
  39   0.4449     86.090  0.2494    91.418  229.32
  40   0.4726     85.840  0.2442    91.646  235.12
  41   0.4555     86.500  0.2292    92.126  240.92
  42   0.4371     86.790  0.2274    92.142  246.75
  43   0.4465     86.960  0.2227    92.462  252.57
  44   0.4491     86.510  0.2077    92.850  258.38
  45   0.4637     86.600  0.2120    92.670  264.26
  46   0.4620     86.810  0.1942    93.232  270.10
  47   0.4443     87.010  0.1938    93.378  275.89
  48   0.4527     86.760  0.1833    93.628  281.69
  49   0.4766     86.520  0.1738    93.954  287.51
  50   0.4859     86.450  0.1745    94.020  293.26
  51   0.4710     86.770  0.1666    94.258  299.16
  52   0.4778     86.510  0.1589    94.500  304.99
  53   0.4468     87.460  0.1587    94.514  310.79
  54   0.4350     87.390  0.1455    94.962  316.61
  55   0.4785     86.910  0.1416    95.126  322.41
  56   0.4502     87.610  0.1360    95.306  328.23
  57   0.4840     86.810  0.1346    95.414  334.12
  58   0.4790     87.590  0.1287    95.576  339.95
  59   0.4626     87.300  0.1243    95.780  345.76
  60   0.4844     87.710  0.1198    95.850  351.57
  61   0.4875     87.650  0.1170    95.950  357.36
  62   0.4946     87.380  0.1080    96.310  363.25
  63   0.4821     87.290  0.1092    96.222  369.07
  64   0.4785     87.660  0.1024    96.564  374.88
  65   0.4888     87.620  0.1008    96.502  380.68
  66   0.4912     87.880  0.0960    96.706  386.53
  67   0.5046     87.750  0.0893    96.918  392.33
  68   0.5005     87.490  0.0886    96.974  398.21
  69   0.5200     87.760  0.0837    97.144  404.03
  70   0.5097     87.540  0.0805    97.194  409.85
  71   0.5060     87.720  0.0825    97.190  415.65
  72   0.5415     87.490  0.0787    97.292  421.46
  73   0.5285     88.090  0.0716    97.558  427.37
  74   0.5290     87.800  0.0691    97.634  433.20
  75   0.5497     87.550  0.0687    97.636  439.00
  76   0.5112     87.990  0.0661    97.710  444.81
  77   0.5200     87.560  0.0686    97.692  450.64
  78   0.5293     87.810  0.0645    97.784  456.46
  79   0.5325     87.740  0.0623    97.886  462.29
  80   0.5419     87.950  0.0595    97.998  468.10
  81   0.5601     87.870  0.0586    97.968  473.92
  82   0.5568     87.870  0.0587    97.976  479.72
  83   0.5361     87.980  0.0586    97.974  485.54
  84   0.5564     87.130  0.0523    98.254  491.34
  85   0.5530     87.960  0.0595    98.002  497.21
