Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2405     14.610  2.2150    14.916  7.83
   2   1.7193     31.890  1.9272    24.596  13.66
   3   1.5494     40.940  1.6160    37.126  19.50
   4   1.1557     58.300  1.3311    51.290  25.32
   5   0.9596     66.570  1.0720    61.616  31.13
   6   0.8554     70.160  0.9206    67.914  36.97
   7   0.7921     72.920  0.8013    72.480  42.87
   8   0.6964     76.870  0.7350    75.138  48.68
   9   0.6280     78.840  0.6647    77.734  54.53
  10   0.5880     80.520  0.6058    79.860  60.36
  11   0.5416     82.010  0.5598    81.490  66.17
  12   0.5985     81.600  0.5128    82.976  72.06
  13   0.4985     83.230  0.4897    83.782  77.90
  14   0.5416     81.630  0.4571    84.846  83.73
  15   0.5455     83.280  0.4296    85.864  89.55
  16   0.5173     84.000  0.4037    86.626  95.36
  17   0.4619     84.840  0.3914    87.048  101.18
  18   0.4811     84.250  0.3633    87.980  107.07
  19   0.4697     85.010  0.3489    88.424  112.88
  20   0.4503     85.480  0.3340    88.968  118.70
  21   0.4351     85.790  0.3159    89.552  124.53
  22   0.4194     86.380  0.3014    90.070  130.35
  23   0.4132     86.390  0.2831    90.624  136.24
  24   0.4493     85.950  0.2686    91.110  142.09
  25   0.4110     87.580  0.2639    91.082  147.90
  26   0.4268     87.160  0.2404    92.050  153.73
  27   0.4226     86.530  0.2308    92.354  159.56
  28   0.4087     87.690  0.2233    92.486  165.39
  29   0.3814     88.230  0.2135    92.796  171.32
  30   0.4150     87.490  0.1987    93.346  177.16
  31   0.3873     88.510  0.1944    93.402  182.98
  32   0.4046     88.490  0.1814    93.884  188.81
  33   0.3893     88.720  0.1744    94.170  194.65
  34   0.4092     88.000  0.1636    94.480  200.53
  35   0.4753     86.790  0.1539    94.836  206.35
  36   0.4112     88.540  0.1568    94.698  212.16
  37   0.3950     88.660  0.1386    95.250  217.99
  38   0.4097     88.760  0.1361    95.506  223.80
  39   0.4112     88.910  0.1278    95.646  229.62
  40   0.4017     89.280  0.1184    96.012  235.49
  41   0.4343     88.230  0.1088    96.334  241.32
  42   0.4044     88.870  0.1019    96.536  247.12
  43   0.4074     89.300  0.0974    96.712  252.93
  44   0.4250     89.030  0.0923    96.860  258.77
  45   0.3928     89.180  0.0851    97.138  264.61
  46   0.4584     89.120  0.0788    97.276  270.49
  47   0.4261     89.440  0.0739    97.530  276.30
  48   0.4203     89.230  0.0644    97.824  282.12
  49   0.4451     89.660  0.0603    98.028  287.94
  50   0.4433     89.370  0.0580    98.020  293.70
  51   0.4126     89.750  0.0569    98.160  299.52
  52   0.4742     90.020  0.0468    98.420  305.39
  53   0.4497     90.050  0.0443    98.506  311.20
  54   0.4734     89.630  0.0421    98.540  317.01
  55   0.4595     89.900  0.0396    98.660  322.85
  56   0.4931     89.940  0.0343    98.856  328.67
  57   0.5003     90.070  0.0312    98.976  334.59
  58   0.4811     89.890  0.0283    99.082  340.41
  59   0.4825     89.930  0.0283    99.032  346.24
  60   0.4908     90.100  0.0258    99.134  352.09
  61   0.4961     90.240  0.0214    99.282  357.90
  62   0.5017     89.930  0.0212    99.280  363.70
  63   0.4849     90.350  0.0179    99.412  369.61
  64   0.5208     90.360  0.0154    99.480  375.44
  65   0.5147     90.420  0.0158    99.474  381.28
  66   0.5364     90.350  0.0142    99.556  387.10
  67   0.5353     90.640  0.0128    99.576  392.92
  68   0.5145     90.740  0.0095    99.706  398.83
  69   0.5178     90.370  0.0112    99.630  404.68
  70   0.5303     90.610  0.0095    99.690  410.50
  71   0.5301     90.740  0.0083    99.726  416.31
  72   0.5375     90.700  0.0076    99.750  422.14
  73   0.5349     90.610  0.0079    99.752  427.95
  74   0.5386     90.600  0.0070    99.788  433.84
  75   0.5406     90.680  0.0061    99.812  439.70
  76   0.5372     90.570  0.0054    99.852  445.54
  77   0.5458     90.950  0.0055    99.808  451.36
  78   0.5498     90.870  0.0046    99.854  457.21
  79   0.5424     90.820  0.0046    99.852  463.05
  80   0.5507     90.760  0.0048    99.842  468.95
  81   0.5451     90.830  0.0038    99.902  474.77
  82   0.5510     90.940  0.0034    99.908  480.62
  83   0.5515     90.780  0.0042    99.860  486.45
  84   0.5540     90.900  0.0036    99.884  492.26
  85   0.5537     90.970  0.0036    99.894  498.07
