Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8305     27.920  2.1409    17.836  7.65
   2   1.4682     43.990  1.6907    34.326  13.47
   3   1.2189     55.590  1.3741    48.586  19.28
   4   0.9983     64.930  1.0985    60.156  25.08
   5   0.8811     69.080  0.9293    66.706  30.89
   6   0.7579     73.540  0.8344    70.456  36.79
   7   0.6854     76.890  0.7314    74.428  42.61
   8   0.6501     77.430  0.6717    76.762  48.42
   9   0.5960     79.740  0.6126    79.008  54.23
  10   0.5669     80.680  0.5815    80.242  60.07
  11   0.5918     80.550  0.5340    81.728  65.96
  12   0.5259     82.630  0.4989    82.980  71.77
  13   0.4943     83.580  0.4696    84.088  77.57
  14   0.5170     83.320  0.4481    84.720  83.38
  15   0.5001     84.300  0.4213    85.442  89.20
  16   0.4547     85.030  0.4005    86.470  95.04
  17   0.4562     84.900  0.3742    87.348  100.90
  18   0.4597     85.110  0.3662    87.692  106.73
  19   0.4382     85.720  0.3425    88.280  112.54
  20   0.4263     86.140  0.3209    88.950  118.33
  21   0.4295     86.050  0.3149    89.234  124.15
  22   0.4108     86.620  0.2973    89.992  129.97
  23   0.4616     85.780  0.2810    90.558  135.86
  24   0.4247     86.220  0.2712    90.840  141.68
  25   0.4186     86.760  0.2637    91.086  147.49
  26   0.4104     87.290  0.2436    91.828  153.29
  27   0.4148     86.600  0.2344    92.110  159.10
  28   0.4182     86.800  0.2335    92.072  164.92
  29   0.4212     87.080  0.2193    92.520  170.79
  30   0.3954     87.690  0.2063    93.038  176.59
  31   0.3925     87.710  0.1997    93.310  182.40
  32   0.3856     88.070  0.1917    93.406  188.21
  33   0.4266     87.610  0.1836    93.794  194.01
  34   0.4096     87.490  0.1683    94.254  199.82
  35   0.4234     87.660  0.1682    94.288  205.70
  36   0.4065     88.300  0.1573    94.642  211.49
  37   0.4012     88.280  0.1543    94.602  217.30
  38   0.4639     87.240  0.1428    95.130  223.11
  39   0.3929     88.940  0.1456    94.994  228.93
  40   0.3876     89.110  0.1267    95.620  234.73
  41   0.4168     87.890  0.1192    95.982  240.56
  42   0.4076     88.510  0.1171    95.960  246.36
  43   0.4086     88.830  0.1109    96.220  252.20
  44   0.4164     88.650  0.1051    96.334  258.02
  45   0.4221     88.480  0.1091    96.246  263.85
  46   0.4307     88.670  0.0931    96.802  269.72
  47   0.4148     88.910  0.0901    96.866  275.56
  48   0.4122     88.750  0.0889    96.852  281.36
  49   0.4339     88.550  0.0818    97.190  287.17
  50   0.4204     89.500  0.0737    97.508  292.91
  51   0.4650     88.690  0.0740    97.448  298.81
  52   0.4398     89.180  0.0697    97.588  304.63
  53   0.4252     89.690  0.0663    97.772  310.45
  54   0.4391     89.260  0.0568    98.028  316.27
  55   0.4079     89.720  0.0540    98.170  322.08
  56   0.4372     89.380  0.0517    98.222  327.92
  57   0.4543     89.500  0.0522    98.178  333.79
  58   0.4635     89.110  0.0450    98.452  339.62
  59   0.4721     89.250  0.0425    98.564  345.45
  60   0.4778     89.010  0.0398    98.652  351.26
  61   0.4591     89.780  0.0399    98.664  357.09
  62   0.4704     89.710  0.0328    98.876  362.91
  63   0.4818     89.830  0.0341    98.834  368.78
  64   0.4802     89.940  0.0277    99.044  374.60
  65   0.4892     89.980  0.0286    99.054  380.41
  66   0.4880     89.560  0.0247    99.178  386.25
  67   0.5059     89.740  0.0207    99.302  392.06
  68   0.4966     89.840  0.0194    99.382  397.86
  69   0.5051     89.890  0.0203    99.324  403.73
  70   0.5078     89.990  0.0171    99.454  409.54
  71   0.5116     89.830  0.0185    99.334  415.37
  72   0.5204     89.940  0.0163    99.456  421.21
  73   0.5309     89.880  0.0128    99.580  427.01
  74   0.5458     90.020  0.0151    99.486  432.83
  75   0.5295     90.100  0.0130    99.600  438.70
  76   0.5152     90.220  0.0120    99.600  444.49
  77   0.5413     89.870  0.0094    99.714  450.29
  78   0.5307     90.350  0.0097    99.690  456.09
  79   0.5386     90.130  0.0082    99.744  461.90
  80   0.5444     90.320  0.0097    99.646  467.79
  81   0.5412     90.260  0.0077    99.754  473.60
  82   0.5413     90.300  0.0073    99.756  479.40
  83   0.5543     90.380  0.0072    99.806  485.22
  84   0.5381     90.500  0.0071    99.790  491.05
  85   0.5442     90.340  0.0067    99.790  496.87
  86   0.5473     90.410  0.0060    99.800  502.74
  87   0.5628     90.300  0.0069    99.770  508.55
  88   0.5583     90.460  0.0059    99.828  514.37
  89   0.5536     90.530  0.0053    99.838  520.17
  90   0.5683     90.380  0.0055    99.822  525.98
