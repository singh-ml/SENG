Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8855     31.290  2.1880    15.906  7.89
   2   1.5767     40.070  1.7631    32.810  13.70
   3   1.3653     48.990  1.5005    43.642  19.49
   4   1.1385     57.680  1.2910    52.436  25.30
   5   0.9795     64.750  1.1238    59.194  31.10
   6   0.9204     66.920  0.9912    64.208  36.97
   7   0.8497     68.990  0.8991    67.894  42.75
   8   0.7859     72.110  0.8308    70.436  48.56
   9   0.7164     75.000  0.7666    72.852  54.39
  10   0.6874     76.080  0.7208    74.394  60.19
  11   0.6448     77.140  0.6746    76.090  66.00
  12   0.6479     77.490  0.6359    77.764  71.90
  13   0.5909     79.750  0.6073    78.640  77.71
  14   0.5715     80.320  0.5821    79.638  83.54
  15   0.5704     80.890  0.5492    80.758  89.34
  16   0.5649     81.140  0.5359    81.222  95.15
  17   0.5348     81.610  0.5105    82.218  100.94
  18   0.5542     81.490  0.4822    83.174  106.82
  19   0.5205     82.200  0.4683    83.834  112.65
  20   0.4970     83.360  0.4449    84.590  118.45
  21   0.5275     82.490  0.4422    84.608  124.27
  22   0.4935     83.620  0.4192    85.558  130.08
  23   0.4776     84.090  0.3987    86.254  135.96
  24   0.4785     84.080  0.3854    86.690  141.76
  25   0.5123     83.080  0.3739    87.226  147.60
  26   0.4707     84.590  0.3621    87.426  153.41
  27   0.4648     84.790  0.3521    87.944  159.22
  28   0.4462     85.850  0.3392    88.242  165.04
  29   0.4290     85.650  0.3306    88.688  170.96
  30   0.4230     86.190  0.3159    89.204  176.77
  31   0.4373     85.700  0.2972    89.676  182.58
  32   0.4629     85.070  0.2918    90.020  188.39
  33   0.4222     86.680  0.2884    90.086  194.18
  34   0.4305     86.120  0.2721    90.780  199.99
  35   0.4294     86.230  0.2649    90.868  205.80
  36   0.4522     85.970  0.2603    91.046  211.73
  37   0.4394     86.270  0.2475    91.528  217.57
  38   0.4331     86.550  0.2417    91.776  223.37
  39   0.4400     86.380  0.2294    92.128  229.21
  40   0.4353     87.050  0.2239    92.346  235.02
  41   0.4405     87.080  0.2140    92.680  240.87
  42   0.4432     87.050  0.2049    92.928  246.67
  43   0.4331     87.130  0.1963    93.320  252.49
  44   0.4346     87.070  0.1931    93.344  258.29
  45   0.4108     87.800  0.1836    93.640  264.10
  46   0.4490     87.370  0.1776    93.862  269.91
  47   0.4402     87.090  0.1694    94.174  275.70
  48   0.4348     87.260  0.1650    94.288  281.60
  49   0.4334     87.710  0.1633    94.378  287.42
  50   0.4331     87.830  0.1541    94.714  293.16
  51   0.4342     88.200  0.1451    95.056  298.97
  52   0.4555     87.970  0.1344    95.352  304.79
  53   0.4342     87.580  0.1434    95.042  310.64
  54   0.4789     87.250  0.1352    95.328  316.44
  55   0.4541     87.830  0.1269    95.542  322.27
  56   0.4561     88.080  0.1247    95.674  328.07
  57   0.4801     87.840  0.1214    95.756  333.90
  58   0.4507     88.020  0.1162    96.056  339.72
  59   0.4711     88.050  0.1056    96.406  345.63
  60   0.4550     88.480  0.1052    96.388  351.42
  61   0.4709     88.160  0.1012    96.518  357.25
  62   0.4731     88.240  0.1030    96.402  363.04
  63   0.4754     87.870  0.0935    96.772  368.84
  64   0.4868     88.200  0.0868    96.964  374.70
  65   0.4756     88.280  0.0870    97.112  380.50
  66   0.5193     87.630  0.0796    97.272  386.29
  67   0.4973     87.840  0.0824    97.156  392.08
  68   0.5130     88.210  0.0727    97.464  397.89
  69   0.4840     88.460  0.0743    97.470  403.69
  70   0.5018     88.190  0.0690    97.560  409.57
  71   0.5001     88.460  0.0663    97.762  415.37
  72   0.4903     88.380  0.0629    97.874  421.21
  73   0.5101     88.780  0.0594    97.970  427.05
  74   0.5606     87.730  0.0585    98.030  432.87
  75   0.5109     88.860  0.0557    98.070  438.70
  76   0.5181     88.360  0.0548    98.180  444.60
  77   0.5667     88.220  0.0515    98.240  450.41
  78   0.5617     87.840  0.0495    98.282  456.21
  79   0.5347     88.380  0.0482    98.356  462.00
  80   0.5404     88.620  0.0437    98.522  467.79
  81   0.5317     88.840  0.0465    98.448  473.59
  82   0.5598     88.510  0.0427    98.574  479.47
  83   0.5551     88.430  0.0417    98.624  485.30
  84   0.5500     88.490  0.0393    98.664  491.12
  85   0.5746     88.490  0.0396    98.614  496.94
  86   0.5576     88.480  0.0391    98.582  502.75
  87   0.5433     88.570  0.0400    98.600  508.58
  88   0.5741     88.300  0.0365    98.756  514.47
  89   0.5523     88.640  0.0370    98.712  520.26
  90   0.6089     88.170  0.0340    98.876  526.10
