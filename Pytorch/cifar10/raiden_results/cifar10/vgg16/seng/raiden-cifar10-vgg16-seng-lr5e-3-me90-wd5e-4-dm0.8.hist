Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8869     29.460  2.1715    16.746  7.82
   2   1.7099     35.760  1.7610    32.304  13.62
   3   1.3640     49.130  1.4930    43.350  19.40
   4   1.2035     56.070  1.2635    53.732  25.21
   5   1.0055     64.050  1.0825    60.504  31.11
   6   0.9041     68.070  0.9611    65.320  36.91
   7   0.8203     70.440  0.8775    68.554  42.72
   8   0.8024     72.670  0.7986    71.540  48.55
   9   0.6926     76.280  0.7449    73.780  54.35
  10   0.6728     76.470  0.6896    75.870  60.15
  11   0.6486     77.800  0.6432    77.510  66.02
  12   0.6487     78.400  0.6089    78.864  71.83
  13   0.5760     80.060  0.5742    80.108  77.62
  14   0.5823     80.530  0.5506    80.874  83.46
  15   0.5516     81.590  0.5221    81.956  89.25
  16   0.5522     81.560  0.4990    82.822  95.06
  17   0.4919     82.890  0.4721    83.668  100.93
  18   0.5072     82.790  0.4534    84.332  106.73
  19   0.5021     83.120  0.4366    85.034  112.53
  20   0.4707     84.280  0.4140    85.810  118.33
  21   0.5118     83.580  0.3993    86.246  124.15
  22   0.4418     85.000  0.3903    86.588  129.94
  23   0.4996     83.610  0.3654    87.510  135.81
  24   0.4561     84.930  0.3492    87.882  141.60
  25   0.4273     85.630  0.3419    88.336  147.39
  26   0.4524     85.520  0.3270    88.806  153.22
  27   0.4281     85.660  0.3152    89.206  159.03
  28   0.4185     86.550  0.3021    89.630  164.82
  29   0.4323     85.560  0.2908    89.986  170.69
  30   0.4132     86.080  0.2778    90.506  176.49
  31   0.4572     85.360  0.2665    90.904  182.31
  32   0.4468     86.270  0.2585    91.090  188.12
  33   0.4191     86.250  0.2564    91.192  193.92
  34   0.4190     86.500  0.2495    91.408  199.71
  35   0.4198     87.100  0.2284    92.260  205.56
  36   0.4145     87.120  0.2221    92.432  211.37
  37   0.4120     87.260  0.2200    92.382  217.16
  38   0.4404     86.490  0.2126    92.718  222.95
  39   0.4174     87.160  0.2057    92.936  228.74
  40   0.4468     87.050  0.1862    93.594  234.53
  41   0.4247     87.360  0.1874    93.574  240.42
  42   0.4160     88.110  0.1810    93.926  246.24
  43   0.4184     87.680  0.1685    94.334  252.04
  44   0.4365     87.450  0.1649    94.354  257.85
  45   0.4036     88.120  0.1626    94.454  263.66
  46   0.4281     87.800  0.1499    94.906  269.55
  47   0.4310     87.050  0.1484    94.900  275.37
  48   0.4329     87.580  0.1415    95.136  281.17
  49   0.4148     87.970  0.1314    95.494  286.98
  50   0.4210     88.160  0.1267    95.702  292.72
  51   0.4357     87.820  0.1245    95.780  298.51
  52   0.4445     87.700  0.1186    95.932  304.39
  53   0.4783     86.790  0.1141    96.056  310.22
  54   0.4604     87.780  0.1077    96.304  316.04
  55   0.4386     88.270  0.0999    96.594  321.85
  56   0.4528     88.050  0.1010    96.606  327.64
  57   0.4625     87.940  0.0997    96.620  333.51
  58   0.4525     88.640  0.0866    97.058  339.31
  59   0.4528     88.520  0.0886    96.898  345.14
  60   0.4820     87.830  0.0849    97.038  350.97
  61   0.4612     88.330  0.0839    97.018  356.78
  62   0.4827     88.290  0.0775    97.278  362.57
  63   0.4788     88.510  0.0652    97.718  368.46
  64   0.4848     88.230  0.0677    97.660  374.25
  65   0.5098     88.350  0.0659    97.770  380.06
  66   0.4805     88.720  0.0618    97.890  385.86
  67   0.5291     88.420  0.0628    97.794  391.67
  68   0.4723     88.640  0.0633    97.924  397.46
  69   0.4873     88.360  0.0592    98.000  403.34
  70   0.5039     88.330  0.0505    98.328  409.14
  71   0.5004     88.310  0.0535    98.198  414.95
  72   0.5045     88.910  0.0498    98.306  420.76
  73   0.5073     88.890  0.0430    98.510  426.58
  74   0.5026     88.940  0.0408    98.576  432.41
  75   0.5019     88.990  0.0446    98.442  438.31
  76   0.5054     89.090  0.0385    98.672  444.12
  77   0.5192     89.020  0.0378    98.716  449.93
  78   0.5121     88.770  0.0415    98.598  455.72
  79   0.5111     89.180  0.0351    98.822  461.51
  80   0.5180     89.260  0.0305    98.934  467.31
  81   0.5327     88.850  0.0336    98.858  473.20
  82   0.5687     88.590  0.0336    98.850  479.00
  83   0.5505     88.960  0.0311    98.960  484.82
  84   0.5433     89.010  0.0278    99.092  490.63
  85   0.5239     89.090  0.0301    98.978  496.44
  86   0.5409     88.970  0.0261    99.122  502.27
  87   0.5468     89.130  0.0284    99.022  508.15
  88   0.5516     89.000  0.0238    99.192  513.97
  89   0.5689     89.010  0.0250    99.158  519.77
  90   0.5601     89.290  0.0256    99.138  525.56
