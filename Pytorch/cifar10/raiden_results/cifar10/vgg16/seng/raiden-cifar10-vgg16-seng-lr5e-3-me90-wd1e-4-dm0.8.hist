Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8509     30.020  2.1454    17.884  7.68
   2   1.5676     40.320  1.7034    35.224  13.52
   3   1.2586     53.730  1.4394    46.170  19.35
   4   1.0943     60.310  1.2288    54.956  25.16
   5   0.9643     64.930  1.0754    61.174  30.99
   6   0.8609     68.930  0.9604    65.504  36.82
   7   0.8120     71.140  0.8623    69.084  42.63
   8   0.7509     73.570  0.7836    72.178  48.47
   9   0.6740     76.080  0.7358    74.058  54.29
  10   0.6583     76.890  0.6764    76.486  60.09
  11   0.6141     78.960  0.6467    77.504  65.99
  12   0.6050     79.800  0.6084    78.988  71.82
  13   0.5675     80.730  0.5701    80.180  77.63
  14   0.5464     81.200  0.5459    81.206  83.44
  15   0.5451     81.660  0.5177    82.094  89.27
  16   0.5196     82.430  0.4897    83.110  95.17
  17   0.5319     81.990  0.4777    83.592  101.02
  18   0.4988     83.170  0.4547    84.178  106.82
  19   0.5518     82.070  0.4334    85.058  112.64
  20   0.4764     84.120  0.4125    85.796  118.47
  21   0.4833     84.010  0.4003    86.234  124.28
  22   0.4563     84.410  0.3763    87.008  130.12
  23   0.4573     84.850  0.3677    87.316  136.00
  24   0.4726     85.120  0.3549    87.716  141.83
  25   0.4956     84.600  0.3448    88.178  147.64
  26   0.4846     84.400  0.3289    88.728  153.46
  27   0.4704     85.090  0.3160    89.148  159.27
  28   0.4470     85.290  0.2997    89.654  165.11
  29   0.4474     85.480  0.2904    90.042  170.98
  30   0.4521     85.060  0.2829    90.242  176.82
  31   0.4498     85.890  0.2723    90.522  182.67
  32   0.4460     85.920  0.2605    91.040  188.48
  33   0.4275     86.550  0.2546    91.220  194.33
  34   0.4548     86.270  0.2422    91.630  200.25
  35   0.4762     85.670  0.2313    92.030  206.10
  36   0.4501     86.810  0.2222    92.258  211.93
  37   0.4575     86.610  0.2162    92.552  217.76
  38   0.4786     85.860  0.2134    92.682  223.58
  39   0.4621     86.380  0.2032    93.046  229.37
  40   0.4647     86.310  0.1946    93.266  235.25
  41   0.4510     86.930  0.1866    93.542  241.06
  42   0.4393     87.160  0.1801    93.756  246.89
  43   0.4553     87.090  0.1689    94.172  252.70
  44   0.4342     87.550  0.1639    94.314  258.51
  45   0.4522     87.340  0.1519    94.758  264.32
  46   0.4698     87.130  0.1539    94.616  270.20
  47   0.4771     87.020  0.1506    94.816  276.00
  48   0.4792     86.750  0.1381    95.286  281.82
  49   0.4612     87.260  0.1387    95.208  287.65
  50   0.4700     87.660  0.1250    95.726  293.41
  51   0.4832     87.440  0.1262    95.524  299.28
  52   0.4548     87.720  0.1178    96.002  305.10
  53   0.4907     87.840  0.1166    95.978  310.91
  54   0.4934     87.140  0.1155    96.008  316.70
  55   0.4843     87.550  0.1051    96.400  322.50
  56   0.4993     87.460  0.0978    96.690  328.33
  57   0.5006     87.330  0.0985    96.662  334.22
  58   0.4764     87.910  0.0943    96.694  340.03
  59   0.4884     87.720  0.0870    97.014  345.86
  60   0.5144     87.230  0.0877    96.934  351.68
  61   0.5101     87.620  0.0836    97.128  357.51
  62   0.5229     87.560  0.0786    97.294  363.38
  63   0.4965     88.180  0.0744    97.470  369.18
  64   0.5385     87.390  0.0742    97.390  374.99
  65   0.5466     87.480  0.0715    97.464  380.83
  66   0.5478     87.960  0.0671    97.716  386.63
  67   0.5380     88.030  0.0622    97.836  392.46
  68   0.5310     87.830  0.0629    97.784  398.37
  69   0.5502     88.100  0.0536    98.182  404.18
  70   0.5449     88.240  0.0576    97.990  410.01
  71   0.5635     88.100  0.0509    98.242  415.81
  72   0.5775     88.310  0.0464    98.392  421.61
  73   0.5580     88.190  0.0469    98.402  427.41
  74   0.5499     88.420  0.0472    98.368  433.22
  75   0.5592     88.160  0.0449    98.432  439.14
  76   0.5782     88.110  0.0404    98.614  444.99
  77   0.6154     87.920  0.0416    98.562  450.82
  78   0.5699     88.220  0.0407    98.638  456.66
  79   0.5919     88.370  0.0361    98.770  462.49
  80   0.5942     88.400  0.0352    98.774  468.37
  81   0.6053     88.150  0.0321    98.836  474.16
  82   0.6085     88.070  0.0341    98.808  479.96
  83   0.6143     88.280  0.0328    98.858  485.80
  84   0.6166     88.180  0.0304    98.930  491.60
  85   0.6326     88.320  0.0310    98.942  497.49
  86   0.6290     88.370  0.0304    98.930  503.31
  87   0.6313     88.460  0.0277    99.092  509.15
  88   0.6357     88.390  0.0272    99.088  514.95
  89   0.6401     88.310  0.0261    99.104  520.80
  90   0.6273     88.560  0.0285    99.020  526.63
