Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8440     31.220  2.1260    18.822  7.70
   2   1.4680     44.110  1.6961    34.970  13.53
   3   1.2664     52.700  1.4099    47.120  19.34
   4   1.0205     63.160  1.1870    56.530  25.15
   5   0.9624     64.780  1.0190    62.900  30.97
   6   0.8345     70.350  0.8978    67.794  36.78
   7   0.7846     72.630  0.8125    71.032  42.67
   8   0.6918     75.970  0.7504    73.648  48.48
   9   0.6919     75.860  0.6844    75.878  54.32
  10   0.6642     76.840  0.6424    77.840  60.12
  11   0.5984     79.580  0.6031    79.286  65.93
  12   0.5961     80.030  0.5622    80.488  71.78
  13   0.5697     81.100  0.5349    81.662  77.59
  14   0.5426     81.590  0.5124    82.406  83.43
  15   0.5075     82.990  0.4878    83.392  89.23
  16   0.5195     82.230  0.4566    84.438  95.03
  17   0.4780     83.800  0.4340    85.200  100.84
  18   0.4695     84.130  0.4124    85.956  106.72
  19   0.4954     83.350  0.3908    86.708  112.51
  20   0.4587     84.690  0.3875    86.730  118.33
  21   0.4474     84.540  0.3649    87.468  124.17
  22   0.4354     85.650  0.3496    88.014  129.96
  23   0.4455     85.460  0.3323    88.756  135.77
  24   0.4574     85.050  0.3260    88.812  141.67
  25   0.4118     86.260  0.3041    89.530  147.47
  26   0.4351     85.750  0.2982    89.726  153.27
  27   0.4268     86.550  0.2816    90.252  159.07
  28   0.4669     85.720  0.2671    90.814  164.87
  29   0.3973     87.190  0.2645    90.994  170.70
  30   0.4039     86.820  0.2517    91.498  176.58
  31   0.4474     85.720  0.2362    91.898  182.41
  32   0.4153     86.910  0.2334    91.950  188.22
  33   0.3991     87.040  0.2175    92.496  194.06
  34   0.4118     87.130  0.2108    92.708  199.90
  35   0.4518     85.800  0.2050    93.010  205.71
  36   0.3966     87.850  0.1979    93.244  211.61
  37   0.3941     87.640  0.1796    93.912  217.43
  38   0.4001     87.430  0.1774    93.870  223.23
  39   0.4443     87.350  0.1665    94.260  229.05
  40   0.4335     87.540  0.1632    94.424  234.86
  41   0.3933     88.200  0.1595    94.556  240.73
  42   0.3954     88.010  0.1456    95.044  246.52
  43   0.4048     88.590  0.1409    95.242  252.36
  44   0.4361     87.100  0.1325    95.436  258.18
  45   0.4119     88.030  0.1274    95.696  264.01
  46   0.4197     87.860  0.1200    95.854  269.80
  47   0.4049     88.150  0.1159    95.974  275.67
  48   0.4246     88.520  0.1079    96.302  281.46
  49   0.4377     88.190  0.1032    96.514  287.31
  50   0.4324     88.290  0.1039    96.452  293.03
  51   0.4424     88.160  0.0938    96.750  298.82
  52   0.4514     87.840  0.0895    96.842  304.70
  53   0.4373     88.660  0.0875    97.026  310.52
  54   0.4569     88.220  0.0752    97.462  316.33
  55   0.4336     88.800  0.0828    97.186  322.15
  56   0.4369     88.990  0.0687    97.618  327.98
  57   0.4280     89.060  0.0700    97.650  333.77
  58   0.4127     89.190  0.0670    97.628  339.67
  59   0.4534     89.140  0.0541    98.124  345.49
  60   0.4533     88.920  0.0566    98.022  351.31
  61   0.4633     89.000  0.0514    98.228  357.11
  62   0.4646     89.210  0.0487    98.310  362.93
  63   0.5003     88.700  0.0429    98.518  368.75
  64   0.4947     88.730  0.0419    98.564  374.63
  65   0.4839     89.190  0.0410    98.664  380.44
  66   0.4668     89.370  0.0383    98.712  386.28
  67   0.4991     89.460  0.0298    99.030  392.11
  68   0.4878     89.230  0.0324    98.914  397.91
  69   0.4994     89.120  0.0292    99.028  403.73
  70   0.5047     89.400  0.0271    99.064  409.51
  71   0.4989     89.050  0.0247    99.158  415.32
  72   0.5028     89.110  0.0259    99.176  421.14
  73   0.4918     89.350  0.0264    99.116  426.96
  74   0.4971     89.400  0.0212    99.294  432.76
  75   0.5041     89.300  0.0215    99.294  438.63
  76   0.5256     89.520  0.0186    99.400  444.42
  77   0.5033     89.590  0.0181    99.416  450.23
  78   0.5152     89.690  0.0178    99.414  456.03
  79   0.5033     89.650  0.0170    99.466  461.85
  80   0.5147     89.810  0.0140    99.584  467.67
  81   0.5496     89.280  0.0143    99.552  473.53
  82   0.5173     89.670  0.0138    99.528  479.34
  83   0.5209     89.410  0.0140    99.530  485.13
  84   0.5299     89.590  0.0134    99.566  490.94
  85   0.5229     89.660  0.0119    99.624  496.77
  86   0.5388     89.690  0.0107    99.672  502.65
  87   0.5425     89.530  0.0113    99.658  508.45
  88   0.5343     89.820  0.0108    99.670  514.28
  89   0.5424     89.760  0.0109    99.684  520.08
  90   0.5586     89.690  0.0102    99.682  525.88
