Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9967     23.130  2.2208    14.522  7.74
   2   1.7049     36.290  1.8153    30.304  13.58
   3   1.3533     48.830  1.5395    41.002  19.39
   4   1.1467     58.030  1.2746    53.096  25.18
   5   0.9840     64.890  1.0650    61.278  30.98
   6   0.8381     70.090  0.9285    66.900  36.83
   7   0.7870     72.270  0.8272    70.958  42.65
   8   0.7203     75.320  0.7521    73.680  48.47
   9   0.6514     77.400  0.6883    76.110  54.26
  10   0.6148     79.000  0.6412    77.704  60.10
  11   0.6032     79.460  0.5976    79.470  65.91
  12   0.5766     80.430  0.5490    81.130  71.75
  13   0.5451     81.960  0.5267    81.940  77.58
  14   0.5203     81.960  0.4945    82.988  83.41
  15   0.4953     83.060  0.4723    83.766  89.21
  16   0.5365     82.070  0.4484    84.716  95.02
  17   0.4890     83.980  0.4276    85.456  100.88
  18   0.4526     84.820  0.3970    86.432  106.69
  19   0.4535     84.940  0.3788    87.020  112.52
  20   0.4561     85.090  0.3664    87.544  118.33
  21   0.4695     84.730  0.3494    88.122  124.14
  22   0.4806     84.040  0.3331    88.734  129.94
  23   0.4396     85.710  0.3211    89.098  135.86
  24   0.4628     84.980  0.3028    89.540  141.66
  25   0.4204     86.120  0.2967    89.896  147.46
  26   0.4956     85.050  0.2754    90.588  153.29
  27   0.4213     86.410  0.2735    90.638  159.11
  28   0.4258     86.380  0.2499    91.388  165.00
  29   0.4091     86.720  0.2423    91.658  170.80
  30   0.4045     87.780  0.2317    91.946  176.64
  31   0.4236     86.870  0.2235    92.318  182.42
  32   0.4368     86.840  0.2181    92.566  188.22
  33   0.4393     86.730  0.2111    92.684  194.02
  34   0.4074     87.420  0.1925    93.492  199.88
  35   0.4367     86.930  0.1827    93.678  205.68
  36   0.4453     87.110  0.1836    93.546  211.50
  37   0.4135     88.070  0.1713    94.070  217.31
  38   0.4357     87.160  0.1579    94.512  223.14
  39   0.4454     87.360  0.1572    94.592  228.93
  40   0.4334     87.830  0.1511    94.748  234.80
  41   0.4395     87.780  0.1408    95.160  240.62
  42   0.4364     88.010  0.1431    94.972  246.42
  43   0.4594     87.390  0.1311    95.494  252.21
  44   0.4514     88.190  0.1195    95.934  258.03
  45   0.4504     88.360  0.1160    95.988  263.84
  46   0.4514     87.440  0.1134    96.108  269.66
  47   0.4239     88.640  0.1066    96.358  275.53
  48   0.4805     88.270  0.1021    96.522  281.34
  49   0.4740     88.310  0.0963    96.658  287.15
  50   0.4764     88.160  0.0950    96.656  292.87
  51   0.4685     88.520  0.0904    96.916  298.70
  52   0.4854     88.610  0.0757    97.396  304.52
  53   0.4912     88.320  0.0762    97.352  310.40
  54   0.4795     88.710  0.0747    97.430  316.20
  55   0.4824     88.810  0.0700    97.566  321.99
  56   0.4968     88.170  0.0658    97.712  327.80
  57   0.5080     88.920  0.0594    97.972  333.60
  58   0.5182     88.620  0.0569    98.072  339.51
  59   0.5465     88.600  0.0544    98.094  345.32
  60   0.5095     88.270  0.0536    98.192  351.13
  61   0.5195     88.440  0.0490    98.308  356.94
  62   0.5217     89.040  0.0440    98.492  362.80
  63   0.5471     88.940  0.0405    98.634  368.61
  64   0.5247     89.290  0.0430    98.494  374.49
  65   0.5278     89.050  0.0385    98.678  380.30
  66   0.5295     89.240  0.0345    98.848  386.11
  67   0.5519     89.330  0.0292    99.014  391.91
  68   0.5501     89.180  0.0287    98.986  397.72
  69   0.5684     89.280  0.0305    98.972  403.53
  70   0.6016     89.260  0.0249    99.106  409.33
  71   0.5813     89.320  0.0258    99.156  415.13
  72   0.5951     89.200  0.0244    99.170  420.96
  73   0.5772     89.490  0.0236    99.224  426.77
  74   0.6162     88.990  0.0190    99.378  432.60
  75   0.6140     89.210  0.0186    99.356  438.48
  76   0.6054     89.280  0.0200    99.348  444.30
  77   0.6182     89.090  0.0183    99.380  450.10
  78   0.6164     89.610  0.0171    99.430  455.93
  79   0.6071     89.610  0.0140    99.542  461.74
  80   0.6302     89.410  0.0138    99.522  467.54
  81   0.6378     89.410  0.0134    99.550  473.41
  82   0.6299     89.600  0.0146    99.482  479.25
  83   0.6351     89.420  0.0148    99.514  485.07
  84   0.6468     89.310  0.0111    99.622  490.86
  85   0.6686     89.490  0.0114    99.622  496.68
  86   0.6665     89.640  0.0111    99.632  502.56
  87   0.6550     89.540  0.0111    99.636  508.36
  88   0.6753     89.500  0.0117    99.596  514.18
  89   0.6636     89.580  0.0112    99.620  519.98
  90   0.6633     89.440  0.0109    99.638  525.80
