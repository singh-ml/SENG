Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9035     25.350  2.1773    16.306  7.62
   2   1.5113     42.700  1.7379    32.804  13.46
   3   1.2645     52.380  1.4316    46.250  19.27
   4   1.0348     62.800  1.1552    57.734  25.11
   5   0.8850     68.910  0.9551    65.810  30.93
   6   0.7629     73.310  0.8468    70.108  36.82
   7   0.6917     76.820  0.7637    73.228  42.67
   8   0.6429     77.950  0.6984    76.022  48.49
   9   0.6780     77.020  0.6377    78.032  54.31
  10   0.5861     80.210  0.5938    79.596  60.12
  11   0.5439     81.980  0.5466    81.122  65.94
  12   0.5670     81.460  0.5195    82.350  71.77
  13   0.5150     82.680  0.4858    83.512  77.58
  14   0.4830     84.040  0.4549    84.508  83.43
  15   0.5297     83.070  0.4277    85.568  89.24
  16   0.4867     84.450  0.4133    85.800  95.05
  17   0.4575     85.150  0.3920    86.704  100.98
  18   0.4882     84.150  0.3704    87.402  106.79
  19   0.4637     84.800  0.3484    88.180  112.59
  20   0.4517     85.210  0.3429    88.392  118.42
  21   0.4711     85.420  0.3183    89.148  124.27
  22   0.4651     85.520  0.3169    89.280  130.11
  23   0.4889     85.060  0.2940    90.006  136.02
  24   0.4291     86.230  0.2737    90.650  141.82
  25   0.4872     85.130  0.2699    90.874  147.64
  26   0.4122     87.100  0.2564    91.324  153.47
  27   0.4175     87.200  0.2416    91.728  159.29
  28   0.4364     86.300  0.2340    91.958  165.19
  29   0.4200     87.490  0.2170    92.522  171.03
  30   0.4234     87.450  0.2095    92.824  176.84
  31   0.4058     87.530  0.2033    93.134  182.64
  32   0.4319     87.290  0.1947    93.406  188.45
  33   0.4429     87.210  0.1812    93.764  194.30
  34   0.4273     87.020  0.1807    93.836  200.19
  35   0.4198     87.610  0.1697    94.144  206.02
  36   0.4069     88.310  0.1614    94.360  211.84
  37   0.4451     87.020  0.1554    94.670  217.65
  38   0.4220     87.780  0.1438    95.076  223.49
  39   0.4280     87.830  0.1419    95.104  229.31
  40   0.4261     88.150  0.1338    95.368  235.17
  41   0.4236     88.200  0.1264    95.664  241.01
  42   0.4384     88.270  0.1236    95.710  246.84
  43   0.4239     88.700  0.1161    96.030  252.68
  44   0.4793     87.510  0.1090    96.204  258.51
  45   0.4381     88.410  0.1034    96.500  264.33
  46   0.4944     87.840  0.1005    96.618  270.27
  47   0.4587     88.600  0.0915    96.886  276.12
  48   0.4542     88.190  0.0901    96.954  281.92
  49   0.4753     88.220  0.0847    97.054  287.76
  50   0.4474     88.830  0.0790    97.394  293.51
  51   0.4585     88.420  0.0763    97.398  299.42
  52   0.4787     88.830  0.0677    97.654  305.25
  53   0.4745     88.490  0.0656    97.760  311.06
  54   0.4764     88.580  0.0618    97.916  316.88
  55   0.5044     88.500  0.0598    98.020  322.69
  56   0.4983     88.980  0.0538    98.182  328.52
  57   0.5037     88.960  0.0502    98.288  334.43
  58   0.5158     89.160  0.0464    98.396  340.25
  59   0.5030     89.120  0.0455    98.434  346.06
  60   0.5311     89.000  0.0407    98.584  351.88
  61   0.5221     89.300  0.0384    98.680  357.70
  62   0.5106     89.450  0.0369    98.782  363.53
  63   0.5154     89.410  0.0376    98.706  369.34
  64   0.5416     89.230  0.0293    98.958  375.20
  65   0.5273     89.290  0.0306    98.962  381.03
  66   0.5720     89.170  0.0277    99.032  386.85
  67   0.5448     89.390  0.0268    99.102  392.69
  68   0.5940     88.990  0.0249    99.152  398.59
  69   0.5570     89.410  0.0247    99.168  404.41
  70   0.5656     89.520  0.0240    99.120  410.23
  71   0.5699     89.380  0.0224    99.228  416.07
  72   0.5650     89.640  0.0192    99.316  421.92
  73   0.5909     89.410  0.0168    99.438  427.76
  74   0.5888     89.650  0.0167    99.430  433.66
  75   0.6083     89.510  0.0164    99.418  439.48
  76   0.5929     89.620  0.0168    99.432  445.31
  77   0.5892     89.770  0.0147    99.552  451.15
  78   0.5980     89.810  0.0130    99.562  456.97
  79   0.6014     89.670  0.0107    99.644  462.80
  80   0.6120     90.030  0.0109    99.604  468.68
  81   0.6260     89.590  0.0110    99.644  474.52
  82   0.6281     89.610  0.0119    99.622  480.36
  83   0.6263     89.610  0.0099    99.674  486.18
  84   0.6270     89.790  0.0099    99.674  492.01
  85   0.6304     89.760  0.0081    99.740  497.89
  86   0.6301     89.840  0.0095    99.704  503.73
  87   0.6395     89.660  0.0085    99.746  509.55
  88   0.6363     89.770  0.0078    99.742  515.36
  89   0.6560     89.360  0.0081    99.760  521.17
  90   0.6465     89.570  0.0075    99.740  527.00
