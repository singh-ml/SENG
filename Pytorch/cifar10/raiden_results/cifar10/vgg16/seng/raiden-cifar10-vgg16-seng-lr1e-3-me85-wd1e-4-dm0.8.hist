Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2685     13.300  2.2947    10.684  7.73
   2   1.9808     26.300  2.1791    17.528  13.56
   3   1.7868     32.530  1.9178    26.702  19.39
   4   1.6738     36.290  1.7507    33.166  25.30
   5   1.5326     42.280  1.6327    37.902  31.11
   6   1.3823     48.050  1.5123    42.824  36.93
   7   1.3373     49.820  1.4217    46.946  42.74
   8   1.2388     54.300  1.3471    49.956  48.58
   9   1.1738     57.310  1.2760    53.012  54.44
  10   1.1650     57.480  1.2034    56.026  60.35
  11   1.0764     61.170  1.1443    58.464  66.19
  12   1.0329     63.390  1.1001    59.748  72.04
  13   0.9779     64.540  1.0422    62.398  77.86
  14   0.9421     65.730  1.0012    63.638  83.70
  15   0.9096     67.300  0.9585    65.340  89.55
  16   0.8833     68.340  0.9223    66.864  95.48
  17   0.8614     69.010  0.8843    67.932  101.30
  18   0.8271     70.180  0.8538    69.434  107.10
  19   0.7768     72.610  0.8250    70.580  112.94
  20   0.7907     72.260  0.7960    71.630  118.78
  21   0.7482     73.860  0.7689    72.530  124.68
  22   0.8057     72.140  0.7478    73.394  130.50
  23   0.7301     74.740  0.7258    74.182  136.31
  24   0.6987     75.940  0.7035    74.930  142.15
  25   0.6927     76.320  0.6936    75.334  147.97
  26   0.6547     76.920  0.6708    76.266  153.79
  27   0.6763     76.890  0.6457    76.888  159.70
  28   0.6504     77.660  0.6341    77.600  165.50
  29   0.6436     77.820  0.6235    78.058  171.31
  30   0.6194     78.380  0.6065    78.630  177.13
  31   0.6129     79.160  0.5937    78.900  182.95
  32   0.6077     79.460  0.5801    79.572  188.85
  33   0.5955     79.900  0.5675    80.056  194.68
  34   0.5656     80.630  0.5544    80.388  200.49
  35   0.5936     79.490  0.5447    80.794  206.31
  36   0.5911     80.340  0.5322    81.216  212.12
  37   0.5642     80.290  0.5218    81.668  217.95
  38   0.5593     80.810  0.5134    82.000  223.86
  39   0.5390     81.060  0.5047    82.400  229.66
  40   0.5510     81.450  0.4927    82.626  235.47
  41   0.5548     80.920  0.4861    82.930  241.29
  42   0.5257     82.220  0.4850    82.970  247.11
  43   0.5714     81.470  0.4640    83.758  252.92
  44   0.5523     81.470  0.4602    83.934  258.83
  45   0.5418     82.250  0.4432    84.346  264.66
  46   0.5251     82.220  0.4452    84.464  270.48
  47   0.5166     82.670  0.4366    84.572  276.31
  48   0.5384     81.900  0.4310    84.758  282.11
  49   0.5102     83.000  0.4159    85.454  287.94
  50   0.5038     83.240  0.4091    85.590  293.74
  51   0.5029     83.360  0.4038    85.782  299.59
  52   0.5012     83.720  0.3988    86.120  305.43
  53   0.5204     82.830  0.3874    86.388  311.26
  54   0.4806     83.750  0.3812    86.744  317.08
  55   0.4995     83.810  0.3734    86.950  322.93
  56   0.4949     83.270  0.3707    87.004  328.81
  57   0.4897     83.520  0.3676    87.168  334.63
  58   0.5012     83.900  0.3567    87.492  340.45
  59   0.4886     84.030  0.3505    87.826  346.27
  60   0.5122     83.470  0.3524    87.642  352.08
  61   0.5100     83.360  0.3462    87.994  358.00
  62   0.5180     83.590  0.3370    88.190  363.81
  63   0.4949     84.410  0.3253    88.624  369.63
  64   0.4960     84.390  0.3275    88.534  375.45
  65   0.5004     84.240  0.3184    88.808  381.28
  66   0.5094     84.090  0.3165    88.936  387.13
  67   0.4889     84.420  0.3129    88.978  392.95
  68   0.4903     84.240  0.3013    89.454  398.80
  69   0.4868     84.170  0.2945    89.600  404.61
  70   0.5074     83.800  0.2884    89.896  410.44
  71   0.5068     84.290  0.2972    89.654  416.25
  72   0.4903     84.600  0.2863    89.990  422.13
  73   0.4981     85.190  0.2762    90.320  427.94
  74   0.4630     85.200  0.2728    90.480  433.78
  75   0.5080     84.650  0.2685    90.592  439.59
  76   0.4998     85.060  0.2692    90.532  445.42
  77   0.5171     84.520  0.2589    91.018  451.23
  78   0.4744     85.270  0.2580    91.096  457.11
  79   0.5008     84.870  0.2475    91.372  462.94
  80   0.4829     85.180  0.2464    91.418  468.78
  81   0.5492     84.250  0.2477    91.274  474.62
  82   0.5083     84.940  0.2393    91.562  480.43
  83   0.4980     85.030  0.2374    91.720  486.24
  84   0.5484     83.890  0.2305    91.968  492.13
  85   0.4993     84.930  0.2262    92.038  497.97
