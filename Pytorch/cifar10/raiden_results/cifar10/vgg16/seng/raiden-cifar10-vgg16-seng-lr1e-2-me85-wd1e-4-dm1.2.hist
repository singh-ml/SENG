Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8135     31.890  2.1294    18.874  7.85
   2   1.5806     39.850  1.6960    35.318  13.68
   3   1.1772     57.190  1.4154    46.814  19.49
   4   1.0444     61.890  1.1775    56.948  25.31
   5   0.9244     67.030  1.0018    63.834  31.12
   6   0.8061     71.500  0.8814    68.204  36.96
   7   0.7874     72.410  0.7868    72.114  42.86
   8   0.6780     76.650  0.7264    74.506  48.68
   9   0.6545     77.830  0.6693    76.754  54.50
  10   0.6464     77.340  0.6268    78.214  60.34
  11   0.6025     79.040  0.5943    79.426  66.17
  12   0.5451     81.730  0.5568    80.836  72.07
  13   0.5520     81.700  0.5251    81.962  77.88
  14   0.5554     81.560  0.4984    82.796  83.71
  15   0.5036     82.980  0.4753    83.624  89.52
  16   0.5041     83.020  0.4520    84.582  95.34
  17   0.4758     83.870  0.4284    85.394  101.25
  18   0.4757     83.550  0.4080    86.028  107.06
  19   0.4745     83.840  0.3923    86.530  112.86
  20   0.4631     84.470  0.3813    86.794  118.69
  21   0.4715     83.800  0.3548    87.804  124.50
  22   0.4722     84.350  0.3473    88.100  130.34
  23   0.4429     85.450  0.3287    88.694  136.15
  24   0.4466     85.530  0.3161    89.114  142.04
  25   0.4131     86.470  0.3024    89.628  147.86
  26   0.4468     85.400  0.2871    90.094  153.70
  27   0.4328     85.950  0.2721    90.666  159.51
  28   0.4130     86.600  0.2693    90.646  165.32
  29   0.4255     85.810  0.2547    91.272  171.17
  30   0.4208     86.120  0.2472    91.450  177.08
  31   0.4202     86.530  0.2326    91.962  182.90
  32   0.4078     86.780  0.2226    92.344  188.71
  33   0.4145     87.150  0.2090    92.836  194.54
  34   0.4476     86.660  0.2136    92.606  200.38
  35   0.4373     86.220  0.1995    93.152  206.20
  36   0.4299     86.580  0.1905    93.606  212.08
  37   0.4104     87.040  0.1802    93.792  217.90
  38   0.4510     86.330  0.1740    93.940  223.72
  39   0.4607     86.670  0.1655    94.232  229.55
  40   0.4915     86.870  0.1606    94.524  235.35
  41   0.4384     87.330  0.1489    94.834  241.22
  42   0.4757     87.020  0.1471    94.924  247.03
  43   0.4796     87.400  0.1380    95.208  252.86
  44   0.4266     87.790  0.1402    95.130  258.68
  45   0.4315     88.120  0.1278    95.674  264.53
  46   0.4625     87.630  0.1187    95.968  270.34
  47   0.4849     87.420  0.1109    96.100  276.25
  48   0.4932     87.890  0.1109    96.176  282.07
  49   0.5000     87.460  0.1005    96.484  287.88
  50   0.4643     87.780  0.0904    96.860  293.65
  51   0.4794     88.000  0.0961    96.686  299.46
  52   0.4773     88.060  0.0913    96.816  305.36
  53   0.5063     87.790  0.0861    97.012  311.17
  54   0.4984     87.750  0.0770    97.312  316.99
  55   0.5176     88.240  0.0741    97.366  322.82
  56   0.5324     87.810  0.0696    97.560  328.63
  57   0.4917     88.250  0.0706    97.602  334.45
  58   0.5144     88.440  0.0570    98.026  340.37
  59   0.5122     88.450  0.0603    97.902  346.20
  60   0.5076     88.520  0.0593    97.968  352.02
  61   0.5370     88.440  0.0557    98.100  357.85
  62   0.5493     88.620  0.0522    98.186  363.67
  63   0.5584     88.510  0.0462    98.384  369.56
  64   0.5581     88.550  0.0441    98.492  375.39
  65   0.5684     88.490  0.0419    98.558  381.20
  66   0.5636     88.570  0.0424    98.526  387.01
  67   0.5642     88.350  0.0365    98.806  392.82
  68   0.5602     88.680  0.0370    98.742  398.64
  69   0.5620     88.710  0.0335    98.844  404.46
  70   0.5998     88.740  0.0304    98.988  410.36
  71   0.5884     88.610  0.0308    98.944  416.17
  72   0.5901     88.650  0.0292    99.032  422.02
  73   0.5957     88.800  0.0255    99.124  427.85
  74   0.6165     88.680  0.0231    99.206  433.65
  75   0.6395     88.580  0.0229    99.232  439.48
  76   0.5921     88.900  0.0233    99.216  445.39
  77   0.6041     88.930  0.0216    99.298  451.20
  78   0.6194     88.830  0.0207    99.340  457.01
  79   0.6253     88.980  0.0202    99.280  462.85
  80   0.6272     88.930  0.0189    99.352  468.68
  81   0.6363     88.830  0.0184    99.298  474.59
  82   0.6431     88.960  0.0190    99.336  480.41
  83   0.6508     88.770  0.0180    99.402  486.25
  84   0.6606     88.780  0.0163    99.444  492.06
  85   0.6416     88.730  0.0174    99.434  497.88
