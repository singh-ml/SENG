Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2955     11.460  2.3007    10.088  7.64
   2   2.2225     17.800  2.2859    12.048  13.47
   3   1.8394     31.360  2.0493    21.494  19.30
   4   1.7008     34.570  1.8095    30.208  25.10
   5   1.5957     39.420  1.6760    35.702  30.98
   6   1.5102     43.260  1.5564    40.848  36.79
   7   1.3858     48.780  1.4658    45.006  42.60
   8   1.2934     52.100  1.3874    48.374  48.40
   9   1.2626     54.260  1.3157    51.312  54.20
  10   1.1353     58.480  1.2424    54.370  60.05
  11   1.0758     61.090  1.1748    57.090  65.96
  12   1.0547     61.970  1.1180    59.390  71.80
  13   0.9830     64.520  1.0682    61.244  77.59
  14   0.9822     64.810  1.0220    63.176  83.40
  15   0.9185     67.020  0.9919    64.282  89.21
  16   0.8902     68.480  0.9449    65.878  95.12
  17   0.8479     69.930  0.9070    67.282  100.95
  18   0.8714     69.330  0.8818    68.304  106.78
  19   0.8083     71.520  0.8439    69.840  112.58
  20   0.7706     72.530  0.8170    71.076  118.40
  21   0.7693     73.240  0.7862    72.040  124.21
  22   0.7643     73.200  0.7707    72.690  130.13
  23   0.7244     74.510  0.7402    73.756  135.94
  24   0.6993     74.940  0.7193    74.418  141.74
  25   0.6715     76.490  0.7019    75.070  147.55
  26   0.6827     76.530  0.6826    75.840  153.39
  27   0.6774     76.600  0.6682    76.314  159.26
  28   0.6521     77.630  0.6539    76.966  165.10
  29   0.6417     77.680  0.6381    77.270  170.93
  30   0.6445     78.250  0.6179    78.362  176.74
  31   0.6450     78.540  0.6125    78.384  182.57
  32   0.6243     78.570  0.5988    78.854  188.37
  33   0.6200     78.840  0.5832    79.614  194.20
  34   0.6194     79.400  0.5753    79.958  200.07
  35   0.5869     80.140  0.5636    80.158  205.91
  36   0.5833     79.790  0.5531    80.666  211.71
  37   0.6001     80.090  0.5414    80.796  217.51
  38   0.5752     80.450  0.5320    81.198  223.34
  39   0.5748     80.300  0.5176    81.716  229.15
  40   0.5559     81.370  0.5087    82.160  235.04
  41   0.5468     81.340  0.5041    82.274  240.86
  42   0.5575     81.580  0.4960    82.538  246.69
  43   0.5795     80.450  0.4813    83.002  252.51
  44   0.5588     81.380  0.4740    83.406  258.31
  45   0.5372     82.150  0.4674    83.534  264.17
  46   0.5331     82.190  0.4603    83.886  270.09
  47   0.5329     82.140  0.4491    84.332  275.90
  48   0.5591     81.810  0.4419    84.582  281.70
  49   0.5226     82.770  0.4334    84.690  287.53
  50   0.5521     81.910  0.4282    85.010  293.29
  51   0.5300     82.520  0.4258    85.164  299.23
  52   0.5617     81.750  0.4116    85.734  305.03
  53   0.5106     83.130  0.4074    85.810  310.83
  54   0.5157     82.610  0.4043    85.864  316.65
  55   0.5301     82.390  0.3948    86.336  322.48
  56   0.4991     83.300  0.3890    86.406  328.30
  57   0.5087     83.610  0.3803    86.706  334.20
  58   0.4923     83.800  0.3773    86.870  340.01
  59   0.5101     83.630  0.3649    87.272  345.82
  60   0.5006     83.680  0.3625    87.290  351.65
  61   0.4955     83.950  0.3567    87.380  357.46
  62   0.5039     83.690  0.3467    87.768  363.34
  63   0.5282     83.200  0.3381    88.146  369.16
  64   0.4988     83.910  0.3415    88.178  374.97
  65   0.4912     83.760  0.3343    88.516  380.79
  66   0.5078     83.130  0.3272    88.480  386.61
  67   0.4987     84.580  0.3243    88.598  392.41
  68   0.4886     84.460  0.3170    88.908  398.29
  69   0.4917     84.130  0.3082    89.126  404.12
  70   0.5195     84.310  0.3054    89.480  409.93
  71   0.4980     84.840  0.2991    89.380  415.75
  72   0.5050     84.500  0.2970    89.560  421.56
  73   0.5276     83.890  0.2873    89.978  427.43
  74   0.4810     84.780  0.2917    89.952  433.26
  75   0.4852     84.830  0.2831    90.030  439.06
  76   0.4870     84.560  0.2815    90.056  444.91
  77   0.4890     84.940  0.2790    90.228  450.73
  78   0.4934     84.720  0.2690    90.524  456.54
  79   0.5169     84.290  0.2608    90.902  462.41
  80   0.5428     83.890  0.2622    90.708  468.23
  81   0.4892     84.900  0.2532    91.128  474.06
  82   0.5090     84.510  0.2508    91.216  479.87
  83   0.5138     84.770  0.2429    91.486  485.72
  84   0.5096     84.850  0.2429    91.502  491.53
  85   0.5116     85.450  0.2424    91.516  497.40
