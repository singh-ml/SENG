Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9473     22.670  2.2218    14.730  7.62
   2   1.6859     33.420  1.8811    25.268  13.51
   3   1.6215     41.990  1.6101    37.648  19.31
   4   1.0686     61.460  1.3171    51.262  25.15
   5   1.0187     65.990  1.0610    62.948  30.96
   6   0.8065     72.910  0.9049    68.782  36.78
   7   0.7456     75.830  0.7947    73.080  42.59
   8   0.6339     79.290  0.7202    76.050  48.52
   9   0.7422     75.370  0.6425    78.576  54.33
  10   0.5717     81.230  0.6081    79.956  60.16
  11   0.5937     81.080  0.5591    81.714  65.99
  12   0.6062     80.960  0.5061    83.318  71.82
  13   0.5404     82.860  0.4799    84.376  77.68
  14   0.5052     83.610  0.4441    85.114  83.61
  15   0.5741     81.760  0.4259    86.242  89.45
  16   0.4986     83.860  0.4079    86.714  95.28
  17   0.4721     85.210  0.3830    87.268  101.11
  18   0.4622     85.290  0.3573    88.288  106.92
  19   0.4631     85.110  0.3486    88.438  112.83
  20   0.4292     86.630  0.3221    89.416  118.64
  21   0.4644     85.630  0.3086    89.776  124.48
  22   0.4578     85.830  0.2994    90.256  130.29
  23   0.4223     87.080  0.2755    90.898  136.12
  24   0.4023     87.590  0.2698    91.076  141.95
  25   0.4329     86.880  0.2526    91.806  147.90
  26   0.3997     87.290  0.2428    92.080  153.74
  27   0.4109     87.900  0.2274    92.378  159.58
  28   0.3999     88.050  0.2132    92.948  165.40
  29   0.4410     87.000  0.2107    92.956  171.23
  30   0.4523     86.420  0.2015    93.326  177.16
  31   0.3915     88.510  0.1898    93.600  182.98
  32   0.4027     88.380  0.1670    94.476  188.83
  33   0.3982     88.370  0.1751    94.238  194.69
  34   0.4219     88.380  0.1550    94.824  200.55
  35   0.4011     88.460  0.1484    95.074  206.42
  36   0.4263     88.240  0.1425    95.272  212.23
  37   0.4035     88.870  0.1283    95.668  218.04
  38   0.4067     88.930  0.1294    95.664  223.85
  39   0.3823     89.210  0.1191    95.990  229.67
  40   0.3955     89.820  0.1118    96.350  235.50
  41   0.3968     89.090  0.1018    96.712  241.34
  42   0.3817     89.620  0.0971    96.752  247.23
  43   0.4485     89.300  0.0930    96.898  253.06
  44   0.4243     89.300  0.0890    97.082  258.91
  45   0.4603     89.170  0.0751    97.456  264.72
  46   0.4197     89.490  0.0766    97.480  270.54
  47   0.4287     89.870  0.0690    97.768  276.38
  48   0.4035     90.080  0.0674    97.740  282.24
  49   0.4041     89.810  0.0593    98.010  288.06
  50   0.4172     89.870  0.0569    98.138  293.82
  51   0.4504     90.230  0.0498    98.358  299.68
  52   0.4306     90.330  0.0453    98.504  305.53
  53   0.4603     89.920  0.0404    98.694  311.38
  54   0.4372     90.190  0.0402    98.656  317.23
  55   0.4502     90.350  0.0366    98.772  323.05
  56   0.4713     90.570  0.0313    98.966  328.87
  57   0.4873     89.910  0.0317    98.930  334.69
  58   0.4834     90.480  0.0271    99.102  340.51
  59   0.4791     90.400  0.0251    99.180  346.40
  60   0.4935     90.550  0.0208    99.296  352.23
  61   0.4955     90.410  0.0206    99.348  358.06
  62   0.4943     90.790  0.0180    99.388  363.87
  63   0.4895     90.590  0.0177    99.426  369.69
  64   0.5212     90.580  0.0147    99.558  375.52
  65   0.5007     90.770  0.0132    99.572  381.37
  66   0.4966     90.540  0.0127    99.554  387.20
  67   0.5047     90.980  0.0121    99.628  393.05
  68   0.5086     90.740  0.0111    99.664  398.87
  69   0.5274     90.740  0.0092    99.720  404.72
  70   0.5171     90.710  0.0090    99.718  410.60
  71   0.5210     91.040  0.0068    99.774  416.42
  72   0.5333     90.780  0.0060    99.808  422.26
  73   0.5418     90.800  0.0062    99.798  428.07
  74   0.5383     91.060  0.0059    99.820  433.89
  75   0.5442     91.050  0.0052    99.850  439.74
  76   0.5411     91.190  0.0057    99.812  445.66
  77   0.5523     90.960  0.0050    99.850  451.49
  78   0.5487     91.040  0.0046    99.856  457.32
  79   0.5559     91.050  0.0043    99.866  463.13
  80   0.5544     91.070  0.0040    99.876  468.97
  81   0.5544     91.140  0.0042    99.862  474.79
  82   0.5541     91.070  0.0056    99.836  480.73
  83   0.5479     91.250  0.0040    99.884  486.59
  84   0.5509     91.170  0.0036    99.880  492.42
  85   0.5518     91.210  0.0042    99.878  498.24
