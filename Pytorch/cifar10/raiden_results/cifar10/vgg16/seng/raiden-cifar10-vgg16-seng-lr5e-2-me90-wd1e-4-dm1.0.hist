Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2764     11.290  2.1509    17.388  7.66
   2   1.8621     27.720  2.0294    20.502  13.48
   3   1.6302     35.660  1.7586    31.154  19.32
   4   1.4989     47.590  1.4824    44.310  25.14
   5   1.1289     61.990  1.1859    57.558  30.98
   6   0.9431     67.360  0.9887    65.766  36.81
   7   0.8621     72.340  0.8712    70.568  42.70
   8   0.8265     72.710  0.7644    74.264  48.54
   9   0.6443     78.580  0.7018    76.706  54.35
  10   0.6371     79.150  0.6314    78.992  60.21
  11   0.5982     80.770  0.5784    80.760  66.03
  12   0.5861     80.460  0.5509    81.794  71.91
  13   0.5987     80.440  0.5141    83.174  77.73
  14   0.5148     83.400  0.4852    84.258  83.57
  15   0.5516     82.460  0.4509    85.336  89.41
  16   0.4876     84.300  0.4334    85.762  95.23
  17   0.4929     84.630  0.4095    86.630  101.07
  18   0.4786     84.600  0.3931    87.400  106.95
  19   0.4429     85.840  0.3726    87.864  112.79
  20   0.4525     85.550  0.3458    88.566  118.61
  21   0.4710     85.140  0.3286    89.196  124.46
  22   0.5259     85.530  0.3276    89.224  130.29
  23   0.4384     85.920  0.3280    89.134  136.18
  24   0.4502     86.540  0.2848    90.674  142.01
  25   0.4430     86.310  0.2752    91.024  147.86
  26   0.4287     86.580  0.2576    91.478  153.69
  27   0.4203     87.320  0.2442    91.954  159.51
  28   0.4545     87.140  0.2380    91.978  165.34
  29   0.4119     87.370  0.2357    92.144  171.22
  30   0.4082     87.820  0.2205    92.860  177.05
  31   0.4079     87.690  0.2007    93.330  182.87
  32   0.3827     88.300  0.1982    93.382  188.72
  33   0.4293     87.320  0.1892    93.672  194.56
  34   0.4335     87.360  0.1749    94.156  200.40
  35   0.3770     88.530  0.1698    94.330  206.33
  36   0.4132     88.140  0.1593    94.616  212.16
  37   0.3916     88.140  0.1556    94.878  218.02
  38   0.4003     88.640  0.1517    94.912  223.84
  39   0.4463     88.150  0.1380    95.308  229.69
  40   0.3725     88.910  0.1351    95.534  235.55
  41   0.4293     88.480  0.1232    95.782  241.37
  42   0.4013     88.710  0.1150    96.092  247.19
  43   0.4339     88.870  0.1117    96.260  253.01
  44   0.4186     89.420  0.1048    96.592  258.84
  45   0.4165     88.900  0.0956    96.822  264.67
  46   0.4480     88.380  0.0962    96.862  270.57
  47   0.3962     89.530  0.0837    97.200  276.40
  48   0.4057     89.780  0.0787    97.396  282.23
  49   0.4436     89.290  0.0781    97.320  288.03
  50   0.4468     88.950  0.0721    97.646  293.80
  51   0.4221     89.390  0.0711    97.646  299.65
  52   0.4420     89.310  0.0655    97.762  305.56
  53   0.4793     89.390  0.0547    98.158  311.37
  54   0.4713     89.590  0.0530    98.180  317.19
  55   0.4485     89.840  0.0508    98.302  323.04
  56   0.4413     89.540  0.0457    98.540  328.87
  57   0.4980     89.540  0.0405    98.694  334.74
  58   0.4715     89.310  0.0401    98.708  340.56
  59   0.4733     89.590  0.0336    98.900  346.39
  60   0.4798     89.610  0.0329    98.914  352.23
  61   0.4792     89.830  0.0309    98.970  358.07
  62   0.4927     90.060  0.0257    99.154  363.92
  63   0.5012     90.020  0.0240    99.236  369.85
  64   0.5182     89.670  0.0227    99.282  375.68
  65   0.5136     90.030  0.0202    99.316  381.53
  66   0.5056     90.230  0.0194    99.330  387.36
  67   0.5229     89.690  0.0192    99.348  393.18
  68   0.5271     89.990  0.0154    99.500  399.00
  69   0.5257     90.120  0.0143    99.512  404.90
  70   0.5340     90.020  0.0131    99.564  410.72
  71   0.5439     90.120  0.0124    99.590  416.53
  72   0.5360     90.260  0.0101    99.680  422.37
  73   0.5300     90.530  0.0100    99.678  428.18
  74   0.5528     90.410  0.0094    99.710  434.03
  75   0.5492     90.410  0.0077    99.758  439.94
  76   0.5511     90.190  0.0071    99.788  445.75
  77   0.5613     90.280  0.0061    99.798  451.59
  78   0.5537     90.380  0.0057    99.820  457.45
  79   0.5715     90.310  0.0062    99.786  463.29
  80   0.5691     90.350  0.0063    99.792  469.12
  81   0.5662     90.530  0.0045    99.850  475.02
  82   0.5639     90.510  0.0050    99.854  480.84
  83   0.5649     90.640  0.0049    99.844  486.65
  84   0.5659     90.570  0.0046    99.846  492.49
  85   0.5647     90.480  0.0049    99.850  498.30
  86   0.5712     90.640  0.0035    99.876  504.18
  87   0.5775     90.500  0.0035    99.904  510.00
  88   0.5830     90.420  0.0034    99.898  515.86
  89   0.5799     90.500  0.0034    99.892  521.70
  90   0.5802     90.500  0.0044    99.862  527.57
