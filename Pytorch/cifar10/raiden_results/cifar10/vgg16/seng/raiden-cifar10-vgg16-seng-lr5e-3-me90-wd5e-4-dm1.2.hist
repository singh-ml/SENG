Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0308     23.150  2.2228    14.128  8.16
   2   1.6620     35.800  1.9002    27.238  14.07
   3   1.4310     46.180  1.6090    38.640  19.90
   4   1.2497     53.880  1.4174    46.780  25.71
   5   1.0952     60.440  1.2394    54.504  31.55
   6   1.0214     63.600  1.1058    60.006  37.36
   7   0.9390     66.140  1.0178    63.276  43.19
   8   0.8588     68.880  0.9343    66.242  49.07
   9   0.8370     70.250  0.8641    68.928  54.92
  10   0.7610     73.070  0.8085    71.194  60.77
  11   0.7037     75.270  0.7621    73.070  66.58
  12   0.7369     74.790  0.7102    74.916  72.42
  13   0.6566     77.030  0.6675    76.424  78.30
  14   0.6140     79.080  0.6366    77.748  84.13
  15   0.6265     78.870  0.6078    78.702  89.97
  16   0.5974     79.750  0.5838    79.696  95.79
  17   0.6004     79.730  0.5593    80.598  101.60
  18   0.5648     81.190  0.5411    81.210  107.42
  19   0.5696     81.080  0.5218    81.812  113.25
  20   0.5514     81.040  0.4996    82.662  119.09
  21   0.5284     82.360  0.4800    83.298  124.92
  22   0.5213     82.480  0.4709    83.650  130.74
  23   0.5035     83.360  0.4500    84.410  136.55
  24   0.5085     82.780  0.4294    85.210  142.48
  25   0.4880     83.450  0.4170    85.720  148.30
  26   0.4873     83.290  0.4044    86.066  154.10
  27   0.4744     83.660  0.3916    86.360  159.96
  28   0.4759     84.420  0.3810    86.990  165.79
  29   0.4468     85.060  0.3638    87.410  171.59
  30   0.4843     84.120  0.3555    87.826  177.48
  31   0.4392     85.460  0.3425    88.268  183.30
  32   0.4763     84.730  0.3330    88.554  189.11
  33   0.4584     84.980  0.3201    88.960  194.93
  34   0.4442     85.640  0.3156    89.092  200.76
  35   0.4586     85.260  0.2999    89.714  206.58
  36   0.4411     85.830  0.2883    90.044  212.45
  37   0.4420     85.420  0.2808    90.294  218.29
  38   0.4608     85.190  0.2810    90.272  224.10
  39   0.4213     86.630  0.2655    90.740  229.94
  40   0.4257     86.720  0.2578    91.148  235.76
  41   0.4404     86.080  0.2445    91.582  241.57
  42   0.4229     86.400  0.2348    92.028  247.45
  43   0.4748     85.630  0.2325    91.950  253.31
  44   0.4136     86.460  0.2314    92.014  259.14
  45   0.4639     86.000  0.2168    92.430  264.95
  46   0.4160     86.960  0.2070    92.846  270.77
  47   0.4351     86.270  0.2051    92.868  276.70
  48   0.4362     86.920  0.1975    93.212  282.52
  49   0.4405     86.960  0.1906    93.340  288.35
  50   0.4272     86.920  0.1857    93.562  294.10
  51   0.4304     87.110  0.1789    93.850  299.93
  52   0.4271     86.990  0.1725    94.014  305.76
  53   0.4391     87.270  0.1643    94.320  311.70
  54   0.4311     87.170  0.1639    94.318  317.54
  55   0.4372     87.180  0.1568    94.550  323.36
  56   0.4451     87.290  0.1468    94.916  329.20
  57   0.4429     87.380  0.1491    94.868  335.04
  58   0.4380     87.410  0.1383    95.254  340.95
  59   0.4624     87.550  0.1356    95.354  346.81
  60   0.4610     87.540  0.1268    95.698  352.61
  61   0.4725     87.120  0.1324    95.390  358.42
  62   0.4889     87.050  0.1238    95.804  364.25
  63   0.4664     87.880  0.1173    95.862  370.07
  64   0.4503     87.800  0.1109    96.142  375.97
  65   0.4591     87.610  0.1085    96.302  381.81
  66   0.4505     87.790  0.1050    96.306  387.63
  67   0.4559     87.890  0.0976    96.704  393.47
  68   0.4686     87.800  0.0983    96.722  399.32
  69   0.4763     87.850  0.0909    96.822  405.15
  70   0.4897     88.020  0.0875    97.004  411.04
  71   0.4772     88.020  0.0862    97.010  416.87
  72   0.4898     87.770  0.0839    97.088  422.70
  73   0.5098     87.540  0.0819    97.150  428.50
  74   0.4801     88.280  0.0771    97.358  434.32
  75   0.4854     88.100  0.0776    97.306  440.15
  76   0.4930     88.040  0.0733    97.546  446.04
  77   0.4931     88.080  0.0687    97.598  451.88
  78   0.5095     87.760  0.0668    97.682  457.68
  79   0.5023     87.850  0.0691    97.616  463.51
  80   0.5259     87.800  0.0639    97.728  469.36
  81   0.5085     88.260  0.0597    97.956  475.18
  82   0.5005     88.270  0.0649    97.822  481.02
  83   0.4997     88.060  0.0571    98.080  486.82
  84   0.5239     88.410  0.0549    98.154  492.66
  85   0.5057     88.350  0.0574    98.024  498.48
  86   0.5004     88.440  0.0545    98.104  504.30
  87   0.5081     88.480  0.0520    98.182  510.22
  88   0.5176     88.240  0.0523    98.258  516.08
  89   0.5644     87.830  0.0495    98.324  521.93
  90   0.5078     88.120  0.0491    98.268  527.74
