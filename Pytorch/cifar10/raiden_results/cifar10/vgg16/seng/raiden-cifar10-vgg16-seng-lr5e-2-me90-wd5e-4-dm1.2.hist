Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1522     17.060  2.2636    13.862  7.85
   2   1.8354     27.290  1.9821    23.344  13.66
   3   1.6208     37.380  1.7524    32.524  19.47
   4   1.3520     49.440  1.5474    41.582  25.32
   5   1.1699     57.250  1.3079    52.412  31.18
   6   1.0500     62.460  1.1082    60.674  37.00
   7   0.8852     69.260  0.9474    66.882  42.91
   8   0.8858     70.080  0.8534    70.744  48.73
   9   0.7450     75.330  0.7667    74.064  54.55
  10   0.6800     78.320  0.7212    75.792  60.37
  11   0.6194     79.580  0.6621    77.924  66.21
  12   0.6216     79.270  0.6296    78.938  72.02
  13   0.5934     80.480  0.5846    80.490  77.90
  14   0.6039     80.170  0.5577    81.420  83.72
  15   0.5255     82.880  0.5342    82.540  89.54
  16   0.5485     82.520  0.5084    83.248  95.35
  17   0.5943     81.490  0.4847    84.032  101.20
  18   0.5097     83.200  0.4594    84.910  107.11
  19   0.5210     82.840  0.4452    85.050  112.96
  20   0.5021     83.560  0.4232    85.972  118.82
  21   0.4554     85.170  0.4087    86.418  124.64
  22   0.4645     84.620  0.4037    86.504  130.48
  23   0.4435     86.120  0.3668    87.920  136.32
  24   0.4532     85.520  0.3626    87.944  142.21
  25   0.4572     85.070  0.3552    88.154  148.04
  26   0.4257     86.570  0.3468    88.558  153.87
  27   0.4332     85.810  0.3402    88.644  159.69
  28   0.4484     84.890  0.3264    89.170  165.51
  29   0.4479     86.000  0.3077    89.652  171.35
  30   0.4371     86.540  0.2942    90.240  177.16
  31   0.4693     85.680  0.2951    90.096  182.96
  32   0.4179     86.600  0.2724    90.980  188.83
  33   0.3986     87.290  0.2838    90.624  194.65
  34   0.4187     86.780  0.2707    90.972  200.50
  35   0.4171     86.960  0.2562    91.518  206.31
  36   0.3879     87.830  0.2462    91.736  212.23
  37   0.4120     87.530  0.2300    92.202  218.09
  38   0.3836     88.230  0.2297    92.312  223.93
  39   0.3866     87.590  0.2229    92.558  229.74
  40   0.3750     88.800  0.2056    93.070  235.59
  41   0.3979     87.740  0.2046    93.088  241.42
  42   0.3846     87.710  0.1909    93.596  247.34
  43   0.3969     88.180  0.1856    93.696  253.18
  44   0.3896     88.410  0.1808    93.906  258.99
  45   0.4023     88.170  0.1723    94.122  264.83
  46   0.3783     88.480  0.1562    94.614  270.67
  47   0.4167     87.760  0.1621    94.424  276.52
  48   0.3971     88.580  0.1497    94.944  282.42
  49   0.3835     88.790  0.1471    95.068  288.24
  50   0.3758     89.050  0.1326    95.498  293.99
  51   0.3969     88.600  0.1257    95.688  299.83
  52   0.3740     89.700  0.1228    95.838  305.67
  53   0.3858     89.000  0.1120    96.162  311.49
  54   0.3896     89.030  0.1104    96.122  317.40
  55   0.3772     89.400  0.1067    96.374  323.25
  56   0.4078     89.350  0.0976    96.622  329.09
  57   0.3813     89.440  0.0845    97.110  334.91
  58   0.3952     89.290  0.0846    97.138  340.73
  59   0.3774     89.770  0.0819    97.264  346.62
  60   0.3834     89.590  0.0724    97.478  352.46
  61   0.3779     90.270  0.0634    97.902  358.29
  62   0.3999     90.030  0.0606    98.002  364.13
  63   0.3869     90.350  0.0586    98.028  369.95
  64   0.3884     90.250  0.0531    98.184  375.80
  65   0.3963     90.210  0.0447    98.452  381.71
  66   0.4262     89.940  0.0439    98.554  387.53
  67   0.3978     90.460  0.0436    98.516  393.36
  68   0.4054     90.550  0.0330    98.926  399.18
  69   0.4194     90.350  0.0311    98.908  405.02
  70   0.4322     90.060  0.0263    99.066  410.88
  71   0.4322     90.550  0.0250    99.142  416.70
  72   0.4182     90.830  0.0215    99.304  422.52
  73   0.4242     90.630  0.0206    99.352  428.35
  74   0.4299     90.780  0.0185    99.414  434.17
  75   0.4280     90.840  0.0153    99.462  439.97
  76   0.4251     91.050  0.0135    99.540  445.85
  77   0.4279     91.060  0.0133    99.560  451.66
  78   0.4208     91.140  0.0110    99.694  457.48
  79   0.4304     91.030  0.0104    99.688  463.28
  80   0.4271     91.280  0.0086    99.752  469.11
  81   0.4214     91.320  0.0083    99.758  474.94
  82   0.4271     91.370  0.0077    99.772  480.84
  83   0.4332     91.280  0.0072    99.770  486.65
  84   0.4330     91.220  0.0065    99.828  492.48
  85   0.4293     91.250  0.0067    99.816  498.30
  86   0.4324     91.200  0.0064    99.816  504.10
  87   0.4322     91.250  0.0057    99.852  509.94
  88   0.4340     91.130  0.0052    99.876  515.84
  89   0.4345     91.120  0.0054    99.856  521.71
  90   0.4393     91.130  0.0058    99.836  527.57
