Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8634     26.230  2.1061    18.176  7.72
   2   1.4813     44.550  1.7004    33.446  13.54
   3   1.2386     54.920  1.3930    48.688  19.37
   4   0.9784     65.710  1.1084    60.702  25.19
   5   0.8574     70.650  0.9404    66.974  31.01
   6   0.7473     75.190  0.8209    71.926  36.86
   7   0.6653     77.490  0.7226    75.568  42.68
   8   0.6591     78.290  0.6603    77.928  48.50
   9   0.6503     79.290  0.6026    80.004  54.39
  10   0.5627     82.090  0.5643    81.192  60.21
  11   0.5563     82.210  0.5212    82.814  66.03
  12   0.5699     81.660  0.4955    83.506  71.85
  13   0.4927     83.760  0.4618    84.638  77.66
  14   0.4733     84.870  0.4373    85.442  83.48
  15   0.4692     85.400  0.3999    86.774  89.36
  16   0.4691     85.030  0.3781    87.420  95.18
  17   0.4464     85.640  0.3621    87.866  101.01
  18   0.4330     85.820  0.3450    88.684  106.82
  19   0.4492     85.860  0.3259    89.106  112.64
  20   0.4096     86.880  0.3072    89.652  118.54
  21   0.4268     86.730  0.2999    89.980  124.37
  22   0.4318     86.460  0.2811    90.702  130.19
  23   0.4100     87.790  0.2725    90.994  136.03
  24   0.4065     87.460  0.2537    91.482  141.86
  25   0.4352     86.890  0.2430    91.804  147.67
  26   0.4280     87.080  0.2388    91.936  153.57
  27   0.4290     87.220  0.2224    92.722  159.39
  28   0.4162     87.430  0.2089    93.052  165.24
  29   0.3750     88.750  0.2029    93.242  171.09
  30   0.3942     88.390  0.1974    93.476  176.92
  31   0.3850     88.340  0.1807    93.890  182.78
  32   0.4027     88.780  0.1735    94.132  188.61
  33   0.3681     89.210  0.1605    94.560  194.43
  34   0.3708     89.220  0.1561    94.904  200.26
  35   0.4041     88.620  0.1453    95.124  206.09
  36   0.3847     89.070  0.1399    95.306  211.90
  37   0.3913     88.980  0.1320    95.604  217.78
  38   0.4101     89.070  0.1284    95.734  223.61
  39   0.4227     88.540  0.1208    96.018  229.43
  40   0.3914     89.670  0.1099    96.304  235.26
  41   0.4304     88.870  0.1031    96.556  241.10
  42   0.4144     89.820  0.0938    96.860  246.93
  43   0.4204     89.340  0.0903    96.936  252.83
  44   0.4338     89.470  0.0898    96.952  258.69
  45   0.4045     89.660  0.0763    97.416  264.51
  46   0.4123     89.400  0.0761    97.434  270.32
  47   0.4074     89.620  0.0692    97.654  276.17
  48   0.4317     89.870  0.0655    97.828  281.97
  49   0.4243     89.740  0.0609    97.958  287.89
  50   0.4261     89.820  0.0555    98.074  293.63
  51   0.4240     89.810  0.0529    98.212  299.47
  52   0.4423     90.010  0.0425    98.568  305.28
  53   0.4481     90.080  0.0444    98.534  311.14
  54   0.4460     89.930  0.0403    98.652  316.97
  55   0.4569     89.720  0.0367    98.770  322.86
  56   0.4391     90.160  0.0356    98.826  328.67
  57   0.4488     90.410  0.0308    98.960  334.52
  58   0.4388     90.640  0.0304    98.968  340.35
  59   0.4534     90.160  0.0236    99.218  346.20
  60   0.4601     90.630  0.0212    99.310  352.10
  61   0.4743     90.760  0.0182    99.390  357.91
  62   0.4672     90.960  0.0169    99.456  363.76
  63   0.4745     90.540  0.0168    99.482  369.57
  64   0.4992     90.730  0.0136    99.528  375.39
  65   0.4739     91.040  0.0125    99.592  381.20
  66   0.4900     90.700  0.0100    99.690  387.09
  67   0.4890     90.940  0.0109    99.638  392.91
  68   0.4779     90.780  0.0098    99.690  398.74
  69   0.4949     90.730  0.0078    99.748  404.56
  70   0.4877     90.910  0.0067    99.774  410.39
  71   0.4956     90.920  0.0061    99.838  416.21
  72   0.4901     91.160  0.0053    99.844  422.10
  73   0.4872     91.110  0.0053    99.842  427.93
  74   0.4923     91.290  0.0041    99.884  433.76
  75   0.4907     91.220  0.0044    99.874  439.57
  76   0.4949     91.090  0.0034    99.906  445.40
  77   0.4934     91.160  0.0038    99.888  451.21
  78   0.4975     91.190  0.0033    99.906  457.13
  79   0.4920     91.380  0.0035    99.904  462.95
  80   0.4902     91.340  0.0031    99.898  468.79
  81   0.4923     91.360  0.0026    99.926  474.64
  82   0.4963     91.220  0.0029    99.918  480.45
  83   0.4943     91.280  0.0027    99.928  486.28
  84   0.4968     91.160  0.0027    99.926  492.19
  85   0.4968     91.170  0.0026    99.934  498.04
