Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9010     29.000  2.1772    16.842  7.81
   2   1.5313     42.660  1.7441    33.380  13.64
   3   1.3716     48.990  1.5062    43.234  19.44
   4   1.2013     56.480  1.3221    51.366  25.25
   5   1.0147     63.880  1.1390    58.690  31.06
   6   0.9366     66.510  1.0283    62.552  36.88
   7   0.8605     69.650  0.9251    66.766  42.79
   8   0.7710     73.320  0.8525    69.694  48.62
   9   0.7820     72.290  0.7788    72.326  54.46
  10   0.6725     76.710  0.7252    74.500  60.30
  11   0.6772     76.980  0.6791    76.312  66.11
  12   0.6729     76.810  0.6393    77.676  71.93
  13   0.6108     79.220  0.6165    78.460  77.83
  14   0.6434     79.110  0.5712    80.064  83.69
  15   0.5971     79.840  0.5576    80.570  89.53
  16   0.5808     80.660  0.5276    81.796  95.36
  17   0.5416     81.590  0.5060    82.486  101.20
  18   0.5407     81.350  0.4885    83.228  107.12
  19   0.5159     82.860  0.4744    83.582  112.94
  20   0.4910     83.650  0.4505    84.294  118.80
  21   0.5232     82.420  0.4338    85.108  124.59
  22   0.4842     83.490  0.4195    85.476  130.42
  23   0.4867     83.330  0.4010    86.302  136.24
  24   0.4766     84.110  0.3851    86.746  142.13
  25   0.4826     83.700  0.3749    87.198  147.97
  26   0.5010     83.200  0.3624    87.574  153.81
  27   0.4798     84.210  0.3402    88.198  159.63
  28   0.4452     85.290  0.3373    88.482  165.44
  29   0.4566     84.900  0.3249    88.762  171.32
  30   0.4700     84.630  0.3148    89.202  177.17
  31   0.4586     85.060  0.2972    89.726  182.99
  32   0.4510     86.020  0.2867    90.214  188.82
  33   0.4385     85.670  0.2825    90.208  194.66
  34   0.4439     85.930  0.2726    90.596  200.50
  35   0.4325     86.180  0.2658    90.800  206.36
  36   0.4727     85.460  0.2538    91.226  212.18
  37   0.4608     85.740  0.2375    91.848  218.02
  38   0.4528     86.310  0.2343    91.884  223.83
  39   0.4420     86.490  0.2332    91.964  229.69
  40   0.4610     86.570  0.2196    92.416  235.64
  41   0.4452     86.510  0.2135    92.702  241.45
  42   0.4683     86.410  0.2022    93.022  247.29
  43   0.4532     86.690  0.1976    93.184  253.10
  44   0.4618     86.130  0.1872    93.580  258.91
  45   0.4451     86.970  0.1893    93.408  264.72
  46   0.4493     86.990  0.1746    93.922  270.63
  47   0.4605     86.650  0.1657    94.306  276.48
  48   0.4367     87.290  0.1623    94.292  282.29
  49   0.4803     86.420  0.1551    94.550  288.14
  50   0.4817     86.950  0.1503    94.842  293.89
  51   0.4909     86.450  0.1439    95.000  299.72
  52   0.4601     87.280  0.1453    94.984  305.62
  53   0.4951     87.040  0.1341    95.224  311.42
  54   0.4801     87.530  0.1330    95.370  317.25
  55   0.4893     87.320  0.1269    95.598  323.09
  56   0.4832     87.340  0.1163    95.962  328.94
  57   0.5030     87.570  0.1128    96.074  334.75
  58   0.5197     87.210  0.1112    96.192  340.62
  59   0.5289     86.890  0.1043    96.400  346.47
  60   0.5121     86.940  0.1041    96.454  352.28
  61   0.5138     86.830  0.0963    96.682  358.11
  62   0.5082     87.240  0.0933    96.844  363.96
  63   0.5303     87.160  0.0874    97.046  369.77
  64   0.5513     87.210  0.0882    96.924  375.64
  65   0.5583     87.430  0.0817    97.134  381.48
  66   0.5576     87.480  0.0772    97.312  387.27
  67   0.5278     87.450  0.0775    97.366  393.09
  68   0.5567     87.620  0.0764    97.416  398.93
  69   0.5784     87.070  0.0735    97.416  404.81
  70   0.5478     87.370  0.0673    97.674  410.63
  71   0.5552     87.130  0.0665    97.720  416.47
  72   0.5453     87.770  0.0667    97.656  422.30
  73   0.5773     87.670  0.0586    98.042  428.11
  74   0.5657     87.600  0.0570    98.050  433.93
  75   0.5885     87.390  0.0557    98.052  439.81
  76   0.5936     88.010  0.0578    97.962  445.65
  77   0.5963     87.810  0.0538    98.168  451.47
  78   0.5991     87.790  0.0541    98.172  457.28
  79   0.5798     87.880  0.0545    98.132  463.12
  80   0.6012     87.900  0.0482    98.288  468.96
  81   0.5848     87.810  0.0490    98.340  474.91
  82   0.5932     87.730  0.0477    98.328  480.75
  83   0.6121     87.840  0.0475    98.374  486.56
  84   0.5984     87.850  0.0464    98.412  492.38
  85   0.5943     87.650  0.0464    98.418  498.22
