Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2891     10.230  2.2989    10.484  8.02
   2   2.1024     20.560  2.2513    14.008  13.91
   3   1.8580     30.640  2.0171    22.668  19.72
   4   1.7131     35.090  1.8478    28.904  25.52
   5   1.6055     39.250  1.7295    33.854  31.33
   6   1.5573     41.320  1.6278    38.068  37.15
   7   1.4417     46.010  1.5377    41.892  42.94
   8   1.3864     48.660  1.4770    44.614  48.81
   9   1.3183     51.550  1.4068    47.312  54.62
  10   1.2675     53.410  1.3485    49.844  60.45
  11   1.2272     54.700  1.2928    51.992  66.25
  12   1.1464     58.730  1.2377    54.336  72.06
  13   1.1251     59.650  1.1908    56.196  77.86
  14   1.1049     59.740  1.1499    57.834  83.78
  15   1.0540     62.040  1.1109    59.672  89.62
  16   0.9980     64.170  1.0730    61.090  95.42
  17   0.9758     65.060  1.0359    62.690  101.22
  18   0.9611     65.260  1.0040    63.822  107.05
  19   0.9181     67.360  0.9767    64.840  112.95
  20   0.9533     65.720  0.9518    65.748  118.79
  21   0.9160     67.300  0.9324    66.710  124.59
  22   0.8736     68.770  0.9023    67.550  130.41
  23   0.8407     70.480  0.8760    68.594  136.23
  24   0.8282     70.520  0.8570    69.502  142.07
  25   0.8154     71.170  0.8368    70.038  147.97
  26   0.7995     71.950  0.8161    70.902  153.81
  27   0.7930     72.140  0.8008    71.610  159.64
  28   0.7529     73.390  0.7768    72.294  165.44
  29   0.7521     73.810  0.7568    73.062  171.26
  30   0.7378     74.140  0.7482    73.514  177.12
  31   0.7794     72.670  0.7319    74.204  182.93
  32   0.7082     75.050  0.7167    74.744  188.75
  33   0.7075     75.350  0.7002    75.148  194.57
  34   0.7215     75.060  0.6880    75.946  200.40
  35   0.6818     75.680  0.6700    76.478  206.24
  36   0.6565     77.080  0.6677    76.612  212.12
  37   0.6732     76.850  0.6560    76.790  217.92
  38   0.6606     77.120  0.6374    77.568  223.72
  39   0.6527     77.240  0.6290    77.964  229.52
  40   0.6459     77.970  0.6214    78.210  235.33
  41   0.6422     77.650  0.6083    78.626  241.17
  42   0.6174     78.750  0.5962    78.954  247.03
  43   0.6081     79.190  0.5892    79.334  252.84
  44   0.6149     78.630  0.5810    79.648  258.66
  45   0.5981     79.150  0.5660    80.254  264.48
  46   0.6157     79.270  0.5571    80.484  270.30
  47   0.6013     79.700  0.5556    80.590  276.16
  48   0.6118     79.100  0.5424    81.018  281.97
  49   0.5974     79.220  0.5387    81.048  287.77
  50   0.5813     79.980  0.5313    81.322  293.55
  51   0.5791     79.690  0.5262    81.544  299.37
  52   0.5739     80.420  0.5143    81.954  305.20
  53   0.5789     80.280  0.5092    82.242  311.10
  54   0.5778     80.400  0.4988    82.614  316.93
  55   0.5583     81.160  0.4959    82.696  322.75
  56   0.5570     80.960  0.4908    82.792  328.57
  57   0.5809     80.590  0.4855    83.012  334.38
  58   0.5570     81.190  0.4781    83.314  340.23
  59   0.5508     81.620  0.4654    83.752  346.13
  60   0.5478     81.680  0.4627    83.838  351.98
  61   0.5633     81.220  0.4522    84.124  357.81
  62   0.5527     81.580  0.4501    84.330  363.61
  63   0.5535     81.750  0.4454    84.360  369.44
  64   0.5753     80.940  0.4422    84.492  375.26
  65   0.5891     80.920  0.4411    84.578  381.06
  66   0.5255     82.400  0.4242    85.218  386.97
  67   0.5336     81.830  0.4199    85.368  392.81
  68   0.5462     82.280  0.4191    85.274  398.63
  69   0.5400     81.870  0.4076    85.614  404.42
  70   0.5467     82.130  0.4105    85.648  410.25
  71   0.5313     82.680  0.4029    86.088  416.15
  72   0.5271     83.050  0.3980    86.208  421.98
  73   0.5195     82.550  0.3830    86.682  427.79
  74   0.5287     82.620  0.3834    86.518  433.63
  75   0.5294     83.260  0.3757    86.840  439.44
  76   0.5624     82.250  0.3733    86.894  445.24
  77   0.5306     82.860  0.3658    87.166  451.14
  78   0.5490     82.450  0.3628    87.240  456.95
  79   0.5216     83.170  0.3601    87.456  462.76
  80   0.5325     82.850  0.3635    87.332  468.61
  81   0.5256     82.690  0.3501    87.724  474.42
  82   0.5106     83.730  0.3470    87.868  480.30
  83   0.5171     83.460  0.3479    87.780  486.11
  84   0.5241     83.290  0.3329    88.248  491.93
  85   0.5260     82.830  0.3334    88.320  497.75
