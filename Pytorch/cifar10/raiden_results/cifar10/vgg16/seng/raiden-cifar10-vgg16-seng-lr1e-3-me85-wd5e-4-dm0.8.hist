Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2914     10.660  2.2997    10.610  8.11
   2   2.0576     23.580  2.2418    14.306  13.92
   3   1.7786     32.080  1.9555    24.774  19.73
   4   1.6387     37.550  1.7598    32.368  25.56
   5   1.5037     42.890  1.6389    37.398  31.35
   6   1.4221     45.800  1.5242    42.714  37.15
   7   1.2980     51.280  1.4351    46.362  43.03
   8   1.2478     54.680  1.3520    49.948  48.83
   9   1.2010     56.570  1.2850    52.820  54.64
  10   1.1071     59.970  1.2111    55.730  60.44
  11   1.0642     62.050  1.1480    58.088  66.26
  12   1.0220     62.830  1.0921    60.450  72.05
  13   0.9868     64.650  1.0484    62.114  77.92
  14   0.9489     66.090  1.0116    63.414  83.73
  15   0.9479     66.630  0.9780    64.874  89.54
  16   0.9111     67.520  0.9395    66.166  95.35
  17   0.8943     67.700  0.9060    67.316  101.18
  18   0.8646     69.410  0.8750    68.554  106.97
  19   0.7982     71.430  0.8372    70.084  112.76
  20   0.8187     70.180  0.8132    70.928  118.58
  21   0.7571     73.230  0.7830    72.096  124.41
  22   0.7345     74.170  0.7534    73.084  130.23
  23   0.7031     74.900  0.7394    73.842  136.03
  24   0.7144     75.250  0.7153    74.592  141.92
  25   0.7800     73.550  0.6941    75.704  147.73
  26   0.6579     77.080  0.6775    76.314  153.54
  27   0.6647     76.510  0.6657    76.426  159.34
  28   0.6585     77.180  0.6486    77.186  165.15
  29   0.6493     77.530  0.6309    77.764  170.97
  30   0.6400     78.020  0.6125    78.440  176.77
  31   0.6277     78.460  0.6001    79.006  182.56
  32   0.6050     78.970  0.5861    79.394  188.37
  33   0.6378     78.020  0.5731    79.872  194.18
  34   0.5789     80.560  0.5673    80.068  199.98
  35   0.5778     79.730  0.5477    80.748  205.86
  36   0.5775     80.500  0.5383    81.036  211.66
  37   0.5718     80.560  0.5363    81.328  217.46
  38   0.5505     81.080  0.5181    81.836  223.26
  39   0.5799     80.750  0.5144    81.814  229.05
  40   0.5693     80.400  0.5003    82.428  234.86
  41   0.5683     80.950  0.4910    82.804  240.76
  42   0.5618     80.570  0.4810    83.290  246.55
  43   0.5451     81.740  0.4723    83.374  252.36
  44   0.5376     81.760  0.4638    83.802  258.15
  45   0.5209     82.360  0.4542    84.058  263.96
  46   0.5377     81.930  0.4491    84.162  269.76
  47   0.5103     82.510  0.4428    84.458  275.62
  48   0.5141     82.860  0.4298    85.010  281.43
  49   0.5084     82.680  0.4252    85.272  287.26
  50   0.5100     82.980  0.4131    85.682  293.01
  51   0.5188     83.040  0.4141    85.536  298.82
  52   0.5102     82.920  0.4019    85.980  304.61
  53   0.5004     83.490  0.3976    86.026  310.50
  54   0.5074     83.260  0.3979    85.966  316.32
  55   0.4988     83.200  0.3809    86.730  322.12
  56   0.5026     83.240  0.3780    86.824  327.92
  57   0.5151     83.460  0.3719    86.908  333.72
  58   0.5096     83.700  0.3685    87.396  339.62
  59   0.5049     83.250  0.3565    87.522  345.42
  60   0.5074     84.160  0.3507    87.850  351.22
  61   0.5007     83.760  0.3453    87.748  357.02
  62   0.5050     83.810  0.3392    88.158  362.82
  63   0.4788     84.320  0.3374    88.276  368.63
  64   0.4749     84.350  0.3297    88.446  374.51
  65   0.4748     84.450  0.3226    88.626  380.31
  66   0.4825     84.570  0.3177    89.076  386.12
  67   0.5001     84.550  0.3170    88.914  391.93
  68   0.4849     84.310  0.3113    89.028  397.72
  69   0.4979     84.470  0.3027    89.478  403.54
  70   0.5241     83.750  0.3001    89.588  409.41
  71   0.5538     82.500  0.2987    89.508  415.21
  72   0.4575     85.560  0.2829    90.062  421.01
  73   0.4985     84.220  0.2859    90.062  426.83
  74   0.4645     85.090  0.2797    90.294  432.64
  75   0.4778     84.380  0.2743    90.414  438.52
  76   0.4773     84.240  0.2756    90.466  444.33
  77   0.4894     84.750  0.2651    90.754  450.17
  78   0.4704     85.340  0.2589    91.056  455.98
  79   0.4879     84.980  0.2610    90.874  461.78
  80   0.4732     85.420  0.2599    90.916  467.57
  81   0.4877     84.120  0.2503    91.398  473.44
  82   0.5242     84.230  0.2455    91.300  479.23
  83   0.4774     85.380  0.2358    91.764  485.09
  84   0.5023     84.980  0.2370    91.700  490.92
  85   0.4710     85.650  0.2345    91.900  496.75
