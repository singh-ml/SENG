Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7672     32.050  2.1029    19.378  7.69
   2   1.5023     42.570  1.6817    34.608  13.52
   3   1.2651     53.850  1.3845    47.786  19.32
   4   1.0074     63.770  1.1288    58.956  25.21
   5   0.8423     70.260  0.9654    65.242  31.03
   6   0.7568     73.200  0.8449    69.908  36.84
   7   0.7343     75.070  0.7593    73.470  42.66
   8   0.7007     75.980  0.6927    75.940  48.48
   9   0.6178     79.170  0.6409    78.024  54.30
  10   0.6094     79.780  0.5774    80.154  60.18
  11   0.5700     81.350  0.5455    81.420  66.00
  12   0.5848     81.290  0.5058    82.728  71.80
  13   0.5083     83.300  0.4801    83.586  77.64
  14   0.4927     83.680  0.4472    84.748  83.44
  15   0.4884     83.940  0.4266    85.478  89.27
  16   0.4892     84.390  0.4037    86.114  95.17
  17   0.4482     85.120  0.3805    86.940  101.00
  18   0.4928     83.570  0.3591    87.692  106.84
  19   0.4533     85.160  0.3422    88.318  112.66
  20   0.4295     86.260  0.3278    88.870  118.50
  21   0.4232     86.050  0.3144    89.196  124.31
  22   0.4259     86.150  0.3008    89.654  130.20
  23   0.4143     86.550  0.2845    90.280  136.02
  24   0.4258     86.290  0.2739    90.676  141.82
  25   0.4054     86.830  0.2636    91.052  147.64
  26   0.3955     87.270  0.2441    91.610  153.45
  27   0.4179     86.700  0.2367    91.960  159.30
  28   0.4313     87.020  0.2231    92.548  165.13
  29   0.4311     86.980  0.2175    92.640  170.94
  30   0.4492     86.480  0.2078    92.880  176.79
  31   0.4542     86.600  0.1949    93.326  182.64
  32   0.4274     87.540  0.1885    93.524  188.46
  33   0.3938     87.620  0.1773    93.842  194.36
  34   0.4334     87.220  0.1695    94.172  200.18
  35   0.4258     87.810  0.1640    94.390  206.00
  36   0.4036     88.150  0.1577    94.590  211.81
  37   0.3991     88.270  0.1495    94.854  217.61
  38   0.4380     87.560  0.1384    95.210  223.44
  39   0.4059     89.000  0.1320    95.454  229.35
  40   0.4435     87.110  0.1256    95.704  235.19
  41   0.4369     88.230  0.1190    95.918  241.01
  42   0.4100     88.950  0.1180    95.872  246.87
  43   0.4581     88.190  0.1043    96.426  252.70
  44   0.4563     88.460  0.1157    96.132  258.54
  45   0.4721     88.250  0.0941    96.730  264.44
  46   0.4662     88.780  0.0900    96.916  270.27
  47   0.4769     88.400  0.0881    97.006  276.08
  48   0.4952     88.190  0.0792    97.284  281.90
  49   0.4855     88.920  0.0743    97.474  287.72
  50   0.4778     88.920  0.0732    97.522  293.49
  51   0.4772     88.610  0.0702    97.518  299.37
  52   0.4792     89.080  0.0611    97.872  305.21
  53   0.4773     89.250  0.0593    97.968  311.06
  54   0.5067     88.880  0.0529    98.146  316.88
  55   0.5063     88.920  0.0517    98.252  322.69
  56   0.4967     88.770  0.0511    98.216  328.56
  57   0.5084     88.940  0.0455    98.454  334.38
  58   0.5072     89.500  0.0429    98.498  340.18
  59   0.5052     89.250  0.0404    98.604  346.00
  60   0.5259     89.200  0.0356    98.750  351.80
  61   0.5315     89.380  0.0319    98.964  357.63
  62   0.5463     89.640  0.0294    99.002  363.53
  63   0.5441     89.210  0.0302    99.000  369.34
  64   0.5722     89.300  0.0304    98.946  375.15
  65   0.5539     89.430  0.0245    99.146  380.97
  66   0.5517     89.670  0.0246    99.202  386.78
  67   0.5586     89.700  0.0229    99.212  392.57
  68   0.5663     89.820  0.0202    99.330  398.40
  69   0.5567     89.300  0.0205    99.314  404.21
  70   0.5796     89.950  0.0175    99.426  410.03
  71   0.5981     89.670  0.0151    99.468  415.83
  72   0.5998     89.770  0.0151    99.456  421.66
  73   0.6050     89.530  0.0144    99.492  427.55
  74   0.6050     89.700  0.0152    99.514  433.37
  75   0.6110     89.900  0.0136    99.516  439.18
  76   0.6212     89.690  0.0102    99.666  445.01
  77   0.6159     89.790  0.0130    99.562  450.82
  78   0.6340     89.560  0.0106    99.652  456.64
  79   0.6180     89.760  0.0118    99.610  462.53
  80   0.6283     89.710  0.0101    99.656  468.34
  81   0.6265     89.740  0.0090    99.712  474.16
  82   0.6347     89.940  0.0086    99.718  479.98
  83   0.6351     89.770  0.0093    99.678  485.79
  84   0.6413     89.610  0.0088    99.708  491.62
  85   0.6476     89.750  0.0081    99.716  497.52
