Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0072     26.640  2.2170    15.194  7.82
   2   1.5945     40.570  1.8109    31.024  13.64
   3   1.4327     46.840  1.5886    40.138  19.48
   4   1.2791     54.120  1.3761    48.858  25.28
   5   1.0945     59.220  1.1941    56.472  31.12
   6   0.9734     65.050  1.0750    60.966  37.00
   7   0.9078     67.310  0.9718    64.958  42.84
   8   0.8048     71.370  0.9007    67.894  48.66
   9   0.7757     72.790  0.8239    70.714  54.48
  10   0.7088     74.710  0.7668    72.956  60.31
  11   0.6764     76.270  0.7105    74.882  66.16
  12   0.6808     76.140  0.6825    75.994  72.06
  13   0.6825     76.770  0.6407    77.610  77.87
  14   0.5975     79.550  0.6201    78.416  83.73
  15   0.5815     80.130  0.5862    79.634  89.55
  16   0.6141     79.810  0.5639    80.434  95.39
  17   0.5907     80.300  0.5470    80.908  101.21
  18   0.5373     81.770  0.5243    81.768  107.11
  19   0.5383     81.680  0.4977    82.922  112.96
  20   0.5102     82.350  0.4801    83.384  118.77
  21   0.5385     81.820  0.4607    83.906  124.59
  22   0.5244     82.500  0.4428    84.780  130.42
  23   0.5008     83.080  0.4317    85.060  136.28
  24   0.4999     83.620  0.4159    85.520  142.13
  25   0.5133     83.200  0.4069    86.008  147.94
  26   0.4710     84.140  0.3911    86.426  153.75
  27   0.4659     84.510  0.3862    86.692  159.60
  28   0.4681     84.230  0.3658    87.308  165.47
  29   0.4512     85.150  0.3513    87.832  171.36
  30   0.4591     84.470  0.3431    88.112  177.17
  31   0.4571     85.220  0.3302    88.444  183.01
  32   0.4598     85.020  0.3155    89.086  188.83
  33   0.4466     85.600  0.3075    89.430  194.64
  34   0.4646     84.670  0.3002    89.534  200.53
  35   0.4460     85.490  0.2905    89.882  206.35
  36   0.4612     85.110  0.2801    90.282  212.17
  37   0.4604     85.480  0.2763    90.562  217.99
  38   0.4568     86.080  0.2651    90.746  223.83
  39   0.4418     85.980  0.2564    91.124  229.65
  40   0.4487     85.930  0.2477    91.364  235.53
  41   0.4576     85.470  0.2432    91.570  241.35
  42   0.4565     85.710  0.2296    92.160  247.18
  43   0.4381     86.020  0.2265    92.204  253.00
  44   0.4576     86.190  0.2144    92.584  258.84
  45   0.4617     86.180  0.2104    92.570  264.66
  46   0.4392     86.750  0.2069    92.838  270.60
  47   0.4229     86.700  0.2004    93.144  276.43
  48   0.4539     86.770  0.1895    93.396  282.26
  49   0.4593     86.370  0.1803    93.776  288.07
  50   0.4456     87.230  0.1761    93.918  293.82
  51   0.4526     86.600  0.1752    93.860  299.69
  52   0.4432     87.160  0.1682    94.132  305.58
  53   0.4480     86.970  0.1585    94.702  311.42
  54   0.4930     86.750  0.1552    94.502  317.25
  55   0.4768     86.810  0.1521    94.750  323.06
  56   0.4561     87.230  0.1507    94.696  328.88
  57   0.4794     86.940  0.1446    94.922  334.74
  58   0.4568     87.020  0.1382    95.186  340.64
  59   0.4862     86.560  0.1330    95.388  346.49
  60   0.5060     87.160  0.1316    95.378  352.31
  61   0.4928     87.070  0.1252    95.646  358.13
  62   0.4918     87.330  0.1224    95.702  363.95
  63   0.4789     87.460  0.1101    96.218  369.77
  64   0.5099     87.070  0.1069    96.298  375.69
  65   0.4850     87.610  0.1045    96.306  381.53
  66   0.5055     87.210  0.1008    96.478  387.35
  67   0.4933     87.250  0.0988    96.628  393.18
  68   0.5232     87.090  0.0941    96.772  399.02
  69   0.4955     87.450  0.0958    96.650  404.83
  70   0.5119     87.220  0.0874    97.042  410.72
  71   0.5339     87.370  0.0836    97.166  416.53
  72   0.5326     87.650  0.0818    97.138  422.37
  73   0.5358     87.680  0.0770    97.346  428.18
  74   0.5303     87.490  0.0824    97.124  434.01
  75   0.5425     87.330  0.0769    97.324  439.91
  76   0.5214     87.870  0.0760    97.388  445.73
  77   0.5472     87.590  0.0732    97.532  451.53
  78   0.5480     87.420  0.0692    97.592  457.34
  79   0.5669     87.670  0.0695    97.672  463.16
  80   0.5576     87.440  0.0657    97.736  468.98
  81   0.5693     87.920  0.0631    97.774  474.89
  82   0.5618     87.550  0.0657    97.742  480.71
  83   0.5667     87.870  0.0632    97.800  486.54
  84   0.5876     87.780  0.0574    97.968  492.37
  85   0.5882     87.740  0.0569    98.044  498.19
