Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7564     31.500  2.1115    18.984  7.81
   2   1.6305     37.340  1.8244    29.578  13.66
   3   1.3372     50.740  1.5016    42.860  19.47
   4   1.1019     59.390  1.2579    54.138  25.30
   5   0.9541     66.020  1.0482    62.376  31.12
   6   0.8426     70.360  0.9100    67.548  37.04
   7   0.7593     73.870  0.8139    71.380  42.85
   8   0.7202     75.260  0.7346    74.326  48.69
   9   0.6302     78.330  0.6703    76.802  54.49
  10   0.5920     79.850  0.6184    78.672  60.33
  11   0.5656     80.530  0.5748    80.148  66.17
  12   0.5815     80.180  0.5395    81.606  72.06
  13   0.5125     82.740  0.5119    82.424  77.90
  14   0.5196     82.110  0.4827    83.518  83.72
  15   0.5393     82.350  0.4478    84.786  89.56
  16   0.5072     83.610  0.4330    85.242  95.40
  17   0.4685     84.820  0.4105    86.128  101.31
  18   0.4683     84.270  0.3843    86.972  107.12
  19   0.4671     84.400  0.3646    87.572  112.96
  20   0.4781     84.620  0.3481    88.174  118.79
  21   0.4304     85.950  0.3333    88.636  124.63
  22   0.4215     86.060  0.3215    89.060  130.46
  23   0.4243     86.240  0.3064    89.718  136.30
  24   0.4327     86.800  0.2850    90.280  142.20
  25   0.4372     85.820  0.2728    90.780  148.04
  26   0.4137     86.920  0.2583    91.166  153.88
  27   0.4149     86.800  0.2525    91.406  159.69
  28   0.4409     85.990  0.2360    91.944  165.53
  29   0.4265     86.450  0.2377    91.966  171.46
  30   0.4055     87.880  0.2157    92.594  177.31
  31   0.4137     87.300  0.2118    92.630  183.16
  32   0.4161     87.780  0.2084    92.856  188.99
  33   0.4186     87.740  0.1892    93.504  194.85
  34   0.4314     87.070  0.1840    93.666  200.66
  35   0.4255     87.670  0.1807    93.810  206.57
  36   0.3942     88.050  0.1632    94.384  212.41
  37   0.4151     87.930  0.1603    94.508  218.22
  38   0.3998     88.370  0.1490    94.810  224.03
  39   0.4047     88.220  0.1485    94.918  229.85
  40   0.4297     88.180  0.1341    95.422  235.77
  41   0.4264     87.770  0.1295    95.396  241.60
  42   0.4325     88.280  0.1312    95.582  247.43
  43   0.4411     88.280  0.1192    95.900  253.25
  44   0.4434     88.120  0.1154    95.952  259.07
  45   0.4467     88.320  0.1042    96.374  264.91
  46   0.4984     86.680  0.1018    96.528  270.80
  47   0.4598     88.950  0.0973    96.654  276.63
  48   0.4558     88.680  0.0866    96.972  282.47
  49   0.4482     88.860  0.0845    97.038  288.29
  50   0.4499     88.850  0.0793    97.276  294.03
  51   0.4826     88.570  0.0777    97.342  299.89
  52   0.4775     89.080  0.0745    97.446  305.78
  53   0.5046     88.170  0.0681    97.674  311.61
  54   0.4723     88.980  0.0660    97.724  317.43
  55   0.4876     88.810  0.0596    97.956  323.24
  56   0.4779     89.020  0.0621    97.808  329.07
  57   0.4821     89.420  0.0524    98.266  334.88
  58   0.4688     88.730  0.0520    98.218  340.76
  59   0.4931     88.950  0.0465    98.392  346.57
  60   0.4803     88.970  0.0482    98.404  352.39
  61   0.5151     88.560  0.0413    98.610  358.22
  62   0.4998     89.540  0.0382    98.676  364.06
  63   0.5214     89.340  0.0348    98.804  369.89
  64   0.5120     89.670  0.0335    98.904  375.77
  65   0.5244     89.520  0.0312    98.988  381.59
  66   0.5626     89.100  0.0284    99.024  387.44
  67   0.5390     89.270  0.0294    98.974  393.28
  68   0.5251     89.490  0.0281    99.066  399.09
  69   0.5473     89.670  0.0251    99.136  404.91
  70   0.5481     89.480  0.0232    99.198  410.81
  71   0.5581     89.580  0.0230    99.248  416.63
  72   0.5326     89.580  0.0210    99.272  422.47
  73   0.5620     89.420  0.0181    99.364  428.29
  74   0.5587     89.820  0.0153    99.500  434.11
  75   0.5565     89.730  0.0192    99.338  440.00
  76   0.5749     89.800  0.0136    99.552  445.81
  77   0.5767     89.740  0.0156    99.490  451.65
  78   0.5728     89.720  0.0139    99.550  457.46
  79   0.5768     89.900  0.0126    99.612  463.27
  80   0.5973     89.810  0.0121    99.588  469.11
  81   0.5938     89.900  0.0103    99.638  475.02
  82   0.5927     89.910  0.0112    99.626  480.84
  83   0.6023     89.890  0.0092    99.682  486.68
  84   0.5979     89.730  0.0080    99.734  492.52
  85   0.6149     89.880  0.0081    99.736  498.37
  86   0.6226     89.920  0.0085    99.730  504.22
  87   0.6168     89.790  0.0083    99.730  510.13
  88   0.6121     89.650  0.0084    99.734  515.94
  89   0.6251     89.970  0.0081    99.752  521.77
  90   0.6162     89.760  0.0087    99.726  527.58
