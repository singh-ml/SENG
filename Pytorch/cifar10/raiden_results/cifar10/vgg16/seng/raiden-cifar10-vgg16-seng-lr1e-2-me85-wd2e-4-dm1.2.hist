Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7650     32.990  2.1162    18.608  7.84
   2   1.4698     44.150  1.6960    35.170  13.72
   3   1.2212     54.710  1.4185    46.766  19.52
   4   1.0584     62.480  1.1827    56.836  25.32
   5   0.9154     67.960  1.0169    63.182  31.10
   6   0.7897     71.790  0.8941    68.026  36.90
   7   0.7714     73.140  0.8051    71.712  42.72
   8   0.7301     74.890  0.7439    73.742  48.52
   9   0.6494     77.570  0.6850    76.164  54.40
  10   0.6679     76.190  0.6355    77.938  60.21
  11   0.5887     80.160  0.5892    79.622  66.01
  12   0.6190     79.110  0.5628    80.540  71.81
  13   0.5376     82.020  0.5276    81.770  77.62
  14   0.5386     81.850  0.4985    82.830  83.49
  15   0.5248     82.320  0.4772    83.376  89.29
  16   0.5135     82.990  0.4590    84.214  95.10
  17   0.4760     84.030  0.4338    85.100  100.92
  18   0.4794     84.030  0.4089    85.866  106.70
  19   0.5089     84.220  0.3933    86.418  112.53
  20   0.4530     85.310  0.3745    87.172  118.44
  21   0.4688     84.630  0.3555    87.720  124.28
  22   0.4653     85.090  0.3398    88.268  130.10
  23   0.4504     85.730  0.3297    88.690  135.91
  24   0.4340     85.850  0.3167    89.182  141.75
  25   0.4475     85.850  0.3053    89.412  147.60
  26   0.4132     86.650  0.2888    90.106  153.42
  27   0.4372     86.140  0.2747    90.526  159.24
  28   0.4466     85.740  0.2677    90.692  165.04
  29   0.4174     86.720  0.2536    91.384  170.83
  30   0.4175     87.300  0.2404    91.790  176.65
  31   0.4336     86.980  0.2360    91.910  182.46
  32   0.4192     86.830  0.2175    92.570  188.36
  33   0.4520     86.370  0.2164    92.470  194.17
  34   0.4324     86.590  0.2027    93.020  199.99
  35   0.4344     87.420  0.1918    93.288  205.80
  36   0.4226     87.450  0.1857    93.536  211.61
  37   0.4172     87.750  0.1787    93.966  217.49
  38   0.4151     87.180  0.1658    94.344  223.33
  39   0.4504     87.210  0.1597    94.434  229.11
  40   0.4375     87.760  0.1510    94.868  234.92
  41   0.4245     87.700  0.1509    94.702  240.71
  42   0.4350     87.750  0.1385    95.154  246.53
  43   0.4730     87.320  0.1357    95.270  252.40
  44   0.4430     87.830  0.1335    95.368  258.20
  45   0.4333     88.000  0.1233    95.750  264.01
  46   0.4592     88.120  0.1127    96.084  269.81
  47   0.4625     88.210  0.1133    96.128  275.64
  48   0.4550     87.840  0.1032    96.458  281.44
  49   0.4691     88.100  0.0977    96.614  287.37
  50   0.4789     87.910  0.0906    96.862  293.13
  51   0.4816     88.080  0.0905    96.768  298.94
  52   0.4716     88.580  0.0837    97.134  304.74
  53   0.4646     88.400  0.0810    97.172  310.53
  54   0.5051     87.940  0.0740    97.476  316.43
  55   0.4908     88.560  0.0689    97.646  322.24
  56   0.4976     88.000  0.0712    97.512  328.05
  57   0.5001     88.480  0.0593    97.980  333.88
  58   0.5048     88.830  0.0611    97.824  339.71
  59   0.5235     88.250  0.0590    98.004  345.51
  60   0.5240     87.960  0.0573    98.004  351.40
  61   0.5215     88.640  0.0497    98.252  357.19
  62   0.5326     88.540  0.0480    98.342  363.02
  63   0.5454     88.470  0.0412    98.566  368.86
  64   0.5296     89.000  0.0431    98.514  374.65
  65   0.5424     88.320  0.0397    98.622  380.53
  66   0.5374     89.010  0.0379    98.694  386.37
  67   0.5472     88.650  0.0361    98.750  392.20
  68   0.5526     88.710  0.0299    99.006  398.02
  69   0.5718     88.390  0.0291    99.052  403.82
  70   0.5624     88.770  0.0280    99.070  409.62
  71   0.5578     88.830  0.0277    99.082  415.48
  72   0.5746     89.150  0.0259    99.114  421.30
  73   0.5647     88.830  0.0245    99.214  427.09
  74   0.5814     89.010  0.0212    99.316  432.92
  75   0.5886     88.870  0.0196    99.356  438.74
  76   0.6154     89.010  0.0201    99.324  444.52
  77   0.5976     89.030  0.0207    99.310  450.42
  78   0.5897     88.870  0.0191    99.384  456.22
  79   0.6166     88.810  0.0178    99.384  462.04
  80   0.6084     89.120  0.0174    99.436  467.84
  81   0.6246     89.000  0.0159    99.462  473.63
  82   0.6288     88.920  0.0165    99.434  479.46
  83   0.6192     89.240  0.0153    99.482  485.31
  84   0.6087     88.930  0.0152    99.458  491.10
  85   0.6165     88.980  0.0151    99.490  496.90
