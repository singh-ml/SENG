Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0362     18.550  2.1806    17.250  7.75
   2   1.6996     34.270  1.8960    24.134  13.64
   3   1.4957     43.260  1.6429    36.140  19.48
   4   1.1959     57.190  1.3681    49.426  25.29
   5   0.9490     66.440  1.1038    61.020  31.12
   6   0.8656     70.770  0.9476    67.108  36.94
   7   0.7438     75.450  0.8256    71.968  42.80
   8   0.7530     75.810  0.7317    75.376  48.70
   9   0.6350     79.350  0.6725    77.774  54.54
  10   0.6438     78.810  0.6187    79.678  60.37
  11   0.6128     80.820  0.5857    80.884  66.21
  12   0.5815     80.770  0.5471    82.122  72.01
  13   0.5591     81.570  0.5080    83.428  77.82
  14   0.5214     83.560  0.4788    84.436  83.73
  15   0.5033     84.010  0.4622    84.834  89.57
  16   0.4961     83.950  0.4349    85.804  95.37
  17   0.4697     85.210  0.4085    86.764  101.18
  18   0.4664     84.750  0.3942    86.976  107.00
  19   0.4714     84.370  0.3797    87.460  112.88
  20   0.4506     85.450  0.3693    87.822  118.71
  21   0.4232     86.090  0.3502    88.640  124.55
  22   0.4464     85.780  0.3307    89.208  130.38
  23   0.4713     85.550  0.3248    89.420  136.22
  24   0.4286     86.920  0.3197    89.462  142.05
  25   0.4189     86.410  0.2966    90.336  147.94
  26   0.4134     87.220  0.2900    90.362  153.77
  27   0.3907     87.870  0.2742    91.062  159.60
  28   0.4704     86.180  0.2728    90.932  165.41
  29   0.3985     87.590  0.2544    91.748  171.23
  30   0.4236     87.000  0.2395    92.076  177.16
  31   0.4000     87.680  0.2385    92.246  182.99
  32   0.4237     87.000  0.2328    92.222  188.81
  33   0.4108     87.570  0.2191    92.762  194.64
  34   0.4116     87.680  0.2040    93.280  200.49
  35   0.3733     89.010  0.2042    93.338  206.30
  36   0.4047     88.240  0.1873    93.798  212.17
  37   0.3796     88.800  0.1926    93.490  217.99
  38   0.3927     88.050  0.1769    94.158  223.79
  39   0.4343     87.750  0.1628    94.588  229.62
  40   0.4043     88.880  0.1694    94.370  235.43
  41   0.3816     89.120  0.1640    94.498  241.31
  42   0.4044     88.840  0.1392    95.408  247.12
  43   0.3755     89.380  0.1398    95.320  252.98
  44   0.3664     89.610  0.1264    95.722  258.80
  45   0.3992     89.320  0.1259    95.832  264.62
  46   0.3811     89.070  0.1179    96.090  270.46
  47   0.4069     89.180  0.1097    96.288  276.36
  48   0.3943     89.060  0.1129    96.174  282.18
  49   0.3881     89.690  0.1021    96.576  288.01
  50   0.3843     89.670  0.0888    97.118  293.78
  51   0.4084     89.420  0.0845    97.212  299.60
  52   0.3678     90.240  0.0816    97.278  305.42
  53   0.3828     90.110  0.0768    97.436  311.30
  54   0.3825     90.050  0.0714    97.566  317.15
  55   0.3856     90.420  0.0659    97.788  322.98
  56   0.4158     89.470  0.0573    98.078  328.79
  57   0.3945     90.310  0.0525    98.288  334.63
  58   0.4210     90.100  0.0508    98.292  340.47
  59   0.3869     90.320  0.0440    98.548  346.37
  60   0.4221     90.140  0.0372    98.840  352.22
  61   0.4024     90.650  0.0345    98.778  358.06
  62   0.4138     90.940  0.0319    98.974  363.89
  63   0.4213     90.840  0.0267    99.088  369.69
  64   0.4085     90.830  0.0248    99.182  375.59
  65   0.4237     90.910  0.0238    99.236  381.43
  66   0.4233     91.030  0.0183    99.420  387.25
  67   0.4371     91.010  0.0170    99.396  393.10
  68   0.4256     90.960  0.0148    99.536  398.90
  69   0.4398     90.920  0.0126    99.574  404.74
  70   0.4380     91.160  0.0101    99.678  410.60
  71   0.4354     91.150  0.0100    99.702  416.42
  72   0.4320     91.150  0.0077    99.772  422.25
  73   0.4416     91.330  0.0067    99.812  428.07
  74   0.4422     91.370  0.0078    99.770  433.91
  75   0.4353     91.400  0.0053    99.856  439.82
  76   0.4346     91.420  0.0055    99.850  445.62
  77   0.4345     91.570  0.0049    99.872  451.47
  78   0.4337     91.550  0.0047    99.870  457.32
  79   0.4320     91.470  0.0047    99.878  463.12
  80   0.4342     91.450  0.0037    99.914  468.97
  81   0.4337     91.510  0.0043    99.894  474.84
  82   0.4362     91.380  0.0043    99.888  480.70
  83   0.4351     91.570  0.0036    99.908  486.51
  84   0.4407     91.400  0.0030    99.934  492.34
  85   0.4338     91.580  0.0035    99.918  498.18
