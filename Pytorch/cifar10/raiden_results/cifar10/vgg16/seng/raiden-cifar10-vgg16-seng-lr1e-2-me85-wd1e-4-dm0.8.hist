Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7353     33.860  2.0703    20.524  7.70
   2   1.4066     47.190  1.5947    38.954  13.53
   3   1.1826     57.220  1.3087    51.618  19.37
   4   0.9981     64.450  1.0943    60.380  25.18
   5   0.8875     68.040  0.9451    66.290  31.00
   6   0.7842     72.320  0.8321    70.470  36.81
   7   0.7247     75.690  0.7497    73.858  42.61
   8   0.6851     77.050  0.6893    76.268  48.51
   9   0.6103     79.290  0.6272    78.238  54.35
  10   0.6032     79.620  0.5780    80.122  60.16
  11   0.6012     80.360  0.5489    81.268  65.97
  12   0.5181     82.410  0.5071    82.564  71.83
  13   0.5417     81.900  0.4841    83.572  77.71
  14   0.5361     82.060  0.4584    84.338  83.54
  15   0.4995     83.560  0.4309    85.528  89.39
  16   0.4968     83.730  0.4081    86.296  95.19
  17   0.4810     84.600  0.3836    86.930  100.98
  18   0.4775     84.520  0.3592    87.650  106.83
  19   0.4538     84.790  0.3451    88.280  112.72
  20   0.4359     86.070  0.3320    88.686  118.55
  21   0.4265     86.000  0.3193    89.168  124.37
  22   0.4456     86.050  0.2993    89.764  130.17
  23   0.4460     86.070  0.2846    90.258  135.98
  24   0.4034     87.370  0.2744    90.642  141.81
  25   0.4151     86.740  0.2583    91.102  147.71
  26   0.4319     86.510  0.2407    91.804  153.53
  27   0.4294     86.730  0.2395    91.806  159.33
  28   0.4560     86.290  0.2269    92.258  165.14
  29   0.4098     87.330  0.2143    92.652  170.96
  30   0.4484     86.530  0.2036    93.120  176.84
  31   0.4111     87.060  0.1945    93.336  182.64
  32   0.4182     88.090  0.1847    93.654  188.47
  33   0.4169     87.530  0.1763    93.998  194.29
  34   0.4358     87.500  0.1715    94.104  200.11
  35   0.4224     87.810  0.1585    94.570  205.95
  36   0.4091     88.140  0.1514    94.746  211.81
  37   0.4380     88.150  0.1459    94.930  217.64
  38   0.4288     88.410  0.1347    95.374  223.44
  39   0.4242     87.880  0.1290    95.488  229.24
  40   0.4481     88.410  0.1176    95.924  235.05
  41   0.4233     88.480  0.1183    95.824  240.86
  42   0.4411     88.320  0.1072    96.362  246.75
  43   0.4321     88.530  0.1079    96.308  252.59
  44   0.4460     88.800  0.0970    96.584  258.40
  45   0.4646     87.880  0.0996    96.522  264.23
  46   0.4908     88.160  0.0872    97.010  270.04
  47   0.4720     88.420  0.0857    97.068  275.84
  48   0.4584     88.710  0.0808    97.188  281.71
  49   0.4692     88.560  0.0756    97.432  287.53
  50   0.4672     88.750  0.0725    97.564  293.27
  51   0.4668     88.680  0.0627    97.772  299.09
  52   0.4772     88.900  0.0635    97.848  304.89
  53   0.4838     88.620  0.0572    98.018  310.79
  54   0.4887     88.790  0.0512    98.150  316.60
  55   0.4746     89.030  0.0553    98.120  322.43
  56   0.5271     88.500  0.0528    98.142  328.24
  57   0.5170     89.220  0.0459    98.412  334.06
  58   0.5142     89.060  0.0416    98.550  339.87
  59   0.5160     88.850  0.0394    98.632  345.74
  60   0.5125     89.010  0.0377    98.758  351.54
  61   0.5180     89.340  0.0344    98.876  357.33
  62   0.5271     89.120  0.0317    98.924  363.16
  63   0.5213     89.390  0.0318    98.942  368.99
  64   0.5448     89.530  0.0281    99.064  374.84
  65   0.5649     89.210  0.0251    99.172  380.75
  66   0.5559     89.230  0.0226    99.246  386.59
  67   0.5711     89.070  0.0213    99.326  392.43
  68   0.5417     89.650  0.0228    99.250  398.24
  69   0.5807     89.500  0.0165    99.408  404.09
  70   0.5698     89.500  0.0185    99.378  409.98
  71   0.5900     89.560  0.0175    99.418  415.80
  72   0.5878     89.360  0.0145    99.504  421.63
  73   0.6023     89.580  0.0140    99.538  427.48
  74   0.5889     89.650  0.0158    99.462  433.31
  75   0.6151     89.440  0.0124    99.560  439.14
  76   0.6142     89.620  0.0126    99.534  444.99
  77   0.6081     89.700  0.0112    99.622  450.79
  78   0.6307     89.670  0.0100    99.648  456.61
  79   0.6207     89.600  0.0122    99.600  462.42
  80   0.6162     89.830  0.0113    99.642  468.21
  81   0.6286     89.780  0.0097    99.666  474.03
  82   0.6207     89.930  0.0097    99.692  479.91
  83   0.6299     89.690  0.0087    99.704  485.72
  84   0.6402     89.790  0.0083    99.688  491.53
  85   0.6468     89.720  0.0079    99.736  497.34
