Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2888     16.350  2.2989    10.472  7.64
   2   2.1571     21.500  2.2555    13.066  13.44
   3   1.9724     26.750  2.0732    22.534  19.29
   4   1.7826     33.430  1.9041    27.512  25.09
   5   1.6807     37.430  1.7607    32.512  30.89
   6   1.5574     40.810  1.6589    36.830  36.71
   7   1.4335     46.570  1.5579    40.974  42.50
   8   1.3837     48.240  1.4813    44.690  48.29
   9   1.3067     51.050  1.4116    47.334  54.17
  10   1.2907     52.120  1.3531    49.878  59.97
  11   1.2162     54.990  1.2906    52.284  65.76
  12   1.1679     57.750  1.2381    54.656  71.58
  13   1.1008     60.400  1.1814    56.846  77.39
  14   1.0536     62.400  1.1303    58.622  83.19
  15   1.0234     62.780  1.0897    60.260  89.08
  16   0.9922     64.100  1.0465    61.920  94.87
  17   0.9636     65.240  1.0079    63.556  100.73
  18   0.9248     66.990  0.9767    64.694  106.53
  19   0.8944     67.910  0.9478    66.030  112.33
  20   0.8890     68.630  0.9141    67.016  118.13
  21   0.8559     69.110  0.8911    67.800  124.06
  22   0.8706     68.950  0.8637    69.030  129.85
  23   0.8393     70.550  0.8430    69.670  135.67
  24   0.8027     71.440  0.8113    70.926  141.47
  25   0.7586     72.840  0.7906    71.608  147.26
  26   0.7473     73.530  0.7669    72.620  153.08
  27   0.7924     73.110  0.7512    73.232  158.90
  28   0.7160     74.860  0.7303    74.064  164.69
  29   0.7155     74.760  0.7133    74.744  170.52
  30   0.7146     75.440  0.6937    75.476  176.32
  31   0.6809     75.940  0.6809    76.066  182.12
  32   0.6871     76.330  0.6701    76.290  187.97
  33   0.6782     76.330  0.6585    76.624  193.78
  34   0.6612     77.000  0.6434    77.440  199.58
  35   0.6551     77.590  0.6283    77.848  205.37
  36   0.6332     78.120  0.6134    78.254  211.18
  37   0.6367     78.110  0.6027    78.690  216.97
  38   0.6399     77.490  0.5910    79.056  222.85
  39   0.6183     79.030  0.5825    79.434  228.68
  40   0.6064     79.390  0.5754    79.860  234.49
  41   0.5957     79.600  0.5622    80.350  240.29
  42   0.6190     78.850  0.5523    80.706  246.10
  43   0.6233     78.510  0.5402    80.928  251.95
  44   0.5781     80.450  0.5368    81.064  257.76
  45   0.5817     80.280  0.5245    81.566  263.56
  46   0.5685     80.470  0.5199    81.666  269.36
  47   0.5994     79.650  0.5005    82.364  275.17
  48   0.5626     80.930  0.4992    82.390  280.98
  49   0.5757     80.720  0.4905    82.794  286.84
  50   0.5858     80.920  0.4888    82.806  292.57
  51   0.5611     81.490  0.4784    83.282  298.37
  52   0.5611     81.190  0.4738    83.338  304.17
  53   0.5469     81.940  0.4635    83.494  309.99
  54   0.5416     82.060  0.4518    84.078  315.79
  55   0.5264     82.690  0.4530    84.194  321.66
  56   0.5306     82.190  0.4445    84.428  327.46
  57   0.5337     82.290  0.4332    84.756  333.27
  58   0.5569     81.950  0.4370    84.570  339.10
  59   0.5229     82.340  0.4244    85.226  344.90
  60   0.5340     82.290  0.4232    85.244  350.71
  61   0.5346     82.160  0.4106    85.676  356.58
  62   0.5398     82.090  0.4044    85.564  362.38
  63   0.5762     81.780  0.3996    85.886  368.19
  64   0.5137     83.440  0.3954    86.092  374.00
  65   0.5063     82.770  0.3909    86.190  379.80
  66   0.5065     83.480  0.3821    86.714  385.63
  67   0.5148     83.380  0.3756    86.902  391.41
  68   0.5309     82.360  0.3734    86.968  397.23
  69   0.5016     83.440  0.3662    87.258  403.05
  70   0.5068     83.510  0.3640    87.244  408.88
  71   0.5061     83.590  0.3620    87.346  414.68
  72   0.4994     83.300  0.3522    87.800  420.58
  73   0.5245     82.500  0.3479    87.818  426.38
  74   0.4986     84.340  0.3417    88.018  432.20
  75   0.5024     83.850  0.3325    88.368  438.02
  76   0.4868     84.320  0.3301    88.462  443.82
  77   0.5372     83.270  0.3209    88.844  449.63
  78   0.4893     84.150  0.3281    88.512  455.53
  79   0.5167     84.250  0.3130    89.138  461.32
  80   0.5034     84.280  0.3057    89.364  467.12
  81   0.5010     84.610  0.3035    89.456  472.93
  82   0.5055     84.620  0.2991    89.428  478.73
  83   0.4920     84.750  0.2955    89.654  484.56
  84   0.5032     84.150  0.2919    89.782  490.45
  85   0.5078     84.420  0.2837    90.234  496.24
  86   0.4849     85.030  0.2852    90.144  502.07
  87   0.5023     84.010  0.2821    90.038  507.87
  88   0.5125     83.850  0.2804    90.154  513.67
  89   0.5031     84.570  0.2634    90.850  519.53
  90   0.5054     84.940  0.2672    90.724  525.35
