Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8321     30.780  2.1482    17.984  7.60
   2   1.5818     40.950  1.6810    35.758  13.40
   3   1.2420     53.140  1.4028    47.626  19.30
   4   1.0745     61.880  1.2046    55.834  25.12
   5   0.9340     66.740  1.0204    63.054  30.92
   6   0.8237     70.570  0.8949    67.792  36.73
   7   0.7488     73.430  0.8183    70.916  42.54
   8   0.6719     76.350  0.7430    73.904  48.34
   9   0.6834     76.680  0.6834    76.312  54.21
  10   0.6256     78.680  0.6390    77.702  60.02
  11   0.5872     79.700  0.6058    79.020  65.82
  12   0.5808     80.690  0.5641    80.452  71.62
  13   0.5443     81.470  0.5411    81.470  77.42
  14   0.5266     82.200  0.5117    82.268  83.28
  15   0.5062     82.670  0.4795    83.580  89.11
  16   0.4841     83.480  0.4538    84.550  94.91
  17   0.4950     83.600  0.4335    85.216  100.72
  18   0.4788     84.440  0.4238    85.494  106.52
  19   0.4683     83.800  0.3966    86.438  112.35
  20   0.4696     84.170  0.3849    86.862  118.15
  21   0.5043     83.070  0.3692    87.200  124.05
  22   0.4643     84.520  0.3565    87.784  129.85
  23   0.4506     84.880  0.3415    88.416  135.67
  24   0.4454     85.330  0.3231    89.054  141.50
  25   0.4265     86.200  0.3130    89.312  147.31
  26   0.4492     85.340  0.2975    89.832  153.21
  27   0.4271     86.370  0.2912    90.022  159.01
  28   0.4065     86.900  0.2747    90.578  164.83
  29   0.4973     84.730  0.2666    90.754  170.61
  30   0.4643     85.020  0.2522    91.454  176.43
  31   0.4313     86.800  0.2375    91.742  182.22
  32   0.4379     86.100  0.2302    92.120  188.12
  33   0.4251     87.290  0.2246    92.352  193.94
  34   0.3950     87.570  0.2135    92.764  199.75
  35   0.4113     87.260  0.2047    92.936  205.55
  36   0.4038     87.180  0.2014    93.080  211.37
  37   0.4252     87.200  0.1908    93.506  217.15
  38   0.4273     87.570  0.1793    93.868  223.01
  39   0.4166     87.960  0.1681    94.234  228.82
  40   0.4401     87.160  0.1599    94.542  234.63
  41   0.4227     87.590  0.1605    94.544  240.45
  42   0.4243     87.880  0.1474    95.032  246.26
  43   0.4539     87.360  0.1417    95.146  252.07
  44   0.4274     87.650  0.1411    95.192  257.87
  45   0.4511     87.690  0.1321    95.462  263.67
  46   0.4374     87.820  0.1264    95.716  269.47
  47   0.4227     88.210  0.1196    95.886  275.29
  48   0.4303     88.380  0.1131    96.140  281.10
  49   0.4469     88.200  0.1064    96.366  286.99
  50   0.4851     87.760  0.1030    96.476  292.72
  51   0.4262     88.420  0.1002    96.462  298.53
  52   0.4437     88.240  0.0915    96.828  304.33
  53   0.4619     88.050  0.0875    97.002  310.12
  54   0.4602     88.350  0.0810    97.156  315.95
  55   0.4520     88.420  0.0741    97.510  321.81
  56   0.4586     88.690  0.0716    97.618  327.64
  57   0.4540     88.730  0.0676    97.644  333.43
  58   0.4748     88.220  0.0646    97.756  339.22
  59   0.4570     89.000  0.0602    97.950  345.01
  60   0.4705     89.060  0.0523    98.232  350.84
  61   0.4821     88.980  0.0509    98.280  356.64
  62   0.4846     88.320  0.0491    98.360  362.44
  63   0.4885     88.830  0.0470    98.368  368.26
  64   0.4925     88.910  0.0417    98.642  374.05
  65   0.4948     89.100  0.0405    98.638  379.84
  66   0.5082     88.740  0.0392    98.738  385.64
  67   0.5069     89.160  0.0355    98.788  391.49
  68   0.4860     89.210  0.0340    98.840  397.32
  69   0.5211     88.970  0.0311    98.986  403.15
  70   0.5096     89.130  0.0279    99.082  408.95
  71   0.5075     89.420  0.0258    99.174  414.77
  72   0.5335     89.020  0.0260    99.140  420.64
  73   0.5114     89.210  0.0243    99.234  426.44
  74   0.5357     89.170  0.0243    99.212  432.25
  75   0.5191     89.460  0.0219    99.286  438.04
  76   0.5357     89.540  0.0203    99.340  443.84
  77   0.5344     89.120  0.0200    99.384  449.65
  78   0.5267     89.430  0.0193    99.388  455.49
  79   0.5447     89.140  0.0193    99.390  461.31
  80   0.5449     89.270  0.0173    99.468  467.12
  81   0.5694     89.180  0.0162    99.508  472.92
  82   0.5538     89.480  0.0164    99.454  478.74
  83   0.5548     89.630  0.0140    99.564  484.57
  84   0.5501     89.330  0.0147    99.522  490.38
  85   0.5646     89.460  0.0149    99.510  496.27
