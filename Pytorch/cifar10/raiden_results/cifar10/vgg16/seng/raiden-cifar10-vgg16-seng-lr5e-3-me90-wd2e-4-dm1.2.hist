Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9172     26.700  2.1973    15.434  7.61
   2   1.8209     32.620  1.7962    30.630  13.42
   3   1.3754     48.210  1.5389    41.418  19.23
   4   1.2263     55.070  1.3587    49.456  25.04
   5   1.1251     59.660  1.1790    57.136  30.92
   6   1.0145     63.660  1.0620    61.250  36.71
   7   0.8631     69.190  0.9676    65.008  42.52
   8   0.8453     70.490  0.8768    68.514  48.34
   9   0.7982     72.570  0.8124    70.834  54.19
  10   0.7175     74.970  0.7585    73.114  59.99
  11   0.7171     75.500  0.7132    74.990  65.89
  12   0.6710     76.950  0.6709    76.276  71.70
  13   0.6664     77.240  0.6460    77.352  77.51
  14   0.6188     78.490  0.6152    78.500  83.32
  15   0.6309     78.840  0.5840    79.586  89.13
  16   0.5867     80.280  0.5568    80.394  94.98
  17   0.5966     79.780  0.5442    81.214  100.81
  18   0.5543     81.100  0.5198    81.948  106.61
  19   0.5382     81.480  0.4986    82.792  112.46
  20   0.5147     82.520  0.4780    83.498  118.29
  21   0.5184     83.150  0.4586    84.040  124.13
  22   0.5296     82.300  0.4436    84.602  129.95
  23   0.5202     82.990  0.4352    84.892  135.84
  24   0.4983     82.530  0.4186    85.534  141.67
  25   0.4868     83.810  0.4086    85.656  147.51
  26   0.4838     83.790  0.3911    86.456  153.36
  27   0.4746     84.320  0.3787    86.864  159.17
  28   0.4706     84.570  0.3670    87.240  164.98
  29   0.4643     83.910  0.3553    87.558  170.88
  30   0.4654     84.410  0.3385    88.352  176.70
  31   0.4511     85.180  0.3263    88.746  182.51
  32   0.4384     85.690  0.3165    89.048  188.33
  33   0.4812     84.320  0.3061    89.556  194.17
  34   0.4353     85.840  0.2992    89.730  199.98
  35   0.4590     85.390  0.2933    89.824  205.85
  36   0.4711     85.250  0.2806    90.312  211.68
  37   0.4482     84.920  0.2748    90.532  217.50
  38   0.4344     86.260  0.2623    91.008  223.31
  39   0.4590     86.050  0.2488    91.312  229.12
  40   0.4608     85.490  0.2432    91.600  235.03
  41   0.4446     86.090  0.2376    91.660  240.86
  42   0.4706     85.740  0.2256    92.230  246.68
  43   0.4481     86.220  0.2280    92.150  252.51
  44   0.4420     86.500  0.2129    92.618  258.33
  45   0.4696     86.160  0.2120    92.592  264.14
  46   0.4499     86.150  0.2059    92.770  270.03
  47   0.4493     86.500  0.1951    93.188  275.84
  48   0.4580     86.400  0.1852    93.626  281.67
  49   0.4700     86.520  0.1853    93.568  287.50
  50   0.4323     87.510  0.1793    93.786  293.24
  51   0.4476     86.520  0.1741    93.950  299.13
  52   0.4681     86.470  0.1708    94.036  304.94
  53   0.4574     87.120  0.1594    94.502  310.78
  54   0.4697     87.070  0.1597    94.422  316.60
  55   0.4654     86.990  0.1523    94.748  322.43
  56   0.4588     86.990  0.1458    94.916  328.27
  57   0.4783     87.010  0.1357    95.214  334.18
  58   0.4550     87.360  0.1372    95.310  339.98
  59   0.4930     87.330  0.1272    95.588  345.79
  60   0.4681     87.590  0.1257    95.642  351.60
  61   0.4793     87.680  0.1218    95.698  357.40
  62   0.4833     87.350  0.1177    95.876  363.27
  63   0.4988     86.580  0.1119    96.142  369.11
  64   0.4983     87.460  0.1069    96.304  374.95
  65   0.4968     87.690  0.1018    96.452  380.79
  66   0.4925     87.690  0.0975    96.636  386.60
  67   0.4878     87.700  0.0978    96.592  392.41
  68   0.5126     87.730  0.0937    96.820  398.30
  69   0.5153     87.700  0.0925    96.862  404.15
  70   0.5419     87.500  0.0868    97.014  409.95
  71   0.5154     88.020  0.0865    96.946  415.80
  72   0.5296     87.830  0.0776    97.262  421.60
  73   0.5215     87.670  0.0825    97.090  427.41
  74   0.5178     87.640  0.0743    97.492  433.31
  75   0.5456     87.810  0.0734    97.396  439.13
  76   0.5481     87.580  0.0718    97.564  444.95
  77   0.5186     88.040  0.0712    97.504  450.77
  78   0.5200     87.990  0.0677    97.668  456.58
  79   0.5355     87.980  0.0609    97.932  462.38
  80   0.5529     87.780  0.0615    97.892  468.28
  81   0.5422     87.890  0.0606    97.882  474.11
  82   0.5374     87.720  0.0629    97.794  479.95
  83   0.5586     87.830  0.0547    98.094  485.76
  84   0.5537     87.970  0.0567    98.086  491.60
  85   0.5694     88.030  0.0552    98.130  497.42
  86   0.5463     87.940  0.0531    98.124  503.30
  87   0.5803     87.970  0.0511    98.242  509.10
  88   0.5776     87.860  0.0498    98.318  514.94
  89   0.5682     88.140  0.0500    98.270  520.75
  90   0.6102     88.380  0.0493    98.318  526.59
