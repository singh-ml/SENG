Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1538     17.440  2.2199    15.856  7.74
   2   1.7237     35.620  1.9763    25.308  13.55
   3   1.4365     45.580  1.6205    38.044  19.37
   4   1.3011     51.650  1.3752    49.142  25.18
   5   1.0558     62.300  1.1351    59.558  30.98
   6   0.8615     70.380  0.9670    66.300  36.80
   7   0.8109     72.370  0.8467    70.848  42.73
   8   0.6784     77.340  0.7486    74.858  48.55
   9   0.6394     78.670  0.6874    77.000  54.37
  10   0.6405     78.530  0.6262    79.196  60.20
  11   0.5902     80.390  0.5754    80.780  66.04
  12   0.5813     79.980  0.5346    82.108  71.86
  13   0.5392     82.080  0.5224    82.668  77.77
  14   0.5374     82.300  0.4768    83.980  83.59
  15   0.5802     81.310  0.4447    85.428  89.41
  16   0.5196     82.820  0.4316    85.912  95.24
  17   0.5368     82.420  0.4148    86.476  101.08
  18   0.4841     83.910  0.3813    87.408  106.97
  19   0.5198     83.540  0.3655    88.006  112.80
  20   0.4871     83.980  0.3541    88.256  118.61
  21   0.4544     85.640  0.3382    88.756  124.42
  22   0.4480     85.560  0.3156    89.496  130.23
  23   0.4480     86.210  0.3067    89.790  136.06
  24   0.4286     86.410  0.2995    90.010  141.95
  25   0.4274     86.350  0.2773    90.764  147.76
  26   0.4236     86.170  0.2722    90.934  153.60
  27   0.3889     88.190  0.2554    91.332  159.42
  28   0.4155     87.190  0.2399    92.056  165.24
  29   0.4248     86.640  0.2342    92.224  171.06
  30   0.4161     87.270  0.2423    92.008  176.95
  31   0.4382     87.180  0.2116    92.972  182.76
  32   0.4028     88.400  0.2083    93.142  188.58
  33   0.4493     86.600  0.1913    93.542  194.42
  34   0.4020     88.230  0.1941    93.586  200.24
  35   0.4145     87.780  0.1779    94.080  206.06
  36   0.4315     87.350  0.1688    94.256  211.94
  37   0.4395     87.280  0.1593    94.640  217.76
  38   0.4249     87.970  0.1531    94.902  223.58
  39   0.4223     88.140  0.1399    95.282  229.41
  40   0.4097     88.180  0.1419    95.296  235.22
  41   0.4127     89.000  0.1245    95.872  241.03
  42   0.4436     87.940  0.1329    95.568  246.93
  43   0.4195     88.590  0.1197    95.962  252.75
  44   0.4313     88.370  0.1136    96.176  258.57
  45   0.4148     89.120  0.1057    96.438  264.40
  46   0.4136     89.240  0.1022    96.576  270.23
  47   0.4302     89.070  0.0957    96.758  276.05
  48   0.4106     88.770  0.0934    96.834  281.93
  49   0.4368     89.200  0.0813    97.256  287.78
  50   0.4311     89.470  0.0770    97.306  293.52
  51   0.4496     89.400  0.0737    97.546  299.35
  52   0.4319     89.500  0.0689    97.666  305.19
  53   0.4655     88.960  0.0636    97.916  311.09
  54   0.4281     89.750  0.0572    98.088  316.93
  55   0.4383     89.850  0.0512    98.238  322.74
  56   0.4500     89.370  0.0492    98.328  328.56
  57   0.4770     89.070  0.0453    98.476  334.37
  58   0.4474     89.790  0.0434    98.522  340.20
  59   0.4768     89.490  0.0365    98.764  346.09
  60   0.4771     89.560  0.0353    98.776  351.91
  61   0.4719     89.860  0.0299    98.998  357.72
  62   0.4604     90.220  0.0290    99.040  363.53
  63   0.4797     89.850  0.0279    99.086  369.36
  64   0.4949     89.960  0.0239    99.222  375.18
  65   0.4858     90.190  0.0232    99.202  381.11
  66   0.4853     90.360  0.0210    99.290  386.93
  67   0.5024     90.180  0.0183    99.418  392.77
  68   0.4848     90.480  0.0163    99.434  398.62
  69   0.4788     90.520  0.0147    99.512  404.44
  70   0.4847     90.690  0.0125    99.596  410.28
  71   0.4889     90.870  0.0113    99.618  416.16
  72   0.5055     90.780  0.0104    99.654  421.98
  73   0.4977     90.670  0.0099    99.676  427.80
  74   0.5103     90.960  0.0086    99.730  433.61
  75   0.5269     90.390  0.0071    99.818  439.43
  76   0.5031     90.870  0.0066    99.808  445.25
  77   0.5150     90.940  0.0050    99.834  451.18
  78   0.5148     90.820  0.0057    99.828  457.03
  79   0.5168     90.870  0.0047    99.870  462.85
  80   0.5167     91.050  0.0050    99.852  468.69
  81   0.5168     91.050  0.0051    99.850  474.50
  82   0.5098     91.050  0.0044    99.858  480.34
  83   0.5126     91.050  0.0039    99.894  486.21
  84   0.5122     91.030  0.0032    99.916  492.05
  85   0.5174     91.030  0.0035    99.892  497.87
  86   0.5127     91.190  0.0033    99.912  503.71
  87   0.5137     91.280  0.0033    99.906  509.53
  88   0.5163     91.240  0.0030    99.934  515.35
  89   0.5148     91.150  0.0029    99.912  521.21
  90   0.5203     91.130  0.0032    99.912  527.03
