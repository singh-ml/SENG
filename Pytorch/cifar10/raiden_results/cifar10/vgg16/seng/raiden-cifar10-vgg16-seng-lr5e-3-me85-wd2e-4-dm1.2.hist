Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9600     28.270  2.2212    15.510  7.70
   2   1.6315     38.930  1.8623    29.560  13.61
   3   1.4341     45.860  1.6040    39.340  19.43
   4   1.3143     52.070  1.4075    47.822  25.26
   5   1.1072     60.150  1.2474    54.172  31.09
   6   1.0312     62.340  1.0967    60.098  36.88
   7   0.8882     67.690  0.9935    64.290  42.70
   8   0.8695     68.950  0.9084    67.464  48.58
   9   0.7907     71.970  0.8319    70.136  54.38
  10   0.7361     74.640  0.7784    72.436  60.18
  11   0.7174     75.340  0.7294    74.190  65.97
  12   0.6662     76.900  0.6916    75.836  71.78
  13   0.7130     75.480  0.6565    77.028  77.59
  14   0.6254     78.610  0.6325    77.874  83.47
  15   0.5764     80.010  0.5942    79.186  89.29
  16   0.5843     80.010  0.5733    80.020  95.09
  17   0.5849     80.260  0.5454    81.108  100.92
  18   0.5527     80.690  0.5247    81.666  106.72
  19   0.5754     80.780  0.5080    82.334  112.53
  20   0.5337     81.610  0.4868    83.160  118.41
  21   0.5071     82.760  0.4702    83.598  124.25
  22   0.5270     82.210  0.4554    84.184  130.09
  23   0.4901     83.200  0.4374    84.778  135.92
  24   0.4953     83.370  0.4241    85.400  141.76
  25   0.5001     83.500  0.4090    85.958  147.63
  26   0.5169     83.030  0.3964    86.200  153.44
  27   0.4758     84.280  0.3847    86.586  159.23
  28   0.4810     84.090  0.3682    87.108  165.04
  29   0.4678     84.390  0.3525    87.724  170.86
  30   0.4743     84.230  0.3481    87.904  176.69
  31   0.4509     84.930  0.3354    88.422  182.57
  32   0.4649     84.170  0.3199    88.988  188.37
  33   0.4613     85.270  0.3189    88.996  194.17
  34   0.4247     86.020  0.3008    89.658  199.97
  35   0.4588     85.280  0.2885    89.980  205.77
  36   0.4263     86.140  0.2889    90.028  211.67
  37   0.4860     84.830  0.2736    90.558  217.47
  38   0.4336     86.480  0.2712    90.732  223.27
  39   0.4454     86.360  0.2561    91.102  229.08
  40   0.4366     86.200  0.2456    91.644  234.88
  41   0.4259     86.720  0.2463    91.496  240.68
  42   0.4390     86.700  0.2367    91.770  246.56
  43   0.4232     86.400  0.2243    92.276  252.37
  44   0.4333     86.750  0.2163    92.612  258.18
  45   0.4371     86.570  0.2168    92.432  263.96
  46   0.4399     86.500  0.2089    92.742  269.76
  47   0.4424     86.810  0.1958    93.254  275.67
  48   0.4354     86.830  0.1861    93.676  281.48
  49   0.4469     87.180  0.1871    93.388  287.30
  50   0.4243     87.000  0.1812    93.732  293.05
  51   0.4516     86.840  0.1785    93.830  298.86
  52   0.4394     86.640  0.1715    94.070  304.64
  53   0.4510     87.140  0.1600    94.546  310.53
  54   0.4707     86.190  0.1592    94.492  316.36
  55   0.4719     86.950  0.1521    94.778  322.19
  56   0.4427     87.230  0.1412    95.200  327.97
  57   0.4533     86.920  0.1398    95.148  333.78
  58   0.4553     87.230  0.1358    95.330  339.57
  59   0.4687     87.290  0.1303    95.422  345.39
  60   0.4506     87.280  0.1223    95.736  351.19
  61   0.4824     87.070  0.1156    95.926  356.99
  62   0.4911     87.200  0.1164    95.974  362.82
  63   0.4843     87.230  0.1130    96.100  368.62
  64   0.4845     87.150  0.1074    96.326  374.42
  65   0.4915     87.310  0.1039    96.428  380.22
  66   0.5001     87.000  0.1043    96.398  386.10
  67   0.5011     87.460  0.0988    96.658  391.90
  68   0.4932     87.410  0.0917    96.878  397.69
  69   0.5307     87.550  0.0859    97.046  403.50
  70   0.5125     87.480  0.0881    96.918  409.30
  71   0.4989     87.590  0.0854    97.064  415.13
  72   0.5144     87.980  0.0808    97.246  421.00
  73   0.5100     87.430  0.0761    97.404  426.80
  74   0.5323     87.670  0.0741    97.448  432.63
  75   0.5211     87.590  0.0745    97.330  438.44
  76   0.5376     87.030  0.0749    97.432  444.26
  77   0.5217     87.710  0.0695    97.690  450.11
  78   0.5307     87.730  0.0686    97.652  455.91
  79   0.5425     87.690  0.0665    97.734  461.75
  80   0.5347     87.750  0.0655    97.720  467.55
  81   0.5480     87.800  0.0598    97.940  473.38
  82   0.5552     87.690  0.0624    97.846  479.19
  83   0.5414     87.760  0.0610    97.842  485.04
  84   0.5569     87.500  0.0577    97.996  490.85
  85   0.5565     87.590  0.0586    97.978  496.68
