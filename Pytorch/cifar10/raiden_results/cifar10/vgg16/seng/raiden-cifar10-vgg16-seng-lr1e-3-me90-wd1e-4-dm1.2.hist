Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2906     12.640  2.2996    10.576  7.64
   2   2.1549     21.430  2.2686    13.592  13.42
   3   1.8722     28.150  2.0688    21.616  19.22
   4   1.7196     34.370  1.8579    28.082  25.01
   5   1.6788     36.080  1.7374    33.020  30.86
   6   1.5467     41.680  1.6591    36.476  36.66
   7   1.4730     44.680  1.5572    40.748  42.47
   8   1.4182     46.970  1.4855    43.856  48.27
   9   1.3574     48.570  1.4206    46.714  54.06
  10   1.2779     52.920  1.3645    48.916  59.86
  11   1.2389     54.000  1.3120    51.048  65.75
  12   1.1794     56.830  1.2673    53.014  71.53
  13   1.1309     58.890  1.2129    55.360  77.35
  14   1.0869     60.870  1.1742    56.866  83.16
  15   1.0612     61.660  1.1306    58.744  88.95
  16   1.0298     62.680  1.0914    60.178  94.84
  17   1.0154     63.080  1.0599    61.374  100.66
  18   0.9915     63.860  1.0255    62.990  106.47
  19   0.9419     65.440  1.0003    63.832  112.29
  20   0.9327     66.160  0.9677    64.858  118.08
  21   0.8956     67.700  0.9408    65.916  123.91
  22   0.8723     68.410  0.9169    67.034  129.79
  23   0.8395     69.900  0.8887    68.020  135.59
  24   0.8286     70.470  0.8698    68.806  141.41
  25   0.8266     70.280  0.8406    69.608  147.21
  26   0.7942     71.730  0.8196    70.726  153.00
  27   0.7761     72.290  0.8075    71.316  158.81
  28   0.7757     72.560  0.7849    72.014  164.68
  29   0.7516     73.310  0.7741    72.218  170.47
  30   0.7321     74.530  0.7532    73.404  176.29
  31   0.7250     74.310  0.7352    73.870  182.13
  32   0.7066     75.110  0.7241    74.138  187.93
  33   0.6975     75.350  0.7068    74.906  193.82
  34   0.7266     74.630  0.6920    75.314  199.63
  35   0.6701     76.750  0.6781    75.868  205.44
  36   0.6604     76.740  0.6682    76.274  211.25
  37   0.6509     77.250  0.6592    76.756  217.07
  38   0.6588     76.480  0.6411    77.272  222.88
  39   0.6761     76.590  0.6414    77.440  228.75
  40   0.6208     78.580  0.6260    77.980  234.57
  41   0.6152     78.780  0.6150    78.296  240.38
  42   0.6136     78.610  0.6007    78.820  246.17
  43   0.6082     78.830  0.5960    78.836  251.99
  44   0.5967     78.980  0.5840    79.344  257.81
  45   0.6023     78.940  0.5754    79.662  263.71
  46   0.6234     78.910  0.5677    79.898  269.51
  47   0.5857     79.980  0.5607    80.132  275.32
  48   0.5902     79.730  0.5487    80.698  281.14
  49   0.6060     79.620  0.5417    80.962  286.94
  50   0.5696     80.590  0.5369    81.154  292.67
  51   0.5611     80.620  0.5296    81.466  298.56
  52   0.5656     80.540  0.5224    81.640  304.35
  53   0.5714     80.090  0.5135    82.042  310.15
  54   0.5618     80.570  0.5088    82.078  315.96
  55   0.5519     81.250  0.5000    82.320  321.78
  56   0.5532     81.170  0.4924    82.730  327.67
  57   0.5445     81.580  0.4884    82.798  333.50
  58   0.5460     81.550  0.4840    82.970  339.31
  59   0.5602     81.390  0.4725    83.440  345.13
  60   0.5384     81.700  0.4633    83.964  350.96
  61   0.5359     82.040  0.4596    83.842  356.76
  62   0.5168     82.320  0.4530    84.144  362.62
  63   0.5193     82.670  0.4464    84.468  368.44
  64   0.5186     82.400  0.4416    84.646  374.24
  65   0.5436     81.780  0.4334    84.794  380.05
  66   0.5236     82.370  0.4298    85.166  385.86
  67   0.5586     81.740  0.4234    85.132  391.75
  68   0.5208     82.610  0.4184    85.218  397.59
  69   0.5325     82.110  0.4149    85.568  403.41
  70   0.5155     82.750  0.4056    85.806  409.22
  71   0.5245     82.520  0.4029    85.872  415.02
  72   0.5186     83.340  0.4022    85.934  420.83
  73   0.5281     82.670  0.3938    86.194  426.68
  74   0.5130     82.800  0.3925    86.274  432.51
  75   0.5046     83.110  0.3809    86.648  438.34
  76   0.5119     83.140  0.3787    86.722  444.14
  77   0.5237     83.010  0.3681    87.138  449.98
  78   0.5057     83.830  0.3694    87.084  455.87
  79   0.4978     84.350  0.3557    87.540  461.70
  80   0.5025     83.370  0.3578    87.510  467.54
  81   0.5006     83.490  0.3537    87.584  473.34
  82   0.5030     83.670  0.3537    87.570  479.18
  83   0.5028     83.930  0.3443    87.868  485.01
  84   0.5141     83.440  0.3389    88.126  490.90
  85   0.4878     84.170  0.3379    88.110  496.71
  86   0.4898     83.990  0.3326    88.482  502.53
  87   0.5008     83.670  0.3257    88.414  508.35
  88   0.5131     84.080  0.3198    88.744  514.17
  89   0.5144     83.880  0.3163    88.924  519.99
  90   0.4912     84.450  0.3151    88.976  525.79
