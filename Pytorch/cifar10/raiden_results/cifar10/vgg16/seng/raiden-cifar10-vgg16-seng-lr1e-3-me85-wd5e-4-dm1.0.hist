Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2828     15.170  2.2979    11.030  7.74
   2   1.9961     24.110  2.1745    17.858  13.55
   3   1.7620     32.150  1.9237    26.126  19.35
   4   1.6553     37.220  1.7721    32.086  25.15
   5   1.5324     42.060  1.6598    36.764  30.96
   6   1.4565     45.570  1.5574    41.280  36.81
   7   1.3488     49.410  1.4721    44.744  42.63
   8   1.2926     51.900  1.3942    47.778  48.43
   9   1.2820     53.010  1.3423    50.162  54.23
  10   1.1845     57.200  1.2803    52.634  60.03
  11   1.1675     57.280  1.2247    54.946  65.83
  12   1.0871     60.960  1.1737    57.066  71.70
  13   1.0502     62.210  1.1263    58.838  77.54
  14   1.0446     62.500  1.0783    60.642  83.34
  15   0.9916     64.800  1.0424    62.346  89.16
  16   0.9716     65.160  1.0062    63.646  94.97
  17   0.9225     66.540  0.9727    64.948  100.79
  18   0.9008     67.490  0.9458    65.860  106.68
  19   0.8883     68.240  0.9097    67.390  112.47
  20   0.8367     70.410  0.8873    68.174  118.28
  21   0.8271     70.340  0.8571    69.188  124.10
  22   0.7794     72.250  0.8294    70.154  129.90
  23   0.7731     72.770  0.8094    71.000  135.76
  24   0.7702     72.570  0.7891    72.036  141.56
  25   0.7426     73.960  0.7684    72.612  147.36
  26   0.7600     73.310  0.7411    73.464  153.17
  27   0.7109     74.970  0.7265    74.264  158.98
  28   0.6977     75.520  0.7119    74.738  164.79
  29   0.6812     76.500  0.6926    75.390  170.69
  30   0.7012     76.040  0.6754    75.998  176.51
  31   0.6682     76.600  0.6630    76.586  182.35
  32   0.6521     77.880  0.6533    76.832  188.18
  33   0.6383     77.720  0.6326    77.688  194.00
  34   0.6661     77.340  0.6215    77.914  199.81
  35   0.6196     78.710  0.6121    78.506  205.69
  36   0.6193     78.550  0.5950    79.030  211.52
  37   0.6093     78.940  0.5889    79.366  217.31
  38   0.6295     78.120  0.5723    79.746  223.10
  39   0.6203     78.520  0.5763    79.812  228.91
  40   0.6190     79.020  0.5597    80.242  234.79
  41   0.5990     79.140  0.5466    80.800  240.62
  42   0.5983     79.690  0.5391    81.178  246.46
  43   0.5884     80.040  0.5324    81.300  252.28
  44   0.6104     79.520  0.5219    81.668  258.13
  45   0.5789     80.860  0.5130    81.836  263.96
  46   0.5584     80.640  0.5099    82.178  269.87
  47   0.5597     81.030  0.4979    82.636  275.68
  48   0.5592     80.940  0.4852    83.044  281.51
  49   0.5610     80.820  0.4838    83.168  287.31
  50   0.5485     81.680  0.4753    83.270  293.05
  51   0.5581     81.290  0.4654    83.744  298.86
  52   0.5393     82.070  0.4639    83.796  304.73
  53   0.5586     81.220  0.4499    84.228  310.58
  54   0.5548     81.670  0.4464    84.462  316.38
  55   0.5357     81.830  0.4384    84.828  322.18
  56   0.5354     82.300  0.4365    84.616  327.99
  57   0.5421     82.090  0.4273    85.186  333.79
  58   0.5213     82.460  0.4218    85.338  339.68
  59   0.5206     82.760  0.4182    85.470  345.48
  60   0.5068     83.150  0.4134    85.606  351.29
  61   0.5452     82.680  0.4018    86.020  357.09
  62   0.5304     82.480  0.3955    86.178  362.89
  63   0.5172     82.970  0.3945    86.168  368.68
  64   0.4898     83.380  0.3856    86.698  374.52
  65   0.5069     83.060  0.3764    86.876  380.35
  66   0.5247     82.660  0.3771    86.750  386.18
  67   0.5276     83.280  0.3642    87.418  392.00
  68   0.5082     83.320  0.3608    87.432  397.81
  69   0.4857     83.940  0.3565    87.570  403.68
  70   0.5219     83.090  0.3533    87.718  409.51
  71   0.5249     83.570  0.3509    87.640  415.30
  72   0.5344     82.570  0.3440    87.954  421.10
  73   0.5039     83.830  0.3393    88.162  426.92
  74   0.5047     84.300  0.3344    88.390  432.79
  75   0.4925     84.210  0.3350    88.334  438.60
  76   0.5295     83.750  0.3205    88.718  444.43
  77   0.5013     84.420  0.3240    88.722  450.22
  78   0.4913     84.120  0.3114    89.156  456.05
  79   0.5045     83.840  0.3072    89.280  461.84
  80   0.5162     83.880  0.3007    89.566  467.73
  81   0.5012     84.360  0.3026    89.372  473.56
  82   0.4957     84.170  0.2940    89.634  479.37
  83   0.4971     84.820  0.2974    89.654  485.18
  84   0.5134     84.050  0.2898    89.820  491.02
  85   0.4974     84.240  0.2814    90.226  496.84
