Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8848     29.530  2.1688    16.968  7.74
   2   1.5033     42.280  1.7434    33.308  13.56
   3   1.2990     52.430  1.4722    44.686  19.38
   4   1.1024     60.320  1.2706    53.330  25.24
   5   0.9979     63.120  1.0963    60.164  31.06
   6   0.8772     68.980  0.9648    65.186  36.87
   7   0.8441     70.120  0.8750    68.672  42.68
   8   0.7503     73.170  0.7943    71.766  48.48
   9   0.6801     76.090  0.7369    74.022  54.30
  10   0.6868     76.430  0.6819    75.998  60.19
  11   0.6278     78.610  0.6509    77.252  65.99
  12   0.6515     77.830  0.6068    79.030  71.82
  13   0.5880     80.420  0.5757    79.958  77.62
  14   0.6089     79.400  0.5421    81.188  83.43
  15   0.5336     82.080  0.5150    82.126  89.23
  16   0.5414     82.120  0.4901    83.138  95.15
  17   0.5492     82.080  0.4677    83.908  100.97
  18   0.5400     82.340  0.4460    84.564  106.77
  19   0.4978     83.170  0.4342    85.156  112.62
  20   0.5102     83.040  0.4135    85.760  118.47
  21   0.5046     83.500  0.3993    86.250  124.34
  22   0.4823     84.300  0.3807    86.836  130.18
  23   0.4830     84.150  0.3667    87.518  135.99
  24   0.4982     83.510  0.3543    87.780  141.82
  25   0.4513     84.660  0.3430    88.138  147.64
  26   0.4586     84.890  0.3240    88.746  153.46
  27   0.4603     85.350  0.3137    89.180  159.37
  28   0.4727     85.080  0.3025    89.486  165.19
  29   0.4419     86.140  0.2963    89.800  171.01
  30   0.4416     85.480  0.2777    90.458  176.82
  31   0.4505     85.660  0.2666    90.914  182.65
  32   0.4392     86.420  0.2531    91.418  188.55
  33   0.4443     86.280  0.2488    91.442  194.37
  34   0.4356     86.440  0.2403    91.672  200.19
  35   0.4473     86.750  0.2313    92.044  206.02
  36   0.4542     86.640  0.2246    92.248  211.83
  37   0.4609     86.690  0.2182    92.480  217.64
  38   0.4854     86.260  0.2054    92.960  223.46
  39   0.4403     86.880  0.2036    92.970  229.27
  40   0.4343     86.960  0.1923    93.302  235.10
  41   0.4509     86.970  0.1813    93.684  240.91
  42   0.4491     86.710  0.1771    93.944  246.77
  43   0.4538     87.330  0.1683    94.286  252.57
  44   0.4513     86.980  0.1631    94.436  258.44
  45   0.4617     87.080  0.1599    94.516  264.28
  46   0.4533     87.540  0.1497    94.754  270.08
  47   0.4708     87.480  0.1386    95.244  275.88
  48   0.4517     87.920  0.1357    95.376  281.68
  49   0.4953     86.490  0.1345    95.338  287.49
  50   0.4674     87.290  0.1284    95.544  293.34
  51   0.4800     87.600  0.1207    95.788  299.15
  52   0.4627     88.040  0.1156    95.986  304.97
  53   0.4992     87.380  0.1078    96.216  310.80
  54   0.4934     87.200  0.1086    96.226  316.60
  55   0.4690     87.950  0.1033    96.430  322.42
  56   0.4777     88.170  0.0941    96.766  328.25
  57   0.5008     87.960  0.0940    96.694  334.07
  58   0.4904     88.160  0.0906    96.870  339.89
  59   0.4812     88.200  0.0852    97.022  345.74
  60   0.5139     87.880  0.0823    97.216  351.55
  61   0.5190     88.050  0.0779    97.270  357.44
  62   0.5148     87.900  0.0710    97.510  363.25
  63   0.5365     87.550  0.0697    97.622  369.07
  64   0.4997     88.340  0.0670    97.696  374.88
  65   0.5204     88.240  0.0614    97.894  380.68
  66   0.5626     88.060  0.0604    97.940  386.51
  67   0.5482     88.520  0.0592    97.990  392.41
  68   0.5342     88.020  0.0586    97.990  398.26
  69   0.5361     88.730  0.0523    98.254  404.05
  70   0.5755     88.140  0.0511    98.280  409.90
  71   0.5324     88.560  0.0525    98.228  415.72
  72   0.5523     88.400  0.0491    98.326  421.53
  73   0.5744     88.010  0.0457    98.424  427.36
  74   0.5864     88.510  0.0464    98.442  433.19
  75   0.5830     88.490  0.0390    98.662  439.00
  76   0.5824     88.450  0.0368    98.764  444.82
  77   0.5961     88.530  0.0370    98.732  450.64
  78   0.5705     88.480  0.0390    98.654  456.52
  79   0.5573     88.790  0.0377    98.708  462.32
  80   0.5714     88.700  0.0335    98.884  468.15
  81   0.5994     88.750  0.0346    98.798  473.97
  82   0.6190     88.420  0.0325    98.886  479.81
  83   0.6335     88.250  0.0329    98.864  485.68
  84   0.6108     88.750  0.0316    98.888  491.50
  85   0.6107     87.790  0.0326    98.880  497.30
