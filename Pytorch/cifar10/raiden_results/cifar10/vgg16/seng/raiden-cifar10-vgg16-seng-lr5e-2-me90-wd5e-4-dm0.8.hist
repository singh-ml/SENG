Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3031     10.000  2.2974    10.732  7.87
   2   1.9803     23.070  2.1832    16.928  13.67
   3   1.6403     37.230  1.8723    28.564  19.48
   4   1.4161     48.360  1.6174    39.484  25.28
   5   1.2576     54.560  1.3869    49.316  31.11
   6   1.2251     58.530  1.1468    59.200  37.01
   7   0.8481     71.070  0.9933    65.824  42.85
   8   0.8278     73.100  0.8521    71.028  48.66
   9   0.7651     74.930  0.7806    73.786  54.46
  10   0.6730     78.720  0.6932    77.176  60.30
  11   0.7168     77.580  0.6517    78.596  66.22
  12   0.6527     78.380  0.6153    79.790  72.03
  13   0.5923     80.800  0.5625    81.576  77.83
  14   0.5944     81.300  0.5315    82.710  83.68
  15   0.6049     80.830  0.5120    83.280  89.49
  16   0.5138     82.930  0.4884    84.250  95.32
  17   0.5497     82.450  0.4546    85.214  101.17
  18   0.4707     85.310  0.4410    85.794  107.00
  19   0.5278     83.880  0.4281    86.202  112.81
  20   0.4917     84.690  0.4057    86.838  118.62
  21   0.4697     84.790  0.3942    87.028  124.42
  22   0.4785     84.990  0.3796    87.778  130.31
  23   0.4624     85.110  0.3709    88.008  136.12
  24   0.4861     85.440  0.3431    88.820  141.93
  25   0.4219     86.870  0.3254    89.540  147.74
  26   0.4687     85.180  0.3185    89.632  153.59
  27   0.4047     87.470  0.3061    89.964  159.40
  28   0.4259     86.490  0.2917    90.480  165.28
  29   0.4378     86.760  0.2777    90.906  171.11
  30   0.4134     87.090  0.2792    90.826  176.92
  31   0.4269     87.350  0.2642    91.430  182.72
  32   0.3927     87.930  0.2508    91.788  188.57
  33   0.4266     87.220  0.2488    91.838  194.37
  34   0.4795     85.740  0.2345    92.444  200.23
  35   0.3955     87.690  0.2309    92.478  206.04
  36   0.3699     88.580  0.2189    92.788  211.85
  37   0.3799     88.850  0.2067    93.222  217.66
  38   0.3719     88.660  0.2024    93.336  223.48
  39   0.3942     88.390  0.2018    93.358  229.35
  40   0.4073     88.090  0.1911    93.666  235.19
  41   0.4001     88.510  0.1824    93.906  241.01
  42   0.3841     88.570  0.1737    94.284  246.82
  43   0.3820     89.230  0.1661    94.608  252.64
  44   0.3731     88.410  0.1650    94.588  258.46
  45   0.3736     89.130  0.1472    95.206  264.27
  46   0.3749     89.260  0.1476    95.126  270.18
  47   0.3661     89.580  0.1442    95.268  276.00
  48   0.4295     89.200  0.1268    95.974  281.81
  49   0.3936     89.950  0.1269    95.880  287.61
  50   0.3711     89.500  0.1178    96.090  293.36
  51   0.3844     89.130  0.1090    96.428  299.22
  52   0.3812     89.510  0.1025    96.556  305.03
  53   0.3703     90.160  0.0983    96.716  310.86
  54   0.4101     89.540  0.0905    96.992  316.67
  55   0.3822     90.090  0.0834    97.230  322.52
  56   0.3760     90.270  0.0787    97.338  328.39
  57   0.3897     89.960  0.0756    97.494  334.19
  58   0.4030     89.990  0.0666    97.778  340.01
  59   0.3865     90.310  0.0709    97.674  345.84
  60   0.3886     90.270  0.0617    97.924  351.65
  61   0.4071     90.130  0.0504    98.294  357.47
  62   0.3918     90.750  0.0481    98.302  363.33
  63   0.4096     90.560  0.0479    98.416  369.14
  64   0.4102     90.380  0.0424    98.536  374.97
  65   0.3935     91.060  0.0406    98.650  380.76
  66   0.4212     90.770  0.0288    99.034  386.58
  67   0.3928     90.870  0.0282    99.048  392.49
  68   0.3998     91.150  0.0264    99.122  398.29
  69   0.4105     91.030  0.0216    99.296  404.12
  70   0.4076     90.960  0.0220    99.274  409.91
  71   0.4102     91.360  0.0166    99.468  415.71
  72   0.4111     91.320  0.0154    99.528  421.54
  73   0.4110     91.400  0.0114    99.634  427.43
  74   0.4199     91.300  0.0103    99.650  433.26
  75   0.4367     91.520  0.0097    99.694  439.09
  76   0.4113     91.770  0.0097    99.706  444.90
  77   0.4209     91.510  0.0082    99.714  450.69
  78   0.4164     91.610  0.0073    99.822  456.52
  79   0.4215     91.610  0.0063    99.808  462.42
  80   0.4229     91.560  0.0051    99.846  468.22
  81   0.4175     91.830  0.0055    99.840  474.04
  82   0.4210     91.800  0.0049    99.876  479.87
  83   0.4196     91.850  0.0042    99.898  485.67
  84   0.4235     92.070  0.0045    99.866  491.49
  85   0.4199     91.890  0.0038    99.898  497.40
  86   0.4205     91.960  0.0035    99.906  503.20
  87   0.4232     91.960  0.0034    99.924  509.02
  88   0.4201     91.980  0.0033    99.922  514.88
  89   0.4199     91.960  0.0037    99.906  520.72
  90   0.4204     91.940  0.0030    99.926  526.52
