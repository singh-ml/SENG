Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9404     26.850  2.1656    16.548  7.85
   2   1.6134     38.270  1.7243    33.418  13.66
   3   1.2683     53.340  1.4728    44.486  19.51
   4   1.0920     60.630  1.2399    54.492  25.34
   5   0.9785     64.310  1.0749    60.926  31.18
   6   0.9222     67.380  0.9493    65.678  37.06
   7   0.8807     69.970  0.8606    69.242  42.88
   8   0.7495     74.010  0.7964    71.742  48.69
   9   0.7628     73.220  0.7329    74.078  54.50
  10   0.6283     78.090  0.6787    76.188  60.35
  11   0.6084     79.070  0.6323    78.192  66.15
  12   0.5927     79.570  0.6002    79.094  72.04
  13   0.5543     81.070  0.5712    80.166  77.87
  14   0.5530     81.220  0.5376    81.226  83.70
  15   0.5534     80.990  0.5177    82.000  89.51
  16   0.5496     81.790  0.4819    83.376  95.33
  17   0.5272     82.370  0.4768    83.594  101.15
  18   0.5202     81.970  0.4455    84.536  106.99
  19   0.4988     83.390  0.4229    85.438  112.81
  20   0.4842     83.940  0.4160    85.730  118.62
  21   0.4986     83.650  0.3935    86.562  124.45
  22   0.4866     83.600  0.3837    86.780  130.29
  23   0.4646     84.290  0.3625    87.454  136.22
  24   0.4403     85.010  0.3470    88.144  142.06
  25   0.4524     85.060  0.3352    88.354  147.88
  26   0.4357     85.590  0.3167    89.028  153.72
  27   0.4592     85.260  0.3094    89.318  159.54
  28   0.4367     85.820  0.3029    89.576  165.36
  29   0.4286     86.080  0.2877    90.098  171.27
  30   0.4511     85.650  0.2799    90.410  177.10
  31   0.4402     86.730  0.2634    91.086  182.91
  32   0.4387     86.340  0.2577    91.106  188.76
  33   0.4323     86.590  0.2428    91.644  194.58
  34   0.4314     87.010  0.2354    92.002  200.41
  35   0.4266     87.020  0.2328    91.932  206.32
  36   0.4401     86.760  0.2258    92.230  212.15
  37   0.4150     86.890  0.2128    92.650  217.95
  38   0.4681     86.250  0.2093    92.886  223.76
  39   0.4350     87.000  0.1958    93.244  229.61
  40   0.4313     87.290  0.1870    93.576  235.43
  41   0.4134     87.020  0.1819    93.682  241.34
  42   0.4362     87.450  0.1713    94.226  247.16
  43   0.4402     87.440  0.1708    94.038  253.00
  44   0.4576     86.660  0.1678    94.162  258.84
  45   0.4433     87.180  0.1541    94.790  264.66
  46   0.4359     87.180  0.1534    94.704  270.56
  47   0.4503     87.320  0.1442    95.082  276.42
  48   0.4436     87.310  0.1375    95.236  282.24
  49   0.4593     87.510  0.1353    95.186  288.06
  50   0.4692     87.270  0.1304    95.572  293.81
  51   0.4662     87.250  0.1182    95.950  299.63
  52   0.4704     87.960  0.1220    95.916  305.52
  53   0.4754     87.410  0.1131    96.068  311.35
  54   0.4599     87.730  0.1114    96.108  317.18
  55   0.4722     87.940  0.1039    96.324  323.00
  56   0.4731     88.170  0.0994    96.514  328.81
  57   0.4812     87.960  0.0953    96.660  334.69
  58   0.4785     88.570  0.0905    96.918  340.53
  59   0.4805     88.310  0.0815    97.208  346.36
  60   0.4954     88.140  0.0811    97.114  352.18
  61   0.5177     87.450  0.0759    97.316  357.98
  62   0.4744     88.480  0.0857    96.948  363.83
  63   0.5176     87.700  0.0679    97.698  369.69
  64   0.5145     87.990  0.0694    97.622  375.51
  65   0.5067     87.760  0.0646    97.824  381.33
  66   0.5238     88.060  0.0621    97.790  387.17
  67   0.4957     88.420  0.0601    97.928  392.99
  68   0.5350     87.820  0.0581    98.004  398.82
  69   0.5253     88.540  0.0553    98.160  404.76
  70   0.5322     88.320  0.0514    98.188  410.60
  71   0.5481     88.730  0.0478    98.382  416.44
  72   0.5616     87.960  0.0493    98.252  422.27
  73   0.5353     88.540  0.0446    98.532  428.10
  74   0.5574     88.330  0.0449    98.438  433.93
  75   0.5544     88.310  0.0422    98.606  439.85
  76   0.5655     88.370  0.0416    98.632  445.70
  77   0.5544     88.720  0.0359    98.792  451.52
  78   0.5901     88.300  0.0357    98.792  457.37
  79   0.5704     88.770  0.0347    98.844  463.18
  80   0.5731     88.620  0.0361    98.736  468.99
  81   0.5790     88.720  0.0305    98.976  474.90
  82   0.5837     89.030  0.0297    99.028  480.76
  83   0.5774     88.330  0.0317    98.884  486.60
  84   0.5896     88.310  0.0276    99.082  492.41
  85   0.5928     88.770  0.0272    99.086  498.23
  86   0.5899     88.730  0.0277    99.048  504.04
  87   0.6216     88.840  0.0243    99.168  509.94
  88   0.5960     88.690  0.0284    99.028  515.78
  89   0.6103     88.730  0.0252    99.116  521.60
  90   0.6280     88.910  0.0227    99.242  527.45
