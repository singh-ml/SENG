Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7444392960 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1199     20.680  2.2700    13.228  7.75
   2   1.8141     28.080  2.0128    22.118  13.64
   3   1.6165     42.250  1.7200    33.706  19.49
   4   1.4006     48.280  1.5035    44.244  25.31
   5   1.1175     61.330  1.2626    54.756  31.14
   6   1.0336     65.620  1.0898    61.928  36.98
   7   0.8776     70.920  0.9488    67.390  42.90
   8   0.8143     72.510  0.8358    71.938  48.70
   9   0.7190     76.390  0.7621    74.584  54.55
  10   0.6846     76.870  0.6922    77.050  60.37
  11   0.6634     78.530  0.6445    78.428  66.23
  12   0.6296     79.090  0.6041    80.006  72.08
  13   0.6058     80.910  0.5617    81.348  77.99
  14   0.5699     81.310  0.5293    82.542  83.82
  15   0.6066     80.590  0.5084    83.214  89.66
  16   0.5170     82.980  0.4776    84.210  95.47
  17   0.4940     83.670  0.4371    85.612  101.34
  18   0.5001     83.590  0.4239    86.016  107.24
  19   0.5137     83.550  0.4113    86.340  113.10
  20   0.4991     84.080  0.3838    87.210  118.93
  21   0.4678     85.360  0.3806    87.370  124.76
  22   0.4388     86.240  0.3506    88.422  130.56
  23   0.4526     85.630  0.3328    88.964  136.38
  24   0.4762     85.570  0.3187    89.312  142.30
  25   0.4328     86.040  0.3195    89.476  148.11
  26   0.4416     85.800  0.3020    90.068  153.96
  27   0.4423     86.840  0.2813    90.640  159.78
  28   0.4186     86.970  0.2695    91.122  165.63
  29   0.4099     86.850  0.2563    91.410  171.45
  30   0.4403     86.830  0.2519    91.704  177.31
  31   0.3949     87.340  0.2376    92.004  183.22
  32   0.4719     86.420  0.2199    92.672  189.08
  33   0.4141     87.100  0.2198    92.718  194.90
  34   0.4175     87.510  0.2043    93.076  200.76
  35   0.4225     87.810  0.1967    93.366  206.61
  36   0.3841     88.160  0.1883    93.674  212.53
  37   0.3943     88.630  0.1777    94.038  218.34
  38   0.3957     88.670  0.1740    94.078  224.18
  39   0.4138     88.340  0.1606    94.724  229.99
  40   0.3890     88.510  0.1635    94.450  235.80
  41   0.3972     88.450  0.1478    94.956  241.62
  42   0.4375     88.180  0.1450    95.036  247.54
  43   0.3885     89.180  0.1394    95.338  253.37
  44   0.3750     88.980  0.1267    95.732  259.19
  45   0.3792     89.380  0.1195    95.964  265.01
  46   0.4260     87.970  0.1127    96.224  270.83
  47   0.4095     88.930  0.1098    96.326  276.77
  48   0.4100     88.960  0.0951    96.846  282.62
  49   0.4180     88.980  0.0948    96.912  288.44
  50   0.4094     89.480  0.0923    96.848  294.21
  51   0.4123     89.430  0.0792    97.302  300.05
  52   0.4278     89.470  0.0759    97.440  305.91
  53   0.4293     89.400  0.0726    97.546  311.83
  54   0.4364     89.500  0.0692    97.688  317.69
  55   0.4649     89.080  0.0645    97.800  323.50
  56   0.4377     89.220  0.0600    97.910  329.33
  57   0.4135     89.940  0.0516    98.288  335.19
  58   0.4773     89.420  0.0514    98.256  341.08
  59   0.4288     89.820  0.0470    98.418  346.91
  60   0.4281     89.960  0.0440    98.554  352.76
  61   0.4489     90.190  0.0370    98.782  358.58
  62   0.4607     90.220  0.0337    98.866  364.38
  63   0.4545     90.050  0.0312    98.986  370.21
  64   0.4753     90.300  0.0274    99.078  376.11
  65   0.4485     90.090  0.0285    99.028  381.92
  66   0.4724     90.300  0.0235    99.238  387.74
  67   0.4913     90.280  0.0208    99.312  393.55
  68   0.4925     90.350  0.0173    99.426  399.41
  69   0.4943     90.130  0.0178    99.396  405.24
  70   0.4911     90.590  0.0159    99.470  411.15
  71   0.4754     90.690  0.0147    99.536  416.98
  72   0.4921     90.870  0.0132    99.566  422.81
  73   0.4930     90.700  0.0121    99.600  428.64
  74   0.4934     90.880  0.0109    99.648  434.48
  75   0.5141     90.860  0.0086    99.728  440.31
  76   0.5087     90.830  0.0083    99.718  446.26
  77   0.4996     90.870  0.0076    99.768  452.10
  78   0.4991     91.180  0.0077    99.772  457.93
  79   0.5226     90.640  0.0068    99.782  463.76
  80   0.5157     90.750  0.0065    99.804  469.60
  81   0.5124     90.960  0.0058    99.816  475.45
  82   0.5094     90.920  0.0054    99.850  481.35
  83   0.5111     90.900  0.0055    99.828  487.18
  84   0.5118     90.900  0.0052    99.834  493.01
  85   0.5129     91.040  0.0043    99.884  498.84
  86   0.5088     91.110  0.0051    99.846  504.68
  87   0.5101     91.140  0.0044    99.872  510.59
  88   0.5141     91.070  0.0040    99.872  516.41
  89   0.5226     90.840  0.0043    99.856  522.24
  90   0.5193     90.980  0.0038    99.874  528.08
