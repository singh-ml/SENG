Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7446998016 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2882     11.120  2.2986    10.940  7.82
   2   2.0905     18.910  2.1761    16.774  13.66
   3   1.7500     31.990  1.9185    22.690  19.47
   4   1.5367     40.660  1.6933    34.668  25.31
   5   1.3380     51.970  1.4552    45.472  31.13
   6   1.1410     59.930  1.2432    55.970  37.02
   7   1.0321     65.990  1.0744    63.138  42.84
   8   0.9553     67.980  0.9465    68.376  48.65
   9   0.8045     73.860  0.8545    71.828  54.48
  10   0.7068     76.560  0.7848    74.382  60.31
  11   0.7456     76.230  0.7285    76.336  66.16
  12   0.7011     77.920  0.6760    78.290  72.08
  13   0.6415     80.350  0.6300    79.636  77.93
  14   0.6794     77.980  0.5909    81.156  83.75
  15   0.5597     82.470  0.5594    82.270  89.58
  16   0.6134     79.940  0.5403    82.682  95.39
  17   0.6273     81.410  0.5308    83.138  101.27
  18   0.5769     82.230  0.4889    84.214  107.09
  19   0.5089     83.490  0.4737    84.932  112.90
  20   0.4888     84.010  0.4578    85.598  118.74
  21   0.4573     85.270  0.4473    85.872  124.58
  22   0.5271     83.480  0.4098    86.866  130.38
  23   0.5166     85.230  0.4020    87.106  136.32
  24   0.5086     84.380  0.3853    87.674  142.16
  25   0.4726     85.930  0.3676    88.220  148.00
  26   0.4961     85.000  0.3488    89.000  153.81
  27   0.5333     83.160  0.3435    89.066  159.62
  28   0.4444     86.510  0.3194    89.738  165.52
  29   0.4543     86.650  0.3022    90.364  171.35
  30   0.4874     85.590  0.3023    90.428  177.17
  31   0.4389     86.420  0.2842    90.778  182.98
  32   0.4377     87.090  0.2750    91.148  188.79
  33   0.4395     86.710  0.2588    91.742  194.60
  34   0.4415     86.970  0.2516    91.792  200.49
  35   0.4278     87.820  0.2372    92.316  206.30
  36   0.4135     87.950  0.2247    92.760  212.13
  37   0.4130     87.400  0.2116    93.122  217.97
  38   0.3974     88.300  0.2027    93.514  223.77
  39   0.3918     88.820  0.1958    93.752  229.60
  40   0.4042     88.770  0.1824    94.044  235.49
  41   0.4166     88.070  0.1683    94.384  241.33
  42   0.4189     88.630  0.1630    94.668  247.14
  43   0.4300     88.280  0.1634    94.696  252.95
  44   0.4562     88.510  0.1522    94.932  258.75
  45   0.4237     88.950  0.1473    95.102  264.56
  46   0.4087     89.020  0.1332    95.690  270.46
  47   0.4179     88.840  0.1205    96.030  276.29
  48   0.4124     89.350  0.1178    96.238  282.12
  49   0.4102     89.240  0.1088    96.460  287.94
  50   0.4347     88.970  0.1070    96.476  293.69
  51   0.4315     89.350  0.0983    96.760  299.52
  52   0.4124     89.650  0.0962    96.832  305.45
  53   0.4301     89.440  0.0841    97.228  311.27
  54   0.4320     89.020  0.0824    97.302  317.10
  55   0.4228     89.860  0.0768    97.434  322.94
  56   0.4604     89.540  0.0708    97.684  328.75
  57   0.4596     89.660  0.0608    98.026  334.65
  58   0.4324     90.050  0.0616    98.022  340.49
  59   0.4421     90.190  0.0500    98.334  346.32
  60   0.4564     89.940  0.0478    98.442  352.12
  61   0.4597     90.210  0.0454    98.502  357.94
  62   0.4787     89.780  0.0427    98.574  363.74
  63   0.4523     89.970  0.0390    98.722  369.61
  64   0.4646     90.370  0.0364    98.822  375.42
  65   0.4685     90.410  0.0321    98.904  381.21
  66   0.4997     90.530  0.0268    99.120  387.04
  67   0.4828     90.350  0.0264    99.154  392.86
  68   0.4831     90.730  0.0223    99.308  398.76
  69   0.5111     90.400  0.0217    99.336  404.61
  70   0.5050     90.350  0.0192    99.382  410.44
  71   0.5379     90.260  0.0152    99.508  416.27
  72   0.5016     90.700  0.0159    99.518  422.08
  73   0.4956     90.990  0.0148    99.560  427.90
  74   0.5000     90.730  0.0133    99.598  433.77
  75   0.5172     90.730  0.0119    99.652  439.58
  76   0.5055     90.820  0.0115    99.632  445.40
  77   0.5138     90.930  0.0101    99.676  451.23
  78   0.5215     90.840  0.0094    99.714  457.05
  79   0.5379     90.970  0.0079    99.762  462.87
  80   0.5267     91.080  0.0069    99.796  468.76
  81   0.5233     91.110  0.0074    99.772  474.57
  82   0.5289     90.910  0.0075    99.772  480.40
  83   0.5298     91.000  0.0055    99.846  486.22
  84   0.5285     90.990  0.0067    99.788  492.02
  85   0.5339     91.300  0.0054    99.852  497.87
  86   0.5343     91.040  0.0062    99.802  503.77
  87   0.5331     91.230  0.0052    99.818  509.58
  88   0.5353     91.070  0.0056    99.832  515.39
  89   0.5396     91.170  0.0052    99.856  521.24
  90   0.5361     91.220  0.0054    99.842  527.04
