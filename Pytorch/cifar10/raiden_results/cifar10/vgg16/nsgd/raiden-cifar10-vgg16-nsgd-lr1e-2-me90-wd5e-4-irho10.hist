Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 47358104576 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3030     10.000  2.2990    10.500  30.55
   2   2.3031     10.000  2.3035    10.144  55.28
   3   2.3032     10.000  2.3037     9.826  81.68
   4   2.3033     10.000  2.3035     9.940  107.78
   5   2.3032     10.000  2.3038     9.804  133.97
   6   2.3038     10.000  2.3035    10.012  152.37
   7   2.3035     10.000  2.3038     9.860  176.97
   8   2.3028     10.000  2.3038     9.870  195.49
   9   2.3034     10.000  2.3033    10.002  221.81
  10   2.3031     10.000  2.3034     9.958  246.54
  11   2.3035     10.000  2.3034    10.004  265.00
  12   2.3032     10.000  2.3035    10.068  283.68
  13   2.3030     10.000  2.3033    10.034  310.00
  14   2.3049     10.000  2.3034    10.042  328.60
  15   2.3028     10.000  2.3037     9.960  354.67
  16   2.3031     10.000  2.3035     9.882  373.34
  17   2.3034     10.000  2.3034     9.828  391.79
  18   2.3036     10.000  2.3034     9.848  410.42
  19   2.3031     10.000  2.3035     9.946  428.89
  20   2.3039     10.000  2.3035    10.216  455.02
  21   2.3031     10.000  2.3035    10.030  481.02
  22   2.3031     10.000  2.3035     9.934  505.53
  23   2.3031     10.000  2.3035     9.968  524.10
  24   2.3026     10.000  2.3035     9.862  542.61
  25   2.3029     10.000  2.3034    10.004  568.71
  26   2.3039     10.000  2.3033    10.138  594.62
  27   2.3040     10.000  2.3033     9.946  621.14
  28   2.3033     10.000  2.3034     9.656  639.60
  29   2.3037     10.000  2.3033     9.874  658.27
  30   2.3032     10.000  2.3033     9.892  684.22
  31   2.3035     10.000  2.3034     9.948  702.75
  32   2.3034     10.000  2.3032    10.020  728.93
  33   2.3033     10.000  2.3032     9.846  747.39
  34   2.3028     10.000  2.3035     9.932  765.90
  35   2.3033     10.000  2.3034    10.022  784.39
  36   2.3032     10.000  2.3031    10.228  802.90
  37   2.3032     10.000  2.3033     9.722  821.50
  38   2.3030     10.000  2.3033     9.950  840.00
  39   2.3030     10.000  2.3031    10.088  858.64
  40   2.3027     10.000  2.3033     9.970  876.94
  41   2.3031     10.000  2.3031     9.912  903.24
  42   2.3029     10.000  2.3033     9.828  921.68
  43   2.3030     10.000  2.3032     9.916  940.33
  44   2.3028     10.000  2.3032     9.822  958.80
  45   2.3030     10.000  2.3032     9.916  985.06
  46   2.3032     10.000  2.3031     9.916  1011.11
  47   2.3031     10.000  2.3031    10.126  1037.19
  48   2.3027     10.000  2.3031     9.866  1055.75
  49   2.3034     10.000  2.3031     9.946  1074.24
  50   2.3029     10.000  2.3031     9.710  1092.76
  51   2.3025     10.000  2.3030    10.006  1111.09
  52   2.3033     10.000  2.3029    10.034  1129.63
  53   2.3027     10.000  2.3031     9.792  1148.21
  54   2.3031     10.000  2.3031     9.704  1166.62
  55   2.3028     10.000  2.3031     9.896  1185.18
  56   2.3027     10.000  2.3031     9.918  1203.64
  57   2.3031     10.000  2.3030     9.860  1230.04
  58   2.3027     10.000  2.3030     9.790  1248.47
  59   2.3027     10.000  2.3030     9.844  1274.64
  60   2.3026     10.000  2.3029     9.836  1300.71
  61   2.3027     10.000  2.3030     9.888  1326.74
  62   2.3026     10.000  2.3029     9.882  1345.19
  63   2.3026     10.000  2.3029     9.950  1363.64
  64   2.3027     10.000  2.3028     9.994  1382.12
  65   2.3027     10.000  2.3029     9.850  1400.58
  66   2.3027     10.000  2.3029     9.918  1419.07
  67   2.3027     10.000  2.3029     9.926  1445.34
  68   2.3027     10.000  2.3029     9.822  1463.81
