Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 50581342720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2798     10.580  2.2684    12.976  30.73
   2   2.3069     10.000  2.2031    16.172  57.61
   3   2.3264     12.260  2.2974    11.506  83.93
   4   2.0504     18.470  2.2265    14.188  109.40
   5   1.7962     27.050  1.9413    21.874  136.26
   6   1.6911     35.470  1.7719    30.428  162.95
   7   1.4962     44.110  1.6267    36.890  188.19
   8   1.5890     43.870  1.4666    45.182  214.99
   9   1.2451     56.200  1.3016    53.172  240.07
  10   1.1326     58.990  1.1290    60.622  266.98
  11   1.0197     64.430  0.9884    65.894  293.82
  12   0.9617     69.040  0.8923    69.508  320.64
  13   0.8434     71.870  0.8132    72.672  347.78
  14   0.7653     74.890  0.7374    75.424  374.46
  15   0.6917     77.450  0.6748    77.750  401.33
  16   0.6339     78.760  0.6221    79.524  428.15
  17   0.5841     80.600  0.5806    80.892  455.07
  18   0.6144     80.400  0.5516    81.796  482.07
  19   0.5847     81.100  0.5268    82.718  508.90
  20   0.6099     80.900  0.4922    83.812  535.68
  21   0.5028     83.100  0.4671    84.906  561.07
  22   0.5288     83.590  0.4488    85.082  587.74
  23   0.5170     83.570  0.4177    86.456  614.53
  24   0.4682     85.190  0.3941    86.994  641.49
  25   0.4795     84.490  0.3799    87.528  668.32
  26   0.4577     84.870  0.3673    88.032  695.14
  27   0.4838     85.060  0.3439    88.712  721.94
  28   0.4888     84.880  0.3273    89.268  750.23
  29   0.4845     85.220  0.3082    89.860  776.92
  30   0.5177     85.390  0.2936    90.312  803.80
  31   0.4917     85.430  0.2912    90.434  830.61
  32   0.4414     86.290  0.2822    90.764  859.04
  33   0.4533     86.460  0.2686    91.048  885.92
  34   0.4357     86.600  0.2420    91.960  914.37
  35   0.4218     86.840  0.2397    92.092  941.22
  36   0.4362     87.190  0.2327    92.314  968.16
  37   0.4388     87.060  0.2203    92.648  994.92
  38   0.4173     87.640  0.2017    93.264  1021.75
  39   0.4171     87.940  0.2020    93.358  1048.70
  40   0.4455     86.940  0.1870    93.830  1075.57
