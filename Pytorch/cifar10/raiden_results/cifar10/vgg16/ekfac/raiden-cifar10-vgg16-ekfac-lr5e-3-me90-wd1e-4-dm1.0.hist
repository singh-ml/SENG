Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 14133946880 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8034     34.640  1.9143    25.134  65.16
   2   0.9990     64.300  1.3219    50.856  128.26
   3   0.8066     72.790  0.9554    66.440  191.41
   4   0.6954     76.610  0.7888    72.906  254.56
   5   0.6789     77.650  0.6750    77.600  317.65
   6   0.5646     81.540  0.5999    80.356  380.73
   7   0.5504     82.360  0.5368    82.322  443.83
   8   0.5201     82.940  0.4945    83.800  506.91
   9   0.4899     84.670  0.4564    85.062  570.04
  10   0.4750     85.360  0.4178    86.492  633.14
  11   0.4470     85.710  0.4009    86.882  696.22
  12   0.4559     85.610  0.3653    87.974  759.40
  13   0.4168     86.290  0.3437    88.642  822.48
  14   0.5195     85.430  0.3278    89.404  885.65
  15   0.4176     87.080  0.3139    89.798  948.80
  16   0.4153     87.050  0.2943    90.288  1011.97
  17   0.3893     87.710  0.2700    91.114  1075.12
  18   0.3928     87.710  0.2645    91.248  1138.25
  19   0.4086     87.290  0.2459    91.814  1201.37
  20   0.4107     87.900  0.2348    92.438  1264.45
  21   0.3633     88.580  0.2255    92.570  1327.56
  22   0.3922     88.700  0.2146    93.076  1390.66
  23   0.3830     88.640  0.2031    93.326  1453.83
  24   0.3652     89.170  0.1948    93.712  1517.09
  25   0.3935     88.740  0.1828    94.064  1580.23
  26   0.3876     88.860  0.1729    94.416  1643.35
  27   0.3909     89.240  0.1680    94.508  1706.38
  28   0.3772     89.940  0.1600    94.830  1769.62
  29   0.3998     88.870  0.1499    95.022  1832.70
  30   0.4267     89.070  0.1437    95.296  1895.85
  31   0.3890     89.680  0.1367    95.454  1958.95
  32   0.3887     89.340  0.1256    95.868  2022.10
  33   0.4151     89.120  0.1217    96.020  2085.24
  34   0.3862     89.870  0.1179    96.112  2148.34
  35   0.3877     89.830  0.1169    96.278  2211.42
  36   0.4465     89.640  0.1046    96.600  2274.48
  37   0.4327     89.270  0.1020    96.568  2337.61
  38   0.3976     90.070  0.0909    96.962  2400.68
  39   0.3884     90.350  0.0935    96.942  2463.78
  40   0.4227     90.190  0.0824    97.308  2527.04
  41   0.4117     90.350  0.0817    97.272  2590.28
  42   0.4182     90.140  0.0774    97.540  2653.38
  43   0.4155     90.250  0.0722    97.728  2716.50
  44      nan     10.000     nan    87.786  2779.53
