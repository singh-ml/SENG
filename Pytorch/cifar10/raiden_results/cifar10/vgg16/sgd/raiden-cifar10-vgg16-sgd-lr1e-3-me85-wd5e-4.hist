Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2823     14.350  2.2980    10.634  6.04
   2   2.0358     25.160  2.2176    15.692  10.36
   3   1.8992     28.580  2.0100    24.366  14.68
   4   1.7352     34.260  1.8803    28.290  19.01
   5   1.6623     37.970  1.7775    32.694  23.32
   6   1.6101     38.400  1.6911    36.308  27.66
   7   1.5543     42.480  1.6122    39.778  32.02
   8   1.4011     48.210  1.5192    43.186  36.41
   9   1.3861     48.250  1.4561    45.998  40.75
  10   1.2727     52.590  1.3915    48.540  45.08
  11   1.2665     54.000  1.3529    50.050  49.42
  12   1.1659     57.000  1.2916    52.452  53.73
  13   1.1358     59.200  1.2402    54.664  58.07
  14   1.0788     60.670  1.1989    56.230  62.39
  15   1.1139     60.320  1.1507    58.114  66.72
  16   1.0454     63.040  1.1257    59.128  71.14
  17   1.0695     62.200  1.0740    61.052  75.51
  18   1.0496     61.860  1.0404    62.546  79.86
  19   0.9376     66.400  1.0120    63.410  84.20
  20   0.9486     66.830  0.9711    65.050  88.52
  21   0.9205     67.100  0.9608    65.572  92.87
  22   0.8933     68.690  0.9223    66.900  97.21
  23   0.8863     68.660  0.8922    68.060  101.56
  24   0.8068     71.750  0.8801    68.570  106.01
  25   0.8364     70.760  0.8452    69.880  110.36
  26   0.8012     71.470  0.8381    70.230  114.68
  27   0.8105     71.590  0.8074    71.288  119.00
  28   0.7449     73.970  0.7865    71.948  123.37
  29   0.7453     74.010  0.7668    72.930  127.71
  30   0.7296     74.050  0.7578    73.066  132.05
  31   0.7418     74.130  0.7309    74.210  136.38
  32   0.7035     75.800  0.7248    74.602  140.82
  33   0.7010     75.970  0.6933    75.538  145.17
  34   0.6902     75.910  0.6896    75.650  149.52
  35   0.7348     75.340  0.6737    76.106  153.85
  36   0.6644     76.750  0.6672    76.454  158.17
  37   0.6489     77.570  0.6641    76.572  162.55
  38   0.6946     76.030  0.6400    77.608  166.88
  39   0.6472     77.810  0.6226    78.238  171.23
  40   0.6184     79.170  0.6111    78.632  175.62
  41   0.6461     78.190  0.6038    78.726  179.96
  42   0.6358     78.740  0.5901    79.226  184.31
  43   0.6180     79.180  0.5823    79.504  188.64
  44   0.6300     78.650  0.5641    80.102  192.96
  45   0.6022     79.800  0.5606    80.476  197.31
  46   0.5979     79.570  0.5483    80.762  201.68
  47   0.5833     80.320  0.5404    81.290  206.12
  48   0.5948     80.410  0.5296    81.416  210.49
  49   0.5625     80.840  0.5264    81.496  214.82
  50   0.6053     80.010  0.5147    81.830  219.17
  51   0.5905     80.340  0.5125    82.134  223.49
  52   0.5919     80.510  0.4955    82.592  227.84
  53   0.5946     79.930  0.4991    82.436  232.17
  54   0.5645     81.070  0.4823    83.010  236.52
  55   0.5972     80.370  0.4710    83.598  240.84
  56   0.6366     79.290  0.4671    83.742  245.20
  57   0.5684     81.060  0.4642    83.792  249.54
  58   0.5662     82.020  0.4511    84.150  253.91
  59   0.5555     81.810  0.4419    84.554  258.25
  60   0.5500     82.030  0.4430    84.516  262.59
  61   0.5666     81.250  0.4357    84.882  266.92
  62   0.5632     81.500  0.4302    84.966  271.36
  63   0.5535     81.540  0.4169    85.398  275.69
  64   0.5840     81.420  0.4111    85.630  280.03
  65   0.5312     82.640  0.4120    85.466  284.36
  66   0.5288     83.050  0.3904    86.388  288.69
  67   0.5330     82.710  0.3930    86.354  293.02
  68   0.5835     81.020  0.3841    86.522  297.37
  69   0.5630     82.040  0.3833    86.496  301.71
  70   0.5692     81.800  0.3723    86.976  306.13
  71   0.5169     83.130  0.3700    87.060  310.51
  72   0.5321     83.050  0.3598    87.494  314.85
  73   0.5291     83.310  0.3551    87.622  319.21
  74   0.5681     81.790  0.3548    87.514  323.58
  75   0.5353     82.940  0.3482    87.856  327.91
  76   0.5670     82.730  0.3412    88.024  332.26
  77   0.5781     82.310  0.3378    88.194  336.61
  78   0.5168     83.430  0.3291    88.402  341.04
  79   0.5486     83.280  0.3286    88.680  345.39
  80   0.5320     83.560  0.3174    88.860  349.73
  81   0.5281     83.790  0.3114    89.036  354.10
  82   0.5368     83.060  0.3057    89.278  358.43
  83   0.5621     83.630  0.2998    89.504  362.77
  84   0.5470     82.640  0.2974    89.618  367.11
  85   0.5097     84.310  0.3007    89.476  371.55
