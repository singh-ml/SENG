Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8880     28.320  2.1739    16.710  6.03
   2   1.6449     37.610  1.8117    30.550  10.42
   3   1.5003     43.090  1.5871    40.104  14.85
   4   1.3131     50.050  1.4247    46.974  19.24
   5   1.1178     59.320  1.2632    53.590  23.64
   6   1.0596     61.580  1.1513    57.916  28.00
   7   0.9292     66.180  1.0482    62.190  32.35
   8   0.9221     66.820  0.9634    65.452  36.71
   9   0.8187     70.980  0.9003    67.838  41.08
  10   0.7982     72.220  0.8389    70.210  45.46
  11   0.7849     72.860  0.7845    72.256  49.93
  12   0.6892     75.930  0.7348    74.156  54.34
  13   0.6835     76.220  0.6944    75.628  58.74
  14   0.6741     76.750  0.6574    77.076  63.10
  15   0.6391     77.450  0.6217    78.302  67.50
  16   0.6109     79.180  0.5990    79.146  71.90
  17   0.5793     80.180  0.5682    80.220  76.24
  18   0.5633     80.740  0.5471    81.148  80.66
  19   0.6302     78.520  0.5216    82.048  85.00
  20   0.5341     81.490  0.5096    82.288  89.36
  21   0.5594     80.560  0.4860    83.244  93.72
  22   0.5695     80.510  0.4749    83.558  98.10
  23   0.5014     83.040  0.4557    84.492  102.45
  24   0.4889     83.380  0.4334    84.946  106.80
  25   0.5065     83.340  0.4218    85.428  111.16
  26   0.4944     83.760  0.3959    86.348  115.52
  27   0.4575     84.590  0.3860    86.756  119.97
  28   0.4680     84.430  0.3706    87.196  124.31
  29   0.4759     84.500  0.3647    87.442  128.66
  30   0.5353     82.810  0.3491    87.904  133.03
  31   0.4650     84.750  0.3318    88.446  137.39
  32   0.4507     85.330  0.3238    88.884  141.74
  33   0.4525     85.500  0.3064    89.494  146.09
  34   0.4745     84.060  0.3049    89.570  150.54
  35   0.4799     84.860  0.2939    89.800  154.92
  36   0.4379     85.860  0.2819    90.238  159.27
  37   0.4522     85.790  0.2663    90.870  163.65
  38   0.4571     85.460  0.2566    91.170  168.01
  39   0.4424     86.390  0.2522    91.296  172.39
  40   0.4664     85.650  0.2429    91.610  176.73
  41   0.4376     86.290  0.2300    92.046  181.11
  42   0.4362     86.530  0.2232    92.480  185.50
  43   0.4329     86.880  0.2201    92.402  189.86
  44   0.4431     86.530  0.2083    92.794  194.22
  45   0.4612     85.440  0.1994    93.118  198.58
  46   0.4641     86.320  0.1969    93.158  202.95
  47   0.4464     86.780  0.1846    93.734  207.30
  48   0.4758     86.390  0.1734    94.032  211.69
  49   0.4353     87.020  0.1700    94.122  216.07
  50   0.4266     87.210  0.1610    94.406  220.47
  51   0.4624     86.590  0.1590    94.524  224.81
  52   0.4853     86.230  0.1514    94.764  229.17
  53   0.4511     87.560  0.1454    94.934  233.54
  54   0.4565     87.530  0.1339    95.282  237.89
  55   0.4574     87.470  0.1338    95.426  242.26
  56   0.4604     87.050  0.1255    95.596  246.64
  57   0.4718     87.530  0.1194    95.864  251.07
  58   0.4620     87.690  0.1171    95.946  255.42
  59   0.4848     86.810  0.1097    96.138  259.80
  60   0.4773     87.250  0.1059    96.392  264.15
  61   0.4866     87.510  0.1018    96.576  268.50
  62   0.4821     87.410  0.0952    96.654  272.87
  63   0.4990     87.460  0.0966    96.680  277.22
  64   0.5301     86.900  0.0889    96.968  281.59
  65   0.4946     87.310  0.0875    97.040  286.06
  66   0.4985     87.880  0.0839    97.086  290.41
  67   0.4878     88.010  0.0785    97.292  294.79
  68   0.5198     87.990  0.0737    97.544  299.17
  69   0.5183     87.940  0.0713    97.536  303.53
  70   0.5118     88.010  0.0694    97.638  307.90
  71   0.5300     87.840  0.0627    97.858  312.26
  72   0.5221     88.230  0.0617    97.942  316.62
  73   0.5122     88.300  0.0596    97.964  321.05
  74   0.5293     87.940  0.0568    98.024  325.43
  75   0.5570     87.610  0.0563    98.088  329.81
  76   0.5366     87.860  0.0542    98.126  334.19
  77   0.5412     88.140  0.0505    98.284  338.54
  78   0.5314     88.080  0.0511    98.306  342.90
  79   0.5469     88.170  0.0437    98.554  347.25
  80   0.5474     87.980  0.0451    98.476  351.61
  81   0.5361     88.130  0.0481    98.332  355.99
  82   0.5630     87.960  0.0411    98.632  360.43
  83   0.5486     87.850  0.0446    98.480  364.77
  84   0.5658     87.890  0.0424    98.526  369.12
  85   0.5571     88.120  0.0403    98.610  373.47
