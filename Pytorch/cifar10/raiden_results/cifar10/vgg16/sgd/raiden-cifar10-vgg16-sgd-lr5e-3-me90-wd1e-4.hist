Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8657     30.220  2.1675    17.308  6.02
   2   1.6297     39.220  1.7988    31.948  10.37
   3   1.4136     47.660  1.6004    39.690  14.73
   4   1.3281     50.850  1.4226    47.018  19.17
   5   1.1348     59.280  1.2678    53.670  23.56
   6   1.1528     59.680  1.1409    58.558  27.91
   7   0.9950     64.350  1.0464    62.272  32.27
   8   1.0201     66.260  0.9454    66.018  36.66
   9   0.8375     70.670  0.8911    68.286  41.02
  10   0.8065     71.440  0.8260    70.852  45.36
  11   0.7130     75.090  0.7730    72.602  49.75
  12   0.6745     76.660  0.7190    74.854  54.20
  13   0.6944     75.940  0.6845    75.926  58.60
  14   0.6502     77.990  0.6497    77.188  62.93
  15   0.6313     78.220  0.6240    78.348  67.32
  16   0.6185     78.960  0.5893    79.452  71.71
  17   0.5535     81.410  0.5590    80.610  76.07
  18   0.7015     77.210  0.5365    81.366  80.46
  19   0.5647     80.960  0.5291    81.598  84.80
  20   0.5326     81.660  0.5020    82.754  89.22
  21   0.5246     82.700  0.4779    83.356  93.58
  22   0.5110     82.600  0.4566    84.100  97.93
  23   0.5166     82.400  0.4446    84.770  102.27
  24   0.5503     81.830  0.4211    85.554  106.63
  25   0.5853     81.690  0.4097    86.042  110.99
  26   0.4817     83.280  0.3969    86.264  115.38
  27   0.4986     83.580  0.3844    86.712  119.81
  28   0.4907     84.040  0.3631    87.408  124.18
  29   0.5113     82.840  0.3513    87.876  128.54
  30   0.4851     84.180  0.3402    88.272  132.90
  31   0.5138     84.100  0.3281    88.624  137.25
  32   0.4519     85.250  0.3216    88.848  141.61
  33   0.4427     85.450  0.3047    89.500  145.97
  34   0.4459     85.670  0.3037    89.516  150.34
  35   0.4467     85.500  0.2852    90.174  154.76
  36   0.4662     85.280  0.2726    90.488  159.13
  37   0.4661     85.360  0.2725    90.512  163.49
  38   0.4318     86.270  0.2567    91.158  167.87
  39   0.4494     85.970  0.2507    91.366  172.23
  40   0.4632     85.740  0.2436    91.542  176.55
  41   0.4818     85.920  0.2290    92.064  180.91
  42   0.4310     86.530  0.2265    92.090  185.26
  43   0.4833     85.730  0.2174    92.360  189.67
  44   0.4516     86.270  0.2163    92.414  194.04
  45   0.4584     86.330  0.2001    93.142  198.41
  46   0.4459     86.470  0.1987    93.214  202.76
  47   0.4737     85.990  0.1840    93.776  207.12
  48   0.4559     86.430  0.1798    93.844  211.47
  49   0.4431     87.050  0.1756    93.860  215.81
  50   0.4405     87.720  0.1663    94.334  220.22
  51   0.4644     87.310  0.1522    94.672  224.65
  52   0.4614     87.150  0.1522    94.864  229.03
  53   0.5149     86.490  0.1449    94.960  233.39
  54   0.4792     87.130  0.1425    95.018  237.73
  55   0.4781     86.650  0.1346    95.328  242.10
  56   0.4815     87.110  0.1318    95.406  246.47
  57   0.4698     87.360  0.1277    95.598  250.81
  58   0.4757     87.720  0.1222    95.778  255.17
  59   0.4827     87.430  0.1138    96.160  259.62
  60   0.4940     87.380  0.1064    96.342  264.00
  61   0.5098     87.560  0.1042    96.304  268.37
  62   0.5008     87.690  0.0990    96.566  272.71
  63   0.5044     87.380  0.0973    96.578  277.12
  64   0.4925     88.100  0.0943    96.738  281.46
  65   0.5165     87.170  0.0875    96.922  285.83
  66   0.5062     87.450  0.0873    96.918  290.22
  67   0.5183     87.260  0.0796    97.284  294.65
  68   0.5407     87.230  0.0788    97.332  299.03
  69   0.5298     87.590  0.0765    97.376  303.39
  70   0.5330     87.910  0.0722    97.530  307.74
  71   0.5491     87.580  0.0656    97.724  312.08
  72   0.5494     87.740  0.0642    97.842  316.45
  73   0.5496     87.960  0.0649    97.652  320.82
  74   0.5588     87.960  0.0642    97.830  325.24
  75   0.5465     87.990  0.0607    97.932  329.56
  76   0.5541     87.850  0.0554    98.060  333.91
  77   0.5460     88.120  0.0563    98.060  338.26
  78   0.5341     88.610  0.0552    98.122  342.63
  79   0.5825     87.750  0.0491    98.308  346.96
  80   0.5760     87.900  0.0493    98.294  351.30
  81   0.5848     87.740  0.0446    98.510  355.74
  82   0.5788     87.960  0.0468    98.374  360.11
  83   0.5897     87.730  0.0441    98.488  364.46
  84   0.6181     87.660  0.0412    98.612  368.80
  85   0.5929     88.020  0.0394    98.590  373.17
  86   0.5989     87.850  0.0420    98.552  377.52
  87   0.6077     87.970  0.0366    98.736  381.85
  88   0.6071     88.030  0.0393    98.652  386.23
  89   0.6037     87.730  0.0371    98.742  390.67
  90   0.6325     87.680  0.0360    98.778  395.06
