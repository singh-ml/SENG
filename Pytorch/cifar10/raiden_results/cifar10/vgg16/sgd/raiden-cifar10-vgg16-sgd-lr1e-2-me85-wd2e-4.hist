Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7934     34.090  2.1117    20.032  6.01
   2   1.5784     41.020  1.7093    34.642  10.36
   3   1.3038     51.200  1.4838    44.096  14.72
   4   1.1444     58.520  1.2771    53.310  19.08
   5   1.0013     63.570  1.1062    60.076  23.45
   6   0.9093     67.380  0.9835    64.944  27.89
   7   0.8523     70.070  0.9001    68.068  32.29
   8   0.7197     75.570  0.8092    71.468  36.65
   9   0.6993     75.910  0.7373    74.354  41.05
  10   0.6691     76.970  0.6889    76.114  45.43
  11   0.6177     78.740  0.6455    77.792  49.83
  12   0.6419     78.040  0.6117    78.610  54.21
  13   0.5948     79.740  0.5661    80.450  58.60
  14   0.5390     81.840  0.5404    81.426  62.96
  15   0.5742     80.960  0.5137    82.214  67.41
  16   0.5581     81.500  0.4845    83.448  71.78
  17   0.4985     83.540  0.4657    83.984  76.14
  18   0.5242     82.330  0.4470    84.826  80.51
  19   0.5168     83.500  0.4187    85.698  84.85
  20   0.4990     83.910  0.3918    86.578  89.26
  21   0.4932     83.830  0.3827    87.036  93.61
  22   0.4510     85.410  0.3588    87.506  98.00
  23   0.4434     85.750  0.3476    88.090  102.46
  24   0.4604     85.130  0.3348    88.578  106.82
  25   0.4554     85.310  0.3217    88.836  111.17
  26   0.4552     85.510  0.3038    89.456  115.53
  27   0.5073     84.530  0.2920    90.082  119.88
  28   0.4456     85.780  0.2755    90.524  124.24
  29   0.4280     86.500  0.2647    90.878  128.62
  30   0.4230     86.500  0.2520    91.550  132.97
  31   0.4248     86.590  0.2390    91.778  137.43
  32   0.4237     86.980  0.2331    91.956  141.78
  33   0.4729     86.190  0.2250    92.342  146.15
  34   0.4516     86.820  0.2160    92.604  150.52
  35   0.4742     85.950  0.2050    92.936  154.86
  36   0.4497     86.980  0.1939    93.404  159.24
  37   0.4404     87.290  0.1810    93.658  163.61
  38   0.4717     86.390  0.1730    94.042  168.08
  39   0.4326     87.310  0.1690    94.264  172.44
  40   0.4767     86.730  0.1580    94.630  176.79
  41   0.4562     87.390  0.1497    94.814  181.16
  42   0.4725     87.090  0.1462    94.916  185.54
  43   0.4396     87.910  0.1341    95.348  189.91
  44   0.4688     87.230  0.1318    95.410  194.30
  45   0.4627     87.680  0.1203    95.904  198.66
  46   0.4861     87.340  0.1185    95.988  203.09
  47   0.4775     87.650  0.1085    96.278  207.45
  48   0.4709     87.730  0.1025    96.444  211.84
  49   0.4778     88.070  0.0941    96.762  216.20
  50   0.4716     87.740  0.0878    96.972  220.57
  51   0.4855     88.120  0.0909    96.864  224.95
  52   0.5112     87.850  0.0837    97.080  229.33
  53   0.4955     88.300  0.0748    97.506  233.74
  54   0.4883     88.350  0.0737    97.438  238.10
  55   0.5138     88.020  0.0643    97.778  242.47
  56   0.5178     88.080  0.0636    97.830  246.85
  57   0.5337     88.370  0.0574    98.044  251.24
  58   0.5227     88.480  0.0545    98.060  255.60
  59   0.5104     88.450  0.0536    98.164  259.96
  60   0.5496     88.250  0.0463    98.454  264.32
  61   0.5479     88.530  0.0418    98.582  268.74
  62   0.6072     87.610  0.0410    98.592  273.12
  63   0.5732     88.480  0.0414    98.554  277.51
  64   0.5637     88.630  0.0366    98.736  281.87
  65   0.5722     88.410  0.0329    98.874  286.25
  66   0.5719     88.630  0.0354    98.790  290.62
  67   0.5972     88.720  0.0280    99.056  294.98
  68   0.5936     88.880  0.0279    99.034  299.35
  69   0.6041     88.580  0.0247    99.168  303.70
  70   0.6082     88.840  0.0244    99.170  308.06
  71   0.6182     88.700  0.0215    99.288  312.45
  72   0.6141     88.540  0.0228    99.210  316.81
  73   0.6199     88.620  0.0203    99.300  321.18
  74   0.6386     88.760  0.0185    99.418  325.56
  75   0.6412     88.640  0.0174    99.394  329.94
  76   0.6455     88.910  0.0167    99.394  334.37
  77   0.6624     88.690  0.0147    99.468  338.70
  78   0.6733     88.820  0.0155    99.454  343.07
  79   0.6859     88.670  0.0140    99.514  347.44
  80   0.6737     88.860  0.0139    99.548  351.80
  81   0.6784     88.910  0.0132    99.546  356.17
  82   0.6698     88.930  0.0139    99.526  360.53
  83   0.6702     89.060  0.0126    99.584  364.88
  84   0.6737     88.910  0.0114    99.628  369.34
  85   0.6758     88.770  0.0120    99.610  373.71
