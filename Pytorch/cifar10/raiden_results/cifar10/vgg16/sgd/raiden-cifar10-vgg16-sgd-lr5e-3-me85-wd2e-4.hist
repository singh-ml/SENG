Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0233     22.590  2.2150    14.852  5.93
   2   1.6644     36.150  1.8561    28.736  10.39
   3   1.4544     45.740  1.6127    38.768  14.77
   4   1.3218     51.530  1.4410    46.386  19.12
   5   1.1510     58.380  1.2928    52.538  23.46
   6   1.0856     60.240  1.1657    57.612  27.83
   7   1.0544     62.420  1.0537    62.074  32.19
   8   0.9796     65.520  0.9815    64.632  36.54
   9   0.8400     70.150  0.9124    67.282  40.91
  10   0.7992     71.780  0.8587    69.568  45.33
  11   0.7700     73.050  0.7845    72.192  49.67
  12   0.7054     75.380  0.7416    74.012  54.02
  13   0.6759     76.920  0.7029    75.360  58.37
  14   0.6261     78.450  0.6598    77.030  62.73
  15   0.6579     77.480  0.6339    78.044  67.12
  16   0.5996     79.270  0.5992    79.016  71.44
  17   0.5762     80.100  0.5746    79.834  75.86
  18   0.6015     79.670  0.5572    80.652  80.22
  19   0.5314     81.490  0.5349    81.374  84.58
  20   0.5906     80.400  0.5097    82.236  88.98
  21   0.5154     82.220  0.4792    83.496  93.33
  22   0.4939     82.930  0.4706    83.836  97.68
  23   0.5685     81.080  0.4468    84.578  102.05
  24   0.5104     83.360  0.4298    84.990  106.54
  25   0.5193     82.780  0.4172    85.536  110.89
  26   0.5123     82.390  0.4049    86.080  115.28
  27   0.4991     83.500  0.3825    86.788  119.65
  28   0.5032     83.640  0.3735    87.116  123.99
  29   0.4884     84.970  0.3608    87.602  128.34
  30   0.4901     83.780  0.3458    88.048  132.69
  31   0.4622     85.090  0.3341    88.290  137.09
  32   0.4943     84.270  0.3186    88.894  141.44
  33   0.4448     85.730  0.3190    89.028  145.80
  34   0.4472     85.460  0.3003    89.794  150.27
  35   0.4500     85.430  0.2970    89.756  154.62
  36   0.4700     85.490  0.2851    90.074  159.01
  37   0.4397     86.000  0.2738    90.496  163.37
  38   0.4558     85.700  0.2624    90.820  167.75
  39   0.5022     84.910  0.2521    91.264  172.09
  40   0.4813     85.710  0.2382    91.686  176.45
  41   0.4572     86.110  0.2363    91.786  180.89
  42   0.4611     85.690  0.2317    92.050  185.26
  43   0.4706     85.800  0.2256    92.246  189.64
  44   0.4664     86.860  0.2071    92.702  193.98
  45   0.5328     84.680  0.2002    93.004  198.34
  46   0.4653     86.410  0.1919    93.316  202.69
  47   0.5032     85.790  0.1858    93.574  207.05
  48   0.4586     86.790  0.1836    93.620  211.40
  49   0.4654     86.970  0.1716    94.096  215.86
  50   0.4867     86.620  0.1677    94.252  220.20
  51   0.4750     86.920  0.1618    94.422  224.59
  52   0.4840     86.930  0.1501    94.726  228.95
  53   0.4717     87.080  0.1477    94.860  233.32
  54   0.4831     87.180  0.1378    95.266  237.70
  55   0.4782     87.330  0.1328    95.450  242.05
  56   0.4940     86.630  0.1353    95.326  246.49
  57   0.4914     87.150  0.1222    95.724  250.86
  58   0.4651     87.380  0.1216    95.702  255.20
  59   0.4851     87.550  0.1098    96.196  259.58
  60   0.4826     87.600  0.1121    96.074  263.94
  61   0.5007     87.490  0.1070    96.378  268.30
  62   0.5057     87.580  0.1017    96.452  272.64
  63   0.5138     87.700  0.0974    96.550  277.04
  64   0.5235     87.610  0.0910    96.790  281.37
  65   0.5165     87.450  0.0935    96.714  285.76
  66   0.5153     87.520  0.0856    97.004  290.12
  67   0.5413     87.310  0.0807    97.202  294.50
  68   0.5667     87.020  0.0793    97.316  298.88
  69   0.5384     87.880  0.0762    97.406  303.25
  70   0.5513     87.680  0.0726    97.434  307.63
  71   0.5700     87.720  0.0638    97.774  311.99
  72   0.5742     87.760  0.0647    97.774  316.41
  73   0.5869     87.570  0.0613    97.792  320.75
  74   0.5831     87.520  0.0638    97.734  325.12
  75   0.5811     87.610  0.0637    97.786  329.48
  76   0.5721     87.920  0.0588    97.954  333.83
  77   0.5845     87.920  0.0556    98.082  338.22
  78   0.6233     87.410  0.0534    98.060  342.58
  79   0.6192     87.890  0.0498    98.250  346.93
  80   0.5868     88.000  0.0504    98.266  351.29
  81   0.6045     87.880  0.0476    98.388  355.75
  82   0.6239     87.590  0.0459    98.462  360.11
  83   0.6160     87.320  0.0466    98.376  364.46
  84   0.6244     87.820  0.0453    98.476  368.83
  85   0.6144     87.780  0.0418    98.576  373.21
