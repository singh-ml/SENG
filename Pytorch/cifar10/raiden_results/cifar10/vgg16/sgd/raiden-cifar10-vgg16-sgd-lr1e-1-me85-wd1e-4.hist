Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1585     17.510  2.2873    11.944  6.27
   2   2.0097     21.170  2.0860    17.816  10.65
   3   1.8212     27.500  1.9288    20.348  15.05
   4   1.8067     25.840  1.9089    21.420  19.46
   5   1.8711     20.070  1.8774    24.134  23.85
   6   1.6744     30.790  1.8065    26.892  28.21
   7   1.6328     33.910  1.7724    28.222  32.60
   8   1.6494     30.040  1.7594    28.386  36.96
   9   1.5612     36.670  1.6242    34.588  41.41
  10   1.3549     47.320  1.4638    43.320  45.78
  11   1.2913     51.950  1.3967    47.878  50.15
  12   1.2534     54.020  1.2569    54.596  54.53
  13   1.0329     64.140  1.1435    60.056  58.93
  14   1.0123     66.710  1.0253    65.776  63.30
  15   0.9561     65.770  0.9671    67.676  67.67
  16   1.1179     66.120  0.9481    68.946  72.12
  17   0.8271     74.390  0.8715    71.866  76.50
  18   0.8476     73.960  0.8137    74.014  80.87
  19   0.7830     75.260  0.7685    75.444  85.27
  20   0.7318     76.450  0.7282    76.836  89.65
  21   0.7240     76.640  0.6985    78.012  94.01
  22   0.7634     76.050  0.6562    79.272  98.39
  23   0.7028     79.010  0.6373    79.520  102.77
  24   0.7369     76.330  0.5936    81.086  107.22
  25   0.6568     80.070  0.5908    81.196  111.63
  26   0.6275     80.340  0.5567    82.442  116.07
  27   0.5879     82.170  0.5306    83.148  120.46
  28   0.6014     82.120  0.5261    83.422  124.84
  29   0.6160     81.650  0.4939    84.202  129.21
  30   0.5303     83.850  0.4757    84.980  133.61
  31   0.5301     84.330  0.4447    86.046  138.08
  32   0.4910     85.150  0.4452    86.074  142.49
  33   0.5312     83.650  0.4176    86.768  146.89
  34   0.4992     85.440  0.3991    87.206  151.28
  35   0.4752     84.920  0.3821    87.774  155.66
  36   0.4537     85.650  0.3641    88.434  160.09
  37   0.4347     86.120  0.3451    88.972  164.46
  38   0.4712     85.400  0.3350    89.300  168.85
  39   0.4630     86.120  0.3100    89.948  173.24
  40   0.4580     86.310  0.3060    90.042  177.73
  41   0.4273     87.390  0.2978    90.386  182.10
  42   0.4264     86.770  0.2763    91.030  186.47
  43   0.4621     86.480  0.2599    91.724  190.89
  44   0.4082     87.600  0.2589    91.640  195.28
  45   0.4248     87.710  0.2383    92.260  199.69
  46   0.4135     88.610  0.2227    92.684  204.07
  47   0.4085     88.820  0.2051    93.254  208.46
  48   0.4332     87.770  0.2071    93.354  212.90
  49   0.4191     87.710  0.1941    93.794  217.32
  50   0.4186     88.610  0.1817    94.152  221.72
  51   0.4227     87.760  0.1717    94.412  226.09
  52   0.4061     89.120  0.1645    94.606  230.47
  53   0.4146     88.730  0.1477    95.230  234.83
  54   0.4246     88.350  0.1385    95.532  239.25
  55   0.4209     89.090  0.1328    95.626  243.71
  56   0.4073     89.250  0.1274    95.818  248.06
  57   0.4439     88.880  0.1177    96.204  252.47
  58   0.4306     88.990  0.1124    96.308  256.83
  59   0.4113     89.690  0.1030    96.620  261.20
  60   0.4658     89.060  0.1010    96.710  265.56
  61   0.4513     89.350  0.0913    97.022  269.96
  62   0.4540     89.500  0.0832    97.254  274.40
  63   0.4507     89.860  0.0773    97.552  278.77
  64   0.4463     90.070  0.0710    97.746  283.16
  65   0.4568     90.010  0.0670    97.828  287.53
  66   0.4507     89.820  0.0598    98.092  291.90
  67   0.4592     90.010  0.0572    98.148  296.29
  68   0.4565     90.140  0.0517    98.364  300.66
  69   0.4612     89.980  0.0468    98.526  305.13
  70   0.4678     90.190  0.0417    98.650  309.54
  71   0.4765     90.340  0.0398    98.730  313.94
  72   0.5014     90.090  0.0369    98.850  318.33
  73   0.4721     89.940  0.0380    98.800  322.72
  74   0.4797     90.250  0.0349    98.938  327.10
  75   0.4915     90.310  0.0314    99.016  331.49
  76   0.5084     90.240  0.0300    99.066  335.88
  77   0.4956     90.170  0.0271    99.156  340.32
  78   0.4987     90.360  0.0280    99.142  344.71
  79   0.4977     90.390  0.0265    99.170  349.08
  80   0.5044     90.410  0.0253    99.248  353.44
  81   0.5075     90.440  0.0232    99.302  357.81
  82   0.5128     90.440  0.0217    99.340  362.18
  83   0.5120     90.430  0.0230    99.298  366.56
  84   0.5134     90.490  0.0228    99.256  370.93
  85   0.5168     90.550  0.0221    99.316  375.31
