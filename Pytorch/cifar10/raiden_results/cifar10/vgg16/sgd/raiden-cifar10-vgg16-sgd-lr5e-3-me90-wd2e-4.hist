Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'vgg16', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 3786317824 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9460     25.810  2.2380    13.830  6.01
   2   1.6341     37.960  1.8531    28.532  10.37
   3   1.3929     47.980  1.5991    39.522  14.73
   4   1.3318     51.170  1.4358    46.710  19.09
   5   1.1208     59.240  1.2793    53.376  23.43
   6   1.1037     60.430  1.1319    58.904  27.77
   7   1.0406     62.730  1.0565    61.852  32.11
   8   0.8977     68.670  0.9697    65.308  36.47
   9   0.8802     69.510  0.9013    67.830  40.83
  10   0.7648     74.120  0.8309    70.710  45.18
  11   0.7544     73.610  0.7763    72.790  49.62
  12   0.7131     75.300  0.7282    74.602  53.96
  13   0.6923     76.150  0.6803    76.170  58.33
  14   0.6669     77.770  0.6457    77.532  62.68
  15   0.6426     78.280  0.6220    78.280  67.07
  16   0.5808     80.260  0.5902    79.598  71.40
  17   0.6422     78.810  0.5614    80.716  75.74
  18   0.6024     80.020  0.5484    80.928  80.16
  19   0.5947     79.870  0.5225    81.758  84.55
  20   0.5641     81.500  0.4975    82.730  88.90
  21   0.5486     81.520  0.4794    83.524  93.25
  22   0.5212     82.810  0.4545    84.304  97.60
  23   0.4975     83.240  0.4358    84.986  101.96
  24   0.5338     82.700  0.4262    85.358  106.35
  25   0.5556     81.860  0.4152    85.664  110.68
  26   0.5007     83.520  0.3998    86.266  115.12
  27   0.4920     83.890  0.3836    86.686  119.45
  28   0.4847     83.760  0.3770    86.842  123.81
  29   0.4767     84.680  0.3532    87.706  128.17
  30   0.5368     82.730  0.3434    88.074  132.51
  31   0.5105     83.610  0.3303    88.676  136.90
  32   0.5098     84.310  0.3178    89.004  141.30
  33   0.5052     83.820  0.3067    89.442  145.69
  34   0.4719     84.550  0.2954    89.790  150.06
  35   0.4736     85.060  0.2930    89.820  154.40
  36   0.4714     85.030  0.2732    90.538  158.74
  37   0.4513     86.010  0.2694    90.614  163.10
  38   0.4401     85.890  0.2589    91.006  167.43
  39   0.4779     84.900  0.2435    91.592  171.76
  40   0.4539     86.340  0.2359    91.928  176.11
  41   0.4946     85.070  0.2332    91.950  180.56
  42   0.4986     85.350  0.2282    92.060  184.97
  43   0.4564     86.550  0.2136    92.504  189.33
  44   0.4638     85.860  0.2124    92.634  193.69
  45   0.4602     86.990  0.1946    93.316  198.03
  46   0.5230     85.240  0.1837    93.628  202.42
  47   0.4644     86.350  0.1879    93.448  206.80
  48   0.4741     86.810  0.1719    93.984  211.16
  49   0.5003     86.260  0.1678    94.138  215.58
  50   0.4901     86.630  0.1617    94.364  219.96
  51   0.4872     86.730  0.1541    94.582  224.31
  52   0.4812     86.640  0.1500    94.764  228.67
  53   0.4874     87.160  0.1430    95.012  233.04
  54   0.5123     87.100  0.1359    95.342  237.41
  55   0.4903     86.980  0.1333    95.384  241.76
  56   0.4996     87.070  0.1251    95.586  246.15
  57   0.4680     87.140  0.1203    95.794  250.57
  58   0.4852     87.200  0.1132    96.084  254.95
  59   0.5006     87.050  0.1131    96.090  259.33
  60   0.5232     86.910  0.1068    96.276  263.68
  61   0.4936     87.630  0.1042    96.422  268.05
  62   0.5227     87.170  0.0985    96.548  272.41
  63   0.5040     87.340  0.0993    96.506  276.76
  64   0.5202     87.380  0.0901    96.902  281.16
  65   0.5299     87.100  0.0869    96.994  285.57
  66   0.5233     87.670  0.0831    97.138  289.93
  67   0.5187     87.570  0.0783    97.300  294.28
  68   0.5378     87.680  0.0698    97.580  298.64
  69   0.5446     87.280  0.0723    97.486  302.99
  70   0.5461     87.260  0.0687    97.614  307.33
  71   0.5697     87.430  0.0669    97.678  311.68
  72   0.5606     87.680  0.0638    97.842  316.10
  73   0.5647     87.640  0.0595    97.968  320.45
  74   0.5786     87.850  0.0611    97.888  324.84
  75   0.5737     88.020  0.0568    98.054  329.19
  76   0.5758     87.590  0.0529    98.160  333.55
  77   0.5742     87.760  0.0504    98.278  337.89
  78   0.5762     88.020  0.0495    98.340  342.24
  79   0.6048     87.650  0.0469    98.368  346.58
  80   0.6138     87.990  0.0442    98.520  351.02
  81   0.6458     87.070  0.0430    98.506  355.38
  82   0.5978     87.820  0.0433    98.504  359.75
  83   0.6250     87.870  0.0391    98.618  364.10
  84   0.6158     87.700  0.0435    98.478  368.45
  85   0.6378     87.730  0.0381    98.740  372.79
  86   0.6334     87.430  0.0392    98.678  377.14
  87   0.6362     87.880  0.0352    98.796  381.56
  88   0.6168     88.120  0.0355    98.744  385.90
  89   0.6274     88.110  0.0368    98.768  390.26
  90   0.6223     87.910  0.0335    98.838  394.64
