Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3504     51.110  1.5734    41.986  7.58
   2   1.1845     57.750  1.1931    56.834  13.63
   3   0.9505     66.440  0.9883    64.552  19.73
   4   0.8145     71.210  0.8486    69.580  25.81
   5   0.7474     73.800  0.7419    73.698  31.86
   6   0.7004     75.960  0.6681    76.432  37.93
   7   0.6190     78.630  0.6053    78.636  43.96
   8   0.6076     78.930  0.5479    80.762  50.01
   9   0.5814     80.110  0.5055    82.374  56.12
  10   0.5223     81.570  0.4600    83.854  62.19
  11   0.5133     82.380  0.4447    84.516  68.24
  12   0.5218     82.730  0.3999    86.016  74.29
  13   0.4824     83.700  0.3711    86.954  80.31
  14   0.4886     84.070  0.3482    87.904  86.35
  15   0.4816     83.950  0.3376    88.234  92.52
  16   0.4376     85.340  0.3081    89.284  98.56
  17   0.4507     85.240  0.2900    89.964  104.59
  18   0.4477     85.320  0.2747    90.446  110.64
  19   0.4946     84.470  0.2542    91.064  116.69
  20   0.4235     86.300  0.2464    91.362  122.73
  21   0.4177     86.730  0.2266    92.028  128.85
  22   0.4107     86.840  0.2148    92.606  134.91
  23   0.4792     85.640  0.2061    92.762  140.94
  24   0.3885     87.810  0.1926    93.296  146.97
  25   0.4085     87.450  0.1923    93.326  153.03
  26   0.4001     87.610  0.1795    93.764  159.19
  27   0.4342     86.960  0.1677    94.098  165.26
  28   0.4128     87.900  0.1586    94.406  171.30
  29   0.4174     87.530  0.1586    94.354  177.34
  30   0.4341     87.520  0.1427    95.052  183.39
  31   0.4269     87.970  0.1351    95.186  189.40
  32   0.4139     88.140  0.1286    95.436  195.44
  33   0.4413     87.410  0.1323    95.334  201.61
  34   0.4496     87.970  0.1212    95.780  207.64
  35   0.4338     88.050  0.1105    96.088  213.68
  36   0.4455     87.770  0.1106    96.126  219.71
  37   0.4251     88.520  0.1067    96.230  225.76
  38   0.4394     88.300  0.0997    96.420  231.81
  39   0.4392     88.420  0.0947    96.602  237.95
  40   0.4638     88.220  0.1001    96.552  244.00
  41   0.4193     89.000  0.0897    96.770  250.06
  42   0.4309     88.420  0.0851    97.042  256.11
  43   0.4711     88.010  0.0893    96.828  262.16
  44   0.4671     88.060  0.0903    96.682  268.17
  45   0.4171     89.060  0.0904    96.804  274.26
  46   0.4626     88.560  0.0866    97.014  280.32
  47   0.4341     88.670  0.0857    96.988  286.34
  48   0.4327     89.060  0.0804    97.190  292.42
  49   0.4499     88.710  0.0754    97.344  298.48
  50   0.4458     89.390  0.0687    97.574  304.52
  51   0.4608     88.740  0.0680    97.588  310.61
  52   0.4477     89.370  0.0658    97.670  316.64
  53   0.4356     89.430  0.0614    97.862  322.67
  54   0.4691     88.720  0.0685    97.578  328.70
  55   0.5071     88.340  0.0671    97.626  334.73
  56   0.4395     89.420  0.0692    97.496  340.76
  57   0.4790     88.610  0.0600    97.898  346.89
  58   0.4327     89.880  0.0573    98.004  352.94
  59   0.4461     89.370  0.0590    97.852  358.98
  60   0.4874     88.400  0.0584    97.964  365.01
  61   0.4667     89.300  0.0582    97.996  371.04
  62   0.4472     89.550  0.0621    97.856  377.14
  63   0.4458     89.690  0.0539    98.172  383.20
  64   0.4520     89.580  0.0557    98.034  389.25
  65   0.4675     89.090  0.0565    98.020  395.31
  66   0.4445     89.530  0.0506    98.284  401.36
  67   0.4543     89.540  0.0507    98.256  407.40
  68   0.4758     89.290  0.0506    98.268  413.46
  69   0.4975     89.260  0.0514    98.174  419.57
  70   0.4727     89.420  0.0554    98.040  425.63
  71   0.4524     89.790  0.0466    98.430  431.70
  72   0.4854     89.460  0.0441    98.482  437.74
  73   0.4427     89.860  0.0485    98.340  443.76
  74   0.4389     89.960  0.0444    98.502  449.81
  75   0.4877     89.300  0.0429    98.490  455.94
  76   0.4721     89.610  0.0455    98.362  461.97
  77   0.4561     89.990  0.0434    98.476  467.99
  78   0.4418     90.030  0.0413    98.544  474.02
  79   0.4974     89.490  0.0446    98.446  480.06
  80   0.4832     89.430  0.0489    98.358  486.12
  81   0.4828     89.350  0.0465    98.394  492.22
  82   0.4747     89.700  0.0396    98.646  498.27
  83   0.4734     89.800  0.0411    98.558  504.30
  84   0.4624     90.010  0.0427    98.572  510.33
  85   0.4348     90.660  0.0351    98.736  516.38
  86   0.4944     89.610  0.0431    98.546  522.41
  87   0.4307     90.430  0.0445    98.466  528.56
  88   0.4700     89.880  0.0429    98.532  534.59
  89   0.4553     89.800  0.0414    98.616  540.62
  90   0.4500     90.200  0.0408    98.568  546.64
