Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6353     38.320  1.8590    31.340  7.90
   2   1.4143     47.220  1.4591    45.980  14.03
   3   1.1878     57.760  1.2476    54.496  20.19
   4   1.1236     60.010  1.0675    61.612  26.30
   5   0.9102     68.070  0.9403    66.582  32.44
   6   0.9072     68.530  0.8518    69.788  38.60
   7   0.8268     71.700  0.7734    72.698  44.71
   8   0.7041     75.330  0.7040    75.440  50.82
   9   0.6644     77.370  0.6469    77.360  56.95
  10   0.7143     75.730  0.6168    78.554  63.09
  11   0.6399     78.420  0.5938    79.490  69.28
  12   0.6626     77.640  0.5719    80.254  75.38
  13   0.7000     76.470  0.5466    81.082  81.48
  14   0.6299     78.910  0.5421    81.302  87.63
  15   0.5971     79.850  0.5324    81.458  93.75
  16   0.6704     77.770  0.5196    82.202  99.88
  17   0.6028     80.020  0.5142    82.310  106.07
  18   0.5576     81.560  0.5086    82.432  112.20
  19   0.5620     80.670  0.4978    82.802  118.32
  20   0.6109     79.340  0.4996    82.862  124.43
  21   0.5616     81.370  0.4877    83.390  130.58
  22   0.5401     81.580  0.4795    83.472  136.78
  23   0.5940     80.130  0.4795    83.566  142.91
  24   0.5551     81.120  0.4718    83.742  149.03
  25   0.5350     82.300  0.4721    83.848  155.17
  26   0.5765     81.020  0.4634    84.050  161.29
  27   0.5443     81.950  0.4602    84.230  167.43
  28   0.5256     82.180  0.4613    84.304  173.65
  29   0.5292     81.950  0.4579    84.286  179.74
  30   0.5391     82.370  0.4593    84.220  185.84
  31   0.5287     82.110  0.4470    84.662  191.95
  32   0.5129     82.730  0.4537    84.468  198.04
  33   0.5225     82.310  0.4483    84.542  204.21
  34   0.5166     82.650  0.4439    84.802  210.32
  35   0.5662     80.830  0.4409    85.000  216.45
  36   0.5466     81.220  0.4433    84.838  222.57
  37   0.5070     82.860  0.4406    84.864  228.72
  38   0.4807     83.220  0.4440    84.808  234.83
  39   0.5084     82.940  0.4349    84.906  240.99
  40   0.5611     81.970  0.4307    85.214  247.10
  41   0.5219     82.440  0.4278    85.372  253.24
  42   0.5433     82.140  0.4330    85.022  259.36
  43   0.5600     81.240  0.4371    84.968  265.48
  44   0.4677     84.060  0.4307    85.128  271.69
  45   0.4932     83.210  0.4271    85.322  277.83
  46   0.5286     82.390  0.4269    85.330  283.95
  47   0.4902     83.670  0.4280    85.460  290.09
  48   0.5123     83.000  0.4279    85.388  296.26
  49   0.5329     81.920  0.4235    85.464  302.44
  50   0.4958     83.250  0.4264    85.304  308.54
  51   0.5067     83.090  0.4258    85.274  314.68
  52   0.5826     81.240  0.4272    85.306  320.80
  53   0.5703     81.390  0.4301    85.312  326.95
  54   0.4754     83.840  0.4286    85.296  333.13
  55   0.5124     82.680  0.4142    85.802  339.24
  56   0.4997     83.460  0.4203    85.576  345.36
  57   0.6033     80.100  0.4185    85.708  351.46
  58   0.5760     81.320  0.4220    85.614  357.58
  59   0.4743     83.890  0.4167    85.782  363.67
  60   0.5110     82.700  0.4133    85.764  369.85
  61   0.5723     81.240  0.4169    85.640  375.95
  62   0.5089     83.100  0.4207    85.506  382.13
  63   0.4789     83.990  0.4112    85.828  388.28
  64   0.5063     83.770  0.4122    85.888  394.42
  65   0.4968     83.080  0.4096    86.022  400.59
  66   0.4581     84.760  0.4092    85.972  406.69
  67   0.5183     83.150  0.4044    86.030  412.84
  68   0.5228     82.140  0.4117    85.958  418.96
  69   0.5222     82.190  0.4125    85.738  425.10
  70   0.4914     83.490  0.4113    86.028  431.24
  71   0.4837     83.680  0.4185    85.690  437.44
  72   0.4661     84.480  0.4066    86.058  443.55
  73   0.4722     84.130  0.4056    86.026  449.70
  74   0.5656     81.860  0.4097    85.778  455.84
  75   0.5036     83.390  0.4138    85.782  461.96
  76   0.4963     83.650  0.4116    85.750  468.10
  77   0.5277     83.340  0.4073    86.024  474.28
  78   0.4721     84.000  0.4064    86.046  480.38
  79   0.5210     82.370  0.4106    85.894  486.48
  80   0.5595     81.830  0.3982    86.186  492.61
  81   0.5100     83.100  0.4079    86.098  498.71
  82   0.4902     83.660  0.4093    85.850  504.89
  83   0.5322     82.370  0.4048    86.008  511.16
  84   0.4558     84.800  0.4012    86.092  517.30
  85   0.4649     84.120  0.4029    86.132  523.43
