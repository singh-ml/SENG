Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6172     50.310  1.3974    48.898  7.70
   2   0.9895     65.210  0.9489    66.264  13.86
   3   0.7479     73.950  0.7431    74.016  19.99
   4   0.8831     72.190  0.6270    78.228  26.06
   5   0.7852     74.670  0.5604    80.554  32.16
   6   0.5928     79.290  0.5096    82.378  38.30
   7   0.6570     79.060  0.4661    84.104  44.41
   8   0.8019     74.080  0.4363    84.844  50.49
   9   0.7802     75.140  0.4065    86.196  56.56
  10   0.6756     78.610  0.3828    86.792  62.67
  11   0.5285     83.420  0.3633    87.514  68.78
  12   0.5653     81.880  0.3413    88.328  74.92
  13   0.5267     82.650  0.3252    88.796  81.00
  14   0.4971     83.520  0.3088    89.328  87.12
  15   0.4662     85.050  0.2978    89.768  93.26
  16   0.6958     81.510  0.2857    90.108  99.33
  17   0.5759     81.610  0.2774    90.426  105.42
  18   0.4286     86.190  0.2634    91.050  111.55
  19   0.4241     86.530  0.2557    91.344  117.67
  20   0.4174     86.940  0.2481    91.630  123.77
  21   0.3662     88.180  0.2363    91.918  129.88
  22   0.3810     87.740  0.2318    92.114  136.01
  23   0.4201     86.600  0.2217    92.360  142.09
  24   0.4892     85.330  0.2108    92.680  148.28
  25   0.4768     86.050  0.2077    92.936  154.40
  26   0.4409     87.040  0.2028    92.974  160.55
  27   0.3872     88.460  0.2009    93.012  166.65
  28   0.4003     88.500  0.1929    93.406  172.75
  29   0.3409     89.830  0.1881    93.488  178.92
  30   0.3963     88.580  0.1827    93.794  185.01
  31   0.3852     88.310  0.1765    93.874  191.13
  32   0.3415     89.470  0.1803    93.796  197.24
  33   0.3508     89.300  0.1716    94.114  203.36
  34   0.3639     89.050  0.1684    94.274  209.47
  35   0.3549     89.300  0.1620    94.408  215.67
  36   0.3387     89.420  0.1574    94.690  221.75
  37   0.3452     89.000  0.1609    94.454  227.86
  38   0.3595     89.180  0.1589    94.456  234.00
  39   0.3674     88.950  0.1529    94.652  240.10
  40   0.3399     89.930  0.1477    94.912  246.18
  41   0.3433     90.220  0.1485    94.938  252.37
  42   0.4673     86.370  0.1442    95.006  258.47
  43   0.4308     88.200  0.1457    94.966  264.56
  44   0.3121     90.220  0.1439    95.022  270.70
  45   0.3468     89.770  0.1387    95.238  276.82
  46   0.3367     89.730  0.1385    95.220  282.93
  47   0.3758     89.420  0.1374    95.310  289.11
  48   0.3366     90.370  0.1341    95.344  295.20
  49   0.3589     89.430  0.1314    95.504  301.35
  50   0.3439     89.830  0.1292    95.576  307.46
  51   0.3741     89.790  0.1297    95.516  313.59
  52   0.3268     90.330  0.1323    95.324  319.74
  53   0.3937     88.880  0.1228    95.746  325.88
  54   0.3509     89.720  0.1288    95.618  332.00
  55   0.3541     90.040  0.1219    95.832  338.12
  56   0.3219     90.180  0.1286    95.566  344.25
  57   0.3933     89.600  0.1213    95.844  350.38
  58   0.3745     89.630  0.1241    95.776  356.51
  59   0.3898     89.120  0.1212    95.878  362.64
  60   0.3396     90.050  0.1224    95.834  368.75
  61   0.3540     89.740  0.1198    95.756  374.85
  62   0.3764     89.830  0.1138    96.164  380.95
  63   0.4123     88.060  0.1175    95.870  387.04
  64   0.3403     90.400  0.1177    95.892  393.25
  65   0.3616     89.620  0.1125    96.068  399.38
  66   0.3766     90.080  0.1143    96.082  405.53
  67   0.3492     90.070  0.1128    96.126  411.67
  68   0.3135     91.210  0.1104    96.202  417.84
  69   0.3460     90.500  0.1155    96.048  423.94
  70   0.3684     89.480  0.1064    96.306  430.07
  71   0.4023     89.350  0.1097    96.254  436.21
  72   0.3104     90.950  0.1087    96.200  442.33
  73   0.3272     91.270  0.1170    95.978  448.44
  74   0.4591     88.180  0.1126    96.166  454.56
  75   0.3735     89.900  0.1075    96.198  460.72
  76   0.3641     89.790  0.1064    96.246  466.83
  77   0.3500     91.000  0.1059    96.374  472.92
  78   0.4242     89.040  0.1021    96.526  479.02
  79   0.3605     90.240  0.1083    96.226  485.13
  80   0.4113     89.170  0.1094    96.254  491.26
  81   0.3617     90.120  0.1136    96.096  497.46
  82   0.3999     89.470  0.1067    96.372  503.61
  83   0.4581     88.310  0.1013    96.446  509.74
  84   0.3744     90.320  0.1060    96.332  515.92
  85   0.3556     90.570  0.1068    96.370  522.02
