Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2976     53.380  1.5662    42.308  7.70
   2   1.1754     57.070  1.2090    56.318  13.90
   3   0.9787     64.990  1.0351    62.848  20.11
   4   0.9313     67.080  0.9144    67.500  26.37
   5   0.8756     69.410  0.8366    70.336  32.54
   6   0.8042     71.650  0.7619    73.032  38.73
   7   0.7439     74.780  0.7044    75.008  44.92
   8   0.7510     73.420  0.6428    77.492  51.09
   9   0.6516     77.420  0.6054    78.756  57.40
  10   0.6376     78.000  0.5570    80.206  63.61
  11   0.7097     76.010  0.5264    81.682  69.81
  12   0.6496     78.140  0.4926    82.796  76.00
  13   0.6106     79.400  0.4645    83.670  82.20
  14   0.6072     79.160  0.4400    84.444  88.42
  15   0.5902     79.900  0.4189    85.278  94.68
  16   0.5174     82.630  0.4004    86.054  100.88
  17   0.5225     83.000  0.3725    86.770  107.04
  18   0.5349     82.540  0.3602    87.298  113.21
  19   0.5780     81.650  0.3403    88.018  119.38
  20   0.5677     81.390  0.3235    88.766  125.55
  21   0.5552     82.020  0.3089    89.218  131.79
  22   0.5520     82.770  0.2951    89.890  138.01
  23   0.5015     83.920  0.2744    90.546  144.22
  24   0.5517     82.440  0.2624    90.888  150.43
  25   0.4970     84.510  0.2519    91.110  156.62
  26   0.5180     83.940  0.2430    91.446  162.84
  27   0.4839     84.780  0.2291    92.088  169.12
  28   0.5185     83.810  0.2229    92.216  175.31
  29   0.4690     85.470  0.2062    92.752  181.51
  30   0.6015     82.590  0.2022    92.988  187.72
  31   0.4886     84.790  0.1913    93.300  193.92
  32   0.5347     84.590  0.1758    93.824  200.20
  33   0.5394     84.430  0.1765    93.774  206.37
  34   0.5233     84.280  0.1654    94.190  212.58
  35   0.5346     84.280  0.1574    94.534  218.75
  36   0.4821     86.190  0.1539    94.574  224.93
  37   0.5434     84.550  0.1459    94.876  231.12
  38   0.5198     85.330  0.1375    95.158  237.39
  39   0.5505     85.220  0.1342    95.266  243.56
  40   0.5143     85.170  0.1278    95.528  249.76
  41   0.5463     85.360  0.1227    95.762  255.94
  42   0.5557     84.870  0.1204    95.786  262.11
  43   0.5092     86.190  0.1098    96.204  268.37
  44   0.5102     85.960  0.1074    96.184  274.55
  45   0.5306     85.530  0.1016    96.424  280.76
  46   0.5376     86.180  0.0956    96.608  286.93
  47   0.4929     86.840  0.1005    96.552  293.10
  48   0.5682     85.510  0.0971    96.638  299.28
  49   0.5784     84.910  0.0929    96.720  305.48
  50   0.5521     85.940  0.0923    96.818  311.67
  51   0.5869     85.500  0.0862    97.018  317.87
  52   0.5842     85.480  0.0839    97.062  324.06
  53   0.5335     86.270  0.0778    97.394  330.27
  54   0.5003     86.990  0.0815    97.120  336.45
  55   0.5608     85.990  0.0776    97.348  342.69
  56   0.5859     85.490  0.0747    97.458  348.88
  57   0.5532     85.870  0.0706    97.582  355.06
  58   0.5153     86.950  0.0700    97.658  361.22
  59   0.5283     86.600  0.0714    97.546  367.43
  60   0.5606     86.670  0.0691    97.522  373.64
  61   0.5697     86.080  0.0658    97.754  379.92
  62   0.5714     86.770  0.0600    97.966  386.13
  63   0.5479     86.410  0.0620    97.844  392.34
  64   0.5848     86.250  0.0632    97.888  398.58
  65   0.5647     86.370  0.0569    98.148  404.81
  66   0.6067     85.220  0.0629    97.916  410.99
  67   0.5555     86.490  0.0571    98.048  417.29
  68   0.5389     87.380  0.0598    97.896  423.52
  69   0.5295     87.340  0.0566    98.084  429.75
  70   0.5141     87.530  0.0559    98.066  435.94
  71   0.5340     86.980  0.0521    98.236  442.18
  72   0.5332     87.080  0.0550    98.110  448.43
  73   0.5647     87.200  0.0544    98.130  454.63
  74   0.5135     87.870  0.0504    98.286  460.81
  75   0.6105     85.780  0.0501    98.262  466.99
  76   0.5277     87.380  0.0524    98.218  473.22
  77   0.5585     87.070  0.0502    98.236  479.48
  78   0.5170     88.180  0.0495    98.332  485.68
  79   0.5717     86.820  0.0436    98.528  491.85
  80   0.5838     86.420  0.0520    98.224  498.03
  81   0.5034     88.210  0.0457    98.474  504.20
  82   0.5049     87.760  0.0479    98.380  510.40
  83   0.4986     87.610  0.0453    98.478  516.67
  84   0.5164     87.910  0.0414    98.604  522.87
  85   0.5711     87.360  0.0466    98.396  529.06
  86   0.5686     87.630  0.0419    98.586  535.27
  87   0.6172     86.060  0.0454    98.412  541.51
  88   0.4940     88.420  0.0466    98.470  547.77
  89   0.5468     87.390  0.0403    98.684  553.96
  90   0.5489     87.400  0.0381    98.762  560.14
