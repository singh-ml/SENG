Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6081     39.820  1.8321    32.780  7.62
   2   1.3061     51.530  1.4489    46.078  13.69
   3   1.2519     56.190  1.2357    54.952  19.74
   4   1.0910     61.900  1.0749    61.332  25.79
   5   1.0095     64.020  0.9803    65.272  31.95
   6   0.8779     69.030  0.8807    68.842  38.01
   7   0.8438     70.400  0.7886    72.450  44.06
   8   0.7683     73.120  0.7133    75.244  50.15
   9   0.6493     77.770  0.6536    77.222  56.20
  10   0.6665     77.400  0.5880    79.646  62.32
  11   0.5704     80.300  0.5665    80.242  68.40
  12   0.6232     79.570  0.5321    81.750  74.48
  13   0.5650     80.880  0.5019    82.524  80.57
  14   0.5792     80.540  0.4819    83.282  86.61
  15   0.5612     81.420  0.4656    83.976  92.65
  16   0.5152     82.210  0.4533    84.318  98.86
  17   0.5847     81.490  0.4433    84.690  104.89
  18   0.4740     84.380  0.4287    85.162  110.99
  19   0.4670     84.630  0.4132    85.700  117.04
  20   0.4845     83.910  0.4056    86.150  123.12
  21   0.4731     83.900  0.4001    86.268  129.18
  22   0.4917     83.590  0.3843    86.632  135.32
  23   0.4249     85.620  0.3771    87.000  141.40
  24   0.4619     84.660  0.3705    87.330  147.50
  25   0.4776     84.150  0.3678    87.332  153.57
  26   0.4203     86.180  0.3601    87.646  159.62
  27   0.4548     84.670  0.3552    87.662  165.72
  28   0.4151     86.020  0.3482    87.926  171.83
  29   0.4212     85.690  0.3463    88.012  177.90
  30   0.4186     85.830  0.3427    88.048  184.01
  31   0.4367     85.590  0.3347    88.490  190.11
  32   0.4238     86.000  0.3259    88.678  196.15
  33   0.4199     85.770  0.3290    88.636  202.21
  34   0.4241     86.240  0.3192    88.970  208.33
  35   0.4065     86.560  0.3200    89.002  214.40
  36   0.4584     85.270  0.3234    88.734  220.49
  37   0.4276     86.320  0.3243    88.928  226.60
  38   0.4135     86.390  0.3112    89.214  232.64
  39   0.4494     85.350  0.3082    89.230  238.77
  40   0.3933     86.610  0.3098    89.304  244.84
  41   0.4147     86.700  0.3019    89.640  250.97
  42   0.4463     85.540  0.3080    89.380  257.04
  43   0.4248     86.180  0.3048    89.462  263.09
  44   0.4233     86.160  0.2981    89.586  269.21
  45   0.4111     86.400  0.3022    89.488  275.28
  46   0.4155     85.910  0.2942    89.792  281.33
  47   0.4342     86.020  0.2987    89.620  287.48
  48   0.4081     86.850  0.2990    89.684  293.53
  49   0.4792     84.830  0.2924    89.950  299.58
  50   0.3703     87.860  0.2865    90.106  305.67
  51   0.4130     86.760  0.2903    89.934  311.72
  52   0.4268     86.580  0.2851    90.218  317.76
  53   0.4898     84.510  0.2879    90.118  323.94
  54   0.4321     85.930  0.2887    90.022  330.06
  55   0.3642     88.020  0.2879    90.072  336.12
  56   0.3781     87.520  0.2821    90.312  342.22
  57   0.3821     87.490  0.2857    90.242  348.33
  58   0.3800     87.590  0.2793    90.342  354.47
  59   0.3820     87.670  0.2801    90.368  360.54
  60   0.3952     86.980  0.2824    90.094  366.63
  61   0.3745     87.690  0.2797    90.304  372.72
  62   0.3994     86.990  0.2732    90.456  378.83
  63   0.3857     87.500  0.2691    90.562  384.92
  64   0.4134     87.420  0.2725    90.482  391.10
  65   0.4053     87.180  0.2711    90.564  397.16
  66   0.4067     86.730  0.2777    90.356  403.23
  67   0.4129     87.150  0.2766    90.362  409.30
  68   0.4101     87.270  0.2720    90.588  415.35
  69   0.3880     87.570  0.2735    90.526  421.49
  70   0.3957     87.220  0.2714    90.590  427.52
  71   0.3746     87.750  0.2696    90.540  433.56
  72   0.4460     86.200  0.2749    90.450  439.64
  73   0.3940     87.450  0.2690    90.646  445.67
  74   0.4767     85.160  0.2745    90.578  451.71
  75   0.3852     87.790  0.2662    90.724  457.86
  76   0.4205     86.900  0.2613    90.856  463.92
  77   0.3648     87.740  0.2701    90.528  469.98
  78   0.3625     87.810  0.2671    90.706  476.08
  79   0.3967     87.450  0.2679    90.696  482.12
  80   0.3908     87.630  0.2743    90.434  488.23
  81   0.3527     88.560  0.2578    91.100  494.37
  82   0.3837     87.380  0.2618    90.880  500.43
  83   0.3899     87.620  0.2599    91.168  506.52
  84   0.4140     87.540  0.2578    91.124  512.57
  85   0.4207     86.780  0.2590    91.116  518.60
