Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2921     53.010  1.5453    42.888  7.54
   2   0.9931     64.140  1.1487    58.442  13.66
   3   0.9239     67.140  0.9295    66.644  19.81
   4   0.7482     73.340  0.7897    72.194  25.86
   5   0.7064     75.630  0.6833    76.080  31.89
   6   0.6624     77.330  0.6229    78.092  38.00
   7   0.6052     79.390  0.5654    80.180  44.14
   8   0.5587     80.820  0.5136    81.956  50.20
   9   0.5539     81.530  0.4747    83.476  56.26
  10   0.5016     83.140  0.4372    84.698  62.30
  11   0.5002     83.290  0.4034    85.900  68.37
  12   0.4924     83.370  0.3867    86.684  74.46
  13   0.4747     84.120  0.3684    87.292  80.58
  14   0.4629     84.950  0.3412    88.112  86.67
  15   0.4769     84.590  0.3245    88.698  92.73
  16   0.4868     84.610  0.3132    89.114  98.79
  17   0.4722     85.140  0.2924    89.722  104.85
  18   0.4040     87.310  0.2712    90.654  110.90
  19   0.4033     86.530  0.2528    91.238  117.08
  20   0.4160     86.850  0.2435    91.606  123.12
  21   0.3938     87.430  0.2359    91.892  129.16
  22   0.4209     86.630  0.2231    92.294  135.23
  23   0.3944     87.740  0.2197    92.270  141.31
  24   0.4357     86.610  0.2061    92.888  147.45
  25   0.4251     87.330  0.1990    93.028  153.50
  26   0.4097     87.360  0.1879    93.438  159.54
  27   0.4331     87.400  0.1724    94.034  165.63
  28   0.3986     88.190  0.1690    94.178  171.71
  29   0.4019     87.950  0.1553    94.614  177.76
  30   0.4104     88.660  0.1525    94.688  183.82
  31   0.4336     87.250  0.1487    94.856  189.94
  32   0.4179     87.720  0.1427    94.948  196.02
  33   0.4070     88.470  0.1377    95.204  202.05
  34   0.4049     88.230  0.1320    95.422  208.10
  35   0.4073     88.360  0.1278    95.616  214.18
  36   0.4066     88.330  0.1291    95.542  220.24
  37   0.4057     88.840  0.1170    95.920  226.38
  38   0.3716     89.330  0.1222    95.666  232.41
  39   0.4025     88.650  0.1172    95.816  238.49
  40   0.3926     89.140  0.1047    96.224  244.54
  41   0.3934     89.400  0.1030    96.382  250.65
  42   0.4010     89.210  0.1001    96.516  256.74
  43   0.3820     89.280  0.0995    96.580  262.86
  44   0.4139     89.570  0.0988    96.568  268.90
  45   0.3938     89.410  0.0975    96.714  274.96
  46   0.3942     89.620  0.0910    96.702  281.04
  47   0.4092     88.950  0.0882    96.826  287.14
  48   0.4205     89.000  0.0848    97.114  293.24
  49   0.4000     89.240  0.0823    97.230  299.36
  50   0.4097     89.670  0.0782    97.244  305.46
  51   0.3952     89.760  0.0767    97.306  311.51
  52   0.4271     88.870  0.0748    97.416  317.61
  53   0.4165     89.270  0.0768    97.352  323.68
  54   0.4613     88.420  0.0780    97.298  329.73
  55   0.4046     89.230  0.0743    97.326  335.83
  56   0.3949     89.710  0.0728    97.508  341.89
  57   0.4237     89.670  0.0676    97.604  347.93
  58   0.4344     89.160  0.0670    97.652  354.01
  59   0.4158     89.250  0.0689    97.610  360.04
  60   0.4118     89.880  0.0650    97.782  366.20
  61   0.4059     89.880  0.0655    97.674  372.29
  62   0.3918     90.060  0.0615    97.870  378.37
  63   0.4217     89.500  0.0605    97.898  384.44
  64   0.4316     90.180  0.0612    97.862  390.52
  65   0.4166     90.000  0.0574    98.016  396.56
  66   0.4535     89.410  0.0609    97.854  402.70
  67   0.4364     89.300  0.0614    97.862  408.74
  68   0.3992     90.250  0.0577    97.990  414.82
  69   0.4065     89.720  0.0532    98.124  420.90
  70   0.4511     89.510  0.0616    97.918  426.94
  71   0.3920     90.230  0.0602    97.900  433.01
  72   0.4121     90.110  0.0568    98.044  439.04
  73   0.4167     89.890  0.0569    98.056  445.17
  74   0.4046     90.230  0.0536    98.150  451.23
  75   0.4308     89.480  0.0528    98.158  457.33
  76   0.4161     90.120  0.0520    98.230  463.37
  77   0.4109     90.100  0.0509    98.272  469.42
  78   0.4133     90.130  0.0518    98.172  475.48
  79   0.4105     90.450  0.0509    98.216  481.58
  80   0.4246     90.020  0.0467    98.444  487.62
  81   0.3970     89.940  0.0516    98.302  493.68
  82   0.4269     90.210  0.0455    98.458  499.78
  83   0.4308     89.820  0.0467    98.364  505.87
  84   0.4425     89.430  0.0441    98.504  511.92
  85   0.4283     89.830  0.0500    98.246  518.04
  86   0.4303     90.030  0.0445    98.514  524.12
  87   0.4334     89.980  0.0422    98.578  530.18
  88   0.4070     90.020  0.0462    98.406  536.21
  89   0.4327     89.760  0.0458    98.436  542.30
  90   0.4192     90.180  0.0449    98.482  548.44
