Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2838     53.210  1.5227    44.382  7.64
   2   1.1498     58.860  1.1620    58.116  13.70
   3   0.9531     65.850  0.9689    65.150  19.78
   4   0.9657     67.420  0.8298    70.456  25.89
   5   0.7654     73.850  0.7320    74.248  32.01
   6   0.7665     74.630  0.6486    77.484  38.15
   7   0.5939     79.340  0.5791    80.026  44.26
   8   0.5825     80.430  0.5237    81.988  50.34
   9   0.5149     82.490  0.4828    83.304  56.39
  10   0.4995     83.260  0.4472    84.678  62.49
  11   0.5150     83.210  0.4284    85.236  68.63
  12   0.4958     83.980  0.4032    86.182  74.72
  13   0.4991     84.070  0.3780    87.038  80.80
  14   0.4309     85.820  0.3477    87.992  86.91
  15   0.4101     86.950  0.3332    88.416  93.01
  16   0.4161     86.320  0.3138    89.282  99.07
  17   0.3894     87.500  0.2964    89.738  105.15
  18   0.3814     87.360  0.2797    90.446  111.34
  19   0.3897     87.580  0.2724    90.652  117.42
  20   0.4180     87.080  0.2597    91.048  123.51
  21   0.4105     86.810  0.2575    91.238  129.64
  22   0.3875     87.670  0.2401    91.786  135.77
  23   0.3418     88.820  0.2314    92.022  141.88
  24   0.3525     88.440  0.2113    92.762  147.96
  25   0.3719     88.460  0.2250    92.258  154.03
  26   0.3768     87.640  0.2101    92.874  160.10
  27   0.3374     89.210  0.2039    93.056  166.21
  28   0.3341     89.440  0.1962    93.268  172.32
  29   0.3478     89.290  0.1965    93.138  178.44
  30   0.3769     88.900  0.1856    93.572  184.65
  31   0.3472     89.490  0.1741    93.872  190.70
  32   0.3305     89.790  0.1697    94.134  196.81
  33   0.3663     88.510  0.1713    94.168  202.89
  34   0.3727     88.890  0.1700    94.086  208.98
  35   0.3405     89.900  0.1661    94.146  215.08
  36   0.3535     89.770  0.1643    94.300  221.27
  37   0.3539     89.910  0.1544    94.656  227.33
  38   0.3355     89.860  0.1575    94.532  233.42
  39   0.3506     90.540  0.1447    94.890  239.50
  40   0.3458     89.390  0.1489    94.820  245.59
  41   0.3786     89.600  0.1471    94.924  251.74
  42   0.3528     90.180  0.1463    94.940  257.87
  43   0.3206     90.600  0.1439    94.956  263.94
  44   0.3143     90.350  0.1355    95.364  270.01
  45   0.3184     90.590  0.1307    95.508  276.12
  46   0.3490     89.820  0.1350    95.364  282.22
  47   0.3313     90.210  0.1337    95.362  288.41
  48   0.3334     90.750  0.1269    95.590  294.50
  49   0.3457     90.440  0.1349    95.324  300.56
  50   0.3179     90.890  0.1259    95.604  306.64
  51   0.3185     90.760  0.1286    95.546  312.70
  52   0.3386     90.380  0.1179    95.832  318.82
  53   0.3386     90.280  0.1251    95.606  324.97
  54   0.3759     89.700  0.1197    95.868  331.04
  55   0.3498     90.730  0.1172    95.844  337.13
  56   0.3300     90.660  0.1216    95.792  343.23
  57   0.3575     90.250  0.1154    96.054  349.34
  58   0.3196     91.000  0.1145    96.042  355.41
  59   0.3486     90.360  0.1150    96.032  361.62
  60   0.3212     91.230  0.1192    95.900  367.70
  61   0.3081     91.390  0.1113    96.202  373.80
  62   0.3444     90.510  0.1087    96.240  379.87
  63   0.3437     90.790  0.1067    96.250  385.94
  64   0.3576     90.350  0.1127    96.076  392.05
  65   0.3561     90.130  0.1149    96.024  398.22
  66   0.3348     91.020  0.1124    96.132  404.29
  67   0.3762     89.780  0.1098    96.134  410.42
  68   0.3447     90.490  0.1123    96.064  416.49
  69   0.3185     90.900  0.1061    96.340  422.57
  70   0.3503     90.100  0.1063    96.400  428.65
  71   0.3339     91.050  0.1064    96.222  434.77
  72   0.3502     90.260  0.1042    96.464  440.87
  73   0.3296     90.840  0.1042    96.388  446.95
  74   0.3934     90.230  0.0996    96.532  453.01
  75   0.3882     89.610  0.1089    96.262  459.09
  76   0.3389     90.630  0.1089    96.322  465.15
  77   0.3449     90.600  0.1013    96.582  471.30
  78   0.3339     90.910  0.0968    96.578  477.37
  79   0.3528     90.640  0.0965    96.648  483.49
  80   0.3344     90.790  0.0984    96.502  489.55
  81   0.3332     90.790  0.1001    96.464  495.68
  82   0.3239     91.160  0.0999    96.490  501.80
  83   0.3338     91.090  0.1002    96.522  508.00
  84   0.3331     91.310  0.0998    96.522  514.07
  85   0.3397     90.930  0.0967    96.624  520.16
  86   0.3541     90.380  0.0969    96.664  526.29
  87   0.3372     90.950  0.0975    96.642  532.38
  88   0.3378     91.290  0.0967    96.656  538.54
  89   0.3432     90.670  0.0934    96.712  544.61
  90   0.3695     90.520  0.0971    96.604  550.73
