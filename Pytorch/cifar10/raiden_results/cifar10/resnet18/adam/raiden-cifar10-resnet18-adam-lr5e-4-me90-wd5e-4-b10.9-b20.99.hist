Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3089     53.420  1.3881    48.888  7.61
   2   0.8303     70.950  0.9348    66.754  13.70
   3   0.9576     68.930  0.7329    74.490  19.79
   4   0.7379     75.320  0.6324    77.972  25.84
   5   0.9762     70.270  0.5634    80.532  31.93
   6   0.8394     74.150  0.5167    82.318  38.05
   7   0.6844     78.570  0.4727    83.650  44.09
   8   0.5734     81.050  0.4377    85.074  50.14
   9   0.4880     83.790  0.4095    86.002  56.21
  10   0.5881     81.690  0.3878    86.668  62.33
  11   0.4950     84.280  0.3632    87.728  68.42
  12   0.4903     83.520  0.3372    88.482  74.48
  13   0.5743     81.140  0.3243    88.960  80.54
  14   0.4306     85.790  0.3108    89.228  86.60
  15   0.4749     83.680  0.2947    90.014  92.66
  16   0.4059     86.740  0.2806    90.362  98.80
  17   0.5086     83.840  0.2691    90.822  104.85
  18   0.4049     86.130  0.2595    91.182  110.96
  19   0.4712     85.170  0.2478    91.586  117.04
  20   0.4543     85.780  0.2389    91.704  123.08
  21   0.4391     86.770  0.2331    92.016  129.12
  22   0.3911     87.940  0.2289    92.114  135.16
  23   0.4266     86.690  0.2190    92.582  141.34
  24   0.4559     85.780  0.2081    92.908  147.40
  25   0.4051     87.550  0.2022    93.118  153.46
  26   0.4039     87.520  0.2000    93.132  159.48
  27   0.4396     87.160  0.1951    93.272  165.53
  28   0.5019     84.790  0.1870    93.548  171.69
  29   0.4624     86.770  0.1825    93.726  177.78
  30   0.4726     86.020  0.1784    93.852  183.89
  31   0.4881     85.980  0.1742    94.042  189.96
  32   0.4019     87.740  0.1705    94.096  195.99
  33   0.4408     86.700  0.1681    94.262  202.04
  34   0.4195     87.210  0.1638    94.438  208.14
  35   0.3829     88.490  0.1610    94.410  214.18
  36   0.4339     87.450  0.1567    94.596  220.21
  37   0.4738     86.600  0.1479    94.938  226.28
  38   0.4199     87.680  0.1527    94.852  232.34
  39   0.3855     88.280  0.1450    95.054  238.40
  40   0.4053     87.730  0.1457    95.068  244.51
  41   0.3589     89.280  0.1398    95.226  250.57
  42   0.3362     90.000  0.1401    95.298  256.64
  43   0.3843     89.150  0.1363    95.384  262.72
  44   0.3548     89.710  0.1331    95.436  268.79
  45   0.3311     90.620  0.1328    95.410  274.95
  46   0.3587     89.750  0.1323    95.454  280.98
  47   0.3605     89.050  0.1293    95.622  287.06
  48   0.3730     88.870  0.1293    95.576  293.12
  49   0.3897     88.380  0.1295    95.720  299.22
  50   0.4218     88.660  0.1223    95.754  305.29
  51   0.3289     90.650  0.1204    95.908  311.45
  52   0.3762     89.900  0.1217    95.858  317.51
  53   0.3591     89.660  0.1215    95.742  323.54
  54   0.3888     89.060  0.1214    95.820  329.58
  55   0.3504     89.990  0.1140    96.156  335.63
  56   0.3662     89.830  0.1153    96.092  341.69
  57   0.3590     89.940  0.1165    96.112  347.71
  58   0.3552     90.190  0.1114    96.200  353.84
  59   0.3613     89.650  0.1100    96.236  359.88
  60   0.3614     89.460  0.1161    96.088  365.90
  61   0.3915     89.100  0.1104    96.210  371.98
  62   0.3333     90.830  0.1066    96.466  378.01
  63   0.3734     90.310  0.1069    96.382  384.06
  64   0.3273     90.700  0.1078    96.304  390.17
  65   0.3735     89.830  0.1049    96.454  396.23
  66   0.3451     90.020  0.1101    96.272  402.29
  67   0.3318     90.630  0.1040    96.468  408.32
  68   0.3632     90.020  0.1016    96.510  414.37
  69   0.3621     89.750  0.1088    96.300  420.47
  70   0.3572     90.160  0.0995    96.618  426.52
  71   0.3323     90.720  0.1046    96.428  432.55
  72   0.4205     88.790  0.0970    96.658  438.61
  73   0.3596     90.480  0.1016    96.580  444.69
  74   0.3675     89.740  0.0992    96.586  450.79
  75   0.3260     90.720  0.0994    96.570  456.82
  76   0.3675     89.940  0.0970    96.772  462.87
  77   0.3584     90.380  0.0988    96.608  468.94
  78   0.3844     89.860  0.0939    96.868  474.97
  79   0.3823     90.080  0.0987    96.746  481.04
  80   0.3639     89.770  0.0922    96.952  487.07
  81   0.3528     90.120  0.0938    96.858  493.21
  82   0.3673     89.920  0.0990    96.612  499.28
  83   0.3374     90.580  0.0950    96.758  505.31
  84   0.4345     88.420  0.0939    96.824  511.34
  85   0.3657     90.280  0.0959    96.772  517.39
  86   0.3478     90.710  0.0917    96.944  523.50
  87   0.3472     90.740  0.0924    96.854  529.57
  88   0.3324     90.660  0.0904    96.914  535.68
  89   0.3716     89.720  0.0882    97.042  541.78
  90   0.3347     90.800  0.0912    96.898  547.81
