Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2631     53.000  1.5465    42.564  7.69
   2   1.0616     62.050  1.1744    57.302  13.77
   3   0.9159     66.980  0.9680    65.168  19.82
   4   0.8237     71.130  0.8361    70.296  25.87
   5   0.7232     74.250  0.7224    74.530  31.92
   6   0.6580     77.900  0.6386    77.604  37.99
   7   0.6168     79.250  0.5808    79.634  44.10
   8   0.6028     80.050  0.5311    81.260  50.17
   9   0.5451     81.450  0.4851    83.034  56.23
  10   0.5306     81.950  0.4512    84.132  62.26
  11   0.5283     82.490  0.4140    85.562  68.30
  12   0.4783     83.910  0.3926    86.052  74.33
  13   0.5042     83.400  0.3640    87.320  80.47
  14   0.4624     84.670  0.3402    88.072  86.56
  15   0.4816     84.790  0.3198    88.772  92.66
  16   0.4468     85.450  0.3028    89.378  98.72
  17   0.4332     86.230  0.2899    89.726  104.80
  18   0.4780     85.180  0.2622    90.874  110.82
  19   0.4564     85.820  0.2524    91.234  116.96
  20   0.4370     86.170  0.2415    91.388  123.03
  21   0.4466     86.350  0.2227    92.260  129.07
  22   0.4320     86.510  0.2173    92.326  135.11
  23   0.4539     85.950  0.2068    92.792  141.14
  24   0.4339     86.650  0.1974    93.096  147.20
  25   0.4145     87.640  0.1822    93.628  153.34
  26   0.4070     88.020  0.1735    93.882  159.42
  27   0.4342     87.280  0.1723    93.936  165.47
  28   0.4061     87.880  0.1682    94.056  171.50
  29   0.4245     87.710  0.1563    94.430  177.56
  30   0.4072     87.800  0.1485    94.800  183.70
  31   0.4148     88.370  0.1325    95.358  189.78
  32   0.4141     88.350  0.1255    95.590  195.87
  33   0.4412     87.980  0.1318    95.284  201.97
  34   0.4452     88.270  0.1193    95.800  208.01
  35   0.4242     88.480  0.1154    95.934  214.08
  36   0.4238     88.820  0.1081    96.106  220.14
  37   0.4082     88.420  0.1061    96.328  226.28
  38   0.4220     89.060  0.1046    96.338  232.36
  39   0.4502     88.340  0.1024    96.400  238.40
  40   0.4279     88.750  0.0973    96.592  244.44
  41   0.4326     88.650  0.1010    96.394  250.48
  42   0.4520     88.120  0.0991    96.556  256.52
  43   0.4453     88.890  0.0908    96.804  262.69
  44   0.4473     88.810  0.0869    96.884  268.73
  45   0.4759     88.300  0.0838    97.026  274.77
  46   0.4311     88.970  0.0826    97.072  280.81
  47   0.4454     89.290  0.0757    97.320  286.88
  48   0.4650     88.990  0.0736    97.422  292.94
  49   0.4716     88.440  0.0771    97.304  299.08
  50   0.4285     89.600  0.0793    97.184  305.12
  51   0.4872     88.450  0.0754    97.366  311.15
  52   0.4455     89.730  0.0725    97.426  317.21
  53   0.4700     88.930  0.0668    97.654  323.26
  54   0.4327     89.460  0.0677    97.658  329.33
  55   0.4290     89.690  0.0698    97.572  335.47
  56   0.4632     89.430  0.0678    97.580  341.54
  57   0.4231     89.400  0.0609    97.860  347.56
  58   0.4701     89.380  0.0607    97.904  353.64
  59   0.4616     89.510  0.0607    97.910  359.67
  60   0.4608     89.430  0.0618    97.826  365.75
  61   0.4581     89.200  0.0587    97.886  371.88
  62   0.4593     89.110  0.0583    98.006  377.94
  63   0.4525     89.630  0.0588    97.910  384.01
  64   0.4274     89.700  0.0581    97.872  390.09
  65   0.4321     89.840  0.0531    98.150  396.14
  66   0.4325     90.150  0.0524    98.126  402.23
  67   0.4438     89.750  0.0540    98.098  408.26
  68   0.4536     89.770  0.0502    98.266  414.35
  69   0.4330     89.960  0.0462    98.436  420.44
  70   0.4510     90.240  0.0482    98.366  426.50
  71   0.4668     89.950  0.0500    98.292  432.52
  72   0.4764     89.200  0.0466    98.420  438.60
  73   0.4484     89.590  0.0429    98.504  444.73
  74   0.4451     90.190  0.0445    98.438  450.77
  75   0.4746     89.600  0.0459    98.416  456.82
  76   0.4591     89.930  0.0472    98.326  462.89
  77   0.4657     89.690  0.0422    98.576  468.93
  78   0.4638     89.760  0.0446    98.442  474.97
  79   0.4446     90.170  0.0410    98.544  481.06
  80   0.4324     90.220  0.0423    98.548  487.09
  81   0.4313     90.260  0.0437    98.478  493.17
  82   0.4472     90.000  0.0424    98.562  499.20
  83   0.4683     90.050  0.0458    98.458  505.24
  84   0.4477     90.260  0.0470    98.292  511.28
  85   0.4696     90.030  0.0467    98.390  517.39
  86   0.4420     89.940  0.0464    98.380  523.43
  87   0.4263     90.190  0.0385    98.694  529.50
  88   0.4763     89.710  0.0437    98.492  535.60
  89   0.4509     89.880  0.0425    98.558  541.66
  90   0.4628     89.870  0.0405    98.574  547.68
