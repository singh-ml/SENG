Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0390     29.410  1.9102    30.174  7.80
   2   1.5729     43.330  1.4866    44.916  14.00
   3   1.0970     60.670  1.2040    56.214  20.28
   4   1.1564     59.460  1.0239    63.400  26.48
   5   1.1687     61.780  0.9185    67.384  32.69
   6   1.3441     59.450  0.8295    70.698  38.85
   7   0.8157     70.870  0.7592    73.492  45.01
   8   0.9404     69.180  0.6945    75.612  51.21
   9   0.7839     73.380  0.6566    77.162  57.50
  10   0.7162     75.140  0.6307    78.168  63.71
  11   0.7785     74.050  0.6067    78.824  69.88
  12   0.9036     71.000  0.5912    79.494  76.04
  13   0.6489     77.950  0.5770    79.950  82.22
  14   0.8242     73.980  0.5628    80.474  88.52
  15   0.6593     77.260  0.5556    80.748  94.70
  16   0.8172     75.330  0.5432    81.116  100.90
  17   0.6520     78.300  0.5388    81.384  107.12
  18   0.8334     74.080  0.5344    81.516  113.30
  19   0.6406     78.600  0.5254    81.720  119.47
  20   0.9305     72.320  0.5197    82.110  125.76
  21   0.8114     73.410  0.5168    82.090  131.92
  22   0.6405     79.220  0.5059    82.432  138.12
  23   0.5809     81.020  0.5006    82.694  144.31
  24   0.7200     75.760  0.5003    82.722  150.48
  25   0.8013     74.520  0.4939    83.148  156.67
  26   0.6663     78.700  0.4946    82.840  162.89
  27   0.8657     72.320  0.4911    82.976  169.07
  28   0.7369     75.300  0.4918    82.996  175.24
  29   0.6144     79.400  0.4839    83.330  181.43
  30   0.5885     80.550  0.4767    83.452  187.61
  31   0.6036     79.200  0.4787    83.538  193.77
  32   0.9066     72.530  0.4806    83.474  199.97
  33   0.6861     77.100  0.4745    83.652  206.24
  34   0.7682     74.880  0.4708    83.768  212.41
  35   0.6768     77.810  0.4692    83.812  218.62
  36   0.5860     79.790  0.4734    83.650  224.78
  37   0.6272     79.540  0.4717    83.668  230.97
  38   0.6767     77.040  0.4638    83.890  237.13
  39   0.6413     78.630  0.4646    84.052  243.39
  40   0.6584     78.790  0.4634    84.072  249.58
  41   0.6275     79.460  0.4598    84.122  255.73
  42   0.5848     80.490  0.4621    83.982  261.92
  43   0.7017     77.420  0.4641    84.016  268.12
  44   0.5695     80.370  0.4623    84.228  274.41
  45   0.6350     78.810  0.4609    84.224  280.59
  46   0.6273     80.390  0.4574    84.286  286.82
  47   0.9220     73.910  0.4598    83.980  293.03
  48   0.7283     77.550  0.4581    84.186  299.26
  49   0.6267     78.980  0.4564    84.326  305.49
  50   1.1004     69.850  0.4591    84.296  311.76
  51   0.5736     80.890  0.4520    84.350  317.96
  52   0.5792     80.950  0.4536    84.334  324.20
  53   0.7796     75.130  0.4484    84.544  330.38
  54   0.5782     81.370  0.4509    84.402  336.60
  55   0.5173     82.620  0.4559    84.404  342.84
  56   0.6139     79.780  0.4493    84.656  349.00
  57   0.6305     79.080  0.4502    84.484  355.23
  58   0.6596     78.930  0.4490    84.566  361.40
  59   0.9189     72.390  0.4503    84.592  367.60
  60   0.9245     73.310  0.4528    84.550  373.83
  61   0.5794     80.850  0.4455    84.796  380.01
  62   0.5943     80.680  0.4519    84.458  386.17
  63   0.7068     76.590  0.4474    84.660  392.34
  64   0.5539     81.650  0.4464    84.678  398.54
  65   0.9023     73.240  0.4429    84.952  404.69
  66   0.5852     80.790  0.4472    84.466  410.85
  67   0.5444     81.430  0.4457    84.742  417.08
  68   0.6304     79.610  0.4439    84.710  423.29
  69   0.8535     75.010  0.4453    84.598  429.48
  70   0.5967     80.540  0.4419    84.624  435.69
  71   0.6516     79.720  0.4473    84.622  441.87
  72   0.8391     73.750  0.4472    84.594  448.03
  73   0.7758     76.300  0.4388    84.798  454.26
  74   0.5152     82.680  0.4421    84.938  460.47
  75   0.5357     82.220  0.4441    84.530  466.62
  76   0.5634     81.050  0.4420    84.838  472.78
  77   0.5522     81.660  0.4370    84.856  478.94
  78   0.7199     77.450  0.4397    84.848  485.20
  79   0.5807     80.180  0.4366    84.942  491.40
  80   0.7070     78.380  0.4387    84.734  497.57
  81   0.5982     80.070  0.4415    84.752  503.74
  82   0.7735     76.770  0.4351    85.000  509.94
  83   0.5852     80.600  0.4382    84.918  516.11
  84   0.6052     80.410  0.4401    84.914  522.36
  85   0.7217     77.190  0.4404    84.782  528.53
