Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3680     49.930  1.6330    39.704  7.66
   2   1.1747     57.460  1.2873    53.032  13.82
   3   1.0533     62.310  1.1139    60.104  19.90
   4   0.9427     66.400  0.9833    64.944  26.01
   5   0.8583     69.410  0.8825    68.756  32.12
   6   0.7886     72.480  0.7969    71.698  38.22
   7   0.7177     74.660  0.7307    74.444  44.31
   8   0.6789     76.250  0.6688    76.468  50.41
   9   0.6619     77.330  0.6200    78.140  56.49
  10   0.6279     78.200  0.5751    79.942  62.71
  11   0.6096     78.500  0.5371    81.244  68.85
  12   0.5942     79.380  0.5033    82.378  74.94
  13   0.5959     79.560  0.4781    83.360  81.04
  14   0.5530     81.090  0.4503    84.166  87.15
  15   0.5431     81.870  0.4239    85.208  93.24
  16   0.5417     82.230  0.4004    86.122  99.40
  17   0.5390     82.600  0.3860    86.496  105.56
  18   0.5286     82.610  0.3651    87.214  111.66
  19   0.5100     82.960  0.3470    87.940  117.76
  20   0.5041     83.500  0.3290    88.570  123.90
  21   0.5073     83.240  0.3127    88.960  129.99
  22   0.4938     84.120  0.2958    89.768  136.16
  23   0.5080     83.630  0.2827    90.150  142.29
  24   0.5162     83.520  0.2730    90.360  148.38
  25   0.5115     83.810  0.2599    90.830  154.48
  26   0.4878     84.420  0.2460    91.402  160.62
  27   0.5029     84.680  0.2337    91.668  166.78
  28   0.4742     85.160  0.2219    92.246  173.00
  29   0.4953     85.000  0.2048    92.888  179.11
  30   0.5037     85.090  0.1985    93.090  185.22
  31   0.4774     85.370  0.1898    93.368  191.29
  32   0.4822     85.560  0.1807    93.626  197.38
  33   0.4967     85.740  0.1765    93.818  203.58
  34   0.4890     85.910  0.1698    94.014  209.72
  35   0.4672     85.800  0.1584    94.440  215.81
  36   0.4996     86.040  0.1537    94.660  221.92
  37   0.5200     85.430  0.1501    94.770  228.00
  38   0.4975     86.170  0.1390    95.022  234.15
  39   0.5025     85.850  0.1295    95.396  240.30
  40   0.5046     86.170  0.1301    95.436  246.44
  41   0.5035     86.370  0.1189    95.792  252.53
  42   0.5098     86.380  0.1210    95.684  258.66
  43   0.5312     86.000  0.1130    96.002  264.80
  44   0.4936     86.930  0.1175    95.906  270.90
  45   0.5375     86.170  0.1021    96.420  277.05
  46   0.5312     86.690  0.1025    96.404  283.15
  47   0.5189     86.650  0.0943    96.704  289.29
  48   0.5356     86.320  0.0938    96.740  295.39
  49   0.4989     87.090  0.0944    96.626  301.52
  50   0.5126     86.960  0.0906    96.718  307.62
  51   0.5419     86.450  0.0851    97.002  313.82
  52   0.5281     86.890  0.0852    96.942  319.91
  53   0.5227     87.170  0.0827    97.112  326.01
  54   0.5374     86.500  0.0840    97.048  332.10
  55   0.5343     86.810  0.0845    97.026  338.26
  56   0.5081     87.350  0.0790    97.224  344.38
  57   0.5113     87.470  0.0698    97.554  350.56
  58   0.5426     87.080  0.0677    97.598  356.70
  59   0.5408     86.820  0.0695    97.594  362.84
  60   0.5268     87.060  0.0680    97.560  368.97
  61   0.5403     87.000  0.0650    97.688  375.12
  62   0.5646     86.990  0.0644    97.706  381.32
  63   0.5441     87.040  0.0628    97.812  387.48
  64   0.5233     87.490  0.0595    97.928  393.61
  65   0.5394     87.540  0.0583    98.006  399.70
  66   0.5441     87.490  0.0571    98.094  405.88
  67   0.5102     87.870  0.0580    97.974  412.00
  68   0.5532     87.340  0.0530    98.178  418.21
  69   0.5904     87.190  0.0545    98.130  424.29
  70   0.5819     86.870  0.0546    98.074  430.39
  71   0.5163     88.030  0.0569    98.014  436.52
  72   0.5619     87.490  0.0501    98.268  442.66
  73   0.5282     87.670  0.0558    98.038  448.81
  74   0.5282     87.920  0.0508    98.326  455.00
  75   0.5471     88.070  0.0464    98.434  461.11
  76   0.5764     87.770  0.0458    98.380  467.21
  77   0.5571     87.580  0.0483    98.344  473.33
  78   0.5466     88.150  0.0496    98.244  479.46
  79   0.5482     88.100  0.0437    98.478  485.60
  80   0.5603     87.480  0.0432    98.442  491.75
  81   0.5383     88.240  0.0482    98.382  497.90
  82   0.5906     87.310  0.0480    98.414  504.02
  83   0.5439     88.220  0.0444    98.478  510.15
  84   0.5228     88.200  0.0452    98.460  516.26
  85   0.5403     88.040  0.0394    98.666  522.41
