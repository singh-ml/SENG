Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2890     52.510  1.5163    43.848  7.82
   2   1.0505     61.810  1.1338    59.256  13.95
   3   0.8578     69.860  0.9292    66.592  20.06
   4   0.7394     74.080  0.7912    71.928  26.29
   5   0.7549     74.650  0.6947    75.626  32.46
   6   0.7087     76.340  0.6103    78.740  38.58
   7   0.5585     81.160  0.5497    80.920  44.74
   8   0.6601     78.500  0.5003    82.594  50.91
   9   0.4899     83.660  0.4689    83.918  57.11
  10   0.4628     84.430  0.4312    85.204  63.28
  11   0.4832     84.400  0.4015    86.232  69.44
  12   0.4919     83.580  0.3845    86.840  75.55
  13   0.4309     85.620  0.3688    87.418  81.72
  14   0.4056     86.630  0.3421    88.256  87.86
  15   0.4139     86.400  0.3211    88.958  94.07
  16   0.3823     87.110  0.2992    89.730  100.21
  17   0.4347     85.910  0.2926    90.018  106.37
  18   0.3873     87.730  0.2778    90.458  112.55
  19   0.4168     86.320  0.2653    90.752  118.71
  20   0.3955     87.100  0.2577    91.110  124.83
  21   0.3650     87.830  0.2466    91.434  131.03
  22   0.3481     88.670  0.2463    91.580  137.21
  23   0.3679     88.080  0.2280    92.166  143.37
  24   0.3813     87.700  0.2207    92.338  149.51
  25   0.4223     87.340  0.2094    92.754  155.64
  26   0.3428     89.310  0.2082    92.748  161.74
  27   0.3746     88.320  0.2034    92.936  167.94
  28   0.3779     88.630  0.1968    93.146  174.12
  29   0.3747     88.350  0.1890    93.546  180.24
  30   0.3318     89.440  0.1852    93.564  186.42
  31   0.3576     89.000  0.1791    93.782  192.54
  32   0.3626     89.650  0.1712    94.096  198.71
  33   0.3424     89.840  0.1738    93.982  204.84
  34   0.3642     88.820  0.1691    94.012  210.98
  35   0.3759     89.010  0.1698    94.134  217.10
  36   0.3276     90.160  0.1702    94.116  223.24
  37   0.3456     89.140  0.1584    94.508  229.38
  38   0.3374     89.990  0.1564    94.638  235.63
  39   0.3384     89.810  0.1507    94.792  241.76
  40   0.3600     89.640  0.1467    94.942  247.90
  41   0.3230     90.150  0.1449    95.004  254.02
  42   0.3234     90.570  0.1422    95.006  260.17
  43   0.3708     89.280  0.1437    95.028  266.36
  44   0.3525     89.540  0.1495    94.788  272.51
  45   0.3397     90.410  0.1383    95.234  278.65
  46   0.3254     90.310  0.1398    95.244  284.77
  47   0.3405     90.000  0.1355    95.170  290.92
  48   0.3490     89.800  0.1324    95.458  297.10
  49   0.3086     90.820  0.1359    95.380  303.26
  50   0.3739     89.260  0.1327    95.448  309.44
  51   0.3468     90.340  0.1187    95.840  315.62
  52   0.3444     90.360  0.1236    95.668  321.76
  53   0.3580     90.010  0.1234    95.748  327.92
  54   0.3387     90.290  0.1204    95.836  334.08
  55   0.3549     90.400  0.1221    95.766  340.21
  56   0.3759     89.660  0.1196    95.828  346.33
  57   0.3515     90.080  0.1225    95.814  352.44
  58   0.3501     89.980  0.1236    95.648  358.62
  59   0.3790     89.770  0.1187    95.780  364.88
  60   0.3397     90.280  0.1134    96.044  371.01
  61   0.3308     90.940  0.1163    95.884  377.14
  62   0.3542     90.640  0.1113    96.184  383.32
  63   0.3511     90.770  0.1093    96.194  389.47
  64   0.3489     90.260  0.1083    96.222  395.64
  65   0.3577     90.250  0.1108    96.220  401.87
  66   0.3368     90.550  0.1140    96.074  408.05
  67   0.3761     90.000  0.1094    96.156  414.19
  68   0.3382     90.790  0.1100    96.182  420.34
  69   0.3333     90.930  0.1132    96.094  426.48
  70   0.3460     90.400  0.1107    96.180  432.61
  71   0.3358     90.500  0.1095    96.132  438.79
  72   0.3200     91.170  0.1072    96.212  444.91
  73   0.3349     90.860  0.1077    96.304  451.04
  74   0.3272     90.730  0.1036    96.368  457.15
  75   0.3606     90.420  0.1025    96.386  463.32
  76   0.3440     90.630  0.1051    96.366  469.45
  77   0.3421     90.780  0.1040    96.374  475.67
  78   0.3452     90.800  0.1055    96.396  481.83
  79   0.3288     91.170  0.1082    96.254  487.99
  80   0.3729     90.360  0.0991    96.590  494.17
  81   0.3551     91.170  0.0980    96.510  500.34
  82   0.3285     91.000  0.1002    96.562  506.62
  83   0.3496     90.780  0.1019    96.544  512.80
  84   0.3495     90.820  0.1040    96.402  518.95
  85   0.3557     90.760  0.1014    96.480  525.08
