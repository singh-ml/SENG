Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3093     55.560  1.3870    49.470  7.75
   2   1.0448     64.480  0.9266    67.040  13.86
   3   0.7603     74.210  0.7293    74.530  19.95
   4   0.8041     73.430  0.6223    78.536  26.05
   5   0.6573     77.810  0.5621    80.492  32.14
   6   0.6682     77.970  0.5105    82.524  38.26
   7   0.6127     80.040  0.4654    84.086  44.48
   8   0.7382     76.660  0.4364    85.006  50.56
   9   0.5417     82.090  0.4096    85.930  56.69
  10   0.4696     84.790  0.3782    87.072  62.76
  11   0.5416     82.270  0.3623    87.674  68.91
  12   0.4955     83.180  0.3450    88.144  75.10
  13   0.5029     83.700  0.3329    88.784  81.21
  14   0.5120     83.580  0.3118    89.174  87.32
  15   0.5614     81.300  0.2948    89.968  93.41
  16   0.4499     85.760  0.2869    90.186  99.55
  17   0.5796     82.570  0.2736    90.698  105.66
  18   0.3801     87.360  0.2592    91.092  111.72
  19   0.3822     87.600  0.2556    91.284  117.90
  20   0.3686     87.740  0.2507    91.512  124.00
  21   0.4259     87.000  0.2327    92.002  130.06
  22   0.4100     86.750  0.2279    92.182  136.18
  23   0.3815     88.270  0.2224    92.424  142.30
  24   0.3767     88.600  0.2148    92.654  148.44
  25   0.3556     88.910  0.2042    93.012  154.59
  26   0.3758     88.130  0.2004    93.168  160.66
  27   0.3659     88.620  0.1957    93.280  166.77
  28   0.4012     87.770  0.1919    93.388  172.87
  29   0.3846     88.180  0.1845    93.668  178.99
  30   0.3608     89.250  0.1823    93.792  185.06
  31   0.4182     87.600  0.1750    93.938  191.25
  32   0.3497     88.610  0.1753    94.046  197.32
  33   0.3608     88.640  0.1693    94.144  203.39
  34   0.3568     89.240  0.1657    94.298  209.50
  35   0.3987     88.280  0.1618    94.364  215.58
  36   0.3496     89.490  0.1632    94.384  221.66
  37   0.3816     89.100  0.1582    94.494  227.83
  38   0.3943     87.750  0.1532    94.776  233.91
  39   0.3336     90.320  0.1487    94.814  240.03
  40   0.3585     89.630  0.1495    94.918  246.13
  41   0.3919     88.790  0.1504    94.684  252.22
  42   0.3635     89.410  0.1471    95.030  258.33
  43   0.3573     89.650  0.1430    95.052  264.44
  44   0.3641     89.810  0.1474    94.940  270.56
  45   0.3786     89.060  0.1406    95.188  276.67
  46   0.3340     90.180  0.1363    95.400  282.77
  47   0.3469     89.700  0.1365    95.212  288.90
  48   0.3650     89.760  0.1325    95.432  295.08
  49   0.3587     89.830  0.1332    95.446  301.21
  50   0.3604     89.760  0.1323    95.460  307.30
  51   0.3688     89.660  0.1277    95.540  313.39
  52   0.3679     89.680  0.1286    95.608  319.49
  53   0.4066     89.200  0.1265    95.648  325.59
  54   0.3367     90.560  0.1314    95.450  331.79
  55   0.4462     87.810  0.1202    95.836  337.89
  56   0.3320     90.330  0.1279    95.492  343.97
  57   0.4200     88.860  0.1194    95.768  350.04
  58   0.4037     88.690  0.1195    95.902  356.13
  59   0.4133     89.260  0.1220    95.816  362.24
  60   0.3867     89.700  0.1221    95.760  368.39
  61   0.3842     89.760  0.1199    95.910  374.47
  62   0.3990     89.390  0.1177    95.870  380.59
  63   0.4029     88.990  0.1172    96.028  386.73
  64   0.3795     89.810  0.1164    96.048  392.88
  65   0.3681     89.840  0.1165    95.994  398.97
  66   0.3868     89.520  0.1142    96.122  405.10
  67   0.3636     89.880  0.1174    95.928  411.17
  68   0.3547     90.560  0.1117    96.192  417.30
  69   0.3164     90.990  0.1185    95.888  423.41
  70   0.4045     89.370  0.1108    96.128  429.50
  71   0.3503     90.470  0.1106    96.154  435.59
  72   0.3142     91.200  0.1139    96.148  441.75
  73   0.3526     90.460  0.1081    96.242  447.85
  74   0.3536     90.640  0.1037    96.356  453.95
  75   0.3700     90.520  0.1025    96.432  460.06
  76   0.3696     89.730  0.1027    96.368  466.18
  77   0.4364     88.270  0.1058    96.390  472.29
  78   0.3519     90.800  0.1121    96.122  478.54
  79   0.3525     90.090  0.1115    96.094  484.65
  80   0.3360     90.290  0.1053    96.364  490.74
  81   0.3332     90.660  0.1031    96.440  496.84
  82   0.3863     90.320  0.1018    96.562  502.97
  83   0.3288     90.840  0.1100    96.206  509.20
  84   0.3530     90.690  0.1051    96.392  515.33
  85   0.3450     91.170  0.1026    96.504  521.47
  86   0.3287     90.640  0.1037    96.402  527.62
  87   0.3444     90.540  0.1041    96.438  533.78
  88   0.3553     90.260  0.0997    96.634  539.88
  89   0.3543     90.430  0.1032    96.474  546.05
  90   0.3943     89.650  0.0990    96.626  552.18
