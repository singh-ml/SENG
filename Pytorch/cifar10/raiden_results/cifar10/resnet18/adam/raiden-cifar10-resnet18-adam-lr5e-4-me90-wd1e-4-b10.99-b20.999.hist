Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1998     56.650  1.4775    45.572  7.72
   2   0.9942     64.690  1.0842    60.804  13.82
   3   0.9308     67.010  0.8887    68.258  19.92
   4   0.7654     73.740  0.7597    73.116  26.10
   5   0.6610     76.640  0.6575    76.800  32.23
   6   0.6315     78.660  0.5798    79.670  38.30
   7   0.5673     80.570  0.5237    81.656  44.38
   8   0.6214     79.440  0.4782    83.360  50.47
   9   0.5040     83.250  0.4437    84.654  56.63
  10   0.5202     82.300  0.4177    85.688  62.73
  11   0.4729     84.120  0.3837    86.670  68.85
  12   0.4559     84.810  0.3623    87.494  74.98
  13   0.4296     85.350  0.3322    88.492  81.07
  14   0.5356     83.240  0.3059    89.478  87.24
  15   0.4007     86.920  0.3023    89.552  93.33
  16   0.4444     86.460  0.2845    90.190  99.45
  17   0.4157     86.690  0.2620    90.948  105.52
  18   0.4188     86.410  0.2521    91.192  111.64
  19   0.3896     87.790  0.2391    91.620  117.75
  20   0.4447     86.000  0.2242    92.234  123.94
  21   0.4374     86.960  0.2129    92.738  130.02
  22   0.3689     88.380  0.2164    92.430  136.15
  23   0.3419     89.010  0.1977    93.002  142.26
  24   0.3993     87.980  0.1887    93.508  148.40
  25   0.3949     88.240  0.1809    93.682  154.49
  26   0.3611     88.870  0.1665    94.158  160.69
  27   0.4098     88.050  0.1594    94.508  166.82
  28   0.3809     88.590  0.1606    94.458  172.93
  29   0.3872     88.880  0.1590    94.446  179.03
  30   0.3744     89.080  0.1534    94.666  185.18
  31   0.3474     90.050  0.1396    95.052  191.31
  32   0.3759     89.110  0.1365    95.274  197.42
  33   0.3764     89.270  0.1378    95.180  203.50
  34   0.3688     89.740  0.1295    95.476  209.60
  35   0.4149     89.080  0.1156    96.054  215.68
  36   0.3438     90.010  0.1155    95.890  221.80
  37   0.3656     90.020  0.1124    96.170  227.92
  38   0.3639     89.830  0.1118    96.128  234.13
  39   0.3413     90.760  0.1068    96.264  240.23
  40   0.3743     89.780  0.0990    96.558  246.31
  41   0.3943     89.300  0.1043    96.344  252.39
  42   0.3587     90.720  0.0959    96.778  258.54
  43   0.3781     89.980  0.0934    96.706  264.63
  44   0.3622     90.420  0.0946    96.744  270.81
  45   0.3929     89.520  0.0951    96.628  276.96
  46   0.3639     90.220  0.0990    96.576  283.07
  47   0.3810     90.170  0.0768    97.346  289.15
  48   0.3661     90.320  0.0801    97.182  295.26
  49   0.3763     90.520  0.0781    97.240  301.37
  50   0.3664     90.590  0.0806    97.236  307.62
  51   0.3911     90.240  0.0780    97.304  313.72
  52   0.3650     90.810  0.0754    97.394  319.80
  53   0.3606     90.840  0.0736    97.400  325.90
  54   0.3917     90.340  0.0725    97.530  332.03
  55   0.3326     90.960  0.0778    97.270  338.24
  56   0.3574     91.050  0.0776    97.356  344.34
  57   0.3655     90.860  0.0739    97.396  350.45
  58   0.3817     90.740  0.0686    97.572  356.57
  59   0.4015     89.960  0.0749    97.460  362.65
  60   0.4070     90.360  0.0671    97.658  368.84
  61   0.3703     90.520  0.0696    97.578  374.93
  62   0.3666     91.070  0.0660    97.696  381.05
  63   0.3771     90.420  0.0631    97.884  387.16
  64   0.3991     90.780  0.0618    97.976  393.27
  65   0.3518     91.260  0.0623    97.846  399.39
  66   0.4232     90.170  0.0616    97.850  405.56
  67   0.3583     91.210  0.0651    97.794  411.67
  68   0.4005     90.790  0.0601    97.962  417.77
  69   0.3720     90.980  0.0614    97.892  423.86
  70   0.3801     91.140  0.0572    97.998  429.94
  71   0.3716     91.530  0.0560    98.026  436.09
  72   0.4240     90.250  0.0649    97.730  442.19
  73   0.3470     91.360  0.0637    97.860  448.28
  74   0.3775     91.390  0.0556    98.040  454.40
  75   0.3825     90.320  0.0597    97.978  460.51
  76   0.3734     91.070  0.0606    97.890  466.62
  77   0.3800     91.060  0.0519    98.218  472.80
  78   0.4089     90.110  0.0562    98.038  478.89
  79   0.3726     91.060  0.0611    97.896  484.99
  80   0.3776     90.950  0.0525    98.134  491.08
  81   0.3527     91.500  0.0524    98.216  497.22
  82   0.3483     91.410  0.0539    98.164  503.34
  83   0.3424     91.790  0.0538    98.152  509.44
  84   0.3685     90.780  0.0530    98.198  515.59
  85   0.4120     90.370  0.0511    98.254  521.72
  86   0.3681     91.520  0.0500    98.322  527.83
  87   0.4192     90.790  0.0482    98.380  533.98
  88   0.3774     91.140  0.0540    98.162  540.11
  89   0.3624     91.230  0.0542    98.188  546.25
  90   0.3777     90.910  0.0495    98.342  552.34
