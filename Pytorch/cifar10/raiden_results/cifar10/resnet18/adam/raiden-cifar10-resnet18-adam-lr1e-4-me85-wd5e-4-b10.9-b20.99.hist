Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3028     51.960  1.5788    41.604  7.83
   2   1.1979     57.820  1.1935    56.888  13.91
   3   0.9910     65.590  1.0176    63.418  19.96
   4   0.9024     68.380  0.8942    68.212  26.00
   5   0.8143     71.040  0.7943    71.724  32.11
   6   0.7977     72.100  0.7198    74.646  38.23
   7   0.7314     74.960  0.6593    76.922  44.30
   8   0.6923     76.520  0.6141    78.390  50.40
   9   0.6582     77.340  0.5750    80.024  56.44
  10   0.6126     78.670  0.5385    81.174  62.52
  11   0.6344     77.880  0.5037    82.358  68.64
  12   0.5819     80.160  0.4749    83.478  74.69
  13   0.5562     80.680  0.4499    84.238  80.73
  14   0.5751     80.900  0.4273    85.090  86.82
  15   0.5415     81.500  0.4046    85.862  92.86
  16   0.5422     81.910  0.3837    86.788  98.90
  17   0.5405     81.710  0.3620    87.372  105.04
  18   0.5572     81.770  0.3482    87.862  111.11
  19   0.5650     81.670  0.3344    88.454  117.16
  20   0.5051     83.350  0.3159    88.972  123.19
  21   0.5565     82.290  0.3022    89.472  129.22
  22   0.5182     83.450  0.2865    90.026  135.30
  23   0.5618     82.130  0.2744    90.490  141.35
  24   0.5170     83.180  0.2665    90.626  147.49
  25   0.4840     84.470  0.2531    91.264  153.54
  26   0.4927     84.430  0.2397    91.604  159.57
  27   0.4481     85.860  0.2301    91.924  165.64
  28   0.4693     85.010  0.2201    92.284  171.74
  29   0.5147     84.590  0.2066    92.894  177.87
  30   0.4768     85.520  0.2061    92.902  183.92
  31   0.4915     85.530  0.1909    93.384  190.00
  32   0.4511     86.260  0.1846    93.470  196.07
  33   0.4692     86.130  0.1773    93.924  202.12
  34   0.6100     83.110  0.1682    94.204  208.25
  35   0.4859     85.670  0.1631    94.394  214.30
  36   0.4919     85.070  0.1584    94.522  220.38
  37   0.4921     86.130  0.1519    94.772  226.45
  38   0.5040     85.580  0.1490    94.814  232.54
  39   0.4765     86.440  0.1409    95.076  238.58
  40   0.5141     85.640  0.1350    95.408  244.71
  41   0.4394     87.160  0.1317    95.356  250.72
  42   0.4841     86.690  0.1235    95.686  256.77
  43   0.5197     86.200  0.1184    95.918  262.81
  44   0.4814     86.620  0.1202    95.856  268.84
  45   0.4843     86.140  0.1159    96.118  274.88
  46   0.4686     87.140  0.1132    96.124  280.92
  47   0.4701     87.220  0.1060    96.354  287.07
  48   0.5271     85.560  0.1039    96.438  293.10
  49   0.4905     86.690  0.1023    96.430  299.16
  50   0.4836     87.260  0.0964    96.664  305.21
  51   0.5070     86.760  0.0935    96.758  311.29
  52   0.4801     86.710  0.0921    96.792  317.42
  53   0.4739     87.540  0.0882    96.986  323.46
  54   0.4491     87.500  0.0904    96.930  329.49
  55   0.5163     87.260  0.0859    97.078  335.56
  56   0.5204     86.470  0.0861    97.008  341.65
  57   0.5063     86.840  0.0836    97.142  347.67
  58   0.5189     86.980  0.0832    97.188  353.77
  59   0.5456     86.520  0.0821    97.194  359.83
  60   0.4676     87.380  0.0758    97.432  365.91
  61   0.4690     87.770  0.0731    97.570  371.94
  62   0.5217     87.070  0.0750    97.472  378.03
  63   0.5129     86.940  0.0719    97.622  384.18
  64   0.4967     87.050  0.0746    97.408  390.25
  65   0.5081     86.740  0.0681    97.688  396.29
  66   0.4554     87.900  0.0728    97.516  402.34
  67   0.4248     88.790  0.0684    97.680  408.37
  68   0.4342     88.830  0.0695    97.720  414.40
  69   0.4551     88.150  0.0627    97.898  420.56
  70   0.5245     87.000  0.0664    97.786  426.61
  71   0.5615     86.260  0.0648    97.820  432.68
  72   0.4645     88.150  0.0635    97.932  438.71
  73   0.5748     85.780  0.0625    97.902  444.76
  74   0.4913     87.630  0.0631    97.912  450.91
  75   0.5184     87.520  0.0604    97.956  457.02
  76   0.4933     87.480  0.0605    98.022  463.07
  77   0.4661     88.170  0.0566    98.124  469.13
  78   0.5275     86.620  0.0594    97.994  475.14
  79   0.4644     87.870  0.0572    98.036  481.23
  80   0.4930     87.420  0.0535    98.182  487.27
  81   0.4804     87.810  0.0544    98.134  493.39
  82   0.4575     88.310  0.0532    98.246  499.41
  83   0.5234     87.110  0.0554    98.130  505.45
  84   0.4570     88.090  0.0521    98.306  511.53
  85   0.5411     87.000  0.0548    98.178  517.60
