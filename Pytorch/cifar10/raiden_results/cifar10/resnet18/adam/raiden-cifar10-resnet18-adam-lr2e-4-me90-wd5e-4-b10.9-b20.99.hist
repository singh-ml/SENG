Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2012     57.400  1.4693    45.782  7.78
   2   1.2123     58.370  1.0638    61.726  14.05
   3   0.8138     71.460  0.8666    69.148  20.29
   4   0.8067     72.390  0.7323    74.136  26.51
   5   0.6667     76.640  0.6432    77.624  32.75
   6   0.6936     75.980  0.5836    79.740  38.97
   7   0.6937     76.780  0.5366    81.442  45.18
   8   0.5928     79.500  0.4935    82.722  51.46
   9   0.6447     78.630  0.4612    83.848  57.67
  10   0.5031     82.840  0.4296    85.066  63.87
  11   0.5693     80.990  0.4003    86.206  70.08
  12   0.5007     82.900  0.3743    86.972  76.28
  13   0.6031     80.430  0.3530    87.698  82.47
  14   0.5904     80.890  0.3331    88.554  88.73
  15   0.4974     83.730  0.3183    88.868  94.95
  16   0.5185     83.250  0.3032    89.506  101.17
  17   0.4612     85.070  0.2875    90.088  107.39
  18   0.5300     83.540  0.2725    90.628  113.64
  19   0.4371     85.790  0.2569    91.242  119.85
  20   0.4765     85.130  0.2485    91.424  126.12
  21   0.4536     85.450  0.2372    91.648  132.39
  22   0.4038     86.730  0.2245    92.242  138.61
  23   0.4580     85.540  0.2189    92.448  144.81
  24   0.4714     86.370  0.2060    92.868  151.03
  25   0.5244     83.950  0.2050    92.946  157.24
  26   0.5695     83.810  0.1879    93.502  163.51
  27   0.5915     82.610  0.1848    93.622  169.75
  28   0.4199     87.370  0.1720    94.074  175.98
  29   0.4928     85.430  0.1684    94.038  182.19
  30   0.4785     86.640  0.1615    94.374  188.40
  31   0.4024     88.000  0.1574    94.480  194.62
  32   0.4119     88.050  0.1533    94.648  200.93
  33   0.4210     87.590  0.1459    94.880  207.16
  34   0.4312     87.890  0.1404    95.198  213.36
  35   0.4387     88.030  0.1389    95.200  219.58
  36   0.5684     85.110  0.1332    95.392  225.78
  37   0.4452     87.480  0.1306    95.448  232.08
  38   0.3768     88.950  0.1269    95.554  238.29
  39   0.4950     86.800  0.1163    95.990  244.52
  40   0.4251     87.590  0.1198    95.782  250.79
  41   0.3920     88.890  0.1149    96.000  257.02
  42   0.3938     89.030  0.1095    96.250  263.33
  43   0.4346     88.130  0.1083    96.248  269.56
  44   0.5291     85.980  0.1063    96.234  275.77
  45   0.4781     87.340  0.1026    96.440  282.01
  46   0.4883     86.670  0.1024    96.446  288.24
  47   0.4247     88.560  0.0962    96.712  294.43
  48   0.6112     84.280  0.0952    96.692  300.68
  49   0.4387     88.380  0.0985    96.556  306.94
  50   0.4305     88.880  0.0886    96.926  313.14
  51   0.5325     86.450  0.0899    96.950  319.35
  52   0.5411     85.830  0.0929    96.880  325.54
  53   0.4341     88.360  0.0879    96.982  331.76
  54   0.5090     87.600  0.0860    97.060  337.97
  55   0.4989     86.710  0.0885    96.952  344.18
  56   0.4404     88.750  0.0818    97.188  350.38
  57   0.4081     89.110  0.0812    97.286  356.61
  58   0.5659     86.340  0.0804    97.340  362.82
  59   0.4715     87.560  0.0809    97.272  369.12
  60   0.4303     88.430  0.0794    97.286  375.30
  61   0.4046     89.440  0.0795    97.312  381.57
  62   0.4240     89.150  0.0775    97.362  387.81
  63   0.4221     89.120  0.0731    97.546  394.01
  64   0.4764     87.660  0.0749    97.498  400.22
  65   0.3925     89.230  0.0737    97.518  406.53
  66   0.4185     89.100  0.0697    97.602  412.73
  67   0.3748     90.240  0.0743    97.478  418.97
  68   0.4032     89.250  0.0722    97.546  425.20
  69   0.3976     89.630  0.0688    97.644  431.42
  70   0.4217     89.200  0.0684    97.698  437.64
  71   0.4033     89.370  0.0675    97.756  443.93
  72   0.3796     90.350  0.0698    97.654  450.20
  73   0.3967     89.560  0.0661    97.724  456.41
  74   0.4519     88.590  0.0679    97.710  462.59
  75   0.4665     88.220  0.0650    97.794  468.82
  76   0.4422     88.780  0.0668    97.762  475.02
  77   0.4432     88.800  0.0635    97.856  481.31
  78   0.3977     89.600  0.0637    97.888  487.55
  79   0.4652     88.140  0.0657    97.778  493.79
  80   0.3905     89.890  0.0659    97.776  499.99
  81   0.4253     89.310  0.0603    98.002  506.22
  82   0.4818     87.860  0.0600    97.940  512.51
  83   0.3841     90.370  0.0632    97.830  518.74
  84   0.5064     87.230  0.0582    98.050  524.92
  85   0.4251     89.400  0.0625    97.872  531.12
  86   0.4193     89.280  0.0635    97.834  537.33
  87   0.3686     90.220  0.0584    98.058  543.58
  88   0.4210     88.640  0.0605    97.966  549.80
  89   0.3854     90.130  0.0591    98.024  555.98
  90   0.3980     89.730  0.0598    97.994  562.18
