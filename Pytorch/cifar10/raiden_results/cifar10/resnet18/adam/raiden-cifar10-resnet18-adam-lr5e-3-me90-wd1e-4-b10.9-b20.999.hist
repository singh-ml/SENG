Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6436     38.860  1.7978    34.304  7.67
   2   1.2851     54.760  1.3280    51.628  13.81
   3   1.1067     60.660  1.0885    60.992  20.04
   4   1.5579     53.780  0.9187    67.414  26.21
   5   0.8661     69.920  0.7961    71.938  32.34
   6   1.1968     62.930  0.6884    76.006  38.51
   7   0.7183     75.960  0.6244    78.258  44.66
   8   0.6028     79.430  0.5783    80.070  50.81
   9   0.6801     77.310  0.5429    81.368  56.95
  10   0.6600     77.140  0.5148    82.414  63.09
  11   0.5509     81.300  0.4930    83.132  69.27
  12   0.5882     80.760  0.4716    83.746  75.43
  13   0.6228     78.540  0.4595    84.208  81.57
  14   0.6599     77.130  0.4473    84.698  87.71
  15   0.5820     81.230  0.4330    85.214  93.91
  16   0.5657     81.170  0.4216    85.420  100.05
  17   0.5833     80.630  0.4054    86.210  106.18
  18   0.5359     82.470  0.4081    86.000  112.32
  19   0.5761     80.750  0.3938    86.404  118.48
  20   0.6141     80.100  0.3898    86.612  124.63
  21   0.4651     84.790  0.3775    87.088  130.86
  22   0.4954     83.790  0.3776    86.980  137.00
  23   0.5598     82.600  0.3694    87.216  143.18
  24   0.5032     83.110  0.3647    87.428  149.36
  25   0.4459     85.020  0.3623    87.622  155.49
  26   0.5042     83.580  0.3541    87.862  161.62
  27   0.5036     83.250  0.3511    87.962  167.76
  28   0.4717     84.550  0.3476    88.116  173.92
  29   0.4271     85.050  0.3518    87.870  180.06
  30   0.4537     84.910  0.3456    88.058  186.21
  31   0.4401     85.660  0.3359    88.292  192.34
  32   0.5300     83.420  0.3363    88.510  198.57
  33   0.4711     84.350  0.3328    88.532  204.69
  34   0.4719     84.630  0.3330    88.530  210.89
  35   0.4226     85.660  0.3297    88.672  217.03
  36   0.6096     81.020  0.3270    88.772  223.19
  37   0.4424     85.570  0.3232    88.940  229.36
  38   0.4428     85.680  0.3246    88.808  235.58
  39   0.4577     84.700  0.3193    88.866  241.75
  40   0.4222     85.750  0.3182    89.114  247.89
  41   0.5568     82.410  0.3201    89.062  254.06
  42   0.5774     82.120  0.3128    89.212  260.22
  43   0.5365     82.840  0.3153    89.074  266.40
  44   0.4819     84.470  0.3095    89.428  272.60
  45   0.4001     86.380  0.3152    89.088  278.80
  46   0.5117     83.870  0.3030    89.530  284.94
  47   0.4569     85.250  0.3081    89.288  291.08
  48   0.4572     84.910  0.3042    89.566  297.24
  49   0.4140     86.770  0.3040    89.468  303.37
  50   0.4876     84.620  0.3075    89.308  309.58
  51   0.4439     85.590  0.3046    89.642  315.75
  52   0.4378     85.490  0.2974    89.640  321.89
  53   0.4327     86.290  0.2985    89.796  328.04
  54   0.4488     85.410  0.2985    89.738  334.20
  55   0.5602     82.440  0.3012    89.560  340.34
  56   0.5481     82.910  0.2934    89.878  346.57
  57   0.5169     83.200  0.2974    89.684  352.74
  58   0.5302     83.390  0.2963    89.840  358.92
  59   0.4590     84.940  0.2944    89.776  365.08
  60   0.5131     83.640  0.2900    90.040  371.28
  61   0.4316     85.770  0.2903    89.868  377.53
  62   0.4394     86.130  0.2928    89.916  383.67
  63   0.4393     85.650  0.2855    90.222  389.81
  64   0.5600     82.540  0.2894    90.000  395.94
  65   0.4119     86.160  0.2924    89.910  402.14
  66   0.5469     82.460  0.2908    90.072  408.29
  67   0.5428     82.740  0.2904    90.140  414.54
  68   0.3864     86.980  0.2894    89.980  420.72
  69   0.4685     84.790  0.2817    90.400  426.89
  70   0.4265     85.820  0.2918    89.900  433.08
  71   0.3728     87.900  0.2810    90.378  439.26
  72   0.4019     87.130  0.2821    90.264  445.49
  73   0.5316     83.050  0.2840    90.176  451.68
  74   0.4370     85.760  0.2822    90.232  457.83
  75   0.4113     86.330  0.2838    90.242  463.99
  76   0.4872     84.010  0.2852    90.102  470.16
  77   0.5862     82.790  0.2832    90.134  476.37
  78   0.4457     86.030  0.2789    90.418  482.54
  79   0.4513     86.160  0.2766    90.578  488.68
  80   0.4171     86.390  0.2838    90.208  494.82
  81   0.4524     85.310  0.2776    90.434  500.96
  82   0.4131     86.650  0.2764    90.572  507.11
  83   0.4804     84.600  0.2761    90.370  513.28
  84   0.4156     86.590  0.2785    90.482  519.50
  85   0.6103     81.910  0.2748    90.500  525.66
  86   0.3760     87.890  0.2793    90.264  531.82
  87   0.5490     81.960  0.2715    90.620  537.96
  88   0.4362     86.070  0.2739    90.480  544.16
  89   0.4215     86.720  0.2736    90.492  550.31
  90   0.4392     85.920  0.2786    90.382  556.57
