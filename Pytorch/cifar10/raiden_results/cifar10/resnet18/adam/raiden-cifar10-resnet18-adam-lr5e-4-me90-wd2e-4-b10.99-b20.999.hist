Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2995     53.030  1.5159    43.766  7.63
   2   1.0355     63.370  1.1248    59.176  13.73
   3   0.8846     68.740  0.9128    67.544  19.91
   4   0.7630     73.590  0.7705    72.702  26.00
   5   0.6716     77.180  0.6614    76.874  32.11
   6   0.5750     80.170  0.5809    79.890  38.21
   7   0.5864     79.930  0.5307    81.584  44.32
   8   0.6072     79.950  0.4915    82.916  50.44
   9   0.5428     81.170  0.4537    84.102  56.62
  10   0.4871     83.450  0.4260    85.246  62.77
  11   0.4539     84.620  0.3947    86.246  68.85
  12   0.5119     83.170  0.3610    87.440  74.94
  13   0.4747     84.620  0.3404    88.298  81.02
  14   0.4652     84.330  0.3303    88.600  87.16
  15   0.4555     85.100  0.3078    89.426  93.25
  16   0.4421     85.850  0.3009    89.504  99.34
  17   0.3929     87.330  0.2759    90.528  105.50
  18   0.4305     86.210  0.2592    91.036  111.64
  19   0.3978     87.620  0.2356    91.864  117.74
  20   0.3631     87.990  0.2344    91.886  123.93
  21   0.4405     86.460  0.2267    92.154  130.03
  22   0.3713     87.640  0.2215    92.338  136.12
  23   0.4033     87.210  0.2098    92.786  142.23
  24   0.4372     87.120  0.1998    93.040  148.34
  25   0.3627     89.030  0.1948    93.300  154.55
  26   0.4069     88.090  0.1855    93.568  160.66
  27   0.3954     88.550  0.1724    94.064  166.77
  28   0.3466     89.440  0.1726    94.046  172.89
  29   0.3832     88.940  0.1676    94.206  179.03
  30   0.3622     89.270  0.1619    94.430  185.17
  31   0.3788     89.190  0.1480    94.938  191.25
  32   0.4135     88.440  0.1499    94.874  197.35
  33   0.4035     88.360  0.1482    94.876  203.48
  34   0.3798     89.090  0.1414    95.158  209.60
  35   0.3766     89.960  0.1308    95.548  215.66
  36   0.3523     89.910  0.1255    95.638  221.80
  37   0.3428     90.500  0.1240    95.770  227.96
  38   0.3842     89.440  0.1169    96.024  234.04
  39   0.3787     88.770  0.1208    95.882  240.12
  40   0.3415     90.490  0.1183    95.884  246.21
  41   0.3582     90.060  0.1224    95.788  252.29
  42   0.3425     90.420  0.1132    96.126  258.42
  43   0.3406     90.860  0.1066    96.216  264.54
  44   0.3851     89.570  0.1027    96.424  270.65
  45   0.3711     90.110  0.1060    96.224  276.76
  46   0.3429     90.430  0.1094    96.174  282.87
  47   0.3615     90.620  0.1042    96.530  288.95
  48   0.3731     90.040  0.0954    96.744  295.18
  49   0.3641     90.350  0.0928    96.806  301.28
  50   0.3400     90.810  0.0952    96.740  307.37
  51   0.3498     90.690  0.0866    96.994  313.49
  52   0.3361     91.040  0.0902    96.854  319.57
  53   0.3945     90.270  0.0908    96.898  325.66
  54   0.3861     89.950  0.0886    96.928  331.83
  55   0.3729     90.360  0.0900    96.922  337.90
  56   0.3494     90.720  0.0926    96.816  344.02
  57   0.3651     90.370  0.0861    97.122  350.10
  58   0.3540     91.050  0.0801    97.148  356.20
  59   0.3636     90.480  0.0837    97.136  362.28
  60   0.3370     91.420  0.0794    97.230  368.49
  61   0.3681     90.990  0.0799    97.186  374.62
  62   0.3495     90.820  0.0755    97.422  380.74
  63   0.3631     90.290  0.0886    96.958  386.83
  64   0.3271     91.370  0.0766    97.374  392.92
  65   0.3503     91.020  0.0790    97.336  399.12
  66   0.3575     91.110  0.0745    97.428  405.23
  67   0.3538     90.780  0.0732    97.486  411.35
  68   0.3235     91.340  0.0776    97.398  417.41
  69   0.3260     91.330  0.0754    97.362  423.50
  70   0.3173     91.890  0.0698    97.652  429.70
  71   0.3409     91.250  0.0703    97.614  435.78
  72   0.3639     91.050  0.0749    97.456  441.87
  73   0.3262     91.360  0.0741    97.570  447.99
  74   0.3467     91.250  0.0719    97.548  454.08
  75   0.3411     91.420  0.0727    97.496  460.17
  76   0.4318     90.490  0.0654    97.726  466.35
  77   0.3467     91.140  0.0711    97.552  472.43
  78   0.3304     91.580  0.0673    97.718  478.56
  79   0.4124     90.120  0.0651    97.774  484.65
  80   0.3509     90.980  0.0727    97.502  490.73
  81   0.3749     90.870  0.0678    97.598  496.90
  82   0.3641     91.100  0.0680    97.600  503.03
  83   0.3341     91.660  0.0665    97.800  509.13
  84   0.3489     91.250  0.0649    97.826  515.24
  85   0.3613     91.200  0.0654    97.746  521.32
  86   0.3541     91.210  0.0710    97.578  527.42
  87   0.3672     91.620  0.0651    97.806  533.56
  88   0.3510     91.150  0.0627    97.960  539.66
  89   0.3424     91.290  0.0625    97.866  545.82
  90   0.3810     90.890  0.0653    97.704  551.92
