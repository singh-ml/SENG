Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9356     29.070  2.2950    17.512  7.63
   2   1.5814     41.250  1.7304    35.996  13.67
   3   1.4411     47.410  1.5036    44.540  19.76
   4   1.2560     53.710  1.3155    52.036  25.82
   5   1.2887     57.480  1.1398    59.202  31.94
   6   0.9646     65.220  1.0091    63.882  38.00
   7   0.9003     68.570  0.9241    66.998  44.08
   8   0.8407     70.630  0.8609    69.344  50.14
   9   0.8082     71.930  0.8057    71.478  56.21
  10   0.8083     71.790  0.7573    73.334  62.27
  11   0.7586     74.590  0.7100    75.210  68.38
  12   0.7785     73.880  0.6758    76.468  74.42
  13   0.6723     77.030  0.6449    77.338  80.46
  14   0.7164     75.410  0.6135    78.664  86.50
  15   0.6463     77.680  0.6076    79.134  92.54
  16   0.6265     78.280  0.5947    79.378  98.71
  17   0.7079     76.610  0.5786    79.772  104.76
  18   0.7328     76.090  0.5659    80.286  110.82
  19   0.6518     77.510  0.5629    80.392  116.89
  20   0.6024     78.910  0.5605    80.654  122.92
  21   0.6315     78.940  0.5328    81.526  129.05
  22   0.6270     78.690  0.5340    81.344  135.10
  23   0.5778     80.550  0.5297    81.508  141.14
  24   0.5921     79.800  0.5238    82.050  147.19
  25   0.5824     80.370  0.5182    81.948  153.24
  26   0.5912     79.470  0.5100    82.294  159.29
  27   0.5619     80.790  0.5017    82.512  165.39
  28   0.5837     79.700  0.5110    82.398  171.46
  29   0.5617     80.550  0.5003    82.700  177.52
  30   0.5656     81.040  0.4975    82.778  183.60
  31   0.6047     79.820  0.4983    82.744  189.64
  32   0.5877     80.890  0.4850    83.234  195.72
  33   0.5582     80.890  0.4856    82.950  201.85
  34   0.5596     80.570  0.4812    83.232  207.90
  35   0.5405     81.210  0.4773    83.406  213.94
  36   0.5098     82.290  0.4769    83.564  220.01
  37   0.5454     81.660  0.4771    83.340  226.04
  38   0.5534     81.640  0.4756    83.384  232.09
  39   0.5388     81.250  0.4725    83.612  238.23
  40   0.5504     81.000  0.4731    83.692  244.28
  41   0.5211     82.520  0.4711    83.694  250.34
  42   0.6123     79.610  0.4672    83.730  256.41
  43   0.5378     81.610  0.4629    84.010  262.44
  44   0.5296     82.320  0.4576    84.222  268.47
  45   0.5171     82.200  0.4625    83.920  274.59
  46   0.5982     79.630  0.4617    83.986  280.62
  47   0.5521     81.580  0.4535    84.202  286.66
  48   0.5314     81.770  0.4634    83.960  292.72
  49   0.5062     82.840  0.4547    84.248  298.77
  50   0.5128     82.220  0.4529    84.474  304.80
  51   0.5376     81.810  0.4517    84.248  310.89
  52   0.5407     81.520  0.4478    84.304  316.94
  53   0.5113     82.370  0.4492    84.416  322.98
  54   0.5005     83.140  0.4524    84.412  329.02
  55   0.5314     82.180  0.4545    84.324  335.08
  56   0.5264     82.290  0.4464    84.544  341.18
  57   0.5032     82.920  0.4447    84.616  347.23
  58   0.5330     82.360  0.4498    84.444  353.26
  59   0.5424     81.480  0.4417    84.626  359.30
  60   0.4997     83.010  0.4403    84.568  365.33
  61   0.5956     80.350  0.4478    84.452  371.39
  62   0.5463     81.450  0.4413    84.700  377.48
  63   0.5193     82.330  0.4407    84.690  383.57
  64   0.6234     80.400  0.4432    84.704  389.64
  65   0.5172     82.640  0.4438    84.664  395.69
  66   0.6357     78.530  0.4352    84.784  401.76
  67   0.5597     81.280  0.4455    84.630  407.85
  68   0.4835     83.960  0.4439    84.578  413.89
  69   0.4915     83.810  0.4343    84.994  419.93
  70   0.5117     83.070  0.4384    84.818  425.98
  71   0.5710     80.460  0.4383    84.894  432.06
  72   0.5623     81.220  0.4389    84.684  438.12
  73   0.5065     82.590  0.4346    84.882  444.30
  74   0.5250     82.860  0.4394    84.836  450.36
  75   0.5184     82.580  0.4415    84.952  456.42
  76   0.5464     80.890  0.4398    84.950  462.46
  77   0.5054     83.190  0.4325    85.208  468.53
  78   0.5707     80.530  0.4387    84.716  474.64
  79   0.5061     82.620  0.4292    85.148  480.70
  80   0.5315     82.600  0.4308    85.104  486.75
  81   0.6382     79.620  0.4254    85.146  492.79
  82   0.4878     83.520  0.4302    85.140  498.85
  83   0.5014     83.140  0.4327    85.248  504.92
  84   0.5338     82.470  0.4258    85.232  511.09
  85   0.5049     82.780  0.4358    84.914  517.14
