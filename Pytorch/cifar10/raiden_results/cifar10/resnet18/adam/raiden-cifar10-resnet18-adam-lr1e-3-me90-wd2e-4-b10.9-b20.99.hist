Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4840     52.890  1.3820    49.484  7.66
   2   1.6640     54.460  0.9063    67.800  13.72
   3   0.7538     74.810  0.7264    74.604  19.78
   4   0.7531     74.810  0.6185    78.712  25.88
   5   0.9462     71.400  0.5549    81.082  32.08
   6   0.6619     78.460  0.4878    83.124  38.16
   7   0.7102     76.280  0.4535    84.566  44.21
   8   0.6434     80.200  0.4156    85.866  50.28
   9   0.6228     80.280  0.3960    86.502  56.34
  10   0.6789     77.810  0.3681    87.372  62.42
  11   0.6535     78.700  0.3499    88.030  68.57
  12   0.6840     79.780  0.3341    88.654  74.62
  13   0.4138     86.280  0.3159    89.216  80.68
  14   0.5067     84.170  0.2991    89.650  86.75
  15   0.5329     83.340  0.2860    90.168  92.83
  16   0.4406     85.510  0.2742    90.536  98.90
  17   0.5626     83.820  0.2653    90.934  105.07
  18   0.4099     87.120  0.2546    91.336  111.15
  19   0.3863     87.950  0.2476    91.544  117.23
  20   0.3660     88.120  0.2356    91.942  123.31
  21   0.4402     86.810  0.2275    92.316  129.36
  22   0.4370     86.710  0.2198    92.438  135.44
  23   0.4025     87.790  0.2142    92.618  141.58
  24   0.5890     82.530  0.2118    92.586  147.67
  25   0.4239     87.580  0.1981    93.148  153.76
  26   0.3741     88.470  0.1956    93.214  159.83
  27   0.4043     87.830  0.1890    93.428  165.96
  28   0.3774     88.440  0.1884    93.610  172.02
  29   0.3757     88.430  0.1782    93.748  178.07
  30   0.3861     88.590  0.1803    93.772  184.20
  31   0.4343     87.170  0.1709    94.002  190.27
  32   0.4506     87.420  0.1690    94.142  196.33
  33   0.3896     88.520  0.1680    94.094  202.42
  34   0.3853     88.760  0.1635    94.302  208.50
  35   0.4159     88.380  0.1566    94.570  214.57
  36   0.3920     88.530  0.1553    94.716  220.65
  37   0.3619     88.990  0.1506    94.832  226.72
  38   0.3788     88.880  0.1528    94.750  232.79
  39   0.3790     89.050  0.1459    94.890  238.87
  40   0.3618     89.800  0.1438    94.946  244.93
  41   0.3439     89.740  0.1425    95.080  251.10
  42   0.3617     89.580  0.1474    94.876  257.16
  43   0.3443     90.050  0.1424    95.040  263.22
  44   0.3695     89.190  0.1370    95.276  269.30
  45   0.4128     88.330  0.1387    95.214  275.36
  46   0.3843     89.130  0.1357    95.402  281.42
  47   0.4541     87.810  0.1313    95.608  287.55
  48   0.3662     89.440  0.1311    95.542  293.62
  49   0.4101     88.970  0.1306    95.538  299.69
  50   0.3810     89.410  0.1297    95.508  305.77
  51   0.4101     88.780  0.1238    95.746  311.84
  52   0.3369     90.410  0.1290    95.594  318.00
  53   0.4171     88.220  0.1253    95.798  324.11
  54   0.3907     89.960  0.1197    95.852  330.20
  55   0.3333     90.690  0.1255    95.618  336.25
  56   0.3929     88.990  0.1249    95.618  342.33
  57   0.4163     89.060  0.1189    95.846  348.40
  58   0.4148     89.000  0.1163    96.034  354.49
  59   0.3864     89.290  0.1178    95.920  360.58
  60   0.3445     90.200  0.1180    95.946  366.64
  61   0.3661     89.920  0.1132    96.084  372.73
  62   0.3365     91.000  0.1173    95.892  378.80
  63   0.3671     90.360  0.1120    96.144  384.87
  64   0.3802     90.180  0.1158    96.020  390.94
  65   0.4201     88.930  0.1116    96.110  397.07
  66   0.4055     89.470  0.1139    96.144  403.12
  67   0.3488     90.390  0.1112    96.178  409.18
  68   0.3893     89.810  0.1088    96.188  415.28
  69   0.3932     89.790  0.1103    96.122  421.37
  70   0.3913     89.500  0.1111    96.170  427.45
  71   0.3256     91.110  0.1095    96.244  433.56
  72   0.3713     90.090  0.1067    96.294  439.63
  73   0.3844     89.650  0.1096    96.224  445.72
  74   0.4103     89.110  0.1034    96.466  451.78
  75   0.3461     90.540  0.1107    96.238  457.86
  76   0.3673     89.900  0.1085    96.208  463.94
  77   0.3833     90.040  0.1064    96.370  470.11
  78   0.3953     89.570  0.1075    96.324  476.18
  79   0.4699     87.770  0.1052    96.414  482.24
  80   0.3826     89.470  0.1015    96.452  488.32
  81   0.4179     88.560  0.1024    96.452  494.38
  82   0.4361     88.810  0.1066    96.356  500.56
  83   0.3670     90.400  0.1027    96.412  506.67
  84   0.3752     90.110  0.1016    96.506  512.76
  85   0.3926     89.870  0.1022    96.460  518.83
  86   0.3698     90.140  0.0975    96.710  524.91
  87   0.3889     90.030  0.1029    96.384  531.05
  88   0.3893     90.070  0.1011    96.498  537.18
  89   0.3498     90.580  0.0989    96.580  543.24
  90   0.3537     89.970  0.1014    96.454  549.33
