Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4027     49.580  1.5246    43.794  7.86
   2   1.0845     61.750  1.1712    57.360  14.06
   3   0.9718     65.650  0.9820    64.776  20.08
   4   0.8050     71.980  0.8459    70.004  26.09
   5   0.8405     72.410  0.7198    74.870  32.11
   6   0.7168     75.710  0.6527    77.430  38.15
   7   0.6689     77.880  0.5976    79.552  44.16
   8   0.6562     77.810  0.5485    81.040  50.22
   9   0.5237     82.340  0.5070    82.812  56.25
  10   0.5282     81.900  0.4784    83.742  62.28
  11   0.5482     81.780  0.4489    84.716  68.34
  12   0.4951     83.780  0.4118    85.824  74.42
  13   0.4810     83.830  0.3957    86.458  80.51
  14   0.4661     84.720  0.3733    87.296  86.57
  15   0.4244     86.040  0.3553    88.030  92.58
  16   0.5096     83.420  0.3346    88.556  98.64
  17   0.4258     85.890  0.3181    89.212  104.72
  18   0.4257     86.030  0.3133    89.288  110.76
  19   0.4565     85.360  0.3036    89.680  116.84
  20   0.3903     87.460  0.2956    89.770  122.90
  21   0.3898     87.240  0.2861    90.168  128.93
  22   0.3947     87.640  0.2743    90.680  134.97
  23   0.3980     86.920  0.2726    90.698  141.00
  24   0.4104     86.300  0.2698    90.824  147.11
  25   0.3907     87.430  0.2514    91.436  153.12
  26   0.3926     87.550  0.2537    91.372  159.15
  27   0.3689     88.050  0.2461    91.704  165.24
  28   0.3508     88.530  0.2465    91.776  171.29
  29   0.3785     88.290  0.2410    91.876  177.33
  30   0.3579     88.950  0.2239    92.316  183.42
  31   0.3772     87.830  0.2182    92.612  189.47
  32   0.3900     88.170  0.2243    92.312  195.50
  33   0.3439     88.980  0.2167    92.616  201.56
  34   0.3558     89.050  0.2087    92.798  207.57
  35   0.3359     89.340  0.2068    92.958  213.65
  36   0.3695     88.320  0.2042    92.932  219.80
  37   0.3697     88.620  0.2086    92.914  225.82
  38   0.3470     89.480  0.2019    93.226  231.89
  39   0.3571     88.960  0.1923    93.388  237.91
  40   0.3445     89.760  0.1974    93.132  243.95
  41   0.3294     89.820  0.1998    93.176  250.04
  42   0.3584     89.380  0.1862    93.680  256.05
  43   0.3467     89.580  0.1834    93.664  262.07
  44   0.3340     89.710  0.1852    93.586  268.11
  45   0.3389     89.710  0.1763    93.986  274.15
  46   0.3243     89.900  0.1820    93.758  280.29
  47   0.3492     89.200  0.1798    93.880  286.33
  48   0.3533     89.310  0.1814    93.856  292.35
  49   0.3746     88.840  0.1777    94.030  298.39
  50   0.3271     90.080  0.1769    94.032  304.42
  51   0.3319     90.390  0.1672    94.290  310.44
  52   0.3584     88.760  0.1752    94.102  316.58
  53   0.3263     90.290  0.1723    94.114  322.63
  54   0.3803     88.900  0.1691    94.260  328.68
  55   0.3559     89.590  0.1748    94.118  334.75
  56   0.3454     89.910  0.1643    94.374  340.79
  57   0.3616     89.420  0.1618    94.524  346.86
  58   0.3518     89.930  0.1662    94.318  352.89
  59   0.3444     89.590  0.1663    94.274  358.96
  60   0.3184     90.200  0.1638    94.472  364.99
  61   0.3213     90.360  0.1580    94.686  371.05
  62   0.3601     89.340  0.1569    94.662  377.08
  63   0.3716     89.160  0.1648    94.428  383.21
  64   0.3425     90.070  0.1606    94.456  389.27
  65   0.3605     89.510  0.1585    94.516  395.38
  66   0.3289     90.060  0.1618    94.444  401.41
  67   0.3362     89.980  0.1625    94.468  407.44
  68   0.3245     90.460  0.1552    94.796  413.54
  69   0.3190     90.590  0.1546    94.752  419.56
  70   0.3389     90.270  0.1531    94.734  425.61
  71   0.3519     89.500  0.1469    94.852  431.63
  72   0.3181     90.540  0.1498    94.888  437.67
  73   0.3917     88.980  0.1515    94.812  443.69
  74   0.3556     89.470  0.1496    94.982  449.74
  75   0.3252     90.290  0.1491    94.844  455.84
  76   0.3322     89.580  0.1542    94.790  461.85
  77   0.3215     90.570  0.1531    94.744  467.86
  78   0.3440     90.230  0.1440    95.030  473.93
  79   0.3413     89.480  0.1445    95.006  479.98
  80   0.3496     89.960  0.1436    95.014  486.04
  81   0.3667     89.570  0.1468    94.880  492.09
  82   0.3352     89.910  0.1488    94.926  498.15
  83   0.3295     90.280  0.1422    95.136  504.24
  84   0.3668     89.260  0.1424    95.182  510.28
  85   0.3108     90.540  0.1416    95.088  516.31
