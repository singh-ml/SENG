Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2583     54.140  1.5495    42.818  7.85
   2   1.1981     57.970  1.1776    57.424  14.05
   3   0.9582     66.680  0.9726    65.390  20.14
   4   0.8566     69.760  0.8427    70.208  26.22
   5   0.7729     73.600  0.7368    74.164  32.28
   6   0.8064     72.280  0.6552    77.366  38.37
   7   0.7079     76.720  0.5948    79.386  44.43
   8   0.6445     78.970  0.5533    81.064  50.58
   9   0.6384     79.250  0.5098    82.610  56.61
  10   0.5314     82.230  0.4705    83.854  62.67
  11   0.5255     82.450  0.4504    84.652  68.75
  12   0.5087     83.040  0.4278    85.434  74.80
  13   0.4873     83.720  0.4017    86.516  80.92
  14   0.5154     83.270  0.3899    86.958  86.98
  15   0.5358     82.880  0.3649    87.724  93.04
  16   0.4584     85.200  0.3535    87.910  99.15
  17   0.4154     86.040  0.3377    88.354  105.23
  18   0.4244     86.070  0.3237    88.922  111.28
  19   0.3992     86.970  0.3145    89.284  117.43
  20   0.4662     84.630  0.3056    89.702  123.51
  21   0.3621     87.950  0.2970    89.856  129.61
  22   0.3930     87.370  0.2829    90.368  135.67
  23   0.3748     87.550  0.2786    90.576  141.72
  24   0.3873     87.220  0.2731    90.822  147.82
  25   0.3567     88.200  0.2589    91.210  153.92
  26   0.3817     87.200  0.2596    91.028  159.98
  27   0.3784     87.770  0.2539    91.374  166.08
  28   0.3511     88.780  0.2489    91.416  172.13
  29   0.3672     88.090  0.2443    91.652  178.21
  30   0.3537     88.230  0.2414    91.906  184.35
  31   0.3617     88.300  0.2336    91.978  190.42
  32   0.3667     88.590  0.2313    92.062  196.47
  33   0.3605     88.520  0.2315    92.022  202.58
  34   0.3357     89.310  0.2197    92.630  208.65
  35   0.3253     89.540  0.2128    92.682  214.76
  36   0.3393     89.260  0.2087    92.808  220.85
  37   0.3719     88.460  0.2059    92.914  226.97
  38   0.3311     89.330  0.2112    92.808  233.04
  39   0.3403     89.580  0.2052    93.004  239.14
  40   0.3199     89.860  0.2071    92.934  245.19
  41   0.3474     89.050  0.1998    93.184  251.30
  42   0.3394     89.080  0.1928    93.414  257.41
  43   0.3770     88.550  0.1988    93.088  263.49
  44   0.3578     88.910  0.1960    93.310  269.58
  45   0.3574     89.180  0.1913    93.424  275.69
  46   0.3628     89.670  0.1901    93.488  281.84
  47   0.3267     89.510  0.1864    93.554  287.94
  48   0.3357     89.650  0.1836    93.784  294.02
  49   0.3647     89.220  0.1753    93.884  300.14
  50   0.3547     89.340  0.1796    93.770  306.20
  51   0.3390     89.590  0.1760    94.010  312.34
  52   0.3504     89.430  0.1669    94.210  318.41
  53   0.3688     88.780  0.1728    94.004  324.47
  54   0.3158     90.130  0.1796    93.848  330.58
  55   0.3223     90.240  0.1645    94.298  336.66
  56   0.3575     89.890  0.1693    94.256  342.71
  57   0.3518     89.540  0.1689    94.272  348.86
  58   0.3489     89.530  0.1736    94.078  354.95
  59   0.3436     90.040  0.1641    94.412  361.01
  60   0.3462     89.950  0.1701    94.120  367.13
  61   0.3832     88.760  0.1667    94.346  373.16
  62   0.3444     90.080  0.1661    94.300  379.30
  63   0.3120     90.260  0.1637    94.516  385.37
  64   0.3416     89.480  0.1594    94.480  391.46
  65   0.3362     89.330  0.1607    94.494  397.58
  66   0.3134     90.870  0.1608    94.478  403.65
  67   0.3482     89.640  0.1608    94.564  409.74
  68   0.3209     90.410  0.1560    94.680  415.90
  69   0.3592     89.360  0.1666    94.376  421.95
  70   0.3476     89.880  0.1526    94.828  428.00
  71   0.3365     90.340  0.1542    94.786  434.10
  72   0.3400     90.100  0.1505    94.810  440.18
  73   0.3263     90.510  0.1544    94.678  446.24
  74   0.3155     90.330  0.1506    94.870  452.40
  75   0.3382     89.370  0.1504    94.910  458.47
  76   0.3531     89.850  0.1535    94.738  464.55
  77   0.3156     90.260  0.1536    94.832  470.61
  78   0.3381     90.230  0.1497    94.886  476.72
  79   0.3198     90.430  0.1494    94.926  482.80
  80   0.3551     89.810  0.1533    94.798  488.95
  81   0.3336     90.080  0.1491    94.856  495.03
  82   0.3390     90.190  0.1534    94.786  501.07
  83   0.3283     90.330  0.1512    94.816  507.13
  84   0.3372     90.100  0.1442    95.070  513.22
  85   0.3276     90.330  0.1432    95.054  519.39
