Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3067     52.260  1.5372    43.292  7.67
   2   1.0437     62.710  1.1587    58.056  13.80
   3   0.9208     67.290  0.9670    65.438  19.82
   4   0.7672     72.650  0.8286    70.594  25.91
   5   0.6868     75.930  0.7293    74.272  31.97
   6   0.6619     77.100  0.6434    77.516  38.00
   7   0.5976     80.040  0.5862    79.568  44.04
   8   0.5738     80.820  0.5242    81.632  50.17
   9   0.5541     81.160  0.4831    83.154  56.18
  10   0.5745     80.540  0.4564    84.130  62.24
  11   0.5178     82.230  0.4250    85.128  68.28
  12   0.4973     83.410  0.3948    86.144  74.33
  13   0.4980     83.220  0.3647    87.174  80.36
  14   0.5126     82.780  0.3546    87.612  86.47
  15   0.4473     85.050  0.3275    88.646  92.49
  16   0.4589     84.940  0.3074    89.200  98.55
  17   0.4690     85.220  0.2996    89.566  104.60
  18   0.4281     85.950  0.2767    90.332  110.66
  19   0.4601     85.460  0.2550    90.976  116.69
  20   0.4423     85.680  0.2460    91.376  122.84
  21   0.4071     86.880  0.2313    91.980  128.88
  22   0.4328     86.310  0.2203    92.292  134.91
  23   0.4165     87.150  0.2153    92.432  140.93
  24   0.4626     86.260  0.1937    93.278  146.99
  25   0.4723     85.930  0.1860    93.362  153.05
  26   0.4219     87.160  0.1869    93.416  159.22
  27   0.4243     87.280  0.1713    94.044  165.28
  28   0.4505     86.500  0.1637    94.142  171.35
  29   0.4141     87.580  0.1664    94.128  177.39
  30   0.3978     88.890  0.1471    94.874  183.41
  31   0.4525     86.960  0.1468    94.806  189.43
  32   0.4102     88.110  0.1479    94.782  195.55
  33   0.4032     88.370  0.1399    95.036  201.58
  34   0.4049     88.130  0.1302    95.514  207.68
  35   0.4128     88.320  0.1243    95.626  213.71
  36   0.4063     88.590  0.1217    95.764  219.77
  37   0.4127     88.130  0.1132    96.044  225.80
  38   0.4654     86.880  0.1139    95.984  231.88
  39   0.4586     87.630  0.1160    96.016  237.94
  40   0.4032     89.160  0.1002    96.464  243.99
  41   0.4058     88.970  0.1021    96.390  250.04
  42   0.4408     88.580  0.1013    96.520  256.09
  43   0.4341     88.110  0.0976    96.610  262.23
  44   0.3844     89.640  0.1008    96.540  268.26
  45   0.4607     87.910  0.0966    96.580  274.29
  46   0.4079     89.040  0.0888    96.916  280.35
  47   0.4261     88.550  0.0938    96.692  286.38
  48   0.4061     89.130  0.0805    97.248  292.50
  49   0.4343     88.930  0.0773    97.346  298.54
  50   0.4433     88.670  0.0795    97.230  304.57
  51   0.4244     88.940  0.0752    97.358  310.62
  52   0.4134     89.280  0.0753    97.390  316.63
  53   0.3989     89.780  0.0777    97.260  322.65
  54   0.4502     88.380  0.0781    97.298  328.78
  55   0.4114     89.690  0.0657    97.766  334.82
  56   0.4372     89.000  0.0682    97.590  340.83
  57   0.4109     89.440  0.0698    97.606  346.85
  58   0.4394     88.990  0.0628    97.836  352.91
  59   0.4209     89.650  0.0681    97.564  359.00
  60   0.4233     88.930  0.0701    97.502  365.06
  61   0.4129     89.740  0.0656    97.714  371.09
  62   0.4110     89.610  0.0689    97.616  377.14
  63   0.4249     89.510  0.0636    97.736  383.15
  64   0.4444     89.110  0.0598    97.910  389.20
  65   0.4143     89.800  0.0599    97.900  395.31
  66   0.4172     89.600  0.0616    97.880  401.38
  67   0.4213     89.230  0.0618    97.794  407.42
  68   0.4254     89.750  0.0552    98.072  413.48
  69   0.4426     89.330  0.0574    98.012  419.50
  70   0.4244     89.620  0.0572    98.002  425.53
  71   0.4249     89.460  0.0552    98.166  431.61
  72   0.4149     89.930  0.0585    97.994  437.66
  73   0.3991     90.460  0.0521    98.252  443.70
  74   0.4261     89.690  0.0526    98.204  449.72
  75   0.4270     89.490  0.0543    98.148  455.74
  76   0.4161     89.820  0.0483    98.298  461.78
  77   0.4110     90.250  0.0507    98.270  467.83
  78   0.4538     89.280  0.0517    98.244  473.96
  79   0.4125     90.070  0.0551    98.096  480.03
  80   0.4439     89.830  0.0513    98.266  486.06
  81   0.4213     89.850  0.0488    98.370  492.09
  82   0.4916     88.280  0.0513    98.254  498.15
  83   0.4342     90.080  0.0532    98.206  504.22
  84   0.4247     90.310  0.0467    98.432  510.25
  85   0.4461     89.320  0.0499    98.320  516.31
