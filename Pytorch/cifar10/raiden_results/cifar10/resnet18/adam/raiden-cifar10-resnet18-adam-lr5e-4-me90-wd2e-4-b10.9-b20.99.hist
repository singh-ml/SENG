Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1045     60.640  1.3936    48.682  7.65
   2   0.8947     69.060  0.9407    66.482  13.71
   3   0.9426     68.600  0.7326    74.342  19.78
   4   0.7263     75.800  0.6288    77.958  25.96
   5   0.6803     78.250  0.5520    80.812  32.00
   6   0.5742     80.680  0.4962    82.838  38.06
   7   0.6129     80.640  0.4514    84.468  44.12
   8   0.6018     80.940  0.4168    85.676  50.20
   9   0.6903     78.540  0.3866    86.802  56.33
  10   0.4722     84.540  0.3604    87.660  62.36
  11   0.5295     83.030  0.3396    88.312  68.39
  12   0.4464     85.130  0.3211    88.862  74.43
  13   0.5362     83.040  0.2972    89.724  80.47
  14   0.4838     84.340  0.2792    90.470  86.50
  15   0.4775     84.600  0.2717    90.580  92.58
  16   0.4125     86.940  0.2576    91.112  98.62
  17   0.4651     86.310  0.2445    91.454  104.66
  18   0.4246     86.990  0.2329    91.962  110.71
  19   0.4578     86.720  0.2219    92.310  116.80
  20   0.6155     82.900  0.2123    92.710  122.88
  21   0.3896     87.700  0.2027    92.930  128.92
  22   0.4359     87.080  0.1975    93.222  134.98
  23   0.3524     89.230  0.1899    93.424  141.03
  24   0.5545     85.380  0.1734    93.918  147.08
  25   0.4587     86.920  0.1714    94.124  153.13
  26   0.3834     88.800  0.1668    94.264  159.19
  27   0.4607     87.680  0.1578    94.548  165.33
  28   0.4290     87.600  0.1557    94.584  171.36
  29   0.3969     88.600  0.1503    94.694  177.42
  30   0.3627     89.560  0.1423    95.200  183.46
  31   0.3504     89.300  0.1429    95.146  189.52
  32   0.3957     89.000  0.1362    95.232  195.58
  33   0.3530     89.750  0.1288    95.554  201.64
  34   0.4130     88.860  0.1314    95.436  207.80
  35   0.3879     88.970  0.1267    95.532  213.84
  36   0.4335     88.520  0.1212    95.792  219.90
  37   0.4341     88.750  0.1181    95.894  225.96
  38   0.3622     89.890  0.1193    95.888  231.99
  39   0.3865     89.680  0.1156    96.052  238.02
  40   0.3655     89.760  0.1143    95.978  244.15
  41   0.3920     89.370  0.1098    96.196  250.22
  42   0.3657     90.060  0.1097    96.146  256.26
  43   0.4202     88.990  0.1033    96.392  262.30
  44   0.3605     90.170  0.1043    96.374  268.37
  45   0.4092     88.870  0.1050    96.394  274.53
  46   0.3687     89.500  0.1007    96.498  280.59
  47   0.3822     89.700  0.0984    96.536  286.64
  48   0.3470     90.820  0.0948    96.732  292.69
  49   0.3940     89.320  0.0964    96.766  298.74
  50   0.3957     89.900  0.0928    96.820  304.78
  51   0.3696     90.500  0.0893    96.944  310.93
  52   0.3429     90.620  0.0898    96.910  316.95
  53   0.3355     90.830  0.0886    96.938  323.00
  54   0.3896     89.970  0.0861    96.990  329.07
  55   0.4378     89.110  0.0883    96.966  335.15
  56   0.4549     88.930  0.0819    97.208  341.24
  57   0.4058     89.660  0.0879    96.974  347.30
  58   0.3782     90.300  0.0835    97.104  353.35
  59   0.4075     89.480  0.0777    97.316  359.44
  60   0.3881     89.990  0.0802    97.238  365.49
  61   0.3413     90.930  0.0829    97.166  371.53
  62   0.3742     90.470  0.0816    97.276  377.59
  63   0.3646     90.450  0.0782    97.392  383.76
  64   0.3771     90.230  0.0778    97.338  389.84
  65   0.4413     88.770  0.0757    97.512  395.87
  66   0.3459     90.750  0.0788    97.350  401.93
  67   0.4006     89.460  0.0758    97.436  407.99
  68   0.3885     89.790  0.0768    97.328  414.03
  69   0.4137     89.700  0.0745    97.410  420.11
  70   0.4459     88.920  0.0726    97.528  426.15
  71   0.3910     90.670  0.0732    97.402  432.20
  72   0.4449     88.990  0.0713    97.614  438.22
  73   0.3642     90.900  0.0710    97.578  444.28
  74   0.4498     89.130  0.0720    97.484  450.32
  75   0.3790     90.460  0.0677    97.702  456.47
  76   0.3863     90.740  0.0677    97.664  462.51
  77   0.3797     90.790  0.0700    97.616  468.58
  78   0.3621     90.750  0.0706    97.578  474.62
  79   0.3745     91.170  0.0692    97.620  480.66
  80   0.3606     91.430  0.0682    97.654  486.72
  81   0.4114     89.840  0.0688    97.582  492.84
  82   0.3702     90.660  0.0691    97.684  498.92
  83   0.3561     91.350  0.0667    97.686  504.95
  84   0.4328     89.690  0.0664    97.798  510.99
  85   0.3991     90.570  0.0674    97.668  517.03
  86   0.3817     90.540  0.0649    97.776  523.10
  87   0.4216     90.220  0.0637    97.844  529.36
  88   0.3881     90.130  0.0674    97.614  535.43
  89   0.3628     91.060  0.0670    97.718  541.53
  90   0.3654     90.670  0.0654    97.770  547.58
