Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1844     57.740  1.3783    49.660  7.75
   2   1.0140     66.800  0.9288    66.846  13.85
   3   0.7649     73.600  0.7310    74.408  19.98
   4   0.7434     75.680  0.6238    78.344  26.07
   5   0.7019     76.250  0.5538    80.816  32.13
   6   0.5872     80.270  0.4969    82.602  38.24
   7   0.6973     77.620  0.4580    84.290  44.34
   8   0.5548     81.750  0.4154    85.710  50.40
   9   0.6141     80.570  0.3920    86.602  56.44
  10   0.5587     81.410  0.3645    87.380  62.48
  11   0.6076     79.940  0.3457    88.006  68.55
  12   0.5126     83.640  0.3235    88.856  74.63
  13   0.5032     83.790  0.3061    89.454  80.74
  14   0.5238     84.220  0.2863    90.166  86.82
  15   0.5410     82.880  0.2783    90.516  92.86
  16   0.4858     84.590  0.2574    91.070  98.91
  17   0.4893     84.770  0.2495    91.414  104.99
  18   0.4529     86.190  0.2429    91.602  111.04
  19   0.4678     85.820  0.2277    92.128  117.15
  20   0.5230     83.980  0.2183    92.454  123.21
  21   0.5468     84.550  0.2103    92.670  129.31
  22   0.4020     87.680  0.1971    93.114  135.37
  23   0.4491     86.460  0.1964    93.204  141.44
  24   0.4068     88.000  0.1840    93.594  147.54
  25   0.3655     89.300  0.1775    93.856  153.68
  26   0.4590     86.570  0.1765    93.774  159.76
  27   0.4257     86.920  0.1718    94.112  165.84
  28   0.3351     89.540  0.1623    94.384  171.89
  29   0.3962     88.420  0.1513    94.772  177.96
  30   0.4299     87.570  0.1496    94.834  184.00
  31   0.3949     88.190  0.1471    94.828  190.15
  32   0.4100     88.310  0.1379    95.294  196.21
  33   0.4708     87.120  0.1377    95.294  202.28
  34   0.4358     88.400  0.1348    95.376  208.36
  35   0.3985     89.120  0.1247    95.780  214.43
  36   0.4468     87.510  0.1273    95.522  220.48
  37   0.3556     89.810  0.1275    95.756  226.62
  38   0.3610     90.000  0.1181    95.878  232.69
  39   0.4158     88.490  0.1185    96.022  238.79
  40   0.5032     87.440  0.1120    96.084  244.89
  41   0.3863     89.350  0.1086    96.202  250.95
  42   0.3869     89.620  0.1046    96.414  257.07
  43   0.3541     90.350  0.1058    96.338  263.15
  44   0.6064     84.830  0.1046    96.336  269.20
  45   0.4608     88.120  0.1016    96.514  275.26
  46   0.3776     89.980  0.0989    96.634  281.35
  47   0.3759     90.010  0.0954    96.700  287.50
  48   0.3743     90.140  0.1012    96.494  293.57
  49   0.3960     89.510  0.0947    96.774  299.61
  50   0.4355     88.700  0.0945    96.758  305.69
  51   0.3770     90.130  0.0916    96.836  311.76
  52   0.3713     89.980  0.0874    96.970  317.83
  53   0.4046     89.530  0.0899    96.912  323.98
  54   0.3988     89.820  0.0901    96.866  330.08
  55   0.4031     89.800  0.0874    97.004  336.13
  56   0.4271     89.270  0.0855    97.060  342.19
  57   0.3437     90.650  0.0841    97.148  348.23
  58   0.4287     89.220  0.0794    97.360  354.36
  59   0.4311     89.040  0.0848    97.100  360.42
  60   0.3928     89.970  0.0839    97.020  366.46
  61   0.3590     90.390  0.0861    97.020  372.51
  62   0.3588     90.640  0.0746    97.470  378.58
  63   0.3951     89.460  0.0787    97.332  384.66
  64   0.3636     90.440  0.0789    97.352  390.82
  65   0.3607     90.390  0.0828    97.190  396.92
  66   0.3650     90.190  0.0792    97.262  403.00
  67   0.4111     90.210  0.0743    97.460  409.09
  68   0.4131     89.880  0.0717    97.526  415.19
  69   0.3648     90.680  0.0760    97.390  421.24
  70   0.3650     90.550  0.0733    97.504  427.38
  71   0.3366     91.560  0.0754    97.448  433.46
  72   0.4228     89.690  0.0767    97.388  439.60
  73   0.3900     90.630  0.0723    97.482  445.69
  74   0.4261     89.480  0.0688    97.670  451.75
  75   0.3829     89.880  0.0715    97.626  457.81
  76   0.3421     91.420  0.0736    97.440  463.92
  77   0.3967     90.220  0.0710    97.578  469.95
  78   0.3417     91.300  0.0694    97.648  476.02
  79   0.3569     91.170  0.0638    97.782  482.06
  80   0.3792     90.300  0.0698    97.556  488.12
  81   0.4031     90.190  0.0693    97.678  494.22
  82   0.3994     90.210  0.0661    97.692  500.37
  83   0.3655     90.990  0.0628    97.886  506.44
  84   0.3948     90.220  0.0693    97.578  512.54
  85   0.3528     91.310  0.0651    97.764  518.65
