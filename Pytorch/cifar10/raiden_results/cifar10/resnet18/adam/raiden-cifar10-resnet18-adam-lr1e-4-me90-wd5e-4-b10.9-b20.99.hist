Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3609     51.080  1.5753    41.710  7.69
   2   1.1278     60.520  1.1998    56.572  13.87
   3   1.0694     62.930  1.0253    63.218  20.05
   4   0.9361     67.760  0.9022    67.876  26.17
   5   0.8348     71.220  0.8022    71.518  32.33
   6   0.7783     73.560  0.7248    74.598  38.54
   7   0.7433     74.160  0.6619    76.860  44.66
   8   0.6755     76.510  0.6099    78.566  50.77
   9   0.6948     76.450  0.5700    79.998  56.88
  10   0.6442     78.310  0.5356    81.350  63.00
  11   0.6260     79.020  0.5003    82.376  69.16
  12   0.6162     79.910  0.4757    83.488  75.31
  13   0.5743     81.030  0.4531    84.232  81.49
  14   0.5425     81.570  0.4259    85.124  87.62
  15   0.5910     80.640  0.4023    85.958  93.76
  16   0.5717     81.520  0.3809    86.656  99.88
  17   0.5165     82.620  0.3601    87.442  106.14
  18   0.5265     82.560  0.3450    87.890  112.27
  19   0.5301     83.240  0.3253    88.686  118.40
  20   0.5322     83.200  0.3180    88.944  124.53
  21   0.5321     82.880  0.2993    89.594  130.64
  22   0.5879     81.380  0.2876    89.940  136.82
  23   0.5275     83.330  0.2737    90.428  143.10
  24   0.4950     83.780  0.2608    91.010  149.30
  25   0.5032     83.960  0.2508    91.250  155.42
  26   0.4800     85.180  0.2375    91.690  161.57
  27   0.5567     83.260  0.2287    92.076  167.70
  28   0.4704     85.320  0.2167    92.364  173.91
  29   0.6587     81.000  0.2093    92.668  180.04
  30   0.5029     84.430  0.2036    92.854  186.22
  31   0.4697     85.690  0.1911    93.464  192.39
  32   0.4760     85.680  0.1852    93.644  198.51
  33   0.4786     85.670  0.1777    93.842  204.64
  34   0.5065     85.350  0.1700    94.160  210.87
  35   0.5711     83.500  0.1574    94.594  217.00
  36   0.5417     84.840  0.1567    94.586  223.13
  37   0.5744     83.570  0.1538    94.600  229.27
  38   0.5555     84.250  0.1470    94.832  235.46
  39   0.5284     84.470  0.1399    95.124  241.62
  40   0.5145     85.320  0.1341    95.490  247.86
  41   0.5351     84.860  0.1341    95.302  253.98
  42   0.5343     85.190  0.1255    95.744  260.11
  43   0.5686     84.230  0.1209    95.778  266.28
  44   0.4992     86.000  0.1171    95.922  272.40
  45   0.5153     86.030  0.1097    96.302  278.53
  46   0.4594     87.020  0.1119    96.178  284.77
  47   0.4994     86.440  0.1124    96.048  290.93
  48   0.5307     85.800  0.1064    96.350  297.04
  49   0.4856     86.370  0.0968    96.744  303.19
  50   0.5041     86.620  0.0961    96.646  309.34
  51   0.4999     86.800  0.0932    96.848  315.57
  52   0.5842     85.200  0.0932    96.776  321.75
  53   0.5005     86.690  0.0894    96.958  327.93
  54   0.4891     86.940  0.0877    97.026  334.06
  55   0.5520     85.440  0.0894    96.984  340.19
  56   0.5524     85.290  0.0824    97.150  346.30
  57   0.5364     86.640  0.0821    97.184  352.52
  58   0.5106     86.620  0.0773    97.402  358.63
  59   0.4677     87.820  0.0813    97.300  364.75
  60   0.4780     86.700  0.0780    97.380  370.85
  61   0.4691     87.550  0.0760    97.422  377.00
  62   0.4927     87.350  0.0748    97.418  383.22
  63   0.4546     87.930  0.0745    97.386  389.41
  64   0.4726     87.990  0.0697    97.664  395.56
  65   0.5273     86.660  0.0665    97.750  401.72
  66   0.4800     86.930  0.0706    97.558  407.83
  67   0.5005     87.320  0.0675    97.642  414.05
  68   0.4436     88.400  0.0686    97.704  420.22
  69   0.6067     85.210  0.0664    97.704  426.35
  70   0.4917     87.520  0.0661    97.836  432.48
  71   0.4975     87.420  0.0607    97.968  438.62
  72   0.4650     88.020  0.0661    97.754  444.81
  73   0.5167     87.070  0.0614    97.886  450.98
  74   0.5208     87.210  0.0610    97.966  457.11
  75   0.5041     87.600  0.0605    97.990  463.27
  76   0.4976     87.500  0.0608    97.926  469.45
  77   0.5032     87.750  0.0582    97.998  475.61
  78   0.5266     86.840  0.0558    98.146  481.85
  79   0.5089     87.510  0.0568    98.098  487.98
  80   0.4833     87.410  0.0559    98.116  494.15
  81   0.5109     87.230  0.0569    98.092  500.27
  82   0.5401     87.310  0.0567    98.024  506.45
  83   0.5542     86.740  0.0539    98.168  512.61
  84   0.5741     86.010  0.0558    98.120  518.80
  85   0.5086     86.840  0.0558    98.122  524.93
  86   0.5990     86.240  0.0509    98.284  531.10
  87   0.5281     86.930  0.0520    98.236  537.25
  88   0.5137     87.410  0.0481    98.434  543.37
  89   0.4659     88.040  0.0558    98.120  549.53
  90   0.4678     88.420  0.0496    98.354  555.76
