Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2420     54.900  1.4909    44.842  7.67
   2   0.9926     65.030  1.0759    61.248  13.80
   3   0.8186     71.150  0.8783    68.544  19.86
   4   0.7452     74.050  0.7503    73.540  26.08
   5   0.6977     76.390  0.6548    76.986  32.18
   6   0.5953     79.600  0.5774    79.744  38.30
   7   0.5594     80.780  0.5157    82.132  44.43
   8   0.6023     80.240  0.4750    83.594  50.53
   9   0.4928     83.020  0.4353    84.936  56.58
  10   0.5029     83.310  0.4013    86.074  62.74
  11   0.4856     84.630  0.3791    86.890  68.82
  12   0.4435     84.820  0.3526    87.786  74.86
  13   0.4438     85.420  0.3304    88.434  80.98
  14   0.4959     83.480  0.3079    89.352  87.05
  15   0.4198     86.190  0.2949    89.702  93.11
  16   0.4273     86.210  0.2625    90.910  99.22
  17   0.4348     86.240  0.2571    91.018  105.30
  18   0.4081     87.160  0.2508    91.284  111.41
  19   0.4268     87.480  0.2287    92.122  117.46
  20   0.4298     87.290  0.2210    92.358  123.51
  21   0.3851     88.010  0.2107    92.644  129.70
  22   0.3542     88.600  0.1982    93.000  135.82
  23   0.3717     89.040  0.1882    93.414  141.92
  24   0.3951     88.510  0.1783    93.806  148.03
  25   0.4228     88.150  0.1700    94.142  154.14
  26   0.3918     87.970  0.1655    94.236  160.32
  27   0.3552     88.780  0.1591    94.428  166.39
  28   0.3951     88.810  0.1562    94.442  172.45
  29   0.3811     89.320  0.1514    94.710  178.53
  30   0.4211     88.290  0.1524    94.644  184.63
  31   0.3476     89.940  0.1375    95.214  190.77
  32   0.3642     89.980  0.1340    95.324  196.96
  33   0.3796     88.980  0.1279    95.478  203.06
  34   0.3563     89.790  0.1201    95.804  209.17
  35   0.3465     90.250  0.1217    95.768  215.26
  36   0.3871     89.820  0.1139    96.104  221.39
  37   0.3582     90.240  0.1125    95.994  227.58
  38   0.3660     90.390  0.1071    96.322  233.65
  39   0.3908     89.760  0.1030    96.398  239.70
  40   0.3835     90.240  0.1010    96.510  245.81
  41   0.3621     89.950  0.1014    96.446  251.90
  42   0.3870     89.910  0.0948    96.748  258.03
  43   0.3589     90.670  0.0981    96.536  264.10
  44   0.3621     90.690  0.0908    96.854  270.20
  45   0.3869     89.650  0.0927    96.800  276.25
  46   0.3486     90.630  0.0891    96.944  282.32
  47   0.3749     90.160  0.0851    97.156  288.40
  48   0.3489     90.680  0.0893    96.946  294.56
  49   0.3877     89.780  0.0849    97.046  300.61
  50   0.3782     90.470  0.0795    97.222  306.66
  51   0.3943     90.440  0.0864    97.094  312.74
  52   0.3594     90.340  0.0817    97.178  318.79
  53   0.3887     90.200  0.0732    97.530  324.89
  54   0.3831     90.540  0.0745    97.398  331.07
  55   0.3719     90.950  0.0717    97.496  337.14
  56   0.3954     90.560  0.0691    97.612  343.25
  57   0.3639     90.960  0.0734    97.402  349.37
  58   0.3639     90.210  0.0704    97.556  355.44
  59   0.3503     91.250  0.0716    97.560  361.53
  60   0.3918     90.600  0.0656    97.780  367.68
  61   0.3774     90.700  0.0669    97.578  373.79
  62   0.3709     91.040  0.0677    97.746  379.88
  63   0.4198     89.830  0.0664    97.680  385.98
  64   0.3844     90.560  0.0677    97.642  392.09
  65   0.4059     90.120  0.0606    97.938  398.13
  66   0.3893     91.170  0.0611    97.936  404.31
  67   0.3934     90.840  0.0601    97.890  410.43
  68   0.3869     90.730  0.0600    97.866  416.53
  69   0.3722     91.110  0.0598    97.910  422.60
  70   0.3889     90.550  0.0593    97.980  428.67
  71   0.3986     90.730  0.0579    98.040  434.77
  72   0.3989     90.670  0.0592    97.966  440.88
  73   0.3934     90.700  0.0577    98.030  446.97
  74   0.3728     91.110  0.0610    97.814  453.06
  75   0.3711     91.230  0.0575    97.978  459.18
  76   0.3833     91.470  0.0545    98.132  465.25
  77   0.3630     91.140  0.0569    97.980  471.36
  78   0.3872     91.040  0.0606    97.898  477.45
  79   0.3813     91.220  0.0562    98.062  483.60
  80   0.3718     91.220  0.0550    98.076  489.67
  81   0.3996     90.450  0.0553    98.100  495.74
  82   0.3528     91.110  0.0547    98.134  501.82
  83   0.4031     90.680  0.0525    98.142  507.94
  84   0.3531     91.370  0.0561    98.042  514.07
  85   0.3675     91.400  0.0509    98.244  520.28
