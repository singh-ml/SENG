Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2071     56.280  1.4648    46.010  7.52
   2   0.9554     65.840  1.0510    62.320  13.62
   3   0.8808     69.280  0.8522    69.888  19.70
   4   0.7840     73.090  0.7256    74.432  25.75
   5   0.6931     76.560  0.6393    77.666  31.80
   6   0.6789     76.930  0.5703    80.110  37.86
   7   0.6169     78.980  0.5176    81.926  43.97
   8   0.6418     79.400  0.4808    83.354  50.06
   9   0.5137     81.440  0.4459    84.552  56.10
  10   0.5567     81.380  0.4097    85.824  62.20
  11   0.5181     82.190  0.3855    86.698  68.27
  12   0.6065     80.320  0.3643    87.360  74.37
  13   0.4784     84.320  0.3415    88.260  80.44
  14   0.4777     84.340  0.3162    89.102  86.48
  15   0.5434     82.910  0.2993    89.436  92.58
  16   0.4583     84.610  0.2916    89.838  98.66
  17   0.5999     81.700  0.2754    90.318  104.70
  18   0.4925     84.160  0.2632    90.898  110.86
  19   0.4864     84.770  0.2391    91.704  116.91
  20   0.4478     85.850  0.2285    92.126  123.02
  21   0.4650     85.230  0.2203    92.448  129.12
  22   0.4470     86.100  0.2052    92.828  135.20
  23   0.4900     85.100  0.2031    92.876  141.39
  24   0.5511     84.320  0.1884    93.352  147.46
  25   0.4431     86.770  0.1804    93.762  153.55
  26   0.4277     87.160  0.1695    93.968  159.68
  27   0.5175     84.950  0.1695    94.020  165.77
  28   0.4019     87.960  0.1584    94.436  171.82
  29   0.5000     86.110  0.1504    94.670  177.99
  30   0.4521     86.990  0.1453    94.894  184.04
  31   0.5007     85.940  0.1305    95.428  190.09
  32   0.4873     86.550  0.1352    95.248  196.15
  33   0.4949     86.490  0.1307    95.430  202.23
  34   0.5202     86.300  0.1245    95.586  208.31
  35   0.4700     87.150  0.1173    95.908  214.40
  36   0.4347     87.930  0.1159    95.926  220.50
  37   0.4082     88.170  0.1090    96.170  226.56
  38   0.3862     88.660  0.1105    96.162  232.61
  39   0.4478     87.840  0.1048    96.388  238.69
  40   0.4740     87.250  0.1069    96.266  244.76
  41   0.4066     88.850  0.1005    96.434  250.89
  42   0.5038     86.670  0.0941    96.662  256.95
  43   0.4391     88.120  0.0931    96.742  263.05
  44   0.4246     88.810  0.0929    96.746  269.08
  45   0.4372     88.010  0.0873    96.944  275.15
  46   0.4448     88.020  0.0852    97.068  281.22
  47   0.4633     88.150  0.0828    97.104  287.36
  48   0.5286     86.430  0.0820    97.144  293.40
  49   0.4575     88.270  0.0815    97.106  299.46
  50   0.4938     87.540  0.0729    97.536  305.53
  51   0.4670     88.560  0.0773    97.368  311.57
  52   0.4079     89.410  0.0803    97.246  317.63
  53   0.5103     88.230  0.0708    97.556  323.77
  54   0.4634     88.970  0.0694    97.632  329.82
  55   0.4321     89.160  0.0748    97.378  335.93
  56   0.4563     88.540  0.0672    97.686  342.00
  57   0.4368     89.360  0.0634    97.808  348.08
  58   0.4625     88.330  0.0677    97.644  354.14
  59   0.4179     89.190  0.0681    97.660  360.29
  60   0.4796     88.220  0.0669    97.720  366.36
  61   0.4946     87.900  0.0629    97.814  372.43
  62   0.4039     89.770  0.0676    97.638  378.51
  63   0.4321     89.560  0.0576    97.994  384.60
  64   0.4488     88.770  0.0583    97.982  390.76
  65   0.4948     87.960  0.0593    97.984  396.81
  66   0.3973     89.920  0.0612    97.912  402.89
  67   0.5425     87.460  0.0571    98.068  408.94
  68   0.4474     89.270  0.0606    97.852  415.03
  69   0.4628     88.940  0.0549    98.066  421.14
  70   0.4710     88.830  0.0511    98.308  427.23
  71   0.5251     87.780  0.0525    98.212  433.33
  72   0.4525     89.300  0.0550    98.096  439.39
  73   0.4461     89.130  0.0541    98.188  445.44
  74   0.4520     89.330  0.0519    98.222  451.53
  75   0.4009     89.760  0.0581    98.024  457.67
  76   0.4882     88.540  0.0509    98.226  463.72
  77   0.3949     90.240  0.0549    98.118  469.79
  78   0.4331     89.550  0.0484    98.306  475.85
  79   0.4752     89.150  0.0493    98.324  481.94
  80   0.4478     89.470  0.0563    98.092  488.06
  81   0.4757     89.430  0.0476    98.378  494.14
  82   0.4715     88.930  0.0498    98.254  500.17
  83   0.4477     89.570  0.0458    98.418  506.25
  84   0.4177     90.330  0.0500    98.310  512.29
  85   0.3844     90.190  0.0468    98.438  518.36
