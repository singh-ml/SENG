Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2755     53.560  1.5182    44.102  7.69
   2   1.0089     63.640  1.1403    58.816  13.74
   3   0.8504     69.510  0.9497    65.856  19.78
   4   0.7799     72.520  0.8007    71.542  25.84
   5   0.7356     74.460  0.7059    75.106  31.98
   6   0.6711     77.530  0.6154    78.424  38.04
   7   0.6128     79.260  0.5555    80.776  44.06
   8   0.5712     80.190  0.5141    82.164  50.12
   9   0.5418     81.900  0.4806    83.286  56.17
  10   0.5109     82.710  0.4494    84.338  62.22
  11   0.5453     81.760  0.4282    85.170  68.33
  12   0.4851     83.750  0.3919    86.382  74.40
  13   0.5188     82.490  0.3695    87.084  80.46
  14   0.4832     83.880  0.3503    87.944  86.50
  15   0.4513     84.990  0.3339    88.498  92.54
  16   0.4412     85.640  0.3147    89.030  98.56
  17   0.4618     84.940  0.3032    89.548  104.67
  18   0.4198     86.010  0.2734    90.684  110.75
  19   0.3954     86.880  0.2686    90.714  116.77
  20   0.4360     86.160  0.2613    90.916  122.80
  21   0.4029     86.960  0.2384    91.852  128.81
  22   0.4268     86.360  0.2316    91.972  134.93
  23   0.4159     86.730  0.2233    92.408  140.96
  24   0.4087     86.970  0.2176    92.462  147.01
  25   0.4080     87.020  0.2076    92.864  153.03
  26   0.3952     87.220  0.2016    93.138  159.08
  27   0.4108     87.090  0.1890    93.496  165.11
  28   0.3879     87.290  0.1808    93.734  171.25
  29   0.4564     86.530  0.1698    94.108  177.27
  30   0.3812     88.050  0.1631    94.360  183.30
  31   0.3699     88.450  0.1532    94.712  189.32
  32   0.3853     88.480  0.1579    94.506  195.35
  33   0.3698     88.570  0.1522    94.712  201.41
  34   0.4004     87.860  0.1356    95.392  207.48
  35   0.4207     87.850  0.1336    95.478  213.51
  36   0.3651     89.080  0.1383    95.196  219.54
  37   0.4044     88.320  0.1299    95.504  225.56
  38   0.4751     86.820  0.1373    95.252  231.59
  39   0.3923     88.630  0.1336    95.394  237.66
  40   0.3970     88.530  0.1182    95.860  243.71
  41   0.4091     88.730  0.1120    96.136  249.75
  42   0.3694     89.010  0.1136    96.122  255.83
  43   0.3756     89.000  0.1098    96.232  261.84
  44   0.4010     88.510  0.1071    96.400  267.93
  45   0.3775     89.380  0.1055    96.428  273.98
  46   0.3795     89.530  0.1060    96.348  280.03
  47   0.3673     89.380  0.1028    96.468  286.05
  48   0.3663     89.850  0.0929    96.860  292.10
  49   0.3987     88.910  0.0955    96.744  298.13
  50   0.3705     89.710  0.0946    96.792  304.25
  51   0.3573     89.860  0.1025    96.502  310.26
  52   0.4061     88.620  0.0911    96.764  316.30
  53   0.3861     89.220  0.0936    96.808  322.32
  54   0.3748     89.470  0.0879    96.992  328.37
  55   0.4349     88.300  0.0845    97.060  334.50
  56   0.4033     88.850  0.0846    97.140  340.56
  57   0.3705     89.810  0.0834    97.172  346.59
  58   0.4179     88.740  0.0812    97.266  352.66
  59   0.4136     89.370  0.0761    97.440  358.72
  60   0.3941     90.120  0.0727    97.504  364.72
  61   0.4126     89.130  0.0780    97.360  370.83
  62   0.3690     90.070  0.0739    97.594  376.86
  63   0.3694     90.150  0.0685    97.696  382.88
  64   0.3932     89.830  0.0744    97.422  388.95
  65   0.3644     90.110  0.0783    97.318  394.99
  66   0.3767     89.920  0.0740    97.518  401.03
  67   0.3713     90.120  0.0707    97.672  407.13
  68   0.3925     89.840  0.0710    97.532  413.16
  69   0.3989     90.000  0.0658    97.868  419.21
  70   0.3960     89.530  0.0670    97.754  425.26
  71   0.3939     89.760  0.0693    97.690  431.29
  72   0.4036     89.580  0.0717    97.560  437.36
  73   0.3537     90.290  0.0673    97.740  443.44
  74   0.3784     90.120  0.0637    97.862  449.49
  75   0.3745     89.780  0.0662    97.766  455.51
  76   0.3760     90.250  0.0603    97.914  461.54
  77   0.3821     90.180  0.0572    98.044  467.56
  78   0.3557     90.570  0.0591    98.018  473.60
  79   0.3818     89.990  0.0577    98.070  479.70
  80   0.3747     90.070  0.0643    97.798  485.73
  81   0.3528     90.390  0.0632    97.912  491.75
  82   0.3627     90.600  0.0639    97.872  497.76
  83   0.3778     90.140  0.0634    97.804  503.78
  84   0.3546     90.410  0.0606    97.992  509.87
  85   0.3961     89.880  0.0618    97.900  515.91
