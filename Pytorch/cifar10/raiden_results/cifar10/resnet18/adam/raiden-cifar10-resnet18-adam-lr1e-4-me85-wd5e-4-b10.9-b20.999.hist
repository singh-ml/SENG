Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3165     52.270  1.5667    42.248  7.79
   2   1.0847     60.520  1.1989    56.826  13.98
   3   0.9860     64.730  1.0201    63.528  20.18
   4   0.8977     68.530  0.8894    68.336  26.38
   5   0.8338     71.100  0.7830    72.166  32.61
   6   0.7609     73.700  0.7058    75.212  38.84
   7   0.7331     75.110  0.6488    77.180  45.03
   8   0.7156     75.900  0.6005    78.828  51.21
   9   0.6250     78.530  0.5607    80.360  57.38
  10   0.6298     78.490  0.5243    81.760  63.55
  11   0.5864     79.650  0.4947    82.796  69.80
  12   0.5695     80.840  0.4653    83.682  75.98
  13   0.5486     81.780  0.4416    84.532  82.14
  14   0.5484     81.750  0.4144    85.540  88.37
  15   0.5386     81.910  0.3961    86.226  94.54
  16   0.5648     81.410  0.3753    86.930  100.70
  17   0.5062     83.370  0.3607    87.450  106.95
  18   0.5688     81.760  0.3389    88.294  113.19
  19   0.5901     81.280  0.3275    88.540  119.37
  20   0.4835     84.230  0.3088    89.116  125.57
  21   0.5832     82.310  0.2950    89.740  131.76
  22   0.4651     85.280  0.2786    90.256  137.93
  23   0.5023     83.600  0.2721    90.568  144.17
  24   0.5087     84.320  0.2561    91.058  150.39
  25   0.4603     85.120  0.2458    91.522  156.55
  26   0.5289     83.330  0.2366    91.718  162.72
  27   0.4521     85.880  0.2247    92.142  168.93
  28   0.5269     83.930  0.2164    92.388  175.20
  29   0.4994     85.160  0.2060    92.898  181.40
  30   0.5200     84.510  0.1960    93.196  187.58
  31   0.4938     84.570  0.1875    93.532  193.76
  32   0.5546     84.220  0.1800    93.816  199.94
  33   0.5062     85.120  0.1712    94.044  206.13
  34   0.5045     85.230  0.1709    94.062  212.30
  35   0.4627     86.350  0.1634    94.360  218.47
  36   0.4848     86.130  0.1533    94.718  224.62
  37   0.4887     85.500  0.1442    95.154  230.84
  38   0.5130     85.370  0.1411    95.008  237.03
  39   0.5030     85.410  0.1376    95.218  243.26
  40   0.5211     85.400  0.1315    95.512  249.43
  41   0.4536     86.770  0.1332    95.312  255.66
  42   0.5662     84.630  0.1191    95.908  261.87
  43   0.5210     85.260  0.1158    96.090  268.11
  44   0.5162     85.940  0.1161    96.010  274.28
  45   0.4882     85.760  0.1152    95.962  280.47
  46   0.4537     87.380  0.1060    96.422  286.77
  47   0.4419     87.540  0.1050    96.374  292.98
  48   0.5957     84.120  0.1019    96.488  299.22
  49   0.4911     86.500  0.1009    96.590  305.43
  50   0.5270     86.340  0.0972    96.662  311.60
  51   0.4974     87.180  0.0936    96.722  317.88
  52   0.5447     85.740  0.0931    96.824  324.10
  53   0.5053     86.660  0.0910    96.878  330.27
  54   0.4588     87.580  0.0859    97.136  336.50
  55   0.4627     87.520  0.0868    97.038  342.74
  56   0.4930     87.430  0.0838    97.160  348.97
  57   0.4344     88.200  0.0793    97.288  355.19
  58   0.4419     88.080  0.0783    97.330  361.41
  59   0.4684     87.470  0.0782    97.360  367.63
  60   0.4802     87.270  0.0714    97.602  373.85
  61   0.4653     87.090  0.0720    97.584  380.04
  62   0.5070     86.840  0.0735    97.484  386.32
  63   0.4794     87.210  0.0678    97.712  392.48
  64   0.5077     86.860  0.0750    97.466  398.67
  65   0.4743     87.470  0.0699    97.688  404.90
  66   0.5060     86.970  0.0680    97.650  411.10
  67   0.4842     87.460  0.0690    97.740  417.34
  68   0.5276     87.060  0.0660    97.758  423.56
  69   0.4949     87.200  0.0644    97.818  429.75
  70   0.4813     87.280  0.0668    97.716  435.89
  71   0.4382     88.450  0.0627    97.892  442.11
  72   0.5162     86.830  0.0585    98.084  448.39
  73   0.5002     87.620  0.0622    97.984  454.58
  74   0.4925     87.310  0.0629    97.882  460.77
  75   0.4910     87.580  0.0632    97.848  466.94
  76   0.4415     88.110  0.0583    98.048  473.15
  77   0.5282     87.030  0.0576    98.056  479.33
  78   0.6011     85.490  0.0548    98.202  485.52
  79   0.4670     88.090  0.0554    98.132  491.77
  80   0.5352     86.860  0.0624    97.944  498.00
  81   0.5145     86.500  0.0541    98.172  504.21
  82   0.4608     88.710  0.0586    97.954  510.39
  83   0.4499     88.390  0.0540    98.254  516.60
  84   0.4193     89.070  0.0578    98.072  522.85
  85   0.4918     87.130  0.0543    98.218  529.16
