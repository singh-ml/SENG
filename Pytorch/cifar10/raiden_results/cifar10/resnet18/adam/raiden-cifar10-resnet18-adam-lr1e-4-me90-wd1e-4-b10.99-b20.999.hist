Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3648     49.620  1.6531    38.676  7.81
   2   1.1837     57.150  1.2887    53.104  14.10
   3   1.0332     62.930  1.1061    60.268  20.42
   4   0.9446     66.860  0.9746    65.226  26.64
   5   0.8775     69.670  0.8699    69.076  32.87
   6   0.7821     72.560  0.7893    71.942  39.13
   7   0.7697     73.720  0.7181    74.614  45.37
   8   0.7181     74.720  0.6616    76.736  51.67
   9   0.6394     77.820  0.6151    78.568  57.94
  10   0.6287     78.140  0.5715    79.956  64.21
  11   0.6065     78.770  0.5414    81.054  70.44
  12   0.5769     80.310  0.5015    82.446  76.71
  13   0.5788     80.340  0.4706    83.410  82.95
  14   0.5460     81.630  0.4483    84.160  89.24
  15   0.5296     82.020  0.4235    85.140  95.48
  16   0.5142     82.460  0.4051    85.862  101.74
  17   0.5300     82.730  0.3819    86.570  108.01
  18   0.4989     83.030  0.3564    87.590  114.25
  19   0.5210     83.230  0.3437    88.038  120.54
  20   0.5161     83.430  0.3226    88.836  126.81
  21   0.4830     84.090  0.3008    89.494  133.09
  22   0.4891     84.460  0.2919    89.788  139.36
  23   0.4806     84.730  0.2744    90.420  145.63
  24   0.4885     84.630  0.2674    90.650  151.90
  25   0.4858     84.850  0.2523    91.182  158.22
  26   0.4571     85.730  0.2477    91.190  164.49
  27   0.4552     85.640  0.2272    91.948  170.76
  28   0.4591     85.850  0.2184    92.284  177.00
  29   0.4732     85.410  0.2123    92.344  183.28
  30   0.4805     85.570  0.2000    92.962  189.50
  31   0.4671     85.800  0.1950    93.262  195.76
  32   0.4630     86.380  0.1792    93.668  202.01
  33   0.4681     85.960  0.1742    93.878  208.27
  34   0.4939     86.080  0.1697    93.924  214.54
  35   0.4647     86.120  0.1624    94.262  220.78
  36   0.4872     86.440  0.1509    94.762  227.10
  37   0.4864     86.430  0.1419    95.070  233.35
  38   0.4632     86.810  0.1395    95.170  239.63
  39   0.4663     87.050  0.1261    95.502  245.89
  40   0.4854     86.890  0.1245    95.626  252.18
  41   0.4926     86.810  0.1158    95.926  258.40
  42   0.5078     86.790  0.1172    95.944  264.75
  43   0.4834     86.960  0.1111    96.012  271.02
  44   0.4769     86.980  0.1084    96.176  277.25
  45   0.4927     87.000  0.1026    96.366  283.50
  46   0.4796     87.290  0.0984    96.594  289.75
  47   0.4896     87.340  0.0896    96.862  296.04
  48   0.4770     87.560  0.0843    97.050  302.31
  49   0.4918     87.610  0.0822    97.132  308.58
  50   0.5162     87.240  0.0855    96.982  314.81
  51   0.4996     87.460  0.0843    96.988  321.14
  52   0.5072     87.630  0.0825    97.076  327.43
  53   0.5033     87.380  0.0763    97.282  333.79
  54   0.4967     88.170  0.0731    97.504  340.10
  55   0.5498     86.720  0.0715    97.446  346.36
  56   0.5190     87.660  0.0759    97.360  352.59
  57   0.5155     87.330  0.0696    97.560  358.85
  58   0.5261     87.530  0.0629    97.782  365.14
  59   0.5278     87.590  0.0684    97.588  371.43
  60   0.5520     87.100  0.0666    97.692  377.67
  61   0.5326     87.620  0.0610    97.844  383.93
  62   0.5171     88.070  0.0546    98.084  390.20
  63   0.5413     87.640  0.0548    98.156  396.50
  64   0.5564     87.840  0.0585    97.932  402.78
  65   0.5043     87.880  0.0600    97.858  409.03
  66   0.5547     87.490  0.0605    97.890  415.28
  67   0.5288     87.950  0.0576    97.996  421.53
  68   0.5475     88.080  0.0520    98.202  427.79
  69   0.5326     87.940  0.0507    98.232  434.00
  70   0.5574     87.430  0.0517    98.188  440.27
  71   0.5347     88.090  0.0497    98.278  446.53
  72   0.5659     87.900  0.0534    98.160  452.81
  73   0.5375     87.750  0.0493    98.340  459.07
  74   0.5627     87.750  0.0480    98.344  465.43
  75   0.5391     87.680  0.0475    98.350  471.69
  76   0.5295     87.800  0.0458    98.472  477.95
  77   0.5303     88.190  0.0463    98.396  484.23
  78   0.5558     87.600  0.0465    98.350  490.51
  79   0.5248     88.240  0.0433    98.444  496.78
  80   0.5440     88.020  0.0457    98.368  503.13
  81   0.5270     88.020  0.0407    98.594  509.38
  82   0.5107     88.760  0.0396    98.610  515.63
  83   0.5175     88.430  0.0386    98.670  521.87
  84   0.5256     87.920  0.0379    98.672  528.13
  85   0.5678     87.870  0.0399    98.658  534.35
  86   0.5730     87.990  0.0467    98.330  540.67
  87   0.5256     88.500  0.0457    98.412  546.93
  88   0.5275     88.390  0.0424    98.544  553.16
  89   0.5303     88.620  0.0410    98.604  559.40
  90   0.5226     88.700  0.0398    98.608  565.68
