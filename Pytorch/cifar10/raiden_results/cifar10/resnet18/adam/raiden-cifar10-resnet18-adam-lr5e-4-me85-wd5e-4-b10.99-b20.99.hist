Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2209     56.000  1.4969    45.126  7.51
   2   1.0166     64.120  1.1037    60.268  13.52
   3   0.9049     68.210  0.8893    68.254  19.61
   4   0.7642     74.100  0.7393    74.030  25.69
   5   0.6407     77.720  0.6562    77.114  31.75
   6   0.6447     77.750  0.5996    79.130  37.77
   7   0.6049     79.410  0.5443    81.234  43.79
   8   0.5343     81.400  0.5120    82.354  49.87
   9   0.5147     82.240  0.4646    83.958  55.92
  10   0.5297     81.650  0.4253    85.488  62.03
  11   0.4719     84.200  0.4008    86.222  68.05
  12   0.5557     82.020  0.3716    87.334  74.08
  13   0.4795     83.890  0.3623    87.442  80.12
  14   0.4230     86.120  0.3370    88.424  86.16
  15   0.3938     86.590  0.3221    88.928  92.20
  16   0.4648     85.040  0.3098    89.362  98.35
  17   0.4580     85.270  0.2890    90.020  104.40
  18   0.3906     87.250  0.2861    90.146  110.45
  19   0.4147     86.780  0.2654    90.996  116.47
  20   0.3901     87.320  0.2527    91.438  122.52
  21   0.3949     87.410  0.2496    91.364  128.56
  22   0.3879     87.950  0.2336    91.974  134.68
  23   0.4482     86.100  0.2326    91.948  140.72
  24   0.3922     87.540  0.2231    92.360  146.74
  25   0.3629     88.720  0.2069    92.916  152.82
  26   0.3359     89.240  0.2065    92.922  158.86
  27   0.3459     89.100  0.1998    93.232  164.89
  28   0.3927     87.920  0.2002    93.042  170.99
  29   0.4012     87.710  0.1950    93.342  177.05
  30   0.3561     88.640  0.1871    93.586  183.10
  31   0.3458     88.940  0.1793    93.920  189.13
  32   0.3644     89.340  0.1744    94.028  195.21
  33   0.3325     89.670  0.1703    94.142  201.30
  34   0.3450     89.610  0.1663    94.290  207.39
  35   0.3392     89.430  0.1646    94.434  213.46
  36   0.3560     88.820  0.1626    94.368  219.53
  37   0.3501     89.870  0.1546    94.702  225.59
  38   0.3349     89.810  0.1535    94.786  231.62
  39   0.3246     90.020  0.1491    94.904  237.74
  40   0.3439     89.880  0.1420    95.144  243.81
  41   0.3977     88.760  0.1432    95.170  249.83
  42   0.3579     89.340  0.1420    95.174  255.89
  43   0.3431     89.670  0.1354    95.424  261.97
  44   0.3228     90.170  0.1386    95.386  268.04
  45   0.3279     90.310  0.1348    95.408  274.08
  46   0.3691     89.450  0.1351    95.350  280.17
  47   0.3368     90.170  0.1308    95.548  286.25
  48   0.3250     90.380  0.1300    95.506  292.29
  49   0.3048     90.710  0.1240    95.796  298.41
  50   0.3408     90.110  0.1312    95.490  304.48
  51   0.3221     90.760  0.1309    95.536  310.50
  52   0.3207     90.200  0.1217    95.860  316.56
  53   0.3926     89.180  0.1213    95.826  322.59
  54   0.3169     91.000  0.1242    95.686  328.67
  55   0.3429     90.160  0.1159    95.964  334.80
  56   0.3136     90.710  0.1147    96.110  340.86
  57   0.3247     90.820  0.1131    96.098  346.95
  58   0.3309     90.940  0.1129    96.210  352.99
  59   0.3200     90.560  0.1144    96.054  359.03
  60   0.3220     91.310  0.1083    96.318  365.13
  61   0.3498     90.530  0.1142    96.126  371.20
  62   0.3815     89.280  0.1057    96.388  377.28
  63   0.3276     90.680  0.1097    96.200  383.33
  64   0.3386     90.420  0.1083    96.372  389.38
  65   0.3248     90.350  0.1090    96.296  395.43
  66   0.3243     90.730  0.1055    96.376  401.55
  67   0.3345     90.950  0.1053    96.436  407.57
  68   0.3411     90.470  0.1036    96.556  413.64
  69   0.3173     90.970  0.1052    96.366  419.69
  70   0.3504     90.750  0.0992    96.646  425.74
  71   0.3551     90.400  0.1055    96.406  431.76
  72   0.3153     91.180  0.0973    96.674  437.89
  73   0.3493     90.570  0.0932    96.796  443.94
  74   0.3237     91.030  0.1031    96.540  450.00
  75   0.3378     90.840  0.0992    96.610  456.07
  76   0.3361     90.930  0.1014    96.580  462.11
  77   0.3103     90.820  0.0963    96.728  468.17
  78   0.3517     90.410  0.0937    96.798  474.29
  79   0.3174     91.010  0.0974    96.688  480.38
  80   0.3345     90.760  0.0948    96.876  486.43
  81   0.3327     91.120  0.0923    96.770  492.49
  82   0.3324     90.770  0.0948    96.786  498.56
  83   0.3402     90.610  0.0914    96.986  504.60
  84   0.3527     90.640  0.0922    96.878  510.71
  85   0.3425     90.580  0.0938    96.810  516.80
