Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1365     60.160  1.3808    49.322  7.78
   2   1.0990     63.810  0.9287    66.788  13.92
   3   0.8631     71.830  0.7264    74.286  20.02
   4   0.7227     76.030  0.6171    78.328  26.08
   5   0.6181     79.450  0.5472    80.976  32.19
   6   0.5940     79.880  0.4887    83.072  38.26
   7   0.8591     75.390  0.4465    84.484  44.41
   8   0.5636     81.280  0.4124    85.848  50.52
   9   0.5699     81.230  0.3799    86.964  56.58
  10   0.5379     82.850  0.3522    87.798  62.66
  11   0.5190     83.530  0.3307    88.602  68.71
  12   0.4218     85.940  0.3107    89.276  74.85
  13   0.4923     84.470  0.2936    89.704  80.98
  14   0.4730     84.870  0.2739    90.514  87.10
  15   0.4552     85.180  0.2584    91.060  93.15
  16   0.4395     86.180  0.2461    91.384  99.25
  17   0.4203     87.060  0.2356    91.876  105.37
  18   0.4650     86.030  0.2207    92.446  111.48
  19   0.4406     87.190  0.2129    92.616  117.55
  20   0.3976     87.960  0.2051    92.830  123.63
  21   0.4018     87.560  0.1988    93.114  129.76
  22   0.4998     84.900  0.1846    93.580  135.84
  23   0.4104     87.620  0.1744    93.926  141.94
  24   0.4025     88.270  0.1697    94.100  147.98
  25   0.3896     88.080  0.1599    94.366  154.06
  26   0.3811     88.850  0.1541    94.594  160.11
  27   0.4524     87.240  0.1472    94.780  166.20
  28   0.3912     88.580  0.1427    95.082  172.30
  29   0.3989     88.090  0.1447    94.972  178.44
  30   0.4194     87.840  0.1328    95.430  184.51
  31   0.4347     87.790  0.1301    95.472  190.54
  32   0.4266     88.000  0.1226    95.816  196.58
  33   0.4913     87.440  0.1244    95.700  202.62
  34   0.5434     86.480  0.1176    95.876  208.69
  35   0.3943     89.760  0.1149    95.974  214.80
  36   0.4020     89.560  0.1028    96.368  220.83
  37   0.4146     88.730  0.1069    96.260  226.91
  38   0.3934     89.110  0.1057    96.412  233.00
  39   0.3900     89.210  0.1031    96.366  239.10
  40   0.3689     89.840  0.0975    96.704  245.17
  41   0.3521     90.380  0.0974    96.632  251.28
  42   0.4400     88.950  0.0921    96.834  257.34
  43   0.4665     88.370  0.0928    96.740  263.46
  44   0.3927     89.860  0.0886    96.896  269.54
  45   0.4002     89.760  0.0865    96.998  275.64
  46   0.4045     89.770  0.0880    96.920  281.69
  47   0.4175     89.500  0.0787    97.280  287.82
  48   0.4464     89.220  0.0832    97.150  293.90
  49   0.3701     90.160  0.0833    97.110  299.95
  50   0.4127     89.420  0.0785    97.264  306.07
  51   0.3962     90.180  0.0751    97.372  312.13
  52   0.3786     90.440  0.0725    97.496  318.20
  53   0.3816     90.080  0.0736    97.442  324.34
  54   0.4023     90.180  0.0705    97.586  330.39
  55   0.3933     90.410  0.0742    97.468  336.46
  56   0.4385     89.430  0.0660    97.644  342.55
  57   0.4051     89.890  0.0750    97.406  348.62
  58   0.5511     87.920  0.0675    97.660  354.67
  59   0.4148     89.730  0.0661    97.708  360.73
  60   0.4399     89.790  0.0672    97.716  366.85
  61   0.3867     90.180  0.0700    97.548  372.90
  62   0.3826     90.780  0.0628    97.832  378.95
  63   0.4202     90.140  0.0623    97.864  385.06
  64   0.3974     90.410  0.0670    97.702  391.25
  65   0.4079     89.930  0.0652    97.650  397.30
  66   0.4055     90.460  0.0630    97.796  403.43
  67   0.4822     89.330  0.0600    97.908  409.51
  68   0.4780     89.320  0.0611    97.834  415.56
  69   0.3749     90.560  0.0611    97.880  421.64
  70   0.4145     90.600  0.0606    97.936  427.76
  71   0.4393     89.990  0.0575    98.078  433.83
  72   0.4453     90.090  0.0554    98.106  439.89
  73   0.4070     90.360  0.0595    97.924  445.98
  74   0.4561     89.730  0.0564    98.020  452.04
  75   0.4233     90.370  0.0533    98.168  458.22
  76   0.4736     89.380  0.0537    98.120  464.27
  77   0.4021     90.340  0.0614    97.908  470.37
  78   0.3932     90.730  0.0575    98.018  476.46
  79   0.4327     90.260  0.0552    98.116  482.52
  80   0.4061     90.500  0.0546    98.090  488.70
  81   0.4082     90.030  0.0535    98.130  494.76
  82   0.4065     90.460  0.0494    98.360  500.82
  83   0.4142     90.520  0.0506    98.286  506.92
  84   0.4752     89.640  0.0517    98.234  512.99
  85   0.3939     90.540  0.0554    98.094  519.08
  86   0.4041     90.680  0.0529    98.222  525.22
  87   0.3727     91.120  0.0530    98.272  531.29
  88   0.3706     91.100  0.0489    98.336  537.39
  89   0.3716     91.180  0.0538    98.088  543.45
  90   0.4150     90.990  0.0510    98.306  549.51
