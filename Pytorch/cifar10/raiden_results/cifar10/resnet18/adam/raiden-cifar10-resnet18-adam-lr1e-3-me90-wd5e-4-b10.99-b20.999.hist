Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3077     52.200  1.5398    43.180  7.58
   2   1.1667     57.070  1.1790    57.048  13.72
   3   0.9223     68.050  1.0019    64.164  19.87
   4   0.8984     68.800  0.8424    70.262  26.00
   5   0.7714     73.200  0.7554    73.486  32.17
   6   0.7510     74.230  0.6871    75.990  38.28
   7   0.6010     79.490  0.6065    79.058  44.45
   8   0.6445     78.610  0.5565    80.878  50.58
   9   0.6420     78.700  0.5213    82.244  56.68
  10   0.5929     79.750  0.4789    83.638  62.87
  11   0.5323     81.970  0.4492    84.660  69.00
  12   0.4886     83.430  0.4315    85.042  75.14
  13   0.4408     84.760  0.4143    85.928  81.23
  14   0.4435     84.650  0.3878    86.816  87.35
  15   0.4656     84.950  0.3726    87.414  93.46
  16   0.4510     85.260  0.3616    87.682  99.66
  17   0.4241     85.950  0.3390    88.498  105.77
  18   0.4428     85.670  0.3307    88.778  111.91
  19   0.4084     86.550  0.3185    89.200  118.04
  20   0.3918     86.810  0.3172    89.356  124.15
  21   0.3976     87.270  0.3023    89.774  130.36
  22   0.3847     87.340  0.2893    90.188  136.49
  23   0.4093     87.000  0.2737    90.604  142.59
  24   0.4078     87.040  0.2753    90.598  148.73
  25   0.3480     88.960  0.2629    91.112  154.88
  26   0.3593     88.390  0.2593    91.234  161.04
  27   0.4039     87.410  0.2574    91.270  167.17
  28   0.3644     87.880  0.2439    91.594  173.32
  29   0.3433     89.000  0.2455    91.714  179.50
  30   0.4031     86.640  0.2356    91.920  185.65
  31   0.4030     87.610  0.2358    91.916  191.79
  32   0.3254     89.280  0.2357    92.044  197.96
  33   0.3644     88.660  0.2324    92.176  204.10
  34   0.3640     88.290  0.2195    92.492  210.20
  35   0.3418     89.280  0.2163    92.638  216.35
  36   0.3294     89.440  0.2045    93.004  222.50
  37   0.3405     88.810  0.2071    92.912  228.72
  38   0.3446     89.310  0.2083    92.850  234.83
  39   0.3235     89.860  0.2003    93.224  240.96
  40   0.3333     89.550  0.2002    93.032  247.08
  41   0.3596     89.090  0.1988    93.204  253.19
  42   0.3577     88.990  0.1942    93.314  259.39
  43   0.3459     88.890  0.1940    93.376  265.53
  44   0.3163     89.830  0.1864    93.568  271.64
  45   0.3293     89.680  0.1917    93.476  277.76
  46   0.3468     89.380  0.1826    93.696  283.90
  47   0.3368     89.650  0.1809    93.768  290.02
  48   0.3316     89.720  0.1783    93.904  296.18
  49   0.3231     89.980  0.1840    93.678  302.29
  50   0.3262     89.820  0.1835    93.618  308.38
  51   0.3009     90.200  0.1777    93.988  314.48
  52   0.3267     89.390  0.1706    94.110  320.57
  53   0.2980     90.650  0.1737    94.080  326.68
  54   0.3084     90.360  0.1738    94.030  332.85
  55   0.3146     90.140  0.1642    94.390  338.95
  56   0.3392     89.520  0.1657    94.348  345.11
  57   0.3181     90.150  0.1754    93.954  351.29
  58   0.3072     90.050  0.1690    94.184  357.43
  59   0.3304     89.840  0.1685    94.310  363.51
  60   0.3333     89.840  0.1569    94.652  369.67
  61   0.3271     89.860  0.1628    94.412  375.76
  62   0.3309     90.010  0.1625    94.468  381.89
  63   0.3296     89.740  0.1632    94.472  387.97
  64   0.3268     90.270  0.1643    94.390  394.12
  65   0.3298     90.060  0.1602    94.456  400.21
  66   0.3514     89.580  0.1622    94.448  406.42
  67   0.3263     90.410  0.1602    94.566  412.51
  68   0.3211     90.290  0.1588    94.494  418.65
  69   0.3222     90.310  0.1523    94.828  424.80
  70   0.3241     90.150  0.1544    94.744  430.95
  71   0.3666     89.460  0.1531    94.874  437.14
  72   0.3387     90.330  0.1506    94.780  443.25
  73   0.3376     89.730  0.1520    94.670  449.39
  74   0.3376     90.110  0.1556    94.692  455.53
  75   0.3209     90.220  0.1553    94.748  461.69
  76   0.3292     90.200  0.1476    94.976  467.83
  77   0.3432     89.980  0.1493    94.862  474.00
  78   0.3232     90.100  0.1496    94.784  480.15
  79   0.3214     90.100  0.1482    94.838  486.30
  80   0.3205     90.440  0.1465    94.938  492.50
  81   0.3131     90.400  0.1522    94.732  498.67
  82   0.3342     90.140  0.1406    95.120  504.92
  83   0.3130     90.230  0.1488    94.934  511.06
  84   0.3144     90.530  0.1473    94.924  517.21
  85   0.3448     90.350  0.1338    95.378  523.35
  86   0.3148     90.600  0.1479    95.008  529.43
  87   0.3706     89.530  0.1453    95.000  535.62
  88   0.3239     90.360  0.1522    94.772  541.71
  89   0.3305     90.340  0.1437    95.144  547.87
  90   0.3446     90.240  0.1448    95.078  554.01
