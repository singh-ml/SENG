Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3171     51.260  1.5685    41.950  7.76
   2   1.0902     60.590  1.2062    56.200  13.88
   3   0.9675     65.760  1.0000    64.286  19.97
   4   0.8402     70.460  0.8660    69.352  26.11
   5   0.7513     73.910  0.7595    73.180  32.22
   6   0.6869     76.330  0.6615    76.860  38.41
   7   0.6374     78.060  0.5954    79.182  44.53
   8   0.6420     78.380  0.5384    81.146  50.58
   9   0.5485     81.050  0.4974    82.542  56.66
  10   0.5715     80.290  0.4626    83.858  62.74
  11   0.4955     83.160  0.4350    84.882  68.83
  12   0.5481     81.880  0.3994    86.048  74.93
  13   0.5018     83.370  0.3843    86.506  81.01
  14   0.4675     84.310  0.3580    87.564  87.11
  15   0.5011     83.720  0.3360    88.196  93.15
  16   0.4736     84.450  0.3118    89.224  99.21
  17   0.4572     85.010  0.2978    89.594  105.31
  18   0.4467     85.730  0.2787    90.302  111.37
  19   0.4249     86.320  0.2603    90.916  117.42
  20   0.4563     86.350  0.2496    91.400  123.50
  21   0.4445     86.510  0.2424    91.620  129.54
  22   0.4431     86.370  0.2297    91.900  135.59
  23   0.4210     86.860  0.2186    92.302  141.64
  24   0.4027     87.970  0.2018    93.032  147.80
  25   0.3929     87.760  0.1922    93.270  153.85
  26   0.4317     87.120  0.1820    93.718  159.90
  27   0.4233     87.300  0.1768    93.908  166.01
  28   0.4042     87.890  0.1705    93.924  172.04
  29   0.4251     88.130  0.1625    94.346  178.21
  30   0.4332     87.620  0.1552    94.544  184.27
  31   0.4309     87.720  0.1526    94.512  190.34
  32   0.4306     87.670  0.1440    94.934  196.42
  33   0.3897     88.440  0.1360    95.268  202.57
  34   0.3947     88.710  0.1345    95.292  208.68
  35   0.4080     88.700  0.1296    95.416  214.80
  36   0.4228     88.320  0.1248    95.614  220.86
  37   0.3824     89.190  0.1176    95.948  226.96
  38   0.4277     88.250  0.1164    96.000  233.05
  39   0.4035     88.820  0.1112    96.108  239.10
  40   0.4436     88.100  0.1104    96.144  245.21
  41   0.4626     87.810  0.1039    96.404  251.36
  42   0.3983     89.260  0.1054    96.258  257.42
  43   0.3930     89.710  0.0966    96.618  263.49
  44   0.4339     88.930  0.0916    96.768  269.57
  45   0.4190     88.980  0.0916    96.798  275.63
  46   0.4083     89.110  0.0896    96.846  281.76
  47   0.3849     89.940  0.0886    96.834  287.86
  48   0.3979     89.540  0.0848    97.030  293.91
  49   0.4156     88.960  0.0787    97.378  299.96
  50   0.4359     88.820  0.0816    97.184  306.04
  51   0.4368     88.780  0.0819    97.082  312.09
  52   0.4265     89.140  0.0825    97.102  318.21
  53   0.4290     88.890  0.0794    97.250  324.24
  54   0.4029     89.690  0.0770    97.274  330.30
  55   0.3962     89.870  0.0755    97.386  336.40
  56   0.3857     89.910  0.0698    97.562  342.44
  57   0.4464     89.120  0.0734    97.430  348.55
  58   0.4267     89.290  0.0721    97.472  354.61
  59   0.4127     89.220  0.0668    97.664  360.76
  60   0.4138     89.810  0.0664    97.782  366.83
  61   0.4295     89.560  0.0709    97.504  372.91
  62   0.4100     90.020  0.0630    97.810  378.97
  63   0.4225     89.590  0.0637    97.798  385.02
  64   0.4342     89.380  0.0606    97.954  391.10
  65   0.4063     90.090  0.0680    97.634  397.27
  66   0.4022     89.930  0.0634    97.894  403.35
  67   0.4132     89.640  0.0561    98.124  409.45
  68   0.4116     89.960  0.0588    97.984  415.54
  69   0.4182     89.770  0.0578    98.084  421.59
  70   0.4269     89.860  0.0581    98.008  427.72
  71   0.4138     89.940  0.0533    98.158  433.79
  72   0.4233     89.930  0.0547    98.122  439.84
  73   0.4019     90.500  0.0513    98.180  445.92
  74   0.4189     90.410  0.0526    98.218  452.02
  75   0.4324     89.800  0.0591    98.050  458.17
  76   0.4102     90.140  0.0569    98.128  464.22
  77   0.3897     90.630  0.0545    98.114  470.28
  78   0.4263     89.690  0.0499    98.324  476.35
  79   0.4273     89.930  0.0495    98.282  482.46
  80   0.4472     89.220  0.0505    98.262  488.50
  81   0.4245     90.080  0.0526    98.228  494.64
  82   0.4099     90.260  0.0495    98.320  500.72
  83   0.4070     89.960  0.0449    98.478  506.83
  84   0.4265     90.140  0.0499    98.314  512.91
  85   0.3998     90.420  0.0500    98.318  518.98
