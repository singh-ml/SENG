Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3724     50.800  1.5425    43.234  7.88
   2   1.1050     60.420  1.2005    56.448  13.99
   3   0.9364     66.370  0.9920    64.608  20.05
   4   0.8047     71.840  0.8367    70.236  26.11
   5   0.7145     75.250  0.7171    74.604  32.25
   6   0.6596     76.930  0.6386    77.410  38.31
   7   0.6038     79.060  0.5744    79.810  44.36
   8   0.5804     80.330  0.5239    81.754  50.43
   9   0.5297     81.640  0.4872    82.904  56.48
  10   0.5453     81.370  0.4509    84.232  62.54
  11   0.5205     82.820  0.4191    85.468  68.70
  12   0.5011     83.570  0.3897    86.496  74.77
  13   0.4713     83.930  0.3624    87.416  80.83
  14   0.4770     84.630  0.3477    87.972  86.88
  15   0.4651     84.780  0.3248    88.724  92.91
  16   0.4341     85.800  0.3005    89.648  99.04
  17   0.4366     86.130  0.2866    90.052  105.12
  18   0.4261     86.350  0.2706    90.596  111.21
  19   0.4417     86.010  0.2497    91.272  117.29
  20   0.4032     86.900  0.2462    91.408  123.41
  21   0.4378     86.220  0.2363    91.792  129.56
  22   0.4117     87.210  0.2193    92.332  135.61
  23   0.4097     86.820  0.2072    92.796  141.68
  24   0.4033     87.380  0.1979    93.184  147.72
  25   0.4234     86.890  0.1981    93.056  153.80
  26   0.3900     87.560  0.1840    93.566  159.88
  27   0.4103     87.320  0.1767    93.806  166.05
  28   0.3973     88.240  0.1700    93.904  172.13
  29   0.3932     88.590  0.1616    94.368  178.21
  30   0.3855     88.660  0.1479    94.780  184.28
  31   0.4089     88.180  0.1476    94.768  190.35
  32   0.4019     88.190  0.1392    95.166  196.45
  33   0.4101     88.410  0.1369    95.238  202.56
  34   0.4127     87.900  0.1327    95.308  208.65
  35   0.4020     87.880  0.1295    95.398  214.70
  36   0.3929     88.570  0.1187    95.874  220.76
  37   0.3938     89.110  0.1107    96.172  226.83
  38   0.4082     88.620  0.1102    96.156  232.95
  39   0.4155     88.610  0.1058    96.274  239.07
  40   0.4265     88.550  0.1154    95.946  245.14
  41   0.3678     89.660  0.1074    96.264  251.18
  42   0.3860     88.880  0.0991    96.568  257.24
  43   0.4055     89.330  0.0958    96.678  263.30
  44   0.4238     88.640  0.0958    96.658  269.45
  45   0.4024     89.310  0.0935    96.744  275.48
  46   0.4073     89.160  0.0893    96.944  281.55
  47   0.4063     89.110  0.0841    97.076  287.65
  48   0.4309     88.660  0.0821    97.160  293.71
  49   0.4487     87.890  0.0838    97.136  299.82
  50   0.4298     89.070  0.0883    96.900  305.93
  51   0.3861     89.800  0.0731    97.438  311.97
  52   0.4124     89.170  0.0761    97.368  318.07
  53   0.4065     89.400  0.0741    97.440  324.11
  54   0.4401     89.130  0.0749    97.334  330.18
  55   0.4088     89.290  0.0752    97.422  336.22
  56   0.3818     89.940  0.0684    97.650  342.33
  57   0.4167     89.630  0.0667    97.686  348.41
  58   0.3916     89.630  0.0653    97.712  354.47
  59   0.4372     89.050  0.0614    97.958  360.55
  60   0.4774     88.700  0.0655    97.746  366.65
  61   0.3916     89.670  0.0676    97.630  372.72
  62   0.3923     89.790  0.0640    97.816  378.85
  63   0.4082     89.720  0.0629    97.836  384.90
  64   0.3947     90.070  0.0630    97.774  390.95
  65   0.4120     89.680  0.0638    97.832  397.00
  66   0.3956     90.040  0.0566    98.036  403.10
  67   0.4491     89.400  0.0567    97.964  409.26
  68   0.4000     90.320  0.0584    98.044  415.32
  69   0.4118     89.730  0.0628    97.810  421.35
  70   0.3991     90.320  0.0539    98.178  427.44
  71   0.4233     90.130  0.0500    98.324  433.50
  72   0.3882     90.270  0.0524    98.230  439.69
  73   0.4393     89.440  0.0545    98.148  445.80
  74   0.3907     89.880  0.0574    97.952  451.89
  75   0.4211     89.880  0.0525    98.232  457.98
  76   0.4036     89.690  0.0544    98.122  464.04
  77   0.3985     90.250  0.0513    98.218  470.09
  78   0.4070     90.220  0.0512    98.258  476.23
  79   0.3916     90.260  0.0519    98.194  482.28
  80   0.3898     90.310  0.0524    98.206  488.38
  81   0.4011     90.230  0.0538    98.166  494.49
  82   0.3824     90.430  0.0504    98.330  500.52
  83   0.3834     90.380  0.0459    98.470  506.65
  84   0.3994     90.040  0.0452    98.496  512.71
  85   0.3962     90.440  0.0475    98.352  518.77
  86   0.3992     90.190  0.0514    98.276  524.84
  87   0.4104     89.920  0.0473    98.380  530.91
  88   0.4076     90.320  0.0440    98.520  536.98
  89   0.4463     89.760  0.0421    98.572  543.09
  90   0.3923     90.180  0.0468    98.382  549.14
