Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4255     53.340  1.3880    48.896  7.73
   2   0.8851     68.770  0.9361    66.564  13.87
   3   0.8235     72.610  0.7310    74.396  19.95
   4   0.6267     77.890  0.6212    78.260  26.08
   5   0.5952     79.970  0.5406    81.162  32.19
   6   0.6066     80.150  0.4877    83.068  38.42
   7   0.5420     82.120  0.4439    84.600  44.56
   8   0.4856     83.850  0.4109    85.878  50.70
   9   0.4930     83.970  0.3723    87.078  56.82
  10   0.5021     83.740  0.3493    87.912  62.97
  11   0.4637     85.140  0.3253    88.754  69.14
  12   0.4878     84.390  0.3012    89.516  75.25
  13   0.5515     82.740  0.2874    90.086  81.32
  14   0.4374     85.970  0.2716    90.660  87.41
  15   0.4700     85.100  0.2583    90.998  93.54
  16   0.4907     85.470  0.2446    91.412  99.68
  17   0.4857     85.330  0.2271    92.018  105.83
  18   0.3873     88.160  0.2152    92.456  111.92
  19   0.4232     87.710  0.2085    92.816  118.05
  20   0.4383     86.450  0.1955    93.210  124.19
  21   0.3924     87.810  0.1910    93.342  130.29
  22   0.4398     87.120  0.1797    93.754  136.37
  23   0.4103     88.220  0.1737    94.020  142.56
  24   0.4196     88.450  0.1656    94.184  148.65
  25   0.3670     88.800  0.1565    94.534  154.76
  26   0.3791     89.490  0.1471    94.854  160.89
  27   0.4261     87.650  0.1458    94.842  166.95
  28   0.4328     87.880  0.1377    95.160  173.11
  29   0.4130     87.900  0.1366    95.186  179.19
  30   0.3667     90.160  0.1300    95.486  185.29
  31   0.4442     87.560  0.1253    95.688  191.36
  32   0.3947     89.290  0.1201    95.690  197.50
  33   0.4414     87.840  0.1180    95.880  203.65
  34   0.4493     88.210  0.1113    96.134  209.75
  35   0.4455     88.650  0.1091    96.184  215.87
  36   0.4564     88.210  0.1116    96.050  221.95
  37   0.3612     90.000  0.1014    96.474  228.08
  38   0.3613     90.230  0.1016    96.532  234.19
  39   0.4222     89.210  0.0994    96.552  240.37
  40   0.4236     88.680  0.0992    96.570  246.45
  41   0.3635     90.620  0.0930    96.846  252.54
  42   0.4046     89.760  0.0925    96.752  258.63
  43   0.3884     90.520  0.0868    96.968  264.76
  44   0.4113     89.490  0.0932    96.772  270.94
  45   0.4660     88.740  0.0859    96.938  277.00
  46   0.4133     89.870  0.0809    97.164  283.09
  47   0.4692     89.220  0.0801    97.200  289.18
  48   0.4216     89.480  0.0802    97.254  295.28
  49   0.3459     91.280  0.0809    97.188  301.39
  50   0.4217     89.330  0.0773    97.318  307.55
  51   0.3729     90.190  0.0777    97.326  313.64
  52   0.3853     90.470  0.0734    97.498  319.73
  53   0.3804     90.730  0.0708    97.570  325.82
  54   0.4871     88.710  0.0727    97.546  331.92
  55   0.3543     90.820  0.0715    97.540  338.01
  56   0.4276     89.440  0.0707    97.584  344.16
  57   0.3880     90.160  0.0703    97.610  350.24
  58   0.3757     91.060  0.0659    97.704  356.36
  59   0.3535     91.210  0.0655    97.724  362.49
  60   0.3931     90.200  0.0655    97.730  368.57
  61   0.3972     90.460  0.0664    97.680  374.69
  62   0.3675     91.100  0.0677    97.702  380.87
  63   0.4304     89.740  0.0600    97.890  386.98
  64   0.3596     90.780  0.0658    97.746  393.12
  65   0.3972     89.990  0.0633    97.728  399.19
  66   0.3523     91.310  0.0595    97.990  405.31
  67   0.4009     90.690  0.0639    97.756  411.40
  68   0.3858     90.630  0.0609    97.900  417.58
  69   0.4444     89.980  0.0611    97.882  423.68
  70   0.3899     90.770  0.0575    98.050  429.79
  71   0.4491     89.700  0.0609    97.954  435.91
  72   0.4138     90.560  0.0582    97.938  442.02
  73   0.3768     91.270  0.0560    98.074  448.10
  74   0.4157     90.380  0.0560    98.044  454.26
  75   0.3661     91.130  0.0554    98.118  460.34
  76   0.3730     91.000  0.0580    98.008  466.44
  77   0.4301     89.540  0.0519    98.242  472.58
  78   0.3950     90.780  0.0529    98.134  478.66
  79   0.3988     90.820  0.0577    98.038  484.78
  80   0.3785     90.890  0.0557    98.154  490.92
  81   0.4162     90.310  0.0538    98.106  497.00
  82   0.4164     90.320  0.0504    98.316  503.13
  83   0.4097     90.370  0.0553    98.084  509.22
  84   0.3667     91.060  0.0539    98.170  515.36
  85   0.3831     90.780  0.0531    98.182  521.43
