Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2516     55.320  1.4611    46.142  7.67
   2   1.0027     64.420  1.0586    62.084  13.73
   3   0.8789     69.410  0.8697    68.984  19.78
   4   0.7148     75.370  0.7547    73.272  25.92
   5   0.6560     77.180  0.6649    76.852  31.98
   6   0.6373     78.200  0.5810    79.876  38.05
   7   0.5720     80.880  0.5298    81.614  44.17
   8   0.5543     81.380  0.4898    83.048  50.27
   9   0.4855     83.460  0.4587    84.302  56.44
  10   0.5160     83.450  0.4350    85.052  62.53
  11   0.4470     85.130  0.3865    86.912  68.61
  12   0.4615     85.070  0.3584    87.578  74.70
  13   0.4848     84.890  0.3354    88.484  80.76
  14   0.4414     85.790  0.3200    89.086  86.87
  15   0.4212     86.090  0.3142    89.228  92.94
  16   0.3922     87.140  0.2911    89.916  99.03
  17   0.4469     85.900  0.2767    90.300  105.11
  18   0.4035     87.190  0.2659    91.006  111.22
  19   0.3883     87.690  0.2514    91.240  117.33
  20   0.3934     87.590  0.2430    91.632  123.47
  21   0.3667     88.570  0.2252    92.128  129.57
  22   0.3869     87.950  0.2126    92.686  135.62
  23   0.3830     87.850  0.2083    92.788  141.69
  24   0.4164     87.670  0.1998    93.026  147.75
  25   0.4244     87.160  0.1963    93.056  153.91
  26   0.3793     88.420  0.1862    93.562  159.96
  27   0.4022     88.440  0.1883    93.602  166.04
  28   0.3571     89.070  0.1700    94.004  172.10
  29   0.4110     88.170  0.1682    94.240  178.15
  30   0.4044     88.470  0.1658    94.252  184.24
  31   0.3667     89.190  0.1601    94.528  190.34
  32   0.3578     89.650  0.1469    94.872  196.43
  33   0.3981     88.730  0.1534    94.694  202.52
  34   0.3921     89.130  0.1405    95.140  208.63
  35   0.3512     89.700  0.1316    95.436  214.70
  36   0.3909     89.240  0.1282    95.576  220.75
  37   0.3612     89.570  0.1333    95.368  226.97
  38   0.3647     89.470  0.1270    95.606  233.04
  39   0.3593     90.080  0.1192    95.900  239.14
  40   0.3463     89.950  0.1204    95.832  245.19
  41   0.4097     89.180  0.1091    96.288  251.23
  42   0.3589     90.020  0.1143    96.074  257.29
  43   0.3514     90.430  0.1085    96.234  263.49
  44   0.3858     89.510  0.1075    96.236  269.55
  45   0.3450     90.410  0.1093    96.264  275.62
  46   0.3570     90.310  0.1089    96.254  281.68
  47   0.3766     89.850  0.1025    96.452  287.76
  48   0.3612     90.220  0.1032    96.406  293.87
  49   0.3214     91.380  0.1014    96.464  299.99
  50   0.3654     89.970  0.0955    96.636  306.08
  51   0.3676     90.040  0.0953    96.710  312.20
  52   0.3698     90.230  0.0916    96.862  318.26
  53   0.3707     90.400  0.0896    96.824  324.34
  54   0.3407     90.700  0.0911    96.800  330.49
  55   0.3925     89.520  0.0953    96.756  336.55
  56   0.3496     90.850  0.0928    96.848  342.64
  57   0.3918     90.180  0.0853    96.936  348.72
  58   0.4100     89.600  0.0835    97.114  354.79
  59   0.3902     90.200  0.0888    96.924  360.84
  60   0.3806     89.940  0.0916    96.874  367.01
  61   0.3793     90.290  0.0820    97.086  373.10
  62   0.3737     90.240  0.0787    97.320  379.15
  63   0.3773     90.440  0.0858    97.058  385.22
  64   0.3460     90.820  0.0778    97.280  391.27
  65   0.3593     90.760  0.0781    97.336  397.34
  66   0.3521     90.900  0.0795    97.282  403.47
  67   0.3397     91.060  0.0773    97.362  409.55
  68   0.3615     90.510  0.0777    97.332  415.63
  69   0.3619     90.500  0.0798    97.222  421.65
  70   0.3677     90.950  0.0712    97.540  427.75
  71   0.3378     91.360  0.0736    97.476  433.95
  72   0.3644     90.950  0.0719    97.504  440.00
  73   0.3562     90.660  0.0755    97.426  446.08
  74   0.3759     90.800  0.0718    97.502  452.13
  75   0.3801     90.680  0.0708    97.508  458.21
  76   0.3397     91.310  0.0732    97.516  464.25
  77   0.3548     91.050  0.0712    97.552  470.35
  78   0.3458     91.110  0.0687    97.608  476.44
  79   0.3942     90.060  0.0699    97.604  482.53
  80   0.3514     91.060  0.0698    97.576  488.63
  81   0.3674     90.980  0.0664    97.714  494.71
  82   0.3646     90.930  0.0691    97.632  500.82
  83   0.3936     90.540  0.0722    97.510  506.89
  84   0.3466     91.030  0.0661    97.700  513.00
  85   0.3545     91.490  0.0594    97.926  519.04
  86   0.3617     90.930  0.0639    97.844  525.13
  87   0.3462     91.260  0.0644    97.832  531.19
  88   0.3491     91.330  0.0655    97.846  537.30
  89   0.3389     91.340  0.0680    97.690  543.40
  90   0.3630     91.320  0.0693    97.584  549.54
