Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2617     54.250  1.4798    45.204  7.64
   2   0.9890     64.770  1.0864    60.886  13.65
   3   0.8550     69.980  0.8977    68.058  19.67
   4   0.8988     70.090  0.7588    73.362  25.71
   5   0.7244     75.420  0.6915    75.898  31.73
   6   0.6782     77.120  0.5828    79.842  37.85
   7   0.6808     78.140  0.5407    81.308  43.89
   8   0.5926     80.000  0.5099    82.346  49.96
   9   0.5860     80.870  0.4751    83.490  55.98
  10   0.5193     82.740  0.4368    85.016  62.01
  11   0.5217     82.360  0.4021    86.274  68.03
  12   0.5418     82.200  0.3867    86.836  74.10
  13   0.4526     85.060  0.3586    87.784  80.18
  14   0.4478     85.230  0.3521    87.950  86.21
  15   0.4374     85.360  0.3269    88.868  92.28
  16   0.4357     86.210  0.3140    89.342  98.29
  17   0.4686     85.300  0.3044    89.628  104.38
  18   0.4270     86.270  0.2892    90.114  110.42
  19   0.3819     87.080  0.2791    90.348  116.44
  20   0.3610     88.330  0.2624    91.168  122.44
  21   0.3657     88.440  0.2553    91.398  128.46
  22   0.4179     86.830  0.2384    91.998  134.46
  23   0.3988     87.270  0.2338    91.942  140.61
  24   0.4075     87.240  0.2199    92.498  146.66
  25   0.3691     88.510  0.2184    92.528  152.72
  26   0.3769     88.530  0.2109    92.818  158.73
  27   0.3814     87.800  0.2112    92.750  164.75
  28   0.4332     86.990  0.2020    93.118  170.82
  29   0.3598     88.900  0.1968    93.314  176.86
  30   0.3529     89.120  0.1943    93.396  182.92
  31   0.3449     89.440  0.1801    93.864  188.96
  32   0.3580     88.830  0.1775    94.004  195.01
  33   0.3362     89.910  0.1700    94.202  201.07
  34   0.3714     89.070  0.1662    94.262  207.15
  35   0.3333     89.880  0.1660    94.294  213.24
  36   0.3539     89.070  0.1594    94.518  219.28
  37   0.4252     87.840  0.1503    94.848  225.33
  38   0.3514     89.730  0.1530    94.772  231.35
  39   0.3572     89.370  0.1522    94.846  237.42
  40   0.3522     89.780  0.1486    94.930  243.44
  41   0.3234     90.550  0.1477    94.944  249.49
  42   0.3549     89.770  0.1436    95.144  255.55
  43   0.3262     90.190  0.1418    95.210  261.64
  44   0.3246     90.340  0.1412    95.192  267.65
  45   0.3674     89.910  0.1310    95.596  273.77
  46   0.3406     90.090  0.1315    95.590  279.79
  47   0.3343     90.240  0.1338    95.450  285.83
  48   0.3332     90.450  0.1313    95.552  291.88
  49   0.3629     90.020  0.1196    95.916  297.91
  50   0.3658     89.750  0.1302    95.662  304.02
  51   0.3301     90.520  0.1356    95.276  310.07
  52   0.3411     90.480  0.1227    95.856  316.10
  53   0.3636     89.770  0.1154    96.038  322.16
  54   0.3575     89.660  0.1171    95.946  328.17
  55   0.3312     90.690  0.1152    96.114  334.23
  56   0.3589     90.220  0.1093    96.292  340.31
  57   0.3564     90.360  0.1122    96.158  346.35
  58   0.3300     90.840  0.1106    96.296  352.40
  59   0.3662     89.900  0.1134    96.108  358.46
  60   0.3509     90.710  0.1172    95.984  364.47
  61   0.3599     90.380  0.1073    96.358  370.49
  62   0.3536     90.500  0.1048    96.470  376.57
  63   0.3554     90.590  0.1018    96.528  382.57
  64   0.3682     90.690  0.1044    96.462  388.66
  65   0.3427     90.950  0.1089    96.268  394.74
  66   0.3846     90.180  0.0985    96.628  400.81
  67   0.3628     89.980  0.1080    96.300  406.83
  68   0.3303     91.020  0.1072    96.380  412.91
  69   0.3402     91.130  0.0974    96.690  418.94
  70   0.3508     90.820  0.0934    96.918  424.99
  71   0.3599     90.250  0.0993    96.660  431.00
  72   0.3472     90.920  0.0953    96.770  437.02
  73   0.3592     90.280  0.0928    96.830  443.03
  74   0.3722     90.080  0.1009    96.612  449.15
  75   0.3472     90.330  0.1035    96.432  455.18
  76   0.3526     90.340  0.0974    96.802  461.20
  77   0.3427     90.660  0.0918    96.886  467.27
  78   0.3598     90.650  0.0918    96.816  473.33
  79   0.3394     90.890  0.0951    96.756  479.43
  80   0.3414     90.950  0.0916    96.906  485.43
  81   0.3494     90.710  0.0923    96.842  491.48
  82   0.3401     91.090  0.0936    96.822  497.49
  83   0.3462     90.530  0.0945    96.792  503.54
  84   0.3362     91.030  0.1006    96.594  509.60
  85   0.3599     90.180  0.0926    96.870  515.69
  86   0.3211     90.970  0.0921    96.954  521.73
  87   0.3352     90.990  0.0874    97.090  527.74
  88   0.3274     91.320  0.0882    97.074  533.84
  89   0.3488     90.890  0.0842    97.128  539.88
  90   0.3638     90.810  0.0850    97.190  545.95
