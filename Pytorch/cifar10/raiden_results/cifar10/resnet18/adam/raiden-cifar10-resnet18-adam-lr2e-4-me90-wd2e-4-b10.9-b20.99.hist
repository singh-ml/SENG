Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3148     53.930  1.4776    45.518  7.78
   2   0.9733     65.320  1.0588    61.756  13.98
   3   0.9710     66.130  0.8588    69.456  20.18
   4   0.7857     72.350  0.7268    74.386  26.39
   5   0.7358     75.650  0.6428    77.540  32.59
   6   0.6134     79.160  0.5779    79.826  38.88
   7   0.7060     76.650  0.5254    81.606  45.08
   8   0.6810     77.580  0.4826    83.174  51.31
   9   0.6068     79.630  0.4457    84.542  57.51
  10   0.5890     81.410  0.4100    85.638  63.71
  11   0.5089     82.740  0.3833    86.674  69.94
  12   0.5603     81.990  0.3651    87.292  76.12
  13   0.4976     83.290  0.3388    88.170  82.34
  14   0.5502     82.930  0.3212    88.980  88.55
  15   0.4926     84.420  0.3021    89.472  94.76
  16   0.5995     81.630  0.2885    90.146  100.95
  17   0.4795     85.360  0.2705    90.534  107.18
  18   0.4935     85.160  0.2545    91.138  113.36
  19   0.4450     86.280  0.2428    91.472  119.54
  20   0.5055     84.680  0.2258    92.220  125.76
  21   0.4989     84.370  0.2188    92.484  131.96
  22   0.4497     86.160  0.2087    92.610  138.16
  23   0.3912     87.530  0.1998    92.964  144.43
  24   0.4407     86.420  0.1859    93.510  150.64
  25   0.5620     84.240  0.1769    93.716  156.84
  26   0.4762     85.960  0.1763    93.772  163.06
  27   0.4161     87.480  0.1664    94.252  169.29
  28   0.4147     87.600  0.1612    94.368  175.48
  29   0.4113     87.960  0.1471    94.828  181.77
  30   0.4420     87.480  0.1434    94.962  187.97
  31   0.4283     87.230  0.1383    95.266  194.14
  32   0.4016     88.340  0.1376    95.174  200.36
  33   0.4901     86.630  0.1250    95.634  206.61
  34   0.5660     85.060  0.1264    95.504  212.83
  35   0.5025     87.070  0.1204    95.820  219.10
  36   0.4564     87.430  0.1141    96.062  225.33
  37   0.4895     87.360  0.1141    96.040  231.57
  38   0.4688     87.310  0.1056    96.320  237.80
  39   0.4363     88.430  0.1040    96.332  244.01
  40   0.4551     88.190  0.1007    96.536  250.33
  41   0.4161     88.790  0.0968    96.656  256.55
  42   0.4669     87.580  0.0969    96.560  262.73
  43   0.4510     87.900  0.0898    96.846  268.90
  44   0.4458     88.730  0.0916    96.802  275.13
  45   0.4801     87.930  0.0899    96.888  281.44
  46   0.4807     87.490  0.0852    97.102  287.64
  47   0.4643     87.970  0.0866    96.952  293.84
  48   0.4802     88.280  0.0855    97.002  300.07
  49   0.4986     87.390  0.0791    97.252  306.25
  50   0.4511     88.540  0.0738    97.440  312.42
  51   0.5231     87.670  0.0777    97.302  318.73
  52   0.3993     89.400  0.0761    97.352  324.92
  53   0.4728     88.420  0.0730    97.542  331.11
  54   0.4509     88.710  0.0687    97.642  337.32
  55   0.5062     87.910  0.0728    97.462  343.53
  56   0.5056     88.220  0.0685    97.630  349.79
  57   0.4196     89.390  0.0672    97.610  356.00
  58   0.4623     88.470  0.0655    97.766  362.23
  59   0.4504     88.580  0.0645    97.800  368.50
  60   0.5283     87.870  0.0649    97.750  374.72
  61   0.4663     88.900  0.0659    97.746  380.96
  62   0.4550     89.440  0.0595    97.986  387.18
  63   0.4804     88.920  0.0621    97.866  393.44
  64   0.4105     89.680  0.0594    97.958  399.65
  65   0.4092     89.730  0.0624    97.856  405.84
  66   0.5091     88.120  0.0562    98.080  412.08
  67   0.5088     88.070  0.0592    97.958  418.35
  68   0.4235     89.530  0.0598    97.968  424.60
  69   0.4470     89.600  0.0545    98.102  430.87
  70   0.4192     89.930  0.0534    98.136  437.10
  71   0.4240     89.010  0.0580    98.012  443.29
  72   0.4589     89.070  0.0519    98.208  449.48
  73   0.4476     89.170  0.0528    98.164  455.65
  74   0.4451     89.570  0.0546    98.134  461.84
  75   0.4432     88.790  0.0530    98.148  468.09
  76   0.4375     89.580  0.0510    98.246  474.26
  77   0.4558     89.470  0.0503    98.290  480.45
  78   0.4811     88.940  0.0491    98.354  486.67
  79   0.4176     90.160  0.0494    98.280  492.87
  80   0.4472     89.520  0.0510    98.230  499.14
  81   0.5113     88.470  0.0466    98.416  505.33
  82   0.4271     90.100  0.0510    98.244  511.51
  83   0.4661     89.500  0.0451    98.440  517.71
  84   0.4297     89.890  0.0496    98.248  523.93
  85   0.4194     89.910  0.0480    98.352  530.22
  86   0.4377     90.000  0.0465    98.398  536.41
  87   0.4683     89.430  0.0466    98.418  542.59
  88   0.4292     90.220  0.0448    98.464  548.79
  89   0.4614     89.480  0.0462    98.456  555.01
  90   0.4225     90.170  0.0418    98.560  561.21
