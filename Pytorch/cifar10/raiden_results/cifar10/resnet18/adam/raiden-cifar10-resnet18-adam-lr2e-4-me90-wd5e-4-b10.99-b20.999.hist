Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3211     51.710  1.5525    42.582  7.57
   2   1.0955     60.810  1.1829    57.244  13.65
   3   0.9674     66.210  0.9860    64.640  19.78
   4   0.8360     70.230  0.8519    69.502  25.83
   5   0.7376     74.020  0.7486    73.532  31.92
   6   0.6820     76.280  0.6592    76.748  37.96
   7   0.6113     78.400  0.5929    79.224  44.00
   8   0.6129     79.100  0.5479    80.854  50.05
   9   0.5476     80.990  0.5001    82.614  56.14
  10   0.5503     81.380  0.4672    83.718  62.20
  11   0.5458     81.630  0.4387    84.738  68.30
  12   0.4894     83.350  0.4092    85.824  74.34
  13   0.4995     82.950  0.3818    86.738  80.43
  14   0.5521     81.920  0.3601    87.498  86.47
  15   0.5014     83.390  0.3360    88.418  92.58
  16   0.5290     82.960  0.3226    88.944  98.66
  17   0.4663     84.880  0.3124    89.148  104.73
  18   0.4172     85.940  0.2856    90.036  110.77
  19   0.4764     85.340  0.2712    90.620  116.86
  20   0.4338     85.610  0.2647    90.870  122.90
  21   0.4640     85.590  0.2476    91.420  129.04
  22   0.4094     86.700  0.2325    91.928  135.07
  23   0.5112     84.380  0.2259    92.086  141.14
  24   0.4120     86.840  0.2270    92.178  147.21
  25   0.4442     86.270  0.2120    92.712  153.24
  26   0.4141     86.870  0.1987    93.026  159.36
  27   0.4134     87.300  0.1931    93.264  165.39
  28   0.3905     87.940  0.1918    93.334  171.45
  29   0.4519     86.140  0.1834    93.664  177.49
  30   0.3932     87.860  0.1760    93.938  183.56
  31   0.4064     88.110  0.1631    94.382  189.61
  32   0.3969     88.060  0.1592    94.594  195.71
  33   0.3780     88.280  0.1511    94.726  201.76
  34   0.4075     87.830  0.1464    94.966  207.79
  35   0.4264     87.270  0.1470    94.922  213.87
  36   0.3990     87.580  0.1398    95.134  219.93
  37   0.3916     88.330  0.1322    95.436  226.10
  38   0.3755     88.930  0.1335    95.408  232.20
  39   0.4052     88.090  0.1248    95.686  238.24
  40   0.3853     88.440  0.1262    95.728  244.27
  41   0.3990     88.430  0.1143    96.182  250.33
  42   0.4152     88.640  0.1115    96.204  256.46
  43   0.3957     88.660  0.1166    96.030  262.51
  44   0.3818     89.070  0.1094    96.292  268.59
  45   0.4052     88.220  0.1043    96.440  274.64
  46   0.3634     89.630  0.0986    96.576  280.72
  47   0.4170     88.860  0.0890    96.964  286.78
  48   0.3988     88.940  0.0989    96.690  292.87
  49   0.3911     89.290  0.1011    96.444  298.91
  50   0.4084     88.680  0.0934    96.784  304.98
  51   0.4124     89.120  0.0909    96.952  311.03
  52   0.4103     89.120  0.0860    97.044  317.06
  53   0.4112     88.960  0.0846    97.058  323.23
  54   0.4296     88.670  0.0915    96.794  329.29
  55   0.3923     89.070  0.0932    96.794  335.34
  56   0.3944     89.200  0.0871    97.044  341.41
  57   0.3942     89.800  0.0786    97.336  347.44
  58   0.3992     89.140  0.0779    97.388  353.52
  59   0.4095     89.310  0.0878    97.050  359.67
  60   0.4041     89.490  0.0790    97.314  365.71
  61   0.3720     89.980  0.0743    97.550  371.81
  62   0.4185     89.020  0.0791    97.244  377.85
  63   0.3861     89.910  0.0771    97.404  383.92
  64   0.3808     89.700  0.0820    97.188  389.95
  65   0.3891     89.540  0.0765    97.520  396.05
  66   0.3885     89.710  0.0774    97.420  402.12
  67   0.3956     89.450  0.0726    97.550  408.23
  68   0.3767     90.230  0.0733    97.538  414.32
  69   0.3939     89.820  0.0704    97.602  420.42
  70   0.4117     89.600  0.0728    97.556  426.46
  71   0.3793     90.330  0.0673    97.762  432.62
  72   0.3835     89.940  0.0662    97.732  438.70
  73   0.3849     90.400  0.0663    97.722  444.79
  74   0.3863     90.090  0.0637    97.912  450.87
  75   0.3642     90.140  0.0688    97.628  456.92
  76   0.4247     88.890  0.0659    97.780  462.97
  77   0.3708     90.440  0.0685    97.686  469.11
  78   0.4030     89.630  0.0646    97.842  475.16
  79   0.3675     90.110  0.0621    97.948  481.24
  80   0.3741     89.960  0.0627    97.908  487.33
  81   0.3556     90.530  0.0626    97.916  493.36
  82   0.3698     90.380  0.0590    98.034  499.44
  83   0.3882     89.580  0.0622    97.908  505.50
  84   0.3520     90.840  0.0624    97.928  511.55
  85   0.3705     90.590  0.0535    98.214  517.64
  86   0.3839     90.570  0.0582    98.002  523.69
  87   0.3946     90.020  0.0618    97.938  529.75
  88   0.3828     90.330  0.0607    97.992  535.88
  89   0.3759     90.630  0.0538    98.176  541.92
  90   0.3923     90.020  0.0568    98.128  547.99
