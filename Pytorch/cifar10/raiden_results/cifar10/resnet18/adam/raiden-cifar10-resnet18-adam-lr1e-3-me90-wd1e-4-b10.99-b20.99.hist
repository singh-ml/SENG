Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3252     50.680  1.5430    42.658  7.66
   2   1.1341     58.830  1.1926    56.466  13.74
   3   1.1087     62.930  1.0031    64.198  19.82
   4   0.8623     69.810  0.8619    69.282  25.95
   5   0.7941     73.010  0.7307    74.350  32.03
   6   0.6575     77.400  0.6354    77.794  38.10
   7   0.5730     80.810  0.5571    80.630  44.21
   8   0.5623     80.910  0.5195    82.006  50.29
   9   0.5481     81.130  0.4807    83.308  56.40
  10   0.4897     83.010  0.4357    85.004  62.50
  11   0.5183     83.160  0.4099    85.876  68.56
  12   0.4864     84.040  0.3838    86.772  74.64
  13   0.4640     84.490  0.3537    87.790  80.73
  14   0.4375     85.530  0.3303    88.592  86.82
  15   0.4210     85.540  0.3095    89.220  92.94
  16   0.3925     87.540  0.3004    89.490  99.01
  17   0.4110     87.190  0.2768    90.430  105.14
  18   0.4212     86.790  0.2614    91.000  111.23
  19   0.4099     87.390  0.2499    91.372  117.30
  20   0.4089     86.390  0.2403    91.662  123.39
  21   0.4162     87.090  0.2362    91.828  129.54
  22   0.3915     88.180  0.2304    92.012  135.63
  23   0.3465     89.190  0.2115    92.580  141.69
  24   0.3585     88.970  0.2009    92.994  147.76
  25   0.3567     88.820  0.1954    93.154  153.88
  26   0.3861     88.270  0.1816    93.736  159.98
  27   0.3581     89.510  0.1775    93.824  166.12
  28   0.3720     88.890  0.1676    94.176  172.21
  29   0.3977     88.770  0.1687    94.158  178.29
  30   0.3691     89.420  0.1570    94.546  184.37
  31   0.3862     88.580  0.1532    94.604  190.43
  32   0.3556     89.760  0.1440    95.002  196.50
  33   0.3352     89.980  0.1411    94.898  202.63
  34   0.3493     89.660  0.1440    94.942  208.72
  35   0.4029     89.680  0.1398    95.150  214.79
  36   0.4004     88.820  0.1414    95.044  220.85
  37   0.3400     90.490  0.1387    95.206  226.93
  38   0.3390     90.000  0.1349    95.320  233.02
  39   0.3584     90.290  0.1270    95.508  239.16
  40   0.3855     90.050  0.1243    95.752  245.24
  41   0.3306     90.790  0.1174    95.972  251.35
  42   0.3644     90.280  0.1168    95.938  257.46
  43   0.3409     90.760  0.1191    95.852  263.57
  44   0.3926     89.980  0.1060    96.312  269.65
  45   0.3599     90.160  0.1145    95.988  275.81
  46   0.3561     90.380  0.1032    96.356  281.90
  47   0.3670     90.050  0.1022    96.346  288.02
  48   0.3698     89.810  0.1078    96.332  294.10
  49   0.3470     90.600  0.1081    96.308  300.15
  50   0.3546     90.700  0.0999    96.456  306.25
  51   0.3224     91.100  0.0992    96.566  312.35
  52   0.3485     90.330  0.0965    96.670  318.47
  53   0.3413     91.180  0.0943    96.742  324.59
  54   0.3336     90.890  0.0931    96.814  330.68
  55   0.3706     90.200  0.0874    96.910  336.75
  56   0.3984     90.350  0.0939    96.598  342.81
  57   0.3347     91.290  0.0930    96.838  348.96
  58   0.3988     89.760  0.0952    96.708  355.02
  59   0.3854     90.540  0.0918    96.818  361.12
  60   0.3573     90.800  0.0930    96.718  367.18
  61   0.3823     90.570  0.0930    96.754  373.24
  62   0.3885     90.810  0.0832    97.048  379.33
  63   0.3901     90.610  0.0872    96.928  385.51
  64   0.3662     90.510  0.0899    96.816  391.61
  65   0.3828     90.560  0.0831    97.136  397.67
  66   0.3464     91.170  0.0858    97.020  403.71
  67   0.3681     90.790  0.0871    97.016  409.80
  68   0.3825     91.020  0.0856    97.024  415.89
  69   0.3866     90.440  0.0835    97.160  421.99
  70   0.3343     91.290  0.0835    97.166  428.09
  71   0.3664     91.190  0.0809    97.228  434.18
  72   0.3789     90.900  0.0759    97.472  440.29
  73   0.4059     90.370  0.0831    97.128  446.38
  74   0.3688     90.840  0.0813    97.202  452.46
  75   0.3379     91.420  0.0861    97.090  458.62
  76   0.3475     90.910  0.0817    97.158  464.67
  77   0.3755     90.330  0.0840    97.128  470.74
  78   0.3356     91.330  0.0798    97.230  476.85
  79   0.3551     91.000  0.0752    97.430  482.97
  80   0.3473     91.200  0.0749    97.498  489.11
  81   0.3751     90.880  0.0812    97.180  495.17
  82   0.3777     90.870  0.0803    97.200  501.29
  83   0.3729     90.840  0.0757    97.434  507.34
  84   0.3600     90.780  0.0748    97.322  513.44
  85   0.4007     90.300  0.0758    97.374  519.52
  86   0.3935     90.800  0.0749    97.396  525.63
  87   0.3955     90.710  0.0735    97.456  531.70
  88   0.3383     91.410  0.0739    97.472  537.80
  89   0.3589     91.170  0.0733    97.432  543.87
  90   0.3651     91.020  0.0769    97.262  549.97
