Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5909     39.680  1.8593    31.140  7.51
   2   1.4184     47.200  1.4815    44.906  13.60
   3   1.3129     53.480  1.2858    52.786  19.69
   4   1.1612     59.650  1.1062    60.228  25.87
   5   0.9944     65.230  0.9705    65.460  31.98
   6   0.8909     68.680  0.8779    69.136  38.05
   7   0.8490     71.110  0.8158    71.268  44.11
   8   0.8383     72.160  0.7565    73.142  50.18
   9   0.8523     71.490  0.7086    75.302  56.32
  10   0.6910     76.140  0.6619    76.874  62.40
  11   0.6891     76.260  0.6330    77.954  68.47
  12   0.6410     77.770  0.6086    79.006  74.54
  13   0.6260     78.910  0.5858    79.730  80.61
  14   0.7537     74.480  0.5732    80.258  86.68
  15   0.6532     77.900  0.5773    80.114  92.84
  16   0.5878     79.860  0.5571    80.932  98.91
  17   0.6464     78.750  0.5408    81.320  104.98
  18   0.6066     80.040  0.5268    81.784  111.12
  19   0.5791     80.430  0.5295    81.702  117.22
  20   0.6005     80.120  0.5223    82.052  123.29
  21   0.5958     80.100  0.5102    82.530  129.37
  22   0.5843     80.080  0.5013    82.724  135.43
  23   0.5855     80.600  0.4984    82.940  141.53
  24   0.5359     81.710  0.4917    83.162  147.64
  25   0.5641     80.850  0.4932    83.064  153.73
  26   0.6114     80.010  0.4899    83.202  159.84
  27   0.5580     80.750  0.4813    83.498  165.99
  28   0.5339     81.940  0.4847    83.460  172.09
  29   0.5498     81.070  0.4800    83.418  178.17
  30   0.5849     80.240  0.4767    83.686  184.24
  31   0.5115     82.990  0.4704    83.796  190.34
  32   0.5948     80.120  0.4582    84.272  196.40
  33   0.6156     80.060  0.4716    83.954  202.56
  34   0.5291     81.740  0.4691    84.084  208.67
  35   0.4987     83.420  0.4654    84.136  214.74
  36   0.5733     81.080  0.4587    84.300  220.79
  37   0.5240     82.640  0.4507    84.526  226.86
  38   0.5726     81.300  0.4455    84.726  233.05
  39   0.5468     81.660  0.4514    84.638  239.12
  40   0.4993     83.380  0.4521    84.376  245.18
  41   0.5473     81.550  0.4466    84.642  251.23
  42   0.5474     81.950  0.4477    84.790  257.35
  43   0.4893     83.510  0.4498    84.586  263.50
  44   0.5218     82.020  0.4410    84.876  269.66
  45   0.5343     82.360  0.4348    85.078  275.74
  46   0.5124     82.640  0.4451    84.666  281.81
  47   0.5016     83.500  0.4325    85.108  287.93
  48   0.5171     82.410  0.4385    84.872  294.00
  49   0.5025     82.990  0.4406    84.932  300.10
  50   0.5376     81.760  0.4296    85.330  306.23
  51   0.4805     83.300  0.4332    85.206  312.31
  52   0.5082     82.800  0.4288    85.252  318.40
  53   0.5102     82.880  0.4309    85.074  324.45
  54   0.5346     82.110  0.4335    85.236  330.50
  55   0.5449     82.230  0.4321    85.070  336.58
  56   0.5096     83.410  0.4299    85.380  342.68
  57   0.5407     81.810  0.4309    85.120  348.78
  58   0.5110     82.700  0.4302    85.178  354.85
  59   0.5094     82.870  0.4308    85.298  360.92
  60   0.5109     82.970  0.4276    85.364  367.02
  61   0.5072     83.040  0.4326    85.220  373.14
  62   0.5583     81.710  0.4284    85.220  379.26
  63   0.4830     83.450  0.4282    85.332  385.36
  64   0.5137     83.430  0.4193    85.398  391.47
  65   0.5109     83.010  0.4237    85.590  397.58
  66   0.6084     79.850  0.4201    85.574  403.70
  67   0.6001     79.810  0.4178    85.760  409.78
  68   0.5124     82.790  0.4262    85.258  415.94
  69   0.4750     83.460  0.4236    85.616  422.06
  70   0.4974     82.980  0.4148    85.826  428.18
  71   0.4960     83.370  0.4274    85.352  434.27
  72   0.5250     82.430  0.4238    85.408  440.34
  73   0.4895     83.530  0.4202    85.622  446.40
  74   0.4944     82.670  0.4186    85.680  452.57
  75   0.4979     83.120  0.4091    86.006  458.65
  76   0.4463     84.530  0.4186    85.554  464.72
  77   0.4989     83.300  0.4167    85.666  470.78
  78   0.6438     79.700  0.4134    85.882  476.87
  79   0.5027     83.190  0.4142    85.766  482.98
  80   0.5008     83.690  0.4097    85.958  489.12
  81   0.5482     82.350  0.4108    85.812  495.27
  82   0.4931     83.780  0.4224    85.546  501.33
  83   0.5511     81.680  0.4096    85.896  507.40
  84   0.5791     80.720  0.4077    85.836  513.51
  85   0.5056     82.800  0.4192    85.664  519.58
  86   0.5257     82.910  0.4132    85.764  525.74
  87   0.5367     82.310  0.4147    85.716  531.81
  88   0.4734     84.410  0.4125    85.896  537.93
  89   0.5417     82.340  0.4049    85.956  544.04
  90   0.4975     82.840  0.4071    86.062  550.12
