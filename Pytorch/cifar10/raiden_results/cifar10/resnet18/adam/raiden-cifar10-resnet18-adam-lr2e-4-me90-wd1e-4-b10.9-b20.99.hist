Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2528     55.300  1.4816    45.094  7.72
   2   1.0155     63.630  1.0678    61.592  13.92
   3   0.9035     68.890  0.8694    69.162  20.13
   4   0.7296     74.680  0.7273    74.512  26.40
   5   0.7279     74.810  0.6434    77.378  32.63
   6   0.7966     73.740  0.5816    79.854  38.81
   7   0.6022     79.630  0.5243    81.660  44.98
   8   0.5452     81.500  0.4848    83.106  51.20
   9   0.6652     78.310  0.4467    84.270  57.44
  10   0.6167     80.160  0.4192    85.462  63.70
  11   0.5940     80.680  0.3898    86.370  69.88
  12   0.5823     81.530  0.3670    87.356  76.09
  13   0.4909     83.580  0.3460    87.982  82.31
  14   0.5638     82.650  0.3229    88.780  88.50
  15   0.5301     82.790  0.3054    89.254  94.74
  16   0.4971     84.280  0.2852    90.178  100.96
  17   0.5500     83.250  0.2711    90.570  107.18
  18   0.4686     85.200  0.2584    90.930  113.37
  19   0.4397     86.240  0.2394    91.548  119.56
  20   0.4322     86.530  0.2261    92.082  125.75
  21   0.5326     84.270  0.2144    92.578  132.03
  22   0.5044     85.400  0.2023    92.986  138.23
  23   0.4583     85.960  0.1933    93.192  144.40
  24   0.4520     86.290  0.1880    93.290  150.60
  25   0.5021     85.470  0.1728    93.968  156.83
  26   0.5329     85.750  0.1661    94.030  163.08
  27   0.4160     87.860  0.1593    94.294  169.31
  28   0.4672     86.820  0.1506    94.742  175.56
  29   0.4862     86.480  0.1461    94.836  181.77
  30   0.4728     87.210  0.1388    95.072  188.01
  31   0.4837     87.150  0.1367    95.074  194.22
  32   0.4928     86.870  0.1338    95.234  200.41
  33   0.4397     88.200  0.1200    95.772  206.64
  34   0.5139     86.540  0.1179    95.944  212.86
  35   0.4715     87.630  0.1146    95.826  219.09
  36   0.4808     87.310  0.1079    96.128  225.32
  37   0.4848     87.370  0.1044    96.346  231.51
  38   0.4476     88.540  0.1013    96.364  237.77
  39   0.5248     87.200  0.0978    96.530  243.99
  40   0.4274     88.400  0.0977    96.550  250.21
  41   0.4889     87.480  0.0924    96.690  256.41
  42   0.5320     86.420  0.0879    96.900  262.59
  43   0.4733     88.380  0.0946    96.680  268.77
  44   0.5034     87.690  0.0830    97.060  275.04
  45   0.4254     89.050  0.0827    97.082  281.27
  46   0.5405     87.120  0.0820    97.120  287.45
  47   0.4397     88.990  0.0790    97.220  293.63
  48   0.4456     88.940  0.0739    97.426  299.81
  49   0.5042     87.890  0.0753    97.324  306.06
  50   0.5161     87.030  0.0740    97.378  312.25
  51   0.5284     87.320  0.0708    97.508  318.48
  52   0.4667     88.520  0.0679    97.636  324.66
  53   0.4274     89.200  0.0677    97.608  330.84
  54   0.4680     88.400  0.0629    97.826  337.01
  55   0.5353     87.060  0.0651    97.672  343.25
  56   0.4825     88.210  0.0648    97.648  349.46
  57   0.4788     88.870  0.0617    97.810  355.69
  58   0.4858     88.790  0.0586    97.912  361.92
  59   0.4352     89.360  0.0613    97.878  368.09
  60   0.5731     87.110  0.0590    97.964  374.28
  61   0.4466     89.530  0.0563    98.032  380.56
  62   0.4970     88.420  0.0577    97.986  386.79
  63   0.4871     88.700  0.0561    97.974  393.00
  64   0.4523     89.190  0.0564    97.966  399.17
  65   0.5458     88.410  0.0529    98.162  405.38
  66   0.4870     89.350  0.0524    98.174  411.56
  67   0.4759     89.330  0.0540    98.128  417.83
  68   0.4370     89.850  0.0517    98.196  424.06
  69   0.5232     88.260  0.0511    98.238  430.26
  70   0.4767     89.530  0.0491    98.280  436.49
  71   0.4523     89.720  0.0502    98.288  442.72
  72   0.4870     88.780  0.0490    98.282  448.90
  73   0.5392     88.400  0.0507    98.270  455.21
  74   0.4670     89.390  0.0468    98.450  461.41
  75   0.4592     89.520  0.0459    98.406  467.59
  76   0.5044     88.910  0.0453    98.442  473.78
  77   0.4952     88.970  0.0463    98.374  480.03
  78   0.5519     88.150  0.0447    98.434  486.26
  79   0.4617     89.930  0.0428    98.532  492.44
  80   0.5484     88.270  0.0451    98.370  498.63
  81   0.5135     88.860  0.0413    98.596  504.84
  82   0.5102     89.230  0.0420    98.594  511.03
  83   0.5226     88.520  0.0419    98.556  517.24
  84   0.4642     89.750  0.0437    98.444  523.55
  85   0.4424     90.330  0.0396    98.676  529.74
  86   0.4929     89.430  0.0426    98.520  535.94
  87   0.4930     89.290  0.0388    98.650  542.14
  88   0.4937     89.350  0.0414    98.556  548.34
  89   0.4615     90.110  0.0398    98.644  554.63
  90   0.4937     89.430  0.0364    98.744  560.88
