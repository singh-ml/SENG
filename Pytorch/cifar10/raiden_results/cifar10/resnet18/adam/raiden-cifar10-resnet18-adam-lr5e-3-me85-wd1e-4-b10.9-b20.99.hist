Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4803     44.550  1.7803    34.128  7.75
   2   1.4039     52.460  1.3415    50.968  13.90
   3   1.5469     48.660  1.0784    61.530  20.10
   4   1.2894     58.160  0.9140    67.588  26.29
   5   1.2066     59.810  0.7917    72.244  32.41
   6   0.7971     72.600  0.6856    75.950  38.53
   7   0.6689     76.930  0.6146    78.678  44.65
   8   0.6671     77.660  0.5709    80.358  50.77
   9   0.8701     74.690  0.5238    81.946  56.94
  10   0.5700     80.190  0.4952    83.030  63.05
  11   0.6526     78.750  0.4702    83.616  69.21
  12   0.5083     82.650  0.4548    84.194  75.33
  13   0.5457     81.780  0.4367    85.042  81.50
  14   0.5383     82.300  0.4235    85.492  87.76
  15   0.6595     79.570  0.4117    85.938  93.90
  16   0.5954     80.910  0.3975    86.254  100.01
  17   0.5091     82.660  0.3903    86.588  106.16
  18   0.4936     84.040  0.3821    86.850  112.33
  19   0.4585     85.160  0.3723    87.206  118.56
  20   0.6181     80.080  0.3674    87.356  124.73
  21   0.4712     85.030  0.3628    87.408  130.86
  22   0.4811     84.330  0.3595    87.718  137.01
  23   0.4864     84.250  0.3493    88.088  143.16
  24   0.4293     85.610  0.3480    88.018  149.34
  25   0.7081     79.150  0.3439    88.166  155.52
  26   0.5238     82.970  0.3419    88.192  161.70
  27   0.5846     82.300  0.3413    88.350  167.85
  28   0.5174     83.310  0.3348    88.486  174.02
  29   0.6700     79.930  0.3310    88.620  180.14
  30   0.4709     84.690  0.3277    88.584  186.36
  31   0.4705     84.470  0.3304    88.594  192.51
  32   0.4754     83.950  0.3186    88.980  198.67
  33   0.4565     84.460  0.3189    89.108  204.79
  34   0.4148     86.580  0.3181    88.806  210.90
  35   0.4492     85.240  0.3193    88.920  217.12
  36   0.4658     84.670  0.3170    88.996  223.26
  37   0.4582     84.840  0.3093    89.530  229.41
  38   0.5827     80.770  0.3146    89.066  235.56
  39   0.4714     85.020  0.3095    89.448  241.73
  40   0.4435     85.060  0.3106    89.234  247.88
  41   0.5864     82.400  0.3031    89.496  254.04
  42   0.4229     86.080  0.3046    89.518  260.16
  43   0.4736     84.670  0.2981    89.728  266.29
  44   0.4449     85.690  0.3014    89.568  272.46
  45   0.4826     84.190  0.3055    89.392  278.58
  46   0.4390     86.580  0.3039    89.562  284.72
  47   0.5062     84.360  0.2984    89.650  290.92
  48   0.5727     83.130  0.2968    89.678  297.07
  49   0.5191     83.350  0.2971    89.820  303.21
  50   0.4325     85.880  0.2984    89.680  309.38
  51   0.5468     82.440  0.2931    89.850  315.49
  52   0.4309     85.840  0.2943    89.748  321.61
  53   0.3959     87.030  0.2918    89.912  327.78
  54   0.5113     84.210  0.2871    89.964  333.94
  55   0.3967     86.740  0.2878    90.054  340.09
  56   0.4841     85.110  0.2909    90.044  346.23
  57   0.4308     85.850  0.2886    90.018  352.36
  58   0.4635     85.070  0.2836    90.276  358.54
  59   0.4799     85.140  0.2957    89.794  364.70
  60   0.5844     82.750  0.2873    90.086  370.80
  61   0.3796     87.480  0.2811    90.322  376.95
  62   0.5084     84.480  0.2834    90.262  383.13
  63   0.4430     86.130  0.2844    90.256  389.24
  64   0.3888     87.280  0.2820    90.234  395.39
  65   0.5130     83.620  0.2828    90.212  401.61
  66   0.4780     84.840  0.2829    90.242  407.76
  67   0.4203     86.370  0.2817    90.298  413.90
  68   0.5657     83.470  0.2782    90.496  420.06
  69   0.4100     86.530  0.2802    90.242  426.18
  70   0.4657     84.980  0.2791    90.460  432.32
  71   0.5722     82.920  0.2780    90.428  438.55
  72   0.3927     87.010  0.2821    90.324  444.65
  73   0.4466     85.130  0.2718    90.584  450.76
  74   0.4703     84.740  0.2759    90.424  456.90
  75   0.3690     88.280  0.2802    90.368  463.06
  76   0.4179     86.290  0.2767    90.488  469.22
  77   0.3934     86.940  0.2820    90.262  475.45
  78   0.4354     86.130  0.2725    90.612  481.68
  79   0.4114     86.960  0.2773    90.504  487.84
  80   0.4115     86.760  0.2724    90.688  493.98
  81   0.5482     83.280  0.2731    90.516  500.13
  82   0.4641     85.660  0.2766    90.458  506.35
  83   0.3713     87.770  0.2726    90.560  512.48
  84   0.4015     86.720  0.2737    90.546  518.66
  85   0.3750     87.730  0.2740    90.524  524.79
