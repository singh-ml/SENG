Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3639     51.260  1.4782    45.768  7.52
   2   1.0751     62.610  1.0748    61.448  13.60
   3   0.9133     68.510  0.8747    68.836  19.66
   4   0.7786     72.980  0.7385    73.826  25.83
   5   0.7686     74.470  0.6501    77.152  31.90
   6   0.7519     74.700  0.5844    79.632  37.97
   7   0.6861     77.120  0.5328    81.330  44.04
   8   0.5638     81.120  0.4919    82.798  50.10
   9   0.5576     81.280  0.4546    84.186  56.16
  10   0.7768     74.600  0.4188    85.440  62.32
  11   0.5782     80.890  0.3970    86.114  68.40
  12   0.5514     82.220  0.3639    87.248  74.46
  13   0.4921     83.790  0.3509    87.714  80.51
  14   0.5441     82.230  0.3227    88.692  86.61
  15   0.4810     84.450  0.3061    89.370  92.73
  16   0.5485     82.970  0.2882    89.948  98.81
  17   0.4794     84.510  0.2707    90.640  104.92
  18   0.4990     84.540  0.2516    91.254  110.99
  19   0.4698     85.570  0.2387    91.610  117.08
  20   0.4514     85.650  0.2317    91.818  123.14
  21   0.4677     85.860  0.2179    92.406  129.27
  22   0.5312     84.810  0.2103    92.740  135.32
  23   0.4725     85.810  0.1919    93.316  141.46
  24   0.5384     84.940  0.1829    93.534  147.54
  25   0.5246     84.920  0.1731    93.972  153.58
  26   0.5244     85.480  0.1692    94.196  159.68
  27   0.4988     85.930  0.1616    94.274  165.76
  28   0.4712     86.680  0.1579    94.450  171.88
  29   0.4371     87.480  0.1448    94.910  177.92
  30   0.4107     87.960  0.1403    95.040  184.04
  31   0.4926     86.710  0.1341    95.290  190.10
  32   0.4695     87.540  0.1248    95.494  196.18
  33   0.4289     88.050  0.1246    95.520  202.24
  34   0.4823     87.280  0.1152    95.896  208.33
  35   0.4287     88.230  0.1127    96.052  214.38
  36   0.5286     86.030  0.1107    96.054  220.43
  37   0.4486     87.850  0.1053    96.242  226.46
  38   0.4716     87.930  0.0956    96.616  232.55
  39   0.5076     87.380  0.0960    96.538  238.64
  40   0.5227     86.990  0.0932    96.754  244.77
  41   0.4783     88.010  0.0920    96.818  250.82
  42   0.5100     87.640  0.0882    96.904  256.88
  43   0.5152     87.240  0.0857    96.908  262.91
  44   0.4521     89.130  0.0857    96.940  268.96
  45   0.5006     87.880  0.0747    97.420  275.12
  46   0.4808     88.130  0.0756    97.408  281.20
  47   0.4898     87.980  0.0807    97.110  287.29
  48   0.5770     86.560  0.0733    97.396  293.34
  49   0.5759     86.690  0.0697    97.512  299.42
  50   0.4816     88.720  0.0677    97.564  305.53
  51   0.5972     87.240  0.0707    97.518  311.57
  52   0.4684     89.010  0.0701    97.582  317.61
  53   0.4920     88.340  0.0662    97.670  323.68
  54   0.5274     87.710  0.0615    97.908  329.71
  55   0.4970     88.320  0.0653    97.730  335.80
  56   0.5328     87.720  0.0638    97.718  341.98
  57   0.4755     89.290  0.0583    97.978  348.07
  58   0.4931     88.390  0.0586    97.962  354.15
  59   0.4585     88.850  0.0657    97.684  360.19
  60   0.4515     89.820  0.0536    98.140  366.23
  61   0.4719     89.130  0.0528    98.132  372.37
  62   0.4366     89.680  0.0535    98.170  378.41
  63   0.4805     88.910  0.0545    98.136  384.47
  64   0.4584     89.140  0.0587    97.998  390.56
  65   0.4524     89.410  0.0506    98.306  396.65
  66   0.4584     89.420  0.0529    98.144  402.74
  67   0.4722     89.120  0.0456    98.380  408.85
  68   0.4897     89.200  0.0510    98.240  414.91
  69   0.4786     89.250  0.0526    98.192  420.95
  70   0.5187     88.690  0.0533    98.134  426.99
  71   0.4338     89.760  0.0524    98.192  433.10
  72   0.4504     89.750  0.0467    98.370  439.16
  73   0.4796     89.290  0.0427    98.502  445.31
  74   0.4752     89.590  0.0499    98.328  451.40
  75   0.4751     89.460  0.0460    98.440  457.45
  76   0.4824     89.230  0.0463    98.378  463.52
  77   0.5106     89.270  0.0449    98.460  469.61
  78   0.4587     89.850  0.0412    98.564  475.71
  79   0.4516     89.900  0.0393    98.648  481.84
  80   0.4531     89.930  0.0460    98.342  487.89
  81   0.4984     88.950  0.0406    98.648  493.99
  82   0.4908     89.290  0.0450    98.534  500.06
  83   0.4764     89.450  0.0444    98.438  506.10
  84   0.4559     90.040  0.0388    98.626  512.17
  85   0.5289     88.990  0.0376    98.744  518.30
