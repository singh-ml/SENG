Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2433     54.700  1.5251    43.820  7.64
   2   1.0754     60.520  1.1604    57.790  13.84
   3   0.9458     66.540  0.9568    65.608  19.98
   4   0.8531     70.920  0.8229    70.750  26.10
   5   0.7511     73.840  0.7041    75.314  32.24
   6   0.6376     78.590  0.6283    78.024  38.42
   7   0.6164     79.600  0.5590    80.554  44.60
   8   0.5554     81.480  0.5146    82.262  50.80
   9   0.5281     82.170  0.4715    83.676  56.95
  10   0.5256     82.170  0.4401    84.852  63.08
  11   0.5917     81.130  0.4152    85.760  69.24
  12   0.4976     83.590  0.3773    86.996  75.35
  13   0.4488     85.700  0.3626    87.508  81.52
  14   0.4482     85.330  0.3466    88.222  87.76
  15   0.4197     86.260  0.3280    88.734  93.92
  16   0.4642     85.680  0.3018    89.670  100.06
  17   0.3826     87.660  0.2724    90.584  106.18
  18   0.3817     87.710  0.2658    90.934  112.32
  19   0.3989     87.560  0.2530    91.288  118.46
  20   0.4104     87.500  0.2521    91.224  124.61
  21   0.3863     87.790  0.2389    91.784  130.78
  22   0.3615     88.320  0.2321    91.940  136.90
  23   0.3793     88.480  0.2167    92.576  143.04
  24   0.3826     87.930  0.1989    93.096  149.20
  25   0.3724     88.490  0.1970    93.212  155.36
  26   0.3615     89.340  0.1907    93.392  161.61
  27   0.3525     89.260  0.1746    94.052  167.78
  28   0.3414     89.520  0.1697    94.152  173.95
  29   0.3611     88.920  0.1743    94.064  180.13
  30   0.3521     89.490  0.1613    94.424  186.30
  31   0.3590     89.150  0.1627    94.352  192.42
  32   0.3457     89.980  0.1496    94.852  198.63
  33   0.3581     89.750  0.1485    94.808  204.77
  34   0.3503     89.590  0.1436    94.952  210.94
  35   0.3306     90.200  0.1468    94.774  217.09
  36   0.3620     89.960  0.1353    95.312  223.20
  37   0.3867     89.720  0.1336    95.386  229.37
  38   0.3558     89.890  0.1270    95.656  235.55
  39   0.3426     90.220  0.1180    95.900  241.72
  40   0.3465     90.060  0.1210    95.810  247.88
  41   0.3732     89.650  0.1196    95.716  253.99
  42   0.3997     89.380  0.1240    95.652  260.16
  43   0.3470     90.090  0.1237    95.798  266.35
  44   0.3576     90.600  0.1103    96.178  272.48
  45   0.3449     90.570  0.1116    96.084  278.60
  46   0.3568     90.110  0.1100    96.182  284.73
  47   0.3566     90.520  0.1132    96.132  290.86
  48   0.3818     90.060  0.1128    96.002  297.08
  49   0.3713     90.230  0.0998    96.534  303.21
  50   0.3678     90.130  0.0973    96.634  309.42
  51   0.3412     90.540  0.1067    96.358  315.60
  52   0.4050     89.460  0.1031    96.486  321.77
  53   0.3273     91.000  0.1038    96.390  327.88
  54   0.3434     91.040  0.0960    96.670  334.05
  55   0.3432     90.930  0.0927    96.796  340.16
  56   0.3454     91.170  0.0910    96.850  346.29
  57   0.3741     90.140  0.0981    96.632  352.40
  58   0.3490     90.800  0.0922    96.810  358.52
  59   0.3147     91.810  0.0927    96.834  364.71
  60   0.3621     91.000  0.0806    97.250  370.82
  61   0.3317     91.160  0.0909    96.856  376.94
  62   0.3492     91.250  0.0865    97.030  383.08
  63   0.3705     90.590  0.0869    96.988  389.21
  64   0.3500     90.770  0.0919    96.814  395.38
  65   0.3385     91.370  0.0857    97.016  401.52
  66   0.3431     91.400  0.0819    97.188  407.62
  67   0.3573     90.820  0.0856    97.014  413.75
  68   0.3417     91.380  0.0866    97.004  419.89
  69   0.3425     91.530  0.0822    97.124  426.05
  70   0.3544     90.870  0.0844    97.110  432.29
  71   0.3352     91.480  0.0830    97.070  438.45
  72   0.3458     91.510  0.0858    97.012  444.55
  73   0.3707     90.600  0.0884    97.048  450.70
  74   0.3582     91.030  0.0809    97.230  456.87
  75   0.3491     91.340  0.0802    97.190  463.05
  76   0.3676     91.310  0.0744    97.520  469.29
  77   0.3923     90.730  0.0764    97.384  475.42
  78   0.3308     91.600  0.0813    97.200  481.59
  79   0.3520     91.220  0.0733    97.462  487.74
  80   0.3533     90.790  0.0803    97.246  493.87
  81   0.3798     90.580  0.0837    97.090  500.10
  82   0.3653     90.910  0.0833    97.096  506.25
  83   0.3520     91.610  0.0803    97.228  512.40
  84   0.3550     91.270  0.0754    97.310  518.58
  85   0.3657     91.160  0.0781    97.354  524.74
  86   0.3559     90.960  0.0755    97.374  530.89
  87   0.3597     91.300  0.0752    97.378  537.13
  88   0.3836     91.100  0.0743    97.334  543.28
  89   0.3889     90.700  0.0729    97.514  549.41
  90   0.3509     91.280  0.0736    97.452  555.53
