Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4258     49.850  1.5668    42.102  7.55
   2   1.0822     61.050  1.2014    56.660  13.66
   3   1.0120     63.540  1.0256    63.256  19.90
   4   0.9410     67.190  0.9069    67.584  26.01
   5   0.9279     68.010  0.8140    70.970  32.13
   6   0.8410     71.110  0.7437    73.830  38.24
   7   0.7168     74.810  0.6818    75.884  44.37
   8   0.7006     75.700  0.6268    78.020  50.49
   9   0.6848     76.560  0.5804    79.746  56.70
  10   0.6814     77.070  0.5452    80.760  62.81
  11   0.6751     76.750  0.5109    82.146  68.92
  12   0.6365     78.930  0.4802    83.192  75.07
  13   0.5827     80.440  0.4523    84.516  81.17
  14   0.5719     80.450  0.4307    84.988  87.36
  15   0.5844     80.340  0.4074    85.718  93.50
  16   0.6143     80.040  0.3893    86.368  99.60
  17   0.5442     82.130  0.3643    87.342  105.74
  18   0.6385     79.790  0.3477    87.814  111.85
  19   0.5502     82.780  0.3329    88.372  117.98
  20   0.5091     83.760  0.3176    88.792  124.16
  21   0.5266     83.290  0.3013    89.576  130.29
  22   0.5406     83.100  0.2855    89.924  136.41
  23   0.6066     81.290  0.2730    90.494  142.53
  24   0.5044     84.180  0.2642    90.786  148.67
  25   0.5179     84.150  0.2485    91.374  154.80
  26   0.5147     84.340  0.2400    91.626  161.00
  27   0.5163     84.810  0.2231    92.072  167.10
  28   0.5227     83.890  0.2195    92.374  173.25
  29   0.5539     83.800  0.2011    93.022  179.39
  30   0.5548     84.130  0.1965    93.112  185.52
  31   0.5626     84.200  0.1809    93.560  191.64
  32   0.5189     84.790  0.1784    93.688  197.85
  33   0.5256     85.010  0.1727    93.884  203.97
  34   0.5268     84.780  0.1626    94.214  210.10
  35   0.5009     85.500  0.1525    94.654  216.23
  36   0.5770     84.610  0.1483    94.772  222.34
  37   0.5112     85.990  0.1416    94.930  228.46
  38   0.5757     84.850  0.1332    95.408  234.68
  39   0.5311     85.780  0.1349    95.272  240.78
  40   0.5053     86.220  0.1253    95.566  246.91
  41   0.5420     85.580  0.1176    95.884  253.03
  42   0.5527     85.580  0.1199    95.832  259.16
  43   0.5390     85.350  0.1026    96.502  265.28
  44   0.5507     85.570  0.1060    96.284  271.49
  45   0.5544     85.790  0.1010    96.538  277.63
  46   0.5274     86.020  0.0961    96.636  283.75
  47   0.5759     85.640  0.0923    96.776  289.90
  48   0.5511     85.930  0.0925    96.792  296.04
  49   0.5523     85.980  0.0886    96.940  302.25
  50   0.5622     86.490  0.0869    96.988  308.39
  51   0.5480     86.180  0.0833    97.104  314.52
  52   0.5437     86.340  0.0811    97.214  320.62
  53   0.5510     86.340  0.0754    97.366  326.76
  54   0.5961     85.620  0.0794    97.264  332.90
  55   0.5596     86.480  0.0750    97.402  339.12
  56   0.6330     85.400  0.0720    97.426  345.22
  57   0.6055     86.190  0.0696    97.560  351.35
  58   0.6143     86.380  0.0678    97.612  357.47
  59   0.5986     86.080  0.0653    97.734  363.59
  60   0.5770     86.170  0.0671    97.628  369.72
  61   0.5316     87.390  0.0618    97.882  375.94
  62   0.6040     85.950  0.0608    97.876  382.06
  63   0.5585     87.040  0.0597    97.838  388.20
  64   0.5779     86.880  0.0588    97.924  394.35
  65   0.5831     86.940  0.0549    98.138  400.47
  66   0.6348     86.020  0.0604    97.844  406.62
  67   0.5907     86.470  0.0559    98.104  412.89
  68   0.6041     87.170  0.0542    98.190  419.02
  69   0.5849     86.440  0.0548    98.108  425.12
  70   0.5688     87.240  0.0534    98.124  431.25
  71   0.6093     86.580  0.0480    98.386  437.38
  72   0.6098     86.870  0.0472    98.332  443.60
  73   0.5428     87.390  0.0503    98.276  449.73
  74   0.5716     87.260  0.0484    98.352  455.86
  75   0.5457     88.040  0.0495    98.376  462.03
  76   0.5689     87.720  0.0464    98.376  468.13
  77   0.5413     87.680  0.0457    98.454  474.30
  78   0.6151     86.950  0.0431    98.474  480.56
  79   0.5662     87.580  0.0450    98.468  486.69
  80   0.5757     87.280  0.0408    98.628  492.81
  81   0.6199     86.890  0.0427    98.554  498.96
  82   0.5884     87.310  0.0465    98.408  505.14
  83   0.5949     87.270  0.0437    98.514  511.36
  84   0.6043     87.810  0.0426    98.588  517.51
  85   0.6463     86.360  0.0409    98.594  523.62
