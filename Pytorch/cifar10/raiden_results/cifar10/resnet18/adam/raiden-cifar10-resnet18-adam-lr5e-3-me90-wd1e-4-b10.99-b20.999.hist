Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6947     35.350  1.9609    27.404  7.81
   2   1.4762     46.090  1.5821    41.082  13.89
   3   1.2814     53.020  1.3884    48.910  20.01
   4   1.1016     60.880  1.2030    56.504  26.08
   5   1.0287     63.660  1.0550    62.274  32.17
   6   0.9793     65.760  0.9312    66.914  38.31
   7   0.9893     65.570  0.8223    70.856  44.39
   8   0.7523     73.730  0.7473    73.862  50.47
   9   0.7030     76.520  0.6556    77.312  56.55
  10   0.6421     77.600  0.6006    79.068  62.68
  11   0.6112     78.900  0.5673    80.376  68.79
  12   0.5991     79.680  0.5381    81.208  74.94
  13   0.5641     80.790  0.5113    82.400  81.05
  14   0.5412     81.200  0.4858    83.116  87.14
  15   0.5189     83.080  0.4689    83.722  93.21
  16   0.5924     80.320  0.4634    83.814  99.32
  17   0.5146     82.460  0.4411    84.968  105.38
  18   0.4934     83.480  0.4292    85.124  111.46
  19   0.4807     84.300  0.4249    85.380  117.56
  20   0.4636     84.430  0.4059    85.922  123.61
  21   0.4891     83.120  0.4091    85.808  129.70
  22   0.4717     83.920  0.3931    86.418  135.78
  23   0.4819     83.580  0.3907    86.528  141.96
  24   0.4619     84.940  0.3844    86.690  148.03
  25   0.4712     84.070  0.3700    87.310  154.15
  26   0.4465     85.170  0.3728    87.156  160.23
  27   0.4939     83.910  0.3548    87.660  166.34
  28   0.4624     84.740  0.3607    87.468  172.46
  29   0.4726     84.910  0.3550    87.754  178.60
  30   0.4445     85.450  0.3420    88.126  184.71
  31   0.4255     86.300  0.3391    88.258  190.80
  32   0.4770     84.480  0.3431    88.122  196.90
  33   0.4504     85.270  0.3437    87.970  203.01
  34   0.4397     85.630  0.3320    88.392  209.16
  35   0.4095     86.490  0.3254    88.628  215.26
  36   0.4955     84.400  0.3202    88.868  221.32
  37   0.4804     83.490  0.3245    88.764  227.44
  38   0.4268     86.000  0.3192    88.896  233.51
  39   0.4548     84.900  0.3197    88.954  239.67
  40   0.4098     86.410  0.3183    89.036  245.75
  41   0.4131     86.580  0.3169    88.924  251.81
  42   0.3914     87.360  0.3097    89.306  257.91
  43   0.4173     86.810  0.3085    89.356  264.02
  44   0.4102     86.410  0.3025    89.564  270.14
  45   0.4169     86.340  0.2949    89.678  276.32
  46   0.4370     85.750  0.2995    89.522  282.42
  47   0.4362     85.830  0.2945    89.882  288.48
  48   0.3783     87.360  0.2934    89.730  294.57
  49   0.4589     86.050  0.2906    89.926  300.68
  50   0.3956     87.030  0.2936    89.730  306.82
  51   0.3897     87.430  0.2930    89.796  313.02
  52   0.4107     86.290  0.2902    89.916  319.15
  53   0.4418     85.920  0.2948    89.668  325.24
  54   0.4358     85.710  0.2945    89.678  331.37
  55   0.4255     86.850  0.2954    89.734  337.51
  56   0.3783     87.510  0.2791    90.324  343.61
  57   0.3678     87.660  0.2789    90.424  349.83
  58   0.4308     85.980  0.2880    89.958  355.95
  59   0.3943     87.020  0.2826    90.300  362.03
  60   0.3898     87.090  0.2837    89.990  368.11
  61   0.3922     87.230  0.2845    90.244  374.19
  62   0.4162     86.240  0.2822    90.178  380.32
  63   0.4147     86.760  0.2844    90.092  386.53
  64   0.4462     85.770  0.2824    90.256  392.65
  65   0.4265     86.390  0.2734    90.546  398.75
  66   0.3811     87.470  0.2753    90.362  404.85
  67   0.3835     87.410  0.2756    90.390  410.91
  68   0.4058     87.560  0.2773    90.426  417.09
  69   0.3712     87.440  0.2736    90.424  423.17
  70   0.3922     86.890  0.2709    90.568  429.27
  71   0.4124     86.790  0.2737    90.426  435.37
  72   0.3805     87.760  0.2615    90.866  441.41
  73   0.4131     87.000  0.2633    90.848  447.49
  74   0.3668     87.770  0.2684    90.704  453.66
  75   0.4325     86.400  0.2669    90.746  459.75
  76   0.4360     86.300  0.2678    90.628  465.83
  77   0.3964     87.080  0.2746    90.448  471.96
  78   0.3718     87.680  0.2699    90.720  478.04
  79   0.3799     87.780  0.2677    90.754  484.22
  80   0.3896     87.150  0.2645    90.894  490.32
  81   0.3886     87.370  0.2688    90.682  496.38
  82   0.3847     87.540  0.2651    90.648  502.46
  83   0.3925     87.650  0.2587    91.172  508.57
  84   0.3867     87.500  0.2655    90.628  514.78
  85   0.3799     87.820  0.2679    90.672  520.92
  86   0.3662     87.830  0.2631    90.834  527.02
  87   0.3979     87.500  0.2703    90.552  533.12
  88   0.3914     86.890  0.2612    90.938  539.21
  89   0.3924     87.560  0.2611    90.884  545.30
  90   0.3874     87.630  0.2532    91.248  551.50
