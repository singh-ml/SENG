Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3760     49.160  1.6361    39.318  7.71
   2   1.1599     58.430  1.2832    53.250  13.89
   3   1.0236     63.680  1.0810    61.182  20.02
   4   0.9236     66.920  0.9629    65.376  26.16
   5   0.8561     70.110  0.8668    69.134  32.40
   6   0.7923     72.040  0.7982    71.612  38.58
   7   0.7385     74.410  0.7243    74.268  44.76
   8   0.6757     76.660  0.6758    76.176  50.94
   9   0.6606     76.720  0.6198    78.120  57.08
  10   0.6162     78.910  0.5757    79.660  63.24
  11   0.6073     79.130  0.5359    81.154  69.37
  12   0.5955     79.830  0.5075    82.158  75.52
  13   0.5846     80.060  0.4795    83.378  81.64
  14   0.5512     80.960  0.4455    84.422  87.82
  15   0.5187     82.280  0.4214    85.228  94.00
  16   0.5517     81.500  0.4056    85.930  100.19
  17   0.5019     83.230  0.3823    86.618  106.38
  18   0.5082     83.400  0.3573    87.480  112.56
  19   0.5404     82.360  0.3415    88.148  118.74
  20   0.5006     83.250  0.3297    88.480  124.90
  21   0.4880     84.260  0.3149    89.108  131.08
  22   0.5223     83.770  0.2972    89.670  137.21
  23   0.4859     83.760  0.2946    89.764  143.39
  24   0.4759     84.450  0.2718    90.684  149.53
  25   0.4866     84.010  0.2524    91.228  155.70
  26   0.4489     85.710  0.2494    91.172  161.88
  27   0.4550     85.270  0.2392    91.592  168.04
  28   0.4433     85.860  0.2217    92.250  174.23
  29   0.4342     86.030  0.2105    92.612  180.39
  30   0.4442     85.930  0.1994    93.174  186.57
  31   0.4329     86.380  0.1932    93.274  192.72
  32   0.4431     86.340  0.1832    93.736  198.88
  33   0.4444     86.200  0.1743    93.902  205.12
  34   0.4761     85.770  0.1709    94.000  211.29
  35   0.4327     86.680  0.1625    94.374  217.45
  36   0.4619     86.140  0.1583    94.558  223.62
  37   0.4611     86.560  0.1547    94.596  229.77
  38   0.4471     86.270  0.1515    94.674  235.89
  39   0.4517     86.730  0.1443    94.966  242.12
  40   0.5145     85.220  0.1380    95.258  248.28
  41   0.4544     86.680  0.1320    95.414  254.40
  42   0.4735     86.460  0.1252    95.766  260.55
  43   0.4364     87.420  0.1195    95.902  266.69
  44   0.4839     86.260  0.1168    95.994  272.86
  45   0.4611     87.070  0.1140    96.004  279.13
  46   0.4380     87.090  0.1147    96.020  285.29
  47   0.4849     86.210  0.1106    96.200  291.45
  48   0.4740     87.220  0.1059    96.404  297.61
  49   0.4607     87.520  0.0983    96.570  303.74
  50   0.4725     87.350  0.0976    96.694  309.89
  51   0.4302     87.800  0.1004    96.494  316.08
  52   0.4904     86.990  0.0949    96.726  322.27
  53   0.4682     87.770  0.0908    96.888  328.45
  54   0.4761     87.240  0.0939    96.808  334.62
  55   0.4595     87.380  0.0882    96.946  340.75
  56   0.5373     86.010  0.0848    97.156  347.02
  57   0.4494     87.830  0.0886    96.978  353.15
  58   0.4266     88.370  0.0793    97.314  359.33
  59   0.4615     88.040  0.0808    97.272  365.45
  60   0.4487     88.230  0.0806    97.290  371.60
  61   0.4372     88.320  0.0775    97.332  377.85
  62   0.5049     87.060  0.0744    97.426  384.02
  63   0.4575     87.780  0.0736    97.510  390.20
  64   0.4604     87.640  0.0718    97.600  396.33
  65   0.4801     87.690  0.0690    97.654  402.44
  66   0.4703     87.830  0.0712    97.598  408.60
  67   0.4725     87.380  0.0666    97.746  414.83
  68   0.4766     87.820  0.0648    97.834  420.96
  69   0.4628     88.050  0.0679    97.688  427.15
  70   0.4689     88.000  0.0632    97.918  433.31
  71   0.4881     87.590  0.0658    97.742  439.48
  72   0.4532     88.750  0.0582    98.088  445.74
  73   0.4653     88.000  0.0627    97.902  451.86
  74   0.4481     88.560  0.0579    98.084  458.05
  75   0.5395     87.160  0.0607    97.980  464.17
  76   0.4903     87.710  0.0598    97.980  470.29
  77   0.4684     88.290  0.0593    98.018  476.43
  78   0.4702     87.930  0.0594    97.946  482.59
  79   0.4653     88.390  0.0579    98.104  488.84
  80   0.4687     88.300  0.0582    98.024  495.00
  81   0.4407     88.860  0.0590    98.006  501.16
  82   0.4427     89.050  0.0583    98.036  507.35
  83   0.4481     88.270  0.0570    98.082  513.54
  84   0.4475     88.460  0.0534    98.150  519.78
  85   0.4600     88.990  0.0534    98.182  526.06
