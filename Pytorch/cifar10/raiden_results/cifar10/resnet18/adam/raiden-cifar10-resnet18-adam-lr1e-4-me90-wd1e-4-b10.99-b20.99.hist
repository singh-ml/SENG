Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3837     49.480  1.6378    39.546  7.64
   2   1.1744     57.300  1.2958    52.648  13.74
   3   1.0345     62.780  1.1085    60.166  19.86
   4   0.9305     66.930  0.9654    65.634  25.93
   5   0.8391     70.420  0.8639    69.290  32.05
   6   0.7800     72.910  0.7816    72.376  38.13
   7   0.7385     74.280  0.7087    74.948  44.21
   8   0.6738     76.700  0.6538    76.762  50.27
   9   0.6386     77.870  0.6053    78.724  56.47
  10   0.6297     78.610  0.5628    80.412  62.55
  11   0.5913     79.840  0.5287    81.522  68.66
  12   0.5843     79.630  0.4964    82.618  74.76
  13   0.5763     80.370  0.4677    83.526  80.84
  14   0.5579     81.020  0.4451    84.420  86.91
  15   0.5224     82.470  0.4195    85.386  93.07
  16   0.5358     82.620  0.3944    86.254  99.19
  17   0.5172     82.360  0.3720    87.042  105.26
  18   0.5183     83.050  0.3599    87.462  111.32
  19   0.4916     83.350  0.3421    88.104  117.40
  20   0.4725     84.120  0.3243    88.754  123.47
  21   0.4687     84.690  0.3104    89.232  129.65
  22   0.4917     83.870  0.2871    90.026  135.75
  23   0.4809     84.230  0.2710    90.494  141.87
  24   0.4659     85.030  0.2606    90.940  147.95
  25   0.4777     85.000  0.2550    91.046  154.07
  26   0.4957     85.050  0.2465    91.338  160.14
  27   0.4914     84.900  0.2316    91.822  166.31
  28   0.4827     85.160  0.2270    92.154  172.37
  29   0.4763     85.160  0.2097    92.504  178.47
  30   0.4767     85.860  0.1979    93.058  184.52
  31   0.5002     85.360  0.1889    93.366  190.62
  32   0.4739     86.140  0.1806    93.634  196.72
  33   0.4862     85.550  0.1762    93.788  202.84
  34   0.4953     85.430  0.1673    94.148  208.93
  35   0.4774     86.090  0.1591    94.446  215.00
  36   0.4540     86.490  0.1541    94.744  221.07
  37   0.4714     86.390  0.1448    94.992  227.13
  38   0.4624     86.710  0.1479    94.816  233.20
  39   0.4692     86.550  0.1349    95.276  239.32
  40   0.4836     86.430  0.1274    95.488  245.37
  41   0.4900     86.930  0.1227    95.622  251.42
  42   0.4676     87.030  0.1186    95.782  257.49
  43   0.5042     86.600  0.1188    95.818  263.55
  44   0.4840     86.650  0.1129    96.108  269.69
  45   0.4959     87.430  0.1072    96.214  275.78
  46   0.4656     87.010  0.1008    96.494  281.82
  47   0.5262     86.560  0.0938    96.658  287.91
  48   0.4883     87.080  0.0961    96.622  294.03
  49   0.4992     87.200  0.0902    96.764  300.09
  50   0.4933     87.520  0.0914    96.828  306.23
  51   0.4816     87.570  0.0836    97.046  312.34
  52   0.5134     86.770  0.0785    97.266  318.39
  53   0.4931     87.630  0.0771    97.336  324.46
  54   0.4953     87.530  0.0757    97.388  330.59
  55   0.5307     86.980  0.0789    97.252  336.66
  56   0.4986     87.440  0.0770    97.248  342.84
  57   0.5201     87.450  0.0753    97.408  348.90
  58   0.4918     87.410  0.0674    97.680  355.00
  59   0.5220     87.310  0.0674    97.672  361.12
  60   0.5019     87.880  0.0672    97.648  367.21
  61   0.4946     87.850  0.0634    97.786  373.27
  62   0.5011     87.680  0.0659    97.700  379.43
  63   0.5231     87.540  0.0627    97.728  385.51
  64   0.5222     87.410  0.0612    97.872  391.62
  65   0.4847     88.110  0.0597    97.948  397.67
  66   0.4972     88.120  0.0594    97.892  403.75
  67   0.5121     87.780  0.0625    97.810  409.87
  68   0.5123     88.200  0.0610    97.914  416.04
  69   0.5059     87.960  0.0527    98.166  422.14
  70   0.5298     87.760  0.0499    98.306  428.24
  71   0.5197     87.760  0.0529    98.172  434.30
  72   0.5171     87.710  0.0560    98.086  440.36
  73   0.5248     87.740  0.0485    98.334  446.42
  74   0.5158     87.950  0.0499    98.290  452.62
  75   0.5013     88.520  0.0478    98.360  458.71
  76   0.5237     87.980  0.0475    98.348  464.82
  77   0.5147     87.940  0.0489    98.282  470.88
  78   0.5322     87.620  0.0466    98.372  477.00
  79   0.5808     87.770  0.0488    98.330  483.13
  80   0.4890     88.460  0.0488    98.314  489.20
  81   0.5431     87.870  0.0431    98.532  495.27
  82   0.5308     87.960  0.0429    98.534  501.36
  83   0.5241     87.900  0.0411    98.606  507.48
  84   0.5440     88.080  0.0421    98.592  513.58
  85   0.5562     87.650  0.0456    98.468  519.77
  86   0.5503     87.910  0.0440    98.466  525.87
  87   0.5351     87.680  0.0434    98.498  532.03
  88   0.5367     87.990  0.0391    98.684  538.13
  89   0.5381     88.060  0.0382    98.720  544.25
  90   0.5274     88.300  0.0375    98.694  550.30
