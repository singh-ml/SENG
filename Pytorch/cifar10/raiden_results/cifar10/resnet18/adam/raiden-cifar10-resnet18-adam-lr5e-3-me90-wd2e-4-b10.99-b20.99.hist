Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6315     38.950  1.8745    30.444  7.74
   2   1.4473     46.270  1.5032    44.316  13.93
   3   1.2787     54.700  1.2851    52.722  20.00
   4   1.0930     61.130  1.1366    58.968  26.07
   5   0.9687     65.600  0.9808    64.868  32.14
   6   0.9613     65.990  0.8758    68.958  38.25
   7   0.7760     72.780  0.7854    72.130  44.38
   8   0.7887     72.680  0.7095    74.970  50.45
   9   0.6138     78.370  0.6389    77.554  56.57
  10   0.7264     75.860  0.5859    79.528  62.68
  11   0.6529     77.840  0.5579    80.652  68.76
  12   0.6579     77.800  0.5304    81.690  74.89
  13   0.5328     81.620  0.5056    82.356  81.04
  14   0.5710     80.940  0.4907    83.062  87.10
  15   0.6224     79.010  0.4753    83.618  93.18
  16   0.5282     81.820  0.4525    84.514  99.31
  17   0.5812     80.720  0.4518    84.386  105.43
  18   0.5246     82.080  0.4379    84.932  111.54
  19   0.5852     81.680  0.4265    85.298  117.73
  20   0.5165     82.770  0.4180    85.742  123.79
  21   0.5566     81.500  0.4182    85.538  129.90
  22   0.5127     82.830  0.4121    85.812  135.98
  23   0.5162     83.130  0.4094    85.824  142.04
  24   0.5002     83.110  0.3988    86.276  148.19
  25   0.4985     83.600  0.3947    86.564  154.34
  26   0.4962     83.990  0.3976    86.224  160.39
  27   0.4808     84.020  0.3875    86.728  166.51
  28   0.4778     84.240  0.3779    86.986  172.58
  29   0.4616     84.380  0.3828    86.670  178.70
  30   0.4605     84.330  0.3727    87.102  184.87
  31   0.4528     84.760  0.3789    87.116  190.94
  32   0.4918     84.470  0.3720    87.206  196.99
  33   0.5233     82.610  0.3682    87.222  203.06
  34   0.4971     83.490  0.3736    87.100  209.17
  35   0.5101     83.680  0.3651    87.272  215.24
  36   0.4702     84.100  0.3684    87.180  221.32
  37   0.4316     84.990  0.3581    87.730  227.40
  38   0.4931     83.510  0.3564    87.782  233.47
  39   0.4629     84.480  0.3502    88.004  239.56
  40   0.4643     84.950  0.3531    87.852  245.64
  41   0.4493     85.400  0.3560    87.792  251.76
  42   0.4295     85.250  0.3500    87.888  257.91
  43   0.4234     85.630  0.3495    87.930  264.03
  44   0.4127     86.200  0.3465    88.178  270.11
  45   0.4471     84.920  0.3441    88.128  276.19
  46   0.4543     84.870  0.3529    87.762  282.25
  47   0.4543     85.230  0.3470    88.290  288.32
  48   0.4822     84.500  0.3370    88.372  294.38
  49   0.4918     84.100  0.3399    88.286  300.47
  50   0.4277     85.900  0.3427    88.040  306.56
  51   0.4673     84.240  0.3410    88.116  312.62
  52   0.4351     85.980  0.3394    88.260  318.71
  53   0.4557     84.950  0.3408    88.206  324.82
  54   0.4199     86.420  0.3439    88.272  330.97
  55   0.4134     86.570  0.3330    88.510  337.07
  56   0.4254     85.810  0.3359    88.328  343.14
  57   0.4467     84.780  0.3383    88.360  349.21
  58   0.4303     86.250  0.3360    88.448  355.29
  59   0.4339     85.850  0.3292    88.598  361.40
  60   0.4393     85.740  0.3325    88.486  367.53
  61   0.3969     86.380  0.3355    88.378  373.60
  62   0.4395     85.660  0.3283    88.616  379.68
  63   0.4468     85.320  0.3268    88.820  385.78
  64   0.4327     85.440  0.3344    88.458  391.90
  65   0.4599     84.240  0.3343    88.564  398.06
  66   0.4539     84.910  0.3288    88.678  404.11
  67   0.4077     86.190  0.3237    88.772  410.21
  68   0.4595     84.790  0.3220    88.980  416.40
  69   0.4082     86.360  0.3326    88.536  422.50
  70   0.5018     84.100  0.3233    88.896  428.57
  71   0.4506     85.880  0.3262    88.836  434.73
  72   0.4229     86.000  0.3299    88.606  440.86
  73   0.4301     85.850  0.3302    88.600  446.96
  74   0.4458     85.150  0.3271    88.810  453.08
  75   0.4146     86.760  0.3205    88.986  459.14
  76   0.4241     86.170  0.3262    88.696  465.20
  77   0.4630     85.270  0.3233    88.912  471.26
  78   0.4606     85.030  0.3265    88.662  477.41
  79   0.4144     86.370  0.3239    88.864  483.50
  80   0.4145     86.410  0.3167    89.082  489.56
  81   0.4306     85.770  0.3263    88.724  495.65
  82   0.4017     86.720  0.3216    88.890  501.71
  83   0.3983     87.210  0.3180    89.124  507.81
  84   0.4167     86.260  0.3212    88.870  513.95
  85   0.4487     85.240  0.3212    89.016  520.07
  86   0.4329     85.710  0.3219    88.968  526.15
  87   0.4062     86.370  0.3156    88.956  532.24
  88   0.4208     86.100  0.3193    89.070  538.33
  89   0.4164     85.970  0.3181    88.982  544.49
  90   0.4165     86.120  0.3155    89.066  550.57
