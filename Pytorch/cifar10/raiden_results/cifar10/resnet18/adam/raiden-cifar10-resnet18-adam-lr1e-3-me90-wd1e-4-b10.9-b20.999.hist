Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2115     58.090  1.3739    49.712  7.80
   2   1.0255     64.690  0.9288    66.784  13.89
   3   0.7979     72.100  0.7341    74.028  19.95
   4   0.6847     77.460  0.6167    78.372  26.02
   5   0.6720     78.020  0.5458    81.010  32.22
   6   0.6268     79.680  0.4900    83.066  38.28
   7   0.6883     77.500  0.4527    84.610  44.36
   8   0.5973     80.480  0.4148    85.874  50.44
   9   0.5988     79.880  0.3808    86.826  56.50
  10   0.5582     82.080  0.3599    87.742  62.62
  11   0.4588     85.130  0.3381    88.388  68.82
  12   0.4432     85.680  0.3218    88.950  74.93
  13   0.4345     86.080  0.3018    89.660  80.98
  14   0.4393     85.050  0.2853    90.250  87.05
  15   0.4436     85.850  0.2777    90.412  93.15
  16   0.4629     85.480  0.2626    90.952  99.28
  17   0.5406     82.890  0.2497    91.518  105.35
  18   0.4107     87.250  0.2434    91.524  111.43
  19   0.4148     87.180  0.2277    92.142  117.54
  20   0.4692     86.110  0.2150    92.608  123.61
  21   0.3673     88.420  0.2094    92.730  129.70
  22   0.4647     86.180  0.1982    93.118  135.81
  23   0.5673     83.850  0.1941    93.308  141.94
  24   0.4214     87.190  0.1881    93.570  148.06
  25   0.3769     88.950  0.1799    93.810  154.14
  26   0.3800     88.580  0.1717    94.114  160.22
  27   0.4183     88.090  0.1663    94.194  166.28
  28   0.4009     88.550  0.1619    94.438  172.36
  29   0.4239     87.910  0.1611    94.290  178.49
  30   0.3882     88.860  0.1487    94.874  184.56
  31   0.3514     89.620  0.1521    94.784  190.64
  32   0.3373     90.210  0.1418    95.018  196.71
  33   0.4076     88.790  0.1402    95.228  202.83
  34   0.3554     89.380  0.1351    95.300  208.92
  35   0.3423     90.100  0.1300    95.476  215.13
  36   0.3744     89.650  0.1303    95.552  221.24
  37   0.4515     87.810  0.1298    95.462  227.33
  38   0.4294     88.820  0.1232    95.754  233.41
  39   0.4109     89.390  0.1269    95.476  239.49
  40   0.3764     90.070  0.1183    95.818  245.57
  41   0.4066     89.430  0.1163    95.938  251.70
  42   0.4275     88.410  0.1126    96.072  257.77
  43   0.3352     91.230  0.1160    95.940  263.83
  44   0.3723     90.280  0.1113    96.204  269.90
  45   0.4778     87.650  0.1086    96.178  276.05
  46   0.3711     90.020  0.1063    96.340  282.19
  47   0.3684     90.050  0.1077    96.226  288.26
  48   0.3587     90.450  0.1072    96.196  294.38
  49   0.3920     89.650  0.0999    96.456  300.45
  50   0.4512     88.010  0.1026    96.450  306.56
  51   0.3994     89.380  0.0991    96.536  312.66
  52   0.3701     90.020  0.1054    96.304  318.81
  53   0.3589     90.610  0.1002    96.542  324.87
  54   0.3792     89.750  0.0929    96.726  330.95
  55   0.3817     89.930  0.0952    96.670  337.09
  56   0.3479     90.620  0.0931    96.810  343.21
  57   0.3717     90.050  0.0941    96.706  349.33
  58   0.3411     91.020  0.0948    96.676  355.47
  59   0.4133     89.430  0.0943    96.718  361.54
  60   0.3614     90.420  0.0923    96.776  367.60
  61   0.3702     90.360  0.0941    96.698  373.69
  62   0.4153     90.140  0.0828    97.150  379.78
  63   0.3639     90.510  0.0941    96.756  385.87
  64   0.3607     90.540  0.0946    96.782  392.03
  65   0.3899     89.550  0.0846    97.096  398.11
  66   0.3644     90.700  0.0858    97.106  404.21
  67   0.3580     91.000  0.0921    96.848  410.29
  68   0.3731     90.380  0.0870    96.988  416.40
  69   0.3774     90.570  0.0919    96.856  422.46
  70   0.4414     89.020  0.0879    97.014  428.54
  71   0.3673     90.920  0.0813    97.196  434.63
  72   0.4180     89.840  0.0796    97.244  440.71
  73   0.3453     91.220  0.0871    97.004  446.82
  74   0.4275     89.330  0.0792    97.230  452.91
  75   0.3759     90.590  0.0891    96.906  459.00
  76   0.3518     91.460  0.0827    97.192  465.20
  77   0.3679     90.390  0.0866    96.992  471.30
  78   0.3502     91.020  0.0783    97.282  477.39
  79   0.3981     90.320  0.0801    97.202  483.47
  80   0.3434     91.300  0.0787    97.362  489.56
  81   0.3578     90.910  0.0772    97.324  495.67
  82   0.3838     90.400  0.0778    97.316  501.76
  83   0.3516     91.160  0.0817    97.254  507.85
  84   0.3334     91.230  0.0765    97.370  513.92
  85   0.3648     91.210  0.0775    97.318  520.01
  86   0.4104     90.440  0.0757    97.480  526.11
  87   0.3852     90.850  0.0745    97.408  532.33
  88   0.3633     90.900  0.0823    97.150  538.44
  89   0.3455     91.370  0.0777    97.384  544.52
  90   0.3839     90.280  0.0750    97.354  550.60
