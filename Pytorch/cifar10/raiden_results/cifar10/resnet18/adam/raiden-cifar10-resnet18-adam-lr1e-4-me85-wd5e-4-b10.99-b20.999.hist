Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3532     49.520  1.6475    39.282  7.58
   2   1.1786     57.050  1.2866    52.968  13.62
   3   1.0293     62.310  1.1064    59.824  19.68
   4   0.9194     66.880  0.9674    65.400  25.76
   5   0.8369     69.600  0.8689    69.136  31.89
   6   0.7982     71.610  0.7911    72.068  37.99
   7   0.7452     73.580  0.7243    74.502  44.04
   8   0.7048     75.750  0.6590    76.668  50.08
   9   0.6460     77.410  0.6091    78.544  56.12
  10   0.6143     78.350  0.5721    80.180  62.15
  11   0.5997     79.200  0.5310    81.520  68.24
  12   0.5965     79.280  0.4968    82.528  74.33
  13   0.5926     80.300  0.4761    83.372  80.42
  14   0.5434     81.130  0.4411    84.666  86.47
  15   0.5341     82.300  0.4203    85.406  92.51
  16   0.5311     82.330  0.4016    86.012  98.57
  17   0.5166     82.790  0.3806    86.598  104.78
  18   0.4915     83.410  0.3559    87.556  110.85
  19   0.4869     84.130  0.3379    88.198  116.89
  20   0.4926     83.940  0.3225    88.728  122.96
  21   0.4711     84.500  0.3046    89.598  129.00
  22   0.4700     84.420  0.2955    89.666  135.08
  23   0.4914     84.320  0.2825    90.236  141.18
  24   0.5187     82.890  0.2792    90.196  147.22
  25   0.4938     84.480  0.2711    90.600  153.26
  26   0.4397     85.670  0.2508    91.198  159.33
  27   0.4617     84.400  0.2332    91.756  165.43
  28   0.4683     85.200  0.2273    92.082  171.52
  29   0.4393     85.790  0.2121    92.746  177.57
  30   0.4516     85.680  0.2058    92.898  183.60
  31   0.4360     86.110  0.1936    93.278  189.63
  32   0.4475     85.960  0.1930    93.320  195.68
  33   0.4438     86.080  0.1797    93.776  201.77
  34   0.4889     85.230  0.1717    94.024  207.93
  35   0.4867     85.170  0.1675    94.224  213.99
  36   0.4400     86.580  0.1626    94.432  220.03
  37   0.4412     87.230  0.1492    94.732  226.09
  38   0.4431     86.950  0.1497    94.752  232.18
  39   0.4300     87.090  0.1413    95.162  238.21
  40   0.4495     86.710  0.1344    95.434  244.31
  41   0.4380     86.970  0.1301    95.540  250.34
  42   0.4418     86.900  0.1314    95.524  256.39
  43   0.4337     87.050  0.1197    95.910  262.43
  44   0.4521     87.500  0.1131    96.116  268.47
  45   0.4402     87.720  0.1108    96.198  274.50
  46   0.4466     87.150  0.1078    96.274  280.64
  47   0.4500     87.340  0.1091    96.192  286.67
  48   0.4626     87.100  0.1039    96.366  292.74
  49   0.4551     87.270  0.0946    96.772  298.77
  50   0.4568     87.440  0.0976    96.668  304.85
  51   0.4894     86.000  0.0959    96.732  310.89
  52   0.4422     88.070  0.0951    96.688  316.98
  53   0.4277     87.950  0.0873    97.050  323.05
  54   0.4686     87.010  0.0889    96.942  329.12
  55   0.4373     88.120  0.0851    97.114  335.16
  56   0.4564     87.880  0.0812    97.208  341.19
  57   0.4284     88.300  0.0796    97.220  347.32
  58   0.4289     88.120  0.0808    97.210  353.36
  59   0.4240     88.090  0.0773    97.474  359.45
  60   0.4325     88.430  0.0741    97.498  365.53
  61   0.4487     87.930  0.0733    97.542  371.56
  62   0.4311     88.430  0.0691    97.728  377.60
  63   0.4488     87.940  0.0782    97.358  383.71
  64   0.4627     87.460  0.0805    97.212  389.79
  65   0.4719     87.720  0.0780    97.376  395.87
  66   0.4300     88.560  0.0714    97.638  401.91
  67   0.4310     88.510  0.0625    97.892  407.94
  68   0.4690     87.510  0.0597    97.998  413.96
  69   0.4369     88.510  0.0605    97.930  420.04
  70   0.4696     87.840  0.0649    97.892  426.13
  71   0.4546     87.920  0.0691    97.622  432.14
  72   0.4085     89.000  0.0603    98.028  438.19
  73   0.4301     88.870  0.0602    97.948  444.24
  74   0.4191     88.930  0.0573    98.080  450.39
  75   0.4244     88.690  0.0607    97.944  456.47
  76   0.4793     87.320  0.0651    97.836  462.54
  77   0.4539     88.020  0.0666    97.784  468.62
  78   0.4494     88.800  0.0594    98.082  474.64
  79   0.4455     88.470  0.0608    97.884  480.69
  80   0.4547     88.460  0.0544    98.258  486.73
  81   0.4726     88.080  0.0537    98.154  492.80
  82   0.4322     88.230  0.0544    98.194  498.90
  83   0.4476     88.500  0.0523    98.306  504.94
  84   0.4555     88.800  0.0544    98.244  510.98
  85   0.4237     88.760  0.0510    98.296  517.03
