Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2472     54.540  1.5061    44.454  7.80
   2   1.0148     63.410  1.1148    59.546  13.91
   3   0.9925     65.770  0.9219    67.158  20.03
   4   0.7676     73.210  0.7810    72.350  26.12
   5   0.6971     75.670  0.6721    76.284  32.21
   6   0.6535     77.210  0.6017    79.012  38.27
   7   0.5995     80.080  0.5525    80.804  44.42
   8   0.5802     80.880  0.5030    82.542  50.51
   9   0.5495     82.010  0.4646    84.040  56.62
  10   0.5321     82.630  0.4369    84.950  62.66
  11   0.5272     82.740  0.4101    85.990  68.72
  12   0.4627     84.790  0.3857    86.812  74.77
  13   0.4951     83.520  0.3602    87.678  80.91
  14   0.4875     84.250  0.3442    88.252  87.05
  15   0.4606     85.480  0.3244    88.950  93.12
  16   0.4209     86.460  0.3133    89.182  99.18
  17   0.4603     84.860  0.2962    90.006  105.23
  18   0.4005     86.760  0.2886    90.124  111.35
  19   0.5275     84.440  0.2692    90.800  117.44
  20   0.4744     84.880  0.2603    91.078  123.51
  21   0.3909     87.180  0.2520    91.332  129.59
  22   0.3718     87.700  0.2427    91.692  135.63
  23   0.3847     87.760  0.2284    92.104  141.72
  24   0.3836     88.250  0.2240    92.246  147.85
  25   0.3731     88.050  0.2168    92.540  153.93
  26   0.3308     89.370  0.2104    92.852  160.01
  27   0.3925     87.980  0.1979    93.262  166.08
  28   0.3551     88.780  0.1977    93.248  172.15
  29   0.3782     88.480  0.1830    93.884  178.23
  30   0.3517     89.030  0.1893    93.512  184.37
  31   0.3954     88.380  0.1855    93.580  190.46
  32   0.3666     88.720  0.1767    93.924  196.53
  33   0.3408     89.410  0.1699    94.212  202.58
  34   0.3412     89.220  0.1705    94.168  208.68
  35   0.3608     88.970  0.1629    94.480  214.84
  36   0.3335     90.000  0.1620    94.444  220.96
  37   0.3677     89.140  0.1610    94.548  227.04
  38   0.3424     89.900  0.1544    94.742  233.12
  39   0.3339     90.030  0.1514    94.808  239.18
  40   0.3901     89.380  0.1457    95.024  245.33
  41   0.3312     90.120  0.1378    95.260  251.44
  42   0.3481     89.880  0.1414    95.260  257.53
  43   0.3370     90.020  0.1433    95.146  263.58
  44   0.3590     89.370  0.1378    95.320  269.66
  45   0.3558     89.730  0.1371    95.312  275.72
  46   0.3330     90.230  0.1339    95.372  281.81
  47   0.3449     90.100  0.1310    95.624  287.85
  48   0.3349     90.140  0.1335    95.364  293.92
  49   0.3749     89.660  0.1245    95.740  300.00
  50   0.3405     90.200  0.1311    95.560  306.06
  51   0.3628     89.810  0.1175    96.022  312.20
  52   0.3722     89.420  0.1257    95.658  318.30
  53   0.3226     90.570  0.1230    95.814  324.36
  54   0.3336     90.920  0.1136    96.130  330.43
  55   0.3428     90.510  0.1140    96.074  336.48
  56   0.3338     90.350  0.1160    95.988  342.57
  57   0.3580     90.050  0.1179    95.914  348.77
  58   0.3205     90.840  0.1166    95.972  354.85
  59   0.3462     90.320  0.1141    96.088  360.91
  60   0.3489     90.340  0.1139    96.166  367.00
  61   0.3352     90.570  0.1092    96.228  373.05
  62   0.3544     90.030  0.1109    96.208  379.09
  63   0.3693     89.930  0.1096    96.306  385.23
  64   0.3480     90.550  0.1020    96.562  391.28
  65   0.3717     90.040  0.1097    96.140  397.40
  66   0.3413     90.570  0.1068    96.342  403.53
  67   0.3644     90.500  0.1027    96.466  409.60
  68   0.3513     90.770  0.0999    96.570  415.67
  69   0.3312     90.890  0.0995    96.654  421.81
  70   0.3303     90.650  0.1029    96.480  427.90
  71   0.3346     90.840  0.0974    96.708  433.96
  72   0.3439     90.500  0.0946    96.810  440.05
  73   0.3400     90.830  0.0943    96.856  446.15
  74   0.3388     90.950  0.0911    96.932  452.20
  75   0.3321     90.980  0.0958    96.678  458.35
  76   0.3921     90.070  0.0951    96.744  464.42
  77   0.3490     90.790  0.0961    96.756  470.50
  78   0.3537     90.530  0.0969    96.650  476.61
  79   0.3724     90.120  0.0906    97.018  482.68
  80   0.3576     90.440  0.0919    96.926  488.82
  81   0.3604     90.320  0.0936    96.820  494.91
  82   0.3639     90.270  0.0927    96.908  500.97
  83   0.3386     90.890  0.0970    96.734  507.07
  84   0.3379     90.970  0.0874    97.042  513.16
  85   0.3810     90.320  0.0864    97.080  519.25
  86   0.3717     90.020  0.0950    96.864  525.38
  87   0.3380     90.450  0.0914    96.958  531.43
  88   0.3567     90.680  0.0905    96.930  537.50
  89   0.3276     91.200  0.0891    97.018  543.62
  90   0.3557     90.500  0.0874    96.954  549.73
