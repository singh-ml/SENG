Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8608     27.800  2.1357    22.036  7.58
   2   1.5874     41.090  1.7179    35.684  13.71
   3   1.3607     50.590  1.4155    47.992  19.80
   4   1.2472     56.260  1.2211    55.800  25.86
   5   1.0040     63.990  1.0457    62.832  31.93
   6   0.9534     66.890  0.9261    66.978  38.00
   7   0.9246     69.030  0.8350    70.482  44.07
   8   0.8213     72.440  0.7356    74.152  50.13
   9   0.6599     77.780  0.6900    75.982  56.25
  10   0.6807     75.980  0.6424    77.632  62.38
  11   0.6223     78.790  0.6022    78.962  68.46
  12   0.6709     76.970  0.5809    79.900  74.52
  13   0.7023     76.610  0.5610    80.520  80.63
  14   0.6239     78.850  0.5480    81.006  86.72
  15   0.6062     79.200  0.5340    81.644  92.84
  16   0.6308     78.860  0.5203    82.004  98.99
  17   0.6020     79.490  0.5097    82.388  105.08
  18   0.6230     79.010  0.4996    82.774  111.14
  19   0.5629     80.860  0.5008    82.594  117.20
  20   0.5393     81.570  0.4905    83.014  123.29
  21   0.5559     80.990  0.4855    83.242  129.48
  22   0.5531     81.180  0.4809    83.366  135.55
  23   0.5347     82.270  0.4764    83.582  141.65
  24   0.5486     81.450  0.4753    83.482  147.72
  25   0.5394     81.860  0.4688    83.836  153.78
  26   0.5309     81.620  0.4646    83.902  159.88
  27   0.5258     82.140  0.4611    84.058  166.00
  28   0.5691     81.390  0.4571    84.048  172.16
  29   0.5508     81.440  0.4500    84.454  178.23
  30   0.5554     81.200  0.4475    84.606  184.28
  31   0.5622     81.540  0.4476    84.536  190.36
  32   0.5239     82.260  0.4465    84.548  196.44
  33   0.5855     81.080  0.4396    84.752  202.48
  34   0.5207     82.710  0.4360    84.970  208.66
  35   0.4847     83.380  0.4393    84.686  214.79
  36   0.5420     81.920  0.4362    84.942  220.85
  37   0.5435     81.420  0.4286    85.194  226.90
  38   0.5024     82.910  0.4327    84.930  232.95
  39   0.5064     82.870  0.4330    85.100  239.03
  40   0.5819     80.860  0.4291    85.204  245.17
  41   0.5432     82.040  0.4256    85.372  251.24
  42   0.5877     81.230  0.4328    85.144  257.29
  43   0.4800     83.840  0.4177    85.574  263.37
  44   0.5422     82.020  0.4229    85.514  269.41
  45   0.5828     80.810  0.4214    85.638  275.46
  46   0.4784     83.860  0.4240    85.350  281.59
  47   0.5951     80.570  0.4215    85.448  287.64
  48   0.5512     81.930  0.4161    85.560  293.70
  49   0.4828     83.850  0.4140    85.578  299.72
  50   0.5158     82.630  0.4230    85.472  305.84
  51   0.5199     82.780  0.4211    85.562  311.89
  52   0.5287     82.430  0.4194    85.402  318.01
  53   0.5508     82.140  0.4157    85.502  324.08
  54   0.5077     82.930  0.4143    85.658  330.16
  55   0.4755     83.830  0.4174    85.548  336.20
  56   0.4800     83.930  0.4097    85.974  342.28
  57   0.4971     83.580  0.4092    85.818  348.37
  58   0.4671     83.850  0.4100    85.896  354.52
  59   0.5067     82.900  0.4126    85.734  360.59
  60   0.5046     83.020  0.4080    85.808  366.70
  61   0.5674     81.280  0.4087    85.842  372.79
  62   0.5122     83.550  0.4032    86.070  378.86
  63   0.5083     83.060  0.4111    85.724  385.01
  64   0.5103     82.850  0.4029    85.948  391.05
  65   0.4914     83.120  0.4156    85.642  397.10
  66   0.5339     82.330  0.4089    85.880  403.16
  67   0.4997     83.450  0.4035    85.994  409.18
  68   0.4575     84.690  0.4130    85.740  415.23
  69   0.4777     83.470  0.4048    86.018  421.31
  70   0.5127     82.990  0.3988    86.156  427.47
  71   0.4804     84.490  0.4082    85.870  433.57
  72   0.4985     83.260  0.3979    86.324  439.67
  73   0.4551     84.490  0.3998    86.064  445.75
  74   0.4914     83.570  0.4015    86.010  451.84
  75   0.5172     82.930  0.4030    86.004  457.91
  76   0.4541     84.610  0.4001    86.242  464.12
  77   0.4876     83.720  0.3991    86.200  470.17
  78   0.5303     82.480  0.4019    85.914  476.28
  79   0.4894     83.250  0.4054    86.072  482.35
  80   0.4883     83.310  0.4030    86.174  488.45
  81   0.5479     82.210  0.3981    86.152  494.50
  82   0.5636     82.230  0.3958    86.434  500.61
  83   0.4866     83.890  0.3941    86.240  506.68
  84   0.4939     83.650  0.3970    86.196  512.74
  85   0.4498     84.890  0.3965    86.170  518.84
  86   0.5157     82.680  0.3964    86.274  524.87
  87   0.5023     82.840  0.4027    86.124  530.94
  88   0.4594     84.330  0.3943    86.310  537.12
  89   0.5190     82.710  0.3902    86.348  543.17
  90   0.5210     82.740  0.3985    86.310  549.22
