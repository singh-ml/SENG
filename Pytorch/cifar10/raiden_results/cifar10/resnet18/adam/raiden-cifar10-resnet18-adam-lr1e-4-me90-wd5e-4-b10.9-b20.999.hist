Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2782     52.960  1.5729    41.850  7.80
   2   1.1066     60.210  1.1774    57.308  13.98
   3   1.0283     65.160  1.0006    64.168  20.23
   4   0.9110     67.940  0.8793    68.584  26.44
   5   0.8473     70.360  0.7901    72.106  32.62
   6   0.7648     73.210  0.7113    74.882  38.77
   7   0.7365     74.610  0.6526    77.040  44.96
   8   0.7840     73.980  0.6007    78.884  51.12
   9   0.6711     77.090  0.5609    80.440  57.38
  10   0.6434     78.470  0.5250    81.800  63.55
  11   0.5937     79.610  0.4931    82.842  69.77
  12   0.6105     78.980  0.4689    83.446  75.96
  13   0.6141     80.040  0.4382    84.874  82.14
  14   0.6127     79.620  0.4134    85.584  88.35
  15   0.5506     81.110  0.3968    86.138  94.61
  16   0.5336     82.470  0.3796    86.756  100.83
  17   0.5675     80.810  0.3604    87.482  106.99
  18   0.5731     81.530  0.3411    88.096  113.17
  19   0.5360     82.290  0.3271    88.634  119.32
  20   0.5348     82.480  0.3094    89.304  125.60
  21   0.4804     84.090  0.3000    89.614  131.79
  22   0.5319     82.590  0.2786    90.370  137.96
  23   0.5287     83.510  0.2682    90.676  144.12
  24   0.5668     81.690  0.2599    90.994  150.30
  25   0.4865     84.290  0.2443    91.524  156.50
  26   0.5334     83.410  0.2330    91.954  162.74
  27   0.5145     83.770  0.2237    92.164  168.94
  28   0.5045     84.420  0.2165    92.394  175.13
  29   0.4956     84.850  0.2063    92.788  181.34
  30   0.4919     84.430  0.1987    93.104  187.52
  31   0.4917     84.630  0.1899    93.282  193.77
  32   0.5060     84.680  0.1796    93.726  199.94
  33   0.5210     84.470  0.1731    94.056  206.10
  34   0.5173     85.100  0.1647    94.242  212.27
  35   0.4947     85.590  0.1624    94.306  218.47
  36   0.4801     85.320  0.1485    94.948  224.61
  37   0.4907     85.080  0.1492    94.890  230.84
  38   0.4769     86.430  0.1420    95.100  237.02
  39   0.4381     87.130  0.1437    95.038  243.18
  40   0.5450     84.580  0.1319    95.432  249.39
  41   0.5433     84.400  0.1287    95.626  255.58
  42   0.5047     85.920  0.1213    95.900  261.74
  43   0.5586     85.130  0.1209    95.760  267.98
  44   0.4381     87.840  0.1104    96.240  274.14
  45   0.4855     86.170  0.1117    96.220  280.34
  46   0.5080     85.870  0.1078    96.298  286.48
  47   0.5432     85.730  0.1070    96.258  292.63
  48   0.4690     86.400  0.1046    96.380  298.83
  49   0.4633     86.850  0.0963    96.686  305.05
  50   0.4356     87.880  0.0917    96.956  311.21
  51   0.4921     85.750  0.0857    97.108  317.39
  52   0.4819     86.900  0.0936    96.726  323.57
  53   0.5755     85.090  0.0913    96.820  329.72
  54   0.4539     87.880  0.0892    96.938  335.89
  55   0.4906     86.690  0.0870    97.016  342.10
  56   0.4778     87.260  0.0795    97.248  348.29
  57   0.5466     85.430  0.0809    97.178  354.47
  58   0.5716     85.560  0.0747    97.574  360.62
  59   0.5571     85.590  0.0837    97.120  366.79
  60   0.4682     87.860  0.0721    97.598  372.99
  61   0.4827     86.850  0.0769    97.420  379.27
  62   0.5129     86.320  0.0748    97.530  385.42
  63   0.6050     85.360  0.0651    97.902  391.59
  64   0.4887     86.550  0.0708    97.594  397.77
  65   0.4819     87.680  0.0651    97.778  403.92
  66   0.5150     87.160  0.0689    97.662  410.15
  67   0.4482     88.100  0.0659    97.804  416.34
  68   0.4693     88.040  0.0671    97.680  422.52
  69   0.5486     86.120  0.0705    97.602  428.72
  70   0.5097     87.100  0.0650    97.872  434.92
  71   0.4734     88.050  0.0602    98.004  441.10
  72   0.4697     87.830  0.0629    97.852  447.34
  73   0.4966     87.670  0.0595    98.076  453.56
  74   0.5329     87.010  0.0597    98.018  459.72
  75   0.5078     87.380  0.0601    97.946  465.95
  76   0.5282     86.760  0.0584    98.036  472.15
  77   0.5011     88.110  0.0648    97.832  478.32
  78   0.5225     86.920  0.0561    98.158  484.59
  79   0.4922     87.990  0.0612    97.964  490.80
  80   0.4449     88.820  0.0547    98.202  497.00
  81   0.4703     88.040  0.0551    98.142  503.15
  82   0.4356     88.880  0.0526    98.276  509.31
  83   0.6204     85.050  0.0518    98.266  515.57
  84   0.4974     87.360  0.0551    98.248  521.74
  85   0.4815     87.950  0.0574    98.052  527.91
  86   0.5115     87.260  0.0499    98.354  534.10
  87   0.4689     88.400  0.0534    98.204  540.25
  88   0.5252     86.960  0.0494    98.396  546.44
  89   0.4769     88.310  0.0553    98.148  552.71
  90   0.5274     87.410  0.0518    98.304  558.90
