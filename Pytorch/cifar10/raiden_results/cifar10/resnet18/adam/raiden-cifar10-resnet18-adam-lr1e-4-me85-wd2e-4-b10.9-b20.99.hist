Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3197     51.980  1.5588    42.668  8.07
   2   1.1469     58.560  1.1904    56.832  14.22
   3   0.9942     64.340  1.0176    63.490  20.31
   4   0.9106     67.350  0.9023    67.696  26.41
   5   0.9230     67.960  0.8179    71.020  32.48
   6   0.8405     70.990  0.7362    73.850  38.57
   7   0.7892     72.590  0.6779    75.956  44.71
   8   0.7388     74.680  0.6256    77.914  50.89
   9   0.6714     76.370  0.5763    79.956  57.02
  10   0.6369     78.430  0.5400    81.188  63.14
  11   0.6129     79.260  0.5030    82.260  69.24
  12   0.6632     77.970  0.4773    83.398  75.37
  13   0.5714     80.370  0.4531    83.994  81.57
  14   0.5559     80.950  0.4247    85.044  87.70
  15   0.5260     81.840  0.4017    85.942  93.78
  16   0.6058     80.240  0.3810    86.678  99.89
  17   0.5133     82.270  0.3585    87.634  105.97
  18   0.5407     82.400  0.3432    87.830  112.05
  19   0.5327     82.450  0.3271    88.476  118.21
  20   0.6113     80.120  0.3080    89.196  124.28
  21   0.5002     83.800  0.2962    89.644  130.41
  22   0.4608     85.120  0.2830    90.136  136.50
  23   0.4963     84.030  0.2656    90.660  142.60
  24   0.4699     84.470  0.2556    90.896  148.74
  25   0.5625     82.590  0.2434    91.492  154.94
  26   0.4641     85.320  0.2340    91.900  161.06
  27   0.4443     85.710  0.2220    92.236  167.19
  28   0.4688     85.260  0.2111    92.576  173.31
  29   0.4769     85.500  0.2013    92.972  179.38
  30   0.4986     85.130  0.1931    93.284  185.45
  31   0.5149     84.560  0.1829    93.602  191.61
  32   0.5067     84.940  0.1787    93.704  197.69
  33   0.4708     85.760  0.1692    94.016  203.83
  34   0.5280     85.290  0.1630    94.318  209.94
  35   0.4970     85.790  0.1579    94.408  216.03
  36   0.4520     86.430  0.1476    94.896  222.16
  37   0.7166     82.410  0.1417    95.006  228.36
  38   0.4996     86.010  0.1365    95.234  234.49
  39   0.4877     86.170  0.1324    95.430  240.60
  40   0.5289     85.500  0.1286    95.472  246.74
  41   0.5376     85.350  0.1192    95.914  252.81
  42   0.5755     85.080  0.1207    95.766  258.92
  43   0.4751     86.780  0.1145    95.938  265.06
  44   0.5905     84.510  0.1054    96.302  271.18
  45   0.5943     84.670  0.1047    96.408  277.30
  46   0.4904     87.040  0.0989    96.542  283.41
  47   0.4996     86.230  0.0987    96.536  289.54
  48   0.4879     86.410  0.0967    96.658  295.75
  49   0.5192     86.390  0.0907    96.848  301.82
  50   0.4844     87.300  0.0917    96.872  307.90
  51   0.5150     86.320  0.0898    96.816  313.98
  52   0.5119     87.090  0.0826    97.060  320.09
  53   0.4779     87.500  0.0818    97.168  326.20
  54   0.6485     84.740  0.0775    97.346  332.37
  55   0.5034     87.190  0.0772    97.320  338.45
  56   0.5125     87.140  0.0739    97.484  344.58
  57   0.4602     87.930  0.0734    97.458  350.71
  58   0.4725     88.070  0.0746    97.356  356.78
  59   0.4565     88.120  0.0673    97.738  362.95
  60   0.4755     87.890  0.0677    97.656  369.04
  61   0.5533     86.410  0.0699    97.554  375.15
  62   0.5372     86.740  0.0634    97.828  381.28
  63   0.5302     87.210  0.0630    97.874  387.37
  64   0.5044     87.650  0.0615    97.868  393.45
  65   0.5264     87.540  0.0591    97.952  399.61
  66   0.5404     87.290  0.0570    98.112  405.73
  67   0.5554     86.410  0.0608    97.874  411.82
  68   0.5321     87.330  0.0585    97.992  417.89
  69   0.5179     87.450  0.0575    97.968  423.99
  70   0.5072     87.670  0.0562    98.106  430.11
  71   0.6059     86.270  0.0521    98.288  436.30
  72   0.6473     85.820  0.0524    98.200  442.44
  73   0.5141     87.590  0.0548    98.100  448.59
  74   0.5365     87.120  0.0533    98.168  454.71
  75   0.5384     87.710  0.0539    98.202  460.79
  76   0.5055     87.650  0.0494    98.280  466.96
  77   0.5270     87.790  0.0483    98.318  473.09
  78   0.5210     87.770  0.0477    98.400  479.18
  79   0.5226     87.700  0.0477    98.372  485.28
  80   0.5038     87.920  0.0485    98.320  491.41
  81   0.4990     88.400  0.0456    98.508  497.53
  82   0.4828     88.340  0.0495    98.256  503.72
  83   0.5473     87.510  0.0432    98.572  509.85
  84   0.5464     87.690  0.0456    98.444  515.94
  85   0.4998     88.580  0.0449    98.466  522.04
