Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3373     51.400  1.5658    42.176  7.69
   2   1.1878     57.440  1.2031    56.522  13.84
   3   1.0966     60.830  1.0280    63.200  19.99
   4   0.8747     69.330  0.9025    67.984  26.13
   5   0.7857     72.250  0.8005    71.748  32.26
   6   0.7077     75.070  0.7280    74.480  38.49
   7   0.8206     71.540  0.6600    76.996  44.66
   8   0.7246     75.740  0.6129    78.562  50.83
   9   0.6658     77.390  0.5702    80.070  56.98
  10   0.6117     78.880  0.5316    81.286  63.12
  11   0.5998     79.160  0.4997    82.642  69.27
  12   0.5518     81.090  0.4740    83.370  75.47
  13   0.5436     81.240  0.4418    84.638  81.60
  14   0.5663     80.600  0.4201    85.222  87.72
  15   0.5177     82.570  0.3950    86.172  93.87
  16   0.5298     82.230  0.3767    86.856  99.98
  17   0.5125     82.580  0.3561    87.698  106.11
  18   0.5219     82.580  0.3377    88.224  112.28
  19   0.5133     83.040  0.3232    88.658  118.43
  20   0.4765     83.950  0.3087    89.264  124.60
  21   0.4804     84.080  0.2919    89.918  130.72
  22   0.4777     84.100  0.2813    90.190  136.88
  23   0.5511     82.190  0.2660    90.700  143.09
  24   0.5092     83.790  0.2569    91.066  149.22
  25   0.5108     84.280  0.2404    91.610  155.40
  26   0.4846     84.880  0.2289    92.022  161.53
  27   0.5235     83.930  0.2197    92.324  167.70
  28   0.4718     85.170  0.2089    92.806  173.89
  29   0.6859     80.990  0.2041    92.824  180.00
  30   0.4511     85.600  0.1903    93.324  186.16
  31   0.4605     85.790  0.1818    93.476  192.28
  32   0.5146     84.640  0.1733    94.054  198.43
  33   0.5070     85.190  0.1678    94.154  204.66
  34   0.4517     85.950  0.1616    94.294  210.81
  35   0.4807     85.730  0.1491    94.806  216.93
  36   0.5237     84.870  0.1466    94.922  223.06
  37   0.5029     85.420  0.1404    95.122  229.23
  38   0.4535     86.730  0.1374    95.190  235.36
  39   0.5206     85.290  0.1271    95.610  241.60
  40   0.4705     86.320  0.1228    95.670  247.71
  41   0.4792     86.440  0.1184    95.866  253.83
  42   0.4499     87.330  0.1187    95.792  260.02
  43   0.5075     85.540  0.1091    96.216  266.19
  44   0.4575     87.100  0.1103    96.102  272.36
  45   0.4889     86.340  0.1035    96.346  278.47
  46   0.5119     86.520  0.0989    96.606  284.61
  47   0.4917     87.220  0.1000    96.446  290.76
  48   0.4945     86.240  0.0923    96.834  296.94
  49   0.5092     86.480  0.0948    96.640  303.12
  50   0.4523     87.540  0.0877    96.926  309.38
  51   0.5191     86.410  0.0857    97.046  315.48
  52   0.5077     86.260  0.0798    97.204  321.62
  53   0.5818     85.080  0.0814    97.186  327.76
  54   0.4476     87.600  0.0818    97.170  333.87
  55   0.4510     87.630  0.0753    97.378  340.08
  56   0.6433     84.640  0.0754    97.442  346.20
  57   0.5086     87.390  0.0749    97.416  352.37
  58   0.4718     87.420  0.0663    97.728  358.50
  59   0.4611     88.010  0.0716    97.492  364.64
  60   0.5509     86.540  0.0654    97.752  370.80
  61   0.4905     87.680  0.0652    97.812  377.02
  62   0.4844     88.000  0.0670    97.672  383.15
  63   0.4863     87.190  0.0616    97.954  389.28
  64   0.5424     86.870  0.0624    97.868  395.45
  65   0.5334     87.090  0.0615    97.874  401.57
  66   0.5115     87.920  0.0560    98.146  407.74
  67   0.5348     87.350  0.0599    97.966  413.89
  68   0.5563     86.620  0.0561    98.124  420.01
  69   0.5232     87.030  0.0602    97.926  426.16
  70   0.5011     87.570  0.0554    98.088  432.31
  71   0.5583     87.080  0.0567    98.106  438.47
  72   0.4943     87.530  0.0516    98.226  444.70
  73   0.4964     88.100  0.0530    98.166  450.91
  74   0.5206     87.440  0.0517    98.234  457.11
  75   0.4713     88.390  0.0511    98.272  463.24
  76   0.5268     87.460  0.0530    98.154  469.40
  77   0.5078     87.780  0.0479    98.362  475.55
  78   0.5177     87.480  0.0490    98.316  481.77
  79   0.4800     88.350  0.0477    98.320  487.94
  80   0.5020     87.840  0.0454    98.438  494.10
  81   0.5297     87.550  0.0459    98.398  500.26
  82   0.5077     87.940  0.0442    98.478  506.43
  83   0.4638     88.990  0.0471    98.422  512.65
  84   0.5070     88.030  0.0444    98.484  518.78
  85   0.4913     88.390  0.0426    98.588  524.92
  86   0.4710     89.150  0.0472    98.362  531.08
  87   0.5384     87.430  0.0389    98.630  537.26
  88   0.5097     87.970  0.0425    98.558  543.42
  89   0.5200     88.220  0.0461    98.448  549.53
  90   0.5122     88.490  0.0404    98.752  555.66
