Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5728     51.210  1.3878    49.220  7.82
   2   1.4997     52.500  0.9349    66.812  13.90
   3   0.9080     69.010  0.7537    73.676  19.97
   4   0.8119     72.390  0.6513    77.410  26.06
   5   0.7442     74.940  0.5816    79.790  32.08
   6   0.8136     74.140  0.5422    81.360  38.21
   7   0.5872     80.420  0.4963    83.056  44.22
   8   0.5895     80.060  0.4696    84.096  50.25
   9   0.6400     79.460  0.4434    84.866  56.28
  10   0.6690     79.170  0.4256    85.622  62.34
  11   0.5658     81.750  0.3998    86.506  68.44
  12   0.5634     81.550  0.3830    87.002  74.52
  13   0.4717     84.890  0.3661    87.564  80.61
  14   0.6599     79.440  0.3515    88.194  86.63
  15   0.5874     81.370  0.3386    88.386  92.66
  16   0.5682     82.970  0.3342    88.564  98.67
  17   0.5086     83.660  0.3142    89.372  104.80
  18   0.6312     79.660  0.3069    89.536  110.86
  19   0.4683     85.210  0.3011    89.944  116.90
  20   0.4616     85.390  0.2926    89.926  122.94
  21   0.5092     84.020  0.2843    90.422  128.97
  22   0.4027     86.790  0.2799    90.552  135.01
  23   0.7398     78.620  0.2663    90.814  141.11
  24   0.3861     87.580  0.2640    91.068  147.17
  25   0.3458     88.440  0.2572    91.286  153.22
  26   0.4294     86.190  0.2528    91.338  159.23
  27   0.4407     86.410  0.2480    91.496  165.31
  28   0.4404     86.740  0.2420    91.802  171.35
  29   0.3937     87.400  0.2410    91.820  177.44
  30   0.4859     85.000  0.2330    92.078  183.47
  31   0.3495     88.750  0.2339    92.100  189.50
  32   0.3629     88.110  0.2268    92.208  195.58
  33   0.3901     87.690  0.2260    92.216  201.62
  34   0.4324     86.460  0.2204    92.470  207.72
  35   0.3716     88.160  0.2163    92.740  213.88
  36   0.4214     87.030  0.2105    92.866  219.93
  37   0.3624     88.500  0.2102    92.918  226.15
  38   0.4158     86.930  0.2095    92.776  232.25
  39   0.3550     88.440  0.2074    92.842  238.29
  40   0.3338     89.400  0.2068    92.880  244.32
  41   0.3708     88.400  0.2015    93.046  250.43
  42   0.3604     88.880  0.1988    93.190  256.47
  43   0.3652     88.380  0.2004    93.110  262.55
  44   0.3447     89.370  0.1958    93.258  268.60
  45   0.3836     88.590  0.1909    93.504  274.63
  46   0.4012     88.310  0.1993    93.228  280.76
  47   0.4070     87.670  0.1869    93.652  286.83
  48   0.3363     90.010  0.1853    93.570  292.87
  49   0.3988     87.880  0.1856    93.558  298.95
  50   0.3659     88.750  0.1879    93.592  304.99
  51   0.4212     87.250  0.1857    93.586  311.02
  52   0.3452     89.410  0.1842    93.732  317.17
  53   0.3876     88.590  0.1799    93.898  323.22
  54   0.3999     87.840  0.1812    93.764  329.30
  55   0.3808     88.570  0.1799    93.790  335.34
  56   0.3943     88.420  0.1741    94.094  341.39
  57   0.3371     89.410  0.1723    94.084  347.42
  58   0.3709     88.930  0.1713    94.120  353.55
  59   0.3637     88.600  0.1721    94.204  359.59
  60   0.3717     88.950  0.1726    94.156  365.61
  61   0.3468     89.510  0.1638    94.476  371.67
  62   0.3616     88.900  0.1683    94.116  377.75
  63   0.3606     88.870  0.1680    94.250  383.80
  64   0.3712     88.610  0.1674    94.300  389.94
  65   0.4141     87.630  0.1688    94.264  395.97
  66   0.3560     89.330  0.1654    94.250  402.02
  67   0.3606     89.180  0.1676    94.206  408.04
  68   0.3708     89.420  0.1614    94.456  414.10
  69   0.3341     89.590  0.1675    94.298  420.28
  70   0.4303     87.570  0.1605    94.588  426.34
  71   0.4257     87.750  0.1620    94.466  432.40
  72   0.4678     86.640  0.1613    94.408  438.43
  73   0.3223     89.960  0.1584    94.526  444.50
  74   0.3506     89.230  0.1605    94.466  450.55
  75   0.3289     90.280  0.1622    94.492  456.65
  76   0.3429     89.730  0.1538    94.644  462.68
  77   0.3464     89.640  0.1613    94.424  468.74
  78   0.3351     89.560  0.1519    94.784  474.82
  79   0.3384     89.740  0.1639    94.506  480.91
  80   0.4407     87.910  0.1547    94.772  486.95
  81   0.3764     88.870  0.1588    94.538  493.07
  82   0.3608     88.990  0.1520    94.712  499.10
  83   0.3740     89.170  0.1537    94.724  505.15
  84   0.3707     88.890  0.1614    94.492  511.23
  85   0.3691     89.240  0.1564    94.636  517.26
