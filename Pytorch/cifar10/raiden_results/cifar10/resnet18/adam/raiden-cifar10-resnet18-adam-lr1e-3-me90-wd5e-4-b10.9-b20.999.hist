Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1919     57.280  1.3985    48.860  7.73
   2   1.2006     60.040  0.9485    66.506  13.85
   3   0.8884     69.930  0.7579    73.786  20.00
   4   0.7922     71.980  0.6566    77.228  26.17
   5   0.7589     74.610  0.5944    79.444  32.27
   6   0.8592     72.960  0.5452    81.384  38.36
   7   0.6570     78.350  0.5048    82.862  44.43
   8   0.8370     74.200  0.4643    84.280  50.53
   9   0.7493     75.850  0.4457    84.862  56.61
  10   0.6893     77.930  0.4272    85.532  62.80
  11   0.6465     78.440  0.3962    86.512  68.95
  12   0.5720     81.970  0.3792    87.332  75.05
  13   0.5201     83.470  0.3662    87.628  81.17
  14   0.5920     80.970  0.3420    88.296  87.26
  15   0.6166     80.600  0.3407    88.460  93.37
  16   0.4414     85.860  0.3259    88.946  99.52
  17   0.3865     86.790  0.3125    89.376  105.64
  18   0.5000     84.200  0.3086    89.538  111.74
  19   0.4779     84.630  0.2941    90.072  117.85
  20   0.3874     87.390  0.2908    90.236  123.95
  21   0.4352     86.220  0.2778    90.570  130.07
  22   0.4516     85.700  0.2700    90.812  136.25
  23   0.4080     86.870  0.2704    90.788  142.38
  24   0.3783     87.510  0.2645    91.080  148.48
  25   0.4145     86.670  0.2514    91.438  154.60
  26   0.3967     87.250  0.2527    91.330  160.71
  27   0.4601     86.130  0.2441    91.636  166.81
  28   0.3567     88.610  0.2409    91.732  173.01
  29   0.4259     86.740  0.2356    91.944  179.12
  30   0.3905     87.060  0.2358    91.966  185.24
  31   0.3725     88.030  0.2307    92.226  191.37
  32   0.3935     87.720  0.2235    92.490  197.45
  33   0.3619     88.140  0.2223    92.424  203.65
  34   0.3791     88.060  0.2228    92.428  209.77
  35   0.3831     87.850  0.2193    92.568  215.86
  36   0.4008     88.360  0.2135    92.624  221.94
  37   0.3560     88.690  0.2094    92.758  228.04
  38   0.5636     84.480  0.2125    92.834  234.22
  39   0.6031     83.090  0.2085    92.760  240.35
  40   0.3722     87.930  0.2062    92.928  246.48
  41   0.3530     89.220  0.1995    93.166  252.60
  42   0.4359     86.830  0.2013    93.156  258.71
  43   0.3929     87.650  0.2004    93.168  264.82
  44   0.4373     86.240  0.2027    93.124  271.04
  45   0.3723     88.810  0.1964    93.286  277.14
  46   0.3699     89.100  0.1909    93.512  283.26
  47   0.3222     89.860  0.1950    93.314  289.42
  48   0.4011     87.880  0.1836    93.684  295.56
  49   0.4027     88.080  0.1900    93.588  301.69
  50   0.4090     87.340  0.1875    93.590  307.82
  51   0.3609     88.300  0.1819    93.690  314.00
  52   0.3635     89.220  0.1808    93.898  320.12
  53   0.3504     89.120  0.1850    93.674  326.28
  54   0.3489     89.520  0.1810    93.878  332.42
  55   0.4711     86.250  0.1786    93.954  338.53
  56   0.3505     89.550  0.1809    93.844  344.70
  57   0.3977     87.770  0.1729    94.090  350.83
  58   0.3593     89.560  0.1796    93.958  356.97
  59   0.3712     88.720  0.1783    93.850  363.12
  60   0.3747     88.690  0.1777    93.994  369.27
  61   0.3831     89.110  0.1751    94.090  375.42
  62   0.4041     88.050  0.1720    94.078  381.61
  63   0.3526     89.440  0.1708    94.116  387.72
  64   0.3732     88.860  0.1668    94.298  393.84
  65   0.3492     89.360  0.1738    94.000  399.99
  66   0.4099     88.250  0.1688    94.298  406.15
  67   0.4181     87.810  0.1693    94.246  412.36
  68   0.4348     87.410  0.1693    94.226  418.50
  69   0.3816     88.700  0.1679    94.184  424.59
  70   0.3655     89.330  0.1657    94.344  430.71
  71   0.4219     87.930  0.1683    94.236  436.83
  72   0.3864     89.120  0.1639    94.388  442.93
  73   0.3815     88.760  0.1639    94.382  449.05
  74   0.3610     89.550  0.1657    94.390  455.18
  75   0.3469     89.850  0.1589    94.576  461.28
  76   0.3512     89.490  0.1621    94.422  467.42
  77   0.3645     89.300  0.1614    94.478  473.58
  78   0.3455     89.700  0.1602    94.498  479.69
  79   0.3854     88.920  0.1622    94.476  485.84
  80   0.3467     89.650  0.1612    94.464  492.02
  81   0.3706     88.860  0.1602    94.518  498.21
  82   0.4008     88.410  0.1604    94.500  504.33
  83   0.3811     88.750  0.1587    94.584  510.48
  84   0.3604     89.570  0.1556    94.602  516.60
  85   0.3648     89.420  0.1579    94.506  522.79
  86   0.3258     90.000  0.1588    94.542  528.89
  87   0.3050     90.790  0.1511    94.832  535.02
  88   0.3339     89.820  0.1497    94.940  541.15
  89   0.3570     89.700  0.1520    94.832  547.26
  90   0.3416     89.960  0.1547    94.762  553.39
