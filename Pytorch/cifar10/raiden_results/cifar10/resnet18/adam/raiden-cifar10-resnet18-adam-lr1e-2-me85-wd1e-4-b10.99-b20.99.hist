Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9114     29.220  2.1388    22.882  7.71
   2   1.5317     43.990  1.6720    38.090  13.77
   3   1.3397     51.220  1.4261    47.814  19.85
   4   1.1826     57.880  1.2420    55.262  25.92
   5   1.1031     61.560  1.0878    61.092  31.96
   6   0.9799     65.820  0.9583    65.946  38.06
   7   0.9169     67.330  0.8649    69.442  44.12
   8   0.8387     70.400  0.8008    71.582  50.17
   9   0.7843     72.390  0.7581    73.150  56.24
  10   0.7213     74.460  0.7054    75.264  62.28
  11   0.6573     77.410  0.6681    76.660  68.38
  12   0.6704     77.110  0.6356    77.744  74.40
  13   0.6190     79.200  0.6024    78.836  80.45
  14   0.6440     77.500  0.5819    79.676  86.47
  15   0.6346     78.440  0.5771    80.224  92.49
  16   0.6101     78.640  0.5623    80.300  98.53
  17   0.6194     78.970  0.5531    80.894  104.62
  18   0.6234     78.830  0.5404    81.098  110.65
  19   0.5820     80.730  0.5291    81.726  116.70
  20   0.6054     79.590  0.5269    81.710  122.77
  21   0.5923     79.890  0.5109    82.340  128.81
  22   0.5756     80.620  0.5047    82.498  134.84
  23   0.5369     81.920  0.4973    82.738  140.96
  24   0.5405     81.580  0.4960    82.776  146.98
  25   0.5682     81.020  0.4921    82.934  153.04
  26   0.5803     80.410  0.4882    82.912  159.06
  27   0.5504     81.000  0.4719    83.732  165.13
  28   0.5913     80.020  0.4845    83.218  171.19
  29   0.5494     81.270  0.4748    83.484  177.20
  30   0.5458     81.790  0.4746    83.524  183.24
  31   0.5768     80.360  0.4719    83.840  189.30
  32   0.5473     82.090  0.4700    83.874  195.37
  33   0.5327     81.880  0.4724    83.770  201.41
  34   0.5567     82.080  0.4626    83.944  207.49
  35   0.5085     83.040  0.4623    83.984  213.59
  36   0.5557     81.250  0.4543    84.178  219.65
  37   0.5340     82.230  0.4537    84.348  225.68
  38   0.5372     82.340  0.4564    84.200  231.70
  39   0.5227     82.190  0.4489    84.530  237.71
  40   0.5427     81.390  0.4573    84.236  243.71
  41   0.5154     82.480  0.4482    84.418  249.85
  42   0.5125     82.570  0.4544    84.234  255.87
  43   0.5306     82.670  0.4469    84.632  261.92
  44   0.6331     80.030  0.4513    84.366  267.95
  45   0.5241     82.510  0.4452    84.674  274.00
  46   0.5024     83.010  0.4486    84.556  280.08
  47   0.5199     82.970  0.4461    84.714  286.13
  48   0.5627     81.530  0.4481    84.772  292.14
  49   0.5170     83.270  0.4409    84.678  298.15
  50   0.5018     83.380  0.4344    85.012  304.19
  51   0.5621     81.420  0.4374    84.908  310.23
  52   0.5122     82.690  0.4411    84.834  316.33
  53   0.5439     81.790  0.4408    84.708  322.37
  54   0.5222     83.320  0.4391    84.774  328.41
  55   0.4943     83.440  0.4352    85.006  334.45
  56   0.4949     83.580  0.4344    84.996  340.48
  57   0.4988     83.760  0.4329    85.026  346.49
  58   0.5590     82.000  0.4317    84.900  352.51
  59   0.5062     83.460  0.4291    85.174  358.61
  60   0.4927     83.540  0.4280    85.154  364.64
  61   0.5111     82.740  0.4276    85.160  370.67
  62   0.5366     81.950  0.4297    85.076  376.70
  63   0.4970     83.360  0.4273    85.202  382.72
  64   0.5010     83.430  0.4244    85.242  388.74
  65   0.5056     82.740  0.4198    85.504  394.86
  66   0.5102     83.000  0.4255    85.490  400.93
  67   0.5677     81.760  0.4280    85.064  406.96
  68   0.5663     81.720  0.4217    85.268  413.01
  69   0.4987     83.350  0.4230    85.284  419.02
  70   0.4789     84.290  0.4290    85.280  425.05
  71   0.5221     83.290  0.4260    85.360  431.18
  72   0.5059     83.390  0.4211    85.404  437.23
  73   0.5236     82.790  0.4220    85.332  443.26
  74   0.4768     84.040  0.4235    85.186  449.28
  75   0.4987     83.660  0.4129    85.608  455.33
  76   0.4922     83.670  0.4209    85.386  461.39
  77   0.5089     83.200  0.4168    85.640  467.50
  78   0.5147     83.000  0.4150    85.504  473.57
  79   0.5559     82.150  0.4189    85.648  479.58
  80   0.5134     83.140  0.4187    85.556  485.62
  81   0.5635     82.160  0.4112    85.628  491.65
  82   0.5059     83.290  0.4147    85.582  497.73
  83   0.5334     82.610  0.4122    85.756  503.89
  84   0.5825     80.870  0.4179    85.458  509.90
  85   0.5038     83.600  0.4214    85.434  515.91
