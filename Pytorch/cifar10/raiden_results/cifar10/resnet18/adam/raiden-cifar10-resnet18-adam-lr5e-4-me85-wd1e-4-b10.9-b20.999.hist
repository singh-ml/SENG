Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5214     53.800  1.3713    49.740  7.72
   2   1.1145     63.630  0.9233    67.002  13.81
   3   0.7460     74.640  0.7231    74.658  19.84
   4   1.0530     65.980  0.6118    78.762  25.92
   5   0.6780     77.700  0.5411    81.246  31.98
   6   0.6517     78.290  0.4855    83.204  38.12
   7   0.5493     80.810  0.4406    84.718  44.18
   8   0.5987     80.500  0.4098    85.830  50.26
   9   0.4805     84.180  0.3770    86.896  56.31
  10   0.6297     80.960  0.3567    87.774  62.36
  11   0.5413     82.810  0.3296    88.666  68.41
  12   0.5123     83.770  0.3123    89.272  74.53
  13   0.5267     82.720  0.2967    89.596  80.61
  14   0.5553     82.500  0.2817    90.298  86.69
  15   0.4216     86.500  0.2608    90.962  92.73
  16   0.3813     87.690  0.2497    91.272  98.78
  17   0.4411     85.880  0.2334    91.812  104.87
  18   0.4129     86.930  0.2267    92.012  110.91
  19   0.6285     83.190  0.2110    92.542  116.93
  20   0.3919     87.560  0.2060    92.762  122.98
  21   0.3929     87.840  0.1870    93.532  129.02
  22   0.4327     86.840  0.1896    93.274  135.05
  23   0.3692     88.530  0.1734    93.868  141.08
  24   0.4142     87.710  0.1718    93.988  147.21
  25   0.3800     89.160  0.1627    94.400  153.27
  26   0.3805     88.470  0.1565    94.456  159.33
  27   0.3691     89.180  0.1531    94.610  165.38
  28   0.4338     87.690  0.1423    95.030  171.42
  29   0.4167     88.360  0.1396    95.088  177.46
  30   0.3883     88.740  0.1314    95.424  183.60
  31   0.4617     87.030  0.1305    95.482  189.64
  32   0.4064     88.430  0.1266    95.578  195.67
  33   0.3550     89.940  0.1221    95.658  201.71
  34   0.3812     89.480  0.1138    96.002  207.75
  35   0.3925     89.380  0.1091    96.228  213.77
  36   0.4051     88.980  0.1123    96.122  219.93
  37   0.4140     88.740  0.1048    96.410  225.99
  38   0.3672     89.640  0.1074    96.300  232.01
  39   0.3954     89.370  0.0991    96.528  238.07
  40   0.3994     89.570  0.0989    96.504  244.11
  41   0.4737     87.820  0.0960    96.642  250.13
  42   0.3958     90.000  0.0957    96.654  256.29
  43   0.3899     89.840  0.0882    96.856  262.34
  44   0.4026     89.720  0.0938    96.748  268.40
  45   0.3827     90.300  0.0865    97.024  274.41
  46   0.3853     90.050  0.0835    97.030  280.45
  47   0.4029     89.530  0.0845    97.022  286.57
  48   0.4107     90.020  0.0786    97.274  292.61
  49   0.3485     90.880  0.0867    96.958  298.66
  50   0.3889     89.990  0.0799    97.256  304.72
  51   0.4288     89.070  0.0738    97.402  310.77
  52   0.3425     91.380  0.0759    97.288  316.84
  53   0.3923     90.350  0.0714    97.512  322.92
  54   0.3536     90.830  0.0734    97.410  328.96
  55   0.5220     87.760  0.0703    97.528  335.01
  56   0.4115     89.760  0.0694    97.514  341.04
  57   0.3694     90.800  0.0721    97.436  347.09
  58   0.3898     89.840  0.0700    97.658  353.16
  59   0.3843     90.990  0.0624    97.874  359.28
  60   0.4180     89.590  0.0688    97.674  365.33
  61   0.4150     90.050  0.0740    97.418  371.39
  62   0.5274     87.970  0.0586    98.012  377.42
  63   0.5091     88.460  0.0655    97.728  383.47
  64   0.3663     90.690  0.0642    97.810  389.53
  65   0.4644     89.190  0.0585    97.966  395.59
  66   0.3916     90.430  0.0629    97.858  401.70
  67   0.4069     89.780  0.0625    97.864  407.75
  68   0.4186     89.970  0.0594    98.050  413.78
  69   0.3694     90.510  0.0661    97.700  419.86
  70   0.4197     89.810  0.0551    98.160  425.91
  71   0.4815     89.170  0.0606    97.908  432.01
  72   0.3945     90.440  0.0575    97.962  438.14
  73   0.3963     90.960  0.0607    97.930  444.19
  74   0.3774     90.470  0.0543    98.156  450.27
  75   0.3472     91.180  0.0589    98.024  456.32
  76   0.3870     90.580  0.0560    98.184  462.36
  77   0.4241     89.900  0.0563    98.074  468.41
  78   0.4007     89.780  0.0589    97.976  474.54
  79   0.3560     91.420  0.0574    98.042  480.60
  80   0.4073     90.210  0.0548    98.102  486.65
  81   0.3951     90.330  0.0568    98.034  492.69
  82   0.3810     91.020  0.0538    98.118  498.75
  83   0.3705     91.080  0.0542    98.148  504.82
  84   0.4275     89.890  0.0504    98.322  510.90
  85   0.4281     90.940  0.0495    98.296  516.96
