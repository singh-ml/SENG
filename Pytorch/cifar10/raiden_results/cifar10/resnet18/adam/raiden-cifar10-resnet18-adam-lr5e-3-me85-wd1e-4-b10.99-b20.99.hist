Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7090     34.210  1.9058    29.646  7.74
   2   1.3796     49.110  1.5633    42.010  13.81
   3   1.2797     53.750  1.3450    50.600  19.90
   4   1.1132     60.200  1.1685    57.860  25.97
   5   1.0229     63.890  1.0133    63.714  32.06
   6   0.9093     68.790  0.8833    68.838  38.17
   7   0.8212     71.580  0.8164    71.100  44.25
   8   0.7331     74.100  0.7295    74.262  50.35
   9   0.6916     75.960  0.6645    76.520  56.46
  10   0.7135     76.280  0.6075    78.784  62.55
  11   0.6225     79.380  0.5628    80.510  68.71
  12   0.6075     79.550  0.5295    81.530  74.80
  13   0.5969     80.130  0.5034    82.208  80.94
  14   0.5562     81.120  0.4717    83.534  87.02
  15   0.5266     82.550  0.4592    84.180  93.10
  16   0.4868     83.320  0.4333    85.036  99.17
  17   0.4932     83.270  0.4303    85.166  105.34
  18   0.4842     84.060  0.4115    85.740  111.45
  19   0.4853     83.500  0.4010    86.038  117.57
  20   0.4713     84.190  0.3899    86.538  123.65
  21   0.4880     83.880  0.3837    86.766  129.73
  22   0.4410     84.980  0.3769    87.082  135.81
  23   0.4382     85.750  0.3655    87.446  142.00
  24   0.4422     85.030  0.3630    87.374  148.10
  25   0.4428     85.410  0.3516    87.884  154.20
  26   0.4657     84.920  0.3435    88.204  160.30
  27   0.4397     85.390  0.3421    88.304  166.41
  28   0.4435     85.900  0.3394    88.162  172.53
  29   0.4431     85.740  0.3361    88.402  178.60
  30   0.4781     84.690  0.3312    88.520  184.71
  31   0.4198     86.240  0.3262    88.656  190.79
  32   0.4113     86.520  0.3232    88.792  196.89
  33   0.4220     85.980  0.3179    88.974  203.00
  34   0.3937     86.610  0.3136    89.126  209.14
  35   0.4029     86.520  0.3136    89.204  215.21
  36   0.4141     86.030  0.3135    89.226  221.27
  37   0.4104     86.350  0.3048    89.322  227.36
  38   0.4302     86.130  0.3093    89.278  233.46
  39   0.4442     85.520  0.3028    89.486  239.54
  40   0.4038     87.410  0.3065    89.498  245.62
  41   0.3811     87.350  0.2950    89.734  251.81
  42   0.4189     86.240  0.2995    89.700  257.88
  43   0.4080     86.760  0.3011    89.516  263.96
  44   0.4360     86.500  0.2910    89.794  270.06
  45   0.3942     87.160  0.2918    89.790  276.13
  46   0.3964     86.890  0.2874    89.972  282.20
  47   0.3927     86.980  0.2904    89.864  288.35
  48   0.3909     87.570  0.2875    90.136  294.45
  49   0.3778     87.660  0.2880    90.050  300.52
  50   0.3952     87.050  0.2813    90.218  306.60
  51   0.3796     87.310  0.2823    90.106  312.68
  52   0.4031     86.290  0.2873    90.064  318.79
  53   0.3987     87.250  0.2834    90.184  324.96
  54   0.3959     86.920  0.2755    90.454  331.04
  55   0.4073     86.790  0.2874    90.016  337.15
  56   0.3868     87.070  0.2804    90.212  343.28
  57   0.4092     86.430  0.2797    90.190  349.39
  58   0.4162     86.430  0.2825    90.336  355.61
  59   0.3758     87.510  0.2751    90.490  361.69
  60   0.4293     86.220  0.2757    90.356  367.77
  61   0.3738     87.930  0.2769    90.418  373.95
  62   0.3814     87.290  0.2679    90.672  380.07
  63   0.3849     87.240  0.2705    90.592  386.19
  64   0.4104     86.950  0.2709    90.554  392.27
  65   0.3986     86.840  0.2734    90.516  398.46
  66   0.3822     87.500  0.2677    90.682  404.56
  67   0.4193     86.330  0.2770    90.214  410.69
  68   0.4149     86.920  0.2732    90.512  416.79
  69   0.3877     87.410  0.2667    90.744  422.87
  70   0.3964     87.210  0.2703    90.466  429.00
  71   0.3722     87.610  0.2614    90.924  435.07
  72   0.3921     87.360  0.2661    90.798  441.21
  73   0.4139     86.610  0.2659    90.780  447.30
  74   0.4276     86.550  0.2661    90.694  453.41
  75   0.3754     87.480  0.2627    91.022  459.51
  76   0.3778     87.710  0.2689    90.580  465.65
  77   0.3625     87.810  0.2605    90.968  471.73
  78   0.3888     87.320  0.2592    90.942  477.80
  79   0.3677     88.010  0.2568    90.978  483.90
  80   0.3711     87.950  0.2574    91.042  489.97
  81   0.3785     87.830  0.2669    90.744  496.08
  82   0.3647     88.260  0.2596    90.998  502.29
  83   0.3631     88.280  0.2593    91.014  508.38
  84   0.3805     87.570  0.2587    90.974  514.44
  85   0.3861     87.320  0.2593    90.960  520.51
