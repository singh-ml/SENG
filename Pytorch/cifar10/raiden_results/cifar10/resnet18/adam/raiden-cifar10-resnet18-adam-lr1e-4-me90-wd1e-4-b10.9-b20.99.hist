Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3679     51.510  1.5765    42.012  7.70
   2   1.1283     59.540  1.2027    56.616  13.84
   3   0.9725     65.240  1.0292    63.354  20.00
   4   0.9147     68.040  0.9086    67.860  26.12
   5   0.8650     70.020  0.8190    70.920  32.29
   6   0.7948     72.090  0.7432    73.926  38.43
   7   0.7313     74.320  0.6835    75.996  44.59
   8   0.7282     75.280  0.6324    77.930  50.72
   9   0.7381     75.280  0.5884    79.360  56.88
  10   0.6090     78.770  0.5486    80.678  63.02
  11   0.6218     78.690  0.5166    81.802  69.22
  12   0.6012     79.450  0.4826    83.108  75.37
  13   0.5617     80.390  0.4524    84.098  81.54
  14   0.5437     81.470  0.4299    85.046  87.70
  15   0.6010     80.620  0.4061    85.808  93.86
  16   0.5334     82.220  0.3884    86.424  100.11
  17   0.6418     78.720  0.3709    86.822  106.22
  18   0.5022     82.900  0.3521    87.770  112.36
  19   0.5208     82.660  0.3310    88.434  118.47
  20   0.4973     83.730  0.3142    89.042  124.64
  21   0.5546     82.220  0.3022    89.402  130.86
  22   0.5258     83.510  0.2859    89.860  137.05
  23   0.5267     82.900  0.2730    90.308  143.17
  24   0.5144     83.480  0.2566    90.982  149.31
  25   0.5198     83.390  0.2496    91.302  155.43
  26   0.4939     84.790  0.2343    91.732  161.59
  27   0.5170     84.280  0.2224    92.332  167.86
  28   0.5234     84.190  0.2089    92.688  174.01
  29   0.5052     84.820  0.2043    92.890  180.17
  30   0.6384     82.190  0.1922    93.204  186.32
  31   0.5911     83.450  0.1836    93.504  192.47
  32   0.5231     84.630  0.1804    93.642  198.67
  33   0.5084     84.980  0.1695    94.038  204.83
  34   0.5052     85.290  0.1645    94.224  211.01
  35   0.5190     85.340  0.1568    94.484  217.17
  36   0.5082     85.540  0.1486    94.810  223.29
  37   0.5647     84.430  0.1406    95.064  229.54
  38   0.5690     84.960  0.1329    95.288  235.67
  39   0.5510     84.820  0.1286    95.446  241.80
  40   0.5454     85.440  0.1266    95.514  247.90
  41   0.5387     85.440  0.1231    95.640  254.07
  42   0.5585     85.250  0.1134    96.052  260.25
  43   0.5186     86.270  0.1115    96.084  266.45
  44   0.5779     84.850  0.1080    96.222  272.60
  45   0.5542     85.600  0.1034    96.360  278.76
  46   0.5222     86.820  0.0955    96.722  284.91
  47   0.6056     85.290  0.0926    96.778  291.03
  48   0.4994     86.890  0.0911    96.700  297.17
  49   0.5539     85.910  0.0862    96.974  303.38
  50   0.5356     86.370  0.0843    97.086  309.55
  51   0.5784     85.770  0.0838    97.070  315.69
  52   0.5687     86.200  0.0823    97.082  321.84
  53   0.5626     86.010  0.0794    97.234  327.96
  54   0.5236     87.040  0.0799    97.172  334.08
  55   0.5489     86.600  0.0726    97.516  340.29
  56   0.5374     86.920  0.0695    97.584  346.45
  57   0.5716     86.920  0.0734    97.484  352.61
  58   0.5528     87.340  0.0686    97.628  358.72
  59   0.5649     87.040  0.0653    97.728  364.87
  60   0.5569     86.700  0.0650    97.766  370.98
  61   0.5366     87.560  0.0631    97.798  377.20
  62   0.5672     87.370  0.0639    97.746  383.34
  63   0.5252     87.890  0.0605    97.884  389.50
  64   0.6583     85.100  0.0579    97.950  395.63
  65   0.5763     87.400  0.0603    97.926  401.76
  66   0.5391     87.270  0.0576    98.010  407.96
  67   0.5517     87.140  0.0540    98.136  414.11
  68   0.5616     87.060  0.0581    98.012  420.28
  69   0.6235     86.800  0.0504    98.282  426.49
  70   0.5667     88.060  0.0510    98.248  432.66
  71   0.5287     87.850  0.0536    98.128  438.91
  72   0.5716     87.210  0.0516    98.174  445.08
  73   0.5559     87.710  0.0492    98.274  451.24
  74   0.5927     87.320  0.0479    98.350  457.38
  75   0.5470     87.590  0.0467    98.318  463.53
  76   0.5530     87.550  0.0480    98.362  469.68
  77   0.5985     87.260  0.0442    98.500  475.88
  78   0.5512     87.920  0.0465    98.374  482.03
  79   0.5776     87.250  0.0449    98.486  488.18
  80   0.5648     87.690  0.0429    98.476  494.32
  81   0.5820     87.290  0.0442    98.446  500.47
  82   0.5701     87.750  0.0416    98.582  506.72
  83   0.5492     88.100  0.0424    98.520  512.88
  84   0.5459     87.700  0.0439    98.450  519.05
  85   0.5570     87.630  0.0393    98.632  525.17
  86   0.6034     87.360  0.0422    98.532  531.31
  87   0.5308     88.800  0.0379    98.746  537.53
  88   0.5863     87.180  0.0396    98.650  543.66
  89   0.5688     87.920  0.0369    98.742  549.79
  90   0.5756     87.880  0.0375    98.740  555.95
