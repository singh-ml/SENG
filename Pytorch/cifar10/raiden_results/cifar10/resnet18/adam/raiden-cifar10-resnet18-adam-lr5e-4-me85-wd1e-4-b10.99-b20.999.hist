Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2454     54.950  1.4853    45.546  7.70
   2   1.0586     62.230  1.0952    60.478  13.83
   3   0.8851     69.020  0.9132    67.238  20.03
   4   0.8562     69.990  0.7712    72.844  26.23
   5   0.7001     75.870  0.6755    76.124  32.32
   6   0.5794     79.840  0.5900    79.522  38.45
   7   0.5826     80.060  0.5292    81.536  44.55
   8   0.5199     82.220  0.4868    83.114  50.69
   9   0.5468     81.360  0.4436    84.624  56.85
  10   0.5123     82.990  0.4080    85.882  62.97
  11   0.4482     84.730  0.3830    86.744  69.09
  12   0.4449     85.210  0.3564    87.552  75.20
  13   0.4420     85.400  0.3355    88.418  81.28
  14   0.5080     83.540  0.3227    88.738  87.38
  15   0.4261     85.630  0.3061    89.246  93.47
  16   0.4121     86.950  0.2852    90.114  99.63
  17   0.4136     87.010  0.2612    91.002  105.70
  18   0.4485     86.330  0.2510    91.252  111.81
  19   0.3858     87.820  0.2442    91.478  117.88
  20   0.3993     87.430  0.2291    92.164  123.96
  21   0.3855     88.150  0.2140    92.548  130.03
  22   0.3473     88.590  0.2096    92.762  136.14
  23   0.4172     87.300  0.1971    93.092  142.32
  24   0.3859     88.310  0.1936    93.216  148.41
  25   0.4403     87.870  0.1823    93.674  154.50
  26   0.3622     88.750  0.1718    94.102  160.62
  27   0.3896     88.940  0.1630    94.328  166.76
  28   0.3998     88.640  0.1524    94.654  172.84
  29   0.3619     89.030  0.1615    94.308  178.95
  30   0.3969     89.120  0.1429    95.018  185.02
  31   0.3718     89.590  0.1409    95.046  191.09
  32   0.3795     89.840  0.1374    95.156  197.19
  33   0.3755     89.690  0.1314    95.506  203.30
  34   0.3475     89.560  0.1271    95.620  209.43
  35   0.3625     89.940  0.1233    95.594  215.57
  36   0.3507     90.030  0.1183    95.808  221.67
  37   0.3892     89.660  0.1103    96.214  227.79
  38   0.3858     89.680  0.1021    96.456  233.87
  39   0.3831     89.320  0.1097    96.254  240.00
  40   0.3923     89.760  0.1056    96.334  246.14
  41   0.3535     90.370  0.0988    96.618  252.25
  42   0.3748     90.210  0.1015    96.488  258.33
  43   0.3878     90.180  0.0945    96.720  264.44
  44   0.3716     90.080  0.0903    96.910  270.51
  45   0.3627     90.260  0.0913    96.898  276.60
  46   0.3749     89.670  0.0882    96.988  282.80
  47   0.3584     90.760  0.0860    97.036  288.94
  48   0.4128     90.180  0.0776    97.294  295.02
  49   0.3351     91.010  0.0835    97.102  301.08
  50   0.3834     90.540  0.0801    97.152  307.21
  51   0.3868     89.990  0.0870    96.918  313.37
  52   0.3671     91.140  0.0780    97.330  319.47
  53   0.4047     90.280  0.0722    97.514  325.56
  54   0.3547     90.780  0.0770    97.362  331.65
  55   0.4354     90.060  0.0766    97.376  337.72
  56   0.3689     90.690  0.0722    97.500  343.80
  57   0.3439     91.170  0.0697    97.618  349.93
  58   0.3796     90.320  0.0668    97.654  356.02
  59   0.4043     90.050  0.0716    97.530  362.13
  60   0.3846     90.980  0.0701    97.544  368.25
  61   0.3999     90.510  0.0725    97.464  374.35
  62   0.3683     91.100  0.0765    97.352  380.44
  63   0.3723     90.560  0.0672    97.722  386.57
  64   0.3668     90.960  0.0615    97.922  392.73
  65   0.3658     90.890  0.0611    97.896  398.87
  66   0.3858     90.750  0.0627    97.824  404.99
  67   0.3750     90.870  0.0619    97.886  411.08
  68   0.3849     90.980  0.0589    97.992  417.19
  69   0.4042     90.280  0.0648    97.784  423.28
  70   0.3642     91.340  0.0594    97.990  429.45
  71   0.3924     91.240  0.0582    97.900  435.52
  72   0.3995     91.020  0.0546    98.122  441.64
  73   0.3761     91.100  0.0586    98.008  447.72
  74   0.3719     91.060  0.0592    97.968  453.81
  75   0.4010     90.600  0.0589    97.928  459.89
  76   0.3707     91.150  0.0600    97.894  466.05
  77   0.3856     90.670  0.0567    98.114  472.19
  78   0.3576     91.340  0.0598    98.002  478.29
  79   0.3547     91.430  0.0532    98.114  484.38
  80   0.3769     91.420  0.0505    98.282  490.45
  81   0.3677     91.380  0.0528    98.182  496.62
  82   0.3801     91.020  0.0572    97.998  502.75
  83   0.3907     90.840  0.0556    98.140  508.83
  84   0.3597     91.160  0.0504    98.220  514.95
  85   0.3793     90.880  0.0529    98.170  521.11
