Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2649     54.580  1.4968    44.810  7.67
   2   1.0241     63.810  1.1197    59.522  13.72
   3   0.9264     67.130  0.9381    66.428  19.83
   4   0.7570     73.020  0.8013    71.588  25.90
   5   0.7328     74.850  0.6944    75.524  32.03
   6   0.6517     77.570  0.6184    78.484  38.10
   7   0.5888     79.790  0.5526    80.872  44.22
   8   0.5691     81.670  0.5022    82.610  50.27
   9   0.5044     82.960  0.4621    84.008  56.33
  10   0.6158     80.030  0.4266    85.340  62.38
  11   0.4748     83.550  0.4066    86.092  68.47
  12   0.4817     83.960  0.3826    86.822  74.63
  13   0.4832     83.490  0.3469    87.918  80.69
  14   0.5158     83.790  0.3280    88.772  86.77
  15   0.4219     86.370  0.3145    89.238  92.84
  16   0.4411     85.740  0.2927    89.864  98.92
  17   0.3909     87.260  0.2784    90.342  104.99
  18   0.3721     87.730  0.2665    90.672  111.07
  19   0.4107     87.100  0.2543    91.156  117.30
  20   0.3757     87.620  0.2327    91.984  123.39
  21   0.3458     88.710  0.2171    92.516  129.45
  22   0.3590     88.650  0.2095    92.626  135.50
  23   0.3894     88.320  0.2041    92.854  141.61
  24   0.3764     88.480  0.1882    93.506  147.68
  25   0.3674     89.020  0.1839    93.680  153.82
  26   0.3781     88.180  0.1800    93.728  159.88
  27   0.4205     87.580  0.1784    93.670  165.92
  28   0.3746     89.020  0.1731    94.008  171.99
  29   0.3768     88.660  0.1637    94.350  178.03
  30   0.3849     89.290  0.1551    94.530  184.09
  31   0.3549     89.320  0.1548    94.586  190.22
  32   0.3922     88.750  0.1482    94.850  196.37
  33   0.3497     90.110  0.1472    94.808  202.44
  34   0.3384     90.180  0.1382    95.160  208.49
  35   0.3441     90.290  0.1327    95.376  214.55
  36   0.3834     89.220  0.1367    95.094  220.66
  37   0.3967     89.210  0.1346    95.366  226.73
  38   0.3531     89.700  0.1364    95.250  232.83
  39   0.3739     89.240  0.1278    95.478  238.96
  40   0.4004     89.600  0.1232    95.686  245.03
  41   0.3502     89.760  0.1199    95.840  251.10
  42   0.4086     89.540  0.1129    96.086  257.24
  43   0.3823     89.850  0.1233    95.702  263.34
  44   0.3648     90.300  0.1172    95.902  269.40
  45   0.3840     89.640  0.1139    96.054  275.47
  46   0.3726     90.070  0.1142    96.040  281.57
  47   0.3953     89.650  0.1065    96.266  287.69
  48   0.3342     90.320  0.1087    96.240  293.84
  49   0.3439     90.460  0.1097    96.166  299.90
  50   0.3516     90.570  0.1021    96.420  305.99
  51   0.3694     90.380  0.1017    96.434  312.07
  52   0.3712     90.140  0.1022    96.406  318.16
  53   0.3582     90.610  0.0976    96.594  324.22
  54   0.3315     90.710  0.0971    96.718  330.35
  55   0.3475     90.580  0.0939    96.670  336.42
  56   0.3499     90.870  0.0915    96.846  342.52
  57   0.3559     90.740  0.0903    96.900  348.57
  58   0.3687     90.380  0.0909    96.916  354.69
  59   0.3740     90.700  0.0899    96.918  360.73
  60   0.3798     90.330  0.0902    96.894  366.87
  61   0.3298     91.610  0.0924    96.822  372.93
  62   0.3571     90.520  0.0904    96.858  378.99
  63   0.3391     91.150  0.0917    96.786  385.05
  64   0.3566     90.900  0.0853    97.002  391.12
  65   0.3810     90.260  0.0875    97.062  397.17
  66   0.3362     91.170  0.0840    97.060  403.22
  67   0.3788     90.450  0.0869    97.016  409.41
  68   0.3439     90.850  0.0861    97.022  415.45
  69   0.3590     90.790  0.0830    97.056  421.57
  70   0.3663     90.320  0.0894    96.942  427.63
  71   0.3618     90.630  0.0859    97.010  433.71
  72   0.3837     90.770  0.0835    97.076  439.81
  73   0.3923     90.320  0.0793    97.258  445.98
  74   0.3615     90.800  0.0800    97.214  452.07
  75   0.3654     90.990  0.0818    97.118  458.13
  76   0.3721     90.870  0.0819    97.192  464.23
  77   0.3504     90.690  0.0793    97.284  470.29
  78   0.3634     90.900  0.0779    97.300  476.46
  79   0.3924     90.280  0.0781    97.312  482.53
  80   0.3695     90.840  0.0777    97.380  488.59
  81   0.3608     91.120  0.0800    97.252  494.70
  82   0.3532     91.320  0.0774    97.296  500.79
  83   0.3678     90.930  0.0731    97.434  506.91
  84   0.3452     91.170  0.0778    97.314  513.05
  85   0.3741     90.660  0.0770    97.328  519.09
