Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3959     48.910  1.6281    39.668  7.67
   2   1.2336     55.550  1.2986    52.506  13.89
   3   1.0590     62.620  1.1120    59.870  19.99
   4   0.9332     66.720  0.9749    65.088  26.10
   5   0.8512     69.640  0.8677    69.228  32.24
   6   0.7959     71.900  0.7933    71.698  38.38
   7   0.7827     72.830  0.7196    74.690  44.51
   8   0.6745     76.530  0.6569    77.036  50.62
   9   0.6453     77.350  0.6081    78.716  56.77
  10   0.6403     77.930  0.5685    80.108  62.90
  11   0.5790     79.550  0.5403    80.910  69.03
  12   0.5702     80.530  0.5013    82.482  75.16
  13   0.5517     81.300  0.4699    83.420  81.41
  14   0.5470     81.670  0.4469    84.422  87.51
  15   0.5340     81.970  0.4211    85.260  93.62
  16   0.5379     81.990  0.3959    86.236  99.74
  17   0.4989     83.700  0.3825    86.612  105.83
  18   0.5294     82.430  0.3566    87.614  112.04
  19   0.4771     83.990  0.3394    88.022  118.18
  20   0.5083     83.280  0.3289    88.420  124.32
  21   0.5070     83.510  0.3094    89.240  130.43
  22   0.5035     83.340  0.3042    89.382  136.57
  23   0.4886     84.130  0.2858    90.114  142.66
  24   0.4778     84.900  0.2714    90.412  148.85
  25   0.4742     84.960  0.2548    91.148  154.96
  26   0.4859     84.470  0.2472    91.338  161.09
  27   0.4604     85.650  0.2287    92.060  167.18
  28   0.4460     85.970  0.2177    92.406  173.35
  29   0.4772     84.940  0.2094    92.868  179.55
  30   0.4723     85.730  0.1938    93.336  185.64
  31   0.4787     85.250  0.1911    93.320  191.79
  32   0.4665     85.670  0.1811    93.644  197.87
  33   0.4884     85.570  0.1766    93.866  204.01
  34   0.4592     86.090  0.1653    94.262  210.15
  35   0.4710     86.300  0.1587    94.390  216.36
  36   0.4696     86.150  0.1501    94.674  222.47
  37   0.4764     86.620  0.1418    94.976  228.55
  38   0.4587     87.040  0.1384    95.196  234.69
  39   0.4803     86.250  0.1321    95.434  240.83
  40   0.4560     87.360  0.1287    95.490  247.02
  41   0.4630     87.360  0.1236    95.722  253.16
  42   0.4912     86.330  0.1225    95.812  259.27
  43   0.4936     86.460  0.1186    95.826  265.39
  44   0.4963     86.590  0.1144    96.048  271.53
  45   0.4547     87.420  0.1122    96.134  277.61
  46   0.4549     87.780  0.1005    96.500  283.81
  47   0.4889     87.030  0.0880    96.938  289.91
  48   0.4750     87.500  0.0894    96.824  296.04
  49   0.4961     86.870  0.0945    96.654  302.12
  50   0.4935     87.060  0.0918    96.658  308.24
  51   0.4803     87.400  0.0900    96.800  314.36
  52   0.4967     87.060  0.0854    97.004  320.53
  53   0.4840     87.030  0.0820    97.116  326.72
  54   0.5127     86.800  0.0812    97.120  332.82
  55   0.4851     87.300  0.0751    97.494  338.92
  56   0.4932     87.790  0.0749    97.502  345.06
  57   0.4767     87.810  0.0765    97.340  351.19
  58   0.4970     87.770  0.0730    97.462  357.30
  59   0.4750     88.320  0.0705    97.622  363.41
  60   0.5049     87.270  0.0681    97.538  369.53
  61   0.4808     87.970  0.0679    97.628  375.65
  62   0.4762     87.940  0.0600    97.964  381.80
  63   0.5078     87.870  0.0641    97.804  388.04
  64   0.4895     88.030  0.0636    97.810  394.15
  65   0.4876     87.920  0.0601    97.932  400.25
  66   0.4814     88.090  0.0578    97.972  406.36
  67   0.5077     87.720  0.0538    98.162  412.47
  68   0.4952     88.070  0.0528    98.196  418.62
  69   0.5135     88.010  0.0559    98.070  424.73
  70   0.5061     87.620  0.0564    98.080  430.84
  71   0.5120     87.600  0.0585    97.942  436.98
  72   0.4948     88.000  0.0567    98.006  443.09
  73   0.5166     88.000  0.0542    98.170  449.18
  74   0.5175     87.520  0.0551    98.132  455.37
  75   0.4978     87.740  0.0489    98.396  461.51
  76   0.4900     88.380  0.0536    98.150  467.62
  77   0.5052     87.740  0.0498    98.318  473.75
  78   0.5356     87.360  0.0515    98.212  479.85
  79   0.5188     87.900  0.0500    98.264  486.11
  80   0.5171     87.830  0.0502    98.248  492.22
  81   0.5012     88.420  0.0459    98.410  498.36
  82   0.5304     88.300  0.0449    98.500  504.49
  83   0.5136     88.090  0.0453    98.456  510.65
  84   0.5214     87.770  0.0433    98.542  516.80
  85   0.5254     87.820  0.0426    98.576  522.94
  86   0.5334     87.670  0.0491    98.316  529.06
  87   0.5017     88.310  0.0454    98.448  535.17
  88   0.4945     88.580  0.0415    98.568  541.27
  89   0.5164     88.290  0.0423    98.574  547.36
  90   0.5154     87.870  0.0444    98.482  553.61
