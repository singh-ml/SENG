Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6235     47.760  1.3707    50.014  7.65
   2   0.9370     66.200  0.9347    66.540  13.80
   3   0.8176     72.240  0.7369    73.986  19.82
   4   0.7969     73.900  0.6357    77.784  25.86
   5   0.6816     76.910  0.5621    80.336  31.92
   6   0.6778     76.850  0.5080    82.450  38.00
   7   0.6928     77.420  0.4663    83.860  44.05
   8   0.6473     78.690  0.4377    84.886  50.20
   9   0.8900     73.710  0.4154    85.818  56.22
  10   0.4774     83.540  0.3861    86.878  62.27
  11   0.6090     81.730  0.3691    87.414  68.33
  12   0.6496     79.330  0.3548    87.840  74.35
  13   0.5011     83.520  0.3372    88.354  80.45
  14   0.4510     85.260  0.3186    89.226  86.53
  15   0.6740     79.600  0.3041    89.698  92.60
  16   0.4635     85.180  0.2932    89.974  98.69
  17   0.3990     87.170  0.2761    90.780  104.77
  18   0.4262     86.420  0.2644    91.070  110.87
  19   0.4518     85.360  0.2567    91.282  117.02
  20   0.5032     83.740  0.2505    91.518  123.05
  21   0.3769     87.650  0.2459    91.586  129.10
  22   0.3552     88.560  0.2323    92.140  135.14
  23   0.4082     87.000  0.2249    92.382  141.22
  24   0.3863     87.800  0.2199    92.450  147.27
  25   0.5586     84.410  0.2085    92.830  153.38
  26   0.4217     87.040  0.1991    93.238  159.40
  27   0.4347     86.760  0.2006    93.198  165.44
  28   0.4434     86.580  0.1901    93.404  171.51
  29   0.3657     89.140  0.1830    93.914  177.56
  30   0.3947     87.780  0.1853    93.722  183.67
  31   0.4729     86.130  0.1763    93.948  189.70
  32   0.4040     88.090  0.1779    93.848  195.77
  33   0.5469     84.370  0.1655    94.238  201.84
  34   0.4042     87.510  0.1650    94.364  207.86
  35   0.3927     87.840  0.1644    94.424  213.97
  36   0.3790     88.550  0.1532    94.780  219.98
  37   0.4018     88.470  0.1551    94.748  226.09
  38   0.3315     89.670  0.1530    94.762  232.19
  39   0.3922     88.420  0.1466    95.064  238.25
  40   0.3801     88.350  0.1454    95.120  244.31
  41   0.4759     87.170  0.1479    95.012  250.38
  42   0.4025     88.830  0.1385    95.182  256.46
  43   0.3808     88.140  0.1318    95.506  262.53
  44   0.3615     89.580  0.1342    95.442  268.60
  45   0.3844     89.090  0.1342    95.404  274.68
  46   0.3899     88.820  0.1328    95.494  280.79
  47   0.3837     88.920  0.1279    95.716  286.86
  48   0.3689     89.820  0.1279    95.554  292.90
  49   0.3658     89.250  0.1279    95.686  298.94
  50   0.3554     89.180  0.1257    95.754  304.99
  51   0.4398     88.680  0.1142    96.136  311.00
  52   0.3739     89.430  0.1208    95.988  317.14
  53   0.3893     89.480  0.1235    95.786  323.24
  54   0.3399     90.340  0.1129    96.038  329.30
  55   0.3405     90.230  0.1209    95.940  335.36
  56   0.3584     90.050  0.1148    96.100  341.41
  57   0.3623     90.140  0.1085    96.382  347.48
  58   0.3833     89.520  0.1164    96.038  353.63
  59   0.3939     89.370  0.1177    95.960  359.70
  60   0.4444     88.220  0.1099    96.318  365.75
  61   0.3700     89.940  0.1126    96.166  371.79
  62   0.3434     90.500  0.1112    96.248  377.81
  63   0.3793     90.380  0.1020    96.468  383.86
  64   0.3977     89.300  0.1108    96.174  389.98
  65   0.4043     89.050  0.1052    96.454  396.01
  66   0.4067     89.390  0.0968    96.782  402.09
  67   0.3402     90.650  0.1072    96.354  408.13
  68   0.3745     89.520  0.1013    96.550  414.17
  69   0.3666     89.960  0.1055    96.322  420.20
  70   0.3482     90.200  0.1029    96.472  426.30
  71   0.3665     90.370  0.0976    96.748  432.33
  72   0.3971     89.670  0.1016    96.612  438.37
  73   0.3661     90.180  0.1034    96.526  444.41
  74   0.3746     89.880  0.1011    96.648  450.45
  75   0.4453     88.560  0.0997    96.622  456.50
  76   0.3267     90.840  0.0963    96.706  462.62
  77   0.3515     90.170  0.0965    96.682  468.69
  78   0.3504     91.030  0.0985    96.740  474.77
  79   0.4353     89.390  0.0972    96.684  480.85
  80   0.3898     90.270  0.0945    96.804  486.91
  81   0.4500     88.060  0.0919    96.938  493.05
  82   0.3370     91.220  0.0974    96.716  499.13
  83   0.3552     90.410  0.0956    96.766  505.19
  84   0.3859     90.320  0.0952    96.692  511.24
  85   0.3539     90.260  0.0885    97.020  517.29
  86   0.3570     90.590  0.0908    96.962  523.34
  87   0.3845     90.180  0.0921    96.822  529.51
  88   0.3619     90.280  0.0929    96.862  535.58
  89   0.3586     90.150  0.0929    96.806  541.63
  90   0.3546     90.730  0.0921    96.904  547.74
