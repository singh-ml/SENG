Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2470     54.190  1.5104    44.150  7.67
   2   1.0805     61.680  1.1241    59.370  13.80
   3   0.8926     68.610  0.9329    66.910  19.97
   4   0.8251     71.480  0.7967    71.808  26.06
   5   0.7680     74.370  0.6831    76.378  32.15
   6   0.6677     76.870  0.6280    78.340  38.23
   7   0.5996     79.880  0.5561    80.942  44.31
   8   0.6264     79.130  0.5178    82.026  50.40
   9   0.6445     78.220  0.4795    83.548  56.55
  10   0.5256     82.020  0.4597    84.384  62.67
  11   0.5156     83.270  0.4254    85.554  68.77
  12   0.4973     83.210  0.3984    86.446  74.89
  13   0.5678     81.970  0.3686    87.472  81.01
  14   0.4928     83.610  0.3631    87.516  87.14
  15   0.4457     85.200  0.3562    87.954  93.21
  16   0.4159     86.130  0.3381    88.374  99.34
  17   0.4166     86.410  0.3211    88.912  105.46
  18   0.3961     86.820  0.3079    89.544  111.54
  19   0.4388     86.160  0.2958    89.960  117.63
  20   0.4047     87.200  0.2906    90.042  123.74
  21   0.3992     87.480  0.2814    90.356  129.92
  22   0.4111     86.630  0.2670    90.896  136.04
  23   0.4278     86.570  0.2650    91.054  142.17
  24   0.3782     87.600  0.2660    90.830  148.29
  25   0.3682     88.230  0.2570    91.302  154.41
  26   0.3909     87.580  0.2471    91.572  160.49
  27   0.3588     88.340  0.2424    91.678  166.67
  28   0.3730     88.750  0.2373    91.980  172.75
  29   0.3688     88.460  0.2407    91.802  178.83
  30   0.3982     87.430  0.2245    92.216  184.92
  31   0.3559     89.030  0.2204    92.420  191.00
  32   0.3732     87.880  0.2209    92.486  197.10
  33   0.3900     88.320  0.2208    92.412  203.26
  34   0.3538     89.210  0.2135    92.664  209.33
  35   0.3674     88.290  0.2055    92.922  215.43
  36   0.3659     88.930  0.2071    92.976  221.54
  37   0.3917     88.130  0.2014    93.162  227.66
  38   0.3338     89.630  0.1992    93.134  233.83
  39   0.3455     89.220  0.1981    93.160  239.93
  40   0.3671     88.970  0.1894    93.424  246.02
  41   0.3488     89.280  0.1922    93.442  252.11
  42   0.3807     88.700  0.1893    93.550  258.27
  43   0.3795     88.620  0.1872    93.528  264.37
  44   0.3629     89.080  0.1805    93.830  270.52
  45   0.4230     87.920  0.1865    93.700  276.62
  46   0.3389     89.270  0.1853    93.632  282.73
  47   0.3693     88.900  0.1807    93.872  288.84
  48   0.3461     89.340  0.1778    93.896  294.94
  49   0.3717     88.810  0.1696    94.140  301.01
  50   0.3431     89.180  0.1740    93.986  307.20
  51   0.3282     90.000  0.1760    93.886  313.32
  52   0.3561     89.100  0.1755    93.936  319.39
  53   0.3509     89.620  0.1674    94.256  325.52
  54   0.3568     89.640  0.1720    94.098  331.63
  55   0.3518     89.690  0.1698    94.230  337.71
  56   0.3362     89.810  0.1624    94.400  343.88
  57   0.3616     89.270  0.1700    94.092  349.98
  58   0.3629     89.190  0.1612    94.524  356.07
  59   0.3493     89.320  0.1614    94.520  362.17
  60   0.3542     89.700  0.1677    94.272  368.27
  61   0.3650     89.650  0.1570    94.598  374.35
  62   0.3519     89.130  0.1635    94.428  380.52
  63   0.3532     89.700  0.1558    94.752  386.60
  64   0.3542     89.540  0.1546    94.624  392.66
  65   0.3550     89.670  0.1608    94.456  398.78
  66   0.3356     89.840  0.1560    94.650  404.84
  67   0.3564     89.670  0.1479    94.876  410.97
  68   0.3691     89.700  0.1511    94.876  417.06
  69   0.3916     88.840  0.1559    94.624  423.15
  70   0.3670     89.400  0.1552    94.652  429.21
  71   0.3535     89.690  0.1508    94.850  435.28
  72   0.3734     89.110  0.1514    94.730  441.37
  73   0.3440     89.500  0.1514    94.832  447.57
  74   0.3300     90.300  0.1526    94.700  453.65
  75   0.3818     89.310  0.1476    94.984  459.74
  76   0.3406     90.050  0.1511    94.800  465.81
  77   0.3392     90.330  0.1481    94.938  471.93
  78   0.3508     90.280  0.1402    95.136  478.06
  79   0.3286     90.440  0.1431    95.048  484.20
  80   0.3624     89.600  0.1421    95.178  490.36
  81   0.3728     89.410  0.1476    94.874  496.47
  82   0.3509     90.190  0.1508    94.958  502.55
  83   0.3413     90.090  0.1491    94.772  508.72
  84   0.3537     89.880  0.1428    95.022  514.79
  85   0.3622     89.580  0.1415    95.158  520.96
  86   0.3544     90.150  0.1395    95.298  527.11
  87   0.3368     90.390  0.1401    95.198  533.20
  88   0.3491     90.050  0.1377    95.274  539.30
  89   0.3353     90.180  0.1426    95.136  545.37
  90   0.3441     90.420  0.1395    95.148  551.47
