Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2943     52.350  1.5630    41.870  7.79
   2   1.0787     61.190  1.2045    56.260  13.97
   3   0.9751     66.090  0.9970    64.256  20.10
   4   0.8336     70.790  0.8669    69.358  26.29
   5   0.7554     73.540  0.7505    73.694  32.54
   6   0.6629     77.340  0.6605    76.744  38.70
   7   0.6412     78.310  0.6035    78.940  44.90
   8   0.6418     78.390  0.5460    81.048  51.04
   9   0.5948     79.660  0.4977    82.586  57.18
  10   0.5243     82.380  0.4657    83.764  63.33
  11   0.5422     81.710  0.4324    85.112  69.55
  12   0.4824     84.010  0.4054    86.030  75.73
  13   0.4752     83.860  0.3773    86.952  81.90
  14   0.4878     83.870  0.3529    87.808  88.03
  15   0.4402     85.110  0.3321    88.512  94.22
  16   0.4458     85.310  0.3143    89.070  100.40
  17   0.4412     85.530  0.2953    89.768  106.61
  18   0.4437     85.910  0.2901    90.042  112.76
  19   0.4473     85.440  0.2792    90.324  118.92
  20   0.4260     85.930  0.2647    90.712  125.11
  21   0.4113     87.010  0.2471    91.534  131.26
  22   0.4231     86.210  0.2332    92.068  137.48
  23   0.4497     86.140  0.2247    92.178  143.64
  24   0.4063     87.030  0.2189    92.424  149.79
  25   0.4254     86.710  0.2096    92.740  155.97
  26   0.4055     87.130  0.2011    92.956  162.13
  27   0.4279     86.810  0.1910    93.358  168.32
  28   0.4013     87.620  0.1829    93.682  174.57
  29   0.3992     87.650  0.1723    94.056  180.76
  30   0.4293     87.130  0.1716    94.066  186.93
  31   0.3762     88.550  0.1674    94.176  193.11
  32   0.4102     87.900  0.1579    94.542  199.28
  33   0.3679     88.910  0.1526    94.740  205.54
  34   0.3972     88.280  0.1457    95.002  211.68
  35   0.4050     88.000  0.1429    95.060  217.84
  36   0.4064     88.150  0.1362    95.312  224.03
  37   0.4553     87.350  0.1328    95.366  230.20
  38   0.4371     87.500  0.1338    95.318  236.45
  39   0.3961     88.700  0.1282    95.630  242.63
  40   0.3668     89.350  0.1220    95.770  248.77
  41   0.3929     88.850  0.1163    95.940  254.93
  42   0.4124     88.630  0.1120    96.102  261.11
  43   0.3961     88.920  0.1092    96.216  267.24
  44   0.3870     89.250  0.1108    96.220  273.48
  45   0.4224     88.280  0.1040    96.378  279.63
  46   0.3800     89.350  0.1000    96.598  285.75
  47   0.3885     89.230  0.1040    96.442  291.88
  48   0.4187     88.440  0.0959    96.706  298.03
  49   0.3886     89.080  0.0993    96.544  304.23
  50   0.4061     88.750  0.0909    96.964  310.41
  51   0.4040     89.190  0.0950    96.776  316.58
  52   0.3683     89.580  0.0929    96.876  322.74
  53   0.3659     89.760  0.0927    96.780  328.90
  54   0.3959     89.320  0.0915    96.826  335.15
  55   0.3860     89.600  0.0875    96.960  341.30
  56   0.4086     89.210  0.0861    97.056  347.47
  57   0.3852     89.780  0.0816    97.192  353.63
  58   0.3915     89.390  0.0841    97.146  359.82
  59   0.3676     90.080  0.0815    97.210  365.98
  60   0.3693     89.940  0.0778    97.386  372.17
  61   0.4087     89.430  0.0794    97.332  378.32
  62   0.3901     89.350  0.0761    97.480  384.47
  63   0.3914     89.410  0.0753    97.402  390.61
  64   0.3744     90.180  0.0730    97.470  396.78
  65   0.3742     90.020  0.0735    97.560  403.02
  66   0.3752     89.840  0.0746    97.460  409.21
  67   0.3650     90.390  0.0739    97.534  415.35
  68   0.4471     88.680  0.0672    97.726  421.49
  69   0.4063     89.560  0.0730    97.558  427.65
  70   0.3728     90.160  0.0729    97.572  433.80
  71   0.3827     90.120  0.0700    97.656  440.04
  72   0.3970     90.200  0.0655    97.776  446.21
  73   0.3831     89.650  0.0683    97.704  452.37
  74   0.4013     89.530  0.0729    97.560  458.51
  75   0.3838     89.920  0.0690    97.756  464.67
  76   0.3748     90.290  0.0668    97.836  470.86
  77   0.4102     89.560  0.0614    97.956  477.11
  78   0.3754     89.980  0.0656    97.766  483.28
  79   0.3532     90.700  0.0645    97.814  489.43
  80   0.3699     90.310  0.0628    97.890  495.60
  81   0.3740     89.730  0.0635    97.838  501.77
  82   0.3880     89.850  0.0636    97.880  507.96
  83   0.3634     90.730  0.0584    98.046  514.11
  84   0.3497     90.820  0.0615    97.928  520.33
  85   0.3908     90.190  0.0597    98.030  526.56
