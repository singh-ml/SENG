Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5966     40.350  1.8838    30.462  7.68
   2   1.4130     47.640  1.5012    44.518  13.81
   3   1.2339     55.120  1.3132    51.806  19.93
   4   1.1468     59.340  1.1715    57.976  26.02
   5   1.0316     63.320  1.0174    63.746  32.12
   6   1.0007     64.490  0.9269    67.140  38.24
   7   0.8744     70.290  0.8353    70.428  44.33
   8   0.8240     71.390  0.7623    73.374  50.44
   9   0.7510     74.100  0.7023    75.344  56.63
  10   0.7224     75.080  0.6762    76.478  62.70
  11   0.7304     75.560  0.6429    77.490  68.79
  12   0.7360     75.440  0.6216    78.600  74.90
  13   0.6742     76.940  0.6080    78.962  80.99
  14   0.7170     76.200  0.5890    79.626  87.19
  15   0.6207     79.450  0.5881    79.748  93.30
  16   0.6359     78.300  0.5713    80.162  99.39
  17   0.5967     79.480  0.5637    80.718  105.47
  18   0.5946     79.810  0.5463    81.362  111.61
  19   0.6464     78.440  0.5386    81.632  117.71
  20   0.5868     80.020  0.5369    81.470  123.92
  21   0.5845     80.250  0.5362    81.410  130.03
  22   0.6028     79.210  0.5311    81.682  136.16
  23   0.5682     80.790  0.5182    82.074  142.22
  24   0.6430     78.220  0.5122    82.440  148.36
  25   0.6130     79.820  0.5200    81.970  154.48
  26   0.5784     79.740  0.5125    82.292  160.65
  27   0.6394     78.510  0.4968    82.964  166.74
  28   0.6296     78.560  0.5058    82.532  172.85
  29   0.5561     81.170  0.4957    82.960  178.97
  30   0.6491     77.480  0.4984    82.884  185.12
  31   0.5868     80.630  0.4941    83.162  191.22
  32   0.6260     79.050  0.4905    83.240  197.39
  33   0.5970     79.940  0.4903    83.104  203.51
  34   0.5141     82.540  0.4787    83.570  209.60
  35   0.6129     79.750  0.4767    83.614  215.74
  36   0.6394     78.840  0.4815    83.626  221.83
  37   0.5509     81.420  0.4805    83.428  227.95
  38   0.5858     80.430  0.4809    83.472  234.16
  39   0.6670     78.640  0.4669    83.896  240.29
  40   0.6123     80.040  0.4717    83.704  246.43
  41   0.5927     80.110  0.4711    83.796  252.56
  42   0.5323     82.000  0.4652    84.088  258.65
  43   0.5622     81.410  0.4627    84.170  264.84
  44   0.5402     81.780  0.4640    84.028  270.98
  45   0.5490     81.880  0.4648    83.996  277.07
  46   0.5342     81.690  0.4685    83.858  283.17
  47   0.5549     81.650  0.4646    84.032  289.26
  48   0.5106     82.430  0.4653    84.136  295.35
  49   0.5256     82.490  0.4525    84.366  301.57
  50   0.5041     83.230  0.4552    84.300  307.67
  51   0.5176     82.430  0.4507    84.670  313.80
  52   0.5930     80.450  0.4477    84.584  319.92
  53   0.5405     81.850  0.4596    84.184  326.03
  54   0.5947     80.390  0.4594    84.034  332.25
  55   0.5642     81.290  0.4546    84.432  338.36
  56   0.5597     80.880  0.4620    84.166  344.49
  57   0.5459     81.450  0.4528    84.404  350.59
  58   0.5492     81.570  0.4529    84.446  356.68
  59   0.5352     81.650  0.4511    84.424  362.89
  60   0.5491     81.580  0.4516    84.474  368.99
  61   0.6036     80.130  0.4394    84.934  375.08
  62   0.5382     81.800  0.4489    84.392  381.19
  63   0.6240     79.540  0.4476    84.706  387.34
  64   0.5232     82.460  0.4480    84.682  393.48
  65   0.5196     82.060  0.4441    84.820  399.63
  66   0.5526     80.900  0.4526    84.304  405.75
  67   0.5771     80.510  0.4401    84.890  411.87
  68   0.5231     82.760  0.4354    84.842  417.97
  69   0.5456     81.540  0.4444    84.676  424.09
  70   0.5071     83.160  0.4470    84.782  430.25
  71   0.5401     82.120  0.4446    84.750  436.35
  72   0.5697     81.110  0.4442    84.624  442.50
  73   0.4938     83.140  0.4426    84.684  448.62
  74   0.5331     82.150  0.4390    84.914  454.70
  75   0.4950     83.150  0.4376    85.086  460.83
  76   0.5843     81.130  0.4439    84.716  467.00
  77   0.5046     82.800  0.4385    85.050  473.10
  78   0.5902     80.270  0.4419    84.898  479.22
  79   0.5291     82.490  0.4337    85.302  485.34
  80   0.6632     78.210  0.4398    84.950  491.47
  81   0.5332     81.970  0.4381    84.850  497.58
  82   0.5583     81.750  0.4420    84.794  503.72
  83   0.5060     83.260  0.4421    84.878  509.83
  84   0.5268     81.750  0.4351    84.934  515.94
  85   0.5545     81.190  0.4354    85.072  522.03
  86   0.5810     80.960  0.4413    84.864  528.15
  87   0.4965     82.890  0.4289    85.284  534.28
  88   0.7231     77.720  0.4357    84.850  540.40
  89   0.5774     81.230  0.4390    84.870  546.49
  90   0.5074     82.600  0.4339    85.158  552.62
