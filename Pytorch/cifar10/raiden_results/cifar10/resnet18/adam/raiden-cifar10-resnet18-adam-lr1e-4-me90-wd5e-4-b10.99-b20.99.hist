Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3751     49.850  1.6240    40.014  7.57
   2   1.1555     58.070  1.2658    54.022  13.74
   3   1.0331     62.850  1.0829    60.944  19.81
   4   0.9113     67.610  0.9546    65.722  25.90
   5   0.8697     69.170  0.8752    68.598  31.97
   6   0.7987     71.400  0.7949    71.836  38.02
   7   0.7731     72.910  0.7268    74.442  44.14
   8   0.7156     75.170  0.6670    76.402  50.19
   9   0.7079     76.120  0.6168    78.260  56.26
  10   0.7159     75.330  0.5813    79.682  62.33
  11   0.6173     78.710  0.5402    81.070  68.42
  12   0.5830     79.960  0.4998    82.554  74.49
  13   0.6319     79.060  0.4749    83.414  80.67
  14   0.5459     81.200  0.4486    84.368  86.72
  15   0.5439     81.730  0.4273    85.042  92.80
  16   0.5419     81.800  0.4058    85.798  98.86
  17   0.5126     82.950  0.3819    86.656  104.95
  18   0.5341     82.340  0.3691    87.114  111.11
  19   0.5521     82.100  0.3549    87.722  117.16
  20   0.5087     82.990  0.3351    88.398  123.23
  21   0.5144     83.000  0.3096    89.170  129.30
  22   0.4891     84.260  0.2943    89.762  135.35
  23   0.5213     83.430  0.2961    89.622  141.45
  24   0.5104     83.710  0.2775    90.458  147.57
  25   0.4833     84.570  0.2654    90.802  153.65
  26   0.4772     84.560  0.2574    91.034  159.72
  27   0.5109     84.060  0.2396    91.660  165.80
  28   0.4747     85.340  0.2294    92.026  171.86
  29   0.4789     84.970  0.2181    92.484  177.92
  30   0.4737     85.570  0.2086    92.746  184.03
  31   0.4914     84.670  0.2032    93.000  190.12
  32   0.4768     85.560  0.1948    93.214  196.20
  33   0.4812     85.260  0.1808    93.824  202.28
  34   0.5037     85.130  0.1756    93.880  208.35
  35   0.4886     85.540  0.1690    94.146  214.42
  36   0.4644     86.020  0.1645    94.214  220.51
  37   0.4756     85.570  0.1555    94.720  226.65
  38   0.4660     86.220  0.1516    94.802  232.74
  39   0.5009     85.910  0.1484    94.890  238.83
  40   0.4664     86.500  0.1442    95.044  244.90
  41   0.4998     86.240  0.1326    95.486  250.99
  42   0.4649     86.700  0.1355    95.278  257.05
  43   0.4915     86.090  0.1307    95.534  263.17
  44   0.4572     86.830  0.1254    95.698  269.25
  45   0.4648     86.630  0.1191    95.868  275.30
  46   0.5067     86.310  0.1197    95.812  281.36
  47   0.4643     87.100  0.1111    96.140  287.42
  48   0.4856     86.950  0.1060    96.370  293.48
  49   0.4674     87.220  0.1063    96.304  299.61
  50   0.4693     86.920  0.1046    96.364  305.68
  51   0.4733     86.980  0.1015    96.606  311.74
  52   0.4608     87.160  0.0973    96.706  317.80
  53   0.4691     86.770  0.0988    96.544  323.85
  54   0.4482     87.830  0.0928    96.794  329.99
  55   0.4669     87.540  0.0886    96.988  336.04
  56   0.4723     87.410  0.0894    96.950  342.13
  57   0.4895     87.010  0.0882    97.004  348.23
  58   0.4767     87.170  0.0854    97.076  354.37
  59   0.4646     87.790  0.0896    96.868  360.47
  60   0.4851     87.420  0.0813    97.262  366.61
  61   0.4728     87.820  0.0819    97.214  372.74
  62   0.4697     87.560  0.0749    97.408  378.81
  63   0.4667     87.390  0.0783    97.346  384.92
  64   0.4417     88.060  0.0771    97.364  391.08
  65   0.5198     86.850  0.0692    97.680  397.17
  66   0.5002     87.490  0.0709    97.624  403.31
  67   0.5042     87.430  0.0681    97.754  409.42
  68   0.4638     88.160  0.0632    97.886  415.54
  69   0.4710     87.870  0.0704    97.526  421.60
  70   0.4869     87.960  0.0707    97.652  427.66
  71   0.4785     87.500  0.0686    97.704  433.78
  72   0.4944     87.990  0.0649    97.856  439.83
  73   0.4515     88.560  0.0675    97.712  445.93
  74   0.4653     87.960  0.0665    97.744  452.01
  75   0.4781     87.970  0.0631    97.858  458.11
  76   0.4759     88.100  0.0590    98.012  464.16
  77   0.4596     88.250  0.0574    98.102  470.30
  78   0.4765     88.100  0.0591    98.002  476.35
  79   0.4665     88.570  0.0563    98.164  482.44
  80   0.5007     87.780  0.0556    98.142  488.51
  81   0.4589     88.590  0.0565    98.136  494.60
  82   0.5228     87.290  0.0581    98.078  500.70
  83   0.4988     87.980  0.0597    97.988  506.75
  84   0.5089     87.440  0.0610    97.952  512.92
  85   0.4493     88.670  0.0575    98.104  519.01
  86   0.4860     88.170  0.0541    98.208  525.10
  87   0.4617     88.570  0.0574    98.090  531.18
  88   0.4681     88.610  0.0540    98.214  537.25
  89   0.4945     88.210  0.0518    98.358  543.40
  90   0.4533     88.920  0.0530    98.256  549.48
