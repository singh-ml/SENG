Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2964     52.700  1.5585    42.440  7.92
   2   1.1230     60.210  1.1603    58.040  14.06
   3   0.9280     66.990  0.9608    65.646  20.23
   4   0.8959     69.070  0.8259    70.738  26.48
   5   0.7472     74.400  0.7173    74.692  32.64
   6   0.6862     76.260  0.6469    77.288  38.77
   7   0.6718     77.820  0.5795    79.796  44.91
   8   0.5401     81.060  0.5197    82.080  51.04
   9   0.5296     82.230  0.4817    83.460  57.22
  10   0.5079     83.620  0.4459    84.516  63.41
  11   0.5431     82.120  0.4122    85.636  69.61
  12   0.5090     83.120  0.3948    86.342  75.76
  13   0.4276     85.290  0.3672    87.392  81.93
  14   0.4359     85.820  0.3457    88.176  88.05
  15   0.4142     86.100  0.3233    88.828  94.17
  16   0.4481     85.580  0.3065    89.412  100.39
  17   0.4787     84.750  0.2957    89.820  106.53
  18   0.4218     86.370  0.2819    90.230  112.67
  19   0.3872     87.530  0.2610    91.106  118.80
  20   0.3961     87.640  0.2419    91.668  124.97
  21   0.3605     88.310  0.2427    91.572  131.16
  22   0.3740     87.840  0.2304    92.054  137.29
  23   0.4163     86.960  0.2195    92.500  143.41
  24   0.3588     88.710  0.2098    92.740  149.58
  25   0.3872     88.470  0.1944    93.306  155.71
  26   0.3816     88.850  0.1885    93.550  161.96
  27   0.4021     88.270  0.1906    93.442  168.09
  28   0.3497     89.030  0.1810    93.654  174.26
  29   0.3527     89.500  0.1725    94.064  180.36
  30   0.3793     89.170  0.1688    94.062  186.51
  31   0.3581     89.810  0.1573    94.536  192.72
  32   0.3729     89.410  0.1536    94.676  198.86
  33   0.3404     89.700  0.1510    94.760  205.00
  34   0.3588     89.810  0.1383    95.224  211.16
  35   0.3615     89.990  0.1430    95.076  217.32
  36   0.3534     90.070  0.1308    95.400  223.45
  37   0.3267     90.070  0.1352    95.268  229.63
  38   0.3607     89.390  0.1274    95.558  235.80
  39   0.3734     89.220  0.1317    95.340  241.91
  40   0.3486     90.770  0.1242    95.574  248.03
  41   0.3595     90.140  0.1241    95.642  254.17
  42   0.3648     90.200  0.1209    95.784  260.33
  43   0.3444     90.320  0.1164    95.994  266.48
  44   0.3557     90.620  0.1100    96.108  272.63
  45   0.3136     91.160  0.1128    96.040  278.78
  46   0.3569     90.730  0.1112    96.206  284.90
  47   0.3293     91.100  0.1084    96.246  291.04
  48   0.3542     90.520  0.0959    96.686  297.16
  49   0.3512     90.480  0.1038    96.412  303.35
  50   0.3691     90.510  0.1043    96.386  309.51
  51   0.3676     90.420  0.1076    96.252  315.62
  52   0.3679     90.860  0.0998    96.512  321.74
  53   0.3736     89.730  0.0986    96.554  327.87
  54   0.3413     90.740  0.0960    96.682  334.08
  55   0.3497     91.030  0.0972    96.640  340.20
  56   0.3488     90.880  0.0932    96.842  346.35
  57   0.3402     91.030  0.0903    96.900  352.53
  58   0.3506     91.220  0.0850    97.080  358.69
  59   0.3583     90.900  0.0901    96.914  364.85
  60   0.3751     90.790  0.0911    96.884  371.03
  61   0.3444     91.100  0.0882    96.902  377.19
  62   0.3497     91.310  0.0844    97.068  383.33
  63   0.3385     91.130  0.0906    96.932  389.49
  64   0.3569     90.740  0.0868    96.974  395.61
  65   0.3545     91.030  0.0866    96.992  401.76
  66   0.3622     91.360  0.0816    97.204  407.98
  67   0.3649     90.610  0.0900    96.904  414.11
  68   0.3556     90.930  0.0896    96.966  420.26
  69   0.3622     91.110  0.0894    96.912  426.38
  70   0.3701     91.050  0.0850    97.052  432.53
  71   0.3645     91.120  0.0848    97.080  438.64
  72   0.3645     90.900  0.0820    97.134  444.80
  73   0.3811     90.690  0.0877    96.914  451.03
  74   0.3619     90.830  0.0826    97.170  457.14
  75   0.3796     90.440  0.0806    97.234  463.27
  76   0.3370     91.360  0.0807    97.164  469.45
  77   0.3935     90.540  0.0812    97.216  475.57
  78   0.3548     91.230  0.0825    97.150  481.83
  79   0.3674     91.250  0.0792    97.288  488.03
  80   0.3366     91.510  0.0713    97.476  494.25
  81   0.3599     91.440  0.0773    97.404  500.40
  82   0.3769     90.840  0.0798    97.228  506.54
  83   0.3702     91.360  0.0757    97.406  512.73
  84   0.3820     90.760  0.0748    97.410  518.89
  85   0.3878     90.990  0.0788    97.288  525.02
