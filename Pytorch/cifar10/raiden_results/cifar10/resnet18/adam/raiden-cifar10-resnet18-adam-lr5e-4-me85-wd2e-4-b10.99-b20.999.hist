Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2142     56.010  1.4665    45.836  7.54
   2   0.9753     65.140  1.0757    61.152  13.66
   3   0.8593     68.870  0.8951    68.078  19.88
   4   0.7419     74.110  0.7562    73.206  26.03
   5   0.6539     78.020  0.6574    76.816  32.10
   6   0.5945     79.410  0.5846    79.566  38.15
   7   0.5541     81.220  0.5285    81.570  44.21
   8   0.5066     82.860  0.4816    83.274  50.30
   9   0.5023     83.100  0.4517    84.374  56.45
  10   0.4817     83.390  0.4059    85.916  62.49
  11   0.4696     84.720  0.3880    86.504  68.59
  12   0.4349     85.510  0.3622    87.364  74.66
  13   0.5123     83.280  0.3472    87.952  80.74
  14   0.4119     86.080  0.3271    88.780  86.79
  15   0.4469     85.360  0.3043    89.516  92.92
  16   0.4389     85.640  0.2871    90.050  98.98
  17   0.4654     84.760  0.2723    90.472  105.05
  18   0.4010     87.290  0.2617    90.974  111.12
  19   0.3841     87.880  0.2526    91.330  117.18
  20   0.3508     88.240  0.2398    91.550  123.26
  21   0.3673     88.110  0.2183    92.452  129.39
  22   0.3803     87.940  0.2137    92.708  135.45
  23   0.3683     88.650  0.2046    92.884  141.52
  24   0.3728     87.740  0.1997    93.080  147.59
  25   0.3891     87.800  0.1874    93.562  153.64
  26   0.3750     88.570  0.1814    93.752  159.70
  27   0.3992     88.040  0.1806    93.802  165.85
  28   0.3661     88.930  0.1708    94.008  171.90
  29   0.3578     89.340  0.1653    94.290  177.97
  30   0.3782     88.920  0.1579    94.554  184.08
  31   0.3872     89.160  0.1517    94.686  190.18
  32   0.3674     89.410  0.1510    94.760  196.35
  33   0.3780     89.070  0.1480    94.952  202.39
  34   0.3724     89.240  0.1358    95.234  208.45
  35   0.4160     88.590  0.1339    95.402  214.50
  36   0.3655     90.020  0.1312    95.480  220.56
  37   0.3534     89.820  0.1244    95.722  226.62
  38   0.3501     89.900  0.1249    95.544  232.74
  39   0.3584     89.890  0.1187    95.898  238.80
  40   0.3354     90.690  0.1159    96.020  244.85
  41   0.3463     90.420  0.1095    96.226  250.91
  42   0.3355     90.600  0.1110    96.186  256.98
  43   0.3522     90.320  0.1104    96.236  263.05
  44   0.4189     89.120  0.1106    96.208  269.26
  45   0.3655     89.750  0.1136    96.086  275.34
  46   0.3823     90.430  0.0953    96.760  281.41
  47   0.3515     90.800  0.0950    96.790  287.50
  48   0.3279     90.720  0.0985    96.660  293.60
  49   0.3455     91.090  0.0909    96.880  299.71
  50   0.3575     90.680  0.0929    96.746  305.78
  51   0.3449     90.830  0.0954    96.718  311.85
  52   0.3623     90.810  0.0946    96.674  317.90
  53   0.3840     90.060  0.0953    96.800  323.95
  54   0.3705     90.880  0.0909    96.776  330.02
  55   0.3669     90.570  0.0907    96.888  336.11
  56   0.3462     90.970  0.0821    97.176  342.28
  57   0.3559     90.290  0.0838    97.108  348.36
  58   0.3502     90.650  0.0846    97.130  354.45
  59   0.3338     90.740  0.0829    97.154  360.52
  60   0.3736     90.670  0.0782    97.296  366.57
  61   0.3313     91.170  0.0799    97.234  372.61
  62   0.3381     91.140  0.0770    97.412  378.78
  63   0.3339     91.270  0.0819    97.168  384.87
  64   0.3447     90.850  0.0788    97.314  390.93
  65   0.3664     90.730  0.0778    97.372  396.99
  66   0.3281     91.090  0.0774    97.364  403.07
  67   0.3480     91.030  0.0823    97.240  409.25
  68   0.3735     90.980  0.0779    97.300  415.33
  69   0.3744     90.610  0.0714    97.588  421.38
  70   0.3307     91.330  0.0758    97.426  427.44
  71   0.3677     90.450  0.0726    97.566  433.50
  72   0.3451     91.180  0.0648    97.766  439.59
  73   0.3865     90.450  0.0695    97.646  445.69
  74   0.3517     91.410  0.0722    97.540  451.73
  75   0.3087     91.620  0.0731    97.490  457.79
  76   0.3324     91.370  0.0674    97.656  463.86
  77   0.3710     90.690  0.0673    97.672  469.92
  78   0.3411     90.730  0.0671    97.712  476.10
  79   0.3460     91.930  0.0637    97.816  482.20
  80   0.3626     91.160  0.0615    97.898  488.28
  81   0.3591     91.010  0.0736    97.476  494.37
  82   0.3488     90.830  0.0774    97.340  500.43
  83   0.3414     91.490  0.0714    97.544  506.53
  84   0.3448     91.460  0.0698    97.626  512.65
  85   0.3566     91.210  0.0635    97.756  518.75
