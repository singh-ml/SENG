Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3126     52.980  1.4922    44.802  7.61
   2   1.0274     63.430  1.0928    60.320  13.75
   3   0.8528     70.220  0.8924    68.160  19.96
   4   0.7375     74.220  0.7581    73.446  26.06
   5   0.6598     77.260  0.6581    76.834  32.17
   6   0.6036     79.250  0.5850    79.530  38.26
   7   0.5894     80.030  0.5199    82.018  44.32
   8   0.6006     80.190  0.4803    83.528  50.45
   9   0.5800     80.670  0.4548    84.174  56.63
  10   0.5949     80.430  0.4287    85.256  62.79
  11   0.4737     84.610  0.3972    86.198  68.87
  12   0.4662     84.750  0.3697    87.218  75.01
  13   0.4404     85.510  0.3446    88.076  81.09
  14   0.4593     84.900  0.3169    89.052  87.16
  15   0.4407     86.170  0.3028    89.530  93.34
  16   0.4185     86.730  0.2830    90.072  99.43
  17   0.4055     87.290  0.2742    90.324  105.48
  18   0.3887     87.850  0.2637    90.886  111.58
  19   0.3813     87.690  0.2511    91.254  117.65
  20   0.4042     87.090  0.2374    91.716  123.73
  21   0.3945     87.650  0.2265    92.112  129.87
  22   0.4178     87.500  0.2120    92.670  135.94
  23   0.3833     87.850  0.2072    92.856  142.01
  24   0.3764     88.590  0.1995    93.116  148.08
  25   0.3723     88.540  0.1948    93.202  154.18
  26   0.3696     88.960  0.1824    93.718  160.29
  27   0.4035     88.050  0.1743    94.008  166.48
  28   0.3688     88.620  0.1690    94.104  172.59
  29   0.3722     88.760  0.1592    94.442  178.66
  30   0.3700     89.360  0.1577    94.590  184.76
  31   0.3526     89.510  0.1620    94.390  190.87
  32   0.3622     89.550  0.1441    94.962  197.11
  33   0.3701     89.310  0.1444    94.982  203.16
  34   0.3501     89.780  0.1418    95.080  209.22
  35   0.3571     89.870  0.1297    95.538  215.27
  36   0.3470     90.080  0.1231    95.682  221.35
  37   0.3560     89.900  0.1302    95.498  227.42
  38   0.3693     89.940  0.1237    95.638  233.62
  39   0.3542     89.900  0.1213    95.830  239.69
  40   0.3481     90.160  0.1163    95.982  245.82
  41   0.3867     89.700  0.1160    96.018  251.89
  42   0.3498     90.200  0.1148    96.006  257.96
  43   0.3572     90.380  0.1049    96.384  264.04
  44   0.3814     89.530  0.1037    96.326  270.21
  45   0.3706     89.890  0.1035    96.422  276.30
  46   0.3299     90.980  0.1022    96.420  282.39
  47   0.3691     90.160  0.1021    96.458  288.47
  48   0.3756     90.030  0.0972    96.620  294.60
  49   0.3544     90.690  0.0983    96.570  300.65
  50   0.3613     90.460  0.0956    96.620  306.82
  51   0.4276     88.670  0.0979    96.662  312.89
  52   0.3785     89.550  0.0970    96.684  319.02
  53   0.4050     89.630  0.0965    96.726  325.13
  54   0.3661     90.490  0.0950    96.786  331.19
  55   0.3473     91.150  0.0911    96.804  337.24
  56   0.3501     90.940  0.0866    96.906  343.40
  57   0.4042     90.250  0.0905    96.864  349.51
  58   0.3541     90.850  0.0861    97.006  355.58
  59   0.3708     90.400  0.0824    97.130  361.68
  60   0.3801     90.160  0.0856    97.038  367.77
  61   0.3818     90.350  0.0837    97.138  373.86
  62   0.3610     91.050  0.0817    97.138  380.08
  63   0.3621     90.570  0.0783    97.312  386.14
  64   0.3422     91.070  0.0785    97.250  392.20
  65   0.3454     90.860  0.0769    97.360  398.27
  66   0.3792     90.700  0.0783    97.334  404.36
  67   0.3741     90.910  0.0770    97.332  410.49
  68   0.3542     91.220  0.0728    97.466  416.58
  69   0.3485     91.090  0.0777    97.316  422.64
  70   0.3712     90.760  0.0726    97.518  428.73
  71   0.3525     91.360  0.0747    97.442  434.81
  72   0.3349     91.560  0.0760    97.292  440.88
  73   0.3697     90.880  0.0741    97.456  447.02
  74   0.3446     90.920  0.0795    97.280  453.09
  75   0.3531     90.960  0.0790    97.282  459.19
  76   0.3273     91.250  0.0699    97.638  465.26
  77   0.3552     90.870  0.0741    97.492  471.35
  78   0.3331     91.040  0.0739    97.464  477.50
  79   0.3369     91.060  0.0697    97.604  483.65
  80   0.3486     90.850  0.0684    97.610  489.69
  81   0.3535     91.190  0.0675    97.690  495.84
  82   0.3679     91.070  0.0682    97.622  501.96
  83   0.4073     90.260  0.0673    97.680  508.07
  84   0.3832     90.840  0.0688    97.608  514.19
  85   0.3772     90.780  0.0669    97.734  520.41
