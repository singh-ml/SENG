Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2483     53.740  1.4894    44.790  7.73
   2   0.9916     64.310  1.0918    60.696  13.78
   3   0.8323     70.730  0.8773    68.760  19.80
   4   0.8006     72.350  0.7370    74.026  25.85
   5   0.6825     76.480  0.6458    77.308  31.89
   6   0.6659     77.760  0.5779    79.452  38.00
   7   0.6534     78.280  0.5292    81.510  44.06
   8   0.6479     78.390  0.4867    83.004  50.15
   9   0.5373     81.300  0.4505    84.264  56.22
  10   0.6129     80.010  0.4242    85.194  62.28
  11   0.5186     82.240  0.3955    86.320  68.35
  12   0.5095     83.130  0.3678    87.220  74.49
  13   0.4860     83.890  0.3443    88.016  80.53
  14   0.5129     82.780  0.3290    88.512  86.57
  15   0.5082     83.580  0.3106    89.158  92.60
  16   0.4903     84.350  0.2855    90.096  98.66
  17   0.4392     86.170  0.2725    90.592  104.72
  18   0.4937     84.360  0.2578    91.086  110.84
  19   0.4358     85.880  0.2438    91.408  116.87
  20   0.4324     85.660  0.2343    91.754  122.95
  21   0.4495     85.860  0.2265    92.124  129.01
  22   0.4515     85.970  0.2127    92.680  135.05
  23   0.4418     86.100  0.2001    93.108  141.16
  24   0.4280     86.640  0.1947    93.258  147.28
  25   0.4965     84.930  0.1836    93.670  153.41
  26   0.4459     86.430  0.1766    93.864  159.49
  27   0.3831     88.070  0.1752    93.886  165.56
  28   0.5084     85.170  0.1577    94.526  171.59
  29   0.4926     85.870  0.1524    94.612  177.73
  30   0.4990     86.050  0.1463    94.798  183.80
  31   0.4511     86.830  0.1426    95.038  189.87
  32   0.5391     85.090  0.1408    95.048  195.90
  33   0.4012     88.670  0.1333    95.356  201.93
  34   0.4092     88.110  0.1242    95.602  208.00
  35   0.4774     86.740  0.1176    95.876  214.07
  36   0.5187     86.220  0.1151    95.946  220.13
  37   0.4382     87.910  0.1125    96.072  226.21
  38   0.4589     86.850  0.1028    96.414  232.25
  39   0.4201     88.020  0.1150    95.922  238.29
  40   0.5230     86.480  0.1023    96.364  244.41
  41   0.4572     88.430  0.0960    96.584  250.46
  42   0.4220     88.630  0.0979    96.662  256.52
  43   0.4444     87.800  0.0900    96.822  262.62
  44   0.4228     88.040  0.0925    96.734  268.71
  45   0.4674     87.400  0.0955    96.674  274.82
  46   0.4148     88.980  0.0866    96.962  280.87
  47   0.4256     88.840  0.0868    96.962  286.94
  48   0.5060     87.320  0.0772    97.348  293.02
  49   0.4170     88.970  0.0807    97.210  299.09
  50   0.4903     87.530  0.0753    97.366  305.18
  51   0.4740     88.000  0.0759    97.414  311.30
  52   0.4673     88.350  0.0770    97.370  317.33
  53   0.4603     88.200  0.0716    97.534  323.43
  54   0.5048     87.420  0.0777    97.288  329.50
  55   0.5599     86.800  0.0718    97.506  335.54
  56   0.3964     89.260  0.0725    97.462  341.65
  57   0.4489     88.870  0.0623    97.848  347.68
  58   0.4098     89.570  0.0664    97.686  353.71
  59   0.4754     88.020  0.0637    97.804  359.74
  60   0.5166     87.800  0.0616    97.884  365.81
  61   0.5347     87.330  0.0660    97.640  371.87
  62   0.4197     89.610  0.0670    97.688  377.99
  63   0.4198     89.400  0.0650    97.724  384.09
  64   0.4191     89.620  0.0577    97.990  390.16
  65   0.4527     89.450  0.0594    97.942  396.21
  66   0.4476     89.300  0.0608    97.994  402.27
  67   0.4486     88.730  0.0588    98.046  408.34
  68   0.3975     90.170  0.0565    98.112  414.44
  69   0.4554     88.840  0.0546    98.114  420.50
  70   0.4319     89.540  0.0534    98.108  426.53
  71   0.3992     90.010  0.0582    97.984  432.63
  72   0.4621     88.530  0.0603    97.900  438.68
  73   0.3997     89.890  0.0547    98.128  444.72
  74   0.4807     88.310  0.0463    98.460  450.87
  75   0.4476     88.960  0.0543    98.124  456.93
  76   0.5326     87.720  0.0541    98.166  462.98
  77   0.4374     89.110  0.0481    98.418  469.07
  78   0.4170     89.610  0.0528    98.202  475.11
  79   0.4295     89.950  0.0458    98.422  481.21
  80   0.4325     89.340  0.0487    98.350  487.33
  81   0.4659     88.870  0.0468    98.372  493.38
  82   0.4441     89.380  0.0546    98.074  499.46
  83   0.4369     89.490  0.0487    98.338  505.53
  84   0.4141     90.140  0.0514    98.228  511.55
  85   0.4255     90.260  0.0456    98.472  517.59
  86   0.4518     89.630  0.0467    98.412  523.72
  87   0.4165     90.510  0.0460    98.410  529.78
  88   0.4302     89.890  0.0482    98.386  535.81
  89   0.5050     88.000  0.0457    98.448  541.85
  90   0.5508     87.890  0.0466    98.454  547.89
