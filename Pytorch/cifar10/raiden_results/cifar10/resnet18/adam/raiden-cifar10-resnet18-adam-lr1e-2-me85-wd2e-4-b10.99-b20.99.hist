Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7303     35.140  2.0868    23.428  7.62
   2   1.5588     41.450  1.6399    38.966  13.70
   3   1.2789     52.350  1.4045    48.208  19.78
   4   1.1268     59.690  1.1852    56.984  25.83
   5   1.0292     64.540  1.0274    63.122  31.91
   6   0.9078     68.290  0.9156    67.470  37.97
   7   0.8537     71.060  0.8146    71.330  44.09
   8   0.7661     73.340  0.7529    73.440  50.11
   9   0.7860     73.480  0.6989    75.654  56.19
  10   0.7068     76.480  0.6576    76.912  62.29
  11   0.6974     76.010  0.6316    78.154  68.31
  12   0.6536     78.050  0.6136    78.740  74.40
  13   0.6526     77.780  0.5936    79.260  80.52
  14   0.6592     77.520  0.5887    79.650  86.56
  15   0.6656     77.710  0.5715    80.252  92.61
  16   0.6063     79.100  0.5740    79.976  98.64
  17   0.6226     78.690  0.5543    80.590  104.69
  18   0.6154     78.880  0.5468    81.008  110.77
  19   0.6364     78.780  0.5429    81.040  116.86
  20   0.6246     79.100  0.5323    81.488  122.90
  21   0.6039     79.370  0.5276    81.822  128.96
  22   0.6199     78.780  0.5271    81.578  135.01
  23   0.6272     78.610  0.5238    81.784  141.09
  24   0.6181     79.140  0.5229    82.128  147.22
  25   0.6205     78.430  0.5142    82.102  153.28
  26   0.6433     78.630  0.5124    82.294  159.33
  27   0.6037     79.860  0.5069    82.616  165.37
  28   0.6611     76.940  0.5068    82.416  171.38
  29   0.6156     79.340  0.4998    82.662  177.47
  30   0.5827     80.110  0.5010    82.782  183.61
  31   0.5525     81.460  0.4999    82.838  189.68
  32   0.6394     79.460  0.5007    82.748  195.73
  33   0.5864     80.490  0.4957    82.790  201.80
  34   0.6043     80.510  0.4921    82.936  207.88
  35   0.5839     80.380  0.4944    82.766  213.95
  36   0.6880     78.140  0.4882    83.218  220.11
  37   0.5681     81.050  0.4845    83.218  226.16
  38   0.5882     80.020  0.4877    83.074  232.22
  39   0.6409     78.900  0.4874    83.056  238.30
  40   0.5876     80.930  0.4857    83.208  244.37
  41   0.5690     80.430  0.4900    83.048  250.40
  42   0.6294     79.760  0.4876    83.228  256.46
  43   0.6651     78.190  0.4861    83.314  262.58
  44   0.6777     78.200  0.4839    83.130  268.68
  45   0.5532     80.870  0.4847    83.354  274.70
  46   0.6209     79.850  0.4875    83.168  280.75
  47   0.6031     80.190  0.4787    83.388  286.78
  48   0.5471     81.070  0.4768    83.694  292.82
  49   0.5588     80.840  0.4750    83.608  298.96
  50   0.6062     80.080  0.4707    83.734  305.03
  51   0.6780     78.820  0.4699    83.744  311.14
  52   0.5979     80.620  0.4691    83.696  317.21
  53   0.6073     80.210  0.4730    83.446  323.25
  54   0.5240     82.520  0.4665    84.084  329.30
  55   0.5329     81.740  0.4619    84.072  335.34
  56   0.5491     82.050  0.4668    83.802  341.39
  57   0.5114     83.100  0.4598    84.050  347.44
  58   0.6665     77.860  0.4640    83.990  353.53
  59   0.5227     82.490  0.4667    83.862  359.58
  60   0.6733     78.330  0.4681    83.806  365.68
  61   0.5822     80.720  0.4604    84.014  371.76
  62   0.5768     81.120  0.4622    83.944  377.80
  63   0.5871     81.100  0.4703    83.824  383.87
  64   0.6051     79.970  0.4730    83.536  389.96
  65   0.6112     80.110  0.4702    83.572  396.03
  66   0.6226     79.360  0.4670    83.884  402.17
  67   0.6178     79.750  0.4673    83.788  408.22
  68   0.5241     82.390  0.4623    84.040  414.29
  69   0.5270     82.400  0.4559    84.084  420.34
  70   0.5976     80.270  0.4582    84.240  426.39
  71   0.5490     81.810  0.4647    83.798  432.43
  72   0.5881     80.990  0.4645    83.922  438.56
  73   0.5129     82.700  0.4593    84.196  444.67
  74   0.5550     81.720  0.4597    84.272  450.70
  75   0.6045     79.800  0.4617    84.112  456.78
  76   0.5693     81.340  0.4584    84.146  462.85
  77   0.5430     82.210  0.4650    83.858  468.89
  78   0.5287     82.030  0.4645    83.970  475.01
  79   0.5852     81.510  0.4572    84.264  481.07
  80   0.5854     80.520  0.4619    84.026  487.14
  81   0.5444     81.750  0.4548    84.280  493.19
  82   0.5584     81.660  0.4593    84.248  499.26
  83   0.5225     82.280  0.4586    84.240  505.30
  84   0.6244     80.300  0.4593    84.004  511.46
  85   0.5511     81.130  0.4589    84.162  517.52
