Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7346     42.850  1.7238    36.896  7.67
   2   1.5590     46.370  1.2548    54.430  13.85
   3   1.2004     58.250  1.0335    62.922  20.01
   4   0.9882     66.630  0.8670    69.246  26.13
   5   0.9419     68.090  0.7282    74.544  32.27
   6   1.1323     65.200  0.6439    77.614  38.45
   7   0.6060     78.760  0.5864    79.690  44.64
   8   0.7460     76.130  0.5435    81.182  50.80
   9   0.7923     74.480  0.5079    82.588  56.98
  10   0.6890     78.400  0.4795    83.360  63.12
  11   0.6216     79.490  0.4643    84.036  69.27
  12   0.6976     77.700  0.4346    85.046  75.46
  13   0.5218     82.190  0.4253    85.224  81.69
  14   0.5456     82.420  0.4089    85.970  87.86
  15   0.6250     79.980  0.3998    86.164  94.01
  16   0.5399     82.230  0.3925    86.462  100.18
  17   0.4667     84.220  0.3777    86.900  106.35
  18   0.6094     80.410  0.3761    87.104  112.51
  19   0.5080     83.720  0.3645    87.496  118.74
  20   0.6281     79.460  0.3636    87.482  124.86
  21   0.5273     82.740  0.3519    87.824  131.04
  22   0.5325     82.160  0.3540    87.670  137.17
  23   0.5957     81.310  0.3461    88.080  143.31
  24   0.6098     80.870  0.3400    88.284  149.44
  25   0.5614     82.310  0.3350    88.470  155.67
  26   0.4510     84.980  0.3297    88.664  161.80
  27   0.5322     83.140  0.3301    88.684  167.93
  28   0.5233     83.580  0.3238    88.784  174.10
  29   0.4758     84.280  0.3228    88.884  180.27
  30   0.4631     85.500  0.3178    89.008  186.40
  31   0.6154     81.570  0.3218    88.952  192.64
  32   0.4703     85.010  0.3142    89.182  198.82
  33   0.5674     82.990  0.3102    89.162  204.96
  34   0.5126     83.760  0.3112    89.218  211.11
  35   0.4114     86.570  0.3101    89.430  217.27
  36   0.5536     83.200  0.3075    89.248  223.46
  37   0.5141     83.940  0.3081    89.388  229.59
  38   0.5054     84.030  0.3026    89.652  235.73
  39   0.5226     83.880  0.2990    89.696  241.89
  40   0.4479     86.100  0.3023    89.628  248.00
  41   0.5133     84.110  0.3001    89.536  254.22
  42   0.4664     84.910  0.2985    89.658  260.36
  43   0.4819     84.490  0.2945    89.852  266.58
  44   0.7679     78.710  0.2949    89.834  272.75
  45   0.4324     85.580  0.2912    89.956  278.88
  46   0.5032     84.180  0.2930    89.852  285.01
  47   0.5386     83.710  0.2906    90.022  291.22
  48   0.4812     85.370  0.2925    89.960  297.39
  49   0.4517     85.440  0.2898    90.002  303.57
  50   0.4998     84.170  0.2858    90.008  309.74
  51   0.3910     86.990  0.2876    89.950  315.89
  52   0.4698     84.940  0.2849    90.078  322.12
  53   0.4701     85.370  0.2829    90.284  328.25
  54   0.5298     84.080  0.2791    90.302  334.42
  55   0.5568     83.370  0.2851    90.052  340.54
  56   0.5222     83.980  0.2784    90.414  346.66
  57   0.4222     86.440  0.2821    90.210  352.90
  58   0.4658     85.650  0.2823    90.240  359.06
  59   0.4776     84.500  0.2756    90.414  365.24
  60   0.5533     83.710  0.2779    90.364  371.43
  61   0.4685     85.460  0.2844    90.192  377.61
  62   0.4834     84.670  0.2805    90.378  383.79
  63   0.5357     84.030  0.2788    90.386  390.02
  64   0.4737     84.980  0.2814    90.160  396.16
  65   0.3766     87.720  0.2743    90.442  402.35
  66   0.4418     86.270  0.2768    90.444  408.53
  67   0.4611     86.210  0.2734    90.502  414.72
  68   0.5290     84.370  0.2754    90.526  420.97
  69   0.4857     84.990  0.2710    90.690  427.21
  70   0.4188     86.890  0.2755    90.396  433.37
  71   0.4459     85.960  0.2703    90.564  439.55
  72   0.5288     83.950  0.2714    90.600  445.72
  73   0.4628     85.890  0.2735    90.448  451.87
  74   0.3882     86.900  0.2707    90.626  458.12
  75   0.4309     86.570  0.2675    90.742  464.29
  76   0.4314     86.590  0.2742    90.486  470.46
  77   0.4161     86.560  0.2710    90.670  476.64
  78   0.6075     82.960  0.2657    90.778  482.77
  79   0.4199     86.350  0.2698    90.768  488.94
  80   0.6242     81.680  0.2741    90.388  495.21
  81   0.4757     86.060  0.2672    90.702  501.35
  82   0.3767     88.050  0.2681    90.728  507.52
  83   0.4209     86.730  0.2652    90.796  513.65
  84   0.4278     86.220  0.2677    90.616  519.83
  85   0.4212     86.460  0.2645    90.878  525.97
  86   0.4214     86.300  0.2665    90.902  532.16
  87   0.4998     84.790  0.2658    90.834  538.33
  88   0.5406     83.730  0.2656    90.918  544.48
  89   0.5494     83.580  0.2646    90.878  550.61
  90   0.4280     86.630  0.2630    90.946  556.74
