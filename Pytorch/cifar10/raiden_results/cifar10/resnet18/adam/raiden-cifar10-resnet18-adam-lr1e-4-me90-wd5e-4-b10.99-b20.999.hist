Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3680     49.680  1.6188    40.442  7.65
   2   1.1639     58.370  1.2719    53.856  13.80
   3   1.0041     64.260  1.0893    61.050  19.91
   4   0.9254     67.190  0.9586    65.904  25.99
   5   0.8821     69.260  0.8572    69.476  32.15
   6   0.7552     73.710  0.7651    73.056  38.24
   7   0.7196     74.820  0.6982    75.304  44.36
   8   0.6702     76.500  0.6488    77.372  50.46
   9   0.6476     77.630  0.5967    79.280  56.54
  10   0.5941     79.370  0.5565    80.530  62.67
  11   0.6142     78.850  0.5203    81.966  68.86
  12   0.5577     81.030  0.4802    83.258  74.93
  13   0.5669     80.600  0.4584    84.170  81.02
  14   0.5382     81.780  0.4324    85.126  87.08
  15   0.5175     82.280  0.4151    85.592  93.18
  16   0.4966     83.130  0.3869    86.560  99.31
  17   0.4902     83.150  0.3683    87.266  105.54
  18   0.4933     83.560  0.3507    88.074  111.62
  19   0.4905     83.800  0.3322    88.522  117.75
  20   0.4687     84.290  0.3080    89.446  123.85
  21   0.4664     84.290  0.2998    89.700  129.98
  22   0.4546     84.840  0.2984    89.614  136.10
  23   0.4623     85.020  0.2794    90.342  142.25
  24   0.4713     84.660  0.2607    90.968  148.40
  25   0.4472     85.350  0.2497    91.348  154.54
  26   0.4475     85.500  0.2367    91.876  160.65
  27   0.4653     85.230  0.2204    92.338  166.78
  28   0.4410     85.930  0.2163    92.574  172.92
  29   0.4834     84.910  0.2086    92.838  179.04
  30   0.4530     85.600  0.2065    92.846  185.23
  31   0.4192     86.650  0.1940    93.212  191.38
  32   0.4386     86.560  0.1740    93.966  197.52
  33   0.4507     86.070  0.1773    93.810  203.59
  34   0.4677     85.620  0.1723    94.078  209.81
  35   0.4678     85.960  0.1679    94.274  215.88
  36   0.4606     85.850  0.1582    94.566  221.96
  37   0.4386     86.700  0.1519    94.764  228.06
  38   0.4411     86.800  0.1433    95.040  234.17
  39   0.4853     85.970  0.1350    95.476  240.28
  40   0.4420     87.010  0.1335    95.402  246.47
  41   0.4443     87.010  0.1265    95.622  252.57
  42   0.4676     86.780  0.1278    95.524  258.73
  43   0.4728     86.760  0.1226    95.754  264.81
  44   0.4936     85.520  0.1140    96.070  270.91
  45   0.4648     86.910  0.1119    96.176  277.05
  46   0.4402     87.430  0.1097    96.148  283.12
  47   0.4249     87.820  0.1022    96.474  289.21
  48   0.4421     87.350  0.1053    96.380  295.34
  49   0.4340     88.020  0.1002    96.604  301.44
  50   0.4413     88.040  0.0942    96.806  307.65
  51   0.4662     87.120  0.0937    96.790  313.76
  52   0.4575     87.510  0.0948    96.764  319.92
  53   0.4800     87.150  0.0869    97.092  326.03
  54   0.4740     87.570  0.0869    97.064  332.16
  55   0.4823     87.260  0.0820    97.266  338.33
  56   0.4464     88.110  0.0820    97.290  344.46
  57   0.4671     87.650  0.0848    97.124  350.58
  58   0.4614     87.980  0.0805    97.272  356.66
  59   0.4464     87.980  0.0758    97.466  362.76
  60   0.4470     87.980  0.0775    97.324  368.87
  61   0.4457     88.240  0.0725    97.542  375.00
  62   0.4628     87.610  0.0703    97.562  381.15
  63   0.4732     87.430  0.0736    97.438  387.30
  64   0.4322     88.510  0.0746    97.436  393.41
  65   0.4629     87.630  0.0678    97.724  399.51
  66   0.4514     88.070  0.0677    97.730  405.59
  67   0.4532     87.930  0.0703    97.662  411.71
  68   0.4375     88.430  0.0649    97.856  417.82
  69   0.4649     88.170  0.0622    97.948  423.96
  70   0.4416     88.390  0.0566    98.070  430.08
  71   0.4639     88.320  0.0638    97.902  436.18
  72   0.4567     88.400  0.0575    98.078  442.27
  73   0.4726     87.890  0.0650    97.766  448.44
  74   0.4617     88.050  0.0640    97.872  454.55
  75   0.4574     88.150  0.0651    97.788  460.69
  76   0.4539     88.310  0.0629    97.850  466.77
  77   0.4492     88.450  0.0595    97.960  472.88
  78   0.4570     88.280  0.0571    98.070  479.02
  79   0.4698     88.260  0.0618    97.978  485.16
  80   0.4401     89.330  0.0586    98.068  491.27
  81   0.4587     88.220  0.0586    98.058  497.33
  82   0.4371     88.990  0.0549    98.190  503.42
  83   0.4553     88.570  0.0506    98.318  509.48
  84   0.4497     88.850  0.0497    98.338  515.67
  85   0.4338     89.120  0.0505    98.344  521.79
  86   0.4309     88.820  0.0509    98.282  527.90
  87   0.4734     88.150  0.0531    98.192  534.03
  88   0.4632     88.560  0.0501    98.330  540.17
  89   0.4625     88.190  0.0464    98.450  546.39
  90   0.4478     89.030  0.0507    98.292  552.48
