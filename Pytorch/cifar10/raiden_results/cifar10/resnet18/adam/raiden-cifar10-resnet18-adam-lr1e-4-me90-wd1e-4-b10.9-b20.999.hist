Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3315     51.190  1.5582    42.628  7.66
   2   1.0933     60.350  1.1941    56.778  13.83
   3   0.9918     64.480  1.0168    63.604  20.03
   4   0.8873     68.960  0.8959    68.170  26.17
   5   0.8606     70.080  0.8074    71.180  32.36
   6   0.8064     72.310  0.7387    73.656  38.50
   7   0.7317     74.630  0.6812    75.938  44.68
   8   0.7165     74.890  0.6278    78.054  50.80
   9   0.7824     73.240  0.5783    79.896  57.00
  10   0.6649     76.660  0.5475    80.962  63.15
  11   0.6130     79.310  0.5114    82.174  69.31
  12   0.5820     79.760  0.4810    83.214  75.45
  13   0.5582     80.600  0.4529    84.256  81.60
  14   0.5423     81.860  0.4266    84.902  87.84
  15   0.5582     81.130  0.4032    85.788  93.97
  16   0.5804     80.730  0.3833    86.512  100.15
  17   0.5157     82.940  0.3687    86.960  106.29
  18   0.5149     82.620  0.3457    88.066  112.40
  19   0.4956     83.270  0.3275    88.516  118.55
  20   0.5224     83.010  0.3159    88.930  124.79
  21   0.5229     83.040  0.2986    89.708  130.91
  22   0.5021     83.860  0.2874    89.950  137.07
  23   0.5425     82.710  0.2737    90.434  143.23
  24   0.4909     84.120  0.2606    90.866  149.39
  25   0.5189     83.960  0.2416    91.520  155.50
  26   0.5584     82.880  0.2361    91.642  161.70
  27   0.4556     85.400  0.2268    91.932  167.83
  28   0.4921     84.690  0.2150    92.378  173.97
  29   0.4916     84.460  0.2071    92.640  180.11
  30   0.4674     85.360  0.1867    93.572  186.25
  31   0.5139     84.100  0.1846    93.490  192.38
  32   0.4779     85.380  0.1719    94.052  198.62
  33   0.5211     84.970  0.1641    94.246  204.74
  34   0.4845     85.750  0.1618    94.268  210.88
  35   0.4821     86.030  0.1479    94.876  217.00
  36   0.5111     85.070  0.1469    94.804  223.15
  37   0.5525     84.480  0.1420    95.028  229.26
  38   0.5086     85.590  0.1359    95.220  235.48
  39   0.5083     85.330  0.1272    95.578  241.60
  40   0.4896     86.420  0.1189    95.854  247.79
  41   0.4991     86.510  0.1158    96.002  253.95
  42   0.5417     85.460  0.1159    96.054  260.08
  43   0.5018     86.480  0.1096    96.140  266.27
  44   0.5040     86.510  0.0995    96.442  272.40
  45   0.5493     86.070  0.0996    96.426  278.51
  46   0.5016     86.730  0.0984    96.560  284.62
  47   0.5350     86.400  0.0894    96.928  290.75
  48   0.5070     86.550  0.0877    96.914  296.88
  49   0.5569     86.140  0.0927    96.750  303.05
  50   0.5299     86.290  0.0835    97.128  309.17
  51   0.5876     85.600  0.0779    97.276  315.33
  52   0.5264     86.820  0.0775    97.296  321.44
  53   0.5342     86.640  0.0747    97.374  327.59
  54   0.6207     85.640  0.0726    97.470  333.82
  55   0.5796     86.120  0.0713    97.506  339.94
  56   0.6278     85.490  0.0728    97.480  346.07
  57   0.5419     86.600  0.0701    97.592  352.20
  58   0.5031     87.160  0.0683    97.584  358.36
  59   0.5835     85.830  0.0617    97.886  364.53
  60   0.5242     87.460  0.0623    97.828  370.76
  61   0.5884     86.070  0.0581    97.970  376.87
  62   0.5898     86.400  0.0611    97.918  383.07
  63   0.5715     87.000  0.0608    97.976  389.17
  64   0.5333     87.510  0.0599    97.952  395.30
  65   0.5384     86.920  0.0573    98.008  401.45
  66   0.6265     85.890  0.0556    98.028  407.63
  67   0.5121     87.850  0.0520    98.230  413.79
  68   0.5306     87.640  0.0525    98.176  419.91
  69   0.5407     87.350  0.0527    98.150  426.05
  70   0.5650     87.540  0.0523    98.154  432.20
  71   0.6119     86.950  0.0459    98.404  438.37
  72   0.5543     86.930  0.0576    97.970  444.60
  73   0.5295     87.820  0.0447    98.432  450.75
  74   0.5209     87.910  0.0452    98.368  456.95
  75   0.5683     87.350  0.0486    98.332  463.10
  76   0.5646     87.240  0.0466    98.422  469.23
  77   0.5510     87.730  0.0427    98.532  475.37
  78   0.5703     87.160  0.0481    98.316  481.62
  79   0.5083     88.330  0.0425    98.486  487.73
  80   0.5282     88.000  0.0391    98.692  493.86
  81   0.5874     87.470  0.0406    98.596  499.96
  82   0.6279     86.700  0.0379    98.718  506.12
  83   0.5930     87.810  0.0447    98.500  512.33
  84   0.6030     86.990  0.0438    98.532  518.49
  85   0.5297     88.120  0.0394    98.660  524.63
  86   0.5266     87.840  0.0403    98.618  530.79
  87   0.5611     87.210  0.0398    98.668  536.95
  88   0.7127     85.700  0.0435    98.440  543.06
  89   0.5506     87.830  0.0385    98.688  549.27
  90   0.5642     88.040  0.0309    98.990  555.43
