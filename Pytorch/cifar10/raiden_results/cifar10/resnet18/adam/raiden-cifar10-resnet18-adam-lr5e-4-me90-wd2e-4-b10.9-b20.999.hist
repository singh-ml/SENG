Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1396     58.950  1.4042    48.716  7.77
   2   1.0040     66.240  0.9410    66.420  13.82
   3   0.7544     73.850  0.7345    74.290  19.86
   4   0.7673     74.860  0.6208    78.330  25.99
   5   0.6022     79.210  0.5491    80.724  32.03
   6   0.7976     74.400  0.4933    82.890  38.09
   7   0.5271     82.220  0.4519    84.422  44.13
   8   0.5016     82.580  0.4232    85.368  50.17
   9   0.4988     82.920  0.3893    86.502  56.22
  10   0.4966     83.640  0.3701    87.088  62.31
  11   0.4915     83.940  0.3408    88.190  68.37
  12   0.4346     85.800  0.3248    88.816  74.45
  13   0.4177     86.470  0.3058    89.428  80.55
  14   0.6826     79.100  0.2860    90.142  86.59
  15   0.3898     87.200  0.2779    90.356  92.69
  16   0.3788     87.310  0.2596    91.042  98.77
  17   0.5270     83.750  0.2482    91.450  104.84
  18   0.4915     84.590  0.2377    91.850  110.91
  19   0.4954     84.620  0.2312    91.860  116.99
  20   0.3939     87.780  0.2160    92.518  123.05
  21   0.3963     87.880  0.2091    92.818  129.23
  22   0.4167     87.400  0.2005    93.036  135.25
  23   0.4427     86.490  0.1904    93.430  141.35
  24   0.4595     86.290  0.1870    93.466  147.39
  25   0.4506     86.420  0.1774    93.854  153.42
  26   0.4045     87.690  0.1775    93.720  159.59
  27   0.3605     89.310  0.1696    94.110  165.66
  28   0.4145     88.080  0.1558    94.554  171.71
  29   0.4089     88.510  0.1566    94.492  177.79
  30   0.4134     88.100  0.1493    94.792  183.84
  31   0.3771     88.520  0.1477    94.906  190.00
  32   0.3773     88.490  0.1470    94.956  196.06
  33   0.4325     87.880  0.1378    95.198  202.14
  34   0.4710     87.150  0.1365    95.184  208.21
  35   0.3866     88.460  0.1264    95.686  214.25
  36   0.4361     88.100  0.1276    95.552  220.34
  37   0.4007     88.420  0.1245    95.732  226.47
  38   0.5168     86.610  0.1176    95.980  232.55
  39   0.4381     87.950  0.1166    95.892  238.63
  40   0.4527     88.080  0.1136    96.074  244.66
  41   0.3962     88.860  0.1083    96.188  250.72
  42   0.3621     89.440  0.1071    96.326  256.80
  43   0.3847     89.180  0.1084    96.226  262.91
  44   0.3797     89.790  0.1039    96.326  269.01
  45   0.4235     88.780  0.1049    96.368  275.09
  46   0.3991     89.060  0.0985    96.648  281.15
  47   0.3805     89.310  0.0964    96.686  287.21
  48   0.4481     88.020  0.0983    96.554  293.25
  49   0.3928     89.840  0.0990    96.542  299.33
  50   0.3947     89.550  0.0914    96.970  305.47
  51   0.4084     89.670  0.0868    96.986  311.53
  52   0.4214     89.180  0.0908    96.808  317.57
  53   0.4068     89.140  0.0900    96.858  323.62
  54   0.3647     90.540  0.0864    97.036  329.72
  55   0.3994     89.420  0.0907    96.880  335.82
  56   0.3883     90.010  0.0850    97.100  341.87
  57   0.3926     89.500  0.0869    96.978  347.90
  58   0.3717     90.190  0.0822    97.154  353.97
  59   0.4161     89.160  0.0843    97.070  360.04
  60   0.3619     90.260  0.0858    97.054  366.11
  61   0.3602     90.080  0.0804    97.222  372.24
  62   0.4276     89.250  0.0784    97.262  378.32
  63   0.3569     90.740  0.0821    97.152  384.36
  64   0.3945     89.800  0.0812    97.184  390.41
  65   0.3800     90.030  0.0787    97.232  396.51
  66   0.3828     90.240  0.0739    97.450  402.67
  67   0.3759     90.360  0.0783    97.290  408.74
  68   0.3971     90.190  0.0766    97.392  414.83
  69   0.4153     89.840  0.0753    97.390  420.90
  70   0.3688     91.040  0.0735    97.520  426.94
  71   0.4160     89.970  0.0734    97.414  432.98
  72   0.3542     90.170  0.0765    97.400  439.08
  73   0.4477     89.470  0.0707    97.600  445.18
  74   0.3611     91.010  0.0680    97.688  451.28
  75   0.4136     89.920  0.0750    97.434  457.36
  76   0.4082     89.760  0.0677    97.668  463.40
  77   0.4184     90.070  0.0716    97.524  469.54
  78   0.3767     90.450  0.0689    97.676  475.62
  79   0.3787     90.600  0.0712    97.566  481.65
  80   0.3637     90.610  0.0693    97.598  487.72
  81   0.3951     90.480  0.0668    97.738  493.79
  82   0.3807     90.360  0.0667    97.674  499.86
  83   0.4007     90.010  0.0681    97.672  505.98
  84   0.3719     90.990  0.0673    97.684  512.04
  85   0.4159     90.180  0.0648    97.764  518.12
  86   0.3541     90.930  0.0681    97.652  524.20
  87   0.3769     91.030  0.0622    97.824  530.31
  88   0.3795     90.900  0.0671    97.688  536.41
  89   0.3874     90.750  0.0683    97.660  542.45
  90   0.3774     90.500  0.0660    97.692  548.55
