Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6717     36.850  1.9298    30.048  7.64
   2   1.5106     46.320  1.4798    45.232  13.73
   3   1.2295     56.910  1.1893    56.888  19.83
   4   1.1652     59.430  1.0258    63.346  25.98
   5   0.9418     67.220  0.9287    66.976  32.06
   6   1.0384     65.060  0.8362    70.600  38.15
   7   0.8671     70.080  0.7684    73.072  44.22
   8   0.9058     69.500  0.7136    75.062  50.29
   9   0.8051     73.620  0.6762    76.374  56.38
  10   0.7647     74.440  0.6521    77.374  62.50
  11   0.7449     74.240  0.6362    78.042  68.60
  12   1.0143     67.990  0.6139    78.526  74.68
  13   0.7901     73.770  0.5922    79.350  80.73
  14   0.7373     75.380  0.5906    79.532  86.79
  15   0.7447     75.680  0.5711    80.170  92.90
  16   0.7610     75.080  0.5675    80.364  98.97
  17   0.8306     73.000  0.5583    80.824  105.14
  18   0.9454     71.190  0.5520    80.918  111.23
  19   0.7233     76.450  0.5397    81.480  117.33
  20   0.7894     74.230  0.5340    81.604  123.42
  21   0.6474     77.400  0.5286    81.638  129.46
  22   0.7384     75.910  0.5252    81.748  135.57
  23   0.8028     73.860  0.5169    82.078  141.74
  24   0.6495     78.150  0.5150    82.074  147.87
  25   0.5902     80.130  0.5106    82.358  154.02
  26   0.7472     76.230  0.5035    82.704  160.12
  27   1.1166     66.960  0.5030    82.784  166.21
  28   0.7438     75.710  0.4993    82.884  172.34
  29   0.6818     76.420  0.4994    82.874  178.45
  30   0.5476     81.320  0.4918    83.072  184.53
  31   0.8617     72.030  0.4939    83.114  190.62
  32   0.8686     73.970  0.4836    83.244  196.74
  33   0.6596     78.360  0.4867    83.236  202.88
  34   0.6523     79.640  0.4840    83.332  208.95
  35   0.7590     76.580  0.4819    83.372  215.06
  36   0.7772     75.350  0.4832    83.484  221.13
  37   0.7336     75.530  0.4737    83.758  227.24
  38   0.7006     77.100  0.4743    83.734  233.32
  39   0.6599     77.620  0.4745    83.702  239.46
  40   0.9947     71.450  0.4757    83.730  245.52
  41   0.7145     77.820  0.4684    83.776  251.59
  42   0.7343     76.200  0.4727    83.662  257.65
  43   0.9411     72.290  0.4624    84.140  263.71
  44   0.5995     79.970  0.4658    83.974  269.85
  45   0.6488     78.590  0.4650    84.160  275.93
  46   0.7645     75.860  0.4672    83.818  282.02
  47   0.6089     79.650  0.4670    83.966  288.09
  48   0.5685     80.870  0.4619    83.932  294.16
  49   0.7706     76.030  0.4596    84.284  300.24
  50   0.7247     77.290  0.4615    84.188  306.36
  51   0.9341     71.470  0.4613    84.176  312.46
  52   0.7288     76.600  0.4559    84.388  318.55
  53   0.6187     79.900  0.4612    84.064  324.60
  54   0.5514     81.730  0.4534    84.486  330.72
  55   0.5095     82.670  0.4586    84.300  336.83
  56   1.0705     71.440  0.4518    84.342  343.05
  57   0.9144     72.870  0.4555    84.304  349.11
  58   0.8645     74.780  0.4536    84.222  355.22
  59   0.5083     82.720  0.4542    84.408  361.28
  60   0.6860     78.090  0.4511    84.322  367.35
  61   0.6373     78.800  0.4488    84.490  373.54
  62   0.7022     77.580  0.4501    84.514  379.60
  63   2.2517     56.940  0.4452    84.532  385.71
  64   0.6183     79.550  0.4507    84.488  391.78
  65   0.6472     79.370  0.4458    84.636  397.84
  66   0.6779     77.820  0.4539    84.250  403.90
  67   0.6237     79.690  0.4468    84.658  409.97
  68   0.7470     75.280  0.4483    84.474  416.03
  69   0.5918     80.580  0.4420    84.830  422.11
  70   0.7929     76.010  0.4502    84.404  428.19
  71   0.8174     74.030  0.4451    84.632  434.28
  72   0.5430     82.220  0.4462    84.600  440.34
  73   1.8798     52.060  0.4485    84.488  446.41
  74   0.5355     81.880  0.4460    84.738  452.56
  75   0.6629     78.390  0.4448    84.654  458.63
  76   0.6995     77.580  0.4397    84.886  464.72
  77   0.6263     79.460  0.4496    84.528  470.78
  78   0.6742     78.410  0.4454    84.544  476.87
  79   0.5096     82.820  0.4435    84.646  483.02
  80   0.6630     78.660  0.4489    84.540  489.13
  81   0.7272     76.560  0.4408    84.758  495.21
  82   0.5361     82.090  0.4489    84.522  501.29
  83   0.9429     72.610  0.4421    84.836  507.37
  84   0.5974     80.380  0.4388    84.868  513.44
  85   0.6606     78.380  0.4442    84.684  519.56
