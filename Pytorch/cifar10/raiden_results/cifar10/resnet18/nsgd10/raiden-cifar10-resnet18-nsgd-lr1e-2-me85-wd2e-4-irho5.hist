Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '5', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 6248487936 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4218     50.420  1.6328    41.052  274.90
   2   1.0320     64.960  1.0944    60.698  548.54
   3   1.0585     67.690  0.8290    70.628  822.35
   4   0.6907     76.830  0.6889    75.836  1095.39
   5   0.7831     74.690  0.5988    79.148  1368.86
   6   0.7173     77.430  0.5229    81.850  1641.59
   7   0.6566     78.920  0.4674    83.810  1914.82
   8   0.6624     80.280  0.4192    85.328  2188.28
   9   0.5159     82.970  0.3908    86.458  2461.73
  10   0.5742     81.380  0.3523    87.710  2735.40
  11   0.4970     84.260  0.3248    88.674  3008.35
  12   0.4409     85.960  0.2980    89.612  3281.16
  13   0.4347     86.320  0.2733    90.434  3554.93
  14   0.4632     86.670  0.2558    91.030  3828.34
  15   0.4092     87.410  0.2445    91.402  4102.54
  16   0.5069     85.200  0.2228    92.106  4375.69
  17   0.4524     86.590  0.2036    92.824  4649.21
  18   0.4283     87.200  0.1933    93.122  4922.03
  19   0.4430     86.800  0.1812    93.644  5194.97
  20   0.4120     88.410  0.1727    93.890  5468.45
  21   0.4537     87.550  0.1567    94.436  5741.58
  22   0.3927     89.120  0.1458    94.890  6014.82
  23   0.3955     88.840  0.1303    95.466  6288.70
  24   0.4217     88.340  0.1321    95.264  6562.13
  25   0.4815     87.460  0.1229    95.616  6835.67
  26   0.4509     88.810  0.1118    95.842  7108.64
  27   0.4249     88.980  0.1028    96.376  7381.92
  28   0.3915     89.800  0.0941    96.572  7655.97
  29   0.4503     88.990  0.0885    96.922  7929.71
  30   0.4369     89.850  0.0844    96.976  8202.95
  31   0.4137     90.280  0.0773    97.202  8476.14
  32   0.3953     90.140  0.0718    97.430  8749.86
  33   0.4334     89.730  0.0636    97.698  9023.52
  34   0.4233     90.380  0.0586    97.930  9297.14
  35   0.4100     90.800  0.0528    98.116  9570.70
  36   0.4381     90.010  0.0476    98.286  9844.15
  37   0.4086     90.660  0.0456    98.426  10117.49
  38   0.4112     90.940  0.0408    98.638  10390.77
  39   0.4012     91.110  0.0396    98.638  10664.78
  40   0.4294     90.680  0.0361    98.748  10938.34
  41   0.4426     90.630  0.0328    98.850  11212.12
