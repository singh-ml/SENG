Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 6340486144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4063     48.990  1.6876    38.794  274.08
   2   0.9700     66.200  1.1542    58.348  546.70
   3   0.9907     65.140  0.8838    68.532  818.68
   4   0.8203     73.350  0.7106    75.274  1091.26
   5   0.7916     74.450  0.6085    78.944  1363.86
   6   0.6923     77.240  0.5316    81.204  1636.31
   7   0.6585     78.990  0.4831    83.308  1908.67
   8   0.6358     79.370  0.4345    84.970  2181.36
   9   0.7700     76.690  0.4032    86.002  2454.08
  10   0.5203     83.740  0.3632    87.438  2726.38
  11   0.4761     83.970  0.3378    88.090  2998.41
  12   0.5432     82.790  0.3104    88.992  3270.99
  13   0.4719     85.120  0.2894    89.844  3542.94
  14   0.4765     85.370  0.2619    90.942  3815.62
  15   0.4867     85.500  0.2450    91.390  4088.19
  16   0.4178     87.270  0.2259    92.134  4360.25
  17   0.5067     85.350  0.2109    92.604  4633.56
  18   0.5261     85.390  0.1943    93.220  4906.11
  19   0.5115     86.140  0.1886    93.412  5178.58
  20   0.4388     88.030  0.1718    93.852  5450.85
  21   0.4595     87.390  0.1609    94.368  5723.46
  22   0.3971     89.050  0.1511    94.698  5995.76
  23   0.4373     88.280  0.1383    95.040  6267.92
  24   0.4724     87.030  0.1261    95.452  6540.57
  25   0.4411     88.400  0.1220    95.664  6812.97
  26   0.4359     88.180  0.1121    95.974  7085.21
  27   0.4802     88.100  0.1053    96.306  7357.64
  28   0.4293     89.220  0.1002    96.460  7630.14
  29   0.4342     89.050  0.0948    96.658  7902.79
  30   0.4066     89.860  0.0857    96.944  8175.44
  31   0.4507     89.530  0.0758    97.250  8448.39
  32   0.4845     89.160  0.0730    97.484  8721.22
  33   0.4132     90.580  0.0676    97.598  8993.48
  34   0.4511     89.570  0.0668    97.630  9265.87
  35   0.3871     90.740  0.0560    98.016  9538.23
  36   0.4697     89.810  0.0548    98.022  9810.04
  37   0.4417     89.580  0.0495    98.280  10082.41
  38   0.4653     89.680  0.0434    98.524  10355.04
  39   0.4214     90.890  0.0436    98.456  10627.43
  40   0.4522     90.590  0.0360    98.782  10899.72
  41   0.4237     91.210  0.0358    98.772  11171.89
  42   0.4482     90.420  0.0332    98.824  11444.46
  43   0.4771     90.630  0.0299    99.010  11716.76
