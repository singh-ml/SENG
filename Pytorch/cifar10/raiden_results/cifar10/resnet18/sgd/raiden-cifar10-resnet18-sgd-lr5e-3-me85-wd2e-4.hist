Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4941     44.170  1.7560    33.846  7.43
   2   1.2917     53.270  1.3948    48.444  13.30
   3   1.1408     59.350  1.2146    55.778  19.15
   4   1.0153     64.240  1.0573    61.664  24.99
   5   0.9667     65.430  0.9489    65.980  30.90
   6   0.8909     68.960  0.8615    69.342  36.74
   7   0.7885     72.180  0.7875    71.850  42.58
   8   0.7428     74.070  0.7266    74.480  48.44
   9   0.6826     76.230  0.6715    76.244  54.28
  10   0.7099     75.330  0.6349    77.544  60.12
  11   0.6678     77.240  0.5902    79.346  66.07
  12   0.6493     78.180  0.5594    80.238  71.95
  13   0.6313     78.560  0.5242    81.506  77.82
  14   0.6179     78.900  0.4945    82.654  83.70
  15   0.5935     79.960  0.4735    83.406  89.56
  16   0.6090     79.690  0.4547    84.112  95.50
  17   0.5544     81.330  0.4307    84.950  101.34
  18   0.5852     80.750  0.4095    85.726  107.21
  19   0.5188     82.850  0.3937    86.264  113.08
  20   0.5314     82.460  0.3761    86.798  118.97
  21   0.5048     83.230  0.3625    87.194  124.87
  22   0.5557     81.960  0.3458    87.900  130.79
  23   0.4662     84.810  0.3312    88.360  136.64
  24   0.4860     83.940  0.3163    88.880  142.50
  25   0.5122     83.240  0.3021    89.464  148.37
  26   0.5375     83.100  0.2946    89.654  154.22
  27   0.5010     84.270  0.2797    90.226  160.08
  28   0.5119     83.550  0.2677    90.554  166.01
  29   0.4668     84.600  0.2589    90.996  171.89
  30   0.4629     85.310  0.2428    91.408  177.75
  31   0.5016     84.320  0.2421    91.438  183.60
  32   0.4502     86.260  0.2300    91.818  189.45
  33   0.4441     86.170  0.2193    92.328  195.29
  34   0.4689     85.570  0.2123    92.508  201.22
  35   0.4518     86.290  0.1987    93.014  207.08
  36   0.4709     85.930  0.1927    93.198  212.92
  37   0.4531     86.640  0.1881    93.338  218.78
  38   0.5206     84.690  0.1776    93.800  224.66
  39   0.4602     86.420  0.1709    94.008  230.53
  40   0.5377     84.730  0.1617    94.336  236.38
  41   0.4649     86.650  0.1596    94.358  242.31
  42   0.4472     87.290  0.1506    94.760  248.15
  43   0.4424     87.450  0.1451    94.896  254.00
  44   0.4870     86.330  0.1355    95.168  259.85
  45   0.4833     86.780  0.1313    95.378  265.70
  46   0.4984     87.000  0.1221    95.750  271.66
  47   0.4765     86.980  0.1164    95.928  277.53
  48   0.4786     87.290  0.1110    96.060  283.37
  49   0.4815     86.960  0.1131    96.034  289.24
  50   0.4830     86.960  0.1040    96.402  295.11
  51   0.4661     87.890  0.0989    96.530  300.98
  52   0.4909     86.980  0.0950    96.674  306.90
  53   0.4848     87.470  0.0907    96.880  312.78
  54   0.4971     87.310  0.0902    96.874  318.64
  55   0.4850     87.560  0.0826    97.164  324.47
  56   0.4639     87.750  0.0786    97.368  330.33
  57   0.4609     88.110  0.0755    97.454  336.17
  58   0.4711     87.890  0.0734    97.492  342.05
  59   0.4739     88.200  0.0697    97.674  347.91
  60   0.4880     88.080  0.0648    97.848  353.77
  61   0.4825     88.060  0.0615    97.892  359.62
  62   0.4643     88.200  0.0606    97.984  365.49
  63   0.4833     88.300  0.0597    98.028  371.44
  64   0.4934     87.890  0.0560    98.144  377.30
  65   0.4903     88.280  0.0527    98.292  383.18
  66   0.4783     88.300  0.0495    98.422  389.02
  67   0.5208     87.760  0.0469    98.524  394.88
  68   0.4991     88.370  0.0440    98.586  400.73
  69   0.4932     88.380  0.0448    98.568  406.68
  70   0.5062     87.970  0.0420    98.708  412.53
  71   0.4965     88.530  0.0401    98.682  418.38
  72   0.5097     88.240  0.0397    98.682  424.25
  73   0.4933     88.690  0.0379    98.838  430.11
  74   0.4977     88.350  0.0366    98.870  435.94
  75   0.5059     88.790  0.0358    98.936  441.95
  76   0.5170     88.350  0.0352    98.908  447.78
  77   0.4972     88.700  0.0343    98.984  453.63
  78   0.4964     88.730  0.0308    99.146  459.50
  79   0.5140     88.320  0.0309    99.078  465.35
  80   0.4997     88.750  0.0297    99.110  471.23
  81   0.5050     88.650  0.0289    99.112  477.16
  82   0.5195     88.480  0.0282    99.194  483.01
  83   0.5116     88.540  0.0301    99.092  488.88
  84   0.5108     88.580  0.0291    99.118  494.73
  85   0.5185     88.430  0.0272    99.188  500.59
