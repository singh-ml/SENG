Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4774     44.860  1.7510    34.182  7.47
   2   1.3158     51.800  1.3654    49.832  13.36
   3   1.3183     54.300  1.1812    57.340  19.18
   4   0.9775     64.980  1.0348    62.668  25.02
   5   0.9021     67.930  0.9299    66.778  30.87
   6   1.0167     65.420  0.8467    69.970  36.69
   7   0.8197     70.790  0.7756    72.498  42.60
   8   0.8053     72.470  0.7142    74.866  48.42
   9   0.6921     76.570  0.6583    76.746  54.23
  10   0.7933     73.670  0.6150    78.386  60.06
  11   0.6844     77.380  0.5780    79.720  65.90
  12   0.6722     77.030  0.5395    81.292  71.76
  13   0.5702     80.650  0.5115    82.168  77.60
  14   0.7322     77.700  0.4866    82.958  83.47
  15   0.5906     80.160  0.4638    83.694  89.33
  16   0.5556     81.540  0.4369    84.708  95.17
  17   0.5249     82.390  0.4160    85.614  101.00
  18   0.5405     82.060  0.3981    86.038  106.83
  19   0.5666     81.440  0.3795    86.934  112.66
  20   0.5847     81.180  0.3613    87.194  118.59
  21   0.6010     81.130  0.3500    87.656  124.42
  22   0.5590     82.570  0.3352    88.208  130.25
  23   0.4794     84.560  0.3197    88.744  136.09
  24   0.4854     84.410  0.3065    89.326  141.93
  25   0.4948     84.580  0.2972    89.570  147.75
  26   0.5394     83.020  0.2833    90.052  153.65
  27   0.4479     85.750  0.2708    90.554  159.47
  28   0.5005     84.300  0.2583    91.014  165.28
  29   0.4412     86.100  0.2493    91.270  171.13
  30   0.5736     82.890  0.2394    91.680  176.97
  31   0.4821     85.050  0.2348    91.640  182.82
  32   0.5086     85.100  0.2184    92.324  188.72
  33   0.4977     85.180  0.2104    92.552  194.56
  34   0.4722     86.120  0.2028    92.964  200.39
  35   0.6240     82.570  0.1935    93.352  206.24
  36   0.4883     85.980  0.1866    93.486  212.07
  37   0.5124     85.170  0.1798    93.678  218.00
  38   0.4982     85.470  0.1677    94.144  223.84
  39   0.5332     85.030  0.1665    94.226  229.69
  40   0.4730     86.690  0.1580    94.496  235.51
  41   0.4346     87.890  0.1497    94.700  241.33
  42   0.4932     86.340  0.1404    95.038  247.15
  43   0.5055     86.700  0.1369    95.246  253.03
  44   0.4595     86.870  0.1286    95.588  258.88
  45   0.4649     87.140  0.1243    95.668  264.72
  46   0.4885     87.430  0.1165    95.932  270.56
  47   0.4916     87.150  0.1139    96.038  276.38
  48   0.4942     87.140  0.1095    96.166  282.21
  49   0.5111     86.590  0.1056    96.340  288.05
  50   0.4548     88.060  0.0968    96.766  293.94
  51   0.4720     87.910  0.0929    96.782  299.79
  52   0.4688     88.010  0.0862    97.124  305.63
  53   0.4757     88.010  0.0822    97.136  311.46
  54   0.4773     87.350  0.0798    97.216  317.29
  55   0.4752     87.970  0.0741    97.516  323.11
  56   0.4721     88.250  0.0693    97.660  328.98
  57   0.4588     88.830  0.0665    97.748  334.80
  58   0.4879     88.210  0.0658    97.780  340.63
  59   0.5156     87.710  0.0620    97.958  346.46
  60   0.4786     88.800  0.0614    97.896  352.32
  61   0.4929     88.360  0.0566    98.132  358.20
  62   0.4947     88.150  0.0549    98.224  364.01
  63   0.4974     88.400  0.0507    98.370  369.84
  64   0.5271     87.720  0.0474    98.494  375.69
  65   0.4868     88.460  0.0473    98.488  381.53
  66   0.4868     88.650  0.0420    98.648  387.39
  67   0.4790     88.870  0.0425    98.668  393.29
  68   0.4839     88.940  0.0382    98.816  399.11
  69   0.4908     88.810  0.0358    98.948  404.93
  70   0.4875     88.950  0.0341    99.022  410.77
  71   0.4835     88.660  0.0328    99.018  416.62
  72   0.4933     88.750  0.0319    99.100  422.44
  73   0.5123     88.580  0.0314    99.078  428.37
  74   0.4781     89.340  0.0306    99.042  434.18
  75   0.4924     89.070  0.0297    99.198  440.00
  76   0.5131     89.050  0.0268    99.256  445.85
  77   0.4933     89.250  0.0261    99.232  451.69
  78   0.4960     89.070  0.0255    99.274  457.51
  79   0.4843     89.200  0.0241    99.348  463.37
  80   0.4833     89.320  0.0241    99.314  469.17
  81   0.4821     89.480  0.0217    99.440  475.02
  82   0.4932     89.350  0.0228    99.354  480.84
  83   0.4965     89.140  0.0219    99.384  486.67
  84   0.4981     89.170  0.0208    99.444  492.51
  85   0.5008     89.110  0.0210    99.420  498.42
  86   0.4969     89.380  0.0192    99.516  504.25
  87   0.5141     89.110  0.0194    99.496  510.08
  88   0.4940     89.240  0.0193    99.490  515.93
  89   0.5000     89.140  0.0187    99.532  521.77
  90   0.4975     89.300  0.0178    99.562  527.59
