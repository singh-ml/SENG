Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192478208 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4623     45.460  1.7638    33.752  12.29
   2   1.5251     48.370  1.3662    49.922  18.34
   3   1.1490     59.430  1.1698    57.708  24.39
   4   1.1570     60.550  1.0197    63.338  30.46
   5   0.9137     67.370  0.9172    67.074  36.51
   6   0.8996     69.070  0.8273    70.454  42.54
   7   0.9332     68.460  0.7580    73.120  48.67
   8   0.7533     74.090  0.6913    75.562  54.72
   9   0.7324     74.830  0.6461    77.136  60.76
  10   0.6977     76.100  0.6048    78.806  66.79
  11   0.6531     78.300  0.5706    79.700  72.85
  12   0.5791     80.350  0.5361    81.156  78.95
  13   0.5596     80.860  0.5133    81.872  85.01
  14   0.6779     77.750  0.4801    83.140  91.05
  15   0.6672     78.820  0.4529    84.090  97.11
  16   0.5120     82.610  0.4398    84.634  103.15
  17   0.5612     81.610  0.4203    85.186  109.18
  18   0.5242     82.770  0.4045    85.804  115.30
  19   0.5055     83.480  0.3803    86.608  121.36
  20   0.4847     83.870  0.3684    87.196  127.40
  21   0.5127     83.210  0.3486    87.740  133.45
  22   0.4971     83.440  0.3410    88.088  139.49
  23   0.5255     83.330  0.3233    88.658  145.53
  24   0.4666     84.880  0.3120    89.100  151.62
  25   0.5068     84.090  0.2960    89.686  157.65
  26   0.4796     85.140  0.2852    90.040  163.69
  27   0.5159     84.370  0.2720    90.476  169.75
  28   0.4625     85.660  0.2614    90.808  175.80
  29   0.4698     85.810  0.2472    91.332  181.85
  30   0.4687     85.670  0.2431    91.556  187.89
  31   0.5576     83.540  0.2360    91.674  193.95
  32   0.4790     85.110  0.2232    92.112  200.02
  33   0.4809     85.700  0.2116    92.610  206.04
  34   0.4836     85.690  0.2069    92.704  212.11
  35   0.4635     85.790  0.1948    93.234  218.24
  36   0.4927     85.470  0.1855    93.606  224.29
  37   0.4540     86.980  0.1790    93.678  230.36
  38   0.4406     87.440  0.1697    94.166  236.40
  39   0.4916     86.360  0.1635    94.418  242.45
  40   0.4380     87.250  0.1592    94.374  248.47
  41   0.4498     86.970  0.1512    94.782  254.59
  42   0.4499     87.470  0.1439    94.878  260.64
  43   0.4704     86.670  0.1374    95.170  266.70
  44   0.4644     87.180  0.1287    95.570  272.76
  45   0.4535     87.540  0.1211    95.826  278.81
  46   0.4825     87.400  0.1172    95.952  284.92
  47   0.4415     88.040  0.1122    96.130  290.96
  48   0.4529     87.500  0.1090    96.236  296.99
  49   0.4911     87.280  0.1034    96.394  303.01
  50   0.4634     87.880  0.0985    96.582  309.06
  51   0.4669     87.670  0.0938    96.730  315.13
  52   0.4617     88.130  0.0877    97.014  321.19
  53   0.4556     88.130  0.0841    97.060  327.21
  54   0.4766     87.940  0.0801    97.314  333.24
  55   0.4844     87.770  0.0756    97.412  339.31
  56   0.4612     88.340  0.0743    97.454  345.36
  57   0.4722     87.840  0.0663    97.826  351.40
  58   0.4682     88.780  0.0675    97.714  357.51
  59   0.4679     88.530  0.0591    98.090  363.54
  60   0.4687     88.270  0.0588    98.056  369.56
  61   0.4811     88.230  0.0548    98.216  375.64
  62   0.4537     88.700  0.0560    98.142  381.67
  63   0.4698     88.430  0.0478    98.478  387.71
  64   0.4832     88.430  0.0473    98.526  393.74
  65   0.4753     88.810  0.0483    98.412  399.81
  66   0.4523     89.220  0.0433    98.680  405.86
  67   0.4625     88.820  0.0427    98.704  411.89
  68   0.4796     88.600  0.0412    98.726  417.95
  69   0.5038     88.230  0.0373    98.896  424.05
  70   0.4835     88.470  0.0366    98.852  430.11
  71   0.4924     88.630  0.0363    98.902  436.16
  72   0.4723     89.240  0.0351    98.964  442.24
  73   0.4836     89.170  0.0330    99.028  448.30
  74   0.4852     88.830  0.0326    99.080  454.42
  75   0.4735     88.990  0.0295    99.154  460.50
  76   0.4935     88.600  0.0309    99.050  466.54
  77   0.4924     88.760  0.0290    99.178  472.60
  78   0.4961     88.890  0.0287    99.160  478.64
  79   0.4857     89.040  0.0270    99.252  484.71
  80   0.4873     88.940  0.0253    99.306  490.84
  81   0.5019     88.830  0.0261    99.318  496.88
  82   0.4955     88.830  0.0253    99.286  502.93
  83   0.5016     89.090  0.0229    99.440  508.97
  84   0.5113     88.790  0.0238    99.308  514.99
  85   0.5088     88.950  0.0234    99.356  521.06
