Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5019149312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2987     53.090  1.6372    39.244  11.22
   2   1.0498     62.420  1.1569    58.204  20.45
   3   0.8518     69.510  0.9449    66.268  29.78
   4   0.7866     72.280  0.7993    71.768  39.00
   5   0.6974     76.080  0.6914    75.576  48.20
   6   0.6393     78.310  0.6090    78.630  57.43
   7   0.5879     79.950  0.5536    80.678  66.79
   8   0.5525     81.040  0.5072    82.178  75.98
   9   0.5216     82.180  0.4641    83.722  85.25
  10   0.5218     82.730  0.4290    85.148  94.48
  11   0.4925     83.340  0.4000    86.012  103.80
  12   0.5257     83.240  0.3795    86.836  113.03
  13   0.4662     84.490  0.3504    87.856  122.30
  14   0.4717     84.540  0.3317    88.508  131.67
  15   0.5020     84.340  0.3140    89.058  140.95
  16   0.4704     84.880  0.2925    89.806  150.20
  17   0.4580     85.350  0.2759    90.384  159.48
  18   0.4429     85.850  0.2599    90.904  168.86
  19   0.4596     85.340  0.2485    91.310  178.09
  20   0.4179     86.880  0.2328    91.922  187.38
  21   0.4492     86.550  0.2172    92.344  196.65
  22   0.4431     86.710  0.2080    92.722  205.94
  23   0.4473     86.730  0.2005    92.916  215.17
  24   0.4483     86.880  0.1886    93.262  224.49
  25   0.4530     86.610  0.1808    93.566  233.83
  26   0.4511     87.010  0.1694    93.994  243.21
  27   0.4282     87.520  0.1617    94.340  252.43
  28   0.4405     87.920  0.1502    94.692  261.73
  29   0.5192     86.110  0.1480    94.728  271.14
  30   0.4278     87.720  0.1393    95.038  280.35
  31   0.4270     88.160  0.1309    95.382  289.57
  32   0.4197     88.620  0.1261    95.634  298.85
  33   0.5061     86.940  0.1192    95.770  308.17
  34   0.4833     87.730  0.1124    96.094  317.38
  35   0.5013     87.470  0.1076    96.234  326.60
  36   0.4495     88.360  0.1058    96.242  335.85
  37   0.4892     87.920  0.1003    96.526  345.13
  38   0.4516     88.590  0.0961    96.598  354.38
  39   0.5431     87.040  0.0931    96.796  363.58
  40   0.4913     88.090  0.0921    96.782  372.89
  41   0.4628     88.830  0.0832    97.092  382.31
  42   0.4798     88.530  0.0801    97.116  391.55
  43   0.5015     88.150  0.0768    97.322  400.78
  44   0.5612     87.330  0.0807    97.156  410.10
  45   0.4929     88.670  0.0707    97.514  419.48
  46   0.5268     88.400  0.0650    97.674  428.69
  47   0.4959     88.690  0.0628    97.784  437.93
  48   0.4994     88.760  0.0637    97.704  447.33
  49   0.5499     88.220  0.0641    97.784  456.53
  50   0.6320     87.160  0.0603    97.882  463.19
  51   0.4963     89.170  0.0576    97.974  472.45
  52   0.6122     87.310  0.0583    98.004  481.69
  53   0.5560     88.530  0.0548    98.090  490.90
  54   0.5278     88.970  0.0521    98.170  500.09
  55   0.4920     88.960  0.0540    98.052  509.27
  56   0.5718     88.320  0.0486    98.218  518.57
  57   0.5012     89.350  0.0489    98.286  527.77
  58   0.5339     88.760  0.0454    98.432  536.98
  59   0.5421     88.900  0.0448    98.496  546.20
  60   0.5162     89.020  0.0428    98.430  555.50
  61   0.5301     89.580  0.0409    98.612  564.74
  62   0.5839     88.670  0.0446    98.408  573.96
  63   0.5357     89.020  0.0389    98.608  583.24
  64   0.5401     89.230  0.0365    98.718  592.44
  65   0.6437     87.900  0.0370    98.750  601.66
  66   0.5991     88.720  0.0421    98.476  610.88
  67   0.5469     89.500  0.0366    98.704  620.11
  68   0.5980     88.630  0.0337    98.876  629.35
  69   0.5938     88.740  0.0361    98.752  638.63
  70   0.5833     89.100  0.0341    98.844  647.91
  71   0.6046     88.620  0.0345    98.756  657.12
  72   0.5415     89.430  0.0294    98.970  666.47
  73   0.5836     88.620  0.0289    98.982  675.77
  74   0.5649     89.420  0.0309    98.924  684.97
  75   0.5750     89.480  0.0333    98.834  694.16
  76   0.6244     88.930  0.0309    98.928  703.39
  77   0.5273     89.790  0.0293    99.004  712.61
  78   0.5733     89.630  0.0273    99.038  721.81
  79   0.5681     89.410  0.0268    99.068  731.00
  80   0.6179     88.880  0.0252    99.118  740.28
  81   0.5772     89.610  0.0236    99.218  749.50
  82   0.5492     89.950  0.0226    99.220  758.71
  83   0.5738     89.660  0.0227    99.270  767.89
  84   0.6645     88.460  0.0237    99.194  777.14
  85   0.6058     89.390  0.0238    99.160  786.41
