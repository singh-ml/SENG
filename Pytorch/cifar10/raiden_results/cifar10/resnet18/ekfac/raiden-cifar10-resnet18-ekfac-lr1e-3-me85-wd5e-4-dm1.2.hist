Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5019149312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3051     51.760  1.6494    38.652  16.28
   2   0.9865     64.180  1.1577    58.014  25.66
   3   0.8586     70.020  0.9263    66.836  34.94
   4   0.7766     73.300  0.7856    72.262  44.21
   5   0.7157     75.780  0.6829    76.024  53.60
   6   0.6202     78.450  0.6096    78.678  62.91
   7   0.5776     80.230  0.5470    80.680  72.21
   8   0.5681     80.840  0.5008    82.522  81.51
   9   0.5323     82.250  0.4580    84.222  90.84
  10   0.5764     81.220  0.4203    85.382  100.10
  11   0.4792     83.610  0.3932    86.314  109.36
  12   0.4685     84.770  0.3711    87.088  118.63
  13   0.4713     84.580  0.3437    87.952  127.95
  14   0.4478     85.000  0.3246    88.694  137.22
  15   0.4671     85.110  0.3029    89.506  146.48
  16   0.4460     86.370  0.2845    90.090  155.70
  17   0.5203     84.090  0.2712    90.618  164.95
  18   0.4796     85.550  0.2581    90.996  174.35
  19   0.4737     85.550  0.2432    91.442  183.63
  20   0.4295     86.500  0.2312    92.092  192.87
  21   0.4696     86.040  0.2177    92.376  202.08
  22   0.4632     86.010  0.2062    92.662  212.65
  23   0.4440     86.970  0.1986    93.102  221.91
  24   0.4670     87.250  0.1870    93.436  231.23
  25   0.4452     86.890  0.1772    93.844  240.50
  26   0.4329     87.610  0.1654    94.134  249.84
  27   0.4470     87.830  0.1592    94.450  259.07
  28   0.4293     88.060  0.1482    94.700  268.31
  29   0.4499     87.600  0.1434    94.982  277.58
  30   0.4504     87.940  0.1417    95.122  286.96
  31   0.4543     87.500  0.1310    95.286  296.24
  32   0.4750     87.990  0.1207    95.772  305.52
  33   0.4399     88.310  0.1186    95.728  314.85
  34   0.4325     88.470  0.1125    96.022  324.09
  35   0.4553     88.290  0.1129    96.010  333.33
  36   0.4826     87.950  0.1030    96.418  342.61
  37   0.4278     89.200  0.0969    96.604  351.95
  38   0.4999     87.680  0.0953    96.600  361.18
  39   0.4601     88.730  0.0905    96.828  370.43
  40   0.4796     88.450  0.0863    96.962  379.68
  41   0.4692     88.780  0.0881    96.874  389.03
  42   0.4926     88.180  0.0822    97.114  398.28
  43   0.5092     88.460  0.0722    97.434  407.54
  44   0.5301     88.010  0.0731    97.422  416.79
  45   0.5008     88.760  0.0719    97.422  426.08
  46   0.5739     87.290  0.0709    97.592  435.31
  47   0.4915     88.810  0.0666    97.572  444.54
  48   0.4653     89.320  0.0646    97.746  453.91
  49   0.5039     89.000  0.0620    97.860  463.26
  50   0.5280     88.880  0.0585    97.866  469.97
  51   0.5250     88.970  0.0586    97.880  479.22
  52   0.5028     89.220  0.0592    97.916  488.41
  53   0.5182     88.840  0.0578    97.948  497.62
  54   0.5511     89.030  0.0526    98.154  506.98
  55   0.5426     88.490  0.0482    98.286  516.24
  56   0.5337     89.050  0.0536    98.096  525.50
  57   0.5197     89.240  0.0491    98.288  534.85
  58   0.4960     89.460  0.0488    98.344  544.09
  59   0.5308     89.090  0.0513    98.188  553.29
  60   0.5209     89.160  0.0468    98.330  562.54
  61   0.5809     88.400  0.0457    98.428  571.93
  62   0.5328     89.230  0.0397    98.586  581.19
  63   0.5634     89.060  0.0403    98.590  590.40
  64   0.5841     88.880  0.0389    98.656  599.68
  65   0.5645     89.030  0.0390    98.636  609.03
  66   0.5558     89.170  0.0368    98.732  618.28
  67   0.5566     89.310  0.0385    98.680  627.57
  68   0.5374     89.600  0.0368    98.740  636.77
  69   0.5168     89.610  0.0351    98.844  646.10
  70   0.5927     88.720  0.0380    98.644  655.33
  71   0.5765     89.240  0.0324    98.910  664.54
  72   0.5951     89.080  0.0301    98.964  673.79
  73   0.5382     89.260  0.0302    98.944  683.15
  74   0.5825     88.740  0.0284    98.972  692.38
  75   0.5920     89.120  0.0321    98.836  701.58
  76   0.5818     89.140  0.0332    98.870  710.79
  77   0.5697     89.580  0.0300    98.988  720.10
  78   0.5817     89.610  0.0261    99.118  729.32
  79   0.5910     88.930  0.0300    98.952  738.57
  80   0.5738     89.430  0.0293    99.054  747.87
  81   0.5666     89.680  0.0293    98.992  757.13
  82   0.5677     89.490  0.0243    99.166  766.37
  83   0.5733     89.540  0.0292    98.992  775.61
  84   0.6097     89.490  0.0240    99.208  784.99
  85   0.5910     89.260  0.0273    99.048  794.24
