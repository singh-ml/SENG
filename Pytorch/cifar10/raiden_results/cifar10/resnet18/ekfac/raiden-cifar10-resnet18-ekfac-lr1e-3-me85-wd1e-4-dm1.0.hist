Use GPU: 0 for training
==> Running with ['main_ekfac.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5019149312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3221     51.690  1.6295    39.566  11.24
   2   1.0417     61.820  1.1602    58.100  20.64
   3   0.9004     68.040  0.9526    66.058  29.97
   4   0.8025     71.640  0.8191    71.110  39.35
   5   0.7005     75.130  0.7179    74.586  48.71
   6   0.6492     77.020  0.6357    77.698  58.13
   7   0.5841     80.050  0.5707    79.962  67.52
   8   0.5998     79.480  0.5200    81.792  76.88
   9   0.5345     81.960  0.4763    83.306  86.27
  10   0.5304     82.270  0.4377    84.824  95.70
  11   0.4898     83.200  0.4099    85.732  105.07
  12   0.4914     83.370  0.3802    86.806  114.45
  13   0.4844     84.060  0.3573    87.574  123.84
  14   0.4818     84.530  0.3330    88.452  133.31
  15   0.4517     84.910  0.3139    89.094  142.69
  16   0.4558     85.310  0.2931    89.824  152.04
  17   0.4622     85.020  0.2757    90.448  161.40
  18   0.4765     85.080  0.2629    90.732  170.83
  19   0.4405     85.780  0.2505    91.222  180.17
  20   0.4537     85.650  0.2346    91.818  189.55
  21   0.4501     86.560  0.2150    92.588  198.92
  22   0.4700     85.880  0.2132    92.400  208.33
  23   0.4505     86.140  0.2004    92.922  217.66
  24   0.4394     87.030  0.1883    93.412  227.05
  25   0.4532     86.620  0.1769    93.858  236.53
  26   0.4362     87.340  0.1710    94.092  245.88
  27   0.4572     87.250  0.1608    94.274  255.23
  28   0.4743     86.800  0.1516    94.644  264.58
  29   0.4358     87.780  0.1477    94.832  274.15
  30   0.4593     87.300  0.1382    95.236  283.50
  31   0.5243     86.340  0.1336    95.310  292.90
  32   0.4265     88.330  0.1254    95.614  302.32
  33   0.4813     87.250  0.1181    95.836  311.64
  34   0.4746     87.690  0.1120    96.094  320.97
  35   0.4899     87.870  0.1106    96.086  330.31
  36   0.4649     88.260  0.1068    96.186  339.64
  37   0.5058     87.530  0.1030    96.304  349.09
  38   0.5052     87.120  0.0957    96.734  358.46
  39   0.4887     87.980  0.0950    96.644  367.77
  40   0.5184     87.840  0.0895    96.800  377.11
  41   0.5214     87.550  0.0865    96.918  386.58
  42   0.4847     88.440  0.0765    97.278  395.93
  43   0.5016     87.910  0.0736    97.386  405.25
  44   0.4803     88.780  0.0779    97.248  414.63
  45   0.4977     88.460  0.0708    97.480  423.97
  46   0.4968     88.690  0.0686    97.574  433.36
  47   0.5029     88.710  0.0665    97.648  442.71
  48   0.5073     88.570  0.0648    97.736  452.15
  49   0.5611     87.580  0.0621    97.810  461.47
  50   0.5350     88.600  0.0601    97.892  468.29
  51   0.5198     88.560  0.0589    97.916  477.65
  52   0.5609     88.170  0.0548    98.024  487.06
  53   0.5574     87.580  0.0531    98.174  496.40
  54   0.5236     88.440  0.0534    98.070  505.76
  55   0.5393     88.190  0.0464    98.420  515.11
  56   0.5762     88.080  0.0510    98.242  524.44
  57   0.5306     88.740  0.0470    98.318  533.72
  58   0.5388     88.450  0.0504    98.208  543.05
  59   0.5502     88.290  0.0474    98.286  552.36
  60   0.5395     89.400  0.0427    98.470  561.76
  61   0.6183     87.890  0.0419    98.510  571.01
  62   0.5476     89.290  0.0421    98.540  580.29
  63   0.5448     89.060  0.0415    98.576  589.57
  64   0.5400     88.570  0.0366    98.752  598.93
  65   0.5435     88.970  0.0346    98.816  608.19
  66   0.5586     88.810  0.0350    98.810  617.50
  67   0.5863     88.530  0.0356    98.746  626.79
  68   0.5413     89.260  0.0354    98.742  636.14
  69   0.5241     89.320  0.0347    98.816  645.44
  70   0.5683     88.780  0.0342    98.784  654.75
  71   0.5363     89.350  0.0304    98.984  664.08
  72   0.5755     88.800  0.0350    98.814  673.36
  73   0.5729     88.830  0.0302    98.968  682.66
  74   0.6100     88.620  0.0325    98.848  691.93
  75   0.5705     89.330  0.0273    99.090  701.23
  76   0.5826     89.020  0.0279    99.024  710.61
  77   0.6100     88.810  0.0293    99.000  720.04
  78   0.5806     89.120  0.0303    98.962  729.34
  79   0.5693     89.140  0.0271    99.058  738.65
  80   0.5840     89.160  0.0280    99.050  748.07
  81   0.6581     88.540  0.0298    98.968  757.37
  82   0.5866     89.190  0.0254    99.116  766.72
  83   0.5904     89.510  0.0257    99.108  776.05
  84   0.5494     89.780  0.0233    99.212  785.91
  85   0.5781     89.630  0.0241    99.152  795.20
