Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 6339961856 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4108     49.310  1.6514    38.396  19.48
   2   1.1445     59.430  1.2249    55.508  37.30
   3   1.0202     64.510  1.0184    63.466  54.90
   4   0.9314     68.780  0.8703    68.910  72.58
   5   0.8222     71.870  0.7617    72.890  90.21
   6   0.8088     72.630  0.6831    75.874  107.84
   7   0.6736     77.450  0.6178    78.418  125.63
   8   0.7621     75.680  0.5648    80.358  143.29
   9   0.6391     78.620  0.5310    81.456  161.12
  10   0.6447     78.230  0.4833    83.078  178.73
  11   0.5394     82.460  0.4548    84.096  196.40
  12   0.7054     77.920  0.4222    85.278  214.00
  13   0.5756     81.600  0.4033    86.006  231.65
  14   0.5029     83.290  0.3774    86.852  249.48
  15   0.6039     80.550  0.3555    87.578  267.12
  16   0.5082     83.720  0.3376    88.330  284.95
  17   0.4947     83.870  0.3184    88.900  302.57
  18   0.5359     83.200  0.3040    89.310  320.32
  19   0.5443     82.940  0.2916    89.938  337.95
  20   0.5006     84.330  0.2753    90.464  355.59
  21   0.5634     83.490  0.2646    90.770  373.42
  22   0.5068     84.200  0.2566    91.112  391.06
  23   0.4424     86.470  0.2312    91.882  408.76
  24   0.4952     85.420  0.2232    92.230  426.40
  25   0.4415     85.920  0.2179    92.402  444.13
  26   0.4318     87.060  0.2021    92.802  461.74
  27   0.5148     85.510  0.1983    92.856  479.38
  28   0.4473     87.130  0.1866    93.370  497.21
  29   0.4744     86.220  0.1784    93.716  514.81
  30   0.4480     87.420  0.1693    94.090  532.63
  31   0.4544     87.170  0.1586    94.362  550.25
  32   0.4820     86.930  0.1495    94.666  567.97
  33   0.4545     87.160  0.1454    94.812  585.58
  34   0.4487     87.690  0.1390    95.080  603.21
  35   0.4698     87.710  0.1370    95.172  621.04
  36   0.5077     86.630  0.1259    95.552  638.67
  37   0.4939     87.290  0.1258    95.528  656.35
  38   0.5166     86.920  0.1165    95.836  673.97
  39   0.4787     88.080  0.1171    95.838  691.71
  40   0.5334     87.030  0.1042    96.340  709.34
  41   0.4995     87.610  0.1040    96.272  727.00
  42   0.4536     88.640  0.0990    96.500  744.83
  43   0.5493     87.270  0.0897    96.782  762.45
  44   0.5714     86.980  0.0918    96.758  780.33
  45   0.5311     87.630  0.0847    96.982  797.97
  46   0.4907     88.110  0.0802    97.146  815.61
  47   0.4770     88.330  0.0797    97.172  833.49
  48   0.5970     86.860  0.0801    97.120  851.14
  49   0.4704     88.640  0.0748    97.374  868.96
  50   0.5741     87.280  0.0642    97.740  886.57
  51   0.4682     89.100  0.0662    97.672  904.30
  52   0.5160     88.970  0.0622    97.798  921.93
  53   0.5292     88.340  0.0654    97.672  939.56
  54   0.5148     89.090  0.0554    98.022  957.20
  55   0.4758     89.180  0.0577    97.990  974.84
  56   0.5066     89.340  0.0544    98.066  992.69
  57   0.5867     87.560  0.0577    97.890  1010.32
  58   0.5274     88.840  0.0490    98.298  1028.21
  59   0.5354     89.300  0.0502    98.216  1045.83
  60   0.5373     88.690  0.0484    98.290  1063.46
  61   0.5512     88.440  0.0466    98.340  1081.09
  62   0.5345     88.700  0.0422    98.488  1098.73
  63   0.4971     89.690  0.0412    98.554  1116.56
  64   0.5407     89.170  0.0399    98.612  1134.19
  65   0.5313     89.580  0.0378    98.712  1151.91
  66   0.5339     89.740  0.0377    98.644  1169.56
  67   0.5490     89.080  0.0386    98.656  1187.33
  68   0.5213     89.480  0.0377    98.692  1204.97
  69   0.5569     89.190  0.0337    98.806  1222.61
  70   0.5777     88.830  0.0369    98.702  1240.47
  71   0.5175     89.680  0.0305    98.964  1258.11
  72   0.5413     89.470  0.0275    99.060  1275.96
  73   0.5871     89.030  0.0302    98.912  1293.60
  74   0.5609     89.500  0.0271    99.062  1311.32
  75   0.5531     89.830  0.0287    99.032  1328.94
  76   0.5669     89.400  0.0289    99.026  1346.61
  77   0.5734     89.170  0.0278    99.004  1364.42
  78   0.5637     89.300  0.0278    99.044  1382.05
  79   0.5541     89.640  0.0292    98.954  1399.89
  80   0.5418     89.690  0.0254    99.118  1417.50
  81   0.5835     89.060  0.0236    99.166  1435.22
  82   0.5704     89.570  0.0252    99.126  1452.86
  83   0.6212     89.230  0.0239    99.200  1470.48
  84   0.5673     89.720  0.0255    99.136  1488.31
  85   0.5838     89.550  0.0251    99.130  1505.93
