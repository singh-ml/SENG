Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7933302272 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6649     40.520  1.9004    34.560  33.32
   2   1.0838     63.110  1.1828    57.106  64.72
   3   0.8377     70.520  0.9052    67.748  96.15
   4   0.8647     70.570  0.7423    73.788  127.55
   5   0.7607     74.450  0.6284    78.178  158.94
   6   0.8067     75.170  0.5482    80.826  190.33
   7   0.6195     79.410  0.4869    83.270  221.73
   8   0.5004     82.580  0.4424    84.734  253.11
   9   0.4680     84.510  0.4035    85.902  284.51
  10   0.4731     84.630  0.3669    87.396  315.90
  11   0.4785     84.330  0.3397    88.258  347.29
  12   0.4455     86.380  0.3115    89.220  378.73
  13   0.5151     83.910  0.2923    89.790  410.12
  14   0.4385     85.870  0.2709    90.586  441.52
  15   0.4720     85.680  0.2585    90.872  472.90
  16   0.3637     88.640  0.2370    91.646  504.30
  17   0.5054     85.250  0.2247    92.028  535.70
  18   0.6214     82.690  0.2089    92.798  567.10
  19   0.4410     87.170  0.1909    93.404  598.52
  20   0.3881     88.460  0.1883    93.338  629.90
  21   0.3868     88.730  0.1754    93.862  661.29
  22   0.4357     87.640  0.1622    94.278  692.72
  23   0.4190     87.670  0.1498    94.778  724.11
  24   0.3770     89.020  0.1460    94.906  755.47
  25   0.3862     89.280  0.1370    95.076  786.85
  26   0.4050     89.240  0.1255    95.518  818.25
  27   0.3898     89.070  0.1121    96.042  849.65
  28   0.4047     89.520  0.1104    96.086  881.07
  29   0.3500     91.030  0.1034    96.408  912.46
  30   0.3577     90.980  0.0944    96.776  943.85
  31   0.3418     90.970  0.0914    96.794  975.27
  32   0.3666     90.660  0.0783    97.258  1006.68
  33   0.6185     87.350  0.0806    97.142  1038.09
  34   0.4105     90.310  0.0730    97.378  1069.50
  35   0.3744     91.240  0.0687    97.546  1100.91
  36   0.4013     90.960  0.0608    97.838  1132.33
  37   0.3807     91.050  0.0594    97.886  1163.71
  38   0.4002     90.850  0.0524    98.192  1195.13
  39   0.4257     91.150  0.0480    98.244  1226.52
  40   0.4085     91.480  0.0441    98.424  1257.94
  41   0.3665     92.250  0.0423    98.582  1289.34
  42   0.3669     91.870  0.0409    98.634  1320.73
  43   0.4073     91.390  0.0331    98.866  1352.14
  44   0.3929     92.040  0.0304    98.958  1383.55
  45   0.4037     92.140  0.0293    98.944  1414.96
  46   0.4348     91.580  0.0246    99.130  1446.38
  47   0.4559     91.310  0.0227    99.198  1477.78
  48   0.4203     91.930  0.0233    99.158  1509.17
  49   0.4350     91.940  0.0197    99.294  1540.59
  50   0.4130     92.670  0.0185    99.366  1571.99
  51   0.4482     92.370  0.0148    99.494  1603.40
  52   0.4412     92.300  0.0115    99.576  1634.78
  53   0.4623     92.290  0.0138    99.548  1666.20
  54   0.4221     92.440  0.0117    99.616  1697.62
  55   0.4204     93.010  0.0089    99.698  1729.01
  56   0.4365     92.930  0.0092    99.678  1760.39
  57   0.4444     92.920  0.0086    99.696  1791.81
  58   0.4545     92.710  0.0069    99.788  1823.20
  59   0.4325     93.040  0.0068    99.766  1854.63
  60   0.4495     93.060  0.0061    99.784  1886.03
  61   0.4710     92.610  0.0047    99.864  1917.44
  62   0.4663     93.050  0.0043    99.854  1948.84
  63   0.4526     93.420  0.0027    99.928  1980.26
  64   0.4483     93.180  0.0029    99.904  2011.64
  65   0.4686     93.310  0.0031    99.906  2043.03
  66   0.4785     93.040  0.0025    99.910  2074.44
  67   0.4655     93.230  0.0023    99.934  2105.86
  68   0.4602     93.320  0.0014    99.974  2137.27
  69   0.4683     93.310  0.0013    99.966  2168.67
  70   0.4663     93.350  0.0010    99.970  2200.10
  71   0.4749     93.360  0.0013    99.970  2231.51
  72   0.4715     93.300  0.0013    99.954  2262.94
  73   0.4718     93.420  0.0010    99.978  2294.36
  74   0.4892     93.350  0.0010    99.976  2325.75
  75   0.4784     93.500  0.0009    99.974  2357.14
  76   0.4791     93.560  0.0008    99.982  2388.51
  77   0.4816     93.400  0.0011    99.976  2419.92
  78   0.4834     93.300  0.0006    99.986  2451.34
  79   0.4805     93.420  0.0006    99.982  2482.75
  80   0.4815     93.470  0.0006    99.980  2514.13
  81   0.4729     93.530  0.0006    99.988  2545.54
  82   0.4822     93.480  0.0007    99.978  2576.93
  83   0.4837     93.590  0.0006    99.984  2608.32
  84   0.4788     93.420  0.0005    99.990  2639.70
  85   0.4771     93.500  0.0006    99.986  2671.13
