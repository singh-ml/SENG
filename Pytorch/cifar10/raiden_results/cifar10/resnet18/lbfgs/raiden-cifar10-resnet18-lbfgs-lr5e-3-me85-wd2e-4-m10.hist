Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3624     10.570  4.8768    10.444  9.11
   2   2.3617     10.600  4.8769    10.376  16.56
   3   2.3621     10.560  4.8761    10.362  24.03
   4   2.3623     10.570  4.8773    10.398  31.33
   5   2.3628     10.690  4.8778    10.402  38.71
   6   2.3628     10.570  4.8771    10.408  46.25
   7   2.3624     10.550  4.8759    10.402  53.66
   8   2.3626     10.560  4.8760    10.340  61.05
   9   2.3627     10.500  4.8773    10.454  68.51
  10   2.3629     10.550  4.8764    10.380  76.10
  11   2.3623     10.530  4.8769    10.408  83.77
  12   2.3615     10.550  4.8770    10.422  91.09
  13   2.3627     10.520  4.8768    10.402  98.39
  14   2.3626     10.490  4.8761    10.416  105.78
  15   2.3624     10.540  4.8769    10.356  113.39
  16   2.3617     10.570  4.8766    10.474  120.85
  17   2.3623     10.530  4.8749    10.452  128.55
  18   2.3621     10.550  4.8771    10.418  135.88
  19   2.3620     10.480  4.8762    10.432  143.40
  20   2.3629     10.560  4.8767    10.414  150.86
  21   2.3620     10.550  4.8760    10.424  158.24
  22   2.3629     10.580  4.8761    10.418  165.70
  23   2.3622     10.550  4.8751    10.476  172.94
  24   2.3629     10.480  4.8753    10.426  180.54
  25   2.3619     10.530  4.8766    10.394  188.08
  26   2.3620     10.520  4.8767    10.434  195.56
  27   2.3624     10.590  4.8768    10.372  202.87
  28   2.3626     10.570  4.8769    10.412  210.31
  29   2.3619     10.590  4.8766    10.370  217.84
  30   2.3622     10.580  4.8772    10.398  225.24
  31   2.3624     10.540  4.8761    10.334  232.61
  32   2.3622     10.660  4.8771    10.326  239.93
  33   2.3624     10.640  4.8767    10.380  247.36
  34   2.3622     10.540  4.8756    10.304  254.96
  35   2.3630     10.620  4.8759    10.446  262.24
  36   2.3615     10.540  4.8761    10.334  269.51
  37   2.3620     10.510  4.8767    10.378  276.93
  38   2.3618     10.590  4.8774    10.446  284.42
  39   2.3621     10.590  4.8769    10.472  291.89
  40   2.3631     10.530  4.8761    10.348  299.37
  41   2.3631     10.480  4.8761    10.454  306.67
  42   2.3621     10.460  4.8761    10.402  314.05
  43   2.3611     10.520  4.8776    10.396  321.60
  44   2.3620     10.590  4.8769    10.392  329.07
  45   2.3627     10.510  4.8775    10.354  336.46
  46   2.3617     10.520  4.8770    10.400  343.87
  47   2.3620     10.610  4.8768    10.446  351.28
  48   2.3624     10.570  4.8781    10.342  358.82
  49   2.3626     10.480  4.8781    10.380  366.22
  50   2.3616     10.430  4.8766    10.396  373.71
  51   2.3629     10.590  4.8771    10.416  381.15
  52   2.3624     10.590  4.8770    10.452  388.56
  53   2.3617     10.580  4.8775    10.362  396.14
  54   2.3622     10.580  4.8769    10.332  403.78
  55   2.3635     10.580  4.8773    10.352  411.20
  56   2.3616     10.560  4.8761    10.438  418.66
  57   2.3619     10.580  4.8762    10.432  426.04
  58   2.3628     10.500  4.8766    10.344  433.53
  59   2.3616     10.500  4.8763    10.470  440.92
  60   2.3625     10.580  4.8769    10.368  448.37
  61   2.3621     10.490  4.8765    10.530  455.85
  62   2.3625     10.610  4.8763    10.328  463.33
  63   2.3621     10.550  4.8765    10.410  470.92
  64   2.3618     10.480  4.8763    10.530  478.50
  65   2.3624     10.490  4.8760    10.412  485.83
  66   2.3622     10.580  4.8757    10.366  493.22
  67   2.3624     10.530  4.8775    10.440  500.74
  68   2.3621     10.570  4.8762    10.404  508.15
  69   2.3630     10.520  4.8759    10.442  515.41
  70   2.3620     10.540  4.8770    10.418  522.88
  71   2.3627     10.580  4.8765    10.436  530.28
  72   2.3616     10.560  4.8765    10.348  537.77
  73   2.3616     10.580  4.8763    10.430  545.24
  74   2.3628     10.550  4.8774    10.390  552.73
  75   2.3619     10.480  4.8765    10.426  560.15
  76   2.3631     10.530  4.8780    10.480  567.59
  77   2.3621     10.550  4.8762    10.318  575.11
  78   2.3621     10.600  4.8768    10.416  582.52
  79   2.3630     10.530  4.8772    10.344  589.91
  80   2.3624     10.540  4.8774    10.362  597.58
  81   2.3622     10.500  4.8773    10.462  604.94
  82   2.3625     10.560  4.8768    10.402  612.43
  83   2.3627     10.490  4.8767    10.366  619.82
  84   2.3623     10.530  4.8766    10.350  627.20
  85   2.3628     10.540  4.8750    10.474  634.63
