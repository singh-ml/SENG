Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4552     10.140  3.7215    10.318  8.97
   2   2.4537     10.130  3.7214    10.360  16.34
   3   2.4542     10.120  3.7218    10.356  23.72
   4   2.4553     10.140  3.7217    10.274  31.05
   5   2.4538     10.170  3.7224    10.252  38.53
   6   2.4538     10.160  3.7231    10.236  45.79
   7   2.4546     10.200  3.7222    10.334  53.14
   8   2.4542     10.100  3.7224    10.250  60.56
   9   2.4537     10.180  3.7215    10.268  67.95
  10   2.4537     10.150  3.7224    10.312  75.37
  11   2.4528     10.140  3.7218    10.226  82.74
  12   2.4542     10.130  3.7217    10.196  90.18
  13   2.4539     10.170  3.7218    10.394  97.62
  14   2.4546     10.200  3.7218    10.310  104.96
  15   2.4537     10.200  3.7224    10.276  112.52
  16   2.4540     10.180  3.7203    10.268  119.90
  17   2.4542     10.190  3.7222    10.236  127.20
  18   2.4542     10.140  3.7213    10.298  134.54
  19   2.4537     10.190  3.7215    10.286  142.05
  20   2.4539     10.190  3.7210    10.246  149.49
  21   2.4534     10.190  3.7212    10.282  156.93
  22   2.4537     10.220  3.7225    10.338  164.31
  23   2.4534     10.140  3.7214    10.340  171.62
  24   2.4531     10.190  3.7220    10.402  179.05
  25   2.4540     10.220  3.7217    10.362  186.43
  26   2.4541     10.150  3.7218    10.294  193.86
  27   2.4539     10.130  3.7221    10.222  201.34
  28   2.4558     10.200  3.7216    10.250  208.76
  29   2.4541     10.140  3.7204    10.324  216.31
  30   2.4541     10.220  3.7205    10.306  223.74
  31   2.4542     10.150  3.7208    10.262  231.06
  32   2.4539     10.200  3.7216    10.160  238.39
  33   2.4549     10.180  3.7217    10.254  245.75
  34   2.4549     10.180  3.7218    10.266  253.22
  35   2.4543     10.160  3.7216    10.254  260.60
  36   2.4531     10.140  3.7211    10.302  268.03
  37   2.4543     10.220  3.7201    10.340  275.44
  38   2.4543     10.150  3.7217    10.284  282.77
  39   2.4530     10.140  3.7210    10.322  290.35
  40   2.4540     10.210  3.7222    10.230  297.72
  41   2.4539     10.150  3.7204    10.254  305.09
  42   2.4537     10.170  3.7207    10.274  312.42
  43   2.4543     10.180  3.7227    10.260  319.92
  44   2.4550     10.170  3.7213    10.294  327.33
  45   2.4531     10.180  3.7223    10.266  334.76
  46   2.4539     10.140  3.7216    10.352  342.03
  47   2.4543     10.200  3.7219    10.252  349.37
  48   2.4543     10.180  3.7211    10.246  356.75
  49   2.4534     10.170  3.7226    10.288  364.28
  50   2.4547     10.230  3.7212    10.318  371.77
  51   2.4526     10.190  3.7224    10.292  379.01
  52   2.4534     10.180  3.7214    10.328  386.36
  53   2.4538     10.160  3.7213    10.238  393.88
  54   2.4540     10.180  3.7213    10.256  401.25
  55   2.4549     10.160  3.7211    10.268  408.67
  56   2.4537     10.170  3.7214    10.316  416.18
  57   2.4546     10.170  3.7215    10.226  423.49
  58   2.4540     10.180  3.7226    10.262  431.04
  59   2.4541     10.150  3.7217    10.282  438.31
  60   2.4547     10.160  3.7224    10.226  445.64
  61   2.4537     10.180  3.7218    10.232  452.92
  62   2.4534     10.240  3.7214    10.302  460.24
  63   2.4550     10.200  3.7205    10.398  467.76
  64   2.4550     10.170  3.7212    10.272  475.08
  65   2.4545     10.160  3.7220    10.216  482.47
  66   2.4538     10.110  3.7222    10.248  489.85
  67   2.4549     10.110  3.7208    10.282  497.23
  68   2.4533     10.210  3.7224    10.220  504.92
  69   2.4556     10.220  3.7221    10.240  512.26
  70   2.4550     10.170  3.7216    10.286  519.58
  71   2.4538     10.130  3.7214    10.242  526.92
  72   2.4543     10.190  3.7225    10.456  534.47
  73   2.4546     10.190  3.7217    10.224  541.69
  74   2.4549     10.160  3.7214    10.236  549.01
  75   2.4544     10.210  3.7212    10.300  556.37
  76   2.4541     10.170  3.7217    10.256  563.80
  77   2.4534     10.240  3.7224    10.290  571.41
  78   2.4539     10.160  3.7220    10.358  578.83
  79   2.4551     10.160  3.7207    10.252  586.16
  80   2.4546     10.150  3.7224    10.352  593.55
  81   2.4542     10.170  3.7216    10.276  600.92
  82   2.4547     10.170  3.7217    10.252  608.29
  83   2.4542     10.150  3.7206    10.324  615.55
  84   2.4532     10.150  3.7221    10.222  622.86
  85   2.4558     10.180  3.7220    10.372  630.23
