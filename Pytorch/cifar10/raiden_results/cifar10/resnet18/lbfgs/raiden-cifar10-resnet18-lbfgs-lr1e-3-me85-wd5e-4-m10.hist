Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4184      9.130  8.6742     9.836  8.86
   2   2.4177      9.200  8.6741     9.748  15.84
   3   2.4191      9.200  8.6750     9.760  22.82
   4   2.4181      9.220  8.6747     9.784  29.94
   5   2.4179      9.220  8.6737     9.834  37.09
   6   2.4166      9.290  8.6751     9.850  44.18
   7   2.4157      9.230  8.6744     9.760  51.18
   8   2.4165      9.210  8.6737     9.824  58.25
   9   2.4148      9.250  8.6751     9.752  65.29
  10   2.4181      9.230  8.6757     9.734  72.36
  11   2.4176      9.250  8.6745     9.842  79.30
  12   2.4162      9.200  8.6744     9.842  86.35
  13   2.4184      9.260  8.6740     9.850  93.31
  14   2.4176      9.240  8.6749     9.818  100.40
  15   2.4176      9.200  8.6736     9.720  107.41
  16   2.4171      9.230  8.6746     9.862  114.50
  17   2.4180      9.270  8.6760     9.840  121.56
  18   2.4178      9.230  8.6730     9.760  128.67
  19   2.4169      9.230  8.6752     9.842  135.80
  20   2.4156      9.230  8.6739     9.828  142.79
  21   2.4163      9.250  8.6745     9.868  149.76
  22   2.4179      9.230  8.6744     9.762  156.83
  23   2.4183      9.240  8.6751     9.802  163.95
  24   2.4176      9.190  8.6737     9.836  171.03
  25   2.4176      9.210  8.6744     9.824  178.09
  26   2.4171      9.200  8.6748     9.868  185.14
  27   2.4172      9.240  8.6749     9.748  192.19
  28   2.4180      9.190  8.6754     9.720  199.44
  29   2.4175      9.200  8.6732     9.800  206.55
  30   2.4171      9.210  8.6746     9.764  213.52
  31   2.4175      9.230  8.6742     9.730  220.49
  32   2.4163      9.190  8.6745     9.842  227.50
  33   2.4172      9.200  8.6735     9.800  234.64
  34   2.4177      9.220  8.6740     9.860  241.65
  35   2.4176      9.230  8.6746     9.794  248.76
  36   2.4182      9.210  8.6748     9.816  255.75
  37   2.4177      9.200  8.6744     9.784  262.79
  38   2.4169      9.170  8.6747     9.846  269.93
  39   2.4166      9.170  8.6746     9.858  276.99
  40   2.4182      9.160  8.6747     9.832  284.03
  41   2.4163      9.250  8.6750     9.786  291.05
  42   2.4169      9.280  8.6754     9.770  298.11
  43   2.4185      9.190  8.6725     9.884  305.22
  44   2.4189      9.260  8.6741     9.744  312.15
  45   2.4166      9.210  8.6752     9.868  319.18
  46   2.4176      9.230  8.6747     9.804  326.18
  47   2.4171      9.220  8.6746     9.734  333.44
  48   2.4182      9.300  8.6739     9.788  340.44
  49   2.4190      9.200  8.6739     9.918  347.60
  50   2.4188      9.160  8.6742     9.820  354.63
  51   2.4179      9.260  8.6736     9.802  361.57
  52   2.4184      9.150  8.6756     9.810  368.59
  53   2.4148      9.200  8.6746     9.894  375.82
  54   2.4166      9.220  8.6745     9.834  382.74
  55   2.4173      9.200  8.6743     9.786  389.72
  56   2.4174      9.220  8.6731     9.744  396.82
  57   2.4172      9.180  8.6744     9.800  403.93
  58   2.4188      9.200  8.6750     9.834  411.09
  59   2.4162      9.200  8.6764     9.828  418.17
  60   2.4171      9.250  8.6754     9.784  425.12
  61   2.4174      9.210  8.6740     9.932  432.22
  62   2.4169      9.230  8.6743     9.866  439.31
  63   2.4177      9.210  8.6741     9.854  446.42
  64   2.4174      9.180  8.6743     9.774  453.36
  65   2.4173      9.190  8.6734     9.892  460.29
  66   2.4174      9.270  8.6740     9.808  467.37
  67   2.4179      9.120  8.6749     9.798  474.51
  68   2.4163      9.200  8.6736     9.854  481.63
  69   2.4161      9.200  8.6736     9.908  488.71
  70   2.4180      9.190  8.6733     9.806  495.76
  71   2.4169      9.290  8.6741     9.856  502.69
  72   2.4170      9.230  8.6757     9.796  509.78
  73   2.4165      9.220  8.6751     9.870  516.82
  74   2.4159      9.200  8.6748     9.794  523.95
  75   2.4166      9.260  8.6750     9.816  531.01
  76   2.4178      9.210  8.6739     9.816  537.94
  77   2.4166      9.220  8.6749     9.772  545.18
  78   2.4170      9.180  8.6742     9.764  552.20
  79   2.4165      9.250  8.6747     9.820  559.28
  80   2.4177      9.170  8.6734     9.820  566.37
  81   2.4196      9.160  8.6741     9.730  573.41
  82   2.4178      9.290  8.6744     9.902  580.45
  83   2.4181      9.200  8.6739     9.766  587.73
  84   2.4161      9.240  8.6740     9.850  594.75
  85   2.4169      9.210  8.6740     9.846  601.71
