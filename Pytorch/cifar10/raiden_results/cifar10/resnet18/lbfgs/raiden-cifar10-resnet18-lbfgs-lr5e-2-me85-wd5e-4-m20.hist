Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5369622528 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3419     10.820  8.5853    10.456  9.76
   2   2.3421     10.790  8.5837    10.384  18.20
   3   2.3419     10.820  8.5843    10.326  26.68
   4   2.3427     10.770  8.5841    10.498  35.07
   5   2.3419     10.770  8.5859    10.200  43.34
   6   2.3416     10.890  8.5835    10.392  51.56
   7   2.3420     10.820  8.5853    10.310  59.98
   8   2.3422     10.810  8.5843    10.276  68.26
   9   2.3417     10.870  8.5844    10.360  76.53
  10   2.3415     10.860  8.5843    10.338  84.84
  11   2.3419     10.790  8.5845    10.442  93.27
  12   2.3420     10.890  8.5843    10.446  101.47
  13   2.3420     10.780  8.5843    10.146  109.80
  14   2.3424     10.730  8.5840    10.286  118.23
  15   2.3419     10.760  8.5843    10.486  126.69
  16   2.3412     10.790  8.5843    10.354  135.03
  17   2.3416     10.810  8.5857    10.286  143.24
  18   2.3420     10.690  8.5850    10.356  151.67
  19   2.3420     10.820  8.5849    10.504  159.87
  20   2.3426     10.820  8.5835    10.420  168.37
  21   2.3421     10.950  8.5855    10.304  176.72
  22   2.3420     10.750  8.5842    10.228  185.02
  23   2.3416     10.840  8.5839    10.516  193.22
  24   2.3418     10.760  8.5845    10.348  201.66
  25   2.3422     10.850  8.5838    10.282  210.06
  26   2.3418     10.880  8.5845    10.376  218.45
  27   2.3419     10.820  8.5838    10.264  226.86
  28   2.3423     10.720  8.5837    10.290  235.26
  29   2.3415     10.840  8.5850    10.406  243.70
  30   2.3421     10.850  8.5839    10.390  251.90
  31   2.3423     10.840  8.5843    10.370  260.16
  32   2.3421     10.740  8.5841    10.326  268.40
  33   2.3421     10.790  8.5851    10.302  276.81
  34   2.3430     10.710  8.5837    10.434  285.26
  35   2.3418     10.870  8.5836    10.586  293.51
  36   2.3422     10.820  8.5849    10.258  301.79
  37   2.3417     10.810  8.5849    10.158  310.14
  38   2.3419     10.820  8.5854    10.290  318.53
  39   2.3423     10.840  8.5834    10.410  326.89
  40   2.3420     10.780  8.5854    10.194  335.24
  41   2.3418     10.800  8.5839    10.330  343.51
  42   2.3421     10.820  8.5841    10.310  352.00
  43   2.3416     10.790  8.5842    10.394  360.61
  44   2.3411     10.750  8.5855    10.214  368.91
  45   2.3423     10.710  8.5850    10.378  377.31
  46   2.3413     10.760  8.5845    10.414  385.77
  47   2.3422     10.880  8.5853    10.294  394.06
  48   2.3413     10.830  8.5842    10.450  402.35
  49   2.3422     10.850  8.5845    10.180  410.66
  50   2.3421     10.750  8.5840    10.328  419.19
  51   2.3422     10.820  8.5844    10.358  427.61
  52   2.3416     10.800  8.5850    10.268  435.92
  53   2.3418     10.780  8.5851    10.220  444.28
  54   2.3422     10.890  8.5845    10.428  452.66
  55   2.3418     10.810  8.5840    10.192  461.16
  56   2.3422     10.800  8.5849    10.470  469.47
  57   2.3424     10.780  8.5844    10.244  477.86
  58   2.3419     10.890  8.5839    10.388  486.18
  59   2.3422     10.750  8.5845    10.428  494.61
  60   2.3416     10.780  8.5847    10.278  502.88
  61   2.3416     10.860  8.5841    10.468  511.13
  62   2.3414     10.840  8.5852    10.394  519.45
  63   2.3423     10.830  8.5845    10.390  527.96
  64   2.3419     10.760  8.5854    10.324  536.23
  65   2.3418     10.780  8.5837    10.420  544.82
  66   2.3416     10.800  8.5844    10.432  553.12
  67   2.3421     10.820  8.5851    10.142  561.62
  68   2.3422     10.800  8.5851    10.392  569.86
  69   2.3418     10.820  8.5845    10.378  578.24
  70   2.3421     10.810  8.5829    10.284  586.46
  71   2.3417     10.900  8.5847    10.246  594.86
  72   2.3421     10.780  8.5854    10.368  603.18
  73   2.3421     10.770  8.5839    10.536  611.56
  74   2.3419     10.860  8.5849    10.102  619.88
  75   2.3421     10.800  8.5847    10.448  628.18
  76   2.3421     10.740  8.5844    10.368  636.59
  77   2.3420     10.800  8.5840    10.236  644.88
  78   2.3420     10.700  8.5842    10.494  653.20
  79   2.3417     10.830  8.5842    10.450  661.51
  80   2.3418     10.870  8.5843    10.368  669.92
  81   2.3420     10.870  8.5850    10.336  678.22
  82   2.3421     10.790  8.5845    10.390  686.60
  83   2.3424     10.870  8.5846    10.236  694.89
  84   2.3422     10.780  8.5848    10.090  703.22
  85   2.3421     10.810  8.5841    10.324  711.59
