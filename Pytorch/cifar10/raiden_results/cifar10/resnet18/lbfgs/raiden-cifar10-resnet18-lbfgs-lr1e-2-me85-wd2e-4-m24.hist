Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4391022592 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3828     10.760  4.8924    10.484  9.17
   2   2.3838     10.780  4.8923    10.424  16.68
   3   2.3842     10.770  4.8943    10.354  24.42
   4   2.3853     10.770  4.8937    10.428  32.06
   5   2.3822     10.770  4.8919    10.422  39.67
   6   2.3864     10.760  4.8927    10.340  47.37
   7   2.3842     10.770  4.8921    10.462  55.08
   8   2.3862     10.690  4.8930    10.362  62.70
   9   2.3864     10.760  4.8919    10.432  70.29
  10   2.3862     10.770  4.8924    10.342  77.82
  11   2.3845     10.750  4.8924    10.452  85.59
  12   2.3850     10.710  4.8930    10.504  93.13
  13   2.3847     10.820  4.8938    10.506  100.76
  14   2.3861     10.750  4.8934    10.376  108.30
  15   2.3859     10.700  4.8929    10.362  116.00
  16   2.3868     10.720  4.8925    10.496  123.89
  17   2.3830     10.800  4.8926    10.516  131.54
  18   2.3841     10.720  4.8932    10.380  139.08
  19   2.3833     10.730  4.8920    10.522  146.58
  20   2.3846     10.770  4.8935    10.396  154.10
  21   2.3824     10.810  4.8928    10.330  161.92
  22   2.3856     10.780  4.8931    10.440  169.54
  23   2.3833     10.740  4.8931    10.382  177.22
  24   2.3851     10.760  4.8919    10.430  184.80
  25   2.3835     10.770  4.8938    10.346  192.53
  26   2.3852     10.770  4.8938    10.250  200.14
  27   2.3849     10.760  4.8917    10.322  207.76
  28   2.3848     10.680  4.8923    10.462  215.24
  29   2.3854     10.740  4.8919    10.400  222.96
  30   2.3844     10.760  4.8932    10.430  230.62
  31   2.3872     10.770  4.8918    10.420  238.31
  32   2.3853     10.780  4.8935    10.318  245.92
  33   2.3850     10.710  4.8925    10.418  253.54
  34   2.3850     10.760  4.8935    10.406  261.29
  35   2.3841     10.730  4.8924    10.494  268.95
  36   2.3868     10.850  4.8930    10.392  276.59
  37   2.3839     10.820  4.8921    10.292  284.21
  38   2.3876     10.670  4.8933    10.466  291.85
  39   2.3861     10.700  4.8923    10.366  299.47
  40   2.3839     10.770  4.8923    10.482  306.97
  41   2.3840     10.730  4.8926    10.358  314.52
  42   2.3845     10.770  4.8928    10.400  321.99
  43   2.3851     10.750  4.8934    10.452  330.01
  44   2.3849     10.730  4.8936    10.526  337.61
  45   2.3854     10.800  4.8927    10.356  345.13
  46   2.3836     10.740  4.8931    10.428  352.75
  47   2.3847     10.740  4.8931    10.422  360.49
  48   2.3842     10.770  4.8935    10.314  368.11
  49   2.3845     10.700  4.8931    10.482  375.58
  50   2.3869     10.770  4.8919    10.210  383.25
  51   2.3866     10.750  4.8921    10.414  390.92
  52   2.3858     10.750  4.8927    10.498  398.58
  53   2.3859     10.750  4.8926    10.500  406.17
  54   2.3841     10.750  4.8925    10.510  413.71
  55   2.3860     10.780  4.8932    10.446  421.37
  56   2.3865     10.740  4.8926    10.398  428.99
  57   2.3844     10.830  4.8927    10.410  436.71
  58   2.3849     10.730  4.8928    10.318  444.21
  59   2.3841     10.750  4.8927    10.360  452.00
  60   2.3844     10.830  4.8939    10.356  459.66
  61   2.3849     10.750  4.8937    10.372  467.31
  62   2.3836     10.770  4.8925    10.494  474.89
  63   2.3856     10.780  4.8922    10.432  482.61
  64   2.3843     10.710  4.8913    10.514  490.15
  65   2.3857     10.690  4.8935    10.358  497.63
  66   2.3850     10.740  4.8938    10.262  505.27
  67   2.3860     10.770  4.8934    10.346  513.00
  68   2.3834     10.780  4.8930    10.344  520.69
  69   2.3834     10.830  4.8931    10.498  528.18
  70   2.3857     10.730  4.8933    10.312  535.78
  71   2.3836     10.830  4.8936    10.478  543.41
  72   2.3850     10.730  4.8924    10.380  551.05
  73   2.3860     10.740  4.8926    10.498  558.58
  74   2.3858     10.790  4.8919    10.482  566.05
  75   2.3840     10.700  4.8926    10.334  573.91
  76   2.3847     10.720  4.8930    10.450  581.70
  77   2.3853     10.810  4.8934    10.402  589.33
  78   2.3825     10.800  4.8934    10.436  596.90
  79   2.3844     10.700  4.8925    10.392  604.41
  80   2.3858     10.740  4.8942    10.354  612.22
  81   2.3849     10.770  4.8932    10.418  619.71
  82   2.3850     10.730  4.8916    10.582  627.25
  83   2.3853     10.750  4.8930    10.436  634.88
  84   2.3842     10.810  4.8926    10.446  642.43
  85   2.3842     10.750  4.8929    10.442  650.19
