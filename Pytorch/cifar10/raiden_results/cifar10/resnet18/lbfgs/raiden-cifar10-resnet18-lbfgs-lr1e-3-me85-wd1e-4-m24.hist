Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4845      9.810  3.7652     9.802  8.62
   2   2.4846      9.870  3.7658     9.664  15.77
   3   2.4863      9.850  3.7653     9.684  22.91
   4   2.4868      9.870  3.7646     9.786  30.23
   5   2.4869      9.810  3.7662     9.756  37.40
   6   2.4871      9.850  3.7657     9.700  44.54
   7   2.4848      9.840  3.7663     9.782  51.78
   8   2.4865      9.830  3.7647     9.736  58.88
   9   2.4868      9.850  3.7657     9.802  66.08
  10   2.4860      9.850  3.7660     9.800  73.31
  11   2.4853      9.850  3.7663     9.724  80.50
  12   2.4866      9.870  3.7661     9.738  87.59
  13   2.4857      9.860  3.7660     9.610  94.88
  14   2.4878      9.870  3.7667     9.696  102.09
  15   2.4861      9.800  3.7648     9.832  109.16
  16   2.4865      9.930  3.7650     9.712  116.27
  17   2.4853      9.820  3.7660     9.688  123.44
  18   2.4868      9.870  3.7651     9.776  130.49
  19   2.4857      9.880  3.7643     9.740  137.88
  20   2.4868      9.890  3.7656     9.860  144.89
  21   2.4867      9.840  3.7655     9.746  152.18
  22   2.4851      9.930  3.7663     9.630  159.33
  23   2.4851      9.850  3.7665     9.796  166.56
  24   2.4865      9.880  3.7639     9.740  173.75
  25   2.4862      9.900  3.7659     9.662  180.90
  26   2.4863      9.890  3.7658     9.806  188.00
  27   2.4862      9.880  3.7663     9.706  195.24
  28   2.4862      9.840  3.7656     9.740  202.47
  29   2.4850      9.880  3.7645     9.682  209.69
  30   2.4866      9.810  3.7667     9.682  216.96
  31   2.4869      9.900  3.7657     9.784  224.13
  32   2.4853      9.910  3.7656     9.678  231.15
  33   2.4865      9.850  3.7660     9.670  238.29
  34   2.4855      9.870  3.7664     9.746  245.50
  35   2.4857      9.900  3.7635     9.734  252.63
  36   2.4856      9.850  3.7648     9.640  259.83
  37   2.4860      9.850  3.7648     9.776  267.08
  38   2.4872      9.850  3.7657     9.766  274.10
  39   2.4862      9.910  3.7652     9.610  281.26
  40   2.4850      9.810  3.7660     9.802  288.46
  41   2.4858      9.860  3.7649     9.850  295.59
  42   2.4859      9.910  3.7667     9.750  302.63
  43   2.4856      9.880  3.7666     9.728  310.02
  44   2.4870      9.890  3.7652     9.820  317.27
  45   2.4859      9.810  3.7667     9.730  324.45
  46   2.4869      9.840  3.7649     9.678  331.53
  47   2.4856      9.910  3.7642     9.788  338.95
  48   2.4857      9.880  3.7649     9.792  346.22
  49   2.4868      9.840  3.7640     9.772  353.60
  50   2.4859      9.850  3.7655     9.758  360.85
  51   2.4855      9.900  3.7660     9.764  367.86
  52   2.4870      9.880  3.7655     9.782  375.07
  53   2.4859      9.840  3.7653     9.766  382.29
  54   2.4868      9.830  3.7654     9.722  389.29
  55   2.4863      9.890  3.7654     9.784  396.55
  56   2.4866      9.860  3.7666     9.746  404.04
  57   2.4871      9.930  3.7645     9.612  411.20
  58   2.4872      9.910  3.7663     9.714  418.52
  59   2.4866      9.910  3.7647     9.734  425.64
  60   2.4859      9.900  3.7658     9.770  432.71
  61   2.4869      9.930  3.7654     9.782  439.81
  62   2.4848      9.840  3.7646     9.780  447.03
  63   2.4869      9.900  3.7659     9.684  454.39
  64   2.4846      9.810  3.7655     9.718  461.53
  65   2.4844      9.930  3.7650     9.760  468.69
  66   2.4835      9.870  3.7644     9.742  475.82
  67   2.4868      9.870  3.7657     9.702  482.84
  68   2.4863      9.820  3.7646     9.704  490.09
  69   2.4877      9.950  3.7656     9.740  497.30
  70   2.4878      9.880  3.7659     9.716  504.54
  71   2.4866      9.840  3.7662     9.778  511.71
  72   2.4874      9.900  3.7658     9.642  518.95
  73   2.4866      9.890  3.7663     9.680  526.21
  74   2.4865      9.870  3.7657     9.732  533.33
  75   2.4856      9.860  3.7649     9.742  540.54
  76   2.4865      9.840  3.7643     9.760  547.64
  77   2.4854      9.880  3.7656     9.806  555.10
  78   2.4859      9.880  3.7647     9.834  562.29
  79   2.4850      9.840  3.7660     9.724  569.41
  80   2.4866      9.830  3.7652     9.758  576.60
  81   2.4853      9.880  3.7641     9.752  583.72
  82   2.4880      9.920  3.7663     9.748  591.02
  83   2.4860      9.850  3.7657     9.670  598.22
  84   2.4851      9.840  3.7654     9.726  605.33
  85   2.4860      9.830  3.7658     9.832  612.60
