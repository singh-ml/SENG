Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4388140032 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4311     10.020  3.7125    10.056  9.20
   2   2.4329     10.040  3.7119    10.116  17.00
   3   2.4336     10.050  3.7108    10.066  24.77
   4   2.4321     10.050  3.7112    10.076  32.55
   5   2.4348     10.060  3.7124    10.082  40.35
   6   2.4341     10.040  3.7119    10.106  48.27
   7   2.4315     10.020  3.7116    10.096  55.94
   8   2.4327     10.050  3.7122    10.072  63.69
   9   2.4317     10.080  3.7106    10.118  71.40
  10   2.4312     10.070  3.7101    10.076  79.04
  11   2.4305     10.040  3.7132    10.100  86.94
  12   2.4313     10.050  3.7111    10.142  94.80
  13   2.4328     10.060  3.7119    10.076  102.80
  14   2.4331     10.060  3.7123    10.082  110.56
  15   2.4337     10.060  3.7126    10.148  118.31
  16   2.4328     10.050  3.7114    10.100  126.01
  17   2.4311     10.050  3.7125    10.060  133.96
  18   2.4326     10.060  3.7117    10.064  141.66
  19   2.4325     10.050  3.7117    10.058  149.40
  20   2.4324     10.040  3.7119    10.052  157.13
  21   2.4316     10.060  3.7118    10.102  164.92
  22   2.4326     10.040  3.7118    10.076  172.55
  23   2.4320     10.060  3.7133    10.060  180.33
  24   2.4311     10.030  3.7109    10.086  188.05
  25   2.4311     10.050  3.7126    10.074  195.72
  26   2.4308     10.040  3.7121    10.088  203.44
  27   2.4319     10.050  3.7119    10.094  211.18
  28   2.4340     10.040  3.7124    10.066  218.94
  29   2.4327     10.060  3.7115    10.044  226.82
  30   2.4329     10.040  3.7107    10.074  234.68
  31   2.4353     10.060  3.7102    10.108  242.46
  32   2.4347     10.080  3.7123    10.052  250.16
  33   2.4311     10.060  3.7115    10.040  257.93
  34   2.4319     10.060  3.7131    10.072  265.82
  35   2.4333     10.040  3.7125    10.098  273.47
  36   2.4313     10.030  3.7123    10.068  281.24
  37   2.4341     10.050  3.7127    10.108  288.98
  38   2.4331     10.060  3.7113    10.074  296.83
  39   2.4302     10.050  3.7125    10.068  304.72
  40   2.4328     10.060  3.7107    10.044  312.46
  41   2.4328     10.070  3.7107    10.074  320.20
  42   2.4324     10.020  3.7128    10.026  327.99
  43   2.4329     10.050  3.7112    10.088  335.83
  44   2.4335     10.050  3.7124    10.068  343.64
  45   2.4336     10.080  3.7125    10.126  351.45
  46   2.4320     10.020  3.7111    10.068  359.30
  47   2.4320     10.040  3.7119    10.060  367.24
  48   2.4328     10.050  3.7131    10.070  375.03
  49   2.4334     10.050  3.7124    10.046  382.72
  50   2.4323     10.070  3.7116    10.114  390.63
  51   2.4312     10.040  3.7115    10.084  398.51
  52   2.4303     10.040  3.7118    10.064  406.28
  53   2.4338     10.050  3.7119    10.016  413.98
  54   2.4322     10.060  3.7118    10.084  421.80
  55   2.4310     10.050  3.7113    10.042  429.78
  56   2.4320     10.060  3.7125    10.076  437.75
  57   2.4311     10.030  3.7128    10.104  445.45
  58   2.4315     10.040  3.7127    10.088  453.09
  59   2.4295     10.040  3.7125    10.050  460.90
  60   2.4321     10.050  3.7114    10.058  468.65
  61   2.4312     10.040  3.7119    10.108  476.50
  62   2.4336     10.040  3.7121    10.068  484.29
  63   2.4298     10.040  3.7107    10.076  492.01
  64   2.4349     10.040  3.7117    10.100  499.77
  65   2.4330     10.030  3.7123    10.030  507.53
  66   2.4322     10.040  3.7121    10.074  515.36
  67   2.4328     10.040  3.7120    10.084  523.10
  68   2.4307     10.050  3.7119    10.062  531.01
  69   2.4341     10.060  3.7128    10.076  538.81
  70   2.4309     10.040  3.7116    10.056  546.45
  71   2.4343     10.070  3.7112    10.120  554.28
  72   2.4316     10.050  3.7124    10.060  561.91
  73   2.4328     10.060  3.7127    10.034  569.74
  74   2.4327     10.080  3.7118    10.082  577.46
  75   2.4335     10.060  3.7123    10.062  585.29
  76   2.4339     10.060  3.7129    10.094  593.09
  77   2.4329     10.050  3.7111    10.144  600.81
  78   2.4320     10.050  3.7123    10.120  608.58
  79   2.4334     10.030  3.7124    10.078  616.50
  80   2.4328     10.040  3.7110    10.084  624.23
  81   2.4346     10.060  3.7123    10.084  632.02
  82   2.4323     10.040  3.7122    10.058  639.77
  83   2.4304     10.030  3.7117    10.076  647.46
  84   2.4336     10.030  3.7136    10.064  655.58
  85   2.4292     10.020  3.7118    10.104  663.55
