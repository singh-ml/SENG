Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4123     10.970  4.9350    11.526  9.10
   2   2.4122     10.960  4.9339    11.432  16.65
   3   2.4128     11.020  4.9350    11.210  24.36
   4   2.4130     10.840  4.9340    11.088  31.99
   5   2.4135     11.070  4.9338    11.244  39.50
   6   2.4119     11.040  4.9342    11.282  47.07
   7   2.4123     11.020  4.9339    11.134  54.69
   8   2.4160     11.090  4.9343    11.142  62.24
   9   2.4132     10.950  4.9341    11.260  69.86
  10   2.4145     10.930  4.9350    11.168  77.48
  11   2.4143     10.880  4.9340    11.082  85.03
  12   2.4129     10.990  4.9356    11.044  92.60
  13   2.4120     11.020  4.9340    11.476  100.21
  14   2.4139     10.880  4.9341    11.370  107.86
  15   2.4119     10.970  4.9343    11.262  115.52
  16   2.4143     10.920  4.9353    11.136  123.09
  17   2.4110     11.010  4.9346    11.280  130.78
  18   2.4129     10.860  4.9342    11.288  138.42
  19   2.4146     10.980  4.9339    11.338  146.02
  20   2.4136     10.980  4.9352    11.126  153.56
  21   2.4111     10.910  4.9339    11.354  161.11
  22   2.4135     10.850  4.9344    11.274  168.82
  23   2.4129     10.960  4.9325    11.542  176.44
  24   2.4120     10.980  4.9330    11.530  184.10
  25   2.4123     11.030  4.9355    11.290  191.58
  26   2.4126     10.970  4.9340    11.424  199.12
  27   2.4119     10.980  4.9337    11.416  206.81
  28   2.4141     10.950  4.9334    11.268  214.41
  29   2.4119     10.950  4.9343    11.206  221.93
  30   2.4105     10.990  4.9347    11.172  229.49
  31   2.4119     10.990  4.9347    11.442  237.08
  32   2.4118     11.020  4.9342    11.118  244.66
  33   2.4143     11.030  4.9335    11.314  252.20
  34   2.4111     11.080  4.9338    11.280  259.75
  35   2.4121     11.020  4.9338    11.476  267.26
  36   2.4139     11.010  4.9337    11.296  274.85
  37   2.4135     11.030  4.9340    11.386  282.66
  38   2.4151     10.850  4.9340    11.294  290.25
  39   2.4141     11.040  4.9356    11.174  297.69
  40   2.4137     10.820  4.9346    11.340  305.35
  41   2.4139     11.020  4.9337    11.132  312.99
  42   2.4134     10.950  4.9346    11.292  320.56
  43   2.4133     11.010  4.9341    11.284  328.17
  44   2.4137     10.910  4.9340    11.216  335.72
  45   2.4142     10.910  4.9345    11.334  343.35
  46   2.4131     10.980  4.9338    11.266  350.89
  47   2.4105     11.020  4.9328    11.318  358.46
  48   2.4124     11.000  4.9337    11.214  366.06
  49   2.4133     10.920  4.9354    11.228  373.61
  50   2.4124     11.010  4.9349    11.232  381.40
  51   2.4119     10.900  4.9351    11.208  388.96
  52   2.4112     10.990  4.9344    11.288  396.46
  53   2.4119     10.980  4.9341    11.240  404.06
  54   2.4114     11.040  4.9352    11.074  411.69
  55   2.4112     11.020  4.9331    11.378  419.43
  56   2.4131     10.910  4.9346    11.230  427.09
  57   2.4131     10.970  4.9350    11.338  434.69
  58   2.4140     10.970  4.9344    11.366  442.12
  59   2.4127     11.000  4.9351    11.326  449.72
  60   2.4113     11.010  4.9357    11.336  457.38
  61   2.4147     11.030  4.9345    11.168  465.05
  62   2.4133     10.900  4.9342    11.232  472.53
  63   2.4109     10.940  4.9339    11.342  480.09
  64   2.4137     11.050  4.9344    11.296  487.72
  65   2.4146     11.000  4.9337    11.260  495.46
  66   2.4116     10.980  4.9355    11.256  502.99
  67   2.4136     10.940  4.9344    11.184  510.55
  68   2.4135     10.960  4.9341    11.214  518.06
  69   2.4140     10.940  4.9342    11.372  525.78
  70   2.4134     11.000  4.9345    11.238  533.36
  71   2.4133     10.830  4.9327    11.366  541.00
  72   2.4124     10.940  4.9347    11.158  548.51
  73   2.4132     11.000  4.9345    11.226  555.94
  74   2.4120     11.040  4.9344    11.092  563.61
  75   2.4118     11.050  4.9340    11.238  571.13
  76   2.4137     10.940  4.9326    11.332  578.70
  77   2.4141     11.060  4.9338    11.484  586.19
  78   2.4128     11.040  4.9340    11.230  593.79
  79   2.4116     11.000  4.9349    11.464  601.38
  80   2.4127     11.000  4.9339    11.426  608.92
  81   2.4121     11.010  4.9342    11.274  616.48
  82   2.4134     11.030  4.9344    11.306  624.09
  83   2.4140     10.940  4.9350    11.174  631.72
  84   2.4131     10.990  4.9344    11.450  639.29
  85   2.4123     11.030  4.9350    11.244  646.82
