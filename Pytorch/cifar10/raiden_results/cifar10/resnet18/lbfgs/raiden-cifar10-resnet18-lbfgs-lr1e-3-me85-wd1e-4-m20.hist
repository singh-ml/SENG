Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3795     10.320  3.6498     9.710  8.67
   2   2.3793     10.320  3.6499     9.810  15.73
   3   2.3795     10.240  3.6482     9.730  23.09
   4   2.3792     10.240  3.6493     9.652  30.14
   5   2.3781     10.300  3.6483     9.730  37.19
   6   2.3800     10.320  3.6485     9.836  44.16
   7   2.3791     10.290  3.6496     9.742  51.21
   8   2.3796     10.300  3.6491     9.682  58.55
   9   2.3777     10.290  3.6501     9.722  65.74
  10   2.3783     10.380  3.6494     9.782  72.85
  11   2.3795     10.340  3.6488     9.772  79.93
  12   2.3804     10.370  3.6490     9.886  87.17
  13   2.3798     10.320  3.6496     9.776  94.31
  14   2.3812     10.310  3.6490     9.904  101.49
  15   2.3796     10.390  3.6488     9.634  108.58
  16   2.3791     10.310  3.6483     9.632  115.73
  17   2.3791     10.300  3.6484     9.750  122.93
  18   2.3793     10.270  3.6499     9.724  130.07
  19   2.3782     10.360  3.6489     9.568  137.12
  20   2.3786     10.310  3.6489     9.684  144.14
  21   2.3790     10.320  3.6493     9.718  151.12
  22   2.3803     10.360  3.6488     9.774  158.09
  23   2.3800     10.330  3.6489     9.812  165.27
  24   2.3790     10.300  3.6478     9.686  172.42
  25   2.3774     10.230  3.6488     9.788  179.58
  26   2.3799     10.340  3.6484     9.620  186.52
  27   2.3788     10.310  3.6481     9.592  193.60
  28   2.3788     10.420  3.6482     9.926  200.88
  29   2.3798     10.260  3.6496     9.694  207.93
  30   2.3797     10.310  3.6483     9.726  214.99
  31   2.3815     10.270  3.6494     9.718  221.97
  32   2.3808     10.320  3.6491     9.690  229.09
  33   2.3793     10.310  3.6504     9.624  236.32
  34   2.3789     10.320  3.6487     9.834  243.34
  35   2.3793     10.260  3.6492     9.610  250.39
  36   2.3791     10.360  3.6487     9.782  257.36
  37   2.3788     10.390  3.6488     9.602  264.54
  38   2.3777     10.370  3.6468     9.900  271.64
  39   2.3783     10.240  3.6483     9.738  278.72
  40   2.3789     10.320  3.6503     9.656  285.89
  41   2.3796     10.250  3.6490     9.696  293.05
  42   2.3783     10.300  3.6491     9.784  300.21
  43   2.3784     10.360  3.6501     9.762  307.39
  44   2.3792     10.200  3.6486     9.724  314.45
  45   2.3774     10.190  3.6480     9.810  321.58
  46   2.3791     10.280  3.6486     9.726  328.55
  47   2.3791     10.260  3.6490     9.708  335.71
  48   2.3791     10.270  3.6488     9.818  342.87
  49   2.3816     10.280  3.6484     9.640  349.91
  50   2.3801     10.330  3.6483     9.766  356.97
  51   2.3787     10.300  3.6483     9.492  364.16
  52   2.3806     10.290  3.6494     9.722  371.44
  53   2.3802     10.340  3.6501     9.600  378.56
  54   2.3792     10.290  3.6494     9.708  385.64
  55   2.3801     10.300  3.6495     9.862  392.73
  56   2.3793     10.290  3.6488     9.742  399.84
  57   2.3791     10.330  3.6487     9.828  407.10
  58   2.3800     10.330  3.6493     9.594  414.13
  59   2.3783     10.220  3.6491     9.618  421.14
  60   2.3792     10.310  3.6504     9.698  428.15
  61   2.3793     10.290  3.6489     9.698  435.11
  62   2.3781     10.290  3.6486     9.842  442.32
  63   2.3768     10.200  3.6483     9.870  449.30
  64   2.3798     10.340  3.6490     9.664  456.37
  65   2.3793     10.360  3.6494     9.628  463.51
  66   2.3806     10.340  3.6492     9.732  470.64
  67   2.3789     10.380  3.6493     9.636  477.87
  68   2.3785     10.320  3.6492     9.650  484.95
  69   2.3781     10.300  3.6495     9.652  491.91
  70   2.3778     10.250  3.6491     9.682  498.98
  71   2.3790     10.250  3.6491     9.824  506.05
  72   2.3775     10.320  3.6486     9.768  513.32
  73   2.3782     10.270  3.6478     9.786  520.40
  74   2.3803     10.290  3.6495     9.810  527.46
  75   2.3794     10.300  3.6485     9.770  534.52
  76   2.3794     10.290  3.6489     9.804  541.59
  77   2.3803     10.290  3.6494     9.718  548.78
  78   2.3788     10.340  3.6484     9.718  555.95
  79   2.3795     10.370  3.6492     9.878  563.02
  80   2.3787     10.270  3.6493     9.546  570.01
  81   2.3794     10.300  3.6485     9.884  577.21
  82   2.3794     10.320  3.6483     9.854  584.46
  83   2.3790     10.290  3.6484     9.696  591.53
  84   2.3806     10.320  3.6485     9.772  598.61
  85   2.3770     10.250  3.6489     9.696  605.76
