Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4478448128 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4220     11.690  3.7123    11.224  9.05
   2   2.4199     11.660  3.7126    11.020  16.62
   3   2.4209     11.660  3.7127    10.916  24.48
   4   2.4192     11.710  3.7131    11.154  32.15
   5   2.4209     11.710  3.7133    11.094  39.89
   6   2.4178     11.670  3.7151    10.772  47.55
   7   2.4216     11.790  3.7121    11.394  55.25
   8   2.4189     11.700  3.7139    11.148  62.89
   9   2.4208     11.720  3.7137    11.002  70.63
  10   2.4204     11.760  3.7123    11.210  78.14
  11   2.4182     11.650  3.7128    11.016  85.69
  12   2.4212     11.740  3.7131    10.996  93.18
  13   2.4203     11.740  3.7139    10.904  100.79
  14   2.4181     11.650  3.7141    11.010  108.40
  15   2.4179     11.670  3.7129    11.032  115.99
  16   2.4206     11.730  3.7137    11.054  123.52
  17   2.4197     11.710  3.7136    11.136  131.07
  18   2.4213     11.770  3.7128    11.080  138.54
  19   2.4210     11.680  3.7131    10.958  146.42
  20   2.4192     11.680  3.7135    11.078  154.03
  21   2.4211     11.830  3.7130    10.984  161.72
  22   2.4197     11.790  3.7128    11.048  169.40
  23   2.4187     11.760  3.7131    11.130  177.23
  24   2.4213     11.840  3.7133    10.908  184.68
  25   2.4199     11.630  3.7137    10.960  192.29
  26   2.4203     11.740  3.7139    10.754  199.96
  27   2.4239     11.740  3.7128    11.238  207.59
  28   2.4221     11.830  3.7129    10.988  215.29
  29   2.4231     11.670  3.7131    10.964  222.94
  30   2.4209     11.640  3.7138    11.160  230.60
  31   2.4214     11.710  3.7139    11.068  238.33
  32   2.4189     11.680  3.7136    11.022  245.95
  33   2.4209     11.740  3.7133    11.050  253.54
  34   2.4185     11.690  3.7133    11.100  261.40
  35   2.4209     11.620  3.7130    11.114  268.95
  36   2.4210     11.720  3.7132    11.028  276.74
  37   2.4196     11.650  3.7131    11.194  284.29
  38   2.4213     11.800  3.7130    10.944  291.85
  39   2.4191     11.680  3.7128    10.906  299.34
  40   2.4223     11.740  3.7142    10.898  306.96
  41   2.4176     11.690  3.7128    11.070  314.69
  42   2.4211     11.830  3.7133    10.952  322.38
  43   2.4181     11.680  3.7144    11.090  330.04
  44   2.4225     11.620  3.7142    10.996  337.74
  45   2.4223     11.760  3.7125    11.174  345.41
  46   2.4233     11.580  3.7128    11.048  353.30
  47   2.4192     11.780  3.7132    11.114  360.99
  48   2.4211     11.740  3.7128    11.072  368.59
  49   2.4207     11.600  3.7131    11.136  376.27
  50   2.4193     11.800  3.7125    11.018  384.00
  51   2.4220     11.880  3.7141    11.056  391.67
  52   2.4212     11.780  3.7128    11.030  399.38
  53   2.4236     11.740  3.7127    11.138  407.07
  54   2.4208     11.780  3.7120    11.074  414.72
  55   2.4212     11.780  3.7128    11.114  422.45
  56   2.4227     11.800  3.7135    11.118  430.00
  57   2.4197     11.750  3.7132    11.036  437.58
  58   2.4189     11.610  3.7130    11.068  445.10
  59   2.4217     11.740  3.7146    10.946  452.84
  60   2.4196     11.670  3.7126    10.970  460.40
  61   2.4197     11.790  3.7133    11.104  468.05
  62   2.4208     11.740  3.7131    11.008  475.74
  63   2.4198     11.670  3.7124    11.122  483.22
  64   2.4191     11.730  3.7128    11.094  490.97
  65   2.4215     11.700  3.7139    11.042  498.58
  66   2.4186     11.690  3.7137    11.160  506.19
  67   2.4221     11.740  3.7118    11.130  513.76
  68   2.4219     11.750  3.7130    11.196  521.31
  69   2.4225     11.710  3.7137    11.196  528.90
  70   2.4196     11.760  3.7143    11.084  536.55
  71   2.4206     11.690  3.7137    11.128  544.19
  72   2.4189     11.720  3.7145    11.086  552.04
  73   2.4200     11.720  3.7141    11.168  559.73
  74   2.4195     11.750  3.7139    11.104  567.36
  75   2.4208     11.750  3.7130    11.130  575.00
  76   2.4215     11.660  3.7117    11.084  582.58
  77   2.4188     11.600  3.7139    11.134  590.38
  78   2.4190     11.760  3.7131    11.056  598.08
  79   2.4204     11.720  3.7134    11.016  605.78
  80   2.4223     11.720  3.7133    10.888  613.37
  81   2.4215     11.660  3.7120    11.070  621.07
  82   2.4194     11.780  3.7134    11.070  628.66
  83   2.4197     11.760  3.7134    11.028  636.28
  84   2.4185     11.690  3.7132    11.004  644.13
  85   2.4202     11.760  3.7132    11.118  651.79
