Use GPU: 0 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4238856704 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3680      9.790  3.6208    10.028  8.78
   2   2.3686      9.940  3.6217     9.998  15.99
   3   2.3675      9.860  3.6204    10.072  23.18
   4   2.3684      9.950  3.6207    10.130  30.42
   5   2.3678      9.720  3.6214    10.022  37.68
   6   2.3671      9.890  3.6202    10.212  45.02
   7   2.3677      9.880  3.6215    10.078  52.26
   8   2.3679      9.950  3.6208    10.030  59.49
   9   2.3669      9.920  3.6196    10.278  66.72
  10   2.3678      9.860  3.6218    10.316  73.97
  11   2.3673      9.680  3.6200    10.174  81.10
  12   2.3676      9.810  3.6205    10.084  88.23
  13   2.3686     10.000  3.6205    10.146  95.60
  14   2.3674      9.730  3.6212    10.226  102.89
  15   2.3677      9.940  3.6210     9.958  110.04
  16   2.3683      9.910  3.6209    10.016  117.15
  17   2.3682      9.940  3.6205    10.108  124.20
  18   2.3675      9.750  3.6204    10.148  131.39
  19   2.3684      9.990  3.6212    10.108  138.62
  20   2.3679      9.900  3.6211    10.124  145.75
  21   2.3686      9.950  3.6206    10.152  152.99
  22   2.3692      9.840  3.6219    10.076  160.24
  23   2.3678      9.790  3.6203    10.156  167.42
  24   2.3681      9.850  3.6206    10.110  174.82
  25   2.3679      9.780  3.6208    10.012  182.13
  26   2.3686      9.960  3.6205    10.000  189.25
  27   2.3680      9.770  3.6219    10.062  196.55
  28   2.3674      9.770  3.6214    10.130  203.85
  29   2.3676      9.750  3.6213     9.924  211.34
  30   2.3687      9.830  3.6207    10.084  218.53
  31   2.3683      9.910  3.6198    10.172  225.80
  32   2.3673      9.730  3.6227     9.984  232.92
  33   2.3685      9.660  3.6202    10.150  240.19
  34   2.3678      9.820  3.6215    10.166  247.43
  35   2.3680      9.760  3.6215    10.130  254.72
  36   2.3675      9.870  3.6212    10.022  261.90
  37   2.3669      9.860  3.6203    10.334  269.07
  38   2.3678      9.820  3.6207    10.094  276.27
  39   2.3679      9.890  3.6216    10.150  283.61
  40   2.3678      9.880  3.6204    10.268  290.86
  41   2.3680      9.970  3.6207    10.018  298.09
  42   2.3676      9.900  3.6206    10.154  305.34
  43   2.3693      9.800  3.6208    10.060  312.55
  44   2.3686      9.870  3.6215     9.962  319.72
  45   2.3678      9.820  3.6214    10.010  327.03
  46   2.3668      9.700  3.6210    10.244  334.33
  47   2.3666      9.810  3.6209    10.068  341.60
  48   2.3686      9.850  3.6212    10.142  348.93
  49   2.3673      9.630  3.6212    10.174  356.22
  50   2.3679      9.690  3.6215    10.148  363.50
  51   2.3669      9.480  3.6210    10.034  370.75
  52   2.3686      9.840  3.6205    10.292  377.92
  53   2.3683      9.770  3.6202    10.248  385.25
  54   2.3684      9.560  3.6203    10.158  392.54
  55   2.3680      9.800  3.6220     9.918  399.82
  56   2.3682      9.760  3.6210    10.118  407.01
  57   2.3682      9.880  3.6213    10.108  414.29
  58   2.3685      9.840  3.6206    10.148  421.58
  59   2.3672      9.930  3.6203    10.070  428.89
  60   2.3680      9.870  3.6210     9.938  436.20
  61   2.3680      9.850  3.6211    10.104  443.41
  62   2.3678      9.890  3.6212     9.926  450.60
  63   2.3681      9.830  3.6212    10.178  457.80
  64   2.3677      9.980  3.6205     9.996  465.06
  65   2.3678      9.890  3.6215     9.990  472.17
  66   2.3675      9.920  3.6207    10.214  479.35
  67   2.3675      9.660  3.6219    10.200  486.64
  68   2.3675      9.730  3.6214    10.012  494.02
  69   2.3674      9.640  3.6212     9.892  501.25
  70   2.3677      9.760  3.6209    10.188  508.47
  71   2.3683      9.860  3.6209    10.342  515.66
  72   2.3683      9.910  3.6208    10.064  522.95
  73   2.3684      9.930  3.6200    10.224  530.28
  74   2.3689      9.880  3.6203    10.148  537.67
  75   2.3685      9.960  3.6209    10.138  544.85
  76   2.3673      9.830  3.6193    10.134  552.05
  77   2.3681      9.760  3.6208    10.176  559.14
  78   2.3680      9.800  3.6218    10.194  566.50
  79   2.3683      9.740  3.6210    10.224  573.79
  80   2.3680      9.870  3.6205    10.086  581.03
  81   2.3672      9.710  3.6216    10.142  588.26
  82   2.3695      9.980  3.6206    10.132  595.44
  83   2.3670      9.780  3.6214    10.108  602.67
  84   2.3682      9.850  3.6216    10.028  609.94
  85   2.3678      9.580  3.6205    10.198  617.17
