Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8514     31.240  2.0805    22.848  8.78
   2   1.6632     37.940  1.7820    34.186  15.87
   3   1.5576     41.530  1.6474    38.978  22.84
   4   1.4704     45.090  1.5454    42.778  29.82
   5   1.3902     48.420  1.4636    45.958  36.80
   6   1.3274     50.990  1.3878    49.018  43.81
   7   1.2687     53.630  1.3173    52.014  50.85
   8   1.2127     56.020  1.2593    54.428  57.85
   9   1.1689     57.330  1.2056    56.420  64.82
  10   1.1167     59.580  1.1524    58.316  71.82
  11   1.0812     61.010  1.1069    60.246  78.86
  12   1.0369     62.920  1.0617    61.824  85.82
  13   1.0000     64.010  1.0263    63.232  92.84
  14   0.9759     65.340  0.9901    64.618  99.80
  15   0.9501     66.360  0.9549    65.938  106.80
  16   0.9276     67.280  0.9263    67.100  113.81
  17   0.9027     68.170  0.8997    68.122  120.98
  18   0.8771     68.920  0.8752    68.666  127.97
  19   0.8520     69.830  0.8574    69.620  134.97
  20   0.8495     70.020  0.8355    70.276  142.01
  21   0.8364     70.280  0.8172    70.934  149.03
  22   0.8170     71.420  0.7953    71.640  156.07
  23   0.7988     72.250  0.7773    72.302  163.05
  24   0.7900     72.240  0.7613    72.888  170.06
  25   0.7680     73.170  0.7473    73.422  177.04
  26   0.7692     73.070  0.7331    73.872  184.03
  27   0.7578     73.810  0.7204    74.410  191.07
  28   0.7502     74.180  0.7050    74.934  198.08
  29   0.7272     74.770  0.6867    75.862  205.09
  30   0.7233     74.940  0.6726    76.126  212.10
  31   0.7129     75.170  0.6579    76.762  219.10
  32   0.7028     75.560  0.6492    77.054  226.18
  33   0.6955     76.040  0.6359    77.528  233.18
  34   0.6816     76.200  0.6239    78.140  240.17
  35   0.6752     76.900  0.6117    78.396  247.15
  36   0.6649     77.290  0.5982    78.932  254.15
  37   0.6458     77.880  0.5857    79.300  261.17
  38   0.6413     77.980  0.5771    79.650  268.16
  39   0.6460     78.030  0.5665    79.918  275.13
  40   0.6258     78.490  0.5582    80.328  282.13
  41   0.6194     79.090  0.5411    81.032  289.13
  42   0.6131     79.140  0.5343    81.102  296.17
  43   0.6057     79.470  0.5234    81.482  303.17
  44   0.5974     79.630  0.5137    81.878  310.15
  45   0.6008     79.940  0.5063    82.140  317.13
  46   0.5963     80.040  0.4996    82.402  324.17
  47   0.5961     79.940  0.4887    82.738  331.15
  48   0.5867     80.210  0.4840    82.896  338.12
  49   0.5770     80.420  0.4766    83.232  345.11
  50   0.5659     80.690  0.4644    83.634  352.02
  51   0.5744     80.660  0.4582    83.826  359.07
  52   0.5552     81.120  0.4510    84.236  366.05
  53   0.5518     81.700  0.4454    84.222  373.03
  54   0.5439     81.720  0.4392    84.602  380.02
  55   0.5446     81.990  0.4334    84.882  387.00
  56   0.5362     81.870  0.4203    85.248  394.05
  57   0.5394     82.130  0.4135    85.602  401.05
  58   0.5347     82.320  0.4100    85.568  408.06
  59   0.5304     82.730  0.3975    86.168  415.07
  60   0.5320     82.540  0.3997    85.996  422.07
  61   0.5261     82.600  0.3961    86.104  429.14
  62   0.5355     82.340  0.3875    86.388  436.15
  63   0.5302     82.690  0.3798    86.746  443.13
  64   0.5110     83.180  0.3765    86.928  450.14
  65   0.5256     82.650  0.3680    87.132  457.12
  66   0.5139     83.220  0.3627    87.354  464.17
  67   0.5072     83.110  0.3630    87.212  471.15
  68   0.5123     82.990  0.3538    87.668  478.17
  69   0.5112     82.670  0.3502    87.744  485.19
  70   0.5238     82.750  0.3427    87.948  492.17
  71   0.5100     83.280  0.3377    88.124  499.23
  72   0.5068     83.360  0.3378    88.214  506.24
  73   0.5130     83.520  0.3287    88.514  513.28
  74   0.5037     83.790  0.3218    88.766  520.27
  75   0.5013     83.850  0.3176    88.802  527.27
  76   0.4995     84.450  0.3161    88.966  534.33
  77   0.5074     83.910  0.3065    89.360  541.32
  78   0.4955     84.110  0.3065    89.322  548.34
  79   0.4989     84.110  0.3018    89.422  555.32
  80   0.4898     84.340  0.2965    89.626  562.29
  81   0.4971     84.000  0.2950    89.708  569.38
  82   0.5018     84.090  0.2886    89.772  576.39
  83   0.4879     84.390  0.2879    89.874  583.37
  84   0.4942     84.240  0.2794    90.174  590.37
  85   0.4927     84.510  0.2771    90.204  597.35
