Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4371     46.760  1.7685    34.308  8.71
   2   1.2029     56.440  1.3433    50.894  15.65
   3   1.0404     62.390  1.1429    58.888  22.69
   4   0.9084     67.460  0.9893    64.906  29.68
   5   0.8349     70.170  0.8758    68.992  36.63
   6   0.7590     73.240  0.7997    71.696  43.56
   7   0.7185     74.710  0.7304    74.246  50.47
   8   0.6568     77.000  0.6664    76.646  57.46
   9   0.6351     78.210  0.6220    78.158  64.41
  10   0.6056     78.910  0.5805    79.486  71.36
  11   0.5714     80.480  0.5374    81.376  78.30
  12   0.5449     81.510  0.5074    82.120  85.25
  13   0.5314     81.530  0.4786    83.284  92.24
  14   0.5076     82.650  0.4563    83.942  99.16
  15   0.5205     82.510  0.4351    84.944  106.12
  16   0.5002     82.890  0.4121    85.594  113.08
  17   0.4939     83.810  0.3890    86.508  120.02
  18   0.4594     84.530  0.3748    86.916  127.00
  19   0.4548     84.640  0.3540    87.656  133.95
  20   0.4605     84.890  0.3444    87.952  140.96
  21   0.4724     84.910  0.3289    88.422  147.90
  22   0.4589     85.040  0.3157    89.008  154.85
  23   0.4670     84.670  0.3049    89.412  161.85
  24   0.4460     85.630  0.2938    89.734  168.77
  25   0.4400     85.970  0.2776    90.428  175.70
  26   0.4539     85.510  0.2699    90.598  182.64
  27   0.4253     86.220  0.2569    91.068  189.60
  28   0.4238     86.520  0.2456    91.480  196.53
  29   0.4394     86.190  0.2322    91.872  203.54
  30   0.4288     86.740  0.2260    92.102  210.47
  31   0.4335     86.760  0.2136    92.516  217.42
  32   0.4460     86.440  0.2138    92.550  224.38
  33   0.4393     86.610  0.2019    92.870  231.36
  34   0.4125     87.190  0.1959    93.200  238.35
  35   0.4344     87.230  0.1858    93.466  245.30
  36   0.4231     86.850  0.1778    93.630  252.23
  37   0.4337     86.990  0.1743    93.894  259.17
  38   0.4184     87.510  0.1628    94.262  266.10
  39   0.4666     86.540  0.1544    94.586  273.10
  40   0.4451     87.460  0.1503    94.710  280.02
  41   0.4193     87.740  0.1417    95.056  286.99
  42   0.4385     87.780  0.1348    95.238  293.94
  43   0.4574     87.320  0.1299    95.388  300.88
  44   0.4537     87.640  0.1271    95.546  307.89
  45   0.4384     87.870  0.1181    95.814  314.83
  46   0.4420     87.850  0.1165    95.978  321.78
  47   0.4454     88.150  0.1095    96.232  328.70
  48   0.4585     87.830  0.1065    96.314  335.64
  49   0.4480     87.840  0.0995    96.608  342.63
  50   0.4628     88.370  0.0948    96.680  349.45
  51   0.4618     88.010  0.0887    96.926  356.41
  52   0.4514     88.370  0.0852    97.034  363.32
  53   0.4914     88.130  0.0824    97.190  370.29
  54   0.4759     88.320  0.0810    97.216  377.30
  55   0.4602     88.270  0.0762    97.366  384.22
  56   0.4593     88.630  0.0692    97.632  391.15
  57   0.4536     88.360  0.0649    97.780  398.12
  58   0.4674     88.460  0.0633    97.890  405.08
  59   0.4677     88.760  0.0622    97.922  412.03
  60   0.4542     88.750  0.0581    98.064  419.06
  61   0.4470     89.040  0.0542    98.172  426.01
  62   0.4553     89.220  0.0503    98.392  432.93
  63   0.4612     88.860  0.0492    98.392  439.86
  64   0.4644     88.850  0.0498    98.376  446.82
  65   0.4618     89.270  0.0465    98.518  453.80
  66   0.4703     89.260  0.0402    98.690  460.74
  67   0.4664     89.180  0.0402    98.742  467.69
  68   0.4723     88.870  0.0396    98.774  474.62
  69   0.4788     88.870  0.0359    98.906  481.57
  70   0.4675     89.310  0.0331    98.994  488.55
  71   0.4680     89.130  0.0320    99.030  495.48
  72   0.4702     89.220  0.0320    99.030  502.42
  73   0.4888     89.260  0.0286    99.146  509.35
  74   0.4812     89.380  0.0315    99.070  516.28
  75   0.4767     89.380  0.0282    99.160  523.25
  76   0.4972     89.130  0.0252    99.294  530.17
  77   0.4867     89.170  0.0247    99.274  537.11
  78   0.4911     89.240  0.0248    99.312  544.04
  79   0.4972     89.330  0.0232    99.398  551.01
  80   0.4783     89.570  0.0220    99.414  558.04
  81   0.4983     89.270  0.0222    99.406  565.00
  82   0.5006     89.330  0.0224    99.392  571.94
  83   0.4983     89.420  0.0204    99.472  578.90
  84   0.4920     89.710  0.0207    99.448  585.85
  85   0.4964     89.530  0.0202    99.448  592.86
  86   0.4990     89.570  0.0201    99.448  599.80
  87   0.4957     89.590  0.0178    99.530  606.77
  88   0.4972     89.370  0.0183    99.542  613.70
  89   0.5040     89.480  0.0189    99.474  620.66
  90   0.5025     89.490  0.0206    99.450  627.69
