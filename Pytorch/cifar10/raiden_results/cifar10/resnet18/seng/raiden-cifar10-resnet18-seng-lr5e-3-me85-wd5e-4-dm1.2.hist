Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5173     43.670  1.8069    32.866  8.74
   2   1.2411     54.870  1.3891    48.966  15.74
   3   1.1023     60.040  1.1837    57.406  22.65
   4   0.9523     66.090  1.0392    62.636  29.57
   5   0.8806     68.750  0.9295    66.872  36.60
   6   0.8154     71.120  0.8446    70.062  43.51
   7   0.7619     72.980  0.7757    72.514  50.46
   8   0.7334     74.300  0.7113    74.748  57.37
   9   0.6750     76.680  0.6660    76.338  64.33
  10   0.6655     77.320  0.6200    78.266  71.33
  11   0.6287     78.020  0.5939    78.984  78.29
  12   0.5870     79.880  0.5557    80.472  85.21
  13   0.5821     80.140  0.5216    81.776  92.17
  14   0.5675     80.540  0.4918    82.930  99.12
  15   0.5423     81.940  0.4710    83.540  106.07
  16   0.5302     81.940  0.4486    84.278  113.06
  17   0.5120     82.520  0.4265    85.118  119.99
  18   0.5033     82.840  0.4119    85.776  126.96
  19   0.4802     83.800  0.3934    86.376  133.90
  20   0.5120     83.170  0.3759    86.914  140.84
  21   0.4885     84.140  0.3591    87.414  147.86
  22   0.4889     83.810  0.3480    87.952  154.77
  23   0.4692     84.410  0.3297    88.336  161.75
  24   0.4594     84.950  0.3234    88.590  168.71
  25   0.4878     84.530  0.3047    89.478  175.64
  26   0.4530     85.390  0.2929    89.648  182.64
  27   0.4539     85.330  0.2856    90.030  189.56
  28   0.4505     85.460  0.2679    90.686  196.49
  29   0.4619     85.470  0.2587    90.920  203.41
  30   0.4504     85.570  0.2533    91.338  210.34
  31   0.4502     86.290  0.2411    91.644  217.37
  32   0.4566     85.940  0.2371    91.788  224.29
  33   0.4368     86.400  0.2255    92.162  231.25
  34   0.4475     86.540  0.2172    92.462  238.18
  35   0.4474     86.220  0.2091    92.712  245.14
  36   0.4589     86.270  0.1978    93.144  252.12
  37   0.4743     86.280  0.1896    93.386  259.05
  38   0.4463     87.070  0.1917    93.256  265.99
  39   0.4415     87.210  0.1773    93.772  272.91
  40   0.4572     87.010  0.1678    94.086  279.87
  41   0.4376     87.070  0.1636    94.278  286.93
  42   0.4421     87.140  0.1568    94.514  293.86
  43   0.4434     87.320  0.1500    94.772  300.89
  44   0.4760     86.590  0.1436    94.912  307.83
  45   0.4564     86.840  0.1407    95.064  314.77
  46   0.4795     86.790  0.1298    95.544  321.72
  47   0.4585     87.280  0.1254    95.772  328.76
  48   0.4598     87.250  0.1229    95.702  335.69
  49   0.4809     86.950  0.1130    95.974  342.62
  50   0.4748     87.160  0.1105    96.130  349.47
  51   0.4659     87.530  0.1021    96.378  356.40
  52   0.4709     87.370  0.0984    96.626  363.38
  53   0.4768     87.670  0.0916    96.948  370.29
  54   0.4658     87.540  0.0874    97.038  377.22
  55   0.4844     87.470  0.0912    96.834  384.16
  56   0.4752     87.750  0.0837    97.128  391.12
  57   0.4793     87.680  0.0818    97.188  398.17
  58   0.4785     87.940  0.0742    97.486  405.09
  59   0.4899     87.610  0.0707    97.646  412.05
  60   0.4909     87.740  0.0659    97.858  418.99
  61   0.4935     88.150  0.0665    97.820  425.95
  62   0.4926     88.050  0.0634    97.950  432.87
  63   0.4988     87.900  0.0653    97.798  439.77
  64   0.4976     88.070  0.0571    98.088  446.72
  65   0.5023     87.880  0.0557    98.184  453.68
  66   0.5035     88.160  0.0529    98.312  460.73
  67   0.4982     88.170  0.0525    98.254  467.69
  68   0.5114     87.650  0.0488    98.512  474.62
  69   0.5059     88.130  0.0463    98.554  481.55
  70   0.5156     87.960  0.0456    98.556  488.49
  71   0.5248     88.030  0.0422    98.700  495.41
  72   0.5136     88.060  0.0400    98.782  502.43
  73   0.5082     88.320  0.0398    98.800  509.39
  74   0.5193     88.220  0.0402    98.796  516.33
  75   0.5130     88.310  0.0370    98.882  523.29
  76   0.5177     88.180  0.0361    98.902  530.22
  77   0.5165     88.210  0.0336    99.018  537.17
  78   0.5224     88.350  0.0315    99.088  544.22
  79   0.5274     88.300  0.0318    99.080  551.20
  80   0.5192     88.140  0.0322    99.058  558.19
  81   0.5315     88.300  0.0319    99.082  565.12
  82   0.5282     88.330  0.0301    99.076  572.05
  83   0.5363     88.160  0.0299    99.146  579.03
  84   0.5401     88.390  0.0293    99.158  585.97
  85   0.5457     88.020  0.0281    99.232  592.91
