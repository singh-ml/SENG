Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4237     47.740  1.7264    35.926  8.72
   2   1.1418     57.940  1.2670    53.648  15.66
   3   0.9634     65.870  1.0394    62.582  22.62
   4   0.8595     69.730  0.9014    67.732  29.64
   5   0.7636     72.760  0.8117    71.100  36.67
   6   0.6938     75.260  0.7269    74.362  43.67
   7   0.6610     76.910  0.6597    76.826  50.63
   8   0.6213     78.860  0.6150    78.476  57.57
   9   0.5894     79.710  0.5646    80.370  64.52
  10   0.5849     79.910  0.5239    81.566  71.58
  11   0.5373     81.250  0.4910    82.816  78.54
  12   0.5448     81.560  0.4622    83.920  85.48
  13   0.4936     83.160  0.4390    84.626  92.46
  14   0.4809     83.580  0.4143    85.666  99.40
  15   0.5118     83.070  0.3903    86.498  106.44
  16   0.4787     84.340  0.3731    86.964  113.41
  17   0.4581     84.850  0.3505    87.742  120.36
  18   0.4589     84.880  0.3335    88.420  127.38
  19   0.4509     85.090  0.3232    88.624  134.36
  20   0.4523     85.670  0.3071    89.276  141.43
  21   0.4244     86.310  0.2936    89.642  148.36
  22   0.4409     86.030  0.2786    90.324  155.32
  23   0.4452     86.400  0.2643    90.782  162.26
  24   0.4513     85.820  0.2607    90.858  169.23
  25   0.4355     86.580  0.2462    91.364  176.25
  26   0.4175     87.110  0.2385    91.572  183.20
  27   0.4285     86.880  0.2293    91.992  190.19
  28   0.4284     86.890  0.2167    92.292  197.12
  29   0.4270     86.940  0.2036    92.824  204.07
  30   0.4610     86.460  0.2030    92.754  211.13
  31   0.4282     86.960  0.1835    93.566  218.09
  32   0.4225     87.380  0.1816    93.742  225.06
  33   0.4273     87.440  0.1708    94.040  232.05
  34   0.4517     86.940  0.1658    94.296  239.03
  35   0.4178     87.830  0.1600    94.436  246.10
  36   0.4481     87.830  0.1471    94.800  253.03
  37   0.4353     88.100  0.1381    95.102  260.00
  38   0.4170     88.400  0.1375    95.254  266.97
  39   0.3982     88.630  0.1339    95.258  273.94
  40   0.4423     87.940  0.1222    95.762  280.95
  41   0.4118     88.750  0.1218    95.736  287.95
  42   0.4693     87.660  0.1085    96.184  294.93
  43   0.4423     88.460  0.1063    96.222  301.91
  44   0.4192     88.630  0.0968    96.634  308.90
  45   0.4420     88.580  0.0907    96.864  315.93
  46   0.4581     88.330  0.0885    96.892  322.94
  47   0.4714     88.390  0.0910    96.930  329.89
  48   0.4199     89.180  0.0821    97.168  336.85
  49   0.4546     88.610  0.0748    97.364  343.80
  50   0.4537     88.990  0.0703    97.568  350.66
  51   0.4496     89.020  0.0679    97.668  357.66
  52   0.4659     89.170  0.0633    97.866  364.62
  53   0.4412     89.350  0.0661    97.746  371.56
  54   0.4482     88.900  0.0598    97.956  378.53
  55   0.4493     89.130  0.0537    98.232  385.53
  56   0.4370     89.560  0.0501    98.354  392.53
  57   0.4583     89.190  0.0484    98.452  399.50
  58   0.4549     89.360  0.0474    98.378  406.44
  59   0.4467     89.650  0.0422    98.628  413.37
  60   0.4553     89.370  0.0385    98.808  420.36
  61   0.4565     89.660  0.0357    98.896  427.40
  62   0.4563     89.750  0.0358    98.818  434.39
  63   0.4589     89.630  0.0344    98.910  441.37
  64   0.4541     89.260  0.0328    98.958  448.33
  65   0.4715     89.790  0.0309    99.054  455.32
  66   0.4650     89.620  0.0281    99.192  462.30
  67   0.4690     89.530  0.0264    99.206  469.26
  68   0.4654     89.620  0.0250    99.314  476.25
  69   0.4670     89.830  0.0232    99.336  483.22
  70   0.4605     89.790  0.0222    99.398  490.17
  71   0.4669     89.700  0.0226    99.366  497.21
  72   0.4714     89.640  0.0204    99.476  504.19
  73   0.4713     89.930  0.0199    99.450  511.16
  74   0.4802     89.500  0.0184    99.478  518.14
  75   0.4692     89.840  0.0185    99.500  525.08
  76   0.4683     90.090  0.0183    99.498  532.06
  77   0.4789     89.870  0.0172    99.546  539.06
  78   0.4786     89.900  0.0180    99.524  545.99
  79   0.4776     89.970  0.0178    99.522  552.97
  80   0.4702     90.110  0.0175    99.520  559.95
  81   0.4708     89.990  0.0156    99.632  566.93
  82   0.4766     89.990  0.0152    99.618  573.93
  83   0.4697     89.870  0.0137    99.666  580.99
  84   0.4790     89.970  0.0139    99.686  587.98
  85   0.4867     89.680  0.0131    99.698  594.93
