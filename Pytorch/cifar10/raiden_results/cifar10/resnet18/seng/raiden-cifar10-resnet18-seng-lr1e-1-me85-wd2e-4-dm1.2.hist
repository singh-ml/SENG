Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1773     59.820  1.4256    47.484  8.72
   2   0.8238     71.740  0.8964    68.102  15.63
   3   0.6786     77.030  0.6924    75.574  22.58
   4   0.5822     80.740  0.5906    79.380  29.60
   5   0.5773     80.750  0.5195    82.120  36.51
   6   0.5079     83.270  0.4585    84.280  43.46
   7   0.4700     84.680  0.4239    85.186  50.39
   8   0.4848     84.400  0.3895    86.328  57.34
   9   0.4500     85.420  0.3560    87.680  64.34
  10   0.4444     85.310  0.3334    88.316  71.25
  11   0.4173     86.280  0.3091    89.360  78.16
  12   0.4808     85.210  0.2876    90.102  85.06
  13   0.3713     88.060  0.2748    90.326  92.00
  14   0.3814     87.890  0.2479    91.406  98.99
  15   0.4080     87.280  0.2315    91.966  105.88
  16   0.4754     85.810  0.2199    92.298  112.81
  17   0.3708     87.820  0.2174    92.272  119.78
  18   0.4028     87.290  0.1979    93.056  126.68
  19   0.3233     89.590  0.1898    93.354  133.67
  20   0.3494     89.180  0.1798    93.678  140.58
  21   0.3903     88.600  0.1691    94.162  147.52
  22   0.3445     89.080  0.1640    94.214  154.46
  23   0.3844     88.590  0.1530    94.594  161.38
  24   0.3361     89.760  0.1521    94.648  168.35
  25   0.3515     89.160  0.1397    95.148  175.32
  26   0.3574     89.150  0.1317    95.438  182.26
  27   0.3257     90.300  0.1312    95.526  189.17
  28   0.3443     89.850  0.1234    95.668  196.09
  29   0.4044     88.530  0.1129    96.114  203.03
  30   0.3362     89.870  0.1103    96.040  209.97
  31   0.3845     89.450  0.1072    96.266  216.89
  32   0.3968     89.340  0.0992    96.506  223.85
  33   0.3207     90.990  0.0979    96.636  230.77
  34   0.3542     90.190  0.0885    96.852  237.68
  35   0.3556     90.170  0.0861    96.988  244.67
  36   0.3699     89.860  0.0800    97.182  251.59
  37   0.3412     90.600  0.0787    97.230  258.51
  38   0.3465     90.570  0.0766    97.334  265.44
  39   0.3256     91.380  0.0682    97.632  272.36
  40   0.3440     90.560  0.0645    97.752  279.35
  41   0.3364     90.980  0.0601    97.890  286.27
  42   0.3668     90.390  0.0602    97.904  293.16
  43   0.3109     92.050  0.0535    98.100  300.10
  44   0.3416     91.540  0.0464    98.374  307.04
  45   0.3956     90.490  0.0395    98.680  314.04
  46   0.3657     91.120  0.0427    98.550  320.94
  47   0.3410     91.810  0.0338    98.850  327.86
  48   0.3467     91.600  0.0350    98.852  334.77
  49   0.3122     92.410  0.0329    98.918  341.76
  50   0.3311     91.850  0.0268    99.124  348.56
  51   0.3198     92.230  0.0271    99.080  355.52
  52   0.3344     91.830  0.0230    99.234  362.41
  53   0.2991     92.620  0.0168    99.484  369.33
  54   0.3103     92.400  0.0173    99.444  376.29
  55   0.2990     92.880  0.0145    99.556  383.22
  56   0.3218     93.040  0.0116    99.662  390.15
  57   0.3069     92.910  0.0094    99.752  397.04
  58   0.3141     92.580  0.0087    99.734  403.95
  59   0.2944     93.090  0.0059    99.858  410.93
  60   0.3058     92.920  0.0048    99.920  417.84
  61   0.2880     93.500  0.0049    99.892  424.72
  62   0.3005     93.550  0.0036    99.920  431.65
  63   0.2925     93.430  0.0029    99.954  438.55
  64   0.2814     93.670  0.0026    99.962  445.51
  65   0.2816     93.640  0.0019    99.982  452.43
  66   0.2876     93.530  0.0024    99.960  459.34
  67   0.2784     93.660  0.0019    99.974  466.24
  68   0.2733     93.770  0.0018    99.980  473.16
  69   0.2720     93.870  0.0017    99.982  480.16
  70   0.2734     93.810  0.0015    99.982  487.10
  71   0.2711     93.920  0.0013    99.988  494.02
  72   0.2702     93.980  0.0016    99.974  500.96
  73   0.2697     94.040  0.0014    99.986  507.89
  74   0.2687     93.960  0.0012    99.988  514.86
  75   0.2698     93.980  0.0011    99.996  521.81
  76   0.2735     93.940  0.0012    99.992  528.75
  77   0.2693     93.960  0.0013    99.990  535.65
  78   0.2672     93.950  0.0012    99.988  542.56
  79   0.2689     93.970  0.0010    100.000  549.50
  80   0.2665     94.010  0.0011    99.996  556.56
  81   0.2658     93.990  0.0010    99.998  563.47
  82   0.2661     93.940  0.0011    99.988  570.40
  83   0.2669     93.930  0.0011    99.992  577.29
  84   0.2665     93.990  0.0010    99.996  584.21
  85   0.2658     94.010  0.0009    99.998  591.21
