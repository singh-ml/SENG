Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2919     52.070  1.5926    40.840  8.75
   2   0.9609     65.290  1.1087    59.928  15.73
   3   0.8288     70.570  0.8872    68.254  22.69
   4   0.7395     74.110  0.7539    73.394  29.66
   5   0.6394     77.790  0.6555    76.938  36.61
   6   0.5939     79.020  0.5888    79.498  43.54
   7   0.5626     80.550  0.5355    81.270  50.53
   8   0.5175     82.570  0.4926    82.720  57.48
   9   0.5259     82.240  0.4497    84.212  64.42
  10   0.5051     82.890  0.4197    85.386  71.35
  11   0.4614     83.950  0.3912    86.320  78.26
  12   0.4885     83.790  0.3672    87.116  85.32
  13   0.4868     84.420  0.3489    87.880  92.26
  14   0.4478     85.450  0.3224    88.858  99.24
  15   0.4259     85.870  0.3092    89.202  106.17
  16   0.4171     86.010  0.2939    89.764  113.12
  17   0.4331     86.240  0.2718    90.494  120.12
  18   0.4294     85.920  0.2570    91.062  127.05
  19   0.4141     86.550  0.2460    91.402  134.02
  20   0.4397     86.550  0.2326    91.880  140.98
  21   0.3929     87.500  0.2212    92.102  147.90
  22   0.4140     86.840  0.2054    92.824  154.92
  23   0.3843     87.900  0.2028    92.884  161.86
  24   0.4664     86.450  0.1827    93.552  168.77
  25   0.3975     87.980  0.1794    93.592  175.68
  26   0.4007     88.140  0.1665    94.100  182.62
  27   0.4124     88.460  0.1573    94.542  189.62
  28   0.4037     87.850  0.1487    94.740  196.58
  29   0.4009     88.620  0.1427    94.960  203.50
  30   0.4166     88.440  0.1336    95.380  210.40
  31   0.3975     88.450  0.1303    95.320  217.34
  32   0.4015     88.760  0.1192    95.746  224.33
  33   0.4119     88.980  0.1129    96.040  231.27
  34   0.4493     87.970  0.1047    96.270  238.23
  35   0.4248     88.780  0.0979    96.522  245.17
  36   0.4222     88.510  0.0913    96.764  252.14
  37   0.4397     88.550  0.0922    96.750  259.09
  38   0.4355     88.940  0.0897    96.766  266.10
  39   0.4692     88.510  0.0820    97.144  273.02
  40   0.4016     89.880  0.0732    97.450  279.95
  41   0.4363     89.270  0.0666    97.656  286.89
  42   0.4433     89.370  0.0635    97.740  293.79
  43   0.4218     89.600  0.0574    97.954  300.79
  44   0.4271     89.750  0.0530    98.236  307.74
  45   0.4432     89.280  0.0525    98.156  314.66
  46   0.4205     89.690  0.0460    98.402  321.58
  47   0.4361     89.920  0.0412    98.662  328.51
  48   0.4589     89.540  0.0377    98.772  335.57
  49   0.4670     89.230  0.0379    98.696  342.50
  50   0.4445     90.330  0.0341    98.842  349.32
  51   0.4446     90.300  0.0333    98.886  356.26
  52   0.4782     89.710  0.0291    99.036  363.20
  53   0.4580     90.010  0.0276    99.140  370.23
  54   0.4604     89.980  0.0240    99.240  377.17
  55   0.4377     90.380  0.0247    99.230  384.12
  56   0.4566     89.900  0.0202    99.400  391.04
  57   0.4553     90.350  0.0186    99.446  398.00
  58   0.4664     90.160  0.0172    99.522  404.97
  59   0.4542     90.270  0.0171    99.474  411.91
  60   0.4629     90.640  0.0142    99.598  418.87
  61   0.4770     90.370  0.0138    99.614  425.78
  62   0.4703     90.500  0.0124    99.660  432.71
  63   0.4745     90.500  0.0129    99.646  439.75
  64   0.4670     90.440  0.0112    99.704  446.71
  65   0.4755     90.410  0.0111    99.720  453.72
  66   0.4679     90.670  0.0104    99.730  460.70
  67   0.4761     90.460  0.0105    99.734  467.64
  68   0.4543     90.770  0.0098    99.766  474.66
  69   0.4666     90.880  0.0093    99.756  481.56
  70   0.4633     90.740  0.0082    99.790  488.51
  71   0.4628     90.890  0.0079    99.818  495.45
  72   0.4651     90.750  0.0076    99.804  502.39
  73   0.4590     90.950  0.0077    99.812  509.34
  74   0.4579     90.810  0.0069    99.862  516.43
  75   0.4651     90.620  0.0069    99.862  523.39
  76   0.4646     90.740  0.0069    99.836  530.35
  77   0.4665     90.900  0.0060    99.874  537.27
  78   0.4702     90.810  0.0058    99.886  544.22
  79   0.4692     90.970  0.0063    99.864  551.22
  80   0.4660     90.890  0.0060    99.862  558.16
  81   0.4688     90.830  0.0055    99.902  565.16
  82   0.4739     90.870  0.0062    99.868  572.12
  83   0.4695     90.780  0.0058    99.880  579.06
  84   0.4721     90.650  0.0061    99.858  586.01
  85   0.4708     90.790  0.0053    99.884  593.10
