Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4631     46.110  1.7598    34.384  8.69
   2   1.1616     57.830  1.3285    51.460  15.64
   3   1.0269     62.970  1.1144    59.930  22.56
   4   0.9112     66.980  0.9772    65.036  29.63
   5   0.8231     70.890  0.8779    68.764  36.61
   6   0.8074     71.450  0.8003    71.626  43.54
   7   0.7179     74.450  0.7336    74.198  50.46
   8   0.6787     76.090  0.6740    76.382  57.40
   9   0.6318     77.900  0.6235    78.042  64.35
  10   0.6001     78.780  0.5762    79.764  71.37
  11   0.5738     80.170  0.5441    80.884  78.34
  12   0.5719     80.250  0.5122    81.958  85.24
  13   0.5492     81.470  0.4834    83.042  92.19
  14   0.5242     82.250  0.4591    84.020  99.11
  15   0.5128     82.590  0.4334    84.988  106.11
  16   0.5228     82.780  0.4123    85.654  113.06
  17   0.4819     84.220  0.3950    86.132  120.00
  18   0.4908     83.920  0.3796    87.084  126.97
  19   0.4713     84.270  0.3536    87.608  133.92
  20   0.4622     84.820  0.3430    88.002  140.94
  21   0.4659     84.810  0.3304    88.458  147.87
  22   0.4510     85.250  0.3158    88.916  154.83
  23   0.4645     84.910  0.2989    89.600  161.78
  24   0.4463     85.530  0.2946    89.844  168.71
  25   0.4463     85.540  0.2786    90.202  175.75
  26   0.4413     85.890  0.2681    90.460  182.68
  27   0.4504     85.750  0.2537    91.102  189.66
  28   0.4395     86.070  0.2430    91.540  196.58
  29   0.4643     85.980  0.2370    91.668  203.50
  30   0.4560     86.050  0.2316    91.858  210.52
  31   0.4378     86.550  0.2211    92.154  217.44
  32   0.4571     86.420  0.2067    92.730  224.36
  33   0.4325     86.990  0.2004    93.038  231.27
  34   0.4429     86.860  0.1878    93.374  238.20
  35   0.4480     86.640  0.1847    93.566  245.10
  36   0.4362     87.400  0.1782    93.630  252.12
  37   0.4685     86.790  0.1738    93.778  259.04
  38   0.4525     86.830  0.1614    94.382  265.99
  39   0.4371     87.500  0.1580    94.320  272.95
  40   0.4715     86.700  0.1508    94.628  279.91
  41   0.4397     87.570  0.1385    95.090  286.95
  42   0.4486     87.560  0.1384    95.014  293.86
  43   0.4441     87.820  0.1288    95.516  300.82
  44   0.4558     87.940  0.1258    95.410  307.79
  45   0.4519     87.740  0.1225    95.636  314.72
  46   0.4617     87.840  0.1139    96.004  321.76
  47   0.4865     87.270  0.1141    96.020  328.68
  48   0.4661     87.870  0.1062    96.238  335.60
  49   0.4618     87.910  0.0993    96.568  342.51
  50   0.4716     88.180  0.0976    96.646  349.38
  51   0.4964     87.630  0.0925    96.720  356.39
  52   0.4791     87.830  0.0890    96.862  363.33
  53   0.4630     88.580  0.0827    97.154  370.25
  54   0.4596     88.190  0.0790    97.222  377.20
  55   0.4708     88.280  0.0749    97.356  384.13
  56   0.4882     88.440  0.0724    97.488  391.11
  57   0.4897     88.410  0.0676    97.642  398.03
  58   0.4877     88.230  0.0656    97.796  404.95
  59   0.4836     88.680  0.0645    97.794  411.89
  60   0.4961     88.330  0.0598    97.954  418.80
  61   0.5086     88.370  0.0594    97.950  425.77
  62   0.4922     88.440  0.0549    98.118  432.72
  63   0.5053     88.550  0.0526    98.236  439.66
  64   0.4932     88.440  0.0469    98.438  446.60
  65   0.4872     88.590  0.0476    98.348  453.53
  66   0.5102     88.500  0.0455    98.484  460.54
  67   0.4974     88.980  0.0411    98.632  467.44
  68   0.5034     88.780  0.0423    98.628  474.35
  69   0.5038     88.660  0.0398    98.708  481.27
  70   0.5145     88.950  0.0370    98.772  488.19
  71   0.5027     88.850  0.0353    98.886  495.16
  72   0.4990     89.300  0.0344    98.912  502.12
  73   0.5039     88.980  0.0319    99.028  509.04
  74   0.5067     88.970  0.0315    99.028  515.98
  75   0.5124     89.170  0.0302    99.094  522.95
  76   0.5176     88.930  0.0316    99.012  529.87
  77   0.5228     89.130  0.0279    99.148  536.85
  78   0.5213     89.300  0.0281    99.110  543.78
  79   0.5256     89.010  0.0257    99.234  550.69
  80   0.5284     89.060  0.0248    99.292  557.62
  81   0.5288     88.940  0.0238    99.316  564.56
  82   0.5237     89.140  0.0237    99.354  571.59
  83   0.5248     89.260  0.0224    99.408  578.54
  84   0.5164     89.250  0.0229    99.328  585.44
  85   0.5235     89.170  0.0221    99.380  592.40
  86   0.5348     89.190  0.0233    99.316  599.34
  87   0.5314     89.260  0.0217    99.358  606.34
  88   0.5308     88.790  0.0209    99.418  613.30
  89   0.5312     89.350  0.0193    99.474  620.23
  90   0.5269     89.290  0.0204    99.430  627.20
