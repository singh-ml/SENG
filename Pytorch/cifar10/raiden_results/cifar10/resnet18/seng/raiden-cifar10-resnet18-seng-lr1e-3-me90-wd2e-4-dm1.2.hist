Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8735     29.550  2.0726    22.976  8.69
   2   1.6666     37.880  1.7850    34.054  15.67
   3   1.5330     42.780  1.6269    39.424  22.55
   4   1.4411     46.550  1.5208    43.476  29.46
   5   1.3746     49.350  1.4374    46.604  36.41
   6   1.3141     52.020  1.3593    49.858  43.30
   7   1.2521     54.190  1.2980    52.488  50.31
   8   1.1984     56.830  1.2388    54.884  57.21
   9   1.1591     58.170  1.1938    56.866  64.15
  10   1.1198     59.950  1.1466    58.420  71.07
  11   1.0856     61.330  1.1057    59.964  77.95
  12   1.0416     62.450  1.0624    61.604  84.94
  13   1.0146     64.180  1.0288    62.978  91.87
  14   0.9808     64.890  0.9938    64.208  98.78
  15   0.9585     65.870  0.9666    65.366  105.71
  16   0.9364     66.690  0.9358    66.518  112.63
  17   0.9080     67.290  0.9110    67.272  119.62
  18   0.8854     68.510  0.8827    68.370  126.51
  19   0.8713     69.330  0.8609    69.328  133.39
  20   0.8433     70.030  0.8406    69.928  140.32
  21   0.8368     70.600  0.8202    70.582  147.24
  22   0.8218     70.960  0.8033    71.460  154.23
  23   0.8082     71.440  0.7830    72.080  161.11
  24   0.7912     72.220  0.7669    72.728  168.02
  25   0.7759     73.000  0.7490    73.474  174.93
  26   0.7578     73.340  0.7324    74.008  181.85
  27   0.7485     73.900  0.7161    74.678  188.81
  28   0.7342     74.040  0.7030    75.204  195.70
  29   0.7298     74.620  0.6875    75.644  202.60
  30   0.7113     75.260  0.6753    76.188  209.47
  31   0.7129     75.230  0.6677    76.422  216.35
  32   0.6999     75.850  0.6519    77.082  223.29
  33   0.6970     75.990  0.6377    77.508  230.21
  34   0.6851     76.080  0.6274    77.726  237.10
  35   0.6733     76.500  0.6161    78.256  243.99
  36   0.6579     77.030  0.6026    78.758  250.90
  37   0.6573     77.160  0.5898    79.426  257.91
  38   0.6387     77.990  0.5793    79.678  264.83
  39   0.6353     78.260  0.5705    79.784  271.75
  40   0.6250     78.620  0.5549    80.490  278.68
  41   0.6199     78.590  0.5453    80.746  285.67
  42   0.6319     79.090  0.5343    81.224  292.53
  43   0.6120     78.980  0.5327    81.328  299.43
  44   0.6107     79.130  0.5208    81.658  306.31
  45   0.6040     79.540  0.5119    81.888  313.19
  46   0.5896     79.520  0.4997    82.386  320.12
  47   0.5924     80.350  0.4939    82.602  327.07
  48   0.5930     79.960  0.4830    82.926  333.95
  49   0.5672     80.720  0.4778    83.188  340.87
  50   0.5725     80.600  0.4690    83.716  347.65
  51   0.5611     81.100  0.4566    83.906  354.54
  52   0.5605     81.480  0.4515    84.164  361.48
  53   0.5631     81.380  0.4464    84.408  368.40
  54   0.5511     81.570  0.4398    84.500  375.28
  55   0.5447     81.930  0.4325    84.664  382.19
  56   0.5431     82.080  0.4251    85.188  389.07
  57   0.5478     81.870  0.4177    85.378  395.97
  58   0.5446     82.150  0.4112    85.662  402.94
  59   0.5382     82.480  0.4020    85.862  409.82
  60   0.5334     82.560  0.4017    85.802  416.71
  61   0.5284     82.540  0.3954    86.190  423.60
  62   0.5232     82.770  0.3887    86.374  430.52
  63   0.5170     83.180  0.3826    86.648  437.45
  64   0.5112     83.170  0.3748    86.962  444.38
  65   0.5274     82.930  0.3731    87.006  451.26
  66   0.5215     83.090  0.3661    87.102  458.18
  67   0.5236     83.070  0.3614    87.334  465.07
  68   0.5150     83.470  0.3557    87.360  471.97
  69   0.5167     83.420  0.3524    87.396  478.84
  70   0.5124     83.580  0.3475    87.794  485.75
  71   0.5065     83.700  0.3429    87.944  492.62
  72   0.4989     83.750  0.3297    88.462  499.56
  73   0.5113     83.850  0.3307    88.222  506.44
  74   0.4998     83.850  0.3229    88.646  513.33
  75   0.5091     83.720  0.3180    88.838  520.20
  76   0.5101     83.740  0.3193    88.628  527.10
  77   0.4981     84.240  0.3130    89.076  534.05
  78   0.4996     84.240  0.3063    89.340  540.94
  79   0.4908     84.530  0.3013    89.442  547.84
  80   0.5112     84.080  0.2984    89.332  554.73
  81   0.5042     84.150  0.2931    89.622  561.63
  82   0.5008     84.340  0.2937    89.580  568.64
  83   0.5005     84.440  0.2844    90.034  575.56
  84   0.4902     85.070  0.2823    89.912  582.47
  85   0.5087     84.110  0.2790    90.240  589.37
  86   0.5071     84.540  0.2731    90.330  596.25
  87   0.4921     84.790  0.2691    90.488  603.14
  88   0.4937     85.030  0.2627    90.726  610.12
  89   0.5005     84.900  0.2605    90.732  617.03
  90   0.5066     84.430  0.2529    90.942  623.93
