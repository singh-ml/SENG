Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8528     30.850  2.0836    22.658  8.76
   2   1.6096     39.290  1.7418    35.362  15.92
   3   1.4754     44.920  1.5710    41.496  22.97
   4   1.3872     48.560  1.4669    45.694  30.03
   5   1.3041     51.960  1.3814    49.238  37.09
   6   1.2362     54.890  1.3025    52.498  44.15
   7   1.1758     57.330  1.2376    54.890  51.27
   8   1.1174     59.330  1.1772    57.462  58.32
   9   1.0824     60.890  1.1277    59.128  65.34
  10   1.0464     62.490  1.0832    60.986  72.39
  11   1.0079     63.810  1.0393    62.556  79.46
  12   0.9794     64.910  0.9996    64.198  86.61
  13   0.9523     66.230  0.9688    65.118  93.67
  14   0.9166     67.290  0.9343    66.536  100.73
  15   0.8908     68.210  0.9024    67.764  107.82
  16   0.8739     68.820  0.8738    68.992  114.92
  17   0.8557     69.650  0.8509    69.802  121.97
  18   0.8405     70.280  0.8308    70.586  129.02
  19   0.8197     71.320  0.8078    71.200  136.09
  20   0.8001     72.020  0.7839    72.166  143.23
  21   0.7858     72.380  0.7665    72.714  150.39
  22   0.7777     72.690  0.7484    73.576  157.44
  23   0.7545     73.490  0.7334    74.132  164.51
  24   0.7499     73.900  0.7170    74.700  171.53
  25   0.7191     74.940  0.6965    75.310  178.56
  26   0.7232     74.970  0.6833    76.086  185.68
  27   0.6995     75.580  0.6675    76.486  192.73
  28   0.6901     76.190  0.6509    77.030  199.75
  29   0.6811     76.640  0.6326    77.730  206.78
  30   0.6712     76.680  0.6204    78.164  213.84
  31   0.6649     76.820  0.6100    78.508  220.92
  32   0.6502     77.410  0.5928    79.112  228.02
  33   0.6471     77.480  0.5794    79.570  235.08
  34   0.6340     77.820  0.5696    79.866  242.13
  35   0.6265     78.230  0.5580    80.400  249.17
  36   0.6181     78.730  0.5435    80.976  256.24
  37   0.6160     78.730  0.5340    81.348  263.34
  38   0.5927     79.650  0.5231    81.722  270.42
  39   0.5911     79.610  0.5145    81.976  277.48
  40   0.5898     79.790  0.4991    82.620  284.54
  41   0.5814     80.000  0.4955    82.566  291.58
  42   0.5797     80.270  0.4860    83.000  298.70
  43   0.5731     80.720  0.4757    83.298  305.77
  44   0.5631     80.520  0.4700    83.384  312.82
  45   0.5590     81.150  0.4564    84.006  319.90
  46   0.5628     81.440  0.4486    84.336  326.97
  47   0.5633     81.210  0.4399    84.678  334.03
  48   0.5444     81.790  0.4314    84.806  341.07
  49   0.5461     81.430  0.4207    85.336  348.14
  50   0.5337     82.410  0.4166    85.356  355.06
  51   0.5404     82.420  0.4078    85.658  362.18
  52   0.5326     82.420  0.4022    85.894  369.22
  53   0.5355     82.250  0.3963    86.260  376.25
  54   0.5375     82.360  0.3936    86.420  383.28
  55   0.5228     82.740  0.3830    86.646  390.35
  56   0.5290     82.530  0.3797    86.750  397.51
  57   0.5222     83.180  0.3685    87.234  404.55
  58   0.5202     83.150  0.3621    87.292  411.60
  59   0.5176     83.180  0.3531    87.524  418.66
  60   0.5163     83.100  0.3573    87.468  425.72
  61   0.5044     83.540  0.3462    87.996  432.76
  62   0.5119     83.550  0.3437    87.962  439.87
  63   0.5092     83.500  0.3378    88.386  446.93
  64   0.5046     83.660  0.3311    88.530  453.97
  65   0.5048     83.560  0.3246    88.670  461.03
  66   0.5137     83.810  0.3154    89.070  468.05
  67   0.5071     83.980  0.3138    89.056  475.12
  68   0.4966     84.110  0.3118    89.166  482.15
  69   0.4998     83.820  0.3033    89.352  489.20
  70   0.4984     84.410  0.3031    89.424  496.26
  71   0.5038     84.270  0.2929    89.766  503.30
  72   0.5069     83.970  0.2889    89.920  510.39
  73   0.4985     84.390  0.2893    89.916  517.42
  74   0.4916     84.510  0.2820    90.228  524.48
  75   0.5072     84.270  0.2800    90.294  531.55
  76   0.4941     85.030  0.2768    90.382  538.61
  77   0.4933     84.450  0.2678    90.552  545.76
  78   0.4960     84.700  0.2667    90.648  552.82
  79   0.5100     84.840  0.2596    90.960  559.89
  80   0.5032     84.830  0.2549    90.998  566.92
  81   0.5099     84.920  0.2486    91.236  573.96
  82   0.5018     84.450  0.2471    91.324  581.08
  83   0.4948     85.190  0.2438    91.452  588.15
  84   0.4923     85.550  0.2379    91.724  595.21
  85   0.4990     85.060  0.2309    91.876  602.26
  86   0.5031     84.900  0.2337    91.638  609.32
  87   0.5108     85.080  0.2271    92.124  616.45
  88   0.5348     84.950  0.2246    92.158  623.52
  89   0.5150     84.890  0.2201    92.398  630.58
  90   0.5166     84.970  0.2198    92.364  637.62
