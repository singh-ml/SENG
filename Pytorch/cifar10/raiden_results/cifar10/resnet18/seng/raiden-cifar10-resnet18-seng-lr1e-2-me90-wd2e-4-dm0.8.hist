Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3239     52.020  1.5899    41.126  8.71
   2   1.0447     62.730  1.1234    59.402  15.74
   3   0.8319     70.400  0.8932    68.212  22.70
   4   0.6965     76.270  0.7584    73.330  29.68
   5   0.6464     77.720  0.6513    77.268  36.70
   6   0.6155     78.960  0.5826    79.496  43.71
   7   0.5492     81.830  0.5290    81.506  50.72
   8   0.5588     81.240  0.4862    83.004  57.68
   9   0.5363     82.140  0.4495    84.396  64.65
  10   0.5145     83.410  0.4182    85.482  71.62
  11   0.4940     83.540  0.3899    86.432  78.62
  12   0.4839     83.960  0.3638    87.264  85.68
  13   0.4395     85.570  0.3472    87.814  92.66
  14   0.4657     85.200  0.3221    88.848  99.66
  15   0.4341     86.120  0.3059    89.272  106.67
  16   0.4421     85.790  0.2851    90.020  113.69
  17   0.4385     85.940  0.2754    90.362  120.75
  18   0.4353     86.830  0.2553    91.032  127.74
  19   0.4520     85.890  0.2449    91.380  134.71
  20   0.4213     86.620  0.2318    91.888  141.72
  21   0.3970     87.550  0.2161    92.442  148.67
  22   0.4205     87.720  0.2090    92.720  155.72
  23   0.4255     87.330  0.1967    93.068  162.70
  24   0.4445     87.100  0.1854    93.484  169.70
  25   0.4133     87.880  0.1808    93.538  176.67
  26   0.4131     88.340  0.1642    94.156  183.66
  27   0.4005     88.380  0.1609    94.262  190.70
  28   0.4546     87.230  0.1474    94.790  197.69
  29   0.4043     89.000  0.1399    95.050  204.70
  30   0.4357     88.220  0.1297    95.380  211.67
  31   0.3932     89.230  0.1244    95.606  218.69
  32   0.4130     88.940  0.1178    95.798  225.69
  33   0.3850     89.300  0.1130    95.980  232.68
  34   0.4244     89.170  0.1091    96.016  239.68
  35   0.4444     88.430  0.1008    96.472  246.65
  36   0.4015     89.170  0.0947    96.668  253.65
  37   0.4245     89.390  0.0842    97.028  260.70
  38   0.4256     89.610  0.0842    97.054  267.68
  39   0.4233     89.820  0.0732    97.484  274.66
  40   0.4004     89.920  0.0723    97.534  281.65
  41   0.4171     90.140  0.0714    97.538  288.64
  42   0.4408     89.460  0.0627    97.796  295.68
  43   0.4256     89.730  0.0595    97.978  302.69
  44   0.4414     89.800  0.0566    98.014  309.64
  45   0.4413     89.460  0.0559    98.004  316.60
  46   0.4547     89.710  0.0473    98.360  323.62
  47   0.4333     89.940  0.0467    98.396  330.67
  48   0.4415     89.980  0.0427    98.542  337.64
  49   0.4531     89.860  0.0409    98.596  344.65
  50   0.4217     90.510  0.0354    98.838  351.55
  51   0.4164     90.530  0.0308    99.024  358.56
  52   0.4264     90.390  0.0318    98.934  365.64
  53   0.4235     90.590  0.0277    99.090  372.64
  54   0.4080     90.960  0.0272    99.114  379.64
  55   0.4332     90.810  0.0219    99.342  386.63
  56   0.4423     90.560  0.0217    99.300  393.62
  57   0.4370     91.300  0.0207    99.384  400.68
  58   0.4170     91.230  0.0173    99.484  407.67
  59   0.4495     91.040  0.0149    99.580  414.69
  60   0.4206     91.140  0.0138    99.638  421.69
  61   0.4354     90.930  0.0123    99.666  428.65
  62   0.4405     91.100  0.0143    99.600  435.66
  63   0.4486     91.020  0.0122    99.666  442.62
  64   0.4477     91.030  0.0106    99.718  449.62
  65   0.4563     91.050  0.0100    99.758  456.59
  66   0.4436     91.160  0.0093    99.766  463.61
  67   0.4396     91.210  0.0086    99.792  470.57
  68   0.4451     91.300  0.0077    99.820  477.56
  69   0.4452     91.300  0.0076    99.838  484.53
  70   0.4524     91.100  0.0072    99.824  491.52
  71   0.4435     91.400  0.0065    99.848  498.58
  72   0.4503     91.240  0.0070    99.836  505.58
  73   0.4456     91.310  0.0064    99.848  512.54
  74   0.4461     91.540  0.0064    99.872  519.50
  75   0.4550     91.440  0.0054    99.914  526.48
  76   0.4478     91.520  0.0055    99.898  533.53
  77   0.4489     91.360  0.0055    99.886  540.53
  78   0.4407     91.380  0.0051    99.894  547.52
  79   0.4449     91.610  0.0049    99.910  554.55
  80   0.4489     91.380  0.0053    99.910  561.56
  81   0.4473     91.550  0.0044    99.930  568.65
  82   0.4464     91.560  0.0045    99.930  575.66
  83   0.4478     91.490  0.0045    99.926  582.64
  84   0.4480     91.520  0.0041    99.934  589.61
  85   0.4508     91.500  0.0044    99.922  596.56
  86   0.4517     91.590  0.0039    99.950  603.59
  87   0.4507     91.520  0.0044    99.924  610.59
  88   0.4537     91.480  0.0043    99.926  617.60
  89   0.4503     91.430  0.0038    99.938  624.58
  90   0.4472     91.530  0.0041    99.922  631.60
