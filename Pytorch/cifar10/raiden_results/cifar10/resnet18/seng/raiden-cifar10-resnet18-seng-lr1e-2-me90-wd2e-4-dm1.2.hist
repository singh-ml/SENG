Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3468     49.640  1.6699    38.180  8.91
   2   1.0604     61.310  1.2284    55.318  15.86
   3   0.8832     68.650  0.9832    64.878  22.84
   4   0.7806     72.580  0.8371    70.254  29.79
   5   0.7020     75.900  0.7348    73.968  36.84
   6   0.6342     78.390  0.6546    76.768  43.80
   7   0.5675     80.370  0.5980    79.102  50.79
   8   0.5766     80.510  0.5427    80.974  57.74
   9   0.5692     80.780  0.5100    82.186  64.73
  10   0.5640     81.150  0.4706    83.668  71.78
  11   0.5008     83.130  0.4392    84.682  78.78
  12   0.5050     83.210  0.4117    85.632  85.71
  13   0.4966     83.900  0.3952    86.222  92.63
  14   0.4722     84.500  0.3661    87.284  99.57
  15   0.4537     85.080  0.3501    87.930  106.63
  16   0.4627     85.540  0.3314    88.406  113.59
  17   0.4569     85.450  0.3177    88.770  120.58
  18   0.4307     86.240  0.3023    89.368  127.55
  19   0.4520     85.620  0.2829    90.050  134.52
  20   0.4625     85.550  0.2773    90.326  141.55
  21   0.4175     87.040  0.2603    90.900  148.51
  22   0.4265     86.630  0.2436    91.546  155.45
  23   0.4315     85.890  0.2340    91.744  162.44
  24   0.4079     86.950  0.2281    91.874  169.39
  25   0.4265     86.630  0.2137    92.468  176.46
  26   0.4398     86.480  0.2065    92.726  183.43
  27   0.4202     87.420  0.1934    93.232  190.36
  28   0.4153     88.040  0.1846    93.494  197.30
  29   0.4199     87.840  0.1732    93.864  204.25
  30   0.4145     87.920  0.1706    93.926  211.24
  31   0.4412     87.320  0.1557    94.418  218.31
  32   0.4126     87.920  0.1499    94.698  225.24
  33   0.4100     88.330  0.1390    95.146  232.18
  34   0.4281     88.370  0.1385    95.178  239.16
  35   0.4456     87.770  0.1314    95.324  246.15
  36   0.4178     88.370  0.1219    95.742  253.09
  37   0.4040     89.030  0.1184    95.768  260.01
  38   0.4201     88.700  0.1075    96.154  266.97
  39   0.4208     88.780  0.1031    96.368  273.90
  40   0.4384     88.350  0.0974    96.680  280.87
  41   0.4338     88.350  0.0933    96.792  287.92
  42   0.4169     89.220  0.0919    96.830  294.86
  43   0.4286     88.800  0.0837    97.118  301.80
  44   0.4276     88.900  0.0781    97.316  308.75
  45   0.4460     89.060  0.0760    97.338  315.70
  46   0.4348     89.210  0.0659    97.690  322.69
  47   0.4366     89.200  0.0618    97.920  329.62
  48   0.4336     89.330  0.0601    98.018  336.55
  49   0.4588     88.850  0.0582    97.952  343.51
  50   0.4349     89.440  0.0545    98.104  350.35
  51   0.4359     89.280  0.0466    98.470  357.40
  52   0.4587     88.900  0.0448    98.510  364.34
  53   0.4326     89.560  0.0435    98.532  371.31
  54   0.4313     89.870  0.0423    98.598  378.30
  55   0.4338     89.510  0.0391    98.704  385.24
  56   0.4411     89.640  0.0366    98.848  392.28
  57   0.4434     89.730  0.0324    98.954  399.25
  58   0.4449     89.880  0.0289    99.124  406.21
  59   0.4447     89.910  0.0277    99.154  413.20
  60   0.4426     89.910  0.0264    99.184  420.13
  61   0.4640     89.740  0.0247    99.264  427.17
  62   0.4414     89.920  0.0220    99.352  434.14
  63   0.4696     89.790  0.0207    99.432  441.12
  64   0.4572     89.850  0.0210    99.384  448.06
  65   0.4647     89.790  0.0189    99.460  454.98
  66   0.4553     90.150  0.0191    99.434  461.96
  67   0.4568     90.050  0.0170    99.538  468.92
  68   0.4618     89.740  0.0153    99.594  475.83
  69   0.4610     90.310  0.0148    99.590  482.81
  70   0.4586     90.290  0.0130    99.688  489.77
  71   0.4493     90.320  0.0131    99.676  496.73
  72   0.4498     90.440  0.0131    99.666  503.71
  73   0.4598     90.430  0.0126    99.706  510.64
  74   0.4526     90.360  0.0120    99.710  517.58
  75   0.4520     90.450  0.0123    99.696  524.55
  76   0.4561     90.310  0.0108    99.742  531.51
  77   0.4545     90.500  0.0102    99.760  538.53
  78   0.4524     90.510  0.0099    99.796  545.49
  79   0.4595     90.460  0.0092    99.798  552.46
  80   0.4550     90.520  0.0093    99.798  559.40
  81   0.4557     90.330  0.0093    99.806  566.37
  82   0.4524     90.510  0.0095    99.796  573.41
  83   0.4560     90.740  0.0088    99.812  580.36
  84   0.4571     90.560  0.0084    99.824  587.31
  85   0.4616     90.520  0.0086    99.806  594.27
  86   0.4662     90.340  0.0085    99.838  601.24
  87   0.4557     90.520  0.0077    99.862  608.31
  88   0.4625     90.520  0.0079    99.840  615.26
  89   0.4561     90.520  0.0073    99.884  622.22
  90   0.4594     90.520  0.0071    99.886  629.21
