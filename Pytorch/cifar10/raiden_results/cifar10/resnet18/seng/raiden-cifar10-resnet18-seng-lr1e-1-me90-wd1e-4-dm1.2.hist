Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1470     59.680  1.4509    46.770  8.61
   2   0.8577     70.590  0.9288    67.136  15.56
   3   0.6796     76.430  0.7040    75.418  22.48
   4   0.5643     80.960  0.5952    79.270  29.43
   5   0.5334     81.560  0.5234    81.628  36.44
   6   0.5332     81.880  0.4558    84.360  43.38
   7   0.5462     81.660  0.4246    85.408  50.33
   8   0.5098     83.580  0.3916    86.406  57.28
   9   0.4822     85.080  0.3528    87.762  64.20
  10   0.5093     84.760  0.3342    88.246  71.16
  11   0.4336     86.270  0.2994    89.672  78.13
  12   0.3994     87.250  0.2845    89.986  85.04
  13   0.4116     86.840  0.2569    91.108  91.97
  14   0.4167     87.100  0.2450    91.366  98.90
  15   0.3922     87.600  0.2255    92.060  105.90
  16   0.3751     88.020  0.2097    92.606  112.82
  17   0.3633     88.900  0.1999    92.950  119.77
  18   0.3956     88.350  0.1876    93.462  126.71
  19   0.3478     89.320  0.1719    93.960  133.63
  20   0.3965     87.970  0.1637    94.208  140.56
  21   0.3602     89.780  0.1518    94.644  147.56
  22   0.4269     88.370  0.1472    94.896  154.48
  23   0.3561     89.740  0.1344    95.316  161.41
  24   0.3852     89.370  0.1295    95.336  168.38
  25   0.3551     89.770  0.1197    95.810  175.28
  26   0.3667     89.880  0.1123    95.974  182.29
  27   0.3876     89.420  0.1063    96.228  189.23
  28   0.3770     89.960  0.0965    96.554  196.14
  29   0.3786     89.970  0.0948    96.602  203.08
  30   0.3817     89.830  0.0858    96.962  210.02
  31   0.3656     90.360  0.0787    97.246  216.95
  32   0.3890     89.690  0.0797    97.182  223.96
  33   0.3646     90.900  0.0702    97.492  230.91
  34   0.3516     91.020  0.0686    97.588  237.84
  35   0.4039     90.600  0.0584    97.978  244.80
  36   0.3962     89.960  0.0587    97.890  251.72
  37   0.4060     90.710  0.0589    97.932  258.72
  38   0.3996     90.820  0.0499    98.300  265.65
  39   0.3935     91.320  0.0498    98.288  272.57
  40   0.3905     91.060  0.0417    98.572  279.51
  41   0.3899     90.950  0.0408    98.616  286.57
  42   0.3773     91.390  0.0381    98.738  293.55
  43   0.3732     91.920  0.0347    98.822  300.46
  44   0.3841     91.380  0.0326    98.890  307.37
  45   0.3747     91.430  0.0290    99.036  314.30
  46   0.4061     91.100  0.0228    99.254  321.29
  47   0.4171     91.160  0.0273    99.092  328.25
  48   0.3688     91.860  0.0217    99.276  335.16
  49   0.3892     91.970  0.0198    99.346  342.06
  50   0.3561     92.420  0.0166    99.486  348.89
  51   0.3777     92.080  0.0165    99.478  355.93
  52   0.3626     92.200  0.0122    99.632  362.87
  53   0.3739     92.300  0.0110    99.660  369.79
  54   0.3666     92.650  0.0093    99.730  376.78
  55   0.3560     92.850  0.0067    99.828  383.71
  56   0.3542     92.700  0.0066    99.800  390.70
  57   0.3436     93.050  0.0051    99.866  397.63
  58   0.3666     92.920  0.0049    99.878  404.55
  59   0.3605     92.780  0.0036    99.914  411.48
  60   0.3558     92.960  0.0033    99.930  418.42
  61   0.3622     92.980  0.0040    99.900  425.40
  62   0.3517     92.920  0.0029    99.946  432.32
  63   0.3571     92.840  0.0028    99.936  439.28
  64   0.3569     92.790  0.0028    99.938  446.22
  65   0.3388     93.010  0.0020    99.974  453.17
  66   0.3410     93.450  0.0020    99.962  460.20
  67   0.3397     93.240  0.0019    99.962  467.11
  68   0.3388     93.170  0.0017    99.968  474.05
  69   0.3363     93.400  0.0016    99.972  480.97
  70   0.3407     93.240  0.0015    99.974  487.90
  71   0.3389     93.090  0.0015    99.980  494.83
  72   0.3367     93.250  0.0012    99.986  501.80
  73   0.3409     93.240  0.0013    99.978  508.70
  74   0.3391     93.270  0.0012    99.990  515.63
  75   0.3346     93.270  0.0011    99.986  522.58
  76   0.3364     93.410  0.0010    99.996  529.66
  77   0.3321     93.250  0.0010    99.992  536.60
  78   0.3328     93.290  0.0011    99.984  543.57
  79   0.3334     93.280  0.0011    99.990  550.50
  80   0.3322     93.270  0.0010    99.994  557.44
  81   0.3317     93.360  0.0011    99.988  564.39
  82   0.3316     93.290  0.0008    99.998  571.41
  83   0.3322     93.200  0.0009    99.996  578.31
  84   0.3292     93.330  0.0007    99.998  585.23
  85   0.3317     93.280  0.0009    99.998  592.16
  86   0.3323     93.350  0.0009    99.994  599.21
  87   0.3316     93.290  0.0009    99.996  606.14
  88   0.3318     93.200  0.0008    99.990  613.06
  89   0.3312     93.330  0.0008    99.994  620.03
  90   0.3290     93.320  0.0009    99.994  626.99
