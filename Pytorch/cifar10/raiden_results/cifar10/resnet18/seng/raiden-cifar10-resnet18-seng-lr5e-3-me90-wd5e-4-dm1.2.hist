Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4858     45.180  1.7740    33.990  8.78
   2   1.2324     55.240  1.3743    49.212  15.86
   3   1.0728     61.850  1.1853    56.802  22.89
   4   0.9328     66.730  1.0251    63.028  29.87
   5   0.8644     69.110  0.9194    67.236  36.87
   6   0.8099     71.230  0.8382    70.134  43.92
   7   0.7602     73.000  0.7778    72.458  51.07
   8   0.7105     75.000  0.7262    74.298  58.06
   9   0.6883     76.230  0.6764    75.988  65.07
  10   0.6422     77.530  0.6344    77.778  72.10
  11   0.6154     78.490  0.5925    79.106  79.17
  12   0.5916     79.240  0.5590    80.462  86.16
  13   0.5644     80.870  0.5289    81.450  93.17
  14   0.5643     80.700  0.5032    82.414  100.20
  15   0.5462     81.580  0.4773    83.360  107.22
  16   0.5383     81.720  0.4525    84.086  114.29
  17   0.5376     82.080  0.4365    84.884  121.34
  18   0.5048     82.930  0.4179    85.270  128.39
  19   0.4936     83.100  0.3996    85.956  135.40
  20   0.4809     84.080  0.3802    86.868  142.39
  21   0.4822     83.830  0.3660    87.310  149.44
  22   0.4589     84.780  0.3487    87.768  156.43
  23   0.4874     84.300  0.3387    88.204  163.43
  24   0.4562     85.150  0.3272    88.680  170.44
  25   0.4435     85.180  0.3145    88.916  177.43
  26   0.4515     85.570  0.2981    89.570  184.53
  27   0.4398     85.550  0.2887    89.968  191.54
  28   0.4498     85.640  0.2787    90.280  198.55
  29   0.4270     86.450  0.2704    90.476  205.57
  30   0.4459     86.070  0.2592    90.980  212.61
  31   0.4471     85.750  0.2484    91.372  219.69
  32   0.4316     86.310  0.2440    91.480  226.71
  33   0.4350     86.600  0.2310    91.990  233.73
  34   0.4194     86.820  0.2174    92.420  240.71
  35   0.4432     86.550  0.2141    92.484  247.73
  36   0.4691     85.410  0.2122    92.596  254.79
  37   0.4494     86.330  0.2029    92.878  261.79
  38   0.4393     87.010  0.1889    93.426  268.79
  39   0.4297     87.010  0.1826    93.694  275.81
  40   0.4334     86.730  0.1780    93.846  282.82
  41   0.4613     86.740  0.1696    94.012  289.93
  42   0.4444     86.740  0.1602    94.466  296.95
  43   0.4372     87.150  0.1582    94.468  303.98
  44   0.4560     86.810  0.1530    94.684  310.99
  45   0.4584     87.130  0.1427    95.050  318.07
  46   0.4566     87.230  0.1430    95.002  325.13
  47   0.4428     87.330  0.1339    95.318  332.12
  48   0.4495     87.490  0.1262    95.704  339.12
  49   0.4558     87.520  0.1241    95.652  346.13
  50   0.4454     87.750  0.1179    95.966  353.05
  51   0.4377     87.710  0.1097    96.222  360.13
  52   0.4577     87.790  0.1047    96.382  367.15
  53   0.4603     87.860  0.1036    96.456  374.15
  54   0.4823     87.610  0.0964    96.672  381.19
  55   0.4619     87.940  0.0954    96.690  388.23
  56   0.4571     88.020  0.0948    96.664  395.22
  57   0.4602     87.980  0.0848    97.138  402.22
  58   0.4638     87.950  0.0829    97.152  409.23
  59   0.4853     87.910  0.0804    97.358  416.27
  60   0.4655     88.060  0.0737    97.468  423.38
  61   0.4741     87.900  0.0695    97.666  430.39
  62   0.4727     88.250  0.0694    97.672  437.40
  63   0.4651     87.940  0.0648    97.838  444.42
  64   0.4738     87.780  0.0620    97.966  451.45
  65   0.4735     88.160  0.0588    98.054  458.51
  66   0.4847     87.900  0.0601    97.998  465.50
  67   0.4857     88.210  0.0548    98.282  472.49
  68   0.4845     88.380  0.0532    98.232  479.49
  69   0.4935     88.220  0.0505    98.360  486.53
  70   0.4901     88.330  0.0476    98.514  493.57
  71   0.4902     88.180  0.0467    98.534  500.59
  72   0.4834     88.290  0.0447    98.596  507.64
  73   0.4957     88.320  0.0429    98.634  514.67
  74   0.5057     88.260  0.0418    98.724  521.72
  75   0.5032     88.280  0.0393    98.780  528.71
  76   0.5008     88.230  0.0373    98.878  535.69
  77   0.4989     88.380  0.0357    98.956  542.72
  78   0.5054     88.540  0.0340    99.010  549.76
  79   0.5138     88.300  0.0333    99.036  556.90
  80   0.5010     88.350  0.0352    98.952  563.92
  81   0.5107     88.330  0.0325    99.048  570.95
  82   0.5045     88.410  0.0322    99.050  577.96
  83   0.4997     88.590  0.0314    99.102  584.98
  84   0.5102     88.540  0.0314    99.108  592.04
  85   0.5016     88.680  0.0311    99.078  599.06
  86   0.5093     88.540  0.0282    99.200  606.09
  87   0.5203     88.370  0.0272    99.244  613.12
  88   0.5160     88.520  0.0253    99.344  620.12
  89   0.5237     88.430  0.0243    99.352  627.23
  90   0.5290     88.440  0.0245    99.342  634.24
