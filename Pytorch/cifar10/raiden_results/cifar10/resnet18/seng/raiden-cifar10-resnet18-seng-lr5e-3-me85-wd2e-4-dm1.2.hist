Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4623     45.650  1.7688    34.218  8.77
   2   1.2258     55.290  1.3545    50.452  15.70
   3   1.0643     61.080  1.1577    58.248  22.65
   4   0.9391     66.290  1.0230    63.300  29.62
   5   0.8552     69.390  0.9170    67.174  36.54
   6   0.7894     72.200  0.8382    70.014  43.56
   7   0.7453     73.680  0.7649    72.788  50.51
   8   0.7058     75.410  0.7039    75.324  57.45
   9   0.6476     76.980  0.6582    76.862  64.41
  10   0.6511     77.710  0.6129    78.482  71.38
  11   0.6093     79.240  0.5797    79.874  78.38
  12   0.5980     79.200  0.5500    80.640  85.51
  13   0.5628     80.770  0.5199    81.808  92.48
  14   0.5487     81.050  0.4944    82.586  99.41
  15   0.5278     81.890  0.4738    83.522  106.34
  16   0.5172     82.020  0.4521    84.166  113.33
  17   0.5286     81.810  0.4334    84.878  120.27
  18   0.5131     82.730  0.4167    85.460  127.23
  19   0.4944     83.210  0.4049    85.840  134.17
  20   0.4765     83.980  0.3831    86.722  141.09
  21   0.4878     83.720  0.3636    87.330  148.10
  22   0.4876     83.600  0.3557    87.690  155.07
  23   0.4763     84.090  0.3432    87.928  162.01
  24   0.4809     83.840  0.3273    88.594  168.93
  25   0.4633     84.720  0.3169    88.936  175.89
  26   0.4594     84.860  0.3083    89.204  182.93
  27   0.4565     85.220  0.2950    89.750  189.86
  28   0.4409     85.210  0.2853    89.928  196.80
  29   0.4403     85.640  0.2777    90.294  203.75
  30   0.4512     85.290  0.2606    90.942  210.69
  31   0.4381     85.900  0.2584    90.846  217.63
  32   0.4378     85.910  0.2489    91.338  224.64
  33   0.4316     86.630  0.2356    91.798  231.55
  34   0.4487     85.810  0.2258    92.010  238.46
  35   0.4381     86.130  0.2213    92.326  245.40
  36   0.4619     85.940  0.2107    92.776  252.35
  37   0.4506     86.080  0.2079    92.694  259.31
  38   0.4416     85.930  0.1962    93.034  266.26
  39   0.4341     86.890  0.1911    93.324  273.23
  40   0.4600     86.250  0.1837    93.452  280.19
  41   0.4287     87.070  0.1743    93.858  287.16
  42   0.4199     87.090  0.1703    94.018  294.12
  43   0.4369     86.890  0.1652    94.232  301.04
  44   0.4353     87.080  0.1565    94.480  307.96
  45   0.4386     87.180  0.1488    94.772  314.89
  46   0.4362     87.660  0.1455    94.840  321.85
  47   0.4517     87.310  0.1439    94.940  328.86
  48   0.4411     87.500  0.1381    95.110  335.77
  49   0.4342     87.840  0.1278    95.560  342.68
  50   0.4337     87.930  0.1252    95.658  349.54
  51   0.4644     87.670  0.1181    95.964  356.51
  52   0.4467     87.820  0.1170    95.898  363.50
  53   0.4519     87.910  0.1136    96.000  370.46
  54   0.4407     88.260  0.1062    96.304  377.37
  55   0.4642     87.730  0.1047    96.350  384.30
  56   0.4441     88.020  0.1000    96.478  391.29
  57   0.4648     88.050  0.0936    96.786  398.26
  58   0.4530     88.160  0.0896    96.874  405.18
  59   0.4556     88.160  0.0888    96.918  412.11
  60   0.4616     88.140  0.0841    97.178  419.05
  61   0.4592     88.170  0.0836    97.184  425.99
  62   0.4613     88.250  0.0801    97.234  432.98
  63   0.4552     88.330  0.0726    97.614  439.99
  64   0.4832     88.240  0.0733    97.514  446.93
  65   0.4679     88.410  0.0688    97.674  453.87
  66   0.4664     88.440  0.0684    97.712  460.80
  67   0.4732     88.120  0.0636    97.914  467.74
  68   0.4801     88.390  0.0633    97.934  474.72
  69   0.4761     88.680  0.0598    97.928  481.67
  70   0.4769     88.240  0.0565    98.156  488.58
  71   0.4769     88.640  0.0542    98.242  495.50
  72   0.4798     88.520  0.0550    98.218  502.40
  73   0.4877     88.550  0.0532    98.226  509.41
  74   0.4914     88.320  0.0509    98.302  516.38
  75   0.4866     88.630  0.0513    98.288  523.36
  76   0.4812     88.460  0.0489    98.464  530.27
  77   0.4840     88.660  0.0467    98.456  537.22
  78   0.4871     88.650  0.0464    98.474  544.19
  79   0.4935     88.650  0.0450    98.586  551.16
  80   0.4983     88.480  0.0417    98.686  558.09
  81   0.4870     88.590  0.0431    98.616  565.08
  82   0.4907     88.550  0.0421    98.660  572.08
  83   0.4976     88.610  0.0409    98.708  578.99
  84   0.4987     88.720  0.0407    98.700  585.91
  85   0.5091     88.500  0.0405    98.710  592.87
