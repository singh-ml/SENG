Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8234     31.820  2.0572    24.016  8.83
   2   1.5918     40.690  1.7240    35.936  15.82
   3   1.4579     45.950  1.5517    42.522  22.82
   4   1.3475     50.930  1.4339    47.094  29.78
   5   1.2700     53.970  1.3382    50.822  36.74
   6   1.1888     56.900  1.2559    54.144  43.72
   7   1.1248     59.280  1.1807    57.252  50.74
   8   1.0641     61.520  1.1129    59.822  57.73
   9   1.0213     63.490  1.0553    62.372  64.64
  10   0.9851     64.990  1.0048    64.158  71.60
  11   0.9460     66.600  0.9575    65.656  78.53
  12   0.9018     68.050  0.9179    67.300  85.46
  13   0.8841     68.740  0.8795    68.500  92.45
  14   0.8496     70.270  0.8504    69.572  99.39
  15   0.8235     70.740  0.8182    70.846  106.32
  16   0.8103     71.760  0.7966    71.788  113.29
  17   0.7813     72.670  0.7699    72.814  120.20
  18   0.7775     72.910  0.7468    73.496  127.18
  19   0.7425     73.490  0.7283    74.168  134.15
  20   0.7355     74.330  0.7077    74.898  141.10
  21   0.7047     75.840  0.6831    76.042  148.00
  22   0.7011     75.830  0.6676    76.344  154.96
  23   0.6893     76.080  0.6448    77.330  161.95
  24   0.6684     76.680  0.6312    78.038  168.90
  25   0.6630     77.220  0.6155    78.384  175.86
  26   0.6521     77.250  0.5967    78.910  182.81
  27   0.6361     77.860  0.5803    79.492  189.75
  28   0.6203     78.560  0.5637    80.148  196.77
  29   0.6132     78.810  0.5525    80.596  203.71
  30   0.5962     79.500  0.5345    81.164  210.65
  31   0.5975     79.730  0.5250    81.506  217.57
  32   0.5836     79.830  0.5123    82.040  224.55
  33   0.5824     79.900  0.4941    82.746  231.50
  34   0.5661     80.450  0.4845    83.054  238.43
  35   0.5634     80.500  0.4703    83.446  245.40
  36   0.5570     80.910  0.4640    83.746  252.32
  37   0.5459     81.760  0.4510    84.128  259.25
  38   0.5411     81.260  0.4449    84.476  266.18
  39   0.5349     82.270  0.4346    84.920  273.18
  40   0.5284     81.910  0.4254    85.160  280.11
  41   0.5326     82.330  0.4167    85.446  287.03
  42   0.5191     82.650  0.4057    85.780  293.94
  43   0.5248     82.450  0.4006    86.030  300.86
  44   0.5279     82.320  0.3935    86.184  307.89
  45   0.5031     82.850  0.3851    86.484  314.84
  46   0.5004     82.740  0.3773    86.886  321.81
  47   0.5004     83.350  0.3670    87.182  328.76
  48   0.5004     83.550  0.3574    87.408  335.68
  49   0.5102     83.350  0.3521    87.688  342.70
  50   0.4920     83.570  0.3428    88.042  349.57
  51   0.4974     83.680  0.3420    88.092  356.50
  52   0.4949     83.640  0.3347    88.374  363.46
  53   0.4871     83.990  0.3295    88.346  370.41
  54   0.4948     83.860  0.3188    88.880  377.40
  55   0.4891     83.680  0.3158    88.972  384.33
  56   0.4926     84.020  0.3068    89.320  391.28
  57   0.4825     84.790  0.2990    89.520  398.21
  58   0.4910     84.200  0.2973    89.616  405.13
  59   0.4843     84.270  0.2955    89.726  412.16
  60   0.4805     84.640  0.2861    89.954  419.12
  61   0.4749     84.540  0.2764    90.366  426.03
  62   0.4764     84.950  0.2746    90.350  432.97
  63   0.4650     85.040  0.2694    90.528  439.96
  64   0.4780     84.900  0.2647    90.708  446.97
  65   0.4791     84.690  0.2604    90.800  453.93
  66   0.4848     84.930  0.2572    90.952  460.89
  67   0.4840     85.290  0.2505    91.184  467.85
  68   0.4733     85.060  0.2464    91.326  474.81
  69   0.4783     85.030  0.2410    91.540  481.77
  70   0.4818     85.440  0.2360    91.842  488.83
  71   0.4818     85.390  0.2342    91.828  495.77
  72   0.4762     85.610  0.2267    92.116  502.72
  73   0.4742     85.800  0.2215    92.262  509.64
  74   0.4865     85.460  0.2175    92.340  516.56
  75   0.4699     85.960  0.2165    92.400  523.59
  76   0.4826     85.880  0.2092    92.628  530.52
  77   0.4920     85.510  0.2071    92.668  537.48
  78   0.4862     85.400  0.2052    92.804  544.40
  79   0.4801     85.790  0.2010    92.836  551.34
  80   0.4830     85.680  0.1954    93.140  558.33
  81   0.4880     85.720  0.1912    93.168  565.25
  82   0.5011     85.910  0.1883    93.336  572.20
  83   0.4836     85.970  0.1820    93.562  579.16
  84   0.5086     85.590  0.1802    93.746  586.20
  85   0.4945     85.930  0.1777    93.686  593.15
