Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3958     48.130  1.7072    36.592  8.82
   2   1.1463     58.250  1.2864    53.182  15.85
   3   0.9850     64.820  1.0515    62.350  22.81
   4   0.8499     69.490  0.9131    67.464  29.87
   5   0.7641     72.810  0.8154    70.900  36.89
   6   0.7042     75.470  0.7361    73.802  43.90
   7   0.6710     76.620  0.6656    76.282  50.91
   8   0.6333     78.490  0.6046    78.790  57.89
   9   0.6142     79.200  0.5704    80.144  64.99
  10   0.5760     80.290  0.5278    81.624  72.01
  11   0.5279     81.830  0.4901    82.962  79.00
  12   0.5071     82.340  0.4637    83.870  85.97
  13   0.5161     82.400  0.4381    84.612  92.98
  14   0.4913     83.590  0.4171    85.418  99.98
  15   0.4831     83.780  0.3971    86.098  107.02
  16   0.4979     83.830  0.3710    87.190  114.04
  17   0.4764     84.820  0.3532    87.862  121.05
  18   0.4621     85.120  0.3393    88.086  128.12
  19   0.4497     85.540  0.3271    88.506  135.12
  20   0.4791     84.220  0.3110    89.316  142.09
  21   0.4324     85.380  0.3007    89.392  149.09
  22   0.4474     85.680  0.2817    90.154  156.11
  23   0.4311     85.960  0.2715    90.482  163.17
  24   0.4271     85.960  0.2577    91.058  170.19
  25   0.4269     86.160  0.2501    91.366  177.16
  26   0.4190     86.750  0.2411    91.660  184.18
  27   0.4466     85.790  0.2278    91.992  191.19
  28   0.4290     86.920  0.2183    92.272  198.28
  29   0.4705     85.550  0.2071    92.726  205.27
  30   0.4461     86.510  0.1983    93.024  212.25
  31   0.4159     87.480  0.1908    93.346  219.27
  32   0.4309     86.990  0.1811    93.644  226.25
  33   0.4162     87.270  0.1798    93.586  233.35
  34   0.4222     87.250  0.1648    94.244  240.32
  35   0.4259     87.240  0.1588    94.366  247.33
  36   0.4290     87.650  0.1478    94.860  254.34
  37   0.4552     87.280  0.1422    94.934  261.34
  38   0.4229     88.110  0.1350    95.192  268.40
  39   0.4461     87.430  0.1290    95.432  275.40
  40   0.4190     88.350  0.1226    95.724  282.42
  41   0.4377     87.690  0.1192    95.804  289.43
  42   0.4376     87.820  0.1137    96.012  296.44
  43   0.4360     88.060  0.1061    96.238  303.50
  44   0.4354     88.380  0.1047    96.264  310.52
  45   0.4634     87.460  0.0958    96.762  317.52
  46   0.4487     88.370  0.1001    96.378  324.52
  47   0.4487     88.320  0.0835    97.034  331.53
  48   0.4499     88.450  0.0840    97.074  338.54
  49   0.4738     88.250  0.0768    97.408  345.54
  50   0.4290     89.110  0.0721    97.558  352.44
  51   0.4487     88.560  0.0710    97.558  359.43
  52   0.4361     89.000  0.0683    97.606  366.44
  53   0.4728     88.760  0.0653    97.780  373.48
  54   0.4680     88.420  0.0620    97.888  380.46
  55   0.4687     88.480  0.0556    98.154  387.47
  56   0.4593     88.650  0.0543    98.206  394.48
  57   0.4566     88.730  0.0525    98.268  401.55
  58   0.4677     89.040  0.0454    98.562  408.52
  59   0.4763     88.790  0.0446    98.546  415.54
  60   0.4583     89.230  0.0415    98.692  422.55
  61   0.4582     88.990  0.0376    98.830  429.54
  62   0.4688     89.060  0.0369    98.804  436.62
  63   0.4629     89.320  0.0338    98.946  443.58
  64   0.4659     89.250  0.0353    98.868  450.57
  65   0.4841     89.420  0.0329    98.992  457.59
  66   0.4597     89.300  0.0317    98.988  464.59
  67   0.4596     89.710  0.0269    99.230  471.68
  68   0.4636     89.700  0.0271    99.156  478.64
  69   0.4710     89.430  0.0258    99.242  485.62
  70   0.4693     89.190  0.0245    99.250  492.64
  71   0.4605     89.910  0.0225    99.368  499.64
  72   0.4745     89.500  0.0211    99.432  506.67
  73   0.4835     89.460  0.0198    99.464  513.65
  74   0.4778     89.610  0.0190    99.454  520.65
  75   0.4707     89.760  0.0188    99.472  527.66
  76   0.4794     89.830  0.0194    99.422  534.67
  77   0.4827     89.620  0.0165    99.582  541.80
  78   0.4692     89.980  0.0164    99.600  548.78
  79   0.4842     89.580  0.0176    99.508  555.77
  80   0.4828     89.960  0.0142    99.606  562.79
  81   0.4766     89.790  0.0145    99.628  569.91
  82   0.4851     89.880  0.0132    99.666  576.92
  83   0.4804     89.720  0.0146    99.614  583.90
  84   0.4915     89.520  0.0132    99.670  590.91
  85   0.4810     89.840  0.0138    99.650  597.89
  86   0.4707     89.810  0.0129    99.686  604.98
  87   0.4782     89.750  0.0122    99.728  611.98
  88   0.4869     89.490  0.0124    99.738  618.99
  89   0.4803     89.830  0.0121    99.710  625.99
  90   0.4808     89.860  0.0114    99.742  633.02
