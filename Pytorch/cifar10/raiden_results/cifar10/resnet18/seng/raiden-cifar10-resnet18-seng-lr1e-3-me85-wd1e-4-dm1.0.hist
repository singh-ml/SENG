Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8272     31.080  2.0750    23.306  8.76
   2   1.5987     40.110  1.7186    36.148  15.72
   3   1.4867     44.160  1.5671    41.650  22.75
   4   1.3908     48.010  1.4666    45.620  29.70
   5   1.3220     51.010  1.3857    48.754  36.68
   6   1.2551     53.910  1.3178    51.770  43.69
   7   1.1991     56.630  1.2596    53.896  50.65
   8   1.1512     58.150  1.2070    56.176  57.69
   9   1.0995     60.460  1.1478    58.358  64.67
  10   1.0556     61.920  1.0956    60.418  71.60
  11   1.0133     64.000  1.0472    62.432  78.55
  12   0.9772     65.050  1.0106    63.816  85.53
  13   0.9457     66.050  0.9751    64.964  92.49
  14   0.9098     67.290  0.9354    66.258  99.53
  15   0.8933     67.850  0.9026    67.542  106.49
  16   0.8614     69.210  0.8765    68.540  113.47
  17   0.8395     70.000  0.8455    69.784  120.46
  18   0.8323     70.330  0.8272    70.524  127.42
  19   0.8035     71.420  0.8011    71.420  134.51
  20   0.7946     71.610  0.7803    72.238  141.50
  21   0.7757     72.080  0.7620    72.810  148.48
  22   0.7580     73.170  0.7390    73.588  155.47
  23   0.7485     73.370  0.7285    73.942  162.46
  24   0.7340     73.770  0.7026    75.216  169.50
  25   0.7271     74.240  0.6900    75.498  176.45
  26   0.7030     75.490  0.6750    76.278  183.44
  27   0.6989     75.310  0.6548    76.908  190.38
  28   0.6864     76.140  0.6416    77.288  197.32
  29   0.6734     76.710  0.6286    77.708  204.35
  30   0.6638     76.970  0.6107    78.262  211.34
  31   0.6481     77.710  0.5987    78.976  218.31
  32   0.6424     77.470  0.5832    79.446  225.27
  33   0.6347     78.290  0.5682    80.130  232.26
  34   0.6194     78.260  0.5586    80.446  239.25
  35   0.6264     78.430  0.5504    80.542  246.21
  36   0.6092     79.300  0.5362    81.054  253.16
  37   0.5983     79.180  0.5295    81.396  260.13
  38   0.5910     79.700  0.5137    81.990  267.11
  39   0.5858     79.760  0.5028    82.354  274.13
  40   0.5803     80.030  0.4964    82.764  281.12
  41   0.5762     80.760  0.4900    82.776  288.11
  42   0.5637     81.110  0.4750    83.400  295.09
  43   0.5631     81.070  0.4643    83.692  302.07
  44   0.5627     80.970  0.4592    83.800  309.12
  45   0.5620     81.030  0.4525    84.036  316.10
  46   0.5564     81.540  0.4431    84.694  323.08
  47   0.5473     81.970  0.4330    84.662  330.08
  48   0.5350     82.280  0.4264    85.126  337.05
  49   0.5396     81.970  0.4165    85.530  344.03
  50   0.5298     82.120  0.4096    85.802  350.98
  51   0.5414     81.710  0.4081    85.794  357.93
  52   0.5148     82.900  0.4018    86.062  364.87
  53   0.5214     83.080  0.3943    86.154  371.83
  54   0.5205     82.880  0.3884    86.368  378.81
  55   0.5195     83.020  0.3809    86.534  385.83
  56   0.5193     83.000  0.3710    87.054  392.79
  57   0.5168     82.970  0.3653    87.234  399.76
  58   0.5102     83.100  0.3633    87.280  406.74
  59   0.5025     83.450  0.3545    87.618  413.76
  60   0.5005     83.280  0.3474    87.838  420.72
  61   0.4982     83.900  0.3420    88.056  427.70
  62   0.4906     83.920  0.3398    88.156  434.68
  63   0.4913     83.900  0.3309    88.374  441.63
  64   0.5023     83.720  0.3222    88.702  448.62
  65   0.4989     83.700  0.3149    89.038  455.62
  66   0.4981     84.280  0.3166    89.006  462.60
  67   0.4940     84.230  0.3055    89.406  469.52
  68   0.4921     84.640  0.3018    89.568  476.45
  69   0.4965     83.720  0.3015    89.452  483.49
  70   0.4968     84.220  0.2955    89.610  490.49
  71   0.4807     84.500  0.2904    89.800  497.51
  72   0.4870     84.540  0.2843    90.028  504.49
  73   0.4933     84.540  0.2869    89.914  511.47
  74   0.4825     84.790  0.2718    90.596  518.45
  75   0.5118     83.930  0.2707    90.692  525.48
  76   0.4910     84.780  0.2670    90.596  532.44
  77   0.4867     84.960  0.2601    90.942  539.41
  78   0.5042     84.560  0.2590    90.792  546.38
  79   0.4994     84.480  0.2529    91.238  553.36
  80   0.4958     84.930  0.2484    91.162  560.39
  81   0.4844     84.900  0.2484    91.304  567.38
  82   0.4927     85.190  0.2399    91.662  574.37
  83   0.5011     85.070  0.2392    91.714  581.31
  84   0.4988     84.910  0.2339    91.728  588.26
  85   0.4864     85.520  0.2291    91.958  595.21
