Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8877     28.650  2.1178    22.518  8.79
   2   1.6543     38.750  1.7866    33.956  15.81
   3   1.5337     42.650  1.6323    39.208  22.78
   4   1.4549     46.000  1.5281    43.306  29.73
   5   1.3637     49.640  1.4368    46.902  36.65
   6   1.2856     53.030  1.3537    50.512  43.62
   7   1.2332     54.840  1.2826    53.540  50.64
   8   1.1783     57.230  1.2234    55.444  57.62
   9   1.1341     59.000  1.1752    57.376  64.58
  10   1.0965     60.390  1.1273    59.234  71.51
  11   1.0606     61.990  1.0857    61.072  78.44
  12   1.0260     63.060  1.0504    62.236  85.45
  13   1.0031     64.190  1.0160    63.480  92.36
  14   0.9723     65.230  0.9892    64.612  99.31
  15   0.9504     66.200  0.9591    65.646  106.24
  16   0.9190     67.000  0.9296    66.786  113.16
  17   0.9014     67.840  0.9015    67.606  120.21
  18   0.8814     68.530  0.8799    68.606  127.16
  19   0.8592     69.200  0.8589    69.446  134.10
  20   0.8457     70.010  0.8379    69.978  141.10
  21   0.8374     70.130  0.8193    70.734  148.05
  22   0.8159     70.890  0.7989    71.718  155.04
  23   0.8019     71.180  0.7812    72.218  161.97
  24   0.7840     72.080  0.7634    72.872  168.88
  25   0.7736     72.630  0.7512    73.558  175.79
  26   0.7622     73.070  0.7265    74.368  182.73
  27   0.7445     73.730  0.7177    74.522  189.73
  28   0.7310     73.910  0.7020    75.036  196.65
  29   0.7263     74.210  0.6868    75.610  203.61
  30   0.7169     74.900  0.6744    76.138  210.57
  31   0.7004     75.320  0.6596    76.582  217.51
  32   0.6919     75.580  0.6505    77.006  224.52
  33   0.6846     75.820  0.6323    77.692  231.48
  34   0.6687     76.660  0.6218    78.094  238.44
  35   0.6771     76.570  0.6089    78.540  245.39
  36   0.6600     76.660  0.5973    78.880  252.32
  37   0.6525     77.240  0.5863    79.240  259.30
  38   0.6389     77.830  0.5740    79.976  266.25
  39   0.6439     77.730  0.5652    80.126  273.21
  40   0.6340     77.780  0.5541    80.394  280.17
  41   0.6158     78.460  0.5452    80.816  287.14
  42   0.6115     78.670  0.5305    81.498  294.19
  43   0.6112     78.770  0.5225    81.698  301.11
  44   0.6006     79.580  0.5170    81.770  308.03
  45   0.5958     79.690  0.5039    82.392  314.94
  46   0.5975     79.480  0.4941    82.658  321.91
  47   0.5913     79.810  0.4891    83.042  328.85
  48   0.5814     80.160  0.4789    83.222  335.83
  49   0.5801     80.230  0.4700    83.402  342.79
  50   0.5782     80.380  0.4609    83.832  349.61
  51   0.5601     80.700  0.4535    84.256  356.52
  52   0.5547     81.060  0.4514    84.178  363.44
  53   0.5583     81.180  0.4373    84.626  370.44
  54   0.5539     80.800  0.4333    84.800  377.40
  55   0.5499     81.080  0.4258    85.018  384.36
  56   0.5428     81.610  0.4171    85.376  391.27
  57   0.5442     81.230  0.4117    85.716  398.19
  58   0.5433     81.500  0.4093    85.676  405.16
  59   0.5320     81.760  0.3990    86.044  412.08
  60   0.5312     82.280  0.3929    86.250  419.05
  61   0.5365     81.970  0.3864    86.422  426.01
  62   0.5284     82.470  0.3778    86.836  432.92
  63   0.5305     82.430  0.3808    86.660  439.90
  64   0.5296     82.530  0.3726    86.938  446.82
  65   0.5215     82.720  0.3645    87.212  453.78
  66   0.5253     82.450  0.3613    87.312  460.72
  67   0.5174     82.910  0.3550    87.570  467.71
  68   0.5314     82.570  0.3488    87.754  474.74
  69   0.5124     83.310  0.3456    87.944  481.65
  70   0.5172     83.530  0.3364    88.252  488.59
  71   0.5156     82.970  0.3315    88.338  495.50
  72   0.5078     83.460  0.3260    88.632  502.44
  73   0.5129     83.220  0.3242    88.726  509.48
  74   0.5138     83.480  0.3179    88.880  516.41
  75   0.5137     83.560  0.3115    89.126  523.36
  76   0.5074     83.710  0.3070    89.200  530.32
  77   0.5013     83.710  0.3030    89.276  537.28
  78   0.5153     83.330  0.3004    89.458  544.22
  79   0.5101     83.980  0.2949    89.690  551.22
  80   0.5126     83.630  0.2912    89.622  558.17
  81   0.5124     83.920  0.2839    90.070  565.10
  82   0.5039     83.970  0.2810    90.162  572.05
  83   0.5206     83.890  0.2774    90.264  579.00
  84   0.5220     83.910  0.2717    90.466  585.90
  85   0.5156     84.140  0.2686    90.422  592.88
