Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7649     33.640  2.0324    23.538  8.64
   2   1.5584     41.290  1.6720    37.448  15.58
   3   1.4342     46.880  1.5247    42.846  22.58
   4   1.3241     51.150  1.4129    47.604  29.54
   5   1.2330     55.140  1.3140    51.730  36.48
   6   1.1691     57.610  1.2269    55.254  43.38
   7   1.1025     60.050  1.1600    57.828  50.27
   8   1.0625     61.640  1.1009    60.554  57.29
   9   1.0155     63.490  1.0487    62.134  64.18
  10   0.9897     64.830  1.0006    64.050  71.10
  11   0.9434     66.490  0.9592    65.502  78.00
  12   0.9152     67.540  0.9244    66.938  84.92
  13   0.8755     69.200  0.8905    68.040  91.94
  14   0.8767     69.110  0.8570    69.532  98.85
  15   0.8414     70.660  0.8299    70.574  105.77
  16   0.8055     71.510  0.8020    71.660  112.67
  17   0.7980     72.140  0.7774    72.428  119.60
  18   0.7705     72.840  0.7560    73.176  126.64
  19   0.7586     72.920  0.7306    74.134  133.54
  20   0.7417     73.990  0.7119    74.812  140.49
  21   0.7161     75.140  0.6903    75.430  147.43
  22   0.7089     75.600  0.6674    76.334  154.41
  23   0.6935     76.060  0.6499    77.050  161.37
  24   0.6779     76.000  0.6311    77.620  168.34
  25   0.6600     77.200  0.6142    78.500  175.26
  26   0.6449     77.410  0.5977    78.822  182.18
  27   0.6431     78.100  0.5839    79.284  189.21
  28   0.6270     78.430  0.5682    79.956  196.16
  29   0.6138     78.900  0.5534    80.642  203.12
  30   0.6104     78.530  0.5412    80.886  210.08
  31   0.6096     79.320  0.5261    81.526  216.97
  32   0.6025     79.650  0.5132    81.892  223.97
  33   0.5887     79.750  0.5034    82.398  230.87
  34   0.5778     80.120  0.4919    82.656  237.77
  35   0.5751     80.480  0.4780    83.148  244.67
  36   0.5704     80.840  0.4684    83.546  251.59
  37   0.5577     81.510  0.4564    84.068  258.56
  38   0.5492     81.300  0.4489    84.176  265.48
  39   0.5567     81.150  0.4402    84.488  272.41
  40   0.5492     81.280  0.4294    84.954  279.31
  41   0.5343     82.000  0.4189    85.326  286.26
  42   0.5381     82.120  0.4105    85.482  293.28
  43   0.5294     82.240  0.4012    86.056  300.18
  44   0.5530     81.770  0.3939    86.144  307.10
  45   0.5220     82.480  0.3845    86.624  313.99
  46   0.5204     82.700  0.3812    86.824  320.92
  47   0.5188     82.720  0.3704    87.006  327.91
  48   0.5256     82.620  0.3631    87.316  334.82
  49   0.5130     83.160  0.3567    87.646  341.77
  50   0.5076     83.530  0.3484    87.826  348.60
  51   0.4982     83.880  0.3440    87.848  355.63
  52   0.5045     83.870  0.3339    88.250  362.65
  53   0.5134     83.470  0.3273    88.432  369.59
  54   0.4913     84.420  0.3239    88.788  376.54
  55   0.5012     83.900  0.3139    89.202  383.44
  56   0.4982     83.940  0.3068    89.206  390.35
  57   0.4998     83.990  0.3053    89.180  397.37
  58   0.4950     84.300  0.2924    89.750  404.25
  59   0.4956     84.280  0.2977    89.596  411.20
  60   0.5013     84.300  0.2869    89.796  418.13
  61   0.4909     84.290  0.2815    90.174  425.04
  62   0.4915     84.550  0.2702    90.612  431.97
  63   0.4996     84.650  0.2710    90.506  438.88
  64   0.5027     84.620  0.2642    90.626  445.82
  65   0.5051     84.220  0.2574    90.864  452.71
  66   0.5081     84.540  0.2566    91.008  459.65
  67   0.4994     84.710  0.2508    91.170  466.67
  68   0.5027     84.890  0.2464    91.360  473.61
  69   0.4900     84.750  0.2414    91.536  480.54
  70   0.4954     85.030  0.2362    91.914  487.47
  71   0.4988     85.210  0.2349    91.766  494.42
  72   0.4920     85.310  0.2215    92.190  501.39
  73   0.5079     85.120  0.2195    92.202  508.28
  74   0.4952     85.550  0.2162    92.300  515.22
  75   0.4911     84.970  0.2170    92.284  522.13
  76   0.4882     85.270  0.2073    92.758  529.05
  77   0.4914     85.860  0.2044    92.720  535.99
  78   0.4990     85.400  0.2028    92.870  542.94
  79   0.5231     85.070  0.1962    93.070  549.85
  80   0.5039     85.690  0.1951    93.162  556.75
  81   0.5170     85.080  0.1890    93.306  563.67
  82   0.5046     85.450  0.1853    93.504  570.72
  83   0.5095     85.490  0.1776    93.790  577.63
  84   0.4907     85.920  0.1768    93.730  584.53
  85   0.5038     85.470  0.1693    94.034  591.44
  86   0.5037     86.210  0.1707    94.036  598.37
  87   0.5184     85.690  0.1637    94.418  605.35
  88   0.5022     86.020  0.1625    94.232  612.24
  89   0.5265     85.910  0.1544    94.498  619.18
  90   0.5331     85.770  0.1565    94.426  626.08
