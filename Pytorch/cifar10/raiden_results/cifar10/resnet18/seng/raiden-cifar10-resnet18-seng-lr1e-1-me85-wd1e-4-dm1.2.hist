Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1616     58.750  1.4443    46.938  8.66
   2   0.8475     70.010  0.9253    66.968  15.60
   3   0.6549     77.360  0.7168    74.922  22.58
   4   0.5922     80.010  0.6008    79.016  29.52
   5   0.5129     82.250  0.5233    81.794  36.46
   6   0.4993     82.750  0.4660    83.916  43.40
   7   0.4817     84.090  0.4254    85.252  50.36
   8   0.4725     84.210  0.3806    86.914  57.34
   9   0.4740     84.120  0.3506    87.858  64.29
  10   0.4537     85.580  0.3279    88.616  71.21
  11   0.3744     87.510  0.2944    89.836  78.15
  12   0.3954     87.300  0.2798    90.300  85.10
  13   0.3991     87.160  0.2653    90.850  92.13
  14   0.3957     86.900  0.2392    91.644  99.08
  15   0.3754     88.260  0.2288    91.978  106.01
  16   0.3581     88.880  0.2046    92.796  112.92
  17   0.4276     87.650  0.1981    93.076  119.92
  18   0.3761     88.630  0.1802    93.824  126.83
  19   0.3668     88.600  0.1735    93.978  133.73
  20   0.3568     88.940  0.1654    94.116  140.65
  21   0.4179     88.300  0.1531    94.600  147.56
  22   0.3934     88.560  0.1452    94.854  154.61
  23   0.4083     88.790  0.1325    95.320  161.53
  24   0.3515     89.860  0.1311    95.368  168.43
  25   0.3373     90.020  0.1223    95.824  175.37
  26   0.3470     89.900  0.1045    96.324  182.31
  27   0.3502     90.420  0.1040    96.336  189.29
  28   0.3738     90.180  0.0927    96.748  196.26
  29   0.3574     90.500  0.0844    96.954  203.20
  30   0.3762     90.420  0.0865    96.898  210.11
  31   0.3726     90.710  0.0759    97.312  217.02
  32   0.4024     89.910  0.0774    97.258  224.06
  33   0.3514     90.890  0.0648    97.746  231.00
  34   0.3817     90.590  0.0629    97.758  237.91
  35   0.3801     90.640  0.0615    97.834  244.84
  36   0.3907     90.810  0.0599    97.926  251.76
  37   0.3727     91.200  0.0503    98.276  258.73
  38   0.3409     92.030  0.0516    98.184  265.64
  39   0.4026     91.060  0.0428    98.498  272.57
  40   0.3251     92.130  0.0394    98.654  279.48
  41   0.3563     91.880  0.0329    98.932  286.39
  42   0.3649     91.800  0.0359    98.706  293.40
  43   0.3648     91.830  0.0328    98.870  300.34
  44   0.3843     91.640  0.0277    99.042  307.25
  45   0.3787     92.030  0.0246    99.210  314.17
  46   0.3700     91.580  0.0240    99.194  321.17
  47   0.3581     92.150  0.0181    99.408  328.09
  48   0.3763     91.800  0.0157    99.496  335.04
  49   0.3427     92.540  0.0125    99.640  341.95
  50   0.3412     92.710  0.0117    99.650  348.79
  51   0.3624     92.260  0.0126    99.602  355.70
  52   0.3540     92.700  0.0116    99.666  362.69
  53   0.3465     92.630  0.0095    99.694  369.60
  54   0.3399     92.900  0.0067    99.818  376.54
  55   0.3438     92.870  0.0047    99.882  383.45
  56   0.3339     93.000  0.0049    99.878  390.37
  57   0.3304     93.010  0.0046    99.892  397.38
  58   0.3324     93.170  0.0040    99.900  404.31
  59   0.3356     93.160  0.0030    99.930  411.26
  60   0.3296     93.350  0.0027    99.932  418.17
  61   0.3255     93.450  0.0026    99.946  425.18
  62   0.3199     93.500  0.0022    99.960  432.09
  63   0.3217     93.510  0.0020    99.964  439.02
  64   0.3190     93.590  0.0019    99.964  445.97
  65   0.3182     93.460  0.0016    99.984  452.92
  66   0.3206     93.320  0.0015    99.984  459.86
  67   0.3183     93.510  0.0014    99.986  466.82
  68   0.3158     93.510  0.0014    99.982  473.75
  69   0.3201     93.490  0.0012    99.990  480.65
  70   0.3233     93.440  0.0012    99.992  487.59
  71   0.3197     93.500  0.0010    99.996  494.62
  72   0.3176     93.480  0.0011    99.992  501.56
  73   0.3203     93.540  0.0011    99.994  508.49
  74   0.3209     93.550  0.0011    99.988  515.42
  75   0.3179     93.560  0.0011    99.988  522.34
  76   0.3165     93.640  0.0012    99.984  529.33
  77   0.3170     93.560  0.0010    99.994  536.27
  78   0.3178     93.510  0.0012    99.990  543.19
  79   0.3146     93.470  0.0011    99.984  550.13
  80   0.3165     93.580  0.0010    99.994  557.05
  81   0.3167     93.600  0.0011    99.998  564.02
  82   0.3174     93.530  0.0010    99.990  570.93
  83   0.3166     93.630  0.0010    99.996  577.85
  84   0.3162     93.570  0.0010    99.996  584.79
  85   0.3146     93.450  0.0009    99.994  591.70
