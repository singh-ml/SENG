Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4597     45.140  1.7750    33.984  8.73
   2   1.2401     55.100  1.3644    49.832  15.80
   3   1.0709     61.140  1.1748    57.498  22.73
   4   0.9551     65.930  1.0323    63.054  29.67
   5   0.8803     68.630  0.9241    67.052  36.62
   6   0.8365     70.730  0.8548    69.574  43.55
   7   0.7701     72.500  0.7821    72.164  50.50
   8   0.7124     74.510  0.7279    74.446  57.50
   9   0.6937     75.600  0.6763    76.324  64.45
  10   0.6445     77.780  0.6281    78.044  71.38
  11   0.6087     79.120  0.5922    79.246  78.29
  12   0.5997     79.620  0.5605    80.484  85.22
  13   0.5709     80.190  0.5331    81.346  92.27
  14   0.5468     81.380  0.5000    82.624  99.20
  15   0.5478     81.470  0.4771    83.368  106.18
  16   0.5430     81.420  0.4597    84.006  113.15
  17   0.5182     82.610  0.4449    84.500  120.10
  18   0.5292     82.560  0.4175    85.396  127.08
  19   0.5097     82.860  0.4024    85.990  133.99
  20   0.4821     83.920  0.3867    86.514  140.97
  21   0.4686     84.190  0.3682    87.100  147.88
  22   0.4864     83.620  0.3550    87.626  154.85
  23   0.4738     84.400  0.3434    87.960  161.91
  24   0.4581     84.740  0.3330    88.424  168.84
  25   0.4831     84.210  0.3182    88.962  175.76
  26   0.4625     85.050  0.3066    89.280  182.71
  27   0.4705     85.230  0.2919    89.810  189.70
  28   0.4700     84.920  0.2859    90.040  196.63
  29   0.4638     85.460  0.2739    90.448  203.59
  30   0.4580     85.700  0.2694    90.520  210.53
  31   0.4394     86.220  0.2531    91.056  217.50
  32   0.4543     86.130  0.2447    91.416  224.46
  33   0.4659     85.500  0.2344    91.840  231.48
  34   0.4574     85.770  0.2283    92.064  238.40
  35   0.4608     85.960  0.2214    92.272  245.33
  36   0.4598     86.250  0.2120    92.626  252.28
  37   0.4529     86.160  0.2076    92.864  259.22
  38   0.4557     86.480  0.1983    93.004  266.28
  39   0.4728     85.910  0.1958    93.004  273.21
  40   0.4630     86.750  0.1868    93.462  280.17
  41   0.4535     86.600  0.1805    93.604  287.13
  42   0.4754     86.140  0.1706    94.046  294.05
  43   0.4776     86.220  0.1666    94.144  300.95
  44   0.4575     86.760  0.1609    94.410  308.01
  45   0.4736     87.030  0.1540    94.646  314.93
  46   0.4765     86.630  0.1499    94.768  321.89
  47   0.4619     87.060  0.1371    95.226  328.84
  48   0.4800     86.720  0.1349    95.208  335.79
  49   0.4695     86.690  0.1291    95.526  342.79
  50   0.4614     87.550  0.1224    95.636  349.60
  51   0.4627     87.220  0.1203    95.800  356.57
  52   0.4694     87.230  0.1155    95.978  363.49
  53   0.4831     87.380  0.1154    95.992  370.44
  54   0.4761     87.470  0.1082    96.202  377.39
  55   0.4748     87.440  0.1011    96.488  384.35
  56   0.4904     87.100  0.0975    96.700  391.30
  57   0.4750     87.550  0.0970    96.620  398.24
  58   0.4873     87.520  0.0931    96.812  405.20
  59   0.4872     87.340  0.0884    96.954  412.19
  60   0.4865     87.560  0.0824    97.142  419.16
  61   0.4971     87.600  0.0818    97.174  426.13
  62   0.4858     87.490  0.0803    97.250  433.08
  63   0.5085     87.520  0.0745    97.496  440.08
  64   0.4918     87.770  0.0742    97.466  447.05
  65   0.4984     87.540  0.0707    97.594  454.01
  66   0.5098     88.020  0.0676    97.718  460.93
  67   0.5242     87.660  0.0669    97.788  467.84
  68   0.5246     87.610  0.0635    97.916  474.76
  69   0.5037     87.940  0.0605    97.936  481.80
  70   0.5061     88.200  0.0577    98.102  488.74
  71   0.5131     88.080  0.0585    98.022  495.70
  72   0.5200     87.570  0.0538    98.218  502.62
  73   0.5241     87.650  0.0531    98.224  509.56
  74   0.5219     87.860  0.0513    98.314  516.57
  75   0.5158     87.900  0.0516    98.334  523.48
  76   0.5206     87.750  0.0506    98.312  530.41
  77   0.5378     88.070  0.0479    98.390  537.35
  78   0.5394     87.960  0.0460    98.518  544.28
  79   0.5313     87.940  0.0461    98.488  551.26
  80   0.5315     88.010  0.0465    98.432  558.29
  81   0.5399     87.800  0.0426    98.686  565.22
  82   0.5435     87.730  0.0436    98.578  572.22
  83   0.5488     88.100  0.0418    98.680  579.19
  84   0.5461     88.220  0.0407    98.724  586.10
  85   0.5557     87.870  0.0395    98.742  593.11
