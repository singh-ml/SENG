Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3840     49.180  1.6655    37.834  8.69
   2   1.0654     62.270  1.2100    56.046  15.61
   3   0.8723     69.100  0.9908    64.494  22.51
   4   0.7807     72.480  0.8482    69.760  29.45
   5   0.7361     73.770  0.7441    73.596  36.39
   6   0.6691     76.710  0.6647    76.312  43.36
   7   0.6274     78.330  0.6073    78.616  50.40
   8   0.6147     78.230  0.5618    80.270  57.35
   9   0.5557     80.770  0.5182    81.894  64.29
  10   0.5409     81.560  0.4844    83.182  71.21
  11   0.4956     83.210  0.4577    83.914  78.12
  12   0.5000     82.980  0.4188    85.422  85.11
  13   0.4715     83.740  0.4021    85.918  92.06
  14   0.4833     84.080  0.3773    87.030  98.95
  15   0.4666     84.240  0.3610    87.426  105.87
  16   0.4686     84.600  0.3447    87.892  112.83
  17   0.4505     85.230  0.3202    88.872  119.82
  18   0.4356     85.490  0.3070    89.274  126.75
  19   0.4242     85.840  0.2967    89.626  133.67
  20   0.4440     85.540  0.2869    89.904  140.63
  21   0.4348     85.770  0.2697    90.606  147.55
  22   0.4175     86.650  0.2562    91.138  154.53
  23   0.4138     87.080  0.2451    91.300  161.43
  24   0.4457     85.980  0.2274    92.106  168.33
  25   0.4134     86.730  0.2197    92.306  175.26
  26   0.4176     87.000  0.2134    92.448  182.22
  27   0.4067     87.500  0.2019    92.938  189.17
  28   0.4110     87.210  0.1874    93.352  196.09
  29   0.4169     87.570  0.1826    93.676  203.00
  30   0.3957     88.030  0.1704    94.106  209.94
  31   0.4571     86.750  0.1633    94.286  216.90
  32   0.4273     87.580  0.1535    94.514  223.81
  33   0.4117     87.860  0.1480    94.848  230.72
  34   0.4224     87.790  0.1399    95.058  237.67
  35   0.4493     87.260  0.1306    95.302  244.56
  36   0.4292     87.790  0.1249    95.548  251.58
  37   0.4284     88.170  0.1195    95.834  258.53
  38   0.4277     88.200  0.1144    96.024  265.49
  39   0.4418     87.770  0.1036    96.340  272.37
  40   0.4514     87.880  0.0968    96.572  279.34
  41   0.4408     88.100  0.0928    96.844  286.36
  42   0.4281     88.490  0.0874    96.982  293.30
  43   0.4407     88.360  0.0896    96.812  300.23
  44   0.4561     88.650  0.0780    97.286  307.13
  45   0.4306     88.500  0.0780    97.232  314.07
  46   0.4532     88.550  0.0705    97.548  321.05
  47   0.4676     88.660  0.0654    97.752  327.95
  48   0.4400     89.190  0.0638    97.772  334.86
  49   0.4779     88.400  0.0567    98.048  341.78
  50   0.4333     89.260  0.0555    98.040  348.64
  51   0.4739     88.760  0.0517    98.174  355.60
  52   0.4726     88.680  0.0469    98.466  362.52
  53   0.4619     89.210  0.0436    98.566  369.46
  54   0.4557     89.310  0.0417    98.656  376.40
  55   0.4648     89.100  0.0414    98.606  383.33
  56   0.4675     89.420  0.0370    98.824  390.29
  57   0.4681     89.400  0.0331    99.008  397.24
  58   0.4921     88.950  0.0330    98.928  404.18
  59   0.4871     89.300  0.0280    99.134  411.09
  60   0.4782     89.350  0.0264    99.226  417.98
  61   0.4798     89.430  0.0255    99.210  424.98
  62   0.4816     89.410  0.0250    99.302  431.89
  63   0.4792     89.680  0.0227    99.316  438.83
  64   0.4928     89.290  0.0234    99.254  445.77
  65   0.4839     89.460  0.0219    99.354  452.67
  66   0.4855     89.600  0.0197    99.414  459.57
  67   0.4836     89.630  0.0184    99.490  466.48
  68   0.4968     89.650  0.0178    99.504  473.43
  69   0.4829     89.570  0.0171    99.528  480.35
  70   0.4944     89.470  0.0159    99.568  487.28
  71   0.4827     89.790  0.0155    99.598  494.24
  72   0.4859     89.770  0.0138    99.672  501.24
  73   0.4903     89.620  0.0136    99.650  508.17
  74   0.4863     89.590  0.0144    99.608  515.07
  75   0.4824     89.640  0.0130    99.684  521.98
  76   0.4903     89.570  0.0135    99.652  528.96
  77   0.4912     89.590  0.0124    99.694  535.99
  78   0.4895     89.780  0.0119    99.730  542.88
  79   0.4980     89.640  0.0112    99.756  549.84
  80   0.4992     89.700  0.0121    99.692  556.76
  81   0.4910     89.780  0.0110    99.776  563.75
  82   0.4972     89.670  0.0109    99.744  570.70
  83   0.4929     89.640  0.0102    99.756  577.61
  84   0.5015     89.550  0.0107    99.758  584.57
  85   0.4929     89.520  0.0100    99.780  591.47
