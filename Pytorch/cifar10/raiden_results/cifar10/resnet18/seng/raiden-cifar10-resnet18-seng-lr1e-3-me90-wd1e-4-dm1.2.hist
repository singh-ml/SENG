Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8639     29.990  2.1109    21.388  8.65
   2   1.6414     38.910  1.7667    34.568  15.64
   3   1.5201     43.730  1.6146    40.418  22.62
   4   1.4313     46.530  1.5140    44.166  29.52
   5   1.3657     49.300  1.4354    47.228  36.43
   6   1.2987     51.910  1.3625    50.002  43.39
   7   1.2378     54.320  1.3065    52.314  50.32
   8   1.1905     56.080  1.2502    54.250  57.22
   9   1.1523     57.900  1.1977    56.460  64.25
  10   1.1219     59.670  1.1570    58.150  71.14
  11   1.0826     60.970  1.1173    59.628  78.07
  12   1.0614     61.820  1.0850    60.820  85.02
  13   1.0244     63.120  1.0500    62.348  91.97
  14   1.0009     64.210  1.0145    63.646  98.95
  15   0.9746     65.520  0.9900    64.572  105.86
  16   0.9530     65.920  0.9616    65.522  112.78
  17   0.9355     66.690  0.9332    66.556  119.73
  18   0.9070     67.520  0.9088    67.426  126.76
  19   0.8939     68.030  0.8841    68.390  133.71
  20   0.8708     69.030  0.8638    69.190  140.60
  21   0.8542     69.510  0.8433    69.978  147.54
  22   0.8375     70.560  0.8176    70.890  154.45
  23   0.8262     70.620  0.7996    71.756  161.51
  24   0.8145     71.290  0.7801    72.380  168.47
  25   0.7884     72.210  0.7596    73.030  175.38
  26   0.7845     72.400  0.7535    73.376  182.28
  27   0.7649     73.020  0.7307    74.218  189.24
  28   0.7585     73.490  0.7165    74.302  196.20
  29   0.7535     73.850  0.6986    75.382  203.13
  30   0.7246     74.480  0.6861    75.898  210.04
  31   0.7176     75.230  0.6714    76.286  216.95
  32   0.7156     75.170  0.6599    76.546  223.87
  33   0.6959     75.720  0.6486    77.088  230.89
  34   0.6927     76.020  0.6348    77.516  237.85
  35   0.6830     76.080  0.6217    77.956  244.76
  36   0.6738     77.150  0.6113    78.330  251.72
  37   0.6673     77.010  0.5963    78.940  258.62
  38   0.6628     77.300  0.5874    79.218  265.62
  39   0.6537     77.600  0.5793    79.506  272.55
  40   0.6452     77.910  0.5668    79.924  279.47
  41   0.6342     78.400  0.5556    80.408  286.41
  42   0.6266     78.590  0.5484    80.686  293.34
  43   0.6277     78.510  0.5397    81.066  300.31
  44   0.6122     79.290  0.5290    81.426  307.21
  45   0.6102     79.220  0.5202    81.718  314.14
  46   0.6046     79.630  0.5141    81.934  321.07
  47   0.6019     79.810  0.4985    82.488  328.00
  48   0.6043     79.840  0.4924    82.632  334.94
  49   0.5838     80.460  0.4853    82.854  341.91
  50   0.5853     80.480  0.4782    83.276  348.71
  51   0.5841     80.610  0.4662    83.526  355.67
  52   0.5801     80.500  0.4625    83.672  362.60
  53   0.5694     81.090  0.4578    83.776  369.50
  54   0.5738     81.090  0.4487    84.176  376.47
  55   0.5666     81.130  0.4473    84.452  383.40
  56   0.5653     81.320  0.4346    84.760  390.31
  57   0.5665     81.200  0.4274    84.930  397.22
  58   0.5571     81.590  0.4220    84.996  404.16
  59   0.5580     81.920  0.4172    85.358  411.11
  60   0.5592     81.560  0.4143    85.424  418.11
  61   0.5554     81.910  0.4050    85.742  425.02
  62   0.5437     82.230  0.3966    86.132  431.91
  63   0.5444     82.240  0.3887    86.356  438.86
  64   0.5420     82.480  0.3856    86.696  445.77
  65   0.5350     82.740  0.3818    86.322  452.75
  66   0.5349     82.640  0.3781    86.732  459.65
  67   0.5380     82.640  0.3694    86.970  466.60
  68   0.5427     82.640  0.3678    87.104  473.53
  69   0.5339     83.150  0.3568    87.518  480.55
  70   0.5396     83.200  0.3554    87.518  487.50
  71   0.5368     83.110  0.3485    87.860  494.42
  72   0.5286     83.440  0.3435    87.970  501.38
  73   0.5262     83.410  0.3392    87.930  508.28
  74   0.5288     83.640  0.3334    88.502  515.26
  75   0.5231     83.590  0.3301    88.438  522.17
  76   0.5294     83.230  0.3215    88.784  529.07
  77   0.5280     83.410  0.3244    88.652  535.97
  78   0.5186     83.760  0.3171    88.958  542.89
  79   0.5193     83.820  0.3070    89.214  549.87
  80   0.5288     83.830  0.3056    89.308  556.80
  81   0.5196     83.900  0.3065    89.270  563.71
  82   0.5159     84.120  0.2974    89.692  570.67
  83   0.5441     83.600  0.2933    89.790  577.62
  84   0.5334     83.770  0.2909    89.868  584.62
  85   0.5318     83.970  0.2865    89.962  591.57
  86   0.5272     83.710  0.2850    89.968  598.49
  87   0.5233     83.950  0.2757    90.440  605.42
  88   0.5247     84.330  0.2725    90.504  612.35
  89   0.5241     83.890  0.2700    90.682  619.33
  90   0.5278     84.110  0.2681    90.622  626.30
