Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4913     44.760  1.7906    33.014  8.97
   2   1.2031     55.690  1.3635    49.920  15.93
   3   1.0241     62.730  1.1472    58.718  22.89
   4   0.9163     66.810  0.9949    64.386  29.92
   5   0.8453     69.600  0.8926    68.076  36.96
   6   0.7994     71.730  0.8222    70.838  43.92
   7   0.7400     73.790  0.7520    73.232  50.91
   8   0.6911     76.200  0.7033    75.210  57.88
   9   0.6520     77.010  0.6565    76.678  64.85
  10   0.6241     78.490  0.6164    78.344  71.84
  11   0.6005     79.310  0.5812    79.666  78.89
  12   0.5734     80.210  0.5486    80.800  85.83
  13   0.5728     80.700  0.5210    81.646  92.79
  14   0.5356     81.680  0.4962    82.658  99.77
  15   0.5350     81.490  0.4676    83.736  106.73
  16   0.5142     82.730  0.4444    84.580  113.79
  17   0.5057     83.360  0.4290    84.946  120.76
  18   0.5076     83.220  0.4126    85.708  127.74
  19   0.4945     83.590  0.3967    86.286  134.69
  20   0.4875     83.830  0.3800    86.714  141.65
  21   0.4730     84.200  0.3662    87.222  148.59
  22   0.4731     84.520  0.3482    87.774  155.62
  23   0.4656     84.880  0.3383    88.238  162.59
  24   0.4687     85.070  0.3280    88.658  169.55
  25   0.4620     85.030  0.3141    88.982  176.56
  26   0.4521     84.980  0.2970    89.684  183.61
  27   0.4552     85.270  0.2884    89.962  190.57
  28   0.4439     85.340  0.2784    90.316  197.55
  29   0.4431     85.450  0.2731    90.378  204.50
  30   0.4570     85.950  0.2632    90.708  211.44
  31   0.4439     85.830  0.2537    91.036  218.49
  32   0.4433     85.980  0.2475    91.262  225.43
  33   0.4745     86.130  0.2349    91.866  232.42
  34   0.4347     86.680  0.2269    91.940  239.40
  35   0.4817     85.690  0.2194    92.386  246.36
  36   0.4396     86.580  0.2148    92.520  253.41
  37   0.4584     86.610  0.2002    92.960  260.35
  38   0.4513     86.870  0.1989    92.872  267.33
  39   0.4447     86.610  0.1897    93.452  274.32
  40   0.4581     86.880  0.1829    93.640  281.28
  41   0.4514     87.390  0.1785    93.670  288.31
  42   0.4633     86.700  0.1721    93.882  295.27
  43   0.4789     86.500  0.1620    94.376  302.22
  44   0.4481     87.190  0.1659    94.142  309.21
  45   0.4754     86.630  0.1529    94.728  316.18
  46   0.4739     86.950  0.1478    94.768  323.13
  47   0.4560     87.390  0.1407    95.080  330.18
  48   0.4689     87.000  0.1364    95.270  337.12
  49   0.4544     87.690  0.1307    95.380  344.10
  50   0.4548     87.400  0.1285    95.476  350.95
  51   0.4728     87.540  0.1215    95.732  357.93
  52   0.4818     87.250  0.1200    95.886  364.86
  53   0.4815     87.780  0.1128    96.106  371.91
  54   0.4665     87.850  0.1124    96.124  378.88
  55   0.4647     87.810  0.1073    96.250  385.85
  56   0.4614     87.940  0.1035    96.390  392.82
  57   0.4693     87.930  0.0958    96.676  399.77
  58   0.4818     87.780  0.0942    96.708  406.78
  59   0.4681     88.140  0.0929    96.832  413.72
  60   0.4850     87.840  0.0864    96.992  420.67
  61   0.5009     87.710  0.0824    97.170  427.63
  62   0.5079     87.900  0.0820    97.112  434.58
  63   0.4964     88.200  0.0784    97.324  441.61
  64   0.4934     88.320  0.0757    97.466  448.58
  65   0.4881     88.360  0.0740    97.418  455.56
  66   0.5030     88.410  0.0675    97.696  462.55
  67   0.5014     88.320  0.0705    97.494  469.49
  68   0.4968     88.510  0.0643    97.848  476.51
  69   0.5015     88.260  0.0644    97.838  483.47
  70   0.5066     88.080  0.0614    97.978  490.42
  71   0.5075     88.240  0.0593    97.994  497.36
  72   0.5091     88.240  0.0561    98.132  504.33
  73   0.5086     88.290  0.0556    98.146  511.36
  74   0.5095     88.520  0.0523    98.258  518.31
  75   0.5201     88.000  0.0511    98.318  525.24
  76   0.5278     88.020  0.0496    98.386  532.22
  77   0.5317     88.120  0.0501    98.346  539.22
  78   0.5137     88.490  0.0459    98.510  546.25
  79   0.5282     88.270  0.0442    98.550  553.19
  80   0.5217     88.440  0.0438    98.602  560.13
  81   0.5294     88.370  0.0445    98.484  567.08
  82   0.5275     88.620  0.0428    98.596  574.06
  83   0.5239     88.590  0.0397    98.774  581.03
  84   0.5210     88.630  0.0396    98.690  588.02
  85   0.5316     88.570  0.0400    98.762  595.01
  86   0.5348     88.920  0.0393    98.780  601.96
  87   0.5280     88.930  0.0363    98.928  608.93
  88   0.5442     88.560  0.0352    98.888  615.89
  89   0.5337     88.630  0.0366    98.838  622.89
  90   0.5465     88.650  0.0349    98.890  629.87
