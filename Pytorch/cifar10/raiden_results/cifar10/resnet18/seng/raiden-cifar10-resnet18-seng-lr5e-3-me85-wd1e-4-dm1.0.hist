Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4538     45.930  1.7761    34.122  8.91
   2   1.2048     55.870  1.3608    49.848  15.91
   3   1.0416     62.980  1.1515    58.264  22.86
   4   0.9232     67.050  0.9974    64.168  29.82
   5   0.8598     69.670  0.8866    68.096  36.94
   6   0.7559     73.490  0.8019    71.272  43.93
   7   0.7023     75.200  0.7295    74.128  50.91
   8   0.6676     76.350  0.6693    76.406  57.94
   9   0.6341     78.200  0.6221    77.958  64.97
  10   0.5981     79.140  0.5783    79.562  71.97
  11   0.5819     79.900  0.5404    80.932  78.99
  12   0.5464     81.010  0.5094    82.092  85.98
  13   0.5485     81.440  0.4832    82.984  92.97
  14   0.5180     82.630  0.4605    83.984  99.96
  15   0.5564     81.460  0.4366    84.542  107.03
  16   0.5248     82.600  0.4148    85.504  113.99
  17   0.4964     82.970  0.3988    86.106  121.00
  18   0.4994     83.310  0.3833    86.528  128.01
  19   0.4746     84.300  0.3656    87.268  135.00
  20   0.4731     84.440  0.3470    87.874  142.03
  21   0.4727     84.500  0.3308    88.522  149.00
  22   0.4698     84.570  0.3245    88.592  156.00
  23   0.4615     85.390  0.3092    89.296  162.97
  24   0.4630     85.130  0.2961    89.654  169.95
  25   0.4543     85.880  0.2881    89.848  177.03
  26   0.4498     85.500  0.2720    90.614  184.04
  27   0.4485     85.420  0.2652    90.566  191.01
  28   0.4550     85.960  0.2479    91.272  197.98
  29   0.4621     85.800  0.2383    91.672  204.93
  30   0.4391     86.100  0.2316    91.898  211.95
  31   0.4469     86.010  0.2225    92.192  218.93
  32   0.4600     86.000  0.2125    92.486  225.92
  33   0.4848     85.630  0.2069    92.510  232.89
  34   0.4458     86.470  0.1969    92.978  239.87
  35   0.4520     86.490  0.1901    93.200  246.89
  36   0.4625     86.340  0.1793    93.674  253.89
  37   0.4513     86.610  0.1796    93.660  260.84
  38   0.4527     86.680  0.1626    94.254  267.83
  39   0.4575     86.740  0.1676    94.110  274.91
  40   0.4458     87.240  0.1570    94.376  281.91
  41   0.4492     87.340  0.1499    94.732  288.86
  42   0.4435     87.630  0.1436    94.944  295.85
  43   0.4752     87.170  0.1370    95.156  302.86
  44   0.4547     87.710  0.1311    95.334  309.95
  45   0.4565     87.580  0.1219    95.812  316.94
  46   0.4662     87.730  0.1166    95.972  323.94
  47   0.4693     87.680  0.1184    95.916  330.93
  48   0.4744     87.290  0.1073    96.312  337.90
  49   0.4694     87.880  0.1044    96.320  344.94
  50   0.4785     87.400  0.0989    96.522  351.84
  51   0.4752     87.870  0.0957    96.602  358.81
  52   0.4919     87.700  0.0925    96.734  365.78
  53   0.4734     87.570  0.0903    96.890  372.79
  54   0.4718     88.100  0.0789    97.360  379.85
  55   0.4785     88.200  0.0781    97.316  386.85
  56   0.4767     88.360  0.0722    97.560  393.85
  57   0.4804     88.330  0.0706    97.618  400.83
  58   0.4938     88.030  0.0708    97.596  407.80
  59   0.4909     88.370  0.0672    97.664  414.88
  60   0.4898     88.320  0.0650    97.786  421.84
  61   0.4922     88.450  0.0592    97.982  428.84
  62   0.4981     88.280  0.0577    98.016  435.81
  63   0.5160     88.460  0.0536    98.218  442.80
  64   0.4983     88.670  0.0529    98.228  449.83
  65   0.5179     88.190  0.0493    98.416  456.80
  66   0.5210     88.520  0.0503    98.328  463.78
  67   0.5073     88.760  0.0472    98.436  470.74
  68   0.5233     88.060  0.0472    98.416  477.68
  69   0.5230     88.560  0.0444    98.550  484.73
  70   0.5315     88.130  0.0403    98.720  491.71
  71   0.5234     88.790  0.0391    98.744  498.70
  72   0.5139     88.540  0.0402    98.732  505.70
  73   0.5228     88.770  0.0366    98.868  512.67
  74   0.5298     88.670  0.0346    98.954  519.76
  75   0.5312     88.190  0.0346    98.896  526.73
  76   0.5460     88.430  0.0347    98.874  533.71
  77   0.5366     88.710  0.0330    98.944  540.68
  78   0.5488     88.630  0.0313    99.068  547.68
  79   0.5433     88.680  0.0315    99.010  554.78
  80   0.5572     88.400  0.0307    99.072  561.77
  81   0.5399     88.500  0.0305    99.052  568.73
  82   0.5607     88.450  0.0278    99.144  575.70
  83   0.5663     88.440  0.0285    99.126  582.67
  84   0.5514     88.580  0.0292    99.088  589.74
  85   0.5523     88.550  0.0278    99.172  596.72
