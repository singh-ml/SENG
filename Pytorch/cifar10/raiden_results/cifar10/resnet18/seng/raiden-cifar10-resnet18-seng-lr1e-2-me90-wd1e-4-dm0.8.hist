Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2707     54.030  1.5986    40.774  8.71
   2   0.9831     64.920  1.1161    59.818  15.81
   3   0.8425     70.460  0.9066    67.726  22.78
   4   0.7112     75.440  0.7741    72.624  29.75
   5   0.6637     76.970  0.6797    75.920  36.70
   6   0.6532     77.660  0.6093    78.666  43.70
   7   0.5727     80.480  0.5509    81.010  50.72
   8   0.5838     80.620  0.5035    82.298  57.68
   9   0.5353     82.100  0.4675    83.702  64.64
  10   0.4991     83.060  0.4298    85.112  71.60
  11   0.4928     83.320  0.3999    86.128  78.58
  12   0.4738     84.140  0.3786    86.802  85.70
  13   0.4810     84.250  0.3529    87.658  92.67
  14   0.4715     84.900  0.3365    88.334  99.62
  15   0.4648     85.310  0.3118    89.230  106.57
  16   0.4547     85.340  0.2964    89.582  113.59
  17   0.4679     85.540  0.2807    90.084  120.56
  18   0.4414     86.310  0.2680    90.586  127.52
  19   0.4085     86.890  0.2556    91.096  134.51
  20   0.4533     85.710  0.2381    91.660  141.46
  21   0.4437     86.110  0.2226    92.104  148.47
  22   0.4214     87.640  0.2108    92.610  155.45
  23   0.4156     87.430  0.2039    92.846  162.45
  24   0.4171     87.550  0.1898    93.240  169.40
  25   0.4159     87.860  0.1809    93.614  176.39
  26   0.4213     87.790  0.1665    93.986  183.44
  27   0.4181     87.820  0.1618    94.304  190.43
  28   0.4290     87.470  0.1550    94.656  197.41
  29   0.4228     88.260  0.1471    94.918  204.37
  30   0.4435     88.010  0.1395    95.090  211.34
  31   0.4584     87.880  0.1343    95.192  218.41
  32   0.4210     88.600  0.1237    95.618  225.39
  33   0.4237     88.800  0.1047    96.360  232.38
  34   0.4476     88.660  0.1098    96.102  239.34
  35   0.4433     88.240  0.1053    96.204  246.33
  36   0.4336     88.960  0.0992    96.466  253.31
  37   0.4630     88.210  0.0917    96.802  260.37
  38   0.4498     88.660  0.0873    96.948  267.35
  39   0.4472     88.820  0.0786    97.272  274.30
  40   0.4776     89.110  0.0761    97.286  281.28
  41   0.4561     89.230  0.0708    97.530  288.22
  42   0.4502     89.110  0.0653    97.734  295.23
  43   0.4418     89.580  0.0620    97.848  302.21
  44   0.4498     89.530  0.0582    97.972  309.16
  45   0.4591     89.690  0.0521    98.216  316.13
  46   0.4773     89.270  0.0480    98.280  323.11
  47   0.4552     90.250  0.0443    98.442  330.10
  48   0.5076     89.010  0.0433    98.524  337.10
  49   0.4797     89.620  0.0443    98.502  344.06
  50   0.4462     90.040  0.0369    98.720  350.93
  51   0.4824     89.730  0.0345    98.858  357.91
  52   0.4524     90.210  0.0327    98.930  364.86
  53   0.4617     90.290  0.0286    99.082  371.92
  54   0.4728     90.200  0.0259    99.196  378.90
  55   0.4738     89.840  0.0263    99.124  385.88
  56   0.4644     90.210  0.0244    99.208  392.83
  57   0.4831     89.960  0.0217    99.348  399.88
  58   0.4831     90.290  0.0190    99.430  406.85
  59   0.4824     90.250  0.0175    99.458  413.84
  60   0.4873     90.170  0.0172    99.460  420.82
  61   0.4797     90.390  0.0152    99.534  427.81
  62   0.4768     90.590  0.0147    99.594  434.86
  63   0.4729     90.560  0.0117    99.664  441.79
  64   0.4738     90.630  0.0123    99.688  448.76
  65   0.4715     90.420  0.0116    99.694  455.72
  66   0.4888     90.480  0.0122    99.658  462.71
  67   0.4760     90.560  0.0102    99.756  469.70
  68   0.4852     90.560  0.0092    99.760  476.68
  69   0.4821     90.670  0.0094    99.736  483.63
  70   0.4859     90.650  0.0088    99.780  490.63
  71   0.4798     90.590  0.0076    99.818  497.62
  72   0.4793     90.700  0.0074    99.824  504.72
  73   0.4902     90.610  0.0070    99.838  511.68
  74   0.4794     90.810  0.0068    99.826  518.63
  75   0.4849     90.640  0.0061    99.872  525.62
  76   0.4778     90.640  0.0070    99.826  532.64
  77   0.4838     90.800  0.0063    99.848  539.59
  78   0.4932     90.760  0.0059    99.870  546.57
  79   0.4920     90.860  0.0056    99.890  553.58
  80   0.4897     90.850  0.0050    99.906  560.57
  81   0.4914     90.870  0.0056    99.890  567.66
  82   0.4846     90.860  0.0048    99.910  574.65
  83   0.4918     90.890  0.0048    99.922  581.65
  84   0.4897     90.850  0.0049    99.920  588.64
  85   0.4867     91.010  0.0050    99.900  595.62
  86   0.4914     90.940  0.0049    99.894  602.57
  87   0.4940     90.860  0.0048    99.902  609.64
  88   0.4958     90.800  0.0046    99.926  616.59
  89   0.4902     90.870  0.0044    99.914  623.56
  90   0.4951     90.820  0.0043    99.924  630.54
