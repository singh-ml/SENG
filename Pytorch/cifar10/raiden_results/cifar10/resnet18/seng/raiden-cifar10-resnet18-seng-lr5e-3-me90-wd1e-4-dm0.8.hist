Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4145     48.690  1.6995    36.684  8.84
   2   1.1324     58.400  1.2478    54.510  15.70
   3   0.9475     66.380  1.0326    62.892  22.57
   4   0.8570     69.890  0.8963    68.118  29.45
   5   0.7765     72.250  0.8013    71.518  36.33
   6   0.7212     74.500  0.7236    74.186  43.30
   7   0.6629     76.560  0.6626    76.600  50.15
   8   0.6341     78.560  0.6113    78.302  57.06
   9   0.6041     79.310  0.5633    80.254  64.00
  10   0.5647     80.210  0.5268    81.618  70.90
  11   0.5468     81.020  0.4948    82.632  77.90
  12   0.5496     81.480  0.4654    84.000  84.81
  13   0.5269     81.900  0.4399    84.642  91.73
  14   0.4896     83.190  0.4158    85.552  98.60
  15   0.4800     83.870  0.3935    86.248  105.54
  16   0.4777     84.140  0.3792    86.720  112.49
  17   0.4878     84.280  0.3584    87.646  119.37
  18   0.4744     84.180  0.3394    88.272  126.27
  19   0.4606     85.060  0.3284    88.494  133.15
  20   0.4656     85.110  0.3113    89.282  140.06
  21   0.4670     85.290  0.2992    89.536  147.05
  22   0.4558     85.340  0.2820    90.184  153.96
  23   0.4625     85.320  0.2679    90.588  160.89
  24   0.4400     86.150  0.2615    90.872  167.76
  25   0.4455     86.080  0.2536    91.118  174.71
  26   0.4446     86.380  0.2374    91.600  181.66
  27   0.4307     86.630  0.2260    92.096  188.54
  28   0.4453     86.630  0.2147    92.484  195.41
  29   0.4209     87.060  0.2115    92.572  202.30
  30   0.4495     86.250  0.2086    92.676  209.19
  31   0.4523     86.750  0.1966    93.170  216.12
  32   0.4296     87.080  0.1888    93.330  222.98
  33   0.4389     87.160  0.1714    93.982  229.86
  34   0.4292     87.300  0.1706    93.954  236.75
  35   0.4385     87.070  0.1622    94.318  243.64
  36   0.4443     87.270  0.1538    94.534  250.59
  37   0.4190     87.770  0.1479    94.706  257.51
  38   0.4537     87.720  0.1387    95.134  264.39
  39   0.4485     87.640  0.1321    95.326  271.31
  40   0.4262     88.280  0.1272    95.530  278.20
  41   0.4587     87.530  0.1162    95.826  285.22
  42   0.4752     87.340  0.1148    95.876  292.10
  43   0.4818     87.500  0.1106    96.100  299.00
  44   0.4526     88.100  0.1079    96.212  305.92
  45   0.4665     88.190  0.0993    96.440  312.80
  46   0.4617     88.250  0.0906    96.838  319.80
  47   0.4696     87.820  0.0941    96.584  326.73
  48   0.4617     88.330  0.0842    97.086  333.62
  49   0.4766     88.260  0.0798    97.202  340.54
  50   0.4689     88.450  0.0744    97.444  347.34
  51   0.4884     88.120  0.0749    97.368  354.22
  52   0.4819     88.120  0.0696    97.558  361.16
  53   0.4932     88.250  0.0639    97.858  368.02
  54   0.4712     88.680  0.0629    97.800  374.89
  55   0.4760     88.620  0.0555    98.098  381.74
  56   0.4778     88.560  0.0566    98.070  388.65
  57   0.5165     88.290  0.0541    98.144  395.59
  58   0.5065     88.370  0.0487    98.354  402.47
  59   0.4924     88.850  0.0488    98.352  409.38
  60   0.5111     88.700  0.0460    98.454  416.27
  61   0.5116     88.810  0.0454    98.462  423.14
  62   0.5105     88.940  0.0421    98.600  429.99
  63   0.4894     89.040  0.0392    98.718  436.98
  64   0.5130     88.940  0.0359    98.806  443.85
  65   0.5046     88.870  0.0362    98.798  450.78
  66   0.5112     88.870  0.0334    98.872  457.64
  67   0.5048     88.950  0.0336    98.966  464.58
  68   0.5163     88.880  0.0310    99.028  471.45
  69   0.5072     89.270  0.0279    99.146  478.34
  70   0.5165     89.110  0.0286    99.122  485.25
  71   0.5263     89.060  0.0256    99.256  492.14
  72   0.5181     89.110  0.0242    99.274  499.10
  73   0.5102     89.220  0.0230    99.310  506.03
  74   0.5186     89.030  0.0227    99.336  512.91
  75   0.5206     89.000  0.0223    99.332  519.78
  76   0.5262     89.230  0.0209    99.378  526.64
  77   0.5170     89.040  0.0203    99.394  533.62
  78   0.5159     89.050  0.0195    99.448  540.52
  79   0.5200     89.340  0.0188    99.426  547.42
  80   0.5273     89.030  0.0179    99.458  554.37
  81   0.5211     89.370  0.0164    99.570  561.29
  82   0.5255     89.630  0.0167    99.548  568.30
  83   0.5282     89.350  0.0165    99.540  575.18
  84   0.5292     89.370  0.0151    99.578  582.09
  85   0.5334     89.420  0.0145    99.628  588.98
  86   0.5355     89.570  0.0148    99.586  595.88
  87   0.5330     89.600  0.0140    99.604  602.83
  88   0.5399     89.290  0.0139    99.622  609.75
  89   0.5366     89.370  0.0126    99.678  616.65
  90   0.5468     89.430  0.0145    99.620  623.54
