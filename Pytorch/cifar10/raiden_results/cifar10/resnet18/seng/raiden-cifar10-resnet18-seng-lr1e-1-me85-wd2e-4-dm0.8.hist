Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1488     61.460  1.4089    48.378  9.36
   2   0.8492     70.600  0.9093    67.904  16.44
   3   0.7271     74.840  0.7005    75.500  23.48
   4   0.5900     79.820  0.5909    79.174  30.53
   5   0.6370     78.050  0.5224    81.910  37.62
   6   0.5862     81.250  0.4649    83.814  44.64
   7   0.5653     81.380  0.4216    85.458  51.65
   8   0.4600     85.000  0.3834    86.614  58.72
   9   0.4229     85.580  0.3482    87.908  65.74
  10   0.4255     86.390  0.3227    88.868  72.84
  11   0.4599     85.870  0.3022    89.462  79.86
  12   0.3947     87.330  0.2888    89.832  86.90
  13   0.4252     86.250  0.2647    90.938  93.94
  14   0.3714     87.980  0.2417    91.638  101.05
  15   0.4305     86.430  0.2244    92.192  108.10
  16   0.3631     88.250  0.2203    92.216  115.18
  17   0.3850     87.590  0.2112    92.508  122.20
  18   0.4127     87.210  0.1990    92.914  129.33
  19   0.3521     88.960  0.1765    93.902  136.43
  20   0.3618     89.320  0.1762    93.838  143.48
  21   0.3650     89.840  0.1620    94.216  150.54
  22   0.3499     89.860  0.1536    94.620  157.66
  23   0.3519     89.310  0.1508    94.670  164.76
  24   0.4364     87.250  0.1450    94.896  171.86
  25   0.3470     89.700  0.1389    95.096  178.91
  26   0.4411     87.650  0.1304    95.534  185.94
  27   0.4004     88.700  0.1229    95.750  192.96
  28   0.4186     87.720  0.1171    95.876  199.97
  29   0.3891     88.770  0.1154    95.982  207.03
  30   0.3734     89.860  0.1064    96.220  214.15
  31   0.3513     90.090  0.1075    96.200  221.22
  32   0.4344     88.250  0.0980    96.522  228.25
  33   0.3519     90.420  0.0975    96.578  235.31
  34   0.3445     90.410  0.0849    96.986  242.36
  35   0.3526     90.360  0.0854    97.048  249.48
  36   0.3522     90.380  0.0775    97.346  256.54
  37   0.4058     89.150  0.0803    97.196  263.58
  38   0.3790     89.850  0.0741    97.410  270.66
  39   0.3148     91.270  0.0763    97.322  277.69
  40   0.3510     90.960  0.0630    97.782  284.80
  41   0.3645     90.960  0.0578    97.984  291.82
  42   0.3655     90.940  0.0562    98.022  298.88
  43   0.3385     91.180  0.0550    98.142  305.93
  44   0.3625     90.960  0.0516    98.212  312.99
  45   0.3366     91.630  0.0439    98.508  320.05
  46   0.3768     91.200  0.0379    98.716  327.07
  47   0.3358     91.550  0.0404    98.622  334.13
  48   0.3476     91.500  0.0316    98.958  341.14
  49   0.3513     91.690  0.0268    99.078  348.20
  50   0.3399     91.730  0.0298    99.014  355.16
  51   0.3358     91.980  0.0292    98.996  362.18
  52   0.3170     92.790  0.0227    99.230  369.24
  53   0.3372     91.820  0.0204    99.314  376.29
  54   0.3170     92.460  0.0193    99.388  383.33
  55   0.3188     92.510  0.0134    99.572  390.46
  56   0.3302     92.630  0.0113    99.660  397.49
  57   0.3217     92.800  0.0095    99.716  404.55
  58   0.3282     92.840  0.0077    99.778  411.57
  59   0.3185     92.710  0.0062    99.836  418.60
  60   0.3116     92.980  0.0060    99.850  425.71
  61   0.2927     93.370  0.0052    99.850  432.75
  62   0.3054     93.090  0.0044    99.888  439.79
  63   0.2997     93.360  0.0033    99.926  446.84
  64   0.3005     93.400  0.0034    99.926  453.92
  65   0.2992     93.390  0.0032    99.928  461.02
  66   0.2871     93.560  0.0023    99.952  468.07
  67   0.2849     93.600  0.0018    99.968  475.12
  68   0.2902     93.500  0.0018    99.968  482.15
  69   0.2909     93.590  0.0014    99.980  489.17
  70   0.2880     93.640  0.0014    99.976  496.28
  71   0.2870     93.620  0.0013    99.984  503.31
  72   0.2866     93.590  0.0012    99.990  510.33
  73   0.2841     93.600  0.0012    99.988  517.39
  74   0.2808     93.650  0.0012    99.988  524.41
  75   0.2817     93.720  0.0008    100.000  531.47
  76   0.2794     93.680  0.0010    99.992  538.49
  77   0.2814     93.680  0.0009    99.994  545.50
  78   0.2812     93.680  0.0009    99.998  552.56
  79   0.2820     93.750  0.0009    99.996  559.61
  80   0.2803     93.680  0.0008    99.996  566.71
  81   0.2815     93.670  0.0009    99.994  573.77
  82   0.2810     93.800  0.0008    100.000  580.80
  83   0.2827     93.660  0.0009    99.998  587.84
  84   0.2801     93.670  0.0009    99.992  594.98
  85   0.2813     93.760  0.0008    99.996  601.98
