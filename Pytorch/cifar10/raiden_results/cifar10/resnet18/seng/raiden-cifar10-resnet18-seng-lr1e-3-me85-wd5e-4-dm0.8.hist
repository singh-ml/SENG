Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7378     34.470  2.0125    24.968  13.75
   2   1.5379     42.050  1.6511    38.236  20.63
   3   1.4173     47.100  1.5054    43.922  27.51
   4   1.3375     50.740  1.4024    48.312  34.49
   5   1.2621     53.650  1.3234    51.382  41.39
   6   1.1895     56.980  1.2437    54.742  48.24
   7   1.1259     59.650  1.1735    57.390  55.13
   8   1.0690     61.670  1.1069    60.114  62.04
   9   1.0184     63.990  1.0492    62.314  68.97
  10   0.9741     65.540  1.0008    64.196  75.84
  11   0.9454     66.450  0.9541    66.006  82.74
  12   0.9091     67.510  0.9237    66.996  89.64
  13   0.8861     68.900  0.8896    68.182  96.57
  14   0.8715     69.200  0.8592    69.336  103.57
  15   0.8464     70.570  0.8305    70.626  110.47
  16   0.8184     71.230  0.8038    71.242  117.33
  17   0.8032     72.000  0.7772    72.384  124.19
  18   0.7702     73.080  0.7574    73.166  131.05
  19   0.7546     73.540  0.7334    74.106  138.03
  20   0.7433     74.360  0.7103    74.926  144.90
  21   0.7261     74.860  0.6870    75.606  151.77
  22   0.7073     75.690  0.6684    76.582  158.66
  23   0.7091     75.880  0.6501    77.050  165.55
  24   0.6853     76.640  0.6304    77.738  172.55
  25   0.6651     77.050  0.6126    78.410  179.39
  26   0.6585     77.400  0.5930    79.170  186.25
  27   0.6470     77.750  0.5767    79.710  193.15
  28   0.6247     78.410  0.5653    80.168  200.01
  29   0.6176     78.910  0.5521    80.726  206.97
  30   0.6227     78.710  0.5362    81.326  213.84
  31   0.6043     79.560  0.5220    81.668  220.72
  32   0.6024     79.500  0.5089    82.198  227.61
  33   0.5873     79.940  0.5019    82.286  234.53
  34   0.5891     80.320  0.4871    82.880  241.52
  35   0.5756     80.550  0.4789    83.196  248.39
  36   0.5713     80.930  0.4670    83.516  255.26
  37   0.5675     81.020  0.4533    84.142  262.17
  38   0.5655     81.160  0.4424    84.526  269.07
  39   0.5530     81.430  0.4340    84.882  276.05
  40   0.5582     81.260  0.4292    85.056  282.94
  41   0.5527     81.580  0.4180    85.468  289.79
  42   0.5483     81.680  0.4075    85.592  296.70
  43   0.5458     82.070  0.4012    86.000  303.58
  44   0.5364     82.390  0.3908    86.390  310.53
  45   0.5233     83.040  0.3862    86.632  317.41
  46   0.5234     82.760  0.3753    86.846  324.28
  47   0.5245     83.110  0.3701    87.038  331.14
  48   0.5148     83.420  0.3636    87.208  338.00
  49   0.5321     83.080  0.3571    87.428  344.90
  50   0.5310     83.180  0.3525    87.718  351.73
  51   0.5199     83.160  0.3465    87.746  358.64
  52   0.5115     83.610  0.3399    88.102  365.53
  53   0.5070     83.760  0.3264    88.604  372.40
  54   0.5107     84.020  0.3246    88.798  379.27
  55   0.5050     83.950  0.3168    88.896  386.18
  56   0.5054     83.580  0.3119    89.190  393.05
  57   0.5153     83.610  0.3080    89.278  399.91
  58   0.4934     84.200  0.2960    89.630  406.81
  59   0.5017     84.230  0.2931    89.598  413.76
  60   0.4999     84.230  0.2850    90.058  420.63
  61   0.5118     84.260  0.2810    90.202  427.49
  62   0.5092     84.560  0.2788    90.294  434.36
  63   0.4915     84.870  0.2702    90.464  441.26
  64   0.5153     84.410  0.2687    90.574  448.21
  65   0.4893     84.810  0.2638    90.680  455.07
  66   0.4940     85.170  0.2555    90.998  461.91
  67   0.4978     84.990  0.2523    91.032  468.82
  68   0.4973     84.890  0.2460    91.352  475.72
  69   0.5018     84.810  0.2431    91.566  482.66
  70   0.5057     84.800  0.2360    91.690  489.53
  71   0.4771     85.460  0.2320    91.790  496.38
  72   0.5042     85.030  0.2279    92.140  503.24
  73   0.4938     85.540  0.2209    92.288  510.12
  74   0.5094     85.330  0.2140    92.540  517.11
  75   0.5018     85.640  0.2128    92.552  524.00
  76   0.5170     85.350  0.2056    92.654  530.88
  77   0.5080     85.460  0.2010    92.912  537.78
  78   0.5221     85.140  0.2076    92.590  544.68
  79   0.5070     85.390  0.1966    93.150  551.66
  80   0.5196     85.360  0.1941    93.174  558.54
  81   0.5015     85.780  0.1873    93.318  565.41
  82   0.4932     85.880  0.1817    93.568  572.37
  83   0.5004     85.820  0.1807    93.644  579.25
  84   0.5305     85.260  0.1787    93.774  586.18
  85   0.5168     85.740  0.1720    94.020  593.09
