Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7492985856 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.0732     61.990  1.4202    48.056  8.75
   2   0.8083     72.280  0.9164    67.286  15.80
   3   0.6939     76.450  0.7048    75.356  22.91
   4   0.6859     76.880  0.6018    78.994  29.98
   5   0.6248     79.420  0.5315    81.656  37.05
   6   0.5317     82.280  0.4803    83.452  44.12
   7   0.5172     82.530  0.4387    84.972  51.16
   8   0.4855     83.600  0.4065    85.948  58.27
   9   0.4923     83.490  0.3854    86.698  65.33
  10   0.4374     84.850  0.3571    87.576  72.41
  11   0.4656     84.660  0.3401    88.236  79.49
  12   0.4311     85.440  0.3132    89.104  86.54
  13   0.4184     85.600  0.3039    89.524  93.71
  14   0.4561     84.700  0.3031    89.660  100.77
  15   0.3901     86.510  0.2958    89.804  107.85
  16   0.4243     85.720  0.2809    90.280  114.92
  17   0.4303     86.080  0.2704    90.796  122.01
  18   0.4432     85.850  0.2642    90.966  129.25
  19   0.4928     83.910  0.2589    91.108  136.33
  20   0.3861     87.570  0.2515    91.400  143.39
  21   0.4427     85.860  0.2442    91.608  150.47
  22   0.4040     86.990  0.2379    91.774  157.56
  23   0.3936     86.580  0.2308    92.036  164.74
  24   0.4618     84.960  0.2281    92.208  171.88
  25   0.4251     86.520  0.2197    92.516  178.95
  26   0.3723     87.200  0.2207    92.446  185.99
  27   0.3396     88.860  0.2140    92.752  193.08
  28   0.3792     87.690  0.2061    92.958  200.24
  29   0.4091     86.770  0.2029    93.120  207.33
  30   0.3543     88.400  0.1971    93.144  214.42
  31   0.3565     88.400  0.1890    93.564  221.51
  32   0.3539     88.800  0.1895    93.530  228.56
  33   0.3475     88.690  0.1775    93.838  235.74
  34   0.3706     88.580  0.1733    94.072  242.87
  35   0.3493     89.060  0.1735    93.970  249.97
  36   0.3281     90.030  0.1656    94.232  257.02
  37   0.3437     89.550  0.1569    94.524  264.07
  38   0.4247     87.180  0.1593    94.586  271.20
  39   0.3280     89.590  0.1517    94.746  278.28
  40   0.3453     89.410  0.1424    95.062  285.40
  41   0.4131     87.310  0.1426    95.026  292.52
  42   0.3209     89.890  0.1379    95.264  299.61
  43   0.3173     89.820  0.1353    95.324  306.72
  44   0.3219     89.930  0.1251    95.736  313.81
  45   0.3657     88.460  0.1192    96.010  320.88
  46   0.3446     89.910  0.1176    95.908  327.96
  47   0.3434     89.310  0.1124    96.118  335.03
  48   0.3115     90.360  0.1056    96.418  342.15
  49   0.3003     90.790  0.1091    96.278  349.20
  50   0.3262     90.020  0.0979    96.662  356.18
  51   0.3200     90.750  0.0921    96.868  363.23
  52   0.3014     91.480  0.0837    97.162  370.31
  53   0.2883     91.480  0.0826    97.152  377.43
  54   0.2897     91.660  0.0767    97.398  384.47
  55   0.3104     91.360  0.0709    97.632  391.52
  56   0.2720     92.370  0.0636    97.894  398.58
  57   0.3323     90.640  0.0567    98.128  405.64
  58   0.2777     92.370  0.0583    98.048  412.73
  59   0.2957     91.960  0.0509    98.332  419.78
  60   0.2924     91.840  0.0492    98.358  426.87
  61   0.2964     92.290  0.0391    98.774  433.92
  62   0.3031     91.700  0.0448    98.412  441.01
  63   0.2809     92.320  0.0364    98.850  448.10
  64   0.2551     93.330  0.0277    99.122  455.26
  65   0.2703     92.850  0.0235    99.226  462.32
  66   0.2655     93.470  0.0201    99.410  469.41
  67   0.2642     93.550  0.0190    99.412  476.47
  68   0.2651     93.480  0.0164    99.538  483.59
  69   0.2520     93.750  0.0136    99.628  490.65
  70   0.2760     93.340  0.0107    99.702  497.70
  71   0.2567     93.720  0.0079    99.818  504.78
  72   0.2472     94.120  0.0061    99.868  511.83
  73   0.2322     94.440  0.0050    99.918  518.98
  74   0.2412     94.370  0.0052    99.898  526.07
  75   0.2369     94.210  0.0046    99.924  533.15
  76   0.2308     94.440  0.0031    99.966  540.24
  77   0.2304     94.310  0.0033    99.952  547.34
  78   0.2282     94.410  0.0032    99.956  554.45
  79   0.2273     94.420  0.0030    99.960  561.51
  80   0.2242     94.550  0.0027    99.968  568.56
  81   0.2250     94.470  0.0022    99.988  575.63
  82   0.2224     94.480  0.0025    99.974  582.68
  83   0.2200     94.500  0.0021    99.992  589.81
  84   0.2197     94.470  0.0021    99.990  596.87
  85   0.2207     94.580  0.0021    99.990  603.98
  86   0.2195     94.450  0.0022    99.982  611.05
  87   0.2189     94.560  0.0021    99.988  618.16
  88   0.2192     94.520  0.0021    99.988  625.29
  89   0.2180     94.520  0.0021    99.980  632.36
  90   0.2180     94.510  0.0021    99.992  639.46
