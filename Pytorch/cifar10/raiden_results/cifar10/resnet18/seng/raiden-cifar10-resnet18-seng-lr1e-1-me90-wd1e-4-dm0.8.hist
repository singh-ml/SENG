Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7491412992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3512     54.460  1.4392    47.230  8.69
   2   0.8795     69.460  0.9310    67.314  15.58
   3   0.8053     72.630  0.7120    75.114  22.49
   4   0.5968     79.790  0.5963    79.198  29.42
   5   0.5927     80.360  0.5147    82.010  36.32
   6   0.5214     82.750  0.4523    84.340  43.23
   7   0.4420     85.170  0.4128    85.690  50.12
   8   0.4985     83.360  0.3838    86.654  57.07
   9   0.4300     85.540  0.3518    87.910  64.04
  10   0.4256     85.820  0.3135    89.120  70.93
  11   0.4099     86.930  0.2977    89.594  77.81
  12   0.3859     87.240  0.2693    90.566  84.70
  13   0.3891     87.700  0.2540    91.188  91.60
  14   0.3955     88.050  0.2318    91.852  98.56
  15   0.3518     88.770  0.2241    92.326  105.50
  16   0.3656     88.400  0.2036    92.906  112.41
  17   0.3583     89.410  0.1905    93.312  119.35
  18   0.4205     88.020  0.1796    93.772  126.28
  19   0.3851     88.470  0.1736    93.926  133.27
  20   0.3575     89.750  0.1651    94.224  140.19
  21   0.3632     89.380  0.1468    94.838  147.10
  22   0.3548     89.510  0.1362    95.168  154.01
  23   0.3382     90.430  0.1310    95.406  160.92
  24   0.3297     90.290  0.1298    95.430  167.81
  25   0.3962     89.610  0.1156    95.936  174.76
  26   0.3659     89.720  0.1151    95.964  181.67
  27   0.3791     89.430  0.1100    96.118  188.57
  28   0.3548     90.450  0.1012    96.388  195.49
  29   0.4326     89.060  0.0889    96.982  202.40
  30   0.3377     90.780  0.0895    96.760  209.32
  31   0.4250     89.630  0.0783    97.152  216.39
  32   0.3538     90.750  0.0788    97.220  223.29
  33   0.3678     90.700  0.0684    97.626  230.20
  34   0.3933     90.490  0.0632    97.798  237.14
  35   0.3600     91.260  0.0615    97.852  244.09
  36   0.4103     90.630  0.0560    98.030  251.04
  37   0.3798     90.890  0.0553    98.052  257.95
  38   0.3827     91.200  0.0524    98.104  264.90
  39   0.3734     91.590  0.0451    98.516  271.82
  40   0.3784     91.410  0.0401    98.604  278.75
  41   0.4095     91.040  0.0448    98.374  285.73
  42   0.3996     91.450  0.0371    98.718  292.63
  43   0.3721     91.790  0.0357    98.826  299.53
  44   0.4127     91.220  0.0292    99.012  306.47
  45   0.3820     91.510  0.0281    99.046  313.37
  46   0.4371     90.570  0.0324    98.890  320.36
  47   0.3878     91.940  0.0239    99.142  327.25
  48   0.4092     91.560  0.0202    99.314  334.17
  49   0.3854     91.610  0.0208    99.296  341.06
  50   0.4033     91.660  0.0221    99.222  347.90
  51   0.3876     91.930  0.0165    99.452  354.83
  52   0.3883     92.070  0.0142    99.540  361.77
  53   0.3729     92.360  0.0113    99.644  368.68
  54   0.3774     92.740  0.0099    99.714  375.56
  55   0.3486     92.730  0.0094    99.710  382.51
  56   0.3509     92.520  0.0068    99.796  389.39
  57   0.3555     92.740  0.0057    99.826  396.31
  58   0.3551     92.610  0.0060    99.810  403.21
  59   0.3476     92.910  0.0053    99.856  410.15
  60   0.3527     92.860  0.0044    99.886  417.15
  61   0.3570     92.960  0.0033    99.920  424.06
  62   0.3559     93.110  0.0022    99.966  430.97
  63   0.3523     93.150  0.0030    99.918  437.87
  64   0.3501     93.130  0.0029    99.936  444.77
  65   0.3408     93.340  0.0025    99.952  451.74
  66   0.3428     93.260  0.0018    99.970  458.67
  67   0.3454     93.170  0.0018    99.964  465.57
  68   0.3453     93.190  0.0015    99.976  472.47
  69   0.3450     93.160  0.0012    99.986  479.45
  70   0.3446     93.400  0.0013    99.984  486.40
  71   0.3399     93.410  0.0012    99.990  493.34
  72   0.3346     93.520  0.0010    99.988  500.28
  73   0.3378     93.310  0.0010    99.982  507.20
  74   0.3366     93.300  0.0009    99.988  514.12
  75   0.3360     93.270  0.0009    99.990  521.04
  76   0.3348     93.300  0.0009    99.986  528.00
  77   0.3343     93.390  0.0010    99.978  534.89
  78   0.3347     93.430  0.0009    99.986  541.78
  79   0.3354     93.330  0.0009    99.990  548.71
  80   0.3370     93.330  0.0009    99.990  555.68
  81   0.3353     93.450  0.0008    99.986  562.71
  82   0.3348     93.420  0.0008    99.992  569.60
  83   0.3333     93.320  0.0007    99.992  576.56
  84   0.3340     93.420  0.0008    99.994  583.50
  85   0.3348     93.400  0.0007    99.998  590.39
  86   0.3359     93.370  0.0007    99.994  597.43
  87   0.3333     93.410  0.0007    99.996  604.33
  88   0.3330     93.320  0.0007    99.996  611.22
  89   0.3339     93.430  0.0008    99.992  618.10
  90   0.3333     93.340  0.0008    99.990  625.00
