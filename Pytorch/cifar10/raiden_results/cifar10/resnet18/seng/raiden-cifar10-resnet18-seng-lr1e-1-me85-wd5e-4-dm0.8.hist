Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7493510144 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1866     57.620  1.4684    46.540  8.79
   2   0.9936     66.460  0.9450    66.190  15.85
   3   0.6616     77.080  0.7268    74.500  22.78
   4   0.5842     80.350  0.6029    79.108  29.75
   5   0.6076     79.340  0.5386    81.360  36.72
   6   0.5220     82.010  0.4787    83.322  43.68
   7   0.5236     81.660  0.4419    84.790  50.70
   8   0.4804     84.090  0.4058    86.020  57.65
   9   0.5152     83.040  0.3739    87.020  64.64
  10   0.5610     82.010  0.3633    87.670  71.61
  11   0.4123     85.720  0.3388    88.362  78.61
  12   0.4406     85.920  0.3170    89.146  85.69
  13   0.5476     82.240  0.3118    89.350  92.61
  14   0.4182     86.010  0.2983    89.646  99.54
  15   0.4274     86.250  0.2905    90.076  106.49
  16   0.3808     87.080  0.2790    90.350  113.43
  17   0.3661     88.100  0.2678    90.822  120.43
  18   0.4088     86.230  0.2598    91.092  127.37
  19   0.4536     85.420  0.2605    91.000  134.26
  20   0.3716     87.770  0.2506    91.184  141.18
  21   0.3958     86.650  0.2451    91.444  148.09
  22   0.4107     86.590  0.2342    92.002  155.12
  23   0.4359     85.940  0.2322    91.990  162.09
  24   0.3744     88.040  0.2252    92.162  169.06
  25   0.4554     85.960  0.2141    92.708  176.01
  26   0.4159     86.740  0.2156    92.580  182.93
  27   0.4291     86.820  0.2035    93.018  189.97
  28   0.3322     88.720  0.1996    93.130  196.90
  29   0.3461     88.570  0.2026    93.070  203.89
  30   0.3690     88.340  0.1898    93.432  210.85
  31   0.3498     89.150  0.1847    93.640  217.85
  32   0.3761     88.200  0.1783    93.832  224.81
  33   0.3398     89.190  0.1817    93.704  231.81
  34   0.3223     89.970  0.1749    93.866  238.77
  35   0.3534     89.140  0.1738    94.018  245.74
  36   0.3884     87.670  0.1573    94.528  252.74
  37   0.3208     89.810  0.1554    94.576  259.71
  38   0.3132     89.780  0.1488    94.778  266.64
  39   0.3531     89.160  0.1406    95.094  273.55
  40   0.3599     89.260  0.1369    95.302  280.52
  41   0.3086     90.710  0.1320    95.558  287.53
  42   0.3006     90.970  0.1233    95.752  294.45
  43   0.3906     88.200  0.1203    95.838  301.40
  44   0.3808     88.550  0.1180    95.944  308.34
  45   0.3825     89.440  0.1095    96.228  315.28
  46   0.3176     90.530  0.1057    96.338  322.29
  47   0.3015     90.840  0.0946    96.806  329.22
  48   0.3076     90.920  0.0990    96.524  336.15
  49   0.3166     90.650  0.0900    96.946  343.11
  50   0.3342     90.210  0.0866    96.996  349.91
  51   0.3062     91.440  0.0824    97.170  356.91
  52   0.3166     91.180  0.0674    97.696  363.86
  53   0.2807     91.760  0.0658    97.736  370.79
  54   0.2839     91.820  0.0659    97.748  377.73
  55   0.2768     92.130  0.0537    98.206  384.65
  56   0.2742     91.810  0.0537    98.156  391.69
  57   0.3013     91.810  0.0494    98.368  398.66
  58   0.2690     92.470  0.0437    98.560  405.59
  59   0.2736     92.940  0.0372    98.812  412.52
  60   0.3119     92.140  0.0285    99.070  419.47
  61   0.2851     92.720  0.0291    99.022  426.43
  62   0.2628     93.240  0.0218    99.292  433.45
  63   0.2517     93.830  0.0171    99.444  440.36
  64   0.2725     93.160  0.0156    99.508  447.31
  65   0.2633     93.490  0.0133    99.638  454.28
  66   0.2372     93.890  0.0129    99.616  461.22
  67   0.2352     94.220  0.0093    99.740  468.26
  68   0.2452     94.180  0.0058    99.864  475.22
  69   0.2458     94.110  0.0052    99.872  482.19
  70   0.2361     94.200  0.0055    99.882  489.11
  71   0.2321     94.590  0.0041    99.916  496.06
  72   0.2282     94.430  0.0035    99.936  502.97
  73   0.2252     94.560  0.0033    99.930  509.92
  74   0.2276     94.530  0.0027    99.970  516.88
  75   0.2272     94.690  0.0028    99.946  523.81
  76   0.2197     94.740  0.0021    99.980  530.83
  77   0.2201     94.800  0.0021    99.972  537.76
  78   0.2215     94.750  0.0018    99.988  544.66
  79   0.2206     94.630  0.0018    99.986  551.57
  80   0.2205     94.730  0.0017    99.986  558.54
  81   0.2216     94.650  0.0019    99.982  565.57
  82   0.2178     94.780  0.0015    99.990  572.52
  83   0.2186     94.740  0.0018    99.984  579.45
  84   0.2178     94.760  0.0017    99.988  586.37
  85   0.2156     94.830  0.0016    99.994  593.33
