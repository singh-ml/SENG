Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--frac', '1.0', '--bh', '256', '--irho', '2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 62044306432 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6991     32.450  2.1037    20.778  369.07
   2   1.4199     47.650  1.5929    39.386  730.39
   3   1.1808     57.500  1.2880    53.930  1091.75
   4   1.1363     61.470  1.0339    64.022  1453.11
   5   0.9027     68.580  0.8690    70.534  1814.36
   6   0.6899     77.020  0.7538    74.882  2175.73
   7   0.7069     75.650  0.6651    77.840  2537.22
   8   0.6548     77.910  0.5891    80.416  2899.95
   9   0.5850     80.660  0.5342    82.244  3263.31
  10   0.5709     80.560  0.4965    83.592  3625.11
  11   0.5789     80.760  0.4643    84.624  3988.70
  12   0.4706     83.910  0.4348    85.588  4350.43
  13   0.5662     81.820  0.3978    86.774  4713.78
  14   0.4723     84.330  0.3783    87.422  5077.20
  15   0.5929     80.600  0.3493    88.314  5440.56
  16   0.5314     82.480  0.3387    88.696  5804.14
  17   0.4662     85.030  0.3168    89.236  6165.81
  18   0.5016     84.010  0.3039    89.880  6527.42
  19   0.4615     84.790  0.2778    90.622  6890.94
  20   0.4792     84.640  0.2704    90.924  7252.62
  21   0.3881     87.560  0.2532    91.698  7616.77
  22   0.3914     87.210  0.2416    91.806  7980.12
  23   0.4260     86.690  0.2252    92.556  8342.16
  24   0.4484     86.060  0.2165    92.722  8705.48
  25   0.3799     88.130  0.2124    92.790  9069.04
  26   0.4503     86.780  0.1963    93.306  9430.93
  27   0.4510     86.670  0.1920    93.510  9792.63
  28   0.3784     88.120  0.1757    93.966  10156.24
  29   0.4186     87.380  0.1680    94.290  10519.59
  30   0.4100     87.510  0.1585    94.704  10882.91
  31   0.4195     87.390  0.1528    94.828  11244.72
  32   0.4048     88.290  0.1442    95.090  11606.51
  33   0.3906     88.540  0.1357    95.390  11968.18
  34   0.4055     88.180  0.1272    95.758  12330.21
  35   0.4228     88.040  0.1242    95.878  12691.40
  36   0.4021     88.960  0.1199    95.992  13053.30
  37   0.4399     87.860  0.1109    96.370  13416.68
  38   0.4200     88.570  0.1081    96.496  13780.33
  39   0.4284     88.240  0.1015    96.624  14143.88
  40   0.4163     88.950  0.0957    96.870  14505.69
  41   0.3903     89.340  0.0889    97.126  14869.29
  42   0.3816     89.670  0.0817    97.272  15232.71
  43   0.4587     88.270  0.0776    97.414  15596.17
  44   0.4167     89.020  0.0749    97.450  15960.04
  45   0.3986     89.480  0.0713    97.600  16321.76
  46   0.4173     89.250  0.0640    97.810  16683.58
  47   0.4322     89.650  0.0629    97.846  17044.98
  48   0.3920     90.320  0.0593    97.978  17408.38
  49   0.4220     89.840  0.0564    98.068  17769.89
  50   0.4210     89.980  0.0540    98.190  18133.57
  51   0.4180     90.390  0.0450    98.460  18497.05
  52   0.4372     90.120  0.0431    98.556  18860.53
  53   0.4365     90.380  0.0424    98.528  19222.40
  54   0.4096     89.880  0.0437    98.530  19585.84
  55   0.4260     90.090  0.0368    98.750  19947.85
  56   0.4377     90.170  0.0341    98.872  20309.40
  57   0.4445     90.440  0.0330    98.886  20671.01
  58   0.4615     89.790  0.0325    98.902  21032.53
  59   0.4827     89.750  0.0274    99.068  21394.12
  60   0.4648     90.490  0.0277    99.048  21757.50
  61   0.4536     90.670  0.0228    99.248  22120.92
  62   0.4477     90.210  0.0229    99.230  22484.35
  63   0.4604     90.250  0.0220    99.254  22845.88
  64   0.4529     90.770  0.0178    99.388  23207.72
  65   0.4737     90.630  0.0175    99.414  23569.60
  66   0.4863     90.810  0.0156    99.486  23933.03
  67   0.4709     90.840  0.0149    99.494  24294.89
  68   0.4903     90.820  0.0121    99.584  24656.20
  69   0.5173     90.740  0.0118    99.630  25018.15
  70   0.4940     90.830  0.0121    99.566  25379.83
  71   0.4932     90.940  0.0123    99.604  25743.24
  72   0.4904     90.880  0.0111    99.624  26104.76
  73   0.5158     90.970  0.0087    99.700  26466.06
  74   0.5114     90.900  0.0085    99.722  26827.34
  75   0.5195     91.120  0.0095    99.688  27189.20
  76   0.5197     90.890  0.0082    99.734  27550.81
  77   0.5202     90.800  0.0079    99.742  27914.25
  78   0.5114     91.220  0.0072    99.794  28278.54
  79   0.5091     91.260  0.0065    99.766  28641.93
  80   0.5189     91.060  0.0054    99.820  29003.94
  81   0.5263     90.980  0.0045    99.858  29365.35
  82   0.5293     90.970  0.0048    99.834  29726.61
  83   0.5544     90.990  0.0051    99.836  30090.03
  84   0.5547     90.990  0.0051    99.816  30451.67
  85   0.5466     91.120  0.0042    99.886  30813.47
  86   0.5466     91.110  0.0045    99.848  31175.21
  87   0.5426     91.190  0.0040    99.884  31539.08
  88   0.5363     91.190  0.0040    99.848  31901.07
  89   0.5515     91.240  0.0038    99.882  32262.91
  90   0.5450     91.110  0.0039    99.882  32624.50
