Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7818078720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2906     11.570  24.6432    10.786  22.15
   2   2.2918     11.770  2.3081    11.130  42.29
   3   2.2833     12.550  2.2956    11.698  62.40
   4   2.2632     13.670  2.2928    12.286  82.52
   5   2.1988     15.910  2.2641    13.754  102.63
   6   1.9312     22.580  2.1220    18.704  122.75
   7   1.8383     24.520  1.9404    21.858  142.85
   8   8.7150     15.900  2.7394    21.956  162.98
   9   2.2742     12.900  2.4816    19.826  183.09
  10   2.2182     18.530  2.2741    12.412  203.21
  11   1.8473     24.320  2.0226    20.602  223.32
  12   1.7750     26.940  1.8648    23.954  243.46
  13   1.7308     29.060  1.8150    26.284  263.58
  14   1.6950     30.240  1.7670    29.082  283.68
  15   1.5843     37.540  1.6836    33.596  303.83
  16   1.5598     37.760  1.6359    36.432  323.95
  17   1.4332     44.050  1.5281    40.418  344.07
  18   1.4514     44.970  1.4591    43.618  364.17
  19   1.5744     47.230  1.3794    47.650  384.29
  20   1.2552     52.660  1.3016    51.522  404.40
  21   1.1458     58.500  1.2288    54.492  424.54
  22   1.0889     60.260  1.1435    58.438  444.68
  23   1.0689     61.100  1.0824    61.234  464.81
  24   1.0543     63.300  1.0110    64.224  484.93
  25   1.0182     65.030  0.9544    66.720  505.07
  26   0.8619     69.900  0.8947    69.094  525.20
  27   0.8198     71.140  0.8404    71.198  545.32
  28   0.8411     72.090  0.7811    73.180  565.43
  29   0.7673     74.250  0.7387    75.030  585.58
  30   0.7804     73.470  0.7028    76.502  605.71
  31   0.6966     76.290  0.6678    77.776  625.85
  32   0.7339     76.170  0.6215    79.282  645.95
  33   0.6875     77.180  0.5904    80.410  666.11
  34   0.6130     79.670  0.5622    81.334  686.22
  35   0.6223     80.000  0.5312    82.480  706.35
  36   0.5574     81.750  0.5106    83.090  726.47
  37   0.5555     81.570  0.4982    83.412  746.59
  38   0.5306     82.710  0.4576    85.146  766.72
  39   0.4911     84.430  0.4282    85.892  786.82
  40   0.4856     84.450  0.3986    86.828  806.97
  41   0.4835     84.250  0.3793    87.316  827.09
  42   0.4800     84.690  0.3781    87.744  847.23
  43   0.4810     84.650  0.3700    87.854  867.32
  44   0.7360     77.130  0.3874    87.452  887.44
  45   0.5198     83.600  0.4349    85.770  907.56
  46   0.4951     84.420  0.3737    87.698  927.67
  47   0.4863     84.390  0.3489    88.490  947.79
  48   0.4994     84.130  0.3408    88.640  967.89
  49   0.4806     84.530  0.3301    89.088  988.02
  50   0.4775     84.710  0.3309    89.284  1008.14
  51   0.4789     85.170  0.3178    89.566  1028.29
  52   0.4541     85.500  0.3075    89.858  1048.40
  53   0.4466     85.770  0.2916    90.376  1068.52
  54   0.4531     85.940  0.2858    90.544  1088.65
  55   0.4427     85.820  0.2765    90.688  1108.77
  56   0.4589     85.520  0.2730    91.054  1128.93
  57   0.4614     85.520  0.2662    91.076  1149.04
  58   0.4591     85.230  0.2617    91.476  1169.17
  59   0.4431     86.240  0.2556    91.592  1189.32
  60   0.4550     85.870  0.2516    91.600  1209.43
  61   0.4398     86.170  0.2459    91.870  1229.60
  62   0.4418     86.240  0.2390    91.966  1249.71
  63   0.4491     85.960  0.2349    92.266  1269.88
  64   0.4903     84.920  0.2354    92.270  1290.02
  65   0.4599     85.430  0.3038    90.016  1310.15
  66   0.4546     85.710  0.2462    91.768  1330.29
  67   0.4554     86.030  0.2328    92.394  1350.43
  68   0.4541     86.230  0.2219    92.606  1370.55
  69   0.4593     85.780  0.2163    92.800  1390.66
  70   0.4482     86.290  0.2126    93.004  1410.78
  71   0.4460     86.440  0.2060    93.120  1430.88
  72   0.4532     86.090  0.2005    93.420  1451.02
  73   0.4528     86.350  0.1966    93.376  1471.12
  74   0.4583     86.410  0.1938    93.640  1491.24
  75   0.4507     86.630  0.1877    93.726  1511.38
  76   0.4524     86.570  0.1855    93.848  1531.49
  77   0.4477     86.530  0.1840    93.836  1551.67
  78   0.4523     86.530  0.1811    94.112  1571.79
  79   0.4491     86.480  0.1788    93.968  1591.94
  80   0.4531     86.630  0.1756    94.102  1612.10
  81   0.4543     86.590  0.1737    94.174  1632.23
  82   0.4544     86.680  0.1760    94.170  1652.38
  83   0.4564     86.500  0.1732    94.220  1672.49
  84   0.4532     86.620  0.1747    94.230  1692.62
  85   0.4568     86.670  0.1747    94.226  1712.73
