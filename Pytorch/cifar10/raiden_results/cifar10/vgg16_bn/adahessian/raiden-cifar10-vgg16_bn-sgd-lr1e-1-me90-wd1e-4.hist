Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7815981568 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3030     10.000  38.8406    10.068  22.41
   2   2.3028     10.000  2.3080    10.166  42.90
   3   2.3026     10.000  2.3041     9.766  63.38
   4   2.3026     10.000  2.3052     9.966  83.85
   5   2.3025     10.000  2.3041     9.790  104.34
   6   2.3027     10.040  2.3035    10.112  124.82
   7   2.3026     10.050  2.3039     9.984  145.30
   8   2.3027     10.000  2.3036     9.966  165.79
   9   2.3027     10.040  2.3029    10.018  186.25
  10   2.3026     10.000  2.3029    10.050  206.87
  11   2.3027     10.000  2.3029    10.150  227.43
  12   2.3025     10.050  2.3028    10.174  247.90
  13   2.3030     10.040  2.3030    10.090  268.39
  14   2.3023     10.060  2.3030    10.194  288.85
  15   2.3023      9.960  2.3027    10.042  309.35
  16   2.3027     10.070  2.3022    10.108  329.82
  17   2.3019     10.100  2.3017    10.272  350.29
  18   2.3029     10.020  2.3002    10.420  370.75
  19   2.3025     10.000  2.3025    10.204  391.25
  20   2.2979     10.500  2.2975    10.478  411.71
  21   2.0968     17.040  2.2449    13.048  432.20
  22   1.9156     19.820  2.0495    17.604  452.66
  23   1.8516     21.980  1.9332    19.324  473.14
  24   1.7368     30.600  1.8700    23.198  493.63
  25   1.5706     38.330  1.7380    31.326  514.10
  26   1.6123     38.300  1.6077    37.748  534.57
  27   1.4205     47.200  1.4607    44.988  555.03
  28   1.5236     49.450  1.3435    50.676  575.52
  29   1.1027     60.120  1.2553    54.612  595.98
  30   0.9672     65.890  1.1088    61.296  616.47
  31   0.9233     67.150  0.9991    65.336  636.93
  32   0.8138     72.240  0.9190    68.254  657.40
  33   0.7684     73.730  0.8252    71.808  677.84
  34   0.7220     75.260  0.7464    74.708  698.31
  35   0.7278     74.890  0.6992    76.284  718.81
  36   0.6701     77.600  0.6687    77.716  739.30
  37   0.7358     75.380  0.6379    78.808  759.80
  38   0.6317     78.610  0.6036    79.916  780.27
  39   0.6216     79.330  0.5779    80.848  800.76
  40   0.6263     79.070  0.5572    81.494  821.22
  41   0.6634     79.240  0.5361    82.380  841.73
  42   0.5407     82.380  0.4911    83.790  862.19
  43   0.4950     83.600  0.4623    85.012  882.68
  44   0.5301     83.010  0.4227    85.996  903.16
  45   0.4855     83.730  0.4184    86.198  923.66
  46   0.5245     83.380  0.3921    87.012  944.15
  47   0.4992     84.010  0.3775    87.730  964.66
  48   0.5133     83.630  0.3574    88.146  985.16
  49   0.4797     84.490  0.3509    88.248  1005.62
  50   0.4962     84.130  0.3382    88.664  1026.12
  51   0.4934     84.560  0.3241    89.372  1046.58
  52   0.4723     85.160  0.3263    89.106  1067.05
  53   0.4600     85.490  0.3009    89.806  1087.50
  54   0.4687     85.710  0.2781    90.682  1107.99
  55   0.4668     86.030  0.2704    91.000  1128.52
  56   0.4539     86.140  0.2588    91.292  1149.01
  57   0.4851     85.460  0.2462    91.818  1169.49
  58   0.4560     85.720  0.2453    91.774  1189.95
  59   0.4584     86.320  0.2308    92.240  1210.43
  60   0.4664     86.390  0.2204    92.648  1230.90
  61   0.4477     86.530  0.2088    93.048  1251.40
  62   0.4942     86.240  0.2102    92.950  1271.85
  63   0.4879     86.160  0.1990    93.380  1292.36
  64   0.4550     86.920  0.1914    93.668  1312.85
  65   0.4723     86.490  0.1833    93.842  1333.32
  66   0.4750     86.730  0.1733    94.276  1353.79
  67   0.4631     87.040  0.1695    94.248  1374.25
  68   0.4719     87.150  0.1510    94.920  1394.70
  69   0.4787     87.080  0.1352    95.606  1415.17
  70   0.4797     87.140  0.1317    95.630  1435.65
  71   0.4776     87.310  0.1280    95.744  1456.13
  72   0.4907     87.190  0.1251    95.714  1476.69
  73   0.4896     87.360  0.1213    95.880  1497.19
  74   0.5006     87.310  0.1214    96.024  1517.65
  75   0.4865     87.240  0.1258    95.756  1538.15
  76   0.4993     87.360  0.1221    95.910  1558.59
  77   0.4974     87.350  0.1230    95.866  1579.06
  78   0.5014     87.290  0.1213    95.892  1599.52
  79   0.5074     87.340  0.1196    95.898  1620.00
  80   0.5069     87.370  0.1167    96.024  1640.46
  81   0.5088     87.500  0.1199    95.990  1660.91
  82   0.5058     87.450  0.1124    96.120  1681.40
  83   0.5080     87.340  0.1153    96.088  1701.91
  84   0.5023     87.490  0.1131    96.230  1722.38
  85   0.5124     87.550  0.1103    96.190  1742.84
  86   0.5073     87.350  0.1108    96.286  1763.32
  87   0.5105     87.460  0.1141    96.096  1783.78
  88   0.5132     87.350  0.1103    96.262  1804.27
  89   0.5073     87.470  0.1127    96.204  1824.72
  90   0.5083     87.400  0.1102    96.306  1845.23
