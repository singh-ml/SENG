Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7814670848 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2967     10.660  16.8535    11.000  22.30
   2   2.3884     11.300  2.3697    10.966  42.48
   3   2.2726     12.140  2.2931    11.532  62.67
   4   2.2648     12.830  2.2766    11.886  82.86
   5   2.2588     13.270  2.2693    12.276  103.06
   6   1.9335     19.200  2.1623    16.254  123.27
   7   1.8434     23.670  1.9126    21.990  143.45
   8   1.8488     28.380  1.8473    25.072  163.70
   9   1.7180     31.280  1.8341    27.910  183.89
  10   1.5578     38.270  1.6774    33.794  204.10
  11   1.4674     44.310  1.5617    40.014  224.31
  12   1.4069     45.270  1.4475    44.976  244.51
  13   1.3307     50.570  1.3538    49.178  264.74
  14   1.1485     57.140  1.2806    52.764  284.94
  15   1.0958     59.450  1.1644    57.802  305.14
  16   1.0443     62.220  1.0814    61.650  325.32
  17   0.9279     67.790  0.9975    64.944  345.55
  18   0.8087     71.380  0.9399    68.198  365.72
  19   0.7965     71.910  0.8065    72.430  385.94
  20   0.7570     73.580  0.7674    73.792  406.19
  21   0.7547     73.780  0.7297    75.228  426.42
  22   0.6858     76.590  0.6954    76.370  446.63
  23   0.6551     77.440  0.6690    77.604  466.88
  24   0.6774     77.490  0.6424    78.492  487.10
  25   0.6683     76.970  0.6283    79.050  507.37
  26   0.7023     76.810  0.6110    79.730  527.58
  27   0.6650     77.630  0.6425    79.652  547.84
  28   0.6652     77.500  0.5828    80.688  568.14
  29   0.6365     79.120  0.5918    80.726  588.40
  30   0.5905     80.150  0.5464    81.748  608.61
  31   0.6156     79.220  0.5249    82.648  628.88
  32   0.6371     78.090  0.6102    79.908  649.13
  33   0.5925     79.350  0.5647    80.852  669.41
  34   0.5691     80.720  0.5147    82.780  689.59
  35   0.6132     79.110  0.5359    82.334  709.86
  36   0.5969     80.250  0.5026    83.466  730.04
  37   0.5781     81.340  0.4631    84.820  750.20
  38   0.5604     81.300  0.4379    85.692  770.40
  39   0.5470     81.650  0.4165    86.190  790.58
  40   0.5779     80.190  0.4312    85.926  810.79
  41   0.5093     82.560  0.4128    86.124  830.99
  42   0.5553     81.900  0.3882    87.090  851.18
  43   0.5337     82.500  0.3752    87.638  871.38
  44   0.5357     82.300  0.3590    88.180  891.58
  45   0.5499     81.760  0.3543    88.402  911.76
  46   0.5508     82.540  0.3335    88.934  931.99
  47   0.5997     83.360  0.3226    89.364  952.19
  48   0.4991     83.880  0.3159    89.556  972.38
  49   0.4873     84.490  0.2996    90.260  992.58
  50   0.4787     85.170  0.2710    91.078  1012.79
  51   0.4978     84.070  0.2627    91.368  1032.99
  52   0.5033     84.360  0.2558    91.502  1053.19
  53   0.4767     84.870  0.2481    91.700  1073.41
  54   0.5592     83.340  0.2409    91.886  1093.60
  55   0.4857     84.970  0.2344    92.238  1113.80
  56   0.4977     84.990  0.2206    92.650  1134.03
  57   0.5160     84.570  0.2090    93.232  1154.25
  58   0.4782     85.340  0.2048    93.212  1174.44
  59   0.4985     85.360  0.2000    93.444  1194.65
  60   0.5028     85.330  0.1892    93.726  1214.87
  61   0.4855     85.910  0.1806    93.992  1235.05
  62   0.5051     84.710  0.1805    94.036  1255.27
  63   0.4915     85.880  0.1637    94.604  1275.46
  64   0.4918     85.630  0.1581    94.808  1295.68
  65   0.4997     85.530  0.1577    94.806  1315.83
  66   0.4942     85.970  0.1452    95.226  1336.02
  67   0.5036     86.900  0.1250    95.926  1356.25
  68   0.5053     86.720  0.1198    96.184  1376.44
  69   0.5195     86.520  0.1091    96.500  1396.65
  70   0.5074     86.610  0.1097    96.512  1416.84
  71   0.5213     86.730  0.1046    96.672  1437.03
  72   0.5254     86.790  0.1054    96.596  1457.23
  73   0.5143     86.780  0.1030    96.660  1477.45
  74   0.5191     86.900  0.1020    96.726  1497.65
  75   0.5219     86.830  0.1016    96.828  1517.83
  76   0.5214     86.840  0.0986    96.758  1538.06
  77   0.5280     86.670  0.0986    96.800  1558.25
  78   0.5352     86.580  0.0938    96.926  1578.44
  79   0.5387     86.830  0.0943    96.934  1598.63
  80   0.5262     86.760  0.0948    96.970  1618.81
  81   0.5346     86.710  0.0903    96.954  1639.02
  82   0.5332     86.710  0.0945    97.112  1659.24
  83   0.5393     86.810  0.0900    97.128  1679.43
  84   0.5378     86.670  0.1110    96.982  1699.62
  85   0.5122     86.280  0.1412    95.598  1719.84
  86   0.5127     86.570  0.1066    96.590  1740.02
  87   0.5176     86.520  0.1022    96.736  1760.22
  88   0.5232     86.550  0.0970    96.928  1780.43
  89   0.5237     86.640  0.0962    96.834  1800.63
  90   0.5212     86.750  0.0973    96.832  1820.83
