Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7815981568 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2239     16.250  3.1422    12.336  22.09
   2   1.7644     32.620  2.0254    21.576  42.16
   3   1.4920     43.640  1.6983    34.218  62.25
   4   1.3270     51.880  1.4646    45.210  82.31
   5   1.1713     57.160  1.2951    52.678  102.40
   6   1.1007     60.280  1.1843    57.248  122.47
   7   1.0427     62.510  1.0974    60.462  142.55
   8   0.9486     65.660  1.0257    63.220  162.63
   9   0.9367     66.230  0.9587    65.824  182.68
  10   0.8832     68.180  0.9177    67.470  202.76
  11   0.9027     68.630  0.8583    69.748  222.83
  12   0.8004     72.360  0.8077    71.798  242.94
  13   0.7783     72.780  0.7671    73.160  263.01
  14   0.7292     74.180  0.7317    74.510  283.09
  15   0.7831     72.460  0.6916    76.040  303.19
  16   0.7270     75.260  0.6616    77.038  323.24
  17   0.6959     75.990  0.6285    78.230  343.32
  18   0.6896     75.750  0.6046    79.004  363.38
  19   0.6821     75.990  0.5751    80.074  383.45
  20   0.6552     77.430  0.5534    80.798  403.52
  21   0.6532     77.500  0.5261    81.800  423.60
  22   0.6373     77.390  0.5062    82.412  443.71
  23   0.5787     79.940  0.4831    83.370  463.83
  24   0.7047     76.420  0.4639    84.018  483.93
  25   0.5765     79.720  0.4525    84.424  503.99
  26   0.6116     79.440  0.4295    85.052  524.07
  27   0.6011     79.140  0.4132    85.718  544.14
  28   0.5902     79.750  0.3970    86.246  564.23
  29   0.5654     80.810  0.3778    86.952  584.31
  30   0.5591     81.430  0.3678    87.358  604.39
  31   0.5577     81.540  0.3528    88.004  624.48
  32   0.5624     81.480  0.3288    88.570  644.55
  33   0.5558     81.760  0.3150    89.088  664.66
  34   0.5387     82.260  0.3062    89.460  684.72
  35   0.5487     82.420  0.2943    89.712  704.83
  36   0.5857     81.520  0.2815    90.256  724.91
  37   0.6042     81.500  0.2621    90.820  744.99
  38   0.5635     82.230  0.2583    91.092  765.05
  39   0.5649     82.910  0.2426    91.624  785.20
  40   0.5627     82.450  0.2356    91.808  805.29
  41   0.5736     82.330  0.2243    92.246  825.36
  42   0.5874     82.430  0.2143    92.658  845.46
  43   0.5818     82.550  0.2030    92.984  865.52
  44   0.5817     82.830  0.1917    93.466  885.62
  45   0.6033     82.770  0.1835    93.708  905.68
  46   0.5925     82.950  0.1750    93.930  925.79
  47   0.5820     82.700  0.1690    94.242  945.86
  48   0.6384     82.570  0.1573    94.686  965.98
  49   0.6195     83.190  0.1510    94.846  986.07
  50   0.6302     82.700  0.1477    94.880  1006.14
  51   0.6411     83.310  0.1388    95.186  1026.23
  52   0.6333     83.130  0.1305    95.550  1046.31
  53   0.6473     83.500  0.1248    95.692  1066.41
  54   0.6469     83.560  0.1205    95.870  1086.51
  55   0.6687     83.220  0.1116    96.120  1106.58
  56   0.6647     83.510  0.1089    96.262  1126.68
  57   0.6791     83.260  0.1036    96.420  1146.75
  58   0.6731     83.610  0.1058    96.390  1166.88
  59   0.7066     83.200  0.1007    96.564  1186.95
  60   0.6912     83.420  0.0938    96.786  1207.04
  61   0.7172     83.190  0.0917    96.810  1227.11
  62   0.7088     83.280  0.0828    97.238  1247.19
  63   0.7385     83.310  0.0833    97.060  1267.28
  64   0.7163     83.660  0.0806    97.202  1287.35
  65   0.7413     83.420  0.0773    97.332  1307.43
  66   0.7295     83.320  0.0742    97.492  1327.50
  67   0.7358     83.540  0.0747    97.484  1347.58
  68   0.7592     83.570  0.0724    97.600  1367.66
  69   0.7500     83.540  0.0698    97.602  1387.76
  70   0.7538     83.670  0.0679    97.702  1407.83
  71   0.7547     83.680  0.0682    97.712  1427.95
  72   0.7557     83.520  0.0679    97.748  1448.05
  73   0.7641     83.760  0.0626    97.936  1468.12
  74   0.7683     83.610  0.0631    97.840  1488.22
  75   0.7838     83.560  0.0590    98.044  1508.30
  76   0.7780     83.630  0.0581    98.060  1528.40
  77   0.8027     83.450  0.0584    97.996  1548.49
  78   0.7985     83.700  0.0561    98.080  1568.57
  79   0.8018     83.580  0.0543    98.208  1588.64
  80   0.8168     83.540  0.0537    98.204  1608.70
  81   0.8032     83.660  0.0532    98.210  1628.78
  82   0.8179     83.580  0.0518    98.250  1648.86
  83   0.8205     83.570  0.0534    98.248  1668.99
  84   0.8117     83.570  0.0524    98.202  1689.06
  85   0.8296     83.480  0.0497    98.302  1709.20
