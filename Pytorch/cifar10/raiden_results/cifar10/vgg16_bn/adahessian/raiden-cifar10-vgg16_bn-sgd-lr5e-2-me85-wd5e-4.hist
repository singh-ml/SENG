Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7816505856 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2811     12.130  5.7913    11.628  22.48
   2   2.2572     13.260  2.2675    12.666  43.00
   3   1.9431     20.340  2.1154    17.794  63.51
   4   1.8178     26.620  1.9003    22.858  84.02
   5   1.7981     30.260  1.8246    26.900  104.54
   6   1.5342     40.200  1.6827    33.342  125.07
   7   1.3913     46.550  1.5397    40.866  145.64
   8   1.3084     50.900  1.4331    46.716  166.16
   9   1.2422     54.830  1.3899    50.340  186.70
  10   1.1766     59.120  1.2027    57.582  207.27
  11   1.0334     64.610  1.0748    62.462  227.77
  12   1.2077     59.940  1.1739    59.956  248.33
  13   1.0404     62.830  1.0815    62.142  268.85
  14   0.8715     69.170  0.9351    67.592  289.40
  15   0.8312     71.930  0.8433    71.130  309.91
  16   0.7994     72.530  0.7811    73.866  330.43
  17   0.7099     75.640  0.7222    75.660  350.99
  18   0.6735     76.960  0.6828    77.026  371.51
  19   0.7168     76.190  0.6403    78.594  392.08
  20   0.6781     77.480  0.6063    79.820  412.60
  21   0.6314     78.600  0.5868    80.662  433.14
  22   0.6887     77.540  0.5572    81.512  453.66
  23   0.6088     79.570  0.5301    82.356  474.19
  24   0.5623     80.890  0.4985    83.358  494.71
  25   0.5742     80.680  0.4781    84.226  515.23
  26   0.5464     81.570  0.4603    84.862  535.77
  27   0.5377     81.950  0.4480    85.218  556.31
  28   0.6204     79.510  0.4201    86.252  576.88
  29   0.5054     83.020  0.3974    86.974  597.39
  30   0.5189     82.800  0.4005    86.774  617.93
  31   0.5534     82.400  0.3754    87.580  638.46
  32   0.5173     83.290  0.3604    88.144  659.02
  33   0.5420     82.640  0.3530    88.290  679.53
  34   0.4991     83.620  0.3365    88.722  700.09
  35   0.4967     84.120  0.3191    89.654  720.61
  36   0.4842     84.280  0.3010    90.022  741.14
  37   0.4818     84.580  0.2844    90.718  761.70
  38   0.4728     84.750  0.2708    90.948  782.25
  39   0.4930     84.690  0.2687    91.522  802.81
  40   0.4911     84.570  0.2565    91.552  823.31
  41   0.4819     84.830  0.2393    92.130  843.83
  42   0.4687     85.770  0.2316    92.244  864.33
  43   0.4706     85.300  0.2221    92.678  884.88
  44   0.4669     85.400  0.2178    92.794  905.41
  45   0.4611     85.990  0.2014    93.160  925.94
  46   0.4856     85.350  0.1957    93.552  946.48
  47   0.4887     85.410  0.1842    93.884  966.97
  48   0.4542     86.380  0.1871    93.772  987.51
  49   0.4879     85.380  0.1736    94.362  1008.05
  50   0.4832     86.290  0.1505    95.066  1028.58
  51   0.4859     86.800  0.1311    95.734  1049.10
  52   0.4772     86.570  0.1295    95.782  1069.64
  53   0.4860     86.480  0.1262    95.866  1090.17
  54   0.4745     86.730  0.1191    96.096  1110.71
  55   0.4793     86.920  0.1147    96.254  1131.25
  56   0.4870     86.800  0.1118    96.364  1151.79
  57   0.5026     86.750  0.1003    96.762  1172.32
  58   0.5172     86.630  0.0991    96.766  1192.84
  59   0.5184     86.870  0.0976    96.812  1213.42
  60   0.5117     87.050  0.0897    97.116  1233.96
  61   0.5089     87.130  0.0891    97.120  1254.51
  62   0.5033     87.270  0.0877    97.126  1275.04
  63   0.5182     86.970  0.0810    97.338  1295.59
  64   0.5155     87.150  0.0817    97.284  1316.14
  65   0.5190     87.360  0.0765    97.512  1336.64
  66   0.5347     87.230  0.0725    97.702  1357.17
  67   0.5303     87.450  0.0706    97.778  1377.69
  68   0.5538     87.160  0.0645    97.878  1398.24
  69   0.5421     87.440  0.0624    98.014  1418.78
  70   0.5503     87.300  0.0617    98.004  1439.33
  71   0.5647     87.410  0.0598    98.066  1459.85
  72   0.5633     87.010  0.0579    98.118  1480.42
  73   0.5601     87.360  0.0583    98.214  1500.94
  74   0.5645     87.230  0.0569    98.182  1521.47
  75   0.5639     87.440  0.0549    98.254  1541.98
  76   0.5656     87.290  0.0537    98.308  1562.52
  77   0.5737     87.300  0.0526    98.266  1583.10
  78   0.5761     87.480  0.0501    98.396  1603.66
  79   0.5839     87.390  0.0489    98.460  1624.19
  80   0.5936     87.300  0.0464    98.506  1644.72
  81   0.5860     87.330  0.0497    98.394  1665.26
  82   0.5776     87.420  0.0481    98.486  1685.78
  83   0.5837     87.350  0.0458    98.566  1706.31
  84   0.5793     87.280  0.0467    98.498  1726.85
  85   0.5935     87.480  0.0490    98.518  1747.45
