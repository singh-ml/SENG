Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7814670848 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7774     31.740  2.6581    17.550  22.40
   2   1.4718     45.150  1.6626    36.200  42.86
   3   1.2975     51.870  1.4148    47.566  63.32
   4   1.2087     57.090  1.2841    53.348  83.78
   5   1.0998     59.980  1.1690    58.086  104.27
   6   0.9979     64.420  1.0900    61.144  124.73
   7   0.9829     65.570  1.0116    64.066  145.20
   8   0.9215     67.220  0.9525    66.250  165.66
   9   0.8768     69.240  0.8977    68.318  186.14
  10   0.8286     70.970  0.8513    70.106  206.59
  11   0.8321     71.420  0.8017    72.142  227.07
  12   0.7805     73.220  0.7559    73.564  247.53
  13   0.7164     75.470  0.7198    74.984  267.97
  14   0.7397     74.310  0.6796    76.342  288.43
  15   0.7086     75.550  0.6584    77.250  308.88
  16   0.6593     77.310  0.6208    78.534  329.34
  17   0.6759     77.120  0.5938    79.606  349.80
  18   0.6479     77.870  0.5738    80.198  370.26
  19   0.6437     77.870  0.5384    81.496  390.74
  20   0.6605     77.570  0.5256    81.868  411.22
  21   0.6830     76.840  0.5001    82.862  431.68
  22   0.6407     78.090  0.4807    83.522  452.14
  23   0.5699     80.630  0.4600    84.286  472.62
  24   0.5833     80.430  0.4420    84.902  493.07
  25   0.5687     80.060  0.4242    85.534  513.55
  26   0.5860     80.090  0.4035    85.992  534.00
  27   0.5435     81.510  0.3935    86.426  554.47
  28   0.5584     81.010  0.3687    87.382  574.94
  29   0.5397     81.340  0.3538    87.826  595.42
  30   0.5463     81.620  0.3396    88.366  615.89
  31   0.5611     80.840  0.3287    88.648  636.40
  32   0.5754     81.340  0.3137    89.230  656.87
  33   0.5560     81.670  0.3004    89.670  677.34
  34   0.5460     81.950  0.2891    90.044  697.82
  35   0.5517     82.340  0.2709    90.678  718.27
  36   0.5366     82.290  0.2629    90.932  738.76
  37   0.5527     82.030  0.2493    91.420  759.23
  38   0.5551     82.490  0.2426    91.648  779.76
  39   0.5458     82.390  0.2298    92.030  800.21
  40   0.5475     83.010  0.2185    92.520  820.70
  41   0.5476     82.890  0.2072    92.890  841.18
  42   0.5608     83.120  0.1963    93.232  861.63
  43   0.5639     82.930  0.1900    93.480  882.12
  44   0.5665     83.350  0.1807    93.742  902.62
  45   0.5518     83.600  0.1692    94.204  923.13
  46   0.5831     83.010  0.1601    94.362  943.58
  47   0.5766     83.740  0.1544    94.642  964.06
  48   0.5745     83.800  0.1483    94.876  984.52
  49   0.5945     83.650  0.1405    95.056  1004.97
  50   0.5967     83.510  0.1357    95.310  1025.43
  51   0.5990     83.730  0.1252    95.684  1045.91
  52   0.6210     83.970  0.1220    95.700  1066.37
  53   0.6168     83.690  0.1187    96.016  1086.82
  54   0.6252     83.640  0.1114    96.232  1107.30
  55   0.6215     83.810  0.1076    96.254  1127.75
  56   0.6330     83.530  0.1036    96.452  1148.19
  57   0.6307     84.320  0.1009    96.554  1168.67
  58   0.6486     84.120  0.0953    96.682  1189.13
  59   0.6592     84.010  0.0934    96.844  1209.59
  60   0.6733     84.010  0.0904    96.902  1230.07
  61   0.6676     84.310  0.0868    96.996  1250.55
  62   0.6869     84.110  0.0831    97.144  1271.02
  63   0.6794     84.420  0.0827    97.188  1291.51
  64   0.6984     83.860  0.0795    97.268  1311.96
  65   0.7019     84.000  0.0754    97.434  1332.44
  66   0.7103     84.150  0.0710    97.570  1352.92
  67   0.7110     83.940  0.0726    97.538  1373.42
  68   0.7244     84.080  0.0667    97.646  1393.87
  69   0.7402     83.840  0.0650    97.802  1414.34
  70   0.7280     84.120  0.0665    97.712  1434.77
  71   0.7451     83.950  0.0643    97.744  1455.25
  72   0.7289     83.930  0.0635    97.784  1475.71
  73   0.7436     83.860  0.0611    97.904  1496.17
  74   0.7392     84.050  0.0594    97.982  1516.66
  75   0.7464     84.030  0.0585    97.994  1537.13
  76   0.7494     83.600  0.0582    97.992  1557.60
  77   0.7548     84.200  0.0574    97.996  1578.05
  78   0.7533     84.060  0.0535    98.156  1598.54
  79   0.7561     83.980  0.0551    98.142  1619.02
  80   0.7607     84.190  0.0536    98.214  1639.51
  81   0.7699     84.100  0.0497    98.264  1659.96
  82   0.7707     84.320  0.0503    98.242  1680.43
  83   0.7800     83.950  0.0508    98.270  1700.92
  84   0.7845     84.020  0.0504    98.298  1721.38
  85   0.7876     83.970  0.0473    98.446  1741.86
