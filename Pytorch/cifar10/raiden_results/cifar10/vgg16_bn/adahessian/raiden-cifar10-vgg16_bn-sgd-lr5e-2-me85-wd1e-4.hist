Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7815981568 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2768     13.120  4.5822    11.452  22.31
   2   2.2411     13.140  2.2864    12.204  42.77
   3   2.1221     18.190  2.2685    14.662  63.23
   4   1.8336     25.020  2.0000    20.628  83.71
   5   1.7405     29.660  1.8536    24.776  104.18
   6   1.6452     37.730  1.6998    31.998  124.63
   7   1.4628     43.310  1.5622    39.282  145.08
   8   1.3004     53.440  1.3869    47.264  165.55
   9   1.4776     47.260  1.2415    54.566  186.00
  10   1.2469     56.410  1.1089    60.600  206.48
  11   2.0347     41.920  1.0266    65.038  226.94
  12   0.9209     68.430  0.9926    65.948  247.41
  13   0.8752     71.890  0.8404    71.620  267.91
  14   0.7474     74.900  0.7691    74.372  288.37
  15   0.8031     72.770  0.7125    76.552  308.86
  16   0.7277     76.940  0.6792    78.462  329.32
  17   0.6400     78.820  0.6527    78.786  349.79
  18   0.6135     79.580  0.5885    80.794  370.25
  19   0.5637     80.720  0.5420    82.160  390.72
  20   0.5699     81.310  0.5410    82.378  411.18
  21   0.5756     80.980  0.4862    84.058  431.66
  22   0.5103     83.030  0.4550    85.054  452.11
  23   0.5367     82.000  0.4335    85.872  472.58
  24   0.5626     80.970  0.4288    85.998  493.08
  25   0.5243     82.510  0.4076    86.538  513.55
  26   0.5322     82.350  0.4302    86.400  534.04
  27   0.5187     83.160  0.3713    87.782  554.52
  28   0.4564     84.860  0.3592    88.276  575.00
  29   0.4582     85.070  0.3307    89.076  595.47
  30   0.4499     84.750  0.3313    89.212  615.97
  31   0.4567     85.300  0.2910    90.566  636.44
  32   0.4440     85.710  0.2773    90.826  656.94
  33   0.4399     85.720  0.2477    91.856  677.43
  34   0.4553     85.680  0.2291    92.450  697.89
  35   0.4470     86.080  0.2234    92.700  718.38
  36   0.4568     85.580  0.2282    92.916  738.84
  37   0.4278     86.480  0.2009    93.418  759.31
  38   0.4441     86.190  0.1943    93.624  779.79
  39   0.4408     86.720  0.1852    93.940  800.29
  40   0.4190     87.170  0.1785    94.272  820.76
  41   0.4661     86.250  0.1670    94.496  841.24
  42   0.4384     87.410  0.1678    94.798  861.74
  43   0.4225     87.480  0.1491    95.312  882.31
  44   0.4317     87.560  0.1254    95.850  902.81
  45   0.4244     87.780  0.1188    96.182  923.27
  46   0.4452     87.320  0.1154    96.214  943.73
  47   0.4674     87.590  0.1094    96.542  964.20
  48   0.4636     87.710  0.1058    96.522  984.68
  49   0.4469     87.620  0.1040    96.664  1005.14
  50   0.4595     87.740  0.0972    96.860  1025.61
  51   0.4717     87.270  0.1021    96.718  1046.10
  52   0.4465     87.940  0.0975    96.866  1066.57
  53   0.4567     87.620  0.0932    96.964  1087.04
  54   0.4527     87.820  0.0930    96.962  1107.49
  55   0.4926     87.540  0.0949    97.108  1127.99
  56   0.4723     87.100  0.1344    95.794  1148.45
  57   0.4762     87.420  0.1032    96.744  1168.92
  58   0.4732     87.560  0.0971    96.948  1189.37
  59   0.4858     87.560  0.0910    97.090  1209.83
  60   0.4968     87.490  0.0835    97.266  1230.30
  61   0.4955     87.780  0.0785    97.498  1250.79
  62   0.5087     87.420  0.0776    97.462  1271.23
  63   0.5002     87.560  0.0766    97.552  1291.74
  64   0.5034     87.760  0.0754    97.556  1312.24
  65   0.5194     87.690  0.0687    97.846  1332.72
  66   0.5100     87.710  0.0687    97.798  1353.20
  67   0.5297     87.290  0.0644    97.932  1373.66
  68   0.5130     87.750  0.0638    98.002  1394.16
  69   0.5249     87.740  0.0591    98.068  1414.62
  70   0.5270     87.720  0.0558    98.206  1435.09
  71   0.5237     87.770  0.0557    98.192  1455.56
  72   0.5408     87.550  0.0552    98.234  1476.02
  73   0.5326     87.900  0.0566    98.176  1496.49
  74   0.5342     87.830  0.0527    98.272  1516.95
  75   0.5310     87.850  0.0507    98.386  1537.46
  76   0.5423     87.800  0.0497    98.364  1557.92
  77   0.5545     87.660  0.0464    98.562  1578.43
  78   0.5496     87.650  0.0460    98.498  1598.86
  79   0.5525     87.690  0.0458    98.514  1619.32
  80   0.5450     87.790  0.0450    98.530  1639.79
  81   0.5529     87.690  0.0448    98.556  1660.26
  82   0.5596     87.880  0.0450    98.550  1680.72
  83   0.5634     87.870  0.0424    98.658  1701.20
  84   0.5543     87.730  0.0437    98.624  1721.68
  85   0.5470     87.830  0.0430    98.632  1742.24
