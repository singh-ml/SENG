Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-1', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7818078720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4611     10.230  79.7790    10.322  22.30
   2   2.3051     10.130  2.3351    10.284  42.41
   3   2.3033     11.240  2.3069    10.132  62.51
   4   2.3034     10.390  2.3181    10.216  82.66
   5   2.3023     10.560  2.3102    10.268  102.79
   6   2.3010     13.220  2.3060    10.308  122.89
   7   2.2975     12.230  2.3037    10.746  143.00
   8   2.2972     13.800  2.3015    11.056  163.10
   9   2.2881     14.320  2.2995    11.582  183.23
  10   2.2779     14.390  2.2953    12.006  203.35
  11   2.2678     14.920  2.2891    12.696  223.49
  12   2.2559     15.600  2.2807    13.366  243.60
  13   2.2086     16.540  2.2633    13.932  263.70
  14   2.0642     17.490  2.2357    15.020  283.87
  15   1.9470     17.870  2.0777    16.636  303.97
  16   1.8889     20.300  1.9609    18.602  324.08
  17   1.8864     20.860  1.9241    19.760  344.17
  18   1.8424     25.350  1.8919    21.640  364.29
  19   1.7916     25.750  1.8608    24.048  384.42
  20   1.7544     28.780  1.8266    25.994  404.51
  21   1.7130     32.410  1.7879    28.412  424.66
  22   1.6027     36.100  1.7179    31.782  444.76
  23   1.5855     38.770  1.6588    34.694  464.90
  24   1.4930     42.420  1.5877    36.660  485.00
  25   1.4352     44.380  1.4969    40.200  505.15
  26   1.3497     47.800  1.4235    44.876  525.27
  27   1.2949     51.390  1.3392    49.670  545.39
  28   1.1825     57.910  1.2153    55.488  565.53
  29   1.0594     62.110  1.1079    60.040  585.64
  30   0.9443     66.760  1.0168    64.630  605.80
  31   0.9791     66.310  0.9383    67.876  625.96
  32   0.8170     71.870  0.8349    71.876  646.08
  33   0.7458     74.380  0.7848    73.662  666.22
  34   0.8497     71.920  0.7407    75.490  686.33
  35   0.9174     70.020  0.7861    74.104  706.45
  36   0.6850     77.440  0.6967    77.204  726.57
  37   0.6765     77.830  0.6642    78.398  746.70
  38   0.6561     78.080  0.6180    79.752  766.82
  39   0.6620     78.890  0.5948    80.668  786.92
  40   0.6824     77.120  0.5704    81.638  807.09
  41   0.5942     80.700  0.5405    82.356  827.20
  42   0.6648     78.620  0.5109    83.578  847.34
  43   0.6078     80.770  0.4819    84.236  867.44
  44   0.5679     81.570  0.4642    85.022  887.57
  45   0.5481     82.520  0.4342    85.834  907.69
  46   0.5137     83.420  0.4070    86.664  927.81
  47   0.5198     83.770  0.3927    87.250  947.94
  48   0.5083     83.860  0.3849    87.462  968.05
  49   0.5042     84.220  0.3659    88.138  988.17
  50   0.4998     84.270  0.3484    88.762  1008.31
  51   0.4761     84.640  0.3250    89.286  1028.42
  52   0.4677     85.030  0.3106    89.780  1048.53
  53   0.5022     84.310  0.3114    89.906  1068.64
  54   0.4659     85.470  0.2817    90.928  1088.76
  55   0.4744     85.590  0.2655    91.214  1108.88
  56   0.4583     86.000  0.2500    91.674  1129.02
  57   0.4663     85.680  0.2453    92.106  1149.16
  58   0.4846     85.740  0.2338    92.388  1169.28
  59   0.4757     85.980  0.2234    92.718  1189.38
  60   0.4820     86.080  0.2142    93.042  1209.49
  61   0.4782     86.080  0.2094    93.330  1229.64
  62   0.4833     86.030  0.2007    93.420  1249.76
  63   0.4748     86.180  0.1967    93.620  1269.89
  64   0.4795     85.840  0.1904    93.748  1290.00
  65   0.4784     86.530  0.1853    93.922  1310.14
  66   0.4859     86.310  0.1835    94.014  1330.24
  67   0.4924     86.380  0.1747    94.166  1350.37
  68   0.4783     86.550  0.1760    94.274  1370.49
  69   0.4885     86.310  0.1720    94.334  1390.64
  70   0.5041     86.330  0.1673    94.478  1410.79
  71   0.4898     86.470  0.1646    94.780  1430.90
  72   0.5041     86.480  0.1613    94.654  1451.05
  73   0.4949     86.540  0.1560    94.902  1471.18
  74   0.4972     86.370  0.1529    95.004  1491.31
  75   0.5012     86.440  0.1529    94.986  1511.42
  76   0.5008     86.440  0.1513    95.068  1531.55
  77   0.4920     86.550  0.1484    95.124  1551.68
  78   0.5043     86.710  0.1467    95.228  1571.77
  79   0.5093     86.580  0.1454    95.292  1591.91
  80   0.5064     86.530  0.1465    95.138  1612.04
  81   0.5003     86.700  0.1456    95.232  1632.17
  82   0.5053     86.440  0.1462    95.342  1652.28
  83   0.5069     86.490  0.1482    95.148  1672.41
  84   0.5035     86.570  0.1437    95.292  1692.53
  85   0.5062     86.600  0.1428    95.318  1712.70
