Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7818078720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6707     36.470  2.2534    23.440  22.44
   2   1.3337     51.000  1.5418    42.086  42.90
   3   1.1712     56.510  1.3268    51.654  63.37
   4   1.1694     58.770  1.2037    56.608  83.86
   5   1.0327     62.970  1.0995    60.698  104.33
   6   0.9345     66.630  1.0179    63.752  124.79
   7   0.9514     66.110  0.9443    66.634  145.27
   8   0.8572     69.170  0.8831    69.134  165.73
   9   0.8142     71.680  0.8328    71.042  186.21
  10   0.7904     72.240  0.7792    72.958  206.69
  11   0.7526     73.520  0.7378    74.178  227.19
  12   0.7600     74.130  0.6956    75.918  247.65
  13   0.7109     75.460  0.6652    77.058  268.17
  14   0.6908     75.500  0.6335    78.008  288.63
  15   0.6655     76.300  0.6003    79.318  309.14
  16   0.6578     77.440  0.5743    80.162  329.62
  17   0.6277     77.620  0.5470    81.172  350.14
  18   0.6121     78.740  0.5310    81.762  370.64
  19   0.6435     78.010  0.5054    82.576  391.11
  20   0.5850     79.470  0.4873    83.318  411.58
  21   0.5674     80.550  0.4663    83.864  432.04
  22   0.5888     79.630  0.4451    84.726  452.55
  23   0.5550     80.280  0.4217    85.618  473.02
  24   0.5373     81.460  0.4094    85.998  493.49
  25   0.5518     81.050  0.3998    86.354  513.97
  26   0.5663     80.790  0.3815    87.034  534.48
  27   0.5899     79.390  0.3634    87.476  554.96
  28   0.5685     80.610  0.3456    88.052  575.42
  29   0.5294     82.350  0.3295    88.748  595.90
  30   0.5320     82.310  0.3181    88.978  616.37
  31   0.5125     82.900  0.2994    89.738  636.87
  32   0.5549     81.360  0.2877    90.012  657.34
  33   0.5170     83.080  0.2772    90.516  677.81
  34   0.5237     82.540  0.2676    90.798  698.27
  35   0.5054     83.340  0.2537    91.342  718.75
  36   0.5134     83.310  0.2458    91.560  739.20
  37   0.5257     83.200  0.2283    92.250  759.66
  38   0.5263     83.630  0.2170    92.564  780.15
  39   0.5248     83.250  0.2072    92.948  800.61
  40   0.5167     83.890  0.2006    93.114  821.11
  41   0.5117     84.110  0.1927    93.352  841.58
  42   0.5310     83.600  0.1822    93.802  862.09
  43   0.5339     83.600  0.1721    94.176  882.57
  44   0.5378     83.650  0.1661    94.316  903.13
  45   0.5575     84.100  0.1586    94.524  923.58
  46   0.5387     84.490  0.1551    94.690  944.04
  47   0.5457     83.990  0.1459    94.926  964.53
  48   0.5488     84.190  0.1403    95.096  984.99
  49   0.5743     83.930  0.1296    95.516  1005.48
  50   0.5608     84.300  0.1281    95.604  1025.94
  51   0.5663     84.440  0.1232    95.868  1046.48
  52   0.5698     84.360  0.1178    95.956  1066.94
  53   0.5852     84.690  0.1086    96.312  1087.41
  54   0.5755     84.810  0.1095    96.234  1107.87
  55   0.5873     84.520  0.1029    96.462  1128.33
  56   0.6085     84.420  0.0980    96.692  1148.80
  57   0.6119     84.580  0.0920    96.830  1169.26
  58   0.6133     84.490  0.0918    96.876  1189.76
  59   0.6090     84.400  0.0895    96.886  1210.26
  60   0.6274     84.680  0.0812    97.194  1230.75
  61   0.6368     84.590  0.0816    97.228  1251.21
  62   0.6325     84.690  0.0781    97.306  1271.70
  63   0.6350     84.780  0.0773    97.398  1292.16
  64   0.6538     84.660  0.0741    97.386  1312.68
  65   0.6560     84.600  0.0700    97.598  1333.20
  66   0.6749     84.710  0.0675    97.688  1353.65
  67   0.6614     84.380  0.0708    97.622  1374.12
  68   0.6740     84.840  0.0672    97.706  1394.57
  69   0.6742     84.680  0.0619    97.904  1415.05
  70   0.6816     84.770  0.0623    97.842  1435.52
  71   0.6840     84.870  0.0619    97.932  1456.01
  72   0.6899     84.630  0.0603    97.938  1476.46
  73   0.6918     84.740  0.0573    98.102  1496.95
  74   0.6981     84.880  0.0583    97.944  1517.40
  75   0.6996     84.840  0.0570    97.992  1537.90
  76   0.7038     84.730  0.0522    98.248  1558.37
  77   0.7117     84.790  0.0544    98.222  1578.92
  78   0.7139     84.790  0.0531    98.190  1599.42
  79   0.7108     84.970  0.0504    98.220  1619.90
  80   0.7155     84.910  0.0510    98.256  1640.37
  81   0.7095     85.180  0.0506    98.306  1660.86
  82   0.7213     84.890  0.0520    98.296  1681.33
  83   0.7245     85.010  0.0502    98.278  1701.80
  84   0.7265     85.090  0.0476    98.412  1722.27
  85   0.7223     84.870  0.0516    98.284  1742.73
