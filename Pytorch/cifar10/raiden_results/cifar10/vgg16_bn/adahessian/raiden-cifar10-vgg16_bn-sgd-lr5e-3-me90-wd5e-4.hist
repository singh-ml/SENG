Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7815981568 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6992     36.180  2.0979    23.220  22.15
   2   1.4057     47.960  1.6193    38.848  42.33
   3   1.2813     53.810  1.4336    46.798  62.50
   4   1.1715     57.920  1.3145    52.194  82.70
   5   1.1271     59.260  1.2313    55.378  102.87
   6   1.0820     61.030  1.1648    58.144  123.06
   7   1.0397     62.770  1.1091    60.054  143.25
   8   1.0376     63.570  1.0617    62.118  163.42
   9   0.9577     65.900  1.0091    64.124  183.60
  10   0.9491     66.510  0.9706    65.546  203.83
  11   0.8892     68.810  0.9357    66.862  224.03
  12   0.8804     68.240  0.8929    68.368  244.18
  13   0.8641     69.150  0.8694    69.606  264.35
  14   0.8208     70.770  0.8362    70.606  284.51
  15   0.8277     70.890  0.8138    71.538  304.68
  16   0.8075     71.000  0.7827    72.390  324.87
  17   0.7752     72.810  0.7599    73.338  345.03
  18   0.7548     73.190  0.7405    74.110  365.25
  19   0.7744     72.800  0.7160    74.902  385.40
  20   0.7254     74.410  0.6893    75.730  405.59
  21   0.7219     74.550  0.6717    76.484  425.75
  22   0.7287     74.150  0.6551    77.174  445.94
  23   0.6916     75.660  0.6360    77.690  466.10
  24   0.6819     75.950  0.6187    78.260  486.29
  25   0.6975     75.420  0.6020    78.928  506.51
  26   0.6975     75.640  0.5815    79.722  526.67
  27   0.6553     76.690  0.5727    79.938  546.89
  28   0.6628     77.010  0.5518    80.598  567.06
  29   0.6504     77.040  0.5443    80.938  587.31
  30   0.6405     77.910  0.5311    81.404  607.50
  31   0.6439     77.440  0.5081    82.400  627.75
  32   0.6481     77.460  0.5037    82.196  647.96
  33   0.6615     76.940  0.4962    82.550  668.17
  34   0.6311     78.160  0.4821    83.132  688.37
  35   0.6203     78.220  0.4704    83.526  708.56
  36   0.6249     78.390  0.4546    84.152  728.78
  37   0.6251     78.740  0.4495    84.144  748.95
  38   0.6142     78.490  0.4371    84.862  769.12
  39   0.6223     78.520  0.4238    85.160  789.31
  40   0.6232     78.970  0.4174    85.220  809.48
  41   0.6039     79.490  0.4063    85.850  829.67
  42   0.6048     79.350  0.3975    86.022  849.85
  43   0.6087     79.860  0.3811    86.726  870.07
  44   0.6104     79.550  0.3773    86.874  890.23
  45   0.6104     80.060  0.3683    87.114  910.40
  46   0.6105     79.750  0.3617    87.362  930.61
  47   0.6208     79.520  0.3553    87.582  950.78
  48   0.6387     79.300  0.3484    87.850  970.97
  49   0.6188     79.760  0.3368    88.168  991.14
  50   0.6214     79.590  0.3298    88.396  1011.32
  51   0.6112     79.530  0.3213    88.766  1031.49
  52   0.6229     79.710  0.3192    88.878  1051.66
  53   0.6151     80.230  0.3107    89.126  1071.83
  54   0.6223     79.840  0.3016    89.522  1092.03
  55   0.6290     80.170  0.2946    89.686  1112.25
  56   0.6222     80.200  0.2911    89.886  1132.47
  57   0.6229     80.340  0.2820    90.064  1152.71
  58   0.6287     80.220  0.2759    90.334  1172.92
  59   0.6279     80.320  0.2736    90.400  1193.14
  60   0.6418     79.850  0.2695    90.598  1213.35
  61   0.6595     80.100  0.2592    90.900  1233.62
  62   0.6418     80.170  0.2562    91.028  1253.89
  63   0.6374     80.520  0.2531    91.194  1274.18
  64   0.6458     80.590  0.2449    91.398  1294.44
  65   0.6616     80.060  0.2425    91.406  1314.63
  66   0.6516     80.360  0.2403    91.618  1334.86
  67   0.6426     80.030  0.2385    91.516  1355.05
  68   0.6593     80.450  0.2272    92.118  1375.29
  69   0.6578     80.560  0.2282    91.942  1395.48
  70   0.6732     80.630  0.2206    92.266  1415.67
  71   0.6670     80.600  0.2237    92.192  1435.88
  72   0.6756     80.860  0.2178    92.314  1456.06
  73   0.6846     80.630  0.2102    92.714  1476.23
  74   0.6783     80.290  0.2114    92.520  1496.39
  75   0.6785     80.680  0.2077    92.714  1516.60
  76   0.6829     80.230  0.2083    92.764  1536.79
  77   0.6849     80.500  0.2028    92.908  1556.96
  78   0.7012     80.440  0.1972    93.028  1577.15
  79   0.7014     80.530  0.1943    93.124  1597.33
  80   0.6984     80.400  0.1932    93.230  1617.54
  81   0.7011     80.730  0.1923    93.264  1637.70
  82   0.6993     80.430  0.1934    93.266  1657.92
  83   0.7037     80.500  0.1865    93.496  1678.13
  84   0.7159     80.490  0.1840    93.430  1698.31
  85   0.7136     80.660  0.1869    93.396  1718.48
  86   0.7145     80.690  0.1828    93.578  1738.64
  87   0.7174     80.360  0.1855    93.408  1758.83
  88   0.7245     80.450  0.1783    93.730  1779.01
  89   0.7256     80.630  0.1805    93.678  1799.18
  90   0.7407     80.150  0.1734    93.792  1819.37
