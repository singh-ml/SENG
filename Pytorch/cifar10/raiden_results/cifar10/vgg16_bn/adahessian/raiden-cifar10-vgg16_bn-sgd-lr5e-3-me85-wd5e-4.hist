Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7815981568 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7151     35.750  2.3130    21.252  22.59
   2   1.4582     44.760  1.6888    36.200  43.17
   3   1.3355     50.840  1.4984    43.956  63.75
   4   1.2382     54.780  1.3728    49.376  84.32
   5   1.1675     57.560  1.2791    53.450  104.89
   6   1.1068     60.340  1.2106    56.526  125.48
   7   1.0482     61.980  1.1460    58.870  146.04
   8   1.0295     63.320  1.0963    60.732  166.61
   9   0.9976     64.110  1.0495    62.548  187.19
  10   0.9459     66.320  1.0092    63.938  207.76
  11   0.9112     67.410  0.9661    65.710  228.33
  12   0.9028     67.580  0.9329    67.216  248.89
  13   0.8759     68.770  0.8958    68.226  269.48
  14   0.8476     69.530  0.8786    68.892  290.04
  15   0.8276     70.360  0.8352    70.478  310.64
  16   0.8143     70.810  0.8095    71.560  331.19
  17   0.7977     71.530  0.7857    72.546  351.78
  18   0.7762     72.640  0.7619    73.148  372.35
  19   0.7872     71.840  0.7420    73.996  392.91
  20   0.7542     73.320  0.7185    74.844  413.49
  21   0.7532     73.620  0.6935    75.896  434.08
  22   0.7316     74.020  0.6782    76.334  454.67
  23   0.7288     74.660  0.6643    76.942  475.23
  24   0.7570     72.940  0.6469    77.292  495.83
  25   0.6989     75.750  0.6268    78.194  516.41
  26   0.6802     76.260  0.6043    78.972  536.99
  27   0.7111     75.100  0.5983    78.988  557.55
  28   0.6755     76.200  0.5790    79.814  578.13
  29   0.6798     76.480  0.5674    80.310  598.72
  30   0.6643     76.950  0.5513    80.752  619.29
  31   0.6611     77.310  0.5408    81.280  639.90
  32   0.6489     77.620  0.5312    81.594  660.45
  33   0.6601     76.990  0.5100    82.146  681.01
  34   0.6387     77.860  0.4995    82.506  701.61
  35   0.6488     77.640  0.4877    82.892  722.18
  36   0.6469     77.850  0.4773    83.292  742.78
  37   0.6386     78.030  0.4634    83.712  763.33
  38   0.6340     78.100  0.4512    84.374  783.91
  39   0.6411     78.110  0.4401    84.662  804.48
  40   0.6415     77.840  0.4364    84.654  825.04
  41   0.6383     78.780  0.4171    85.430  845.61
  42   0.6368     78.470  0.4100    85.730  866.21
  43   0.6323     78.480  0.4056    85.950  886.81
  44   0.6222     78.880  0.3942    86.240  907.37
  45   0.6313     78.630  0.3865    86.440  927.93
  46   0.6303     79.000  0.3766    86.832  948.53
  47   0.6397     78.700  0.3687    87.254  969.12
  48   0.6342     78.620  0.3594    87.428  989.69
  49   0.6401     78.670  0.3554    87.650  1010.27
  50   0.6378     78.620  0.3469    87.942  1030.83
  51   0.6297     79.110  0.3416    87.988  1051.40
  52   0.6411     78.700  0.3303    88.458  1071.96
  53   0.6483     79.170  0.3235    88.596  1092.59
  54   0.6444     78.950  0.3132    89.098  1113.19
  55   0.6542     79.120  0.3082    89.156  1133.76
  56   0.6526     78.880  0.3046    89.280  1154.33
  57   0.6576     79.360  0.2995    89.520  1174.89
  58   0.6553     79.370  0.2872    89.848  1195.45
  59   0.6589     79.330  0.2838    90.046  1216.01
  60   0.6721     79.150  0.2790    90.376  1236.58
  61   0.6728     79.380  0.2747    90.360  1257.15
  62   0.6757     79.430  0.2635    90.890  1277.73
  63   0.6695     79.400  0.2662    90.632  1298.29
  64   0.6784     79.230  0.2593    90.898  1318.92
  65   0.6690     79.630  0.2594    90.932  1339.48
  66   0.6836     79.600  0.2524    91.182  1360.03
  67   0.6845     79.480  0.2480    91.304  1380.63
  68   0.6884     79.550  0.2473    91.330  1401.21
  69   0.6902     79.480  0.2431    91.520  1421.81
  70   0.7018     79.120  0.2407    91.560  1442.38
  71   0.6944     79.380  0.2386    91.736  1462.96
  72   0.7095     79.410  0.2257    92.102  1483.54
  73   0.7070     79.600  0.2329    91.696  1504.13
  74   0.7021     79.360  0.2267    92.032  1524.72
  75   0.7031     79.470  0.2271    92.110  1545.27
  76   0.7142     79.590  0.2192    92.312  1565.89
  77   0.7138     79.510  0.2208    92.234  1586.44
  78   0.7209     79.340  0.2180    92.434  1607.01
  79   0.7194     79.500  0.2138    92.456  1627.58
  80   0.7250     79.480  0.2094    92.674  1648.15
  81   0.7195     79.820  0.2093    92.744  1668.71
  82   0.7287     79.680  0.2014    92.832  1689.32
  83   0.7286     79.510  0.2073    92.758  1709.89
  84   0.7458     79.450  0.1989    92.970  1730.48
  85   0.7379     79.290  0.2037    92.918  1751.08
