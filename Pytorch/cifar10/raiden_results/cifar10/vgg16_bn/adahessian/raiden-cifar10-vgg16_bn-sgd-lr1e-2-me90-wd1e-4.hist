Use GPU: 0 for training
==> Running with ['main_adahessian.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7816505856 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7258     34.080  2.2016    21.854  22.53
   2   1.2889     52.570  1.5367    42.154  43.08
   3   1.1206     58.780  1.2974    53.018  63.60
   4   1.0902     60.040  1.1651    58.300  84.12
   5   1.0520     62.760  1.0739    61.560  104.65
   6   0.9049     67.760  0.9975    64.684  125.14
   7   0.8624     69.380  0.9287    67.256  145.70
   8   0.8331     70.500  0.8701    69.486  166.19
   9   0.8146     70.830  0.8261    71.066  186.74
  10   0.7906     72.380  0.7751    73.074  207.25
  11   0.7644     73.040  0.7309    74.704  227.86
  12   0.7097     75.060  0.6987    75.876  248.46
  13   0.7312     74.170  0.6626    76.998  268.98
  14   0.7207     75.020  0.6299    78.456  289.50
  15   0.6616     76.720  0.6058    79.188  310.02
  16   0.6662     76.870  0.5766    80.272  330.53
  17   0.6365     77.630  0.5536    80.884  351.03
  18   0.6217     78.550  0.5332    81.644  371.59
  19   0.6249     78.360  0.5113    82.410  392.12
  20   0.5965     78.990  0.4887    83.264  412.67
  21   0.5925     79.620  0.4697    83.860  433.17
  22   0.5816     79.780  0.4514    84.430  453.69
  23   0.5560     81.030  0.4341    84.990  474.19
  24   0.5962     80.180  0.4178    85.606  494.76
  25   0.5676     80.550  0.3979    86.300  515.28
  26   0.5794     80.170  0.3863    86.748  535.78
  27   0.5681     80.770  0.3707    87.082  556.31
  28   0.5462     81.630  0.3563    87.740  576.82
  29   0.5370     81.890  0.3425    88.288  597.37
  30   0.5551     81.220  0.3229    88.970  617.90
  31   0.5460     81.580  0.3146    89.134  638.45
  32   0.5472     81.330  0.3098    89.306  658.93
  33   0.5440     82.380  0.2913    90.178  679.45
  34   0.5049     83.380  0.2787    90.520  699.96
  35   0.5323     82.080  0.2678    90.748  720.47
  36   0.5339     82.710  0.2594    91.010  741.05
  37   0.5250     82.950  0.2489    91.382  761.55
  38   0.5284     83.060  0.2357    91.896  782.05
  39   0.5224     83.110  0.2294    92.290  802.56
  40   0.5298     83.230  0.2190    92.470  823.08
  41   0.5223     83.150  0.2131    92.688  843.57
  42   0.5400     83.120  0.1998    93.082  864.09
  43   0.5367     83.040  0.1881    93.556  884.59
  44   0.5401     83.810  0.1801    93.940  905.11
  45   0.5586     83.300  0.1748    93.992  925.61
  46   0.5511     83.760  0.1645    94.260  946.19
  47   0.5723     83.340  0.1599    94.482  966.73
  48   0.5597     83.810  0.1576    94.576  987.25
  49   0.5750     83.840  0.1465    95.004  1007.79
  50   0.5907     83.480  0.1387    95.152  1028.32
  51   0.5812     83.480  0.1354    95.324  1048.86
  52   0.6030     83.510  0.1299    95.600  1069.35
  53   0.5977     83.950  0.1266    95.620  1089.86
  54   0.5898     83.700  0.1230    95.814  1110.37
  55   0.5975     83.880  0.1134    96.076  1130.89
  56   0.6203     83.450  0.1083    96.278  1151.42
  57   0.6067     83.950  0.1102    96.234  1171.93
  58   0.6130     83.740  0.1072    96.320  1192.45
  59   0.6343     83.710  0.0982    96.568  1212.95
  60   0.6230     83.880  0.0976    96.686  1233.47
  61   0.6438     83.790  0.0912    96.872  1254.00
  62   0.6406     83.920  0.0890    96.962  1274.53
  63   0.6436     84.040  0.0892    97.050  1295.04
  64   0.6602     83.930  0.0835    97.110  1315.65
  65   0.6632     84.100  0.0817    97.248  1336.17
  66   0.6593     83.830  0.0799    97.276  1356.66
  67   0.6738     84.180  0.0733    97.458  1377.16
  68   0.6745     84.060  0.0726    97.528  1397.65
  69   0.6781     83.910  0.0731    97.512  1418.18
  70   0.6715     84.230  0.0707    97.460  1438.72
  71   0.6850     84.120  0.0682    97.656  1459.20
  72   0.6976     84.430  0.0658    97.708  1479.77
  73   0.6994     84.120  0.0648    97.812  1500.29
  74   0.7058     84.250  0.0641    97.776  1520.81
  75   0.7160     84.100  0.0626    97.870  1541.32
  76   0.7125     84.190  0.0611    97.912  1561.85
  77   0.7211     84.110  0.0592    97.958  1582.34
  78   0.7200     84.080  0.0585    98.022  1602.88
  79   0.7213     84.380  0.0599    98.032  1623.40
  80   0.7175     84.170  0.0576    98.014  1643.91
  81   0.7238     84.180  0.0594    98.010  1664.43
  82   0.7240     84.280  0.0549    98.132  1684.92
  83   0.7335     84.340  0.0516    98.230  1705.46
  84   0.7394     84.080  0.0529    98.170  1725.98
  85   0.7423     84.220  0.0525    98.248  1746.49
  86   0.7452     84.300  0.0523    98.262  1766.99
  87   0.7434     84.440  0.0509    98.274  1787.50
  88   0.7522     84.270  0.0502    98.302  1808.01
  89   0.7505     84.500  0.0517    98.280  1828.52
  90   0.7543     84.510  0.0487    98.340  1849.05
