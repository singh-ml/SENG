Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 61885047296 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3437     51.760  1.7342    35.168  36.18
   2   1.1574     59.010  1.2921    53.558  67.29
   3   1.1861     61.090  1.0668    62.458  96.49
   4   0.8819     68.350  0.9146    68.060  125.35
   5   0.8124     71.560  0.7949    72.328  154.17
   6   0.7267     75.380  0.7184    75.350  183.33
   7   0.6642     78.070  0.6529    77.996  212.58
   8   0.6098     79.090  0.5898    80.072  243.50
   9   0.5484     81.630  0.5495    81.508  272.89
  10   0.6059     79.070  0.5091    82.774  303.94
  11   0.5209     82.200  0.4801    83.766  334.80
  12   0.5369     82.300  0.4577    84.532  365.62
  13   0.6358     78.780  0.4254    85.586  396.63
  14   0.5141     81.820  0.4069    86.262  425.80
  15   0.5964     79.730  0.3801    87.132  456.76
  16   0.4725     83.570  0.3629    87.584  487.71
  17   0.4358     85.740  0.3415    88.556  518.82
  18   0.4322     85.390  0.3256    88.966  549.85
  19   0.4623     84.290  0.3115    89.498  580.81
  20   0.4436     84.730  0.2950    89.986  611.68
  21   0.4706     84.170  0.2782    90.598  642.74
  22   0.4480     85.160  0.2706    90.868  673.71
  23   0.4356     85.520  0.2608    91.086  704.59
  24   0.4827     84.170  0.2486    91.470  735.44
  25   0.4425     85.500  0.2371    92.016  766.48
  26   0.4541     85.410  0.2263    92.308  797.48
  27   0.4093     86.280  0.2142    92.700  828.40
  28   0.4232     86.200  0.2026    93.132  859.26
  29   0.4833     85.200  0.1920    93.322  890.59
  30   0.4034     86.620  0.1893    93.500  923.11
  31   0.3778     87.190  0.1818    93.808  952.40
  32   0.3816     87.550  0.1684    94.240  983.29
  33   0.3764     88.010  0.1634    94.432  1014.34
  34   0.3871     87.730  0.1587    94.724  1045.37
  35   0.4624     85.350  0.1499    94.788  1076.28
  36   0.4134     87.360  0.1501    94.878  1105.58
  37   0.3793     87.680  0.1429    95.068  1136.70
  38   0.3933     88.070  0.1331    95.376  1167.68
  39   0.3977     87.410  0.1376    95.318  1198.55
  40   0.4143     87.410  0.1227    95.836  1229.47
  41   0.4296     87.610  0.1138    96.114  1260.52
  42   0.4240     87.330  0.1156    96.086  1289.18
  43   0.4631     86.600  0.1111    96.202  1320.00
  44   0.4065     88.170  0.1079    96.344  1351.03
  45   0.4262     87.710  0.1056    96.388  1382.05
  46   0.4392     87.510  0.0985    96.640  1411.35
  47   0.4118     88.370  0.0978    96.686  1442.24
  48   0.4109     88.170  0.0926    96.744  1473.32
  49   0.4330     88.420  0.0878    96.952  1504.20
  50   0.4226     87.890  0.0844    97.086  1536.70
  51   0.3819     88.730  0.0856    97.022  1567.52
  52   0.4189     88.070  0.0800    97.292  1596.85
  53   0.4578     88.260  0.0749    97.422  1626.01
  54   0.4244     88.340  0.0765    97.348  1656.78
  55   0.4258     88.690  0.0707    97.484  1687.94
  56   0.4604     88.050  0.0696    97.536  1719.03
  57   0.4477     87.550  0.0701    97.564  1749.93
  58   0.4175     88.280  0.0628    97.838  1780.78
  59   0.4560     88.500  0.0588    97.988  1811.85
  60   0.4353     88.620  0.0602    97.970  1841.19
  61   0.3877     89.120  0.0614    97.932  1871.98
  62   0.4706     88.510  0.0569    98.122  1903.04
  63   0.5303     87.050  0.0569    98.084  1934.07
  64   0.4912     87.870  0.0571    98.092  1964.98
  65   0.4101     89.440  0.0534    98.226  1995.84
  66   0.4156     89.120  0.0506    98.324  2026.90
  67   0.4544     88.880  0.0470    98.426  2057.89
  68   0.4519     89.070  0.0544    98.198  2086.93
  69   0.4147     89.470  0.0485    98.384  2117.78
  70   0.4229     89.300  0.0442    98.504  2148.83
  71   0.4034     89.690  0.0471    98.360  2179.80
  72   0.4718     88.670  0.0467    98.366  2210.73
  73   0.4404     89.580  0.0438    98.550  2241.58
  74   0.4441     88.960  0.0424    98.540  2272.64
  75   0.4727     88.330  0.0419    98.642  2303.72
  76   0.4548     89.330  0.0405    98.644  2334.68
  77   0.4597     89.120  0.0412    98.584  2365.52
  78   0.4236     89.820  0.0439    98.562  2396.56
  79   0.4548     89.480  0.0382    98.706  2427.44
  80   0.4280     89.790  0.0353    98.818  2458.38
  81   0.4476     89.870  0.0335    98.814  2489.23
  82   0.4787     88.770  0.0346    98.834  2520.28
  83   0.4519     89.430  0.0331    98.884  2549.74
  84   0.4757     88.800  0.0348    98.804  2580.64
  85   0.4771     89.410  0.0315    98.936  2609.96
  86   0.4713     89.880  0.0319    98.942  2641.02
  87   0.4740     89.380  0.0287    98.992  2672.22
  88   0.4500     89.590  0.0334    98.916  2703.16
  89   0.4399     89.770  0.0305    98.972  2734.00
  90   0.4484     89.610  0.0308    98.942  2765.18
