Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 57049421312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4340     46.190  1.7257    35.534  35.83
   2   1.1201     59.130  1.2711    54.238  66.73
   3   1.0917     62.230  1.0513    63.080  97.55
   4   0.9833     65.780  0.8964    68.792  128.21
   5   0.7663     73.500  0.7776    73.528  158.84
   6   0.6615     77.730  0.6950    76.400  188.14
   7   0.6557     78.010  0.6385    78.398  217.29
   8   0.6039     79.400  0.5805    80.244  247.90
   9   0.6240     79.100  0.5414    81.688  278.72
  10   0.6071     80.210  0.5092    82.814  309.47
  11   0.5820     79.710  0.4715    83.864  340.13
  12   0.5390     81.780  0.4520    84.814  370.78
  13   0.4830     83.400  0.4211    85.872  401.65
  14   0.4708     84.340  0.3929    86.706  430.37
  15   0.4922     83.090  0.3709    87.448  459.25
  16   0.5039     83.250  0.3575    87.854  490.03
  17   0.4385     85.280  0.3336    88.790  519.13
  18   0.4559     84.620  0.3161    89.310  549.83
  19   0.4316     85.660  0.3000    89.936  580.47
  20   0.4402     85.150  0.2922    90.076  611.28
  21   0.4749     84.400  0.2716    90.814  641.98
  22   0.4845     84.220  0.2633    91.096  672.63
  23   0.4104     86.440  0.2499    91.472  703.45
  24   0.4096     86.640  0.2368    92.012  734.27
  25   0.4781     84.290  0.2259    92.366  765.27
  26   0.4372     85.940  0.2215    92.410  795.87
  27   0.4429     85.760  0.2107    92.928  826.74
  28   0.4022     86.500  0.2016    93.282  857.55
  29   0.4369     86.060  0.1897    93.586  888.22
  30   0.4054     87.050  0.1844    93.782  918.92
  31   0.4388     86.020  0.1771    94.036  948.23
  32   0.4669     85.170  0.1674    94.270  978.86
  33   0.4860     85.190  0.1622    94.380  1009.54
  34   0.3994     86.920  0.1587    94.500  1040.16
  35   0.4202     86.960  0.1473    94.888  1070.94
  36   0.4034     87.720  0.1411    95.196  1101.60
  37   0.4275     86.960  0.1388    95.274  1132.35
  38   0.3999     87.530  0.1312    95.582  1162.96
  39   0.3959     87.730  0.1272    95.662  1193.84
  40   0.4250     87.530  0.1197    95.920  1222.78
  41   0.4411     87.450  0.1188    95.922  1253.48
  42   0.4237     87.330  0.1110    96.248  1284.37
  43   0.4299     87.550  0.1092    96.250  1315.19
  44   0.4097     88.400  0.1035    96.396  1345.98
  45   0.4536     86.440  0.1028    96.520  1376.63
  46   0.4102     88.220  0.1001    96.534  1407.55
  47   0.4283     87.200  0.0956    96.744  1438.42
  48   0.4059     88.360  0.0886    96.968  1469.21
  49   0.4331     88.090  0.0873    97.012  1499.93
  50   0.4755     88.020  0.0836    97.114  1530.83
  51   0.4440     87.820  0.0808    97.278  1561.73
  52   0.4193     88.360  0.0790    97.346  1592.44
  53   0.4463     87.750  0.0741    97.398  1623.10
  54   0.4824     87.190  0.0733    97.484  1653.93
  55   0.4543     88.190  0.0705    97.654  1686.43
  56   0.4032     88.910  0.0692    97.686  1717.17
  57   0.4339     88.280  0.0688    97.648  1747.84
  58   0.4235     88.140  0.0668    97.634  1778.80
  59   0.4413     88.240  0.0606    97.974  1809.54
  60   0.4287     88.620  0.0583    97.930  1840.19
  61   0.4129     88.790  0.0622    97.906  1871.11
  62   0.4265     88.680  0.0587    97.984  1901.99
  63   0.4589     88.570  0.0530    98.222  1932.65
  64   0.4110     88.890  0.0568    98.052  1965.00
  65   0.4694     88.120  0.0495    98.298  1995.68
  66   0.4330     88.980  0.0529    98.226  2026.58
  67   0.4952     88.010  0.0506    98.300  2057.29
  68   0.4710     88.800  0.0473    98.406  2088.05
  69   0.4585     88.710  0.0493    98.348  2118.74
  70   0.4380     88.960  0.0463    98.418  2149.55
  71   0.4547     88.630  0.0454    98.424  2180.35
  72   0.4166     89.410  0.0460    98.386  2211.15
  73   0.4744     88.480  0.0415    98.582  2241.83
  74   0.4646     88.810  0.0420    98.574  2272.70
  75   0.4288     88.780  0.0444    98.496  2305.06
  76   0.4568     88.320  0.0409    98.596  2333.93
  77   0.4510     89.090  0.0384    98.694  2364.63
  78   0.4544     88.880  0.0397    98.666  2395.44
  79   0.4450     89.150  0.0383    98.676  2426.23
  80   0.4626     89.030  0.0380    98.632  2456.94
  81   0.4531     89.170  0.0387    98.686  2487.83
  82   0.4301     89.310  0.0390    98.692  2518.68
  83   0.4629     88.800  0.0339    98.864  2549.43
  84   0.4571     89.250  0.0335    98.788  2580.12
  85   0.4527     89.330  0.0325    98.876  2610.97
