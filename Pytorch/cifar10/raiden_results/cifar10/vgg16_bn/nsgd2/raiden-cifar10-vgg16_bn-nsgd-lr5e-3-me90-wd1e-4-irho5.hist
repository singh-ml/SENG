Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '5', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 58662927872 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6162     35.660  1.9954    25.962  35.96
   2   1.3419     51.540  1.5984    39.856  64.41
   3   1.1384     59.920  1.3219    53.212  92.98
   4   0.9478     67.600  1.0780    62.676  123.43
   5   1.0194     66.480  0.9026    69.566  152.16
   6   0.8062     73.410  0.7832    74.084  180.68
   7   0.7711     74.670  0.7256    76.032  209.69
   8   0.6140     79.400  0.6283    79.288  238.09
   9   0.6190     79.600  0.5783    81.218  266.55
  10   0.5979     80.110  0.5336    82.576  295.15
  11   0.5266     83.010  0.4959    83.822  324.09
  12   0.5631     81.680  0.4550    84.962  353.06
  13   0.5194     82.340  0.4246    85.956  381.58
  14   0.5759     81.140  0.4061    86.520  410.82
  15   0.5453     82.320  0.3788    87.462  439.26
  16   0.4515     84.870  0.3548    88.274  469.86
  17   0.4841     84.310  0.3316    89.292  498.74
  18   0.5014     83.230  0.3082    89.844  527.30
  19   0.5042     83.910  0.3007    90.036  555.76
  20   0.4404     85.310  0.2751    90.912  584.70
  21   0.4985     83.800  0.2644    91.292  613.34
  22   0.4248     86.240  0.2471    91.734  642.30
  23   0.4298     86.050  0.2333    92.220  671.12
  24   0.3727     88.310  0.2233    92.650  699.65
  25   0.3871     87.450  0.2169    92.790  728.23
  26   0.4149     86.730  0.2066    93.122  756.75
  27   0.3612     88.550  0.1965    93.464  785.32
  28   0.3924     87.620  0.1806    93.998  815.35
  29   0.4063     86.880  0.1711    94.300  843.91
  30   0.4042     87.970  0.1630    94.540  872.89
  31   0.3872     88.200  0.1541    94.906  902.14
  32   0.4027     87.930  0.1468    95.038  932.78
  33   0.4272     87.640  0.1382    95.362  961.18
  34   0.3891     88.180  0.1310    95.720  989.96
  35   0.3614     89.360  0.1279    95.686  1018.84
  36   0.4403     87.940  0.1110    96.314  1047.22
  37   0.4068     88.290  0.1128    96.200  1076.34
  38   0.4007     88.460  0.1087    96.454  1105.29
  39   0.3985     88.540  0.0994    96.738  1133.84
  40   0.3831     89.440  0.1036    96.522  1164.63
  41   0.3873     89.320  0.0921    96.928  1193.42
  42   0.4074     88.810  0.0847    97.228  1222.45
  43   0.4030     89.310  0.0773    97.412  1250.81
  44   0.4222     89.420  0.0727    97.582  1281.49
  45   0.4339     89.020  0.0694    97.660  1310.35
  46   0.3927     89.750  0.0670    97.772  1340.93
  47   0.4112     89.680  0.0610    98.024  1369.33
  48   0.4276     89.350  0.0602    98.020  1400.15
  49   0.4410     89.450  0.0567    98.082  1430.62
  50   0.4485     89.360  0.0553    98.180  1459.52
  51   0.4242     89.900  0.0480    98.412  1488.52
  52   0.3833     90.230  0.0517    98.250  1517.06
  53   0.4216     89.840  0.0462    98.442  1545.41
  54   0.4172     90.260  0.0411    98.622  1573.98
  55   0.4481     89.990  0.0399    98.686  1604.05
  56   0.4581     90.100  0.0365    98.738  1634.63
  57   0.4206     89.890  0.0374    98.786  1662.98
  58   0.4739     89.680  0.0312    98.984  1692.12
  59   0.4529     90.290  0.0321    98.894  1720.93
  60   0.4658     89.780  0.0276    99.028  1749.63
  61   0.4705     89.850  0.0276    99.056  1778.45
  62   0.4506     90.480  0.0259    99.176  1807.22
  63   0.4616     90.710  0.0221    99.244  1836.06
  64   0.4829     90.100  0.0224    99.286  1864.83
  65   0.4545     90.490  0.0227    99.252  1893.75
  66   0.4493     90.620  0.0188    99.354  1922.70
  67   0.4653     90.470  0.0175    99.430  1951.22
  68   0.4761     90.320  0.0184    99.406  1979.74
  69   0.4698     90.460  0.0176    99.438  2008.40
  70   0.4742     90.570  0.0169    99.436  2037.43
  71   0.4918     90.510  0.0153    99.524  2066.44
  72   0.4896     90.820  0.0125    99.606  2095.34
  73   0.5133     90.530  0.0139    99.556  2123.89
  74   0.4929     90.650  0.0121    99.624  2152.67
  75   0.5055     90.640  0.0107    99.658  2181.55
  76   0.5059     90.380  0.0137    99.544  2210.24
  77   0.4770     91.000  0.0110    99.642  2239.04
  78   0.5040     90.630  0.0098    99.670  2267.32
  79   0.5049     90.860  0.0089    99.734  2296.23
  80   0.5293     90.860  0.0102    99.668  2326.94
  81   0.5114     90.970  0.0093    99.702  2355.89
  82   0.5186     91.080  0.0080    99.728  2384.36
  83   0.5209     90.620  0.0083    99.724  2413.64
  84   0.5232     90.750  0.0082    99.760  2442.39
  85   0.5460     90.780  0.0078    99.754  2471.22
  86   0.5369     90.770  0.0067    99.788  2500.08
  87   0.5382     90.950  0.0070    99.764  2530.89
  88   0.5261     90.930  0.0075    99.754  2559.92
  89   0.5466     91.080  0.0067    99.766  2588.33
  90   0.5499     91.050  0.0069    99.738  2617.25
