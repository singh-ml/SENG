Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 58662927872 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4792     14.960  2.4530    12.064  36.30
   2   2.8519     16.400  2.2107    17.530  65.45
   3   1.9236     23.280  2.0547    20.638  94.30
   4   1.8390     27.340  1.9157    25.368  124.53
   5   1.8797     33.800  1.7928    30.596  153.41
   6   1.4916     43.600  1.6242    38.050  182.22
   7   1.4634     48.220  1.4311    46.690  210.88
   8   1.3993     52.070  1.2247    56.394  239.56
   9   1.0729     64.080  1.0482    63.358  269.97
  10   0.8229     71.920  0.9051    68.810  299.25
  11   0.8619     70.770  0.8078    72.568  327.79
  12   0.9259     70.580  0.7177    75.658  357.07
  13   0.7204     76.040  0.6605    77.824  385.79
  14   0.6233     79.820  0.5941    80.198  414.49
  15   0.6345     79.220  0.5593    81.536  443.41
  16   0.5502     82.200  0.5150    82.746  472.30
  17   0.6004     80.400  0.4902    83.834  502.78
  18   0.5429     81.890  0.4521    85.092  531.52
  19   0.4764     84.390  0.4241    85.786  562.34
  20   0.4595     84.550  0.3969    86.876  591.75
  21   0.4547     85.040  0.3726    87.670  620.86
  22   0.4372     85.340  0.3537    88.200  649.77
  23   0.4109     86.560  0.3523    88.300  679.01
  24   0.4626     85.340  0.3157    89.626  707.90
  25   0.4640     84.970  0.3027    89.868  736.55
  26   0.4533     85.640  0.2869    90.450  767.54
  27   0.4178     85.850  0.2700    90.898  796.47
  28   0.4971     85.160  0.2551    91.680  825.45
  29   0.4322     85.980  0.2407    92.074  856.23
  30   0.4310     86.300  0.2319    92.370  887.18
  31   0.4439     86.060  0.2149    92.808  916.43
  32   0.4994     86.050  0.2043    93.162  945.34
  33   0.4150     87.700  0.1975    93.398  974.73
  34   0.4395     86.880  0.1834    93.864  1003.83
  35   0.4131     87.160  0.1703    94.416  1032.62
  36   0.4174     87.420  0.1650    94.498  1063.05
  37   0.3997     87.790  0.1530    94.826  1091.87
  38   0.4346     87.640  0.1480    95.120  1121.13
  39   0.3968     88.560  0.1404    95.334  1150.22
  40   0.3887     88.850  0.1303    95.676  1179.21
  41   0.4158     88.460  0.1213    95.986  1208.34
  42   0.4715     87.970  0.1139    96.174  1237.09
  43   0.4683     87.570  0.1146    96.220  1266.40
  44   0.3999     89.160  0.1013    96.552  1295.29
  45   0.4163     88.650  0.0975    96.682  1324.35
  46   0.4504     88.540  0.0911    96.992  1353.33
  47   0.4370     88.360  0.0838    97.178  1382.07
  48   0.4414     89.000  0.0810    97.272  1411.04
  49   0.4275     89.080  0.0763    97.394  1441.82
  50   0.4614     88.810  0.0727    97.560  1472.80
  51   0.4331     89.170  0.0705    97.542  1501.65
  52   0.4735     89.440  0.0604    97.986  1532.46
  53   0.4577     89.130  0.0608    97.988  1563.24
  54   0.4503     89.410  0.0542    98.182  1592.45
  55   0.4547     89.560  0.0525    98.306  1621.77
  56   0.5003     89.310  0.0484    98.390  1652.55
  57   0.5078     88.970  0.0462    98.506  1681.53
  58   0.4876     89.660  0.0420    98.600  1710.62
  59   0.4965     89.160  0.0400    98.674  1741.45
  60   0.4848     89.360  0.0389    98.746  1770.51
  61   0.4846     89.460  0.0501    98.378  1799.55
  62   0.4994     89.700  0.0354    98.896  1828.67
  63   0.4916     89.670  0.0347    98.872  1857.86
  64   0.5061     89.830  0.0280    99.064  1886.94
  65   0.4979     89.690  0.0277    99.082  1915.77
  66   0.5346     89.650  0.0274    99.098  1944.52
  67   0.5025     90.000  0.0247    99.194  1974.04
  68   0.5117     90.310  0.0225    99.242  2003.23
  69   0.5258     90.000  0.0211    99.262  2034.02
  70   0.5174     90.290  0.0205    99.304  2063.24
  71   0.5260     90.120  0.0210    99.332  2092.12
  72   0.5155     89.900  0.0185    99.372  2121.23
  73   0.5279     89.970  0.0176    99.436  2150.57
  74   0.5343     90.240  0.0166    99.458  2179.83
  75   0.5486     89.850  0.0153    99.478  2209.22
  76   0.5512     90.360  0.0150    99.544  2238.54
  77   0.5415     90.310  0.0156    99.500  2267.49
  78   0.5586     90.320  0.0118    99.586  2296.51
  79   0.5681     90.250  0.0122    99.558  2325.56
  80   0.5591     90.190  0.0133    99.516  2354.70
  81   0.5822     90.180  0.0107    99.664  2383.22
  82   0.5751     90.180  0.0108    99.636  2412.20
  83   0.5725     90.100  0.0115    99.610  2441.12
  84   0.5261     90.740  0.0132    99.524  2469.97
  85   0.5851     90.370  0.0094    99.670  2499.16
