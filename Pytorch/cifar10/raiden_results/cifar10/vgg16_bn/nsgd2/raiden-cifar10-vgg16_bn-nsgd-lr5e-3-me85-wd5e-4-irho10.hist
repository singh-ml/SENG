Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 52214804992 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2668     12.110  2.5815    11.190  34.83
   2   2.0804     18.200  2.2204    15.156  63.70
   3   1.9809     22.690  1.9986    21.558  92.31
   4   1.8592     31.080  1.8923    26.486  114.97
   5   1.5693     40.960  1.7107    33.472  143.75
   6   1.5038     45.110  1.5253    42.458  172.50
   7   1.2710     54.210  1.3557    50.758  201.38
   8   1.0543     62.660  1.1738    58.534  230.01
   9   1.0584     64.420  1.0577    62.912  259.00
  10   0.9168     68.430  0.9116    68.398  287.91
  11   0.8500     70.360  0.8125    72.176  317.27
  12   0.7586     74.400  0.7614    74.242  347.59
  13   0.9200     73.540  0.7076    76.442  376.44
  14   1.1574     74.650  0.6416    78.736  405.72
  15   0.6953     77.260  0.6256    78.964  435.06
  16   0.6407     78.330  0.5572    81.512  464.41
  17   0.6818     77.690  0.5167    82.768  493.60
  18   0.6274     79.110  0.4930    83.860  524.10
  19   0.5219     82.430  0.4541    85.114  552.97
  20   0.5418     82.880  0.4218    85.830  583.83
  21   0.5335     82.740  0.4057    86.378  612.93
  22   0.4852     84.920  0.3744    87.666  643.23
  23   0.5328     83.100  0.3562    88.296  672.01
  24   0.5291     83.420  0.3332    89.100  701.16
  25   0.4619     85.020  0.3229    89.206  730.51
  26   0.4477     85.600  0.2999    90.052  761.37
  27   0.4392     85.290  0.2872    90.518  790.37
  28   0.4895     84.460  0.2727    90.948  821.41
  29   0.4128     87.420  0.2527    91.632  850.70
  30   0.4319     85.830  0.2494    91.718  881.66
  31   0.4192     86.690  0.2342    92.232  912.43
  32   0.8968     82.970  0.2209    92.666  941.45
  33   0.5353     82.300  0.7609    76.144  972.34
  34   0.4536     85.320  0.3508    88.278  1001.54
  35   0.4401     86.270  0.2923    90.316  1030.70
  36   0.4161     86.860  0.2794    90.718  1061.64
  37   0.4163     86.630  0.2362    92.236  1090.44
  38   0.4249     86.960  0.2100    93.094  1119.75
  39   0.3764     88.700  0.2005    93.204  1149.07
  40   0.3938     87.780  0.1782    93.962  1178.00
  41   0.4025     88.110  0.1606    94.688  1207.01
  42   0.3656     88.770  0.1537    94.934  1236.06
  43   0.3897     88.690  0.1425    95.236  1264.74
  44   0.4270     87.780  0.1332    95.546  1293.53
  45   0.3831     89.030  0.1263    95.792  1324.39
  46   0.3880     89.020  0.1202    95.878  1353.28
  47   0.3865     89.280  0.1082    96.466  1382.16
  48   0.4077     89.050  0.1083    96.386  1411.13
  49   0.4178     88.290  0.1002    96.666  1440.00
  50   0.4219     89.190  0.0902    96.900  1471.02
  51   0.4084     88.920  0.0932    96.914  1500.15
  52   0.3912     89.790  0.0800    97.302  1529.24
  53   0.4225     89.200  0.0795    97.302  1558.21
  54   0.4109     89.150  0.0705    97.584  1587.45
  55   0.4080     89.850  0.0662    97.816  1616.77
  56   0.4405     89.340  0.0607    97.982  1645.97
  57   0.4133     90.080  0.0626    97.950  1676.90
  58   0.4007     89.620  0.0571    98.062  1706.21
  59   0.4340     89.320  0.0545    98.200  1735.39
  60   0.4273     90.200  0.0452    98.502  1764.25
  61   0.4118     90.140  0.0488    98.338  1793.10
  62   0.4064     90.060  0.0454    98.516  1821.75
  63   0.4361     90.500  0.0384    98.696  1850.84
  64   0.4372     90.560  0.0385    98.722  1879.44
  65   0.4466     89.840  0.0356    98.802  1908.54
  66   0.4209     90.590  0.0329    98.876  1937.87
  67   0.4582     90.330  0.0300    98.998  1966.75
  68   0.4445     90.550  0.0294    99.030  1995.85
  69   0.4538     90.360  0.0274    99.044  2024.81
  70   0.4544     90.680  0.0244    99.198  2053.58
  71   0.4918     90.220  0.0252    99.180  2082.78
  72   0.4618     90.350  0.0243    99.210  2112.11
  73   0.4621     90.470  0.0228    99.208  2141.17
  74   0.4723     90.570  0.0226    99.258  2170.15
  75   0.4697     90.390  0.0207    99.318  2199.33
  76   0.4858     90.710  0.0181    99.390  2230.40
  77   0.4847     90.560  0.0193    99.342  2261.27
  78   0.4977     90.630  0.0170    99.440  2290.11
  79   0.4741     90.650  0.0181    99.402  2319.13
  80   0.4932     90.590  0.0165    99.432  2350.15
  81   0.4746     90.810  0.0189    99.370  2379.51
  82   0.5045     90.610  0.0168    99.446  2408.62
  83   0.5072     90.580  0.0142    99.522  2437.79
  84   0.5290     90.660  0.0139    99.496  2467.00
  85   0.4992     90.570  0.0150    99.548  2495.92
