Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 60273909248 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4453     47.080  1.7480    34.882  36.26
   2   1.1245     59.290  1.2938    53.686  67.18
   3   0.9634     66.250  1.0699    62.132  96.46
   4   0.8159     71.020  0.9248    67.936  125.47
   5   0.7524     73.950  0.8155    71.718  156.41
   6   0.7932     72.010  0.7268    74.992  185.76
   7   0.6479     78.090  0.6552    77.730  216.52
   8   0.6324     78.300  0.6069    79.312  247.23
   9   0.6095     78.850  0.5667    80.826  276.33
  10   0.5710     79.770  0.5207    82.366  307.20
  11   0.5521     81.590  0.4956    83.348  338.04
  12   0.5208     82.350  0.4584    84.464  368.78
  13   0.5192     82.280  0.4312    85.494  399.76
  14   0.4821     84.140  0.4087    86.254  430.68
  15   0.4623     84.270  0.3884    86.832  461.46
  16   0.4808     83.280  0.3654    87.472  492.17
  17   0.4674     83.780  0.3533    88.166  523.63
  18   0.4456     84.800  0.3273    88.954  554.60
  19   0.4409     85.470  0.3172    89.414  585.38
  20   0.4727     84.320  0.3004    89.740  616.10
  21   0.4555     84.270  0.2878    90.342  647.11
  22   0.4686     84.620  0.2735    90.656  678.11
  23   0.4185     85.850  0.2588    91.212  708.84
  24   0.4142     86.220  0.2526    91.362  739.60
  25   0.4535     84.910  0.2373    92.072  770.57
  26   0.3981     86.780  0.2293    92.276  801.48
  27   0.4126     86.350  0.2179    92.670  832.28
  28   0.4413     85.620  0.2098    92.812  863.05
  29   0.3996     87.090  0.1983    93.252  894.08
  30   0.3797     87.610  0.1862    93.652  924.97
  31   0.4029     87.380  0.1814    93.804  955.78
  32   0.3853     87.360  0.1771    94.092  986.56
  33   0.4258     86.860  0.1697    94.174  1017.62
  34   0.4097     87.130  0.1613    94.560  1048.48
  35   0.3931     87.500  0.1565    94.664  1079.31
  36   0.4419     87.260  0.1451    95.074  1110.02
  37   0.4678     86.110  0.1414    95.242  1140.94
  38   0.3981     87.650  0.1406    95.160  1171.82
  39   0.3866     87.780  0.1334    95.406  1202.62
  40   0.4454     87.410  0.1259    95.720  1233.33
  41   0.4476     86.930  0.1204    95.892  1264.31
  42   0.3893     88.010  0.1156    96.140  1295.14
  43   0.4170     87.540  0.1123    96.138  1327.52
  44   0.4051     88.070  0.1099    96.170  1358.27
  45   0.4157     88.220  0.1021    96.498  1389.24
  46   0.3871     88.230  0.1010    96.528  1420.02
  47   0.4056     88.210  0.0984    96.546  1450.76
  48   0.4174     87.990  0.0911    96.978  1481.53
  49   0.4580     87.320  0.0873    96.982  1512.47
  50   0.4070     88.310  0.0879    97.030  1543.28
  51   0.4501     87.240  0.0858    97.084  1574.11
  52   0.4070     88.270  0.0811    97.214  1604.86
  53   0.4820     87.820  0.0792    97.244  1635.83
  54   0.4399     88.180  0.0790    97.276  1666.64
  55   0.4164     88.340  0.0783    97.256  1697.45
  56   0.5321     86.370  0.0695    97.622  1728.19
  57   0.4347     88.380  0.0713    97.596  1759.11
  58   0.4130     89.120  0.0682    97.616  1788.17
  59   0.4646     87.750  0.0641    97.782  1818.89
  60   0.4465     88.750  0.0628    97.826  1848.53
  61   0.5038     87.890  0.0622    97.884  1879.70
  62   0.4367     88.170  0.0632    97.848  1910.50
  63   0.4420     88.980  0.0559    98.084  1941.22
  64   0.4263     89.010  0.0592    97.916  1972.19
  65   0.4459     88.530  0.0551    98.080  2001.32
  66   0.4198     89.110  0.0552    98.218  2032.10
  67   0.4341     89.240  0.0522    98.202  2062.84
  68   0.5211     87.940  0.0500    98.270  2093.74
  69   0.4234     89.280  0.0520    98.204  2124.59
  70   0.4138     88.930  0.0475    98.372  2155.37
  71   0.4670     88.300  0.0455    98.498  2186.15
  72   0.4432     88.950  0.0473    98.416  2217.07
  73   0.4473     88.990  0.0478    98.402  2247.83
  74   0.4397     88.710  0.0453    98.430  2278.53
  75   0.4517     88.450  0.0409    98.634  2309.45
  76   0.4344     89.400  0.0404    98.586  2340.35
  77   0.4649     89.040  0.0398    98.650  2371.38
  78   0.4140     89.840  0.0408    98.588  2402.20
  79   0.4861     88.890  0.0357    98.832  2431.13
  80   0.4622     89.150  0.0380    98.664  2462.02
  81   0.4755     89.020  0.0348    98.812  2492.86
  82   0.4663     88.640  0.0380    98.750  2523.64
  83   0.4698     89.230  0.0348    98.784  2554.36
  84   0.5017     88.530  0.0348    98.826  2585.30
  85   0.4519     89.280  0.0329    98.846  2616.14
