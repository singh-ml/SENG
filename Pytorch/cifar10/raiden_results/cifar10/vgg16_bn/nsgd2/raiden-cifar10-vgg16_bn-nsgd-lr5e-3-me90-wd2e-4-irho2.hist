Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 60273909248 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4244     47.720  1.7851    33.810  36.23
   2   1.2665     54.630  1.3048    52.916  64.97
   3   0.9187     67.570  1.0688    62.198  93.57
   4   0.8756     69.640  0.9142    68.158  122.98
   5   0.8271     71.560  0.8016    72.400  151.80
   6   0.7247     75.000  0.7204    75.392  180.87
   7   0.6720     76.940  0.6511    77.884  211.70
   8   0.6330     78.340  0.6019    79.654  242.61
   9   0.6046     78.950  0.5540    81.372  271.45
  10   0.5492     81.440  0.5162    82.610  300.31
  11   0.6858     76.680  0.4853    83.450  329.43
  12   0.5184     82.850  0.4557    84.648  357.96
  13   0.6438     78.320  0.4298    85.542  388.56
  14   0.5085     82.550  0.4069    86.088  419.54
  15   0.4819     83.540  0.3833    86.950  448.87
  16   0.4542     84.410  0.3594    88.062  479.58
  17   0.4600     84.610  0.3430    88.408  508.30
  18   0.4754     83.480  0.3253    88.918  537.56
  19   0.4750     83.980  0.3083    89.564  568.30
  20   0.4372     85.640  0.2973    90.076  597.30
  21   0.4169     86.180  0.2778    90.588  626.49
  22   0.4300     85.860  0.2611    91.070  657.31
  23   0.4170     86.510  0.2489    91.442  689.54
  24   0.4311     85.630  0.2402    91.804  720.56
  25   0.4071     86.710  0.2316    92.216  751.50
  26   0.4116     86.010  0.2214    92.392  780.68
  27   0.4258     86.300  0.2100    92.964  809.91
  28   0.4070     86.860  0.1995    93.300  840.90
  29   0.4337     86.440  0.1903    93.578  870.22
  30   0.4550     85.670  0.1774    93.908  899.34
  31   0.3867     87.650  0.1713    94.256  930.30
  32   0.4025     87.100  0.1636    94.454  959.16
  33   0.4055     88.060  0.1545    94.774  988.10
  34   0.4556     86.210  0.1478    94.918  1018.76
  35   0.3920     88.010  0.1389    95.332  1049.53
  36   0.4605     86.540  0.1325    95.528  1080.39
  37   0.4129     87.690  0.1298    95.578  1111.10
  38   0.4018     87.960  0.1259    95.658  1139.81
  39   0.4128     87.890  0.1123    96.172  1170.77
  40   0.3919     88.490  0.1116    96.202  1201.02
  41   0.4230     87.820  0.1017    96.564  1231.76
  42   0.4502     88.370  0.0955    96.780  1260.69
  43   0.4194     88.430  0.0917    96.888  1289.88
  44   0.3917     89.180  0.0909    96.830  1320.56
  45   0.4155     88.970  0.0849    97.066  1349.60
  46   0.4335     88.260  0.0802    97.270  1380.46
  47   0.4095     89.090  0.0768    97.370  1411.27
  48   0.4178     88.930  0.0688    97.696  1441.78
  49   0.4162     88.800  0.0699    97.544  1470.54
  50   0.4253     88.590  0.0687    97.590  1501.33
  51   0.4445     88.830  0.0601    97.994  1530.53
  52   0.4782     87.860  0.0574    98.064  1561.24
  53   0.4418     89.010  0.0574    98.012  1590.08
  54   0.4392     88.950  0.0538    98.138  1618.92
  55   0.4385     89.290  0.0514    98.214  1647.62
  56   0.4764     89.070  0.0444    98.492  1676.73
  57   0.4447     89.650  0.0456    98.414  1707.55
  58   0.4717     89.130  0.0405    98.594  1738.33
  59   0.4594     89.620  0.0405    98.606  1767.15
  60   0.4792     89.280  0.0368    98.774  1797.82
  61   0.4485     89.990  0.0358    98.766  1827.13
  62   0.4831     89.520  0.0324    98.908  1856.11
  63   0.4726     89.600  0.0345    98.804  1886.77
  64   0.5030     89.660  0.0278    99.062  1915.84
  65   0.4841     89.750  0.0297    98.980  1946.65
  66   0.4796     89.580  0.0283    99.020  1977.38
  67   0.4799     89.800  0.0245    99.188  2006.49
  68   0.4696     90.220  0.0259    99.092  2037.37
  69   0.5115     89.720  0.0194    99.358  2066.10
  70   0.5051     90.130  0.0197    99.304  2096.75
  71   0.5202     89.740  0.0234    99.210  2125.48
  72   0.5154     89.540  0.0209    99.312  2154.65
  73   0.5053     90.090  0.0174    99.428  2183.64
  74   0.5077     89.750  0.0179    99.392  2212.59
  75   0.5109     89.840  0.0151    99.464  2241.42
  76   0.5261     89.940  0.0158    99.442  2270.39
  77   0.5604     89.760  0.0160    99.462  2299.29
  78   0.5236     90.300  0.0133    99.556  2329.95
  79   0.5233     90.000  0.0138    99.528  2359.15
  80   0.5270     90.360  0.0139    99.508  2389.85
  81   0.5448     90.040  0.0119    99.606  2418.42
  82   0.5316     90.060  0.0134    99.560  2447.13
  83   0.5284     89.910  0.0134    99.574  2477.92
  84   0.5536     90.000  0.0118    99.618  2507.09
  85   0.5324     89.980  0.0108    99.644  2537.81
  86   0.5607     90.130  0.0120    99.604  2568.73
  87   0.5558     89.910  0.0103    99.646  2599.58
  88   0.5561     90.200  0.0095    99.676  2630.28
  89   0.5755     90.290  0.0091    99.686  2660.97
  90   0.5728     90.030  0.0092    99.688  2691.84
