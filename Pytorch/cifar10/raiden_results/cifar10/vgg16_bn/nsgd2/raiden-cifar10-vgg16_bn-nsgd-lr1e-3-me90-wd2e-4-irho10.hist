Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 53825982464 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3801     48.220  1.7535    35.216  34.48
   2   1.1122     61.350  1.3038    52.820  63.36
   3   0.9208     67.810  1.0641    62.512  92.13
   4   0.8530     70.180  0.9089    68.532  121.20
   5   0.8085     72.090  0.7907    72.726  149.94
   6   0.7418     74.240  0.7048    76.044  180.88
   7   0.7765     73.720  0.6475    78.054  211.82
   8   0.5950     79.400  0.5919    79.926  240.35
   9   0.6277     78.660  0.5490    81.392  269.34
  10   0.5824     79.860  0.5138    82.714  300.28
  11   0.5284     82.070  0.4829    83.712  329.44
  12   0.5807     80.870  0.4598    84.402  360.21
  13   0.5487     80.960  0.4324    85.520  390.91
  14   0.5160     82.120  0.4096    86.074  420.12
  15   0.5499     81.490  0.3804    87.010  449.18
  16   0.5090     82.830  0.3582    87.848  479.99
  17   0.4476     85.310  0.3429    88.328  508.87
  18   0.5240     82.010  0.3347    88.760  539.80
  19   0.5779     81.100  0.3186    89.260  570.57
  20   0.4509     84.720  0.3026    89.748  601.31
  21   0.4387     85.120  0.2871    90.330  632.31
  22   0.4256     85.360  0.2720    90.818  661.69
  23   0.4320     85.660  0.2625    91.286  692.43
  24   0.4688     84.400  0.2497    91.374  723.40
  25   0.4292     86.170  0.2336    92.144  754.32
  26   0.4758     84.570  0.2240    92.176  785.09
  27   0.4116     86.450  0.2124    92.774  815.80
  28   0.4696     84.610  0.2101    92.790  846.76
  29   0.3944     86.640  0.2003    93.210  877.97
  30   0.4260     86.220  0.1928    93.348  908.81
  31   0.4464     85.600  0.1833    93.752  939.54
  32   0.4139     86.860  0.1716    94.170  970.49
  33   0.4190     86.370  0.1684    94.164  1001.44
  34   0.4180     87.110  0.1608    94.618  1032.22
  35   0.4252     87.090  0.1567    94.642  1061.23
  36   0.3891     87.760  0.1475    94.994  1092.16
  37   0.4301     87.100  0.1469    94.810  1121.37
  38   0.4037     87.230  0.1390    95.214  1152.15
  39   0.4145     87.720  0.1296    95.438  1183.11
  40   0.4376     87.520  0.1277    95.638  1214.05
  41   0.3868     88.530  0.1234    95.752  1244.97
  42   0.4021     87.720  0.1224    95.834  1275.72
  43   0.4171     87.720  0.1147    95.928  1306.56
  44   0.4321     87.960  0.1131    96.104  1337.26
  45   0.4340     87.480  0.1058    96.316  1368.13
  46   0.4083     88.040  0.1002    96.528  1398.95
  47   0.3839     88.870  0.1006    96.530  1429.64
  48   0.4341     87.740  0.0922    96.904  1460.54
  49   0.4104     88.130  0.0917    96.914  1489.91
  50   0.3986     88.480  0.0882    96.936  1520.69
  51   0.4371     87.670  0.0842    97.112  1551.42
  52   0.4139     88.530  0.0806    97.160  1580.61
  53   0.4291     88.530  0.0784    97.352  1611.54
  54   0.4740     87.690  0.0777    97.304  1642.31
  55   0.4373     88.940  0.0754    97.454  1671.31
  56   0.4431     88.220  0.0749    97.492  1700.13
  57   0.4240     88.390  0.0685    97.582  1730.89
  58   0.4625     87.770  0.0657    97.724  1761.63
  59   0.4319     88.860  0.0651    97.800  1792.60
  60   0.4437     88.420  0.0627    97.888  1823.47
  61   0.4939     87.630  0.0629    97.870  1854.33
  62   0.4693     88.790  0.0599    98.002  1885.08
  63   0.4460     89.160  0.0584    98.100  1916.04
  64   0.4346     88.780  0.0598    97.962  1946.97
  65   0.4634     88.540  0.0555    98.154  1977.69
  66   0.4251     89.150  0.0552    98.148  2008.51
  67   0.4659     88.690  0.0521    98.170  2039.23
  68   0.4493     88.640  0.0529    98.182  2068.44
  69   0.4812     88.370  0.0488    98.330  2099.23
  70   0.4559     88.850  0.0502    98.242  2129.99
  71   0.4357     89.590  0.0432    98.534  2160.96
  72   0.4319     89.460  0.0450    98.494  2191.87
  73   0.4504     89.240  0.0423    98.522  2222.62
  74   0.4708     88.910  0.0419    98.566  2253.31
  75   0.4432     89.400  0.0455    98.518  2284.27
  76   0.4370     89.130  0.0419    98.570  2316.82
  77   0.4648     89.080  0.0417    98.562  2347.59
  78   0.4764     88.960  0.0358    98.732  2378.35
  79   0.4808     88.740  0.0430    98.492  2409.34
  80   0.4783     88.860  0.0440    98.478  2440.08
  81   0.4561     89.250  0.0384    98.734  2469.27
  82   0.4305     89.690  0.0377    98.668  2497.85
  83   0.4825     89.340  0.0335    98.828  2527.22
  84   0.4585     89.300  0.0367    98.746  2558.04
  85   0.4558     89.530  0.0351    98.798  2587.25
  86   0.4773     89.230  0.0336    98.880  2618.19
  87   0.4566     89.490  0.0317    98.938  2649.17
  88   0.4447     89.720  0.0298    98.960  2679.96
  89   0.4569     89.660  0.0326    98.906  2710.96
  90   0.4583     89.450  0.0322    98.920  2740.29
