Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--bh', '32', '--irho', '10', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 61885047296 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4503     46.010  1.7542    34.724  36.20
   2   1.2333     55.600  1.2905    53.910  65.07
   3   1.0625     62.850  1.0801    62.000  95.32
   4   0.9086     68.520  0.9162    67.990  126.42
   5   0.7598     73.480  0.8110    72.254  155.29
   6   0.7396     73.900  0.7232    74.988  186.09
   7   0.6585     77.750  0.6565    77.716  214.82
   8   0.6915     76.500  0.6054    79.466  245.85
   9   0.6263     79.080  0.5652    80.818  275.13
  10   0.6341     78.850  0.5250    82.420  305.95
  11   0.5508     81.650  0.4940    83.462  335.34
  12   0.5356     82.210  0.4588    84.334  366.35
  13   0.5471     81.070  0.4389    85.358  397.27
  14   0.5513     81.250  0.4112    86.244  426.34
  15   0.4997     82.830  0.3915    86.678  457.29
  16   0.4426     84.880  0.3718    87.532  488.35
  17   0.4683     84.240  0.3549    88.174  517.75
  18   0.4315     85.240  0.3311    88.890  548.57
  19   0.4843     83.810  0.3171    89.428  578.03
  20   0.4865     83.470  0.3010    89.782  609.00
  21   0.4681     84.440  0.2873    90.274  639.87
  22   0.4588     84.740  0.2705    91.006  668.95
  23   0.4953     83.540  0.2648    91.044  698.43
  24   0.4312     85.390  0.2534    91.384  727.61
  25   0.4023     86.360  0.2395    91.860  758.47
  26   0.4208     86.240  0.2239    92.396  789.33
  27   0.4119     86.040  0.2187    92.620  820.38
  28   0.4233     86.590  0.2069    92.860  851.39
  29   0.4601     85.290  0.2008    93.198  882.26
  30   0.4183     86.550  0.1919    93.432  911.27
  31   0.4107     87.020  0.1826    93.736  942.28
  32   0.5342     83.420  0.1742    94.146  973.30
  33   0.4530     85.750  0.1722    94.150  1004.42
  34   0.4087     87.230  0.1656    94.324  1033.50
  35   0.3972     87.210  0.1589    94.632  1064.50
  36   0.4188     87.570  0.1525    94.740  1095.38
  37   0.4688     86.190  0.1452    95.112  1124.55
  38   0.4522     86.850  0.1438    95.044  1155.63
  39   0.4023     87.870  0.1389    95.300  1186.61
  40   0.4086     88.030  0.1273    95.636  1217.50
  41   0.3778     88.360  0.1253    95.702  1246.88
  42   0.3911     88.800  0.1176    95.986  1276.24
  43   0.3794     88.140  0.1200    95.882  1307.25
  44   0.4216     87.890  0.1116    96.110  1338.07
  45   0.3964     88.380  0.1137    96.084  1367.30
  46   0.3950     88.180  0.1063    96.306  1396.78
  47   0.3872     88.620  0.1005    96.572  1429.37
  48   0.4051     88.300  0.0941    96.782  1458.74
  49   0.4154     88.760  0.0936    96.790  1489.58
  50   0.4209     88.310  0.0928    96.876  1520.57
  51   0.4585     87.780  0.0861    97.096  1551.46
  52   0.4356     88.110  0.0831    97.208  1580.83
  53   0.3898     89.280  0.0827    97.198  1610.09
  54   0.4118     88.690  0.0780    97.276  1641.08
  55   0.4106     88.400  0.0779    97.404  1671.97
  56   0.4180     89.060  0.0714    97.622  1702.89
  57   0.4212     89.170  0.0676    97.648  1733.72
  58   0.4351     88.270  0.0682    97.670  1764.72
  59   0.4151     88.910  0.0658    97.724  1795.69
  60   0.4245     88.760  0.0625    97.872  1825.02
  61   0.4205     88.730  0.0651    97.770  1855.84
  62   0.4202     89.420  0.0636    97.846  1885.11
  63   0.4636     87.920  0.0625    97.918  1916.14
  64   0.4207     89.240  0.0568    98.080  1946.99
  65   0.4240     88.910  0.0569    98.058  1977.83
  66   0.4508     88.890  0.0531    98.156  2008.91
  67   0.4630     88.290  0.0597    97.956  2039.86
  68   0.4466     88.660  0.0525    98.206  2069.17
  69   0.4358     89.170  0.0517    98.322  2097.89
  70   0.4252     89.230  0.0506    98.284  2128.95
  71   0.4239     89.240  0.0458    98.440  2159.85
  72   0.4252     89.190  0.0478    98.292  2190.63
  73   0.4429     88.890  0.0456    98.428  2221.59
  74   0.4318     89.520  0.0422    98.628  2252.61
  75   0.4248     89.350  0.0472    98.368  2283.52
  76   0.4425     89.420  0.0428    98.532  2312.61
  77   0.4652     89.310  0.0433    98.550  2343.59
  78   0.4419     89.370  0.0379    98.668  2374.59
  79   0.4419     89.510  0.0394    98.618  2405.40
  80   0.4548     89.440  0.0402    98.650  2436.23
  81   0.4410     89.580  0.0390    98.720  2467.24
  82   0.4916     89.380  0.0368    98.804  2498.13
  83   0.4236     89.660  0.0394    98.594  2528.98
  84   0.4429     89.430  0.0384    98.714  2559.85
  85   0.4325     89.770  0.0381    98.746  2590.89
  86   0.4169     89.840  0.0374    98.746  2621.78
  87   0.4089     90.230  0.0334    98.898  2652.65
  88   0.4513     89.600  0.0345    98.848  2683.48
  89   0.4829     89.370  0.0311    98.980  2714.50
  90   0.4305     89.860  0.0324    98.970  2745.51
