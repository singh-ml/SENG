Use GPU: 0 for training
==> Running with ['main_nsgd.py', '--batch-size=256', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--bh', '32', '--irho', '5', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 60273909248 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2992     10.950  4.2516    10.558  36.29
   2   2.2289     14.790  2.2742    12.668  65.44
   3   2.1030     19.060  2.2008    16.122  94.45
   4   1.9599     21.500  2.0401    19.734  123.27
   5   1.8981     24.840  1.9636    22.172  152.12
   6   1.8869     25.210  1.9247    23.610  182.51
   7   2.0973     24.020  1.8964    25.336  211.32
   8   1.8398     29.650  1.8464    27.026  241.52
   9   1.8847     29.140  1.7773    30.456  270.48
  10   1.7828     33.920  1.7126    33.342  299.01
  11   1.6597     36.520  1.6508    35.972  330.05
  12   1.7581     35.050  1.6074    38.226  358.75
  13   1.7761     36.790  1.5574    40.414  387.59
  14   1.7526     38.430  1.5027    43.188  417.89
  15   1.5440     41.750  1.4447    45.894  446.48
  16   1.4501     47.770  1.3824    48.822  476.87
  17   1.3318     50.580  1.3188    51.618  505.60
  18   1.3040     52.910  1.2542    54.442  534.37
  19   1.1270     58.960  1.1891    57.340  563.17
  20   1.4398     50.540  1.1328    59.394  592.03
  21   1.1261     60.240  1.0930    61.208  620.63
  22   1.1254     60.120  1.0441    63.018  649.18
  23   0.9912     64.830  0.9836    65.104  678.30
  24   1.0020     65.520  0.9454    66.626  707.33
  25   0.9872     65.660  0.9018    68.328  735.91
  26   0.9178     68.390  0.8568    69.934  765.21
  27   0.9003     68.690  0.8057    71.770  793.90
  28   0.7603     73.680  0.7768    73.030  822.71
  29   0.7786     73.200  0.7358    74.616  851.61
  30   0.7370     74.350  0.7071    75.672  880.64
  31   0.7285     75.490  0.6819    76.760  910.96
  32   0.8162     73.200  0.6525    77.786  940.18
  33   0.7007     76.280  0.6300    78.548  969.21
  34   0.7403     74.950  0.6084    79.408  998.17
  35   0.6390     78.480  0.5781    80.426  1027.37
  36   0.6787     76.480  0.5581    81.356  1056.23
  37   0.6342     78.710  0.5359    81.834  1084.97
  38   0.5983     79.780  0.5157    82.528  1114.96
  39   0.5725     80.720  0.5005    83.146  1143.95
  40   0.5664     80.910  0.4802    83.778  1172.91
  41   0.5456     81.600  0.4578    84.506  1202.01
  42   0.5444     82.600  0.4400    85.096  1230.96
  43   0.5685     81.700  0.4264    85.692  1260.09
  44   0.5591     82.150  0.4125    86.032  1289.07
  45   0.5177     83.560  0.3975    86.422  1317.61
  46   0.4930     84.070  0.3782    87.068  1346.61
  47   0.4825     84.250  0.3705    87.500  1375.78
  48   0.5346     82.740  0.3504    88.180  1404.92
  49   0.4953     84.000  0.3366    88.496  1433.72
  50   0.4776     84.020  0.3297    88.796  1462.19
  51   0.4679     84.760  0.3183    89.248  1490.75
  52   0.4840     84.530  0.3000    89.836  1519.53
  53   0.4716     84.850  0.2896    90.248  1548.11
  54   0.4925     84.330  0.2859    90.228  1576.72
  55   0.4584     85.350  0.2716    90.734  1607.49
  56   0.5151     84.830  0.2592    91.270  1636.46
  57   0.5287     83.970  0.2480    91.568  1665.04
  58   0.4553     85.760  0.2431    91.588  1694.21
  59   0.4813     86.220  0.2289    92.206  1723.49
  60   0.5010     85.210  0.2143    92.584  1753.80
  61   0.4738     85.820  0.2075    92.818  1782.58
  62   0.4841     85.780  0.2046    93.062  1811.60
  63   0.4888     85.570  0.1933    93.356  1840.37
  64   0.4746     85.940  0.1860    93.616  1868.93
  65   0.4785     86.220  0.1762    94.030  1899.94
  66   0.4987     86.420  0.1697    94.084  1930.26
  67   0.4934     86.580  0.1653    94.298  1958.96
  68   0.4818     86.520  0.1551    94.720  1988.14
  69   0.4997     86.140  0.1485    94.840  2017.00
  70   0.4995     86.530  0.1443    95.106  2046.03
  71   0.4943     86.820  0.1343    95.344  2075.16
  72   0.5386     86.300  0.1277    95.638  2104.24
  73   0.4918     87.170  0.1244    95.758  2132.97
  74   0.5199     86.620  0.1200    95.922  2161.57
  75   0.5104     86.870  0.1121    96.104  2190.56
  76   0.4946     87.130  0.1122    96.160  2219.24
  77   0.5178     86.870  0.1039    96.464  2248.44
  78   0.5281     86.920  0.0980    96.564  2277.68
  79   0.5309     87.050  0.0966    96.730  2306.87
  80   0.5365     86.780  0.0941    96.854  2337.68
  81   0.5373     86.790  0.0891    96.954  2366.38
  82   0.5581     86.630  0.0883    97.028  2396.83
  83   0.5423     86.760  0.0896    96.926  2425.41
  84   0.5528     86.800  0.0817    97.208  2454.15
  85   0.5459     87.120  0.0788    97.286  2485.12
