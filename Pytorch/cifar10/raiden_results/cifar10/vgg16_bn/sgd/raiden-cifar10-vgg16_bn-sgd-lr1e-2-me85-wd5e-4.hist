Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4059058688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4590     46.380  1.8133    32.950  13.16
   2   1.2191     56.800  1.3365    51.670  23.98
   3   1.1784     58.230  1.0949    61.314  34.79
   4   0.9264     67.440  0.9267    67.666  45.58
   5   0.7666     73.180  0.8059    72.444  56.38
   6   0.7596     73.940  0.7108    75.924  67.25
   7   0.7039     76.190  0.6500    77.912  78.11
   8   0.6018     79.460  0.5927    80.090  88.87
   9   0.6466     78.480  0.5500    81.298  99.70
  10   0.5731     80.850  0.5126    82.864  110.55
  11   0.6130     79.660  0.4788    83.720  121.34
  12   0.5189     82.450  0.4502    84.926  132.13
  13   0.5247     82.600  0.4226    85.896  142.91
  14   0.4718     84.410  0.3947    86.692  153.72
  15   0.4740     84.200  0.3763    87.424  164.49
  16   0.5113     82.600  0.3660    87.640  175.32
  17   0.5089     83.190  0.3383    88.670  186.10
  18   0.4803     84.370  0.3221    89.104  196.91
  19   0.4497     85.050  0.3021    89.958  207.72
  20   0.4505     84.990  0.2909    90.098  218.50
  21   0.4239     85.870  0.2785    90.552  229.29
  22   0.4387     85.030  0.2596    91.302  240.09
  23   0.5248     82.750  0.2510    91.528  250.88
  24   0.4211     86.280  0.2375    91.900  261.71
  25   0.4618     85.120  0.2274    92.194  272.48
  26   0.4712     85.350  0.2146    92.778  283.33
  27   0.4801     84.740  0.2040    93.068  294.16
  28   0.3729     87.900  0.1969    93.246  304.95
  29   0.4036     87.040  0.1890    93.620  315.75
  30   0.4707     85.740  0.1751    94.010  326.60
  31   0.4029     87.670  0.1697    94.234  337.43
  32   0.4981     85.120  0.1565    94.764  348.21
  33   0.4279     87.280  0.1501    94.842  359.05
  34   0.4704     86.010  0.1473    95.012  369.86
  35   0.4136     87.430  0.1368    95.400  380.67
  36   0.4628     86.870  0.1324    95.498  391.50
  37   0.4153     87.750  0.1234    95.816  402.34
  38   0.4946     86.810  0.1158    96.032  413.21
  39   0.4394     87.690  0.1116    96.218  424.03
  40   0.4002     88.480  0.1090    96.292  434.81
  41   0.4694     87.010  0.0993    96.622  445.62
  42   0.4647     87.260  0.0981    96.680  456.47
  43   0.4330     88.260  0.0908    96.954  467.26
  44   0.4681     87.780  0.0855    97.196  478.08
  45   0.4198     88.760  0.0793    97.196  488.86
  46   0.4291     88.920  0.0707    97.588  499.65
  47   0.4184     89.330  0.0724    97.466  510.43
  48   0.4408     88.970  0.0648    97.830  521.25
  49   0.4443     89.150  0.0645    97.736  532.04
  50   0.4241     89.190  0.0619    97.898  542.84
  51   0.4193     89.270  0.0564    98.060  553.64
  52   0.4978     88.500  0.0494    98.334  564.43
  53   0.4484     89.610  0.0512    98.234  575.29
  54   0.4593     89.000  0.0435    98.482  586.08
  55   0.4729     89.140  0.0426    98.494  596.89
  56   0.4413     89.610  0.0415    98.584  607.70
  57   0.4524     89.760  0.0371    98.786  618.52
  58   0.4662     89.560  0.0372    98.744  629.32
  59   0.4728     89.580  0.0318    98.856  640.14
  60   0.4693     89.540  0.0289    99.054  650.95
  61   0.4558     90.100  0.0304    98.924  661.78
  62   0.4628     89.720  0.0265    99.126  672.60
  63   0.4654     90.150  0.0216    99.252  683.38
  64   0.4648     89.940  0.0218    99.258  694.16
  65   0.4921     89.880  0.0196    99.354  704.93
  66   0.4750     90.070  0.0195    99.340  715.77
  67   0.4887     90.390  0.0183    99.392  726.58
  68   0.4948     90.110  0.0146    99.554  737.38
  69   0.4762     90.360  0.0148    99.534  748.17
  70   0.5017     90.270  0.0118    99.600  758.96
  71   0.4896     90.440  0.0124    99.580  769.74
  72   0.5141     90.280  0.0123    99.570  780.56
  73   0.5050     90.510  0.0112    99.640  791.41
  74   0.5013     90.680  0.0086    99.722  802.21
  75   0.5014     90.710  0.0089    99.698  813.03
  76   0.5120     90.540  0.0091    99.684  823.85
  77   0.5080     90.560  0.0091    99.722  834.67
  78   0.5066     90.620  0.0089    99.720  845.50
  79   0.5019     90.640  0.0085    99.722  856.31
  80   0.4992     90.720  0.0075    99.756  867.14
  81   0.5171     90.620  0.0077    99.760  877.99
  82   0.5125     90.890  0.0086    99.722  888.82
  83   0.5138     90.810  0.0070    99.778  899.65
  84   0.5114     90.590  0.0072    99.746  910.46
  85   0.5042     90.740  0.0057    99.830  921.31
