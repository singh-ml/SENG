Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4059058688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3671     49.480  1.7486    34.364  13.26
   2   1.1605     57.020  1.3089    52.208  24.06
   3   1.1146     60.980  1.1072    60.368  34.91
   4   1.0570     63.490  0.9681    65.562  45.66
   5   0.8307     70.340  0.8660    69.626  56.45
   6   0.7046     75.150  0.7855    72.400  67.22
   7   0.7318     73.830  0.7123    75.266  78.01
   8   0.7400     74.550  0.6601    77.294  88.83
   9   0.6348     78.180  0.6198    78.730  99.60
  10   0.5846     79.920  0.5738    80.292  110.40
  11   0.7037     75.600  0.5464    81.300  121.19
  12   0.5833     80.170  0.5110    82.374  131.94
  13   0.5451     81.290  0.4815    83.528  142.76
  14   0.5487     81.480  0.4617    84.316  153.61
  15   0.5905     79.600  0.4382    85.064  164.41
  16   0.5289     81.620  0.4156    85.752  175.22
  17   0.5070     82.620  0.3971    86.498  186.05
  18   0.4986     83.160  0.3759    87.076  196.84
  19   0.4981     82.850  0.3585    87.704  207.66
  20   0.4900     83.500  0.3497    87.916  218.48
  21   0.4835     84.020  0.3294    88.546  229.25
  22   0.4906     83.500  0.3135    89.310  240.05
  23   0.4669     84.320  0.3036    89.600  250.83
  24   0.4499     84.570  0.2953    89.822  261.65
  25   0.4332     85.460  0.2767    90.496  272.42
  26   0.4868     83.630  0.2666    90.820  283.20
  27   0.4994     83.700  0.2552    91.284  294.01
  28   0.4809     84.350  0.2438    91.568  304.83
  29   0.4374     85.580  0.2365    91.912  315.63
  30   0.4750     85.190  0.2229    92.144  326.40
  31   0.4414     85.730  0.2166    92.614  337.16
  32   0.4128     86.900  0.2040    92.908  347.99
  33   0.4667     85.070  0.2017    93.024  358.83
  34   0.4175     86.890  0.1923    93.346  369.60
  35   0.4331     86.410  0.1804    93.730  380.45
  36   0.4388     86.580  0.1722    94.074  391.30
  37   0.4492     86.380  0.1661    94.232  402.14
  38   0.4473     86.590  0.1599    94.508  412.92
  39   0.4451     86.540  0.1515    94.740  423.74
  40   0.4687     86.660  0.1441    95.042  434.54
  41   0.4313     87.150  0.1381    95.248  445.33
  42   0.4439     87.480  0.1332    95.318  456.17
  43   0.4851     86.480  0.1260    95.628  467.00
  44   0.4546     87.200  0.1211    95.720  477.77
  45   0.4592     86.820  0.1192    95.932  488.59
  46   0.4738     86.830  0.1083    96.186  499.35
  47   0.4630     87.360  0.1066    96.378  510.11
  48   0.4542     87.660  0.1069    96.302  520.88
  49   0.4599     87.820  0.0980    96.580  531.66
  50   0.5081     86.540  0.0929    96.708  542.42
  51   0.4885     87.460  0.0868    96.996  553.22
  52   0.4695     87.750  0.0851    97.074  564.05
  53   0.5113     86.950  0.0772    97.270  574.85
  54   0.5017     87.510  0.0776    97.272  585.65
  55   0.4825     87.550  0.0708    97.550  596.50
  56   0.5156     87.710  0.0691    97.634  607.32
  57   0.5218     87.300  0.0648    97.724  618.12
  58   0.4837     88.450  0.0643    97.746  628.91
  59   0.5286     87.610  0.0607    97.960  639.69
  60   0.5002     87.960  0.0597    97.906  650.45
  61   0.5027     88.640  0.0526    98.142  661.28
  62   0.5101     88.130  0.0498    98.298  672.10
  63   0.5389     88.040  0.0458    98.420  682.87
  64   0.5245     88.560  0.0450    98.462  693.67
  65   0.5187     88.430  0.0405    98.570  704.46
  66   0.5416     88.660  0.0411    98.568  715.31
  67   0.5239     88.380  0.0427    98.520  726.13
  68   0.5236     88.300  0.0383    98.720  736.94
  69   0.5359     88.690  0.0358    98.798  747.75
  70   0.5362     88.510  0.0343    98.826  758.60
  71   0.5329     89.080  0.0306    98.960  769.42
  72   0.5596     88.430  0.0309    98.930  780.19
  73   0.5498     88.630  0.0277    99.048  791.02
  74   0.5513     88.830  0.0275    99.048  801.79
  75   0.5601     88.660  0.0248    99.154  812.55
  76   0.5463     88.690  0.0263    99.088  823.38
  77   0.5521     88.450  0.0269    99.106  834.21
  78   0.5456     88.890  0.0261    99.128  844.98
  79   0.5588     88.860  0.0209    99.308  855.78
  80   0.5591     88.780  0.0206    99.270  866.65
  81   0.5806     88.880  0.0181    99.394  877.47
  82   0.5768     88.630  0.0232    99.200  888.31
  83   0.5787     88.580  0.0221    99.268  899.12
  84   0.5800     88.720  0.0186    99.364  909.91
  85   0.5935     88.730  0.0172    99.468  920.72
  86   0.5903     88.840  0.0173    99.418  931.54
  87   0.6024     88.640  0.0163    99.462  942.34
  88   0.5898     88.950  0.0154    99.492  953.13
  89   0.6013     88.910  0.0145    99.464  964.01
  90   0.6068     88.830  0.0152    99.482  974.84
