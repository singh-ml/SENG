Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4059058688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.4637     11.390  2.6779    11.962  13.61
   2   2.0936     21.640  2.2025    17.148  24.50
   3   1.8563     26.870  1.9994    22.390  35.39
   4   1.9446     27.500  1.8820    26.352  46.24
   5   1.7409     33.030  1.7870    29.972  57.08
   6   1.9420     35.490  1.7074    33.788  67.93
   7   1.5981     39.930  1.5955    38.582  78.81
   8   1.4505     45.640  1.5019    43.232  89.67
   9   1.3053     52.760  1.3693    49.680  100.55
  10   1.2140     57.190  1.2554    54.976  111.45
  11   1.1462     59.600  1.1438    59.578  122.32
  12   1.0907     61.060  1.0676    62.716  133.20
  13   1.0102     65.490  0.9815    66.002  144.09
  14   0.8883     69.070  0.9218    68.064  155.00
  15   0.9349     68.160  0.8389    71.334  165.84
  16   0.7999     73.190  0.7768    73.466  176.75
  17   0.6894     77.160  0.7154    75.886  187.64
  18   0.7331     77.090  0.6561    77.986  198.51
  19   0.6738     77.140  0.6206    79.268  209.35
  20   0.6270     79.090  0.5725    80.992  220.22
  21   0.6080     80.240  0.5505    81.554  231.08
  22   0.6732     78.980  0.5208    82.722  241.95
  23   0.6173     79.590  0.4806    84.304  252.82
  24   0.5100     82.820  0.4655    84.416  263.70
  25   0.5286     82.820  0.4387    85.440  274.57
  26   0.5210     82.840  0.4221    85.886  285.45
  27   0.5192     83.070  0.3977    86.852  296.32
  28   0.4889     84.390  0.3753    87.442  307.16
  29   0.4937     84.470  0.3589    88.080  318.07
  30   0.4670     84.130  0.3449    88.392  328.91
  31   0.5248     83.180  0.3268    89.176  339.80
  32   0.5012     84.390  0.3082    89.714  350.66
  33   0.4743     85.780  0.2919    90.188  361.53
  34   0.4643     85.240  0.2833    90.528  372.42
  35   0.4570     85.430  0.2675    91.058  383.30
  36   0.4688     85.280  0.2559    91.554  394.16
  37   0.4526     86.170  0.2424    91.908  405.03
  38   0.4542     86.220  0.2326    92.156  415.85
  39   0.4804     85.030  0.2247    92.514  426.67
  40   0.4078     87.810  0.2112    92.840  437.56
  41   0.4363     86.760  0.1940    93.420  448.37
  42   0.4268     87.040  0.1885    93.632  459.27
  43   0.4452     86.860  0.1785    93.900  470.17
  44   0.4381     87.160  0.1720    94.248  481.07
  45   0.4755     86.050  0.1627    94.576  491.93
  46   0.4159     87.640  0.1524    94.816  502.77
  47   0.4701     86.950  0.1430    95.162  513.62
  48   0.4173     88.030  0.1358    95.372  524.51
  49   0.4274     87.980  0.1311    95.580  535.36
  50   0.4314     88.270  0.1161    96.078  546.26
  51   0.4484     88.350  0.1118    96.250  557.17
  52   0.4938     87.770  0.1025    96.458  568.03
  53   0.4187     88.810  0.1052    96.430  578.94
  54   0.4181     88.850  0.0919    96.920  589.83
  55   0.4366     89.010  0.0834    97.156  600.72
  56   0.4465     88.760  0.0772    97.370  611.56
  57   0.4720     88.700  0.0720    97.568  622.47
  58   0.4663     88.790  0.0662    97.764  633.30
  59   0.5006     88.670  0.0602    98.006  644.18
  60   0.4502     89.530  0.0551    98.112  655.06
  61   0.4627     89.390  0.0530    98.206  665.91
  62   0.4894     89.060  0.0448    98.526  676.79
  63   0.5176     89.380  0.0417    98.648  687.64
  64   0.5105     89.400  0.0385    98.706  698.51
  65   0.4798     89.810  0.0374    98.754  709.39
  66   0.4975     89.780  0.0338    98.868  720.22
  67   0.5062     89.950  0.0285    99.068  731.11
  68   0.5237     89.610  0.0267    99.060  741.98
  69   0.5044     90.090  0.0244    99.182  752.87
  70   0.5075     89.890  0.0215    99.290  763.78
  71   0.5291     90.190  0.0198    99.322  774.66
  72   0.5249     90.070  0.0183    99.358  785.53
  73   0.5335     90.230  0.0140    99.546  796.40
  74   0.5444     90.130  0.0151    99.510  807.29
  75   0.5339     90.370  0.0141    99.540  818.15
  76   0.5396     90.360  0.0127    99.610  828.97
  77   0.5400     90.350  0.0114    99.610  839.83
  78   0.5536     90.230  0.0100    99.666  850.67
  79   0.5644     90.220  0.0097    99.666  861.54
  80   0.5625     90.270  0.0098    99.690  872.42
  81   0.5599     90.310  0.0091    99.720  883.29
  82   0.5630     90.210  0.0085    99.722  894.15
  83   0.5586     90.280  0.0089    99.732  905.01
  84   0.5606     90.260  0.0084    99.736  915.83
  85   0.5696     90.310  0.0074    99.780  926.72
