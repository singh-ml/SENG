Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4059058688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3756     48.580  1.7290    35.568  13.26
   2   1.1537     58.730  1.3148    51.940  24.00
   3   0.9930     64.140  1.1263    59.776  34.82
   4   0.8838     68.290  0.9842    65.080  45.62
   5   0.8050     71.900  0.8805    69.030  56.43
   6   0.7829     72.880  0.7955    72.454  67.22
   7   0.7099     75.420  0.7292    74.780  78.03
   8   0.6529     77.130  0.6780    76.726  88.83
   9   0.6288     78.400  0.6282    78.494  99.58
  10   0.6373     78.410  0.5884    79.692  110.39
  11   0.6028     79.340  0.5565    80.912  121.18
  12   0.5710     79.770  0.5220    82.174  132.00
  13   0.5673     80.760  0.4933    83.116  142.80
  14   0.5804     80.520  0.4710    83.854  153.59
  15   0.5484     81.030  0.4518    84.556  164.35
  16   0.6305     78.570  0.4214    85.506  175.14
  17   0.5101     82.250  0.4046    86.048  185.90
  18   0.4837     83.730  0.3793    87.024  196.70
  19   0.4761     83.970  0.3687    87.332  207.50
  20   0.5058     82.770  0.3496    87.944  218.36
  21   0.4778     83.980  0.3392    88.270  229.14
  22   0.4767     84.170  0.3238    88.996  239.93
  23   0.4621     84.230  0.3098    89.408  250.70
  24   0.4449     84.600  0.2908    90.066  261.50
  25   0.4430     84.870  0.2811    90.418  272.27
  26   0.4739     84.240  0.2656    90.740  283.05
  27   0.4785     84.240  0.2604    91.042  293.83
  28   0.4392     85.210  0.2452    91.526  304.61
  29   0.4344     85.440  0.2387    91.752  315.45
  30   0.4748     84.620  0.2239    92.306  326.25
  31   0.4338     85.580  0.2173    92.448  337.10
  32   0.4202     86.250  0.2087    92.826  347.87
  33   0.4452     85.900  0.2001    93.100  358.67
  34   0.4572     85.550  0.1957    93.190  369.42
  35   0.4272     86.900  0.1850    93.714  380.20
  36   0.4355     86.330  0.1750    93.956  391.01
  37   0.4467     86.420  0.1657    94.272  401.84
  38   0.4473     86.220  0.1621    94.382  412.64
  39   0.4629     86.050  0.1587    94.540  423.43
  40   0.4622     86.360  0.1473    94.862  434.26
  41   0.4709     86.450  0.1394    95.190  445.04
  42   0.4579     86.590  0.1382    95.328  455.83
  43   0.4720     86.560  0.1252    95.610  466.66
  44   0.4644     86.480  0.1262    95.712  477.44
  45   0.4710     86.810  0.1195    95.936  488.21
  46   0.4622     86.970  0.1103    96.210  499.01
  47   0.4643     86.880  0.1047    96.416  509.80
  48   0.4856     86.910  0.0970    96.662  520.64
  49   0.5020     86.930  0.0954    96.776  531.41
  50   0.5290     86.260  0.0894    96.884  542.18
  51   0.4891     87.070  0.0880    96.972  553.01
  52   0.5378     86.750  0.0808    97.244  563.79
  53   0.5239     87.130  0.0763    97.348  574.54
  54   0.5269     87.420  0.0744    97.468  585.34
  55   0.5344     86.830  0.0716    97.524  596.16
  56   0.5327     87.220  0.0632    97.918  607.02
  57   0.5008     87.410  0.0656    97.674  617.85
  58   0.5425     87.020  0.0615    97.904  628.66
  59   0.5455     87.010  0.0572    98.066  639.49
  60   0.5573     87.340  0.0560    98.076  650.25
  61   0.5400     87.430  0.0547    98.128  661.06
  62   0.5954     86.750  0.0485    98.316  671.86
  63   0.5449     87.660  0.0516    98.240  682.65
  64   0.5570     87.350  0.0451    98.470  693.51
  65   0.5865     87.480  0.0425    98.572  704.34
  66   0.5707     87.730  0.0419    98.594  715.14
  67   0.5714     87.850  0.0405    98.618  725.95
  68   0.5533     87.910  0.0390    98.598  736.77
  69   0.5641     87.620  0.0351    98.774  747.54
  70   0.5763     87.760  0.0330    98.890  758.34
  71   0.5860     87.850  0.0298    98.972  769.16
  72   0.5895     87.790  0.0303    98.930  779.93
  73   0.6104     87.550  0.0294    98.996  790.75
  74   0.5911     87.920  0.0281    99.056  801.60
  75   0.5987     87.780  0.0273    99.032  812.42
  76   0.6264     87.620  0.0249    99.160  823.21
  77   0.6105     87.850  0.0272    99.072  834.01
  78   0.6113     87.850  0.0257    99.130  844.76
  79   0.6138     88.020  0.0258    99.152  855.54
  80   0.6260     87.640  0.0212    99.288  866.31
  81   0.6138     87.980  0.0230    99.200  877.32
  82   0.6120     88.080  0.0223    99.202  888.12
  83   0.6266     87.850  0.0204    99.298  898.94
  84   0.6455     87.690  0.0193    99.338  909.75
  85   0.6296     87.730  0.0229    99.248  920.56
