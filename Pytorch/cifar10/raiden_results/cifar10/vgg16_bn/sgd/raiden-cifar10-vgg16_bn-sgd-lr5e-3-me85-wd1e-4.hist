Use GPU: 0 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4059058688 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4754     45.210  1.7607    34.050  13.10
   2   1.2265     56.170  1.3331    51.224  23.92
   3   1.0824     61.570  1.1256    59.688  34.70
   4   0.9624     65.740  0.9800    65.324  45.47
   5   0.8371     70.020  0.8673    69.394  56.28
   6   0.7483     73.960  0.7920    72.486  67.08
   7   0.7804     73.200  0.7237    74.926  77.84
   8   0.7607     74.400  0.6646    77.160  88.68
   9   0.6895     75.850  0.6257    78.542  99.44
  10   0.6216     79.030  0.5867    80.014  110.22
  11   0.5905     80.130  0.5482    81.202  120.98
  12   0.5773     80.240  0.5173    82.236  131.77
  13   0.5628     80.750  0.4912    83.124  142.54
  14   0.6101     79.120  0.4675    84.086  153.30
  15   0.5990     80.010  0.4457    84.768  164.11
  16   0.5444     80.960  0.4256    85.392  174.89
  17   0.4932     82.830  0.4038    86.290  185.69
  18   0.5063     82.230  0.3848    86.790  196.49
  19   0.5202     82.920  0.3642    87.696  207.25
  20   0.4856     83.720  0.3544    87.870  218.06
  21   0.4840     83.590  0.3379    88.402  228.83
  22   0.4762     83.460  0.3219    88.858  239.68
  23   0.5268     82.330  0.3051    89.432  250.49
  24   0.4619     83.740  0.2969    90.038  261.33
  25   0.4309     85.110  0.2878    90.114  272.10
  26   0.4400     85.030  0.2714    90.578  282.92
  27   0.4602     84.450  0.2591    91.068  293.69
  28   0.4326     85.720  0.2466    91.516  304.50
  29   0.4213     85.650  0.2422    91.762  315.27
  30   0.4547     85.370  0.2248    92.244  326.10
  31   0.4708     85.050  0.2238    92.138  336.90
  32   0.4545     85.360  0.2070    92.908  347.66
  33   0.4558     85.150  0.2036    92.898  358.43
  34   0.4663     85.830  0.1936    93.310  369.28
  35   0.4665     85.100  0.1865    93.472  380.07
  36   0.4336     86.180  0.1741    93.914  390.90
  37   0.4572     86.060  0.1659    94.312  401.72
  38   0.4922     85.480  0.1528    94.722  412.57
  39   0.4311     86.820  0.1546    94.726  423.39
  40   0.4531     86.130  0.1463    94.944  434.19
  41   0.4603     86.410  0.1374    95.270  445.01
  42   0.4758     85.810  0.1375    95.206  455.79
  43   0.5509     84.940  0.1288    95.670  466.65
  44   0.4632     86.450  0.1229    95.828  477.53
  45   0.4744     86.350  0.1188    95.952  488.30
  46   0.4788     86.580  0.1071    96.370  499.08
  47   0.4725     87.140  0.1066    96.204  509.88
  48   0.4690     86.780  0.1049    96.362  520.67
  49   0.4989     86.730  0.0957    96.774  531.48
  50   0.5005     87.210  0.0880    96.966  542.29
  51   0.4707     87.480  0.0875    97.026  553.11
  52   0.4889     86.860  0.0831    97.104  563.90
  53   0.4917     87.250  0.0848    97.088  574.72
  54   0.4900     87.440  0.0739    97.474  585.52
  55   0.5161     87.250  0.0704    97.630  596.35
  56   0.4910     87.490  0.0695    97.596  607.18
  57   0.5062     87.160  0.0636    97.864  618.01
  58   0.5188     87.420  0.0629    97.890  628.83
  59   0.5254     87.510  0.0561    98.064  639.60
  60   0.5169     87.610  0.0559    98.102  650.39
  61   0.5336     87.180  0.0527    98.206  661.21
  62   0.5285     87.450  0.0507    98.328  672.02
  63   0.5189     87.480  0.0533    98.186  682.85
  64   0.5484     87.410  0.0449    98.466  693.64
  65   0.5522     87.640  0.0398    98.630  704.44
  66   0.5470     87.720  0.0410    98.626  715.31
  67   0.5642     87.500  0.0396    98.652  726.10
  68   0.5637     87.740  0.0375    98.688  736.93
  69   0.5669     87.650  0.0361    98.806  747.77
  70   0.5786     87.690  0.0342    98.828  758.61
  71   0.5635     87.840  0.0359    98.766  769.42
  72   0.5564     88.430  0.0332    98.896  780.23
  73   0.5700     88.390  0.0308    98.942  791.04
  74   0.5853     88.120  0.0287    99.048  801.86
  75   0.5797     88.200  0.0282    99.038  812.69
  76   0.5855     88.370  0.0290    98.938  823.50
  77   0.5801     88.340  0.0246    99.134  834.27
  78   0.5832     88.370  0.0248    99.162  845.06
  79   0.6098     88.190  0.0239    99.168  855.86
  80   0.5958     88.180  0.0258    99.108  866.67
  81   0.6017     88.230  0.0253    99.142  877.49
  82   0.6018     88.090  0.0232    99.196  888.26
  83   0.6033     88.280  0.0230    99.228  899.07
  84   0.5946     88.250  0.0222    99.230  909.89
  85   0.6037     88.410  0.0209    99.256  920.71
