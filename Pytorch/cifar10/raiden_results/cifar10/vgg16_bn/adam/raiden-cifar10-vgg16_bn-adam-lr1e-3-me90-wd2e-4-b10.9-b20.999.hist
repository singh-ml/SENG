Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0907     16.320  3.3052    13.498  6.93
   2   1.8885     20.050  2.0081    17.712  12.38
   3   1.9442     22.540  1.9291    19.602  17.78
   4   1.8415     22.250  1.8726    22.192  23.22
   5   1.6902     32.810  1.7752    28.028  28.75
   6   1.5669     38.710  1.6027    35.158  34.18
   7   1.4861     44.520  1.4876    40.886  39.61
   8   1.5221     44.310  1.4484    46.582  45.04
   9   1.2774     54.690  1.4952    46.288  50.46
  10   1.5828     46.280  1.4251    50.980  55.89
  11   1.5547     45.020  1.4231    49.790  61.33
  12   1.8005     30.720  1.4630    52.546  66.87
  13   1.0895     61.120  1.2654    55.164  72.30
  14   1.0907     63.300  1.3593    55.032  77.75
  15   1.5408     45.650  1.6964    44.252  83.20
  16   1.0578     62.190  1.2071    57.216  88.63
  17   5.1412     33.580  1.0562    63.694  94.06
  18   1.4105     47.840  1.7608    35.602  99.52
  19   1.1961     56.460  1.3926    51.890  105.08
  20   0.9874     64.920  1.1054    61.168  110.49
  21   0.9123     66.950  0.9653    65.990  115.91
  22   0.8669     69.870  0.8915    68.670  121.35
  23   1.0467     69.390  0.8328    71.214  126.81
  24   1.2679     53.990  1.8063    45.722  132.24
  25   0.9931     64.450  1.1313    60.430  137.65
  26   0.8486     70.220  0.9279    67.832  143.25
  27   0.8097     72.370  0.8334    71.360  148.68
  28   0.7445     74.380  0.7951    72.848  154.12
  29   0.8273     72.360  0.7391    75.166  159.58
  30   1.0940     61.960  1.0842    65.082  165.03
  31   0.8409     73.070  0.8324    71.586  170.52
  32   1.2665     56.960  0.8558    71.742  175.96
  33   0.7664     74.200  0.7666    74.286  181.54
  34   0.7197     75.950  0.6798    77.334  186.95
  35   0.6549     78.360  0.6331    78.982  192.40
  36   1.9840     27.730  2.1062    51.278  197.86
  37   1.4106     47.540  1.6890    39.396  203.28
  38   1.0977     61.360  1.2839    54.042  208.73
  39   0.8825     68.780  1.0580    63.940  214.14
  40   0.8128     71.450  0.9008    69.546  219.75
  41   0.8029     72.810  0.8080    73.148  225.17
  42   0.8064     73.350  0.7372    75.520  230.63
  43   0.6847     76.930  0.7120    76.622  236.04
  44   0.6292     78.960  0.6580    78.248  241.47
  45   0.6701     78.340  0.6247    79.842  246.90
  46   1.5439     63.710  0.6420    79.394  252.34
  47   0.5714     80.690  0.6368    79.404  257.90
  48   0.5688     81.770  0.5487    82.454  263.31
  49   0.5612     81.450  0.5797    81.370  268.76
  50   0.5662     82.040  0.5375    82.736  274.17
  51   0.5207     82.870  0.4918    84.128  279.60
  52   0.6017     81.430  0.4794    84.466  285.03
  53   0.5374     82.550  0.4634    85.150  290.60
  54   0.5197     82.960  0.4504    85.564  296.04
  55   0.5960     82.120  0.4355    86.234  301.49
  56   0.5213     83.310  0.6202    81.026  306.94
  57   0.5326     83.590  0.4486    85.760  312.39
  58   0.5859     82.910  0.4102    86.918  317.82
  59   0.5616     82.970  0.3913    87.642  323.25
  60   0.5481     82.970  0.3900    87.494  328.70
  61   0.6176     81.930  0.3773    88.182  334.26
  62   0.4851     84.990  0.3713    88.340  339.69
  63   0.4736     85.010  0.3585    88.746  345.14
  64   0.7298     81.710  0.3531    88.762  350.56
  65   0.5806     82.940  0.4492    86.152  355.99
  66   0.5438     83.390  0.3544    88.888  361.45
  67   0.4434     86.230  0.3245    89.710  366.99
  68   0.4910     85.010  0.3144    90.094  372.42
  69   0.4529     86.550  0.3057    90.394  377.87
  70   0.4505     86.120  0.3036    90.418  383.33
  71   0.5304     84.750  0.2923    90.720  388.77
  72   0.4268     86.580  0.2937    90.600  394.22
  73   0.4548     85.970  0.2894    90.794  399.66
  74   0.4687     86.300  0.2782    91.270  405.19
  75   0.5478     83.900  0.5447    84.096  410.64
  76   0.4210     86.820  0.3486    89.028  416.12
  77   0.4440     86.960  0.2886    90.960  421.57
  78   0.4141     87.260  0.2610    91.716  427.01
  79   0.4165     87.810  0.2596    91.856  432.48
  80   0.4317     86.800  0.2482    92.322  437.92
  81   0.4041     87.530  0.2447    92.358  443.49
  82   0.4403     87.200  0.2380    92.538  448.96
  83   0.4479     87.050  0.2435    92.344  454.41
  84   0.4520     86.960  0.2315    92.694  459.85
  85   0.4601     86.780  0.2324    92.750  465.30
  86   0.4252     87.120  0.2285    92.936  470.78
  87   0.4643     87.300  0.2235    92.940  476.26
  88   0.4762     86.580  0.2272    92.936  481.86
  89   0.4719     87.060  0.2396    92.598  487.30
  90   0.4374     87.360  0.2200    93.178  492.74
