Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1779     16.270  3.8910    11.464  7.02
   2   1.9440     24.240  2.0485    17.916  12.42
   3   1.8324     27.290  1.9060    21.912  17.85
   4   1.7229     37.340  1.8281    26.862  23.32
   5   1.6161     36.100  1.6416    36.326  28.75
   6   1.5443     39.310  1.5222    41.398  34.29
   7   1.2438     55.510  1.3338    51.350  39.71
   8   6.2078     37.700  1.1791    58.648  45.16
   9   1.0286     65.550  1.0691    63.304  50.60
  10   4.5204     45.890  1.0030    66.700  56.03
  11   2.3209     61.230  0.9015    70.560  61.44
  12   0.7613     74.740  1.0101    68.402  66.84
  13   0.9254     68.740  0.9867    68.102  72.40
  14   0.8408     72.670  0.8803    71.398  77.82
  15   0.8397     71.980  0.7434    76.044  83.25
  16   1.7329     64.480  0.8060    74.772  88.67
  17   0.7255     76.010  0.8175    74.514  94.10
  18   0.8261     75.260  0.7759    76.822  99.53
  19   0.6269     79.220  0.7436    77.250  105.04
  20   1.3660     67.640  0.7159    78.400  110.48
  21   0.7263     76.970  0.9049    73.946  115.89
  22   0.6139     80.120  0.6610    79.340  121.34
  23   0.5830     80.990  0.7484    77.316  126.77
  24   0.6993     78.330  0.6172    80.672  132.22
  25   0.6366     79.840  0.6834    79.852  137.64
  26   0.8329     72.630  0.6512    80.254  143.07
  27   0.5405     82.840  0.5076    83.632  148.60
  28   0.5863     81.670  0.4833    84.322  154.04
  29   0.6108     80.960  0.6919    79.984  159.47
  30   0.5619     82.120  0.4792    85.096  164.90
  31   0.5100     83.900  0.5001    84.386  170.34
  32   0.5955     81.530  0.4476    85.934  175.75
  33   0.4569     85.660  0.4979    84.792  181.29
  34   0.4827     85.240  0.4019    87.170  186.70
  35   0.5166     83.790  0.3797    87.902  192.15
  36   0.4774     84.510  0.4732    85.482  197.58
  37   0.4709     85.030  0.3592    88.418  203.02
  38   0.6223     80.940  0.3881    88.160  208.44
  39   0.4862     85.200  0.3436    88.930  213.87
  40   3.2028     78.400  0.3992    87.860  219.30
  41   0.4258     86.420  0.4108    87.634  224.85
  42   0.4134     86.620  0.3051    90.234  230.30
  43   0.4819     85.630  0.3124    90.078  235.74
  44   0.4540     85.720  0.3015    90.496  241.15
  45   0.4119     87.130  0.2896    90.872  246.60
  46   0.4726     86.600  0.2781    91.142  252.01
  47   0.5203     85.290  0.3093    90.502  257.56
  48   0.4559     86.720  0.2524    91.918  262.98
  49   0.4935     85.240  0.2755    91.338  268.43
  50   0.4826     86.120  0.2462    92.148  273.87
  51   0.4197     87.500  0.2427    92.326  279.32
  52   0.5148     85.150  0.2353    92.714  284.78
  53   0.5133     86.990  0.2366    92.632  290.21
  54   0.4743     86.650  0.2157    93.104  295.70
  55   0.4407     86.850  0.2118    93.342  301.16
  56   0.4024     87.930  0.2156    93.134  306.62
  57   0.5486     85.680  0.2025    93.624  312.06
  58   0.3987     88.250  0.2219    93.026  317.49
  59   0.4126     88.200  0.1956    93.906  322.92
  60   0.4459     87.570  0.1890    94.108  328.34
  61   0.3986     88.430  0.1896    94.130  333.93
  62   0.4374     87.400  0.2095    93.544  339.37
  63   0.4439     87.750  0.1796    94.302  344.81
  64   0.5125     86.640  0.1954    94.426  350.22
  65   0.4141     88.710  0.2284    93.114  355.63
  66   0.4056     88.680  0.1612    94.894  361.07
  67   0.4276     87.740  0.2059    93.666  366.50
  68   0.4860     87.470  0.1667    94.756  372.07
  69   0.3763     88.910  0.1621    94.852  377.52
  70   0.4392     88.890  0.1584    95.008  382.96
  71   0.4765     88.090  0.1572    95.088  388.41
  72   0.4044     88.990  0.1640    94.782  393.82
  73   0.4150     88.560  0.1496    95.264  399.26
  74   0.4677     87.960  0.1617    94.978  404.70
  75   0.4292     89.600  0.1432    95.408  410.26
  76   1.0962     85.960  0.1573    95.242  415.67
  77   0.4370     88.810  0.1631    94.964  421.14
  78   0.4177     89.130  0.1359    95.828  426.57
  79   0.4813     89.120  0.1421    95.710  432.01
  80   0.4198     89.870  0.1397    95.656  437.48
  81   0.4069     89.300  0.1381    95.688  442.89
  82   0.4918     87.320  0.1367    95.644  448.48
  83   0.4298     89.010  0.1703    94.982  453.92
  84   0.4536     88.960  0.1322    95.980  459.38
  85   0.4295     89.210  0.1310    95.844  464.82
  86   0.4538     89.010  0.1285    96.108  470.28
  87   0.4580     89.380  0.1317    95.858  475.70
  88   0.5048     88.700  0.1283    96.032  481.13
  89   0.4630     88.590  0.1246    96.212  486.70
  90   0.4081     89.960  0.1243    96.142  492.12
