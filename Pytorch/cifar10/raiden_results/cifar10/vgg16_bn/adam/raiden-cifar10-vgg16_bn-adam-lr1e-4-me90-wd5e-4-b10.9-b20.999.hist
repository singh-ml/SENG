Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4509     44.600  1.9192    28.818  6.99
   2   1.1961     56.870  1.3704    49.468  12.42
   3   1.0935     59.880  1.1625    58.516  17.85
   4   0.9268     67.650  1.0233    64.090  23.26
   5   0.8995     68.370  0.9290    67.740  28.80
   6   0.8361     70.790  0.8474    70.532  34.23
   7   0.8488     70.320  0.7794    73.264  39.68
   8   0.7639     72.690  0.7200    75.248  45.10
   9   0.6855     76.270  0.6725    77.216  50.51
  10   0.6597     77.020  0.6340    78.498  55.95
  11   0.6783     76.920  0.5944    79.890  61.39
  12   0.6111     79.060  0.5636    81.134  66.95
  13   0.6385     77.390  0.5331    81.948  72.36
  14   0.5930     80.080  0.5041    83.056  77.80
  15   0.5734     80.440  0.4912    83.402  83.23
  16   0.6042     79.320  0.4587    84.472  88.64
  17   0.5517     81.220  0.4415    85.248  94.08
  18   0.5783     80.700  0.4290    85.518  99.53
  19   0.5192     82.460  0.4094    86.346  105.09
  20   0.5164     82.350  0.3929    86.740  110.51
  21   0.5181     83.060  0.3725    87.414  115.95
  22   0.4971     83.370  0.3656    87.682  121.36
  23   0.4962     83.500  0.3432    88.626  126.82
  24   0.5230     82.580  0.3334    88.982  132.27
  25   0.5367     82.960  0.3271    89.070  137.69
  26   0.5205     83.580  0.3091    89.638  143.22
  27   0.5175     83.440  0.3044    89.758  148.66
  28   0.4564     84.890  0.2873    90.370  154.08
  29   0.5479     82.860  0.2805    90.648  159.52
  30   0.5305     83.580  0.2631    91.144  164.94
  31   0.4717     85.090  0.2615    91.282  170.38
  32   0.4978     84.530  0.2504    91.688  175.83
  33   0.4823     84.430  0.2421    92.004  181.39
  34   0.5512     83.340  0.2418    91.966  186.83
  35   0.5007     85.390  0.2331    92.292  192.24
  36   0.5239     84.460  0.2252    92.542  197.66
  37   0.5088     84.780  0.2146    92.792  203.06
  38   0.5411     84.560  0.2064    93.050  208.50
  39   0.5014     85.850  0.2018    93.194  213.90
  40   0.5064     85.370  0.1958    93.534  219.47
  41   0.5041     85.260  0.1916    93.520  224.88
  42   0.5250     85.550  0.1839    93.926  230.32
  43   0.5627     84.210  0.1817    93.988  235.78
  44   0.4956     86.240  0.1711    94.248  241.21
  45   0.4772     85.810  0.1697    94.390  246.64
  46   0.5239     85.450  0.1670    94.502  252.07
  47   0.5466     85.390  0.1547    94.788  257.62
  48   0.6495     82.750  0.1581    94.864  263.04
  49   0.5679     85.320  0.1564    94.788  268.50
  50   0.5351     85.780  0.1502    95.088  273.92
  51   0.4939     86.110  0.1435    95.320  279.37
  52   0.5406     86.170  0.1414    95.238  284.80
  53   0.4970     86.400  0.1405    95.514  290.24
  54   0.5396     86.250  0.1371    95.422  295.78
  55   0.5644     85.000  0.1385    95.414  301.19
  56   0.5703     85.570  0.1230    95.906  306.61
  57   0.5832     85.510  0.1309    95.676  312.01
  58   0.5126     86.360  0.1219    95.924  317.45
  59   0.5485     86.080  0.1161    96.214  322.88
  60   0.5426     85.820  0.1182    96.182  328.32
  61   0.6280     84.940  0.1195    96.020  333.83
  62   0.5866     86.030  0.1116    96.264  339.27
  63   0.5250     86.340  0.1144    96.256  344.70
  64   0.5418     86.780  0.1089    96.320  350.14
  65   0.5365     87.000  0.1059    96.528  355.57
  66   0.5565     85.880  0.1122    96.312  360.99
  67   0.5444     86.400  0.1012    96.746  366.43
  68   0.5830     85.250  0.1036    96.500  371.98
  69   0.5394     86.430  0.1040    96.580  377.41
  70   0.5613     86.570  0.0984    96.636  382.86
  71   0.5467     86.530  0.1012    96.552  388.30
  72   0.6052     85.410  0.0958    96.902  393.72
  73   0.5880     86.800  0.0976    96.798  399.14
  74   0.5806     85.860  0.0975    96.768  404.58
  75   0.5750     86.440  0.0923    97.000  410.15
  76   0.5182     87.260  0.0889    97.030  415.57
  77   0.5458     86.880  0.0894    97.088  421.02
  78   0.5779     86.480  0.0887    97.004  426.46
  79   0.5277     87.200  0.0929    96.960  431.92
  80   0.6043     85.980  0.0845    97.264  437.33
  81   0.5652     86.440  0.0940    96.960  442.78
  82   0.5387     87.660  0.0832    97.332  448.36
  83   0.5490     86.980  0.0811    97.278  453.81
  84   0.5856     86.610  0.0867    97.100  459.26
  85   0.5774     86.130  0.0876    97.220  464.66
  86   0.6266     85.790  0.0810    97.352  470.08
  87   0.5164     87.040  0.0807    97.258  475.50
  88   0.6595     86.060  0.0778    97.442  480.93
  89   0.5477     87.780  0.0856    97.168  486.49
  90   0.6493     86.830  0.0778    97.426  491.93
