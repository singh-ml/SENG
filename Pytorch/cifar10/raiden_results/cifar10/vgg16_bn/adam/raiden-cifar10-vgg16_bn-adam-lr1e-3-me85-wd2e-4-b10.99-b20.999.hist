Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2933     11.990  3.5248    10.266  7.16
   2   2.2662     12.920  2.3295    10.800  12.67
   3   2.2205     14.060  2.3260    12.240  18.09
   4   2.1818     15.000  2.2511    14.048  23.48
   5   2.1751     15.210  2.1788    15.316  28.87
   6   2.0401     18.200  2.0981    16.696  34.25
   7   1.9227     20.150  1.9849    18.856  39.67
   8   1.8752     22.650  1.9487    20.044  45.08
   9   1.8314     24.410  1.9194    21.414  50.63
  10   1.8430     24.420  1.8797    22.672  56.05
  11   1.7740     25.010  1.8497    24.540  61.45
  12   1.6840     30.500  1.7747    27.372  66.85
  13   1.8077     34.780  1.7010    31.420  72.29
  14   1.6005     40.290  1.6082    37.296  77.70
  15   1.4071     45.880  1.4943    42.224  83.11
  16   1.3122     50.430  1.4373    45.094  88.66
  17   1.3756     51.540  1.3087    51.054  94.11
  18   1.2332     57.570  1.2162    55.702  99.50
  19   1.1045     59.710  1.2057    55.990  104.91
  20   0.9880     64.020  1.0636    61.730  110.33
  21   0.9185     67.760  0.9681    65.642  115.75
  22   1.6400     44.030  1.1900    60.966  121.18
  23   1.2410     55.620  1.3904    50.584  126.61
  24   1.0543     63.780  1.1116    60.334  132.02
  25   0.8960     68.920  0.9796    65.508  137.43
  26   1.0161     68.990  0.9052    68.520  142.82
  27   0.9980     65.100  1.1105    64.790  148.22
  28   0.9669     67.340  1.0358    66.562  153.63
  29   0.8566     70.100  0.9543    68.046  159.03
  30   0.7779     73.550  0.8221    71.988  164.46
  31   0.8826     70.500  0.7728    74.198  170.01
  32   0.8153     72.090  0.9202    70.156  175.42
  33   0.7095     76.680  0.7406    75.238  180.82
  34   0.6505     78.240  0.6630    77.658  186.25
  35   0.6161     79.180  0.6282    79.406  191.66
  36   0.5886     80.880  0.5760    81.014  197.06
  37   0.6125     80.460  0.5622    81.540  202.46
  38   1.2287     61.350  0.7802    77.952  208.05
  39   0.9573     67.730  1.0773    66.820  213.49
  40   0.9253     71.110  0.9375    70.218  218.93
  41   0.7327     77.020  0.7920    74.200  224.36
  42   0.6417     78.880  0.6670    78.086  229.77
  43   0.5467     81.730  0.5852    80.620  235.17
  44   0.5981     80.820  0.5452    82.294  240.61
  45   0.6075     81.480  0.5890    80.850  246.03
  46   0.5409     82.470  0.5107    83.176  251.46
  47   0.5162     82.510  0.4758    84.460  256.89
  48   0.5192     82.780  0.4592    84.964  262.30
  49   0.5127     83.470  0.4456    85.596  267.74
  50   0.5291     83.300  0.4284    86.138  273.18
  51   0.4926     84.420  0.4142    86.666  278.65
  52   0.4829     84.370  0.4030    86.834  284.07
  53   0.4802     84.600  0.3933    87.396  289.48
  54   0.4723     84.670  0.3809    87.816  294.91
  55   0.4901     84.640  0.3694    88.070  300.33
  56   0.5308     84.780  0.3603    88.240  305.75
  57   0.5063     84.910  0.3547    88.440  311.18
  58   0.4501     85.550  0.3608    88.504  316.69
  59   0.5011     85.270  0.3425    89.016  322.12
  60   0.6381     81.170  0.4711    85.788  327.56
  61   0.4488     85.260  0.4624    85.246  333.00
  62   0.4264     86.210  0.3570    88.422  338.42
  63   0.4328     86.410  0.3192    89.776  343.83
  64   0.4374     86.510  0.3031    90.286  349.24
  65   0.4422     86.400  0.2902    90.494  354.80
  66   0.4313     86.870  0.2860    90.934  360.22
  67   0.4432     87.450  0.2757    90.996  365.65
  68   0.4247     87.060  0.2761    91.138  371.08
  69   0.4227     86.920  0.2779    91.074  376.51
  70   0.4400     86.990  0.2658    91.462  381.93
  71   0.7728     84.260  0.2667    91.572  387.38
  72   0.4656     86.360  0.2988    90.546  392.94
  73   0.4081     87.540  0.2698    91.432  398.34
  74   0.4460     87.060  0.2486    92.118  403.75
  75   0.4087     87.690  0.2423    92.190  409.19
  76   0.4023     87.710  0.2431    92.234  414.61
  77   0.4192     87.650  0.2325    92.594  420.00
  78   0.4280     87.580  0.2337    92.692  425.42
  79   0.4536     87.590  0.2280    92.856  430.99
  80   0.4457     87.070  0.2277    92.720  436.45
  81   0.4366     87.770  0.2232    93.036  441.90
  82   0.3957     88.320  0.2110    93.328  447.31
  83   0.4344     88.280  0.2093    93.292  452.73
  84   0.4108     88.280  0.2078    93.356  458.17
  85   0.4256     88.570  0.2041    93.442  463.61
