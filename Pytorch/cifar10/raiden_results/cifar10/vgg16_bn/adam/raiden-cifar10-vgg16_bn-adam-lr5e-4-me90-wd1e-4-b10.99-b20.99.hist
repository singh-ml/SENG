Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2813     11.480  3.0328    10.812  7.28
   2   2.2095     15.490  2.2754    12.230  12.69
   3   2.0975     17.390  2.2027    14.884  18.10
   4   1.8969     23.920  2.0211    19.542  23.49
   5   1.9221     22.270  1.8946    23.190  28.88
   6   1.7419     28.450  1.8128    25.836  34.31
   7   1.6922     31.840  1.7248    29.208  39.71
   8   1.5130     41.230  1.5922    36.806  45.28
   9   1.4179     46.330  1.4434    44.786  50.70
  10   1.2893     52.910  1.3277    50.382  56.10
  11   1.1757     57.170  1.2218    55.466  61.53
  12   1.0867     61.900  1.1176    60.116  66.96
  13   0.9677     66.660  1.0198    64.152  72.40
  14   0.9396     68.060  0.9459    67.246  77.81
  15   0.9088     69.330  0.8899    69.306  83.36
  16   0.9148     69.630  0.8265    71.684  88.79
  17   0.7574     73.900  0.7796    73.494  94.20
  18   0.7378     75.260  0.7202    75.486  99.63
  19   0.6942     77.180  0.6957    76.752  105.05
  20   0.8561     76.520  0.6592    77.974  110.47
  21   0.7466     75.400  0.7456    76.378  115.90
  22   0.6442     78.460  0.6654    77.946  121.34
  23   0.6592     78.870  0.6036    79.998  126.88
  24   0.7025     77.860  0.6548    79.152  132.30
  25   0.6342     78.730  0.6429    79.968  137.70
  26   0.7959     76.110  0.7171    77.558  143.12
  27   0.5985     80.270  0.6530    79.000  148.55
  28   0.5713     81.260  0.5621    81.400  153.98
  29   0.6346     79.870  0.5733    81.864  159.52
  30   0.8026     76.550  0.6208    81.974  164.94
  31   0.8530     77.850  0.7533    78.208  170.38
  32   0.8810     70.710  1.0033    73.512  175.80
  33   0.6545     78.000  0.7714    75.164  181.20
  34   0.5586     81.300  0.5759    80.900  186.63
  35   0.5365     82.170  0.4965    83.558  192.05
  36   0.5369     83.040  0.4660    84.736  197.48
  37   0.4849     83.780  0.4421    85.484  203.01
  38   0.4964     84.060  0.4180    86.330  208.44
  39   0.4563     84.770  0.3955    87.008  213.88
  40   0.5164     83.840  0.4084    87.012  219.28
  41   0.4394     85.650  0.3832    87.358  224.73
  42   0.5708     82.770  0.4123    87.490  230.15
  43   0.9599     80.420  0.4481    85.604  235.58
  44   0.4832     85.130  0.4370    85.850  241.14
  45   0.4778     84.550  0.4120    86.920  246.57
  46   0.4406     85.890  0.3525    88.468  251.99
  47   0.4604     85.950  0.3235    89.554  257.42
  48   0.4479     86.130  0.3160    89.742  262.83
  49   0.4377     85.680  0.2940    90.430  268.27
  50   0.4475     86.600  0.2713    91.100  273.70
  51   0.4273     86.350  0.2681    91.176  279.12
  52   0.4218     87.480  0.2514    91.802  284.52
  53   0.4209     87.550  0.2496    91.936  289.97
  54   0.3987     87.770  0.2400    92.170  295.41
  55   0.4366     86.740  0.2356    92.290  300.85
  56   0.4072     87.660  0.2230    92.656  306.26
  57   0.4218     87.390  0.2050    93.434  311.68
  58   0.4248     87.780  0.2001    93.608  317.24
  59   0.3870     88.580  0.1979    93.544  322.70
  60   0.3937     88.210  0.1882    93.900  328.12
  61   0.4123     88.230  0.1831    94.178  333.53
  62   0.4287     88.140  0.1753    94.350  338.97
  63   0.4381     88.240  0.1705    94.452  344.37
  64   0.4023     88.950  0.1652    94.604  349.93
  65   0.4286     88.390  0.1666    94.598  355.33
  66   0.4239     88.850  0.1630    94.688  360.77
  67   0.4184     88.830  0.1553    94.962  366.18
  68   0.4342     88.090  0.1452    95.278  371.63
  69   0.4032     88.440  0.1480    95.218  377.06
  70   0.4508     88.570  0.1441    95.396  382.53
  71   0.4229     89.030  0.1413    95.550  387.94
  72   0.4290     88.810  0.1328    95.742  393.49
  73   0.4541     88.570  0.1285    95.976  398.93
  74   0.4376     88.770  0.1333    95.794  404.34
  75   0.4223     88.950  0.1281    95.770  409.78
  76   0.4155     89.190  0.1215    96.068  415.20
  77   0.4534     88.630  0.1225    96.082  420.61
  78   0.4287     88.980  0.1227    96.134  426.03
  79   0.4521     88.520  0.1141    96.352  431.61
  80   0.4618     88.870  0.1140    96.366  437.05
  81   0.4529     89.030  0.1114    96.466  442.51
  82   0.4540     89.130  0.1084    96.668  447.92
  83   0.4015     89.430  0.1013    96.774  453.33
  84   0.4249     89.340  0.1035    96.628  458.74
  85   0.4260     89.080  0.1068    96.640  464.19
  86   0.4226     89.660  0.0986    96.906  469.75
  87   0.4340     89.000  0.0995    96.832  475.19
  88   0.4342     89.490  0.0993    96.882  480.60
  89   0.4642     88.950  0.0968    96.862  486.02
  90   0.4296     90.000  0.1009    96.784  491.45
