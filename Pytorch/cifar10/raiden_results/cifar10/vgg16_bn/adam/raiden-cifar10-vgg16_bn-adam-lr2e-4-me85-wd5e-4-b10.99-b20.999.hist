Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2674     11.620  2.5408    11.524  7.08
   2   2.1416     15.460  2.2053    14.312  12.47
   3   1.9071     20.800  2.0290    18.006  17.86
   4   1.8692     24.690  1.8649    23.530  23.25
   5   1.6153     35.860  1.7458    28.992  28.69
   6   1.4470     42.880  1.5605    36.742  34.08
   7   1.3726     45.600  1.4440    42.720  39.55
   8   1.2842     52.140  1.3297    48.126  44.94
   9   1.1213     58.450  1.2051    54.626  50.34
  10   0.9530     65.500  1.0427    61.984  55.73
  11   0.8917     68.720  0.9343    67.078  61.15
  12   0.9659     66.460  0.8743    69.686  66.56
  13   0.7751     74.020  0.7901    72.908  71.94
  14   0.7417     75.420  0.7251    75.634  77.38
  15   0.6711     78.150  0.6730    77.590  82.81
  16   0.6693     78.260  0.6254    79.366  88.20
  17   0.6851     78.490  0.6000    80.614  93.61
  18   0.5872     80.870  0.5643    81.806  99.04
  19   0.5946     80.910  0.5300    82.700  104.43
  20   0.5596     82.150  0.4959    83.780  109.82
  21   0.5312     82.650  0.4718    84.702  115.36
  22   0.5823     81.350  0.4599    85.164  120.79
  23   0.5129     83.680  0.4413    85.876  126.20
  24   0.5408     82.900  0.4229    86.518  131.61
  25   0.5129     84.010  0.3983    87.130  137.04
  26   0.5106     84.250  0.3812    87.688  142.44
  27   0.5304     83.140  0.3602    88.448  147.84
  28   0.4792     84.770  0.3490    88.622  153.38
  29   0.4389     86.310  0.3274    89.586  158.80
  30   0.4869     85.830  0.3193    89.688  164.20
  31   0.4853     85.480  0.3144    89.936  169.58
  32   0.4641     86.020  0.3103    89.958  175.00
  33   0.4662     86.240  0.2841    90.950  180.40
  34   0.4686     85.970  0.2924    90.638  185.83
  35   0.4335     86.830  0.2752    91.132  191.38
  36   0.4337     87.330  0.2501    91.880  196.80
  37   0.4198     87.080  0.2452    92.204  202.21
  38   0.4351     87.020  0.2365    92.364  207.62
  39   0.4374     87.430  0.2267    92.666  213.05
  40   0.4503     87.100  0.2189    92.926  218.46
  41   0.4585     87.450  0.2210    92.860  223.85
  42   0.4225     87.640  0.2083    93.292  229.36
  43   0.4303     87.730  0.1972    93.630  234.74
  44   0.4350     87.560  0.1942    93.668  240.14
  45   0.4366     87.810  0.1878    93.876  245.55
  46   0.4249     88.010  0.1959    93.758  250.94
  47   0.4081     88.790  0.1790    94.174  256.34
  48   0.4279     88.000  0.1720    94.498  261.75
  49   0.4234     88.110  0.1770    94.304  267.29
  50   0.4437     87.870  0.1715    94.474  272.67
  51   0.4462     87.830  0.1602    94.938  278.10
  52   0.4111     89.030  0.1574    94.988  283.49
  53   0.4255     88.660  0.1473    95.228  288.91
  54   0.4145     88.950  0.1444    95.498  294.34
  55   0.4274     88.320  0.1479    95.310  299.73
  56   0.4215     88.710  0.1453    95.388  305.27
  57   0.4140     88.750  0.1416    95.520  310.68
  58   0.4427     88.600  0.1335    95.582  316.10
  59   0.4343     87.910  0.1289    95.820  321.53
  60   0.4722     88.250  0.1260    95.906  326.92
  61   0.4439     88.950  0.1251    96.032  332.36
  62   0.4577     88.810  0.1147    96.320  337.75
  63   0.4738     88.160  0.1239    96.004  343.28
  64   0.4709     88.110  0.1247    96.024  348.69
  65   0.4330     88.850  0.1186    96.248  354.11
  66   0.4441     88.810  0.1126    96.444  359.51
  67   0.4582     88.960  0.1114    96.550  364.90
  68   0.4320     89.340  0.1109    96.424  370.30
  69   0.4113     89.420  0.1150    96.310  375.70
  70   0.4256     89.530  0.1045    96.592  381.19
  71   0.4444     88.940  0.1046    96.714  386.61
  72   0.4512     88.810  0.1031    96.692  392.01
  73   0.4345     89.180  0.0981    96.950  397.44
  74   0.4446     88.920  0.0984    96.830  402.88
  75   0.4804     88.960  0.0960    96.910  408.28
  76   0.4493     88.760  0.1000    96.764  413.68
  77   0.4709     89.110  0.0973    96.906  419.21
  78   0.4582     89.280  0.0967    96.922  424.61
  79   0.4458     89.420  0.0905    97.158  430.03
  80   0.4545     89.360  0.0919    97.076  435.44
  81   0.4421     89.540  0.0887    97.194  440.87
  82   0.4324     89.400  0.0907    97.080  446.25
  83   0.4445     89.520  0.0890    97.154  451.66
  84   0.4428     88.840  0.0876    97.252  457.14
  85   0.4341     89.710  0.0825    97.310  462.58
