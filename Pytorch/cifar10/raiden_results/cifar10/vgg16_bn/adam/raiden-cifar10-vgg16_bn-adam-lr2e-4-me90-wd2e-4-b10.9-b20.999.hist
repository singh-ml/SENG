Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8478     25.710  2.3926    15.154  7.14
   2   1.7786     38.660  1.6941    32.746  12.54
   3   1.4487     48.990  1.3666    49.764  17.92
   4   1.0325     63.630  1.1145    60.932  23.38
   5   0.8537     70.000  0.9398    67.536  28.78
   6   0.8367     70.950  0.8341    71.814  34.18
   7   0.7383     75.150  0.7563    74.784  39.59
   8   0.7099     76.090  0.6865    77.424  45.00
   9   0.6552     78.260  0.6356    79.302  50.39
  10   0.7023     77.050  0.5885    80.748  55.79
  11   0.5595     80.960  0.5519    81.950  61.32
  12   0.6581     78.620  0.5119    83.496  66.71
  13   0.6766     78.080  0.4906    84.124  72.09
  14   0.5751     81.050  0.4592    85.098  77.50
  15   0.5298     82.890  0.4380    85.820  82.93
  16   0.5069     83.330  0.4245    86.308  88.35
  17   0.4863     83.600  0.4003    87.062  93.73
  18   0.5000     83.600  0.3841    87.552  99.14
  19   0.5503     82.100  0.3638    88.254  104.53
  20   0.5240     83.430  0.3534    88.426  109.96
  21   0.5270     83.460  0.3356    89.074  115.36
  22   0.4988     83.310  0.3278    89.376  120.77
  23   0.5221     83.310  0.3081    90.058  126.18
  24   0.5730     83.090  0.2961    90.422  131.60
  25   0.4981     84.580  0.2907    90.582  137.07
  26   0.5754     83.980  0.2703    91.174  142.48
  27   0.4311     86.610  0.2877    90.888  147.91
  28   0.4289     86.310  0.2587    91.556  153.33
  29   0.4839     85.700  0.2480    91.948  158.74
  30   0.4460     86.490  0.2326    92.428  164.14
  31   0.4286     86.300  0.2255    92.744  169.56
  32   0.4796     85.860  0.2252    92.676  174.96
  33   0.4824     85.210  0.3183    90.076  180.47
  34   0.4860     86.000  0.2156    92.928  185.85
  35   0.4422     86.790  0.1984    93.616  191.24
  36   0.5269     84.750  0.1953    93.706  196.65
  37   0.5077     86.020  0.1868    93.936  202.05
  38   0.4571     86.790  0.1756    94.298  207.45
  39   0.4519     87.380  0.1701    94.482  212.88
  40   0.4826     85.040  0.2607    92.390  218.39
  41   0.4296     87.320  0.1923    93.842  223.79
  42   0.4628     87.340  0.1583    94.810  229.20
  43   0.4618     86.990  0.1552    95.034  234.62
  44   0.4288     87.690  0.1483    95.110  240.04
  45   0.4533     86.930  0.1482    95.178  245.43
  46   0.4479     87.340  0.1483    95.146  250.86
  47   0.5016     87.230  0.1400    95.462  256.41
  48   0.4688     87.710  0.1378    95.574  261.84
  49   0.4580     88.000  0.1361    95.618  267.28
  50   0.4994     87.420  0.1289    95.792  272.70
  51   0.4810     87.550  0.1346    95.666  278.11
  52   0.4660     87.740  0.1527    95.174  283.51
  53   0.4827     87.820  0.1281    95.880  288.90
  54   0.4783     88.190  0.1189    96.064  294.45
  55   0.4611     88.570  0.1146    96.344  299.86
  56   0.5001     87.960  0.1123    96.280  305.27
  57   0.4528     88.240  0.1157    96.324  310.70
  58   0.6227     85.540  0.1082    96.476  316.12
  59   0.5327     87.170  0.1058    96.654  321.52
  60   0.4642     89.010  0.1059    96.614  326.98
  61   0.4287     88.730  0.1049    96.598  332.39
  62   0.4934     87.820  0.1065    96.604  337.81
  63   0.5035     87.410  0.0989    96.838  343.22
  64   0.4982     87.410  0.1061    96.602  348.65
  65   0.4511     88.710  0.1015    96.786  354.10
  66   0.4489     89.020  0.0971    96.880  359.50
  67   0.5291     87.420  0.1015    96.784  364.91
  68   0.5166     87.840  0.0984    96.772  370.34
  69   0.5681     87.190  0.0898    97.098  375.74
  70   0.4694     88.480  0.0903    97.012  381.14
  71   0.5203     88.070  0.0843    97.328  386.56
  72   0.5143     88.620  0.0827    97.300  391.96
  73   0.5116     88.110  0.0840    97.368  397.40
  74   0.4797     88.160  0.0813    97.368  402.96
  75   0.4362     89.140  0.0858    97.262  408.37
  76   0.5528     87.940  0.0809    97.424  413.76
  77   0.4502     88.650  0.0833    97.220  419.20
  78   0.5912     87.220  0.0791    97.442  424.61
  79   0.5168     88.450  0.0772    97.528  430.03
  80   0.5711     88.020  0.0774    97.528  435.46
  81   0.4974     88.240  0.0787    97.568  440.88
  82   0.5659     88.010  0.0862    97.376  446.36
  83   0.4767     89.200  0.0820    97.394  451.78
  84   0.4521     89.450  0.0749    97.546  457.18
  85   0.5012     89.400  0.0657    97.856  462.61
  86   0.5118     88.470  0.0713    97.672  468.02
  87   0.5318     88.350  0.0690    97.758  473.42
  88   0.4696     88.900  0.0692    97.806  478.96
  89   0.4855     88.980  0.0706    97.796  484.39
  90   0.5797     87.450  0.0692    97.828  489.80
