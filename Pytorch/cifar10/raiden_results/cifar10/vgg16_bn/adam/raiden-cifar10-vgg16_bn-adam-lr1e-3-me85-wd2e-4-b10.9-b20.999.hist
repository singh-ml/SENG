Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2780     11.980  3.7393    11.394  7.13
   2   1.9499     20.610  2.1797    14.932  12.56
   3   2.0575     18.950  1.9618    18.674  18.08
   4   1.8203     25.780  1.9108    20.980  23.50
   5   1.6491     33.630  1.8134    27.104  28.90
   6   1.5332     37.190  1.6499    33.374  34.31
   7   1.5314     41.060  1.5239    39.544  39.73
   8   1.4526     48.910  1.5167    41.854  45.15
   9   1.3903     44.780  1.3657    47.578  50.56
  10   1.3966     48.240  1.2447    52.498  56.09
  11   1.2270     47.300  1.1531    56.200  61.50
  12   1.1902     58.010  1.1974    57.356  66.92
  13   1.3604     48.530  1.4278    50.420  72.33
  14   1.0998     61.800  1.1627    56.352  77.76
  15   1.7694     30.440  1.3337    55.964  83.20
  16   1.0904     58.560  1.3283    51.078  88.61
  17   1.2211     59.320  1.0590    61.966  94.15
  18   1.3120     53.080  1.3586    54.876  99.58
  19   1.1141     62.050  1.2735    57.882  104.99
  20   1.5897     54.750  1.0713    64.944  110.39
  21   1.7080     34.240  1.6541    50.280  115.81
  22   1.5080     42.770  1.8391    39.856  121.21
  23   1.2579     53.900  1.4133    51.738  126.64
  24   1.4539     45.270  1.4643    52.788  132.20
  25   1.0493     62.380  1.1933    58.864  137.63
  26   0.8744     70.340  0.9705    66.662  143.06
  27   0.8105     72.690  0.8634    70.440  148.48
  28   0.7788     73.500  0.8063    72.544  153.90
  29   0.7117     76.360  0.7475    74.746  159.30
  30   0.7233     75.750  0.7200    76.108  164.72
  31   1.0196     64.760  1.0458    70.520  170.27
  32   0.8324     72.520  1.2089    65.926  175.71
  33   0.6742     77.640  0.7509    75.112  181.12
  34   0.6766     77.520  0.6744    77.942  186.55
  35   0.6453     79.330  0.6333    79.264  191.96
  36   0.6325     79.450  0.6040    80.278  197.38
  37   0.6193     80.740  0.5740    81.494  202.79
  38   0.5739     81.370  0.5582    82.118  208.34
  39   0.5522     82.170  0.5374    82.752  213.77
  40   0.5531     81.790  0.5144    83.374  219.17
  41   1.5762     50.630  0.7796    77.580  224.60
  42   1.3904     48.770  1.8092    40.774  230.00
  43   0.9807     64.870  1.1975    57.764  235.43
  44   0.7863     74.080  0.9085    69.022  240.94
  45   0.6812     77.290  0.7578    74.892  246.37
  46   0.7010     77.590  0.6700    78.098  251.79
  47   0.6144     80.070  0.6097    80.064  257.21
  48   0.5712     81.460  0.5590    81.860  262.62
  49   0.5336     82.750  0.5399    82.446  268.03
  50   0.5423     82.970  0.5044    83.784  273.44
  51   0.5405     82.410  0.4900    84.398  278.85
  52   1.9222     60.390  0.4948    84.626  284.26
  53   0.5598     82.010  0.6639    78.956  289.68
  54   0.5251     83.500  0.4893    84.400  295.12
  55   0.5865     82.600  0.4438    85.878  300.56
  56   0.5171     83.580  0.4267    86.532  306.00
  57   0.5315     83.560  0.4096    87.136  311.43
  58   0.4749     84.500  0.4011    87.206  316.91
  59   0.5342     84.470  0.3840    87.828  322.31
  60   0.5221     84.140  0.3825    87.916  327.75
  61   0.5016     84.910  0.3709    88.198  333.18
  62   0.5245     84.380  0.3709    88.466  338.59
  63   0.5082     84.600  0.3867    87.836  344.01
  64   0.5095     84.150  0.4749    85.400  349.43
  65   0.4437     85.810  0.3670    88.268  354.87
  66   0.5270     84.730  0.3357    89.348  360.30
  67   0.4599     86.090  0.3263    89.682  365.72
  68   0.4718     86.140  0.3146    90.142  371.15
  69   0.5898     84.460  0.3057    90.414  376.59
  70   0.4549     86.450  0.3064    90.458  382.01
  71   0.5009     85.790  0.3080    90.446  387.46
  72   0.5204     85.550  0.2845    91.086  393.06
  73   0.4719     86.050  0.3001    90.352  398.51
  74   0.4616     86.350  0.2893    90.900  403.95
  75   0.4580     86.760  0.2770    91.386  409.39
  76   0.4466     87.220  0.2665    91.770  414.81
  77   0.4468     86.850  0.2741    91.526  420.26
  78   0.5545     85.100  0.2749    91.486  425.69
  79   0.5346     84.710  0.2699    91.510  431.24
  80   0.4360     86.870  0.2524    92.214  436.70
  81   0.4845     86.870  0.2465    92.348  442.15
  82   0.4684     86.490  0.2411    92.644  447.59
  83   0.4275     87.270  0.2395    92.720  453.02
  84   0.5314     85.180  0.2379    92.650  458.47
  85   0.5176     86.400  0.2378    92.592  463.93
