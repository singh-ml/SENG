Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5155     44.560  1.9301    28.862  7.03
   2   1.3945     51.620  1.3637    50.126  12.58
   3   1.0531     62.510  1.1487    58.988  18.03
   4   0.9700     66.720  1.0052    64.684  23.47
   5   0.8608     70.110  0.9031    68.316  28.89
   6   0.8664     70.870  0.8197    71.610  34.30
   7   0.7568     73.820  0.7593    73.992  39.73
   8   0.7053     76.330  0.7078    75.910  45.19
   9   0.7007     75.710  0.6570    77.828  50.72
  10   0.6734     77.110  0.6162    79.168  56.16
  11   0.6059     79.640  0.5832    80.196  61.59
  12   0.6480     78.510  0.5477    81.444  67.07
  13   0.6225     78.870  0.5238    82.308  72.50
  14   0.6226     78.570  0.4969    83.358  77.94
  15   0.5757     80.720  0.4724    83.978  83.39
  16   0.6308     79.190  0.4508    84.810  88.82
  17   0.5680     81.170  0.4342    85.332  94.39
  18   0.5699     80.230  0.4177    86.056  99.83
  19   0.5417     82.230  0.3987    86.488  105.27
  20   0.5340     81.860  0.3788    87.282  110.68
  21   0.5097     83.120  0.3686    87.580  116.11
  22   0.4984     83.560  0.3517    88.130  121.53
  23   0.5208     82.400  0.3415    88.604  126.94
  24   0.4889     83.850  0.3245    89.046  132.49
  25   0.5523     82.180  0.3198    89.174  137.93
  26   0.5767     81.000  0.2994    89.810  143.35
  27   0.5018     83.400  0.2823    90.498  148.78
  28   0.5025     83.270  0.2801    90.644  154.20
  29   0.5192     83.450  0.2675    91.144  159.65
  30   0.4838     84.370  0.2578    91.402  165.12
  31   0.5806     83.260  0.2417    91.848  170.69
  32   0.5623     81.870  0.2458    91.760  176.13
  33   0.5111     84.300  0.2372    92.016  181.55
  34   0.4837     84.760  0.2266    92.298  186.99
  35   0.5358     83.920  0.2104    92.836  192.41
  36   0.4925     85.230  0.2095    92.942  197.85
  37   0.5593     83.680  0.2047    93.284  203.40
  38   0.5167     84.690  0.1986    93.340  208.85
  39   0.5226     84.950  0.1903    93.766  214.28
  40   0.5832     83.830  0.1816    93.870  219.73
  41   0.5593     83.910  0.1783    94.056  225.18
  42   0.5692     84.410  0.1720    94.180  230.64
  43   0.5166     85.080  0.1679    94.414  236.09
  44   0.5254     85.820  0.1584    94.664  241.54
  45   0.5633     84.790  0.1550    94.772  246.98
  46   0.5457     85.330  0.1540    94.834  252.39
  47   0.5077     85.940  0.1502    94.902  257.84
  48   0.5750     84.800  0.1412    95.268  263.30
  49   0.5213     85.630  0.1389    95.310  268.75
  50   0.6020     83.990  0.1366    95.448  274.30
  51   0.5383     85.980  0.1333    95.588  279.70
  52   0.6273     84.300  0.1312    95.690  285.16
  53   0.5373     85.720  0.1260    95.902  290.61
  54   0.5048     86.220  0.1247    95.838  296.05
  55   0.6067     85.480  0.1168    96.096  301.50
  56   0.5756     85.150  0.1171    96.118  306.92
  57   0.6337     85.280  0.1110    96.366  312.36
  58   0.5622     85.550  0.1096    96.460  317.93
  59   0.5826     85.520  0.1103    96.334  323.36
  60   0.5743     85.020  0.1097    96.314  328.83
  61   0.6061     85.670  0.1010    96.590  334.27
  62   0.5629     86.710  0.1020    96.616  339.71
  63   0.5513     86.250  0.1027    96.538  345.16
  64   0.6191     86.020  0.0951    96.760  350.75
  65   0.5714     86.570  0.0954    96.940  356.21
  66   0.5548     86.850  0.0899    97.040  361.66
  67   0.5234     86.750  0.0936    96.900  367.12
  68   0.5366     86.980  0.0895    96.984  372.59
  69   0.5182     87.380  0.0915    96.986  378.04
  70   0.5566     86.630  0.0887    97.040  383.51
  71   0.5465     86.270  0.0862    97.126  388.96
  72   0.5697     86.380  0.0856    97.170  394.54
  73   0.5544     87.150  0.0841    97.242  399.96
  74   0.5848     85.440  0.0834    97.282  405.41
  75   0.6198     86.270  0.0807    97.320  410.83
  76   0.6168     85.060  0.0798    97.292  416.27
  77   0.6062     86.940  0.0783    97.378  421.72
  78   0.5812     86.530  0.0788    97.304  427.17
  79   0.5877     86.400  0.0764    97.532  432.73
  80   0.6337     85.990  0.0758    97.500  438.18
  81   0.5970     87.180  0.0760    97.486  443.63
  82   0.5804     87.030  0.0715    97.638  449.07
  83   0.5870     86.480  0.0717    97.604  454.55
  84   0.5925     85.950  0.0705    97.694  459.98
  85   0.5641     86.960  0.0716    97.698  465.41
  86   0.5727     86.980  0.0746    97.602  470.94
  87   0.5593     87.090  0.0725    97.596  476.40
  88   0.5928     86.100  0.0681    97.754  481.83
  89   0.5632     86.880  0.0705    97.660  487.29
  90   0.5721     87.380  0.0662    97.786  492.74
