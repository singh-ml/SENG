Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1138     17.370  2.7951    11.650  7.13
   2   1.9385     26.660  1.9219    20.712  12.60
   3   1.5676     36.880  1.6660    31.750  18.02
   4   1.3320     46.790  1.4422    42.272  23.45
   5   1.1465     56.820  1.1688    55.904  28.88
   6   1.1371     64.490  0.9752    65.734  34.29
   7   0.9852     65.570  0.9293    69.124  39.70
   8   0.7625     74.650  0.7753    73.528  45.11
   9   6.1217     58.820  0.7225    75.886  50.66
  10   0.6692     78.510  0.7319    76.262  56.07
  11   2.7955     68.840  0.6315    79.650  61.48
  12   0.6039     80.190  0.7570    76.170  66.96
  13   0.9426     71.270  0.5744    81.408  72.36
  14   0.6610     79.370  0.5460    82.234  77.78
  15   0.6114     79.860  0.5038    83.776  83.21
  16   0.6325     80.430  0.6151    81.818  88.64
  17   0.5581     82.880  0.4579    85.156  94.21
  18   0.8452     75.410  0.4525    85.612  99.65
  19   0.6591     79.830  0.5073    84.264  105.07
  20   0.5015     84.560  0.4642    85.330  110.52
  21   0.5615     83.050  0.3908    87.332  115.94
  22   0.5793     82.370  0.3823    87.652  121.38
  23   0.4917     84.860  0.5839    83.206  126.83
  24   0.4598     86.030  0.3718    87.996  132.38
  25   0.4676     85.110  0.3401    89.048  137.82
  26   26.9911     51.960  0.4049    87.942  143.23
  27   0.6004     80.010  0.5934    82.324  148.65
  28   0.4452     85.960  0.3679    87.970  154.08
  29   0.4286     86.630  0.3168    89.636  159.51
  30   0.5451     83.830  0.3084    90.074  164.93
  31   0.4376     86.350  0.3059    90.210  170.47
  32   0.4342     86.620  0.3623    89.156  175.92
  33   0.4219     86.990  0.2751    91.206  181.33
  34   0.4036     87.590  0.2916    90.706  186.76
  35   0.4893     85.830  0.2604    91.614  192.20
  36   0.5746     83.630  0.3064    90.520  197.64
  37   0.4439     87.170  0.2579    91.592  203.08
  38   0.5337     85.640  0.2322    92.504  208.62
  39   0.4076     88.020  0.2391    92.286  214.03
  40   0.4361     87.330  0.2257    92.476  219.46
  41   0.4627     88.190  0.2220    92.712  224.87
  42   0.4088     88.330  0.2180    92.926  230.29
  43   0.5379     86.500  0.2172    93.214  235.74
  44   0.4726     86.660  0.2183    93.058  241.18
  45   0.3801     88.510  0.1972    93.662  246.62
  46   0.4178     87.940  0.1913    93.780  252.06
  47   0.5916     84.730  0.1870    94.070  257.48
  48   3.2169     82.730  0.1947    93.904  262.93
  49   0.4741     87.160  0.1829    94.162  268.35
  50   0.4436     88.010  0.1703    94.502  273.79
  51   0.4233     88.320  0.1772    94.454  279.33
  52   0.4903     86.860  0.1712    94.554  284.76
  53   0.4510     88.000  0.1652    94.756  290.20
  54   0.4138     88.200  0.1567    95.100  295.64
  55   0.4358     88.690  0.1581    95.004  301.09
  56   0.4019     89.660  0.1540    95.124  306.55
  57   0.4698     87.790  0.1508    95.218  312.02
  58   0.4109     89.130  0.1454    95.428  317.58
  59   0.4097     89.300  0.1394    95.602  323.00
  60   0.4322     89.090  0.1401    95.580  328.48
  61   0.3911     89.590  0.1403    95.568  333.94
  62   0.4888     87.160  0.1382    95.570  339.37
  63   0.4221     89.400  0.1405    95.500  344.83
  64   0.4217     88.990  0.1287    95.910  350.26
  65   0.4461     89.120  0.1271    95.954  355.70
  66   0.4713     88.290  0.1248    96.088  361.31
  67   0.3973     89.490  0.1242    96.084  366.77
  68   0.4132     89.150  0.1216    96.160  372.20
  69   0.4613     89.200  0.1205    96.244  377.66
  70   0.4550     89.450  0.1166    96.314  383.08
  71   0.4281     89.820  0.1181    96.282  388.53
  72   0.4737     88.910  0.1184    96.304  394.09
  73   0.4188     89.530  0.1133    96.432  399.53
  74   0.4399     89.130  0.1130    96.362  404.94
  75   0.4604     88.400  0.1130    96.490  410.41
  76   0.4765     88.810  0.1106    96.558  415.84
  77   0.5021     88.000  0.1082    96.694  421.27
  78   0.4154     89.500  0.1094    96.672  426.68
  79   0.4341     89.650  0.1072    96.606  432.24
  80   0.4262     89.920  0.1015    96.874  437.69
  81   0.3829     90.670  0.1019    96.748  443.11
  82   0.4190     90.190  0.1080    96.744  448.53
  83   0.4224     89.380  0.1050    96.762  453.97
  84   0.4789     88.790  0.0930    97.142  459.42
  85   0.4711     89.670  0.0988    96.960  464.87
  86   0.4140     89.930  0.0995    96.932  470.40
  87   0.4471     88.700  0.1007    96.964  475.87
  88   0.4734     88.730  0.0946    97.116  481.28
  89   0.4319     88.980  0.0979    96.976  486.72
  90   0.4283     89.520  0.0942    97.106  492.18
