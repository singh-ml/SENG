Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8094     27.880  2.1786    19.848  6.98
   2   1.5840     37.770  1.7071    32.014  12.38
   3   1.3483     48.490  1.4911    42.244  17.79
   4   1.2601     54.020  1.3281    50.248  23.20
   5   1.0742     61.070  1.1816    57.064  28.75
   6   0.9527     66.040  1.0408    63.120  34.14
   7   0.8395     70.970  0.9300    67.218  39.53
   8   0.7993     71.760  0.8514    70.262  44.92
   9   0.7564     73.460  0.7879    72.892  50.32
  10   0.7112     75.000  0.7229    75.148  55.75
  11   0.7104     75.090  0.6841    76.696  61.30
  12   0.6298     78.190  0.6379    78.426  66.72
  13   0.6253     78.210  0.5984    79.698  72.08
  14   0.6032     79.250  0.5685    80.756  77.49
  15   0.5852     80.030  0.5407    81.852  82.92
  16   0.5869     79.850  0.5132    82.596  88.32
  17   0.5578     81.180  0.5006    83.044  93.71
  18   0.5360     82.420  0.4626    84.592  99.25
  19   0.5163     82.740  0.4424    85.366  104.63
  20   0.5479     81.280  0.4229    85.988  110.04
  21   0.5142     82.850  0.4076    86.368  115.42
  22   0.5001     82.960  0.3774    87.302  120.81
  23   0.5278     82.550  0.3717    87.712  126.18
  24   0.5148     82.740  0.3512    88.324  131.58
  25   0.4845     84.070  0.3429    88.548  137.12
  26   0.5149     82.540  0.3325    88.848  142.54
  27   0.4936     83.970  0.3156    89.624  147.96
  28   0.4859     83.960  0.3036    89.882  153.36
  29   0.4870     83.700  0.2944    90.220  158.77
  30   0.4800     84.460  0.2810    90.618  164.15
  31   0.5182     83.700  0.2758    90.742  169.61
  32   0.4950     84.560  0.2689    91.010  174.99
  33   0.4815     84.560  0.2624    91.298  180.41
  34   0.4907     84.910  0.2415    91.916  185.83
  35   0.4864     85.040  0.2289    92.436  191.23
  36   0.5152     84.660  0.2269    92.482  196.66
  37   0.4914     84.620  0.2167    92.734  202.08
  38   0.5216     84.740  0.2151    92.736  207.49
  39   0.4860     85.960  0.2025    93.284  212.99
  40   0.5394     84.750  0.1970    93.354  218.39
  41   0.4744     85.830  0.1890    93.612  223.80
  42   0.4851     85.730  0.1878    93.782  229.19
  43   0.4820     86.070  0.1769    94.094  234.61
  44   0.5247     85.070  0.1776    94.106  240.02
  45   0.4876     86.140  0.1587    94.624  245.56
  46   0.4838     86.420  0.1615    94.670  250.96
  47   0.4979     86.050  0.1586    94.630  256.39
  48   0.4843     86.420  0.1494    95.030  261.83
  49   0.4940     86.510  0.1500    95.024  267.25
  50   0.5462     86.000  0.1442    95.200  272.64
  51   0.5436     86.430  0.1353    95.456  278.03
  52   0.5080     85.690  0.1391    95.382  283.42
  53   0.5241     86.240  0.1391    95.408  288.84
  54   0.5374     85.970  0.1351    95.528  294.27
  55   0.5135     86.660  0.1254    95.814  299.66
  56   0.5314     86.010  0.1225    95.814  305.07
  57   0.5298     86.850  0.1187    95.986  310.45
  58   0.5486     86.340  0.1127    96.188  315.85
  59   0.5461     86.240  0.1193    95.902  321.37
  60   0.5309     86.260  0.1156    96.100  326.82
  61   0.5255     86.520  0.1049    96.472  332.21
  62   0.5274     86.510  0.1043    96.478  337.60
  63   0.5655     86.560  0.1049    96.434  343.00
  64   0.5510     86.620  0.1037    96.538  348.39
  65   0.5414     86.370  0.1001    96.728  353.84
  66   0.5208     87.190  0.0972    96.778  359.36
  67   0.5651     86.480  0.0987    96.734  364.74
  68   0.5533     86.650  0.0909    96.914  370.16
  69   0.5322     86.810  0.0947    96.934  375.56
  70   0.5450     86.850  0.0890    97.022  380.96
  71   0.5531     87.310  0.0849    97.172  386.38
  72   0.5433     86.830  0.0857    97.178  391.81
  73   0.5234     86.660  0.0833    97.172  397.35
  74   0.5577     86.960  0.0848    97.122  402.77
  75   0.5421     87.460  0.0819    97.280  408.21
  76   0.5422     86.720  0.0759    97.468  413.63
  77   0.5241     87.100  0.0831    97.220  419.06
  78   0.5976     86.310  0.0760    97.502  424.46
  79   0.5215     86.980  0.0878    97.092  429.90
  80   0.5761     86.940  0.0748    97.482  435.42
  81   0.5759     87.590  0.0694    97.674  440.86
  82   0.5279     87.890  0.0753    97.552  446.25
  83   0.5563     87.540  0.0644    97.814  451.67
  84   0.5677     87.410  0.0704    97.764  457.08
  85   0.6065     86.860  0.0669    97.772  462.50
