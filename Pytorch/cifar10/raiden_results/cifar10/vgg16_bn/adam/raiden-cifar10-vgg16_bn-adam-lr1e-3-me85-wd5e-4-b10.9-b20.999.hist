Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2920     11.670  3.3537    10.926  6.98
   2   2.0870     17.090  2.2375    13.280  12.39
   3   1.8991     22.040  1.9774    18.834  17.88
   4   1.8352     24.700  1.9084    20.582  23.29
   5   1.7167     31.310  1.8151    24.360  28.71
   6   1.8758     31.150  1.7256    30.532  34.14
   7   3.9081     30.610  1.6192    36.562  39.56
   8   1.4459     43.800  1.5006    43.324  45.01
   9   1.2307     54.840  1.3420    51.788  50.45
  10   1.6923     45.570  1.1943    57.888  56.01
  11   0.9563     66.990  1.0999    61.180  61.44
  12   1.3305     55.390  1.1016    63.364  66.90
  13   2.4164     20.230  1.2233    59.466  72.34
  14   1.2884     50.730  1.6199    38.468  77.79
  15   1.0377     62.410  1.1911    58.206  83.24
  16   0.9509     66.680  0.9663    66.260  88.68
  17   1.1720     63.890  0.8641    70.702  94.29
  18   0.8428     71.940  0.7955    73.360  99.72
  19   403.7263     19.230  0.7901    74.402  105.14
  20   1.4193     52.800  1.2994    57.736  110.60
  21   0.7451     74.460  0.9179    69.622  116.04
  22   0.7457     74.970  0.7405    75.122  121.49
  23   0.6478     78.490  0.6723    78.080  126.92
  24   0.7209     77.250  0.6337    79.430  132.49
  25   0.6156     79.470  0.6214    80.246  137.94
  26   0.9380     69.950  0.6107    80.614  143.38
  27   0.5840     81.000  0.5762    81.552  148.83
  28   0.6357     80.850  0.5454    82.768  154.26
  29   0.7267     78.210  0.7051    78.744  159.72
  30   0.5575     82.120  0.5625    82.168  165.29
  31   0.5156     83.550  0.5060    83.936  170.71
  32   0.6041     81.200  0.4706    85.248  176.14
  33   0.5833     81.300  0.4569    85.644  181.58
  34   0.5383     83.000  0.4406    86.150  187.02
  35   1.1828     64.840  0.6016    81.278  192.46
  36   0.5626     82.170  0.5696    81.806  197.94
  37   0.5334     83.360  0.4571    85.624  203.37
  38   0.5264     83.610  0.4226    86.610  208.93
  39   0.5111     84.500  0.4021    87.352  214.38
  40   0.5912     82.870  0.4001    87.584  219.84
  41   0.5687     82.960  0.3909    87.910  225.29
  42   0.5245     84.250  0.3819    88.096  230.74
  43   0.5249     83.530  0.3783    88.404  236.19
  44   0.5392     83.910  0.3563    88.894  241.75
  45   0.5866     82.480  0.3561    88.930  247.20
  46   0.5162     85.240  0.3472    89.216  252.67
  47   0.6060     83.450  0.3464    89.228  258.11
  48   0.4674     85.490  0.3349    89.732  263.55
  49   0.5243     84.200  0.3393    89.530  268.98
  50   0.5608     83.940  0.3310    89.746  274.43
  51   0.4397     86.060  0.3158    90.044  280.01
  52   0.4741     85.920  0.3134    90.312  285.45
  53   0.5729     84.000  0.3200    90.216  290.92
  54   0.5391     85.380  0.3117    90.428  296.41
  55   0.4615     86.550  0.3115    90.510  301.86
  56   0.4658     85.690  0.3048    90.662  307.36
  57   0.4831     85.820  0.2978    90.884  312.81
  58   0.4675     86.180  0.2934    90.920  318.27
  59   0.4734     86.870  0.2887    91.146  323.86
  60   0.4131     87.230  0.2886    91.206  329.36
  61   0.4169     87.220  0.2887    91.174  334.84
  62   0.4367     87.230  0.2756    91.560  340.31
  63   0.4628     86.350  0.2781    91.466  345.78
  64   0.4235     87.470  0.2748    91.696  351.26
  65   0.4778     86.470  0.2755    91.596  356.88
  66   0.4721     85.790  0.2659    91.850  362.36
  67   0.4555     86.930  0.2683    91.674  367.81
  68   0.5264     85.500  0.2645    91.952  373.30
  69   0.4628     86.990  0.2593    92.230  378.76
  70   0.5499     84.920  0.2595    92.160  384.22
  71   0.4712     86.570  0.2540    92.322  389.69
  72   0.5316     85.790  0.2526    92.224  395.17
  73   0.4498     87.500  0.2525    92.330  400.75
  74   0.5416     86.480  0.2477    92.348  406.20
  75   0.4868     86.770  0.2472    92.450  411.67
  76   0.5095     86.880  0.2413    92.520  417.13
  77   0.4403     88.340  0.2489    92.504  422.60
  78   0.4158     88.340  0.2449    92.438  428.05
  79   0.4573     87.530  0.2426    92.664  433.61
  80   0.4552     87.620  0.2356    92.988  439.06
  81   0.4229     87.870  0.2337    92.758  444.52
  82   0.4984     87.070  0.2336    92.980  449.95
  83   0.4407     87.680  0.2348    92.856  455.38
  84   0.4233     88.230  0.2293    93.046  460.85
  85   0.4163     88.170  0.2273    93.164  466.31
