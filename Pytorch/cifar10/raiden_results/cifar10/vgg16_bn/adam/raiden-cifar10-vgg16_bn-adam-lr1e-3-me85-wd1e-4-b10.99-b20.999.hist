Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2825     11.990  3.9669    10.422  7.01
   2   2.2315     14.330  2.2815    11.842  12.42
   3   2.1781     15.350  2.2485    13.004  17.85
   4   2.1557     16.700  2.2006    14.610  23.26
   5   2.0905     18.070  2.1632    16.180  28.71
   6   2.0168     17.690  2.1194    17.336  34.12
   7   1.8894     22.110  2.0023    19.528  39.66
   8   1.8419     24.850  1.9140    22.282  45.06
   9   1.7902     26.200  1.8759    23.436  50.48
  10   1.7783     28.330  1.8250    25.808  55.88
  11   1.7743     29.830  1.7827    28.062  61.29
  12   1.6461     34.290  1.7315    31.424  66.71
  13   1.5852     38.600  1.6444    35.718  72.14
  14   1.4882     42.560  1.5470    40.072  77.58
  15   1.3717     47.040  1.4714    44.308  82.99
  16   1.3566     49.790  1.4112    47.408  88.40
  17   1.2286     54.410  1.3333    51.386  93.82
  18   1.2864     55.430  1.2478    55.320  99.26
  19   1.1487     57.650  1.1476    59.486  104.71
  20   1.0277     65.080  1.0772    62.358  110.15
  21   1.0743     62.240  1.0563    63.696  115.73
  22   1.1703     59.000  1.1771    59.504  121.14
  23   0.9911     64.970  1.0677    63.118  126.60
  24   0.8476     70.000  0.9254    68.144  132.01
  25   0.8126     72.730  0.8486    70.912  137.46
  26   0.7545     73.910  0.8065    72.498  142.87
  27   0.7420     74.760  0.7377    74.850  148.29
  28   0.6969     76.400  0.6996    76.598  153.87
  29   0.7104     76.730  0.6655    77.372  159.28
  30   0.6259     79.190  0.6210    79.432  164.72
  31   0.8898     70.600  0.7002    76.842  170.13
  32   0.6778     78.130  0.7190    76.354  175.57
  33   0.6069     80.330  0.6200    79.878  180.98
  34   0.6090     80.110  0.5622    81.680  186.55
  35   0.5829     81.690  0.5256    82.744  191.96
  36   0.6725     79.360  0.5129    83.592  197.39
  37   0.6401     81.500  0.5230    83.012  202.81
  38   0.8188     72.860  0.7541    78.382  208.22
  39   0.7494     75.790  0.8518    74.078  213.65
  40   0.8386     73.360  0.7881    76.394  219.08
  41   0.7236     76.260  0.7459    77.478  224.62
  42   0.6777     79.350  0.7102    77.478  230.05
  43   0.6767     78.020  0.6571    79.918  235.50
  44   0.6754     78.280  0.7022    78.262  240.95
  45   0.7410     75.660  0.8494    73.632  246.37
  46   0.6835     77.570  0.8136    76.636  251.83
  47   0.6517     80.850  0.7002    78.764  257.23
  48   0.5901     81.540  0.5634    82.022  262.79
  49   2.8065     57.670  0.9614    75.950  268.24
  50   0.8664     71.220  1.1972    65.798  273.65
  51   0.6998     76.660  0.7858    74.480  279.11
  52   0.7116     79.570  0.6788    78.276  284.53
  53   0.6149     80.080  0.6072    80.604  289.96
  54   0.7185     77.550  0.5725    81.708  295.41
  55   0.9038     72.300  1.0098    71.562  300.92
  56   0.6397     78.910  0.7303    77.046  306.33
  57   0.5628     81.220  0.5778    81.088  311.74
  58   0.5346     82.130  0.5188    83.390  317.17
  59   0.5952     80.540  0.5523    83.252  322.61
  60   0.5568     82.200  0.5787    82.290  328.04
  61   0.4991     83.820  0.4857    84.228  333.45
  62   0.4915     84.100  0.4430    85.736  338.88
  63   0.4746     84.740  0.4127    86.560  344.29
  64   0.4608     85.520  0.3855    87.344  349.69
  65   0.4525     85.820  0.3651    88.270  355.13
  66   0.4523     85.880  0.3591    88.446  360.54
  67   0.4622     85.650  0.3490    88.654  365.96
  68   0.4591     85.810  0.3376    89.032  371.39
  69   0.4558     85.680  0.3177    89.708  376.97
  70   0.4801     85.790  0.3195    89.748  382.41
  71   0.4969     84.810  0.3398    89.046  387.83
  72   0.8505     76.640  0.5033    85.154  393.25
  73   0.6623     79.010  0.6472    81.838  398.66
  74   1.3539     67.900  0.8166    78.516  404.08
  75   0.9240     71.980  0.9478    72.204  409.50
  76   0.6422     80.050  0.7346    76.960  415.06
  77   0.5945     80.560  0.5681    81.876  420.49
  78   1.4803     64.070  0.7802    77.954  425.93
  79   0.6858     77.790  0.8684    72.280  431.36
  80   0.5521     82.110  0.5665    81.610  436.81
  81   0.4864     83.900  0.4633    84.856  442.21
  82   0.4691     84.670  0.4197    86.234  447.63
  83   0.4537     85.450  0.3837    87.564  453.19
  84   0.4406     85.550  0.3563    88.432  458.66
  85   0.4343     85.980  0.3341    89.114  464.06
