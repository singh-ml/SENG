Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3502     13.350  3.3009    11.266  7.05
   2   2.1058     18.700  2.2577    13.190  12.43
   3   1.9635     17.430  2.0723    17.122  17.98
   4   1.9006     18.700  1.9642    18.326  23.38
   5   1.8917     22.810  1.9004    19.938  28.78
   6   1.7681     32.510  1.8629    23.174  34.17
   7   1.6172     35.370  1.7685    29.176  39.56
   8   1.5848     36.710  1.6657    33.760  44.99
   9   1.5668     42.480  1.5627    38.214  50.39
  10   4.2151     40.310  1.4376    44.774  55.93
  11   1.4079     46.430  1.3294    49.520  61.34
  12   1.3966     48.860  1.5340    45.514  66.73
  13   1.3194     49.820  1.3113    52.174  72.11
  14   1.1435     58.380  1.4021    50.990  77.53
  15   1.2300     55.670  1.3081    54.172  82.95
  16   1.0880     62.040  1.1436    60.530  88.36
  17   1.4521     50.450  1.4395    49.164  93.91
  18   1.0459     64.020  1.1358    59.316  99.32
  19   1.0481     62.600  1.0808    64.056  104.73
  20   3.8835     48.460  1.1244    65.342  110.16
  21   1.3185     51.510  1.7340    44.222  115.59
  22   1.4306     65.310  1.1444    59.706  120.98
  23   1.2501     57.120  1.3873    57.636  126.53
  24   0.9901     66.380  1.2418    58.794  131.97
  25   1.0618     67.850  1.0911    65.530  137.38
  26   0.8997     69.440  1.1792    64.516  142.78
  27   0.8411     71.950  0.8506    71.076  148.22
  28   0.7840     74.130  0.7814    73.644  153.64
  29   0.6997     76.430  0.7281    75.444  159.05
  30   0.7021     76.510  0.7072    76.546  164.61
  31   0.6980     77.420  0.6696    77.796  170.02
  32   0.6382     79.610  0.6358    79.038  175.45
  33   0.6395     79.070  0.6109    79.986  180.86
  34   1.5127     46.110  1.4467    61.936  186.29
  35   1.2183     58.360  1.8078    47.096  191.70
  36   0.9116     69.380  1.0203    65.750  197.16
  37   0.7946     75.140  0.8346    72.266  202.57
  38   0.7490     75.430  0.9286    70.010  208.09
  39   0.6753     78.080  0.7138    76.536  213.52
  40   0.6347     79.540  0.6482    78.780  218.95
  41   0.6368     79.370  0.6233    79.582  224.36
  42   0.5893     80.780  0.5794    81.248  229.78
  43   0.5926     80.670  0.5576    81.812  235.20
  44   0.6304     79.710  0.5903    81.826  240.62
  45   0.5787     81.490  0.5368    82.620  246.15
  46   0.5405     82.350  0.5025    83.872  251.57
  47   0.5337     82.570  0.4924    84.192  257.01
  48   0.6437     78.460  0.5905    81.600  262.44
  49   0.5643     81.770  0.6664    79.044  267.87
  50   0.5743     81.300  0.4904    84.180  273.29
  51   0.5193     83.610  0.4482    85.662  278.86
  52   0.5056     84.110  0.4334    86.018  284.30
  53   0.4785     84.760  0.4164    86.532  289.70
  54   0.5248     83.770  0.4016    87.044  295.13
  55   0.4916     84.380  0.3879    87.524  300.54
  56   0.5632     83.140  0.4207    86.686  305.99
  57   0.4470     85.880  0.3839    87.860  311.40
  58   0.9648     81.140  0.7788    78.234  316.93
  59   2.1993     75.100  0.4790    84.992  322.35
  60   0.4884     84.660  0.4778    84.878  327.79
  61   0.4812     84.630  0.3793    87.952  333.20
  62   0.4509     85.910  0.3568    88.790  338.60
  63   0.5145     84.590  0.3379    89.236  344.04
  64   0.4479     85.920  0.3243    89.792  349.45
  65   0.4370     86.530  0.3198    89.810  355.02
  66   0.4548     85.640  0.3043    90.500  360.44
  67   0.4413     86.520  0.3057    90.340  365.87
  68   0.4544     86.570  0.2890    90.792  371.29
  69   0.4951     86.030  0.2857    91.040  376.73
  70   0.4530     86.570  0.3228    89.942  382.14
  71   0.6049     80.930  0.8511    75.042  387.57
  72   0.4720     85.410  0.4145    86.780  392.99
  73   0.5099     85.330  0.3284    89.448  398.55
  74   0.4510     86.820  0.2900    90.760  403.97
  75   0.4455     86.600  0.2713    91.484  409.42
  76   0.4559     86.580  0.2561    91.948  414.84
  77   0.4375     86.820  0.2551    91.952  420.29
  78   0.4059     88.180  0.2493    92.140  425.71
  79   0.4582     87.270  0.2380    92.540  431.16
  80   0.4086     87.970  0.2361    92.638  436.59
  81   0.5378     85.480  0.2308    92.568  442.05
  82   0.4483     87.360  0.2202    93.102  447.48
  83   0.4459     86.940  0.2227    93.002  452.90
  84   0.5227     85.640  0.2192    93.056  458.34
  85   0.4733     87.100  0.2171    93.226  463.82
