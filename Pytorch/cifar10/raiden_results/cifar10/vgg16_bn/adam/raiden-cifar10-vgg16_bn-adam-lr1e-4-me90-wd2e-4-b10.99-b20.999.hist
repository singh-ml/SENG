Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9270     22.290  2.2713    15.830  7.15
   2   1.7498     28.240  1.8722    24.054  12.57
   3   1.5217     39.160  1.6828    32.122  17.96
   4   1.3570     48.840  1.4977    42.368  23.37
   5   1.2426     52.710  1.3422    49.842  28.78
   6   1.1057     58.980  1.2078    56.174  34.30
   7   1.0079     64.040  1.0681    62.212  39.72
   8   0.9580     67.260  0.9596    66.304  45.09
   9   0.8289     71.350  0.8692    69.922  50.49
  10   0.7772     73.020  0.7948    72.574  55.91
  11   0.7336     74.320  0.7362    75.006  61.28
  12   0.6777     76.990  0.6846    76.876  66.69
  13   0.6759     76.720  0.6402    78.536  72.25
  14   0.6572     77.840  0.6034    79.648  77.65
  15   0.6117     79.140  0.5702    80.912  83.02
  16   0.6029     79.870  0.5405    81.912  88.41
  17   0.5916     80.000  0.5118    82.836  93.81
  18   0.5807     80.310  0.4804    84.118  99.21
  19   0.5468     81.150  0.4703    84.350  104.72
  20   0.5305     82.070  0.4410    85.328  110.12
  21   0.5355     82.160  0.4218    86.056  115.52
  22   0.5348     82.550  0.4052    86.504  120.94
  23   0.4970     83.570  0.3921    87.072  126.34
  24   0.5014     83.670  0.3750    87.448  131.76
  25   0.5170     83.490  0.3596    88.048  137.15
  26   0.5060     83.230  0.3437    88.590  142.53
  27   0.5073     82.860  0.3274    89.044  147.92
  28   0.5347     83.220  0.3118    89.644  153.33
  29   0.5197     83.520  0.3087    89.652  158.71
  30   0.4841     84.620  0.2926    90.366  164.10
  31   0.4876     84.410  0.2794    90.570  169.51
  32   0.4997     84.690  0.2751    90.676  174.93
  33   0.5001     84.480  0.2609    91.290  180.46
  34   0.4696     85.360  0.2611    91.394  185.89
  35   0.4889     85.180  0.2358    92.018  191.28
  36   0.4642     85.620  0.2317    92.358  196.69
  37   0.4844     85.580  0.2264    92.542  202.14
  38   0.4841     85.790  0.2179    92.746  207.55
  39   0.4912     85.100  0.2094    93.134  212.99
  40   0.4847     85.860  0.1968    93.444  218.52
  41   0.5483     83.930  0.1954    93.368  223.94
  42   0.4982     85.540  0.1875    93.752  229.33
  43   0.5056     85.000  0.1914    93.668  234.74
  44   0.4969     85.450  0.1813    93.976  240.14
  45   0.4843     85.580  0.1721    94.144  245.52
  46   0.5021     85.570  0.1704    94.338  250.94
  47   0.5079     85.800  0.1593    94.754  256.45
  48   0.4908     86.290  0.1564    94.776  261.86
  49   0.5064     85.960  0.1527    94.898  267.24
  50   0.4983     85.950  0.1463    95.194  272.64
  51   0.5237     85.690  0.1543    94.872  278.03
  52   0.5225     86.020  0.1597    94.774  283.43
  53   0.5407     86.100  0.1372    95.394  288.81
  54   0.5169     86.500  0.1349    95.540  294.34
  55   0.5229     86.470  0.1255    95.776  299.74
  56   0.5728     85.430  0.1221    95.770  305.14
  57   0.5069     86.850  0.1187    95.974  310.53
  58   0.5441     86.820  0.1116    96.176  315.94
  59   0.4982     86.640  0.1133    96.180  321.39
  60   0.5222     86.660  0.1109    96.368  326.77
  61   0.5392     86.450  0.1057    96.542  332.28
  62   0.4885     86.970  0.1048    96.516  337.68
  63   0.5602     86.460  0.1046    96.382  343.09
  64   0.5761     86.720  0.1065    96.530  348.50
  65   0.5493     86.870  0.1096    96.408  353.89
  66   0.5285     86.710  0.1143    96.250  359.31
  67   0.5780     86.670  0.1021    96.614  364.86
  68   0.5596     86.560  0.0935    96.846  370.27
  69   0.5434     86.970  0.0899    97.058  375.66
  70   0.5245     87.250  0.0892    97.010  381.07
  71   0.5460     87.010  0.0882    97.180  386.49
  72   0.5495     86.990  0.0892    97.000  391.89
  73   0.5394     87.040  0.0802    97.310  397.31
  74   0.5762     86.660  0.0824    97.316  402.85
  75   0.5506     87.020  0.0807    97.354  408.27
  76   0.5796     86.400  0.0765    97.472  413.65
  77   0.6085     86.460  0.0792    97.364  419.07
  78   0.5346     87.220  0.0837    97.220  424.45
  79   0.5845     87.240  0.0771    97.386  429.86
  80   0.5897     87.140  0.0706    97.638  435.27
  81   0.5962     87.100  0.0739    97.560  440.72
  82   0.5978     86.770  0.0703    97.590  446.12
  83   0.5578     86.920  0.0698    97.658  451.50
  84   0.5787     86.680  0.0728    97.590  456.91
  85   0.6416     87.100  0.0677    97.728  462.33
  86   0.5591     87.560  0.0706    97.710  467.72
  87   0.5505     87.900  0.0647    97.830  473.13
  88   0.5098     88.190  0.0666    97.752  478.68
  89   0.5761     87.790  0.0608    97.956  484.08
  90   0.5352     87.410  0.0708    97.594  489.50
