Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2031     16.260  2.5043    12.688  7.06
   2   2.1297     15.530  2.1698    15.488  12.46
   3   1.8515     22.230  1.9956    20.376  18.03
   4   1.7520     28.960  1.8358    24.794  23.46
   5   1.6098     36.190  1.7416    29.694  28.86
   6   1.4991     41.390  1.6043    37.150  34.31
   7   1.3966     46.260  1.4756    43.362  39.71
   8   1.2413     53.640  1.3501    49.614  45.11
   9   1.1124     58.950  1.2191    54.966  50.51
  10   1.0029     63.660  1.0919    60.500  55.95
  11   0.8857     68.680  0.9759    65.552  61.52
  12   0.8454     71.490  0.8847    69.444  66.95
  13   0.7797     73.380  0.8121    71.864  72.41
  14   0.7523     74.630  0.7502    74.874  77.84
  15   0.7156     76.440  0.7033    76.588  83.26
  16   0.6381     78.130  0.6554    78.278  88.68
  17   0.6257     78.700  0.6039    80.060  94.13
  18   0.6026     80.110  0.5695    81.214  99.54
  19   0.5833     80.650  0.5564    81.872  104.96
  20   0.5813     81.470  0.5202    83.134  110.37
  21   0.5391     82.340  0.4887    84.112  115.80
  22   0.5353     82.890  0.4595    85.040  121.22
  23   0.5394     82.500  0.4390    85.844  126.64
  24   0.5415     82.710  0.4198    86.312  132.10
  25   0.5160     83.930  0.4030    86.998  137.65
  26   0.4845     84.180  0.3958    87.294  143.06
  27   0.4745     84.960  0.3705    88.016  148.50
  28   0.4748     84.840  0.3655    88.180  153.94
  29   0.5166     85.290  0.3601    88.518  159.38
  30   0.4962     84.420  0.3717    88.094  164.82
  31   0.4604     85.930  0.3388    88.920  170.24
  32   0.4681     85.680  0.3161    89.848  175.82
  33   0.4695     85.840  0.3100    89.980  181.23
  34   0.4937     85.140  0.3379    89.704  186.68
  35   0.4749     85.460  0.3269    89.546  192.11
  36   0.5127     84.460  0.3283    89.602  197.52
  37   0.4434     86.400  0.3053    90.120  202.96
  38   0.4387     86.680  0.2479    91.954  208.40
  39   0.4120     87.550  0.2340    92.386  213.93
  40   0.4299     87.230  0.2341    92.372  219.37
  41   0.3956     87.940  0.2183    93.006  224.80
  42   0.4006     87.800  0.2059    93.238  230.24
  43   0.4187     88.090  0.2008    93.404  235.68
  44   0.5168     87.150  0.2092    93.238  241.10
  45   0.4650     86.890  0.2245    92.804  246.51
  46   0.4865     86.760  0.2472    91.996  252.08
  47   0.5454     83.600  0.3683    89.330  257.51
  48   0.5767     81.800  0.6864    81.074  262.93
  49   0.4351     86.210  0.3868    87.352  268.38
  50   0.4315     87.150  0.2732    91.016  273.83
  51   0.4059     87.810  0.2340    92.328  279.26
  52   0.3899     88.430  0.1932    93.608  284.70
  53   0.4130     88.020  0.1801    94.122  290.26
  54   0.4223     87.790  0.1676    94.424  295.71
  55   0.4064     88.710  0.1551    94.818  301.15
  56   0.4488     88.140  0.1518    95.012  306.57
  57   0.4015     88.820  0.1449    95.156  312.03
  58   0.4251     88.290  0.1450    95.286  317.47
  59   0.4520     88.600  0.1405    95.440  323.00
  60   0.4497     88.410  0.1392    95.442  328.42
  61   0.4474     88.450  0.1334    95.576  333.84
  62   0.4519     88.740  0.1316    95.592  339.28
  63   0.4282     88.450  0.1374    95.662  344.71
  64   0.4511     87.350  0.1467    95.340  350.13
  65   0.4564     87.950  0.1444    95.324  355.55
  66   0.4170     88.890  0.1372    95.576  361.01
  67   0.4405     88.790  0.1227    96.028  366.55
  68   0.4432     88.730  0.1146    96.296  371.99
  69   0.4451     88.310  0.1250    95.922  377.42
  70   0.4526     88.520  0.1137    96.292  382.86
  71   0.4462     88.140  0.1093    96.460  388.28
  72   0.4733     88.280  0.1099    96.480  393.76
  73   0.4468     88.860  0.1075    96.466  399.20
  74   0.4499     88.870  0.1095    96.354  404.75
  75   0.4276     89.280  0.1090    96.472  410.16
  76   0.4559     88.720  0.1003    96.748  415.59
  77   0.4576     89.120  0.1027    96.576  421.02
  78   0.4420     89.070  0.0997    96.684  426.45
  79   0.4757     88.960  0.0972    96.858  431.87
  80   0.4848     88.650  0.1025    96.712  437.30
  81   0.4623     88.680  0.0995    96.760  442.87
  82   0.4726     88.810  0.0925    96.932  448.28
  83   0.4690     89.090  0.0892    97.054  453.71
  84   0.4311     89.560  0.0938    96.928  459.13
  85   0.4680     88.440  0.0882    97.170  464.56
  86   0.4239     88.890  0.0911    97.088  469.98
  87   0.4457     88.750  0.0863    97.204  475.40
  88   0.4660     89.290  0.0874    97.194  481.00
  89   0.4546     88.520  0.0908    97.066  486.42
  90   0.4635     89.040  0.0801    97.344  491.88
