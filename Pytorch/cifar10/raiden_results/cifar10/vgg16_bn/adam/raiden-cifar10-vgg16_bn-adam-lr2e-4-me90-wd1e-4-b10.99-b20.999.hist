Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2517     13.990  2.5166    11.654  7.09
   2   2.1137     17.230  2.2099    14.690  12.49
   3   1.9415     22.250  2.0929    17.456  17.92
   4   1.8177     25.510  1.9186    22.102  23.32
   5   1.6980     29.960  1.8083    26.252  28.73
   6   1.6546     38.020  1.6830    33.042  34.10
   7   1.4417     44.270  1.5502    40.060  39.67
   8   1.2849     51.970  1.3990    46.686  45.07
   9   1.1677     56.970  1.2880    52.206  50.45
  10   1.1728     58.550  1.1625    57.672  55.88
  11   1.0221     63.570  1.0490    61.950  61.27
  12   0.9579     67.610  0.9734    65.284  66.68
  13   0.9075     70.200  0.8876    69.160  72.08
  14   0.8469     72.430  0.8142    71.764  77.62
  15   0.7676     75.640  0.7599    74.256  83.01
  16   0.7386     76.590  0.6967    76.482  88.45
  17   0.6869     78.170  0.6577    78.312  93.86
  18   0.6338     79.310  0.6143    79.896  99.28
  19   0.6305     80.380  0.5761    81.274  104.67
  20   0.6164     80.260  0.5516    82.212  110.06
  21   0.5780     81.280  0.5256    82.830  115.64
  22   0.5599     81.770  0.4886    84.088  121.02
  23   0.5499     82.270  0.4713    84.838  126.43
  24   0.5416     82.360  0.4548    85.250  131.85
  25   0.5096     83.150  0.4287    86.180  137.24
  26   0.4755     84.840  0.4096    86.724  142.64
  27   0.4825     84.700  0.3928    87.354  148.18
  28   0.4638     85.200  0.3666    88.170  153.61
  29   0.4781     84.400  0.3605    88.180  159.02
  30   0.4576     85.360  0.3370    88.966  164.40
  31   0.4492     85.850  0.3199    89.608  169.81
  32   0.4376     85.880  0.3195    89.766  175.19
  33   0.4478     85.850  0.3162    89.818  180.63
  34   0.4366     86.560  0.3021    90.378  186.15
  35   0.5258     85.240  0.2839    90.848  191.56
  36   0.4915     85.100  0.2811    90.920  196.99
  37   0.4382     86.260  0.2668    91.376  202.40
  38   0.4405     86.430  0.2493    91.812  207.82
  39   0.4641     85.770  0.2485    92.014  213.23
  40   1.1263     84.270  0.2735    91.596  218.63
  41   0.5218     83.810  0.4093    88.102  224.18
  42   0.4388     86.380  0.3215    89.562  229.61
  43   0.4354     87.510  0.2479    92.114  235.00
  44   0.4082     87.620  0.2108    93.226  240.40
  45   0.4286     87.890  0.1902    93.728  245.82
  46   0.4149     87.660  0.1800    94.068  251.22
  47   0.4234     87.760  0.1792    94.210  256.62
  48   0.4221     87.880  0.1855    93.964  262.18
  49   0.4350     87.590  0.1729    94.452  267.58
  50   0.4358     87.280  0.1686    94.518  272.99
  51   0.4542     87.770  0.1700    94.462  278.40
  52   0.4422     87.890  0.1668    94.520  283.83
  53   0.4344     88.140  0.1665    94.520  289.22
  54   0.4524     87.870  0.1559    94.926  294.65
  55   0.4566     87.940  0.1475    95.202  300.18
  56   0.4560     87.520  0.1499    95.088  305.60
  57   0.4412     87.800  0.1474    95.234  311.03
  58   0.4962     87.550  0.1560    95.112  316.47
  59   0.5588     85.260  0.2832    91.538  321.88
  60   3.2240     69.060  0.6497    87.256  327.28
  61   0.5835     81.740  0.7182    78.582  332.82
  62   0.4673     85.280  0.3984    87.324  338.21
  63   0.4384     86.760  0.2765    91.092  343.65
  64   0.4341     87.390  0.2166    93.002  349.05
  65   0.4323     87.580  0.1849    94.060  354.44
  66   0.4350     88.120  0.1582    94.772  359.85
  67   0.4358     88.570  0.1461    95.266  365.25
  68   0.4518     87.890  0.1307    95.738  370.81
  69   0.4583     88.250  0.1276    95.854  376.23
  70   0.4699     88.390  0.1166    96.060  381.63
  71   0.4524     88.450  0.1124    96.404  387.07
  72   0.4299     88.500  0.1098    96.362  392.52
  73   0.4498     88.520  0.1025    96.720  397.93
  74   0.4799     88.780  0.0979    96.878  403.33
  75   0.4849     88.310  0.1039    96.580  408.89
  76   0.4561     88.870  0.0957    96.974  414.31
  77   0.4760     88.670  0.0937    96.962  419.70
  78   0.4431     89.230  0.0971    96.846  425.12
  79   0.4695     89.020  0.0904    97.102  430.53
  80   0.5104     89.100  0.0894    97.082  435.96
  81   0.4806     88.700  0.0883    97.154  441.35
  82   0.4541     88.700  0.0995    96.738  446.92
  83   0.4878     88.200  0.0956    96.868  452.34
  84   0.5242     87.760  0.0928    96.848  457.77
  85   0.5213     88.420  0.0843    97.126  463.16
  86   0.5087     88.500  0.0911    97.078  468.60
  87   0.4602     88.790  0.0857    97.290  474.03
  88   0.4849     89.100  0.0851    97.222  479.52
  89   0.4979     88.830  0.0849    97.186  484.94
  90   0.6013     86.280  0.1339    96.254  490.33
