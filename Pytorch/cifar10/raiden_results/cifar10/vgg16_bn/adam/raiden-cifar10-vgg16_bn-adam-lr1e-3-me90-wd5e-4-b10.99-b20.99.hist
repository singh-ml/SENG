Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2953     11.330  3.9203    10.586  7.12
   2   2.2748     11.750  2.3142    11.082  12.55
   3   2.2775     11.810  2.2995    11.402  18.00
   4   2.2863     11.820  2.3021    11.046  23.42
   5   2.2686     11.820  2.2909    11.318  29.02
   6   1.9023     21.510  2.0289    18.740  34.45
   7   1.7517     28.800  1.8663    24.540  39.89
   8   1.6167     33.060  1.6995    31.992  45.31
   9   1.4729     43.840  1.5438    39.524  50.73
  10   1.3619     51.220  1.4399    45.736  56.16
  11   1.1208     59.110  1.2438    54.880  61.58
  12   1.0150     63.810  1.1077    60.576  67.13
  13   0.9446     67.650  0.9934    64.728  72.57
  14   0.9082     68.040  0.9292    67.784  78.05
  15   0.8431     71.000  0.8670    70.476  83.46
  16   0.7767     74.470  0.8154    72.396  88.89
  17   0.8895     71.850  0.7887    73.672  94.32
  18   0.9716     68.490  0.8990    71.222  99.79
  19   0.7865     73.750  0.8877    70.992  105.35
  20   0.6921     77.220  0.7380    75.246  110.79
  21   0.6448     79.090  0.6577    78.400  116.22
  22   0.6472     79.400  0.6026    80.282  121.64
  23   0.6138     79.720  0.5685    81.488  127.08
  24   0.5501     81.950  0.5560    82.052  132.51
  25   0.5339     82.910  0.5123    83.344  137.94
  26   0.5345     82.670  0.4795    84.612  143.51
  27   0.5368     82.860  0.4563    85.246  148.98
  28   0.4992     84.120  0.4551    85.590  154.44
  29   0.5016     84.440  0.4455    85.784  159.90
  30   0.4937     84.260  0.4195    86.534  165.34
  31   0.4625     85.640  0.4048    87.112  170.81
  32   0.4791     84.800  0.3898    87.724  176.27
  33   0.4536     85.820  0.3688    88.350  181.72
  34   0.4790     85.400  0.3639    88.312  187.29
  35   0.4864     84.690  0.3516    88.870  192.76
  36   0.4161     87.250  0.3435    88.996  198.20
  37   0.4476     86.010  0.3387    89.140  203.67
  38   0.4268     86.590  0.3227    89.708  209.13
  39   0.4230     86.780  0.3178    89.924  214.56
  40   0.4297     86.270  0.3097    90.350  219.99
  41   0.4666     86.390  0.2968    90.594  225.56
  42   0.4460     86.490  0.2948    90.724  230.99
  43   0.4104     87.040  0.2919    90.696  236.42
  44   0.4469     86.140  0.2875    90.910  241.84
  45   0.4344     86.650  0.2953    90.672  247.33
  46   0.4277     87.110  0.2809    91.172  252.78
  47   0.4211     87.470  0.2765    91.220  258.24
  48   0.4432     87.440  0.2598    91.802  263.68
  49   0.4234     88.120  0.2576    91.984  269.11
  50   0.3982     88.360  0.2578    91.900  274.61
  51   0.4290     87.320  0.2560    91.930  280.05
  52   0.3802     88.380  0.2579    91.948  285.48
  53   0.4192     87.850  0.2585    91.840  290.93
  54   0.4226     87.820  0.2447    92.268  296.35
  55   0.3964     88.130  0.2419    92.406  301.78
  56   0.4131     88.160  0.2492    92.226  307.24
  57   0.4236     87.730  0.2455    92.380  312.69
  58   0.4436     86.890  0.2719    91.532  318.12
  59   0.4047     87.970  0.2445    92.342  323.56
  60   0.3957     88.560  0.2408    92.736  329.02
  61   0.4162     88.650  0.2320    92.956  334.47
  62   0.3854     88.570  0.2317    92.920  339.89
  63   0.4030     88.430  0.2283    92.892  345.33
  64   0.4162     88.440  0.2273    92.860  350.75
  65   0.3894     88.740  0.2195    92.978  356.18
  66   0.4175     88.390  0.2157    93.128  361.60
  67   0.3928     88.920  0.2225    93.168  367.03
  68   0.4071     88.680  0.2223    93.148  372.47
  69   0.4050     88.070  0.2151    93.354  377.93
  70   0.3827     88.620  0.2126    93.410  383.38
  71   0.3684     89.220  0.2150    93.360  388.82
  72   0.4017     88.640  0.2074    93.566  394.41
  73   0.3826     88.190  0.2131    93.362  399.86
  74   0.3730     88.900  0.2085    93.536  405.29
  75   0.3925     88.460  0.2016    93.758  410.74
  76   0.4115     88.980  0.2142    93.394  416.16
  77   0.3768     88.850  0.2040    93.612  421.58
  78   0.4286     88.280  0.2068    93.518  427.00
  79   0.4026     88.990  0.2049    93.722  432.56
  80   0.3935     88.730  0.1959    93.890  438.00
  81   0.4069     88.050  0.2005    93.856  443.45
  82   0.4122     88.650  0.1931    93.946  448.89
  83   0.3963     88.760  0.1910    94.046  454.34
  84   0.4071     88.540  0.2034    93.722  459.77
  85   0.3853     88.990  0.1939    93.946  465.21
  86   0.3903     88.930  0.1910    94.098  470.79
  87   0.4481     88.040  0.1942    94.120  476.24
  88   0.4026     89.040  0.1951    94.030  481.70
  89   0.4213     88.190  0.1972    93.850  487.13
  90   0.3795     89.160  0.1923    94.168  492.56
