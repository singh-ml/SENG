Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2892     10.950  3.5631    11.038  7.17
   2   2.2854     11.490  2.3034    11.234  12.58
   3   2.2807     11.560  2.2975    11.264  18.00
   4   2.2785     11.700  2.3053    11.466  23.43
   5   2.2646     12.580  2.2991    11.672  28.85
   6   2.2699     11.680  2.2884    11.838  34.38
   7   2.1139     17.330  2.2332    13.892  39.81
   8   1.9978     18.980  2.1571    15.880  45.21
   9   1.9047     21.170  2.0186    19.176  50.62
  10   1.8538     21.440  1.9418    20.238  56.02
  11   1.8484     24.100  1.9103    21.230  61.46
  12   1.8638     22.630  1.8764    22.680  66.89
  13   1.8170     27.710  1.8291    26.156  72.40
  14   1.7532     30.700  1.7784    28.684  77.83
  15   1.5519     38.420  1.6787    33.438  83.24
  16   1.4679     42.190  1.5722    37.572  88.66
  17   1.4189     45.680  1.4817    41.962  94.09
  18   1.2997     50.590  1.4092    46.528  99.53
  19   1.2257     55.030  1.2942    51.740  104.95
  20   1.0575     62.020  1.1595    57.610  110.51
  21   1.0056     63.680  1.0644    61.804  115.93
  22   1.0060     64.620  0.9781    65.582  121.34
  23   0.9095     67.700  0.9021    68.600  126.78
  24   0.8512     70.780  0.8385    70.770  132.20
  25   0.8005     73.170  0.7858    73.158  137.63
  26   0.7293     75.180  0.7269    75.676  143.03
  27   0.8035     75.250  0.6950    77.022  148.58
  28   0.6886     77.680  0.6641    78.266  154.02
  29   0.6561     78.580  0.6270    79.574  159.45
  30   0.6514     79.700  0.5886    80.964  164.90
  31   0.5928     80.940  0.5681    81.844  170.35
  32   0.6701     79.360  0.6045    80.870  175.78
  33   0.5987     80.970  0.5980    81.118  181.21
  34   0.5593     82.150  0.5110    83.620  186.75
  35   0.5210     83.580  0.4735    84.848  192.19
  36   0.5252     83.640  0.4504    85.694  197.62
  37   0.5157     84.180  0.4294    86.424  203.04
  38   0.5460     83.180  0.4113    86.920  208.49
  39   0.5123     83.840  0.4126    87.130  213.91
  40   4.5077     38.740  1.4524    70.880  219.40
  41   1.9233     47.910  1.8596    42.680  224.83
  42   1.6026     56.980  1.4849    50.974  230.26
  43   1.0044     64.360  1.1251    60.394  235.69
  44   2.5593     44.270  2.4021    47.964  241.13
  45   1.2570     55.440  1.5938    48.898  246.57
  46   1.0735     62.120  1.2262    57.888  251.98
  47   1.0850     66.480  1.0568    63.310  257.53
  48   1.0043     65.080  1.1286    65.002  262.97
  49   0.8630     69.750  0.9892    66.226  268.39
  50   0.7757     72.870  0.8576    71.018  273.81
  51   0.7225     75.910  0.7632    73.624  279.22
  52   0.6575     77.570  0.6874    76.670  284.62
  53   0.6094     79.330  0.6321    78.808  290.04
  54   0.6019     80.010  0.5893    80.560  295.58
  55   0.5640     81.280  0.5455    82.200  301.01
  56   0.5558     81.980  0.5211    82.934  306.43
  57   0.5292     82.560  0.4911    83.958  311.85
  58   0.5171     83.240  0.4677    84.838  317.26
  59   0.5074     84.040  0.4430    85.678  322.71
  60   0.5057     83.690  0.4250    86.022  328.17
  61   0.4972     84.220  0.4056    86.828  333.75
  62   0.4883     84.610  0.3918    87.370  339.16
  63   0.4519     85.540  0.3696    87.988  344.58
  64   0.4647     85.390  0.3505    88.628  350.03
  65   0.4620     85.430  0.3428    88.952  355.44
  66   0.4626     85.760  0.3374    89.502  360.86
  67   0.5068     84.070  0.4637    85.154  366.27
  68   3.7016     76.510  0.5461    83.750  371.78
  69   1.0684     63.960  1.1379    69.190  377.21
  70   0.7327     76.840  0.9437    71.030  382.64
  71   0.6058     80.110  0.6429    79.856  388.05
  72   0.5582     81.910  0.5969    81.144  393.47
  73   0.5208     83.450  0.5254    83.034  398.91
  74   0.4482     85.050  0.4323    85.976  404.34
  75   0.4465     85.520  0.3850    87.390  409.90
  76   0.4399     85.820  0.3785    88.062  415.32
  77   0.4341     85.740  0.3478    88.680  420.74
  78   0.4226     86.760  0.3184    89.514  426.16
  79   0.4236     87.110  0.3052    90.064  431.58
  80   0.4205     87.110  0.2940    90.448  437.02
  81   0.4205     86.710  0.2784    90.916  442.44
  82   0.4057     87.630  0.2692    91.194  447.99
  83   0.4253     86.970  0.2664    91.388  453.44
  84   0.4220     87.060  0.2632    91.444  458.87
  85   0.4279     87.430  0.2468    92.002  464.28
  86   0.4353     87.640  0.2388    92.268  469.74
  87   0.4079     87.820  0.2372    92.396  475.16
  88   0.3920     88.070  0.2300    92.678  480.59
  89   0.4297     87.770  0.2209    93.070  486.05
  90   0.4368     87.380  0.2365    92.698  491.47
