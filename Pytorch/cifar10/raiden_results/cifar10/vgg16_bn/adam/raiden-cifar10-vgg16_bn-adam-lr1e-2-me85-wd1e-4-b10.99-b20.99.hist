Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   53.3435     11.150  129.8060    10.152  7.23
   2   2.7704     10.070  21.4612    10.108  12.65
   3   2.3167     10.000  2.5647     9.914  18.08
   4   2.3481     10.000  2.3784     9.894  23.56
   5   2.3028     10.000  2.3783     9.950  29.12
   6   2.3049      9.460  2.4669    10.014  34.57
   7   2.3035     10.010  2.4395    10.028  40.01
   8   2.3728     10.010  2.6729     9.916  45.42
   9   4.8447     10.000  4.0812    10.174  50.86
  10   2.3322     10.020  3.2305    10.098  56.28
  11   2.3029      9.980  2.4107    10.180  61.70
  12   2.3024      9.930  2.3376    10.206  67.28
  13   2.2966     10.770  2.3286    10.266  72.71
  14   1.9513     19.070  2.0518    18.362  78.13
  15   1.8093     26.050  1.8810    24.332  83.55
  16   1.6928     35.680  1.7343    31.054  88.97
  17   1.4732     45.100  1.5759    38.588  94.41
  18   1.6660     43.520  1.4321    45.440  99.97
  19   1.2200     56.350  1.2796    53.852  105.41
  20   1.1609     60.870  1.1374    60.228  110.85
  21   1.0298     65.590  1.0608    63.340  116.30
  22   0.9333     68.340  0.9604    67.396  121.74
  23   0.8825     70.910  0.9179    69.078  127.17
  24   0.8923     71.020  0.8598    71.394  132.60
  25   0.9195     71.620  0.8076    73.432  138.16
  26   0.8313     73.720  0.8060    73.878  143.59
  27   0.8270     74.140  0.7687    74.966  149.02
  28   0.8896     72.830  0.7380    76.236  154.46
  29   0.8013     75.250  0.7257    76.692  159.88
  30   0.7883     74.830  0.7117    77.194  165.31
  31   0.7962     75.520  0.7094    77.384  170.77
  32   0.7034     77.310  0.6972    78.070  176.37
  33   0.7665     76.490  0.6857    78.164  181.82
  34   0.7585     77.310  0.6674    79.084  187.24
  35   0.7981     76.940  0.6543    79.334  192.68
  36   0.7673     76.770  0.6662    79.152  198.12
  37   0.7405     77.760  0.6594    79.154  203.57
  38   0.7348     78.000  0.6566    79.318  209.00
  39   0.7004     78.100  0.6453    79.866  214.55
  40   0.7281     77.960  0.6343    80.000  220.01
  41   0.8573     74.860  0.6422    80.100  225.45
  42   0.7475     77.250  0.6319    80.398  230.88
  43   0.8413     76.350  0.6199    80.510  236.33
  44   0.6977     77.990  0.6263    80.572  241.77
  45   0.6446     80.260  0.6168    80.706  247.29
  46   0.6718     78.850  0.6202    80.864  252.73
  47   0.7032     78.970  0.6179    80.820  258.17
  48   0.6770     79.150  0.6157    80.752  263.60
  49   0.7113     79.360  0.6132    81.128  269.03
  50   0.6488     80.150  0.6049    81.266  274.45
  51   0.7200     79.480  0.6054    81.316  279.88
  52   0.6454     79.560  0.6076    81.160  285.35
  53   0.6263     80.580  0.6124    81.160  290.78
  54   0.6766     80.060  0.6013    81.282  296.20
  55   0.6686     79.690  0.6033    81.254  301.64
  56   0.6482     80.660  0.6000    81.334  307.08
  57   0.6722     80.480  0.5776    82.038  312.51
  58   0.6308     80.610  0.5909    81.890  317.92
  59   0.6048     81.310  0.5859    81.912  323.35
  60   0.6807     78.350  0.5909    81.824  328.91
  61   0.6392     80.870  0.5821    81.918  334.33
  62   0.6108     81.140  0.5820    82.070  339.78
  63   0.6225     80.720  0.5799    82.030  345.19
  64   0.7197     77.510  0.5658    82.304  350.62
  65   0.6401     81.280  0.5738    82.378  356.04
  66   0.6428     79.760  0.5718    82.520  361.46
  67   0.6468     81.030  0.5780    82.066  367.02
  68   0.7331     78.550  0.5737    82.306  372.46
  69   0.6132     81.540  0.5735    82.274  377.88
  70   0.6030     81.490  0.5697    82.548  383.32
  71   0.7198     80.050  0.5638    82.700  388.77
  72   0.5950     81.380  0.5674    82.524  394.19
  73   0.6963     79.790  0.5636    82.594  399.63
  74   0.5918     81.620  0.5732    82.362  405.18
  75   0.6432     81.370  0.5650    82.770  410.60
  76   0.6580     80.160  0.5620    82.592  416.01
  77   0.7319     78.350  0.5600    82.844  421.46
  78   0.6204     80.840  0.5626    82.830  426.91
  79   0.6365     81.180  0.5688    82.476  432.33
  80   0.5768     81.470  0.5697    82.360  437.75
  81   0.6194     81.320  0.5533    82.944  443.35
  82   0.6063     81.500  0.5539    82.898  448.78
  83   0.7318     80.010  0.5578    82.972  454.23
  84   0.6155     80.360  0.5566    83.024  459.66
  85   0.6244     81.310  0.5557    82.842  465.08
