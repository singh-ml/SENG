Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8372     25.290  2.3672    15.546  7.15
   2   1.4789     44.950  1.6462    35.326  12.55
   3   1.2450     54.780  1.3115    52.372  18.12
   4   1.0290     63.480  1.0916    61.850  23.56
   5   0.9362     67.380  0.9340    67.658  28.99
   6   0.8234     72.630  0.8321    71.608  34.43
   7   0.7021     75.960  0.7529    74.682  39.84
   8   0.6701     77.040  0.6806    77.448  45.29
   9   0.7861     77.630  0.6197    79.422  50.74
  10   0.6171     79.460  0.5933    80.536  56.31
  11   0.6079     79.950  0.5342    82.154  61.74
  12   0.6429     79.050  0.5425    82.368  67.17
  13   0.6273     78.780  0.4829    83.858  72.58
  14   0.5843     81.650  0.4575    84.760  78.01
  15   0.5412     81.810  0.5170    83.550  83.46
  16   0.4868     83.830  0.4022    86.416  89.04
  17   0.5577     82.030  0.3906    87.048  94.48
  18   0.4722     83.970  0.4239    86.164  99.95
  19   0.4979     84.050  0.3709    87.810  105.38
  20   0.4932     84.140  0.3554    88.184  110.83
  21   0.4900     84.510  0.3672    88.064  116.24
  22   0.4864     84.880  0.3298    89.032  121.66
  23   0.6770     79.980  0.3228    89.410  127.23
  24   0.4346     85.990  0.3328    89.318  132.67
  25   0.4992     84.130  0.2852    90.386  138.11
  26   0.4531     85.810  0.2762    90.748  143.58
  27   0.5505     82.830  0.2973    90.132  149.04
  28   0.4945     85.440  0.4856    86.268  154.46
  29   0.8231     81.110  0.3012    90.896  159.89
  30   0.4584     85.670  0.2728    91.016  165.44
  31   0.4652     86.050  0.2423    92.018  170.90
  32   0.4260     86.710  0.2338    92.138  176.32
  33   0.4755     86.410  0.2297    92.336  181.76
  34   0.4563     86.090  0.2285    92.442  187.20
  35   17.9333     67.350  0.3411    90.938  192.64
  36   0.4471     87.470  0.3517    90.510  198.05
  37   0.4321     87.080  0.2039    93.268  203.61
  38   0.4545     86.830  0.1933    93.590  209.05
  39   0.4451     87.070  0.1915    93.720  214.50
  40   0.4884     86.650  0.1915    93.592  219.93
  41   0.4885     87.080  0.2316    92.876  225.35
  42   0.4525     87.140  0.2422    92.800  230.77
  43   0.4354     87.550  0.1636    94.558  236.21
  44   0.4550     87.210  0.1612    94.544  241.77
  45   0.4709     86.740  0.1592    94.654  247.18
  46   0.4778     87.430  0.1619    94.662  252.64
  47   0.4432     88.430  0.2263    93.196  258.07
  48   0.4853     87.230  0.1374    95.390  263.50
  49   0.4351     87.360  0.1482    95.062  268.93
  50   0.4942     87.060  0.1585    94.830  274.48
  51   0.4776     87.630  0.1432    95.326  279.92
  52   0.4721     87.490  0.1347    95.494  285.36
  53   0.4952     87.430  0.1270    95.654  290.78
  54   0.5845     86.890  0.1494    95.242  296.18
  55   0.4664     88.250  0.1237    95.842  301.62
  56   0.7094     86.490  0.2002    94.626  307.04
  57   0.4343     88.750  0.1427    95.458  312.49
  58   0.4402     88.300  0.1108    96.340  318.06
  59   0.4252     88.330  0.1161    96.182  323.53
  60   0.4592     87.740  0.1108    96.258  328.99
  61   0.5818     87.680  0.1142    96.344  334.41
  62   0.5468     86.910  0.1332    95.926  339.83
  63   0.5203     87.270  0.1030    96.566  345.26
  64   0.4582     88.440  0.1005    96.614  350.70
  65   0.4374     87.700  0.1419    95.824  356.14
  66   0.4760     88.690  0.1036    96.534  361.55
  67   0.4650     88.660  0.1419    96.110  366.99
  68   0.4252     89.600  0.0892    96.912  372.43
  69   0.5199     88.410  0.0859    97.076  377.88
  70   0.5653     87.250  0.0928    97.020  383.30
  71   0.5075     88.090  0.0904    97.018  388.74
  72   0.5350     85.520  0.2312    95.552  394.29
  73   0.5299     88.400  0.1632    95.456  399.71
  74   0.4474     89.220  0.0715    97.618  405.14
  75   0.4982     88.370  0.0810    97.282  410.56
  76   0.4529     89.350  0.0820    97.182  415.98
  77   0.5827     87.550  0.0845    97.156  421.38
  78   0.5407     87.870  0.1259    96.668  426.80
  79   0.4897     88.070  0.0783    97.406  432.39
  80   0.4753     88.450  0.0802    97.354  437.80
  81   0.4350     88.350  0.0799    97.444  443.23
  82   0.4937     88.230  0.0761    97.490  448.65
  83   0.4971     88.230  0.0750    97.512  454.08
  84   0.5113     87.950  0.0766    97.502  459.51
  85   0.5391     87.790  0.0737    97.612  464.92
  86   0.4760     89.330  0.0694    97.752  470.46
  87   0.5195     88.230  0.0772    97.532  475.88
  88   0.4903     88.810  0.0706    97.746  481.33
  89   0.4648     88.850  0.0692    97.810  486.77
  90   0.4799     88.700  0.0737    97.544  492.21
