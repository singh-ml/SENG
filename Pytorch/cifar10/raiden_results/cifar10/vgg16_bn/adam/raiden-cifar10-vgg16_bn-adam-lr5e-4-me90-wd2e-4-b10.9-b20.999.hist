Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1020     16.540  2.8759    12.376  6.98
   2   1.7389     27.450  1.9090    22.366  12.53
   3   1.5290     39.170  1.6929    31.136  17.94
   4   1.4131     49.520  1.4720    42.620  23.37
   5   1.2835     56.160  1.2439    54.348  28.81
   6   1.3563     52.970  1.1034    60.870  34.20
   7   0.9739     67.690  0.9544    67.486  39.59
   8   0.9475     69.240  0.8589    71.502  45.03
   9   0.8515     74.720  0.7676    75.284  50.44
  10   0.8379     74.030  0.7455    76.582  55.87
  11   0.8397     73.640  0.7113    77.552  61.26
  12   0.6784     79.600  0.6482    79.866  66.68
  13   0.6765     80.040  0.5915    81.542  72.11
  14   0.5909     83.340  0.5464    83.230  77.51
  15   0.6754     78.670  0.5232    83.754  82.90
  16   0.7303     79.650  0.6804    80.182  88.45
  17   0.6067     81.030  0.5337    83.480  93.86
  18   0.5245     82.660  0.4773    85.144  99.27
  19   0.6216     81.210  0.4337    86.512  104.67
  20   0.5015     84.410  0.4983    85.108  110.07
  21   0.9297     69.250  0.4414    87.064  115.49
  22   0.5410     82.390  0.7201    78.420  120.90
  23   0.4425     85.730  0.4279    86.572  126.44
  24   0.4851     85.140  0.3830    88.052  131.88
  25   0.4614     85.660  0.3629    88.706  137.30
  26   0.4401     85.420  0.3434    89.272  142.70
  27   0.5215     84.460  0.3363    89.464  148.10
  28   0.6517     79.450  0.7963    74.994  153.50
  29   0.4412     85.520  0.4523    85.680  158.97
  30   0.4100     86.670  0.3617    88.628  164.51
  31   0.4881     84.750  0.3254    89.790  169.93
  32   0.4357     85.870  0.3852    88.318  175.35
  33   0.4126     86.770  0.3510    89.140  180.77
  34   0.3885     88.100  0.2896    90.860  186.18
  35   0.3773     87.880  0.2749    91.350  191.59
  36   0.4293     87.660  0.2580    91.804  197.01
  37   0.5268     85.040  0.2477    92.246  202.55
  38   0.3828     88.110  0.2455    92.284  207.97
  39   0.3898     88.420  0.2409    92.490  213.40
  40   0.8124     73.320  1.0473    74.036  218.86
  41   0.4750     84.310  0.5727    81.882  224.28
  42   0.4676     85.050  0.3695    88.316  229.70
  43   0.4479     85.740  0.6219    82.214  235.09
  44   0.3884     86.990  0.3303    89.502  240.66
  45   0.3892     87.460  0.2769    90.998  246.09
  46   0.3653     87.840  0.2468    92.022  251.51
  47   0.4514     87.110  0.2248    92.698  256.93
  48   0.3982     87.880  0.2176    93.058  262.34
  49   0.6282     83.720  0.2362    93.060  267.75
  50   0.3737     88.590  0.2483    92.200  273.17
  51   0.9513     69.330  0.4239    88.224  278.77
  52   0.4103     87.080  0.3999    87.422  284.18
  53   0.4016     88.440  0.2442    92.168  289.60
  54   0.4060     88.280  0.2115    93.220  295.01
  55   0.3540     89.070  0.1992    93.716  300.42
  56   0.3428     89.710  0.1877    94.032  305.83
  57   0.4239     87.980  0.1740    94.400  311.25
  58   0.3953     88.760  0.1717    94.564  316.80
  59   0.4432     87.510  0.1720    94.494  322.25
  60   0.4405     88.160  0.1672    94.662  327.67
  61   0.3721     89.540  0.1626    94.892  333.11
  62   0.3858     88.950  0.1579    94.950  338.55
  63   0.3903     89.280  0.1631    94.730  343.98
  64   0.3983     88.750  0.1661    94.688  349.40
  65   0.4332     88.710  0.1583    94.952  354.93
  66   0.4073     88.900  0.1521    95.190  360.35
  67   0.4082     88.330  0.1531    95.036  365.80
  68   0.4420     88.240  0.1596    95.020  371.22
  69   0.4640     88.120  0.1485    95.364  376.65
  70   0.4665     86.830  0.3900    89.886  382.07
  71   0.3852     89.230  0.1775    94.304  387.53
  72   0.4126     88.670  0.1447    95.432  393.10
  73   0.4132     89.500  0.1394    95.638  398.55
  74   0.4062     89.110  0.1317    95.780  403.98
  75   0.4309     88.500  0.1369    95.584  409.42
  76   0.4093     88.840  0.1330    95.818  414.86
  77   0.4191     89.280  0.1249    96.000  420.28
  78   0.4192     89.150  0.1308    95.952  425.73
  79   0.4113     89.130  0.1275    95.962  431.29
  80   0.4664     88.570  0.1280    96.032  436.72
  81   0.4652     88.430  0.1220    96.212  442.13
  82   0.3985     89.880  0.1190    96.272  447.55
  83   0.4564     88.560  0.1210    96.246  452.99
  84   1.0870     74.020  0.1953    94.604  458.41
  85   0.3584     89.440  0.3826    89.090  463.86
  86   0.3978     89.450  0.1423    95.454  469.41
  87   0.3961     89.730  0.1169    96.212  474.82
  88   0.3990     89.830  0.1104    96.484  480.27
  89   0.3918     90.360  0.1075    96.584  485.70
  90   0.4354     89.190  0.1043    96.784  491.13
