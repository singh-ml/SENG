Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2813     11.590  3.7011    11.184  7.08
   2   1.9519     20.340  2.0725    17.220  12.51
   3   2.0010     20.670  1.9218    20.652  17.95
   4   1.6824     32.530  1.7347    29.776  23.38
   5   1.6195     35.480  1.5721    37.478  28.82
   6   1.4783     48.530  1.4219    45.288  34.34
   7   1.3329     55.150  1.2602    54.616  39.77
   8   1.1910     57.180  1.2140    58.622  45.23
   9   9.0446     50.450  1.0521    63.224  50.66
  10   6.0299     45.690  1.0381    64.740  56.14
  11   1.8991     38.390  1.6997    53.004  61.59
  12   1.5158     45.960  2.0228    46.182  67.03
  13   1.1817     62.550  1.3041    55.614  72.44
  14   1.1901     63.510  1.0750    63.480  77.99
  15   0.8664     69.870  1.0662    64.660  83.41
  16   4.7632     36.540  1.2415    66.434  88.84
  17   0.9059     67.780  1.4964    56.792  94.25
  18   0.8315     71.000  0.8845    69.198  99.70
  19   0.8054     72.800  0.7923    72.842  105.14
  20   3.3370     55.770  0.8915    73.328  110.55
  21   0.9527     70.970  1.2411    64.480  116.12
  22   0.8321     72.070  0.7833    73.518  121.54
  23   0.8194     77.490  0.7033    76.546  126.96
  24   0.7670     74.910  0.8182    74.686  132.40
  25   0.8879     72.740  0.6378    79.060  137.83
  26   0.7177     77.380  0.9485    70.002  143.28
  27   0.6264     79.290  0.6227    79.790  148.84
  28   0.6259     79.620  0.5764    81.244  154.27
  29   0.5872     80.680  0.5535    82.040  159.71
  30   0.6839     78.770  0.5829    82.476  165.14
  31   0.5103     83.580  0.5147    83.418  170.57
  32   0.6605     80.150  0.4754    84.548  175.99
  33   0.5753     81.570  0.4683    85.014  181.42
  34   0.5132     83.870  0.4419    85.758  186.97
  35   0.5214     82.820  0.4323    86.178  192.42
  36   0.5180     83.730  0.4130    86.640  197.86
  37   0.4604     85.740  0.4065    87.022  203.31
  38   0.5147     83.960  0.3748    88.124  208.74
  39   0.4438     85.890  0.3603    88.628  214.16
  40   0.5316     83.020  0.3523    88.842  219.72
  41   0.5575     83.220  0.3402    89.010  225.15
  42   0.5602     83.520  0.3278    89.438  230.61
  43   0.4316     86.390  0.3256    89.612  236.03
  44   0.4964     85.130  0.3107    90.172  241.48
  45   0.5400     84.490  0.3017    90.304  246.93
  46   0.4932     84.750  0.3029    90.476  252.37
  47   0.4129     87.420  0.2957    90.722  257.82
  48   0.5065     85.220  0.2803    91.186  263.39
  49   0.4697     85.830  0.2742    91.472  268.82
  50   0.8162     83.200  0.2657    91.774  274.27
  51   0.4502     86.190  0.2617    91.814  279.72
  52   0.4697     86.400  0.2519    92.138  285.18
  53   0.5017     84.960  0.2512    92.108  290.62
  54   0.4648     86.250  0.2408    92.460  296.05
  55   0.5984     84.310  0.2369    92.608  301.61
  56   0.4372     87.370  0.2324    92.894  307.10
  57   0.4529     87.280  0.2298    92.930  312.56
  58   0.4266     87.750  0.2262    92.896  317.98
  59   0.4142     88.220  0.2195    93.140  323.42
  60   0.4390     88.120  0.2182    93.172  328.86
  61   0.5024     85.620  0.2134    93.400  334.31
  62   0.3953     88.480  0.2118    93.364  339.85
  63   0.4770     86.640  0.2179    93.522  345.33
  64   0.4262     88.460  0.2333    92.846  350.78
  65   0.4407     87.730  0.1968    93.782  356.21
  66   0.4180     87.640  0.1964    93.886  361.68
  67   0.3959     88.730  0.1993    93.766  367.10
  68   0.3873     88.420  0.1896    94.280  372.67
  69   0.4235     88.570  0.1941    94.002  378.09
  70   0.4571     87.000  0.1911    94.166  383.52
  71   0.4255     88.060  0.1896    94.188  388.96
  72   0.3839     88.850  0.1861    94.130  394.40
  73   0.4140     88.160  0.1805    94.336  399.83
  74   0.4249     88.180  0.1763    94.582  405.26
  75   0.4251     88.950  0.1774    94.504  410.69
  76   0.4421     87.580  0.1796    94.558  416.15
  77   0.4230     88.050  0.1751    94.554  421.60
  78   0.4083     89.120  0.1716    94.708  427.05
  79   0.4643     87.810  0.1717    94.762  432.49
  80   0.4355     88.260  0.1733    94.696  437.92
  81   0.4466     88.330  0.1709    94.876  443.34
  82   0.4517     88.260  0.1686    94.718  448.86
  83   0.4419     87.790  0.1702    94.798  454.30
  84   0.4315     88.080  0.1636    94.994  459.75
  85   0.4517     88.050  0.1637    94.986  465.20
  86   0.4336     88.680  0.1615    94.972  470.65
  87   0.4422     88.700  0.1579    95.022  476.10
  88   0.4657     87.880  0.1586    94.992  481.55
  89   0.4656     88.340  0.1579    95.242  487.12
  90   0.4328     88.430  0.1526    95.300  492.58
