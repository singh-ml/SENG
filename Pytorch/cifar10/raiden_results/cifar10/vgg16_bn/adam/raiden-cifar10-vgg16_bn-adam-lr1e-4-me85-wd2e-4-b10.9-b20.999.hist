Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4915     44.560  1.9550    27.702  7.33
   2   1.2560     55.460  1.3814    49.412  12.93
   3   1.0475     61.980  1.1614    58.900  18.57
   4   1.0196     64.430  1.0239    64.020  24.17
   5   0.9535     67.160  0.9203    68.044  29.79
   6   0.8465     70.960  0.8385    70.956  35.39
   7   0.7595     73.530  0.7666    73.934  41.13
   8   0.7066     75.430  0.7096    75.842  46.75
   9   0.7183     74.720  0.6608    77.744  52.34
  10   0.6701     76.380  0.6242    78.900  57.92
  11   0.7071     75.850  0.5825    80.520  63.53
  12   0.6035     79.460  0.5570    81.172  69.12
  13   0.6295     78.480  0.5296    82.302  74.72
  14   0.6300     79.350  0.5013    82.906  80.44
  15   0.5940     79.860  0.4759    83.964  86.04
  16   0.5587     80.830  0.4527    84.786  91.66
  17   0.5305     81.920  0.4256    85.806  97.27
  18   0.5416     81.360  0.4065    86.244  102.87
  19   0.5116     82.360  0.3956    86.760  108.48
  20   0.5153     82.310  0.3796    87.236  114.07
  21   0.5390     81.980  0.3679    87.818  119.81
  22   0.5052     83.330  0.3511    88.178  125.40
  23   0.5145     82.250  0.3366    88.706  131.01
  24   0.5097     82.850  0.3225    89.182  136.60
  25   0.5150     83.370  0.3142    89.462  142.21
  26   0.5021     83.560  0.3052    89.758  147.81
  27   0.5185     83.260  0.2835    90.522  153.43
  28   0.4919     83.840  0.2766    90.868  159.16
  29   0.5162     83.200  0.2683    91.054  164.77
  30   0.5340     83.260  0.2560    91.436  170.39
  31   0.4940     83.860  0.2533    91.472  175.98
  32   0.4954     84.070  0.2398    91.862  181.55
  33   0.5104     84.650  0.2310    92.300  187.13
  34   0.4693     85.190  0.2270    92.468  192.73
  35   0.5118     84.830  0.2064    92.960  198.34
  36   0.5451     83.870  0.2107    92.858  203.94
  37   0.4910     84.430  0.2005    93.412  209.54
  38   0.5059     84.030  0.1991    93.384  215.12
  39   0.4982     85.420  0.1928    93.590  220.71
  40   0.5089     85.480  0.1851    93.890  226.34
  41   0.4934     85.150  0.1821    94.050  231.92
  42   0.4843     86.190  0.1690    94.336  237.65
  43   0.5335     85.120  0.1684    94.450  243.25
  44   0.5198     84.810  0.1661    94.490  248.89
  45   0.5681     84.410  0.1579    94.774  254.47
  46   0.5672     84.670  0.1520    94.912  260.07
  47   0.5478     85.330  0.1456    95.228  265.70
  48   0.5795     83.670  0.1464    95.122  271.43
  49   0.5661     85.360  0.1331    95.536  277.07
  50   0.5899     85.320  0.1386    95.366  282.69
  51   0.5311     85.200  0.1354    95.500  288.31
  52   0.5658     85.520  0.1320    95.628  293.91
  53   0.6124     85.160  0.1258    95.802  299.51
  54   0.5259     86.040  0.1242    95.804  305.13
  55   0.6026     85.180  0.1231    95.920  310.86
  56   0.6375     84.620  0.1150    96.196  316.45
  57   0.5626     85.790  0.1120    96.354  322.07
  58   0.6028     85.570  0.1155    96.170  327.67
  59   0.5459     85.940  0.1087    96.464  333.27
  60   0.5959     85.330  0.1063    96.490  338.89
  61   0.5913     85.880  0.1066    96.496  344.50
  62   0.5893     85.770  0.1015    96.628  350.22
  63   0.5484     85.790  0.1070    96.504  355.83
  64   0.6061     85.450  0.0987    96.812  361.44
  65   0.5563     86.240  0.0927    96.866  367.05
  66   0.5901     86.040  0.0985    96.750  372.64
  67   0.5536     86.740  0.0946    96.858  378.25
  68   0.6091     85.960  0.0940    96.826  383.99
  69   0.5814     87.020  0.0885    97.046  389.62
  70   0.5539     86.730  0.0851    97.178  395.24
  71   0.5942     85.690  0.0842    97.152  400.85
  72   0.6300     86.290  0.0842    97.206  406.45
  73   0.5954     86.000  0.0841    97.184  412.03
  74   0.5533     87.140  0.0870    97.070  417.67
  75   0.5311     87.430  0.0840    97.240  423.40
  76   0.5617     87.530  0.0816    97.226  429.01
  77   0.5846     86.240  0.0789    97.396  434.61
  78   0.5596     87.310  0.0798    97.420  440.20
  79   0.5775     86.450  0.0754    97.512  445.83
  80   0.6131     86.720  0.0716    97.554  451.43
  81   0.6318     86.270  0.0727    97.596  457.04
  82   0.6152     86.730  0.0745    97.564  462.79
  83   0.6327     86.830  0.0700    97.646  468.41
  84   0.5774     87.560  0.0717    97.730  474.03
  85   0.5641     87.250  0.0724    97.564  479.67
