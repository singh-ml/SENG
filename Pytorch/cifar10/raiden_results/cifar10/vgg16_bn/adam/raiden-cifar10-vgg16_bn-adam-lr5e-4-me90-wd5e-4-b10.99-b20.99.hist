Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2073     14.980  2.9587    12.108  7.08
   2   2.1443     16.930  2.2031    14.858  12.48
   3   1.9050     24.090  2.0783    19.056  17.91
   4   1.8359     26.580  1.8958    23.108  23.33
   5   1.6966     31.400  1.7958    27.130  28.76
   6   1.5706     38.180  1.6809    33.476  34.32
   7   1.6302     44.820  1.4961    42.304  39.75
   8   1.2655     52.880  1.3395    50.338  45.18
   9   1.1266     59.250  1.1925    56.506  50.63
  10   1.2761     59.260  1.0634    62.074  56.06
  11   1.0452     64.610  0.9840    65.584  61.51
  12   0.8865     69.690  0.8953    69.254  67.07
  13   0.7692     74.120  0.8215    72.032  72.52
  14   0.7841     73.570  0.7680    74.090  77.94
  15   0.7952     75.810  0.7179    76.200  83.38
  16   0.6863     77.620  0.6800    77.856  88.80
  17   0.6506     79.500  0.6423    79.092  94.24
  18   0.6062     80.510  0.5938    80.778  99.71
  19   0.5952     80.820  0.5673    81.682  105.22
  20   0.6085     80.670  0.5338    82.972  110.67
  21   0.6486     79.560  0.5077    83.708  116.09
  22   0.6423     80.590  0.4871    84.434  121.54
  23   0.5449     82.470  0.4627    85.242  126.98
  24   0.5244     83.880  0.4387    86.078  132.41
  25   0.5388     83.020  0.4287    86.332  137.82
  26   0.4922     84.930  0.3957    87.276  143.37
  27   0.5043     84.690  0.3883    87.870  148.81
  28   0.4812     85.850  0.3734    88.200  154.25
  29   0.4568     86.080  0.3545    88.702  159.70
  30   0.4636     86.080  0.3480    88.978  165.14
  31   0.4389     86.700  0.3306    89.602  170.58
  32   0.4376     86.630  0.3110    90.140  176.02
  33   0.4337     86.310  0.3046    90.336  181.58
  34   0.4189     87.420  0.3048    90.414  187.02
  35   0.4038     87.960  0.2981    90.700  192.44
  36   0.4082     87.290  0.2786    91.298  197.86
  37   0.4358     87.180  0.2801    91.224  203.30
  38   0.4434     87.170  0.2635    91.550  208.75
  39   0.4098     87.450  0.2547    92.054  214.17
  40   0.4090     87.980  0.2553    92.096  219.76
  41   0.3944     88.560  0.2483    92.324  225.19
  42   0.4093     87.620  0.2293    92.708  230.61
  43   0.3848     88.550  0.2352    92.480  236.02
  44   0.4178     87.600  0.2334    92.622  241.45
  45   0.3958     88.440  0.2255    92.952  246.88
  46   0.4665     87.470  0.2118    93.322  252.29
  47   0.4374     87.300  0.2140    93.340  257.89
  48   0.3789     88.940  0.2085    93.538  263.31
  49   0.3898     88.460  0.1953    93.746  268.75
  50   0.4258     88.520  0.1943    94.006  274.17
  51   0.4349     88.350  0.1918    93.882  279.62
  52   0.3763     89.420  0.1869    94.232  285.08
  53   0.3921     89.460  0.1783    94.450  290.49
  54   0.3851     88.830  0.1859    94.156  296.03
  55   0.3655     89.600  0.1839    94.276  301.45
  56   0.3988     89.450  0.1707    94.606  306.89
  57   0.3858     89.250  0.1655    94.866  312.32
  58   0.4137     88.980  0.1745    94.580  317.74
  59   0.3854     89.210  0.1661    94.802  323.15
  60   0.3927     89.320  0.1673    94.876  328.70
  61   0.4189     89.030  0.1686    94.700  334.15
  62   0.4033     89.330  0.1630    94.840  339.57
  63   0.4229     88.810  0.1462    95.434  344.99
  64   0.3814     89.720  0.1498    95.364  350.44
  65   0.3858     89.730  0.1510    95.392  355.84
  66   0.4092     89.160  0.1526    95.228  361.27
  67   0.3851     89.720  0.1467    95.512  366.82
  68   0.4170     89.000  0.1448    95.438  372.27
  69   0.3943     89.550  0.1395    95.758  377.70
  70   0.3690     90.080  0.1350    95.860  383.14
  71   0.4388     89.380  0.1350    95.904  388.59
  72   0.4070     89.820  0.1367    95.776  394.02
  73   0.3941     89.760  0.1366    95.758  399.45
  74   0.4357     89.050  0.1334    95.832  405.03
  75   0.4105     89.670  0.1368    95.858  410.46
  76   0.3813     89.550  0.1344    95.810  415.87
  77   0.4108     89.950  0.1357    95.868  421.28
  78   0.4268     89.550  0.1353    95.846  426.70
  79   0.4257     89.270  0.1277    96.016  432.12
  80   0.3910     89.670  0.1256    96.030  437.52
  81   0.4057     89.470  0.1279    96.010  443.08
  82   0.4061     89.340  0.1274    96.082  448.54
  83   0.4272     89.300  0.1233    96.224  453.96
  84   0.4035     90.050  0.1186    96.286  459.39
  85   0.4277     89.600  0.1184    96.314  464.81
  86   0.4029     89.600  0.1214    96.310  470.22
  87   0.4417     89.400  0.1252    96.202  475.67
  88   0.4171     89.710  0.1152    96.372  481.11
  89   0.4195     89.150  0.1166    96.390  486.52
  90   0.3985     90.010  0.1189    96.398  491.95
