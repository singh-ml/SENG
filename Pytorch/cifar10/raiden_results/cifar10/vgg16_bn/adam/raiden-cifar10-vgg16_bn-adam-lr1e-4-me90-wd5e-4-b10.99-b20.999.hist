Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.9144     22.410  2.2643    15.736  7.16
   2   1.6539     33.370  1.8259    26.802  12.55
   3   1.4285     45.370  1.5985    37.914  18.08
   4   1.3009     51.740  1.4134    46.898  23.49
   5   1.1338     57.530  1.2651    53.064  28.91
   6   1.0542     62.390  1.1233    59.494  34.30
   7   0.9949     66.030  1.0164    64.490  39.73
   8   0.8854     68.280  0.9157    68.290  45.14
   9   0.7879     72.560  0.8298    71.384  50.56
  10   0.7413     73.980  0.7601    74.120  55.93
  11   0.6985     76.130  0.7077    76.044  61.35
  12   0.6544     77.490  0.6460    78.246  66.77
  13   0.6410     78.660  0.6044    79.746  72.19
  14   0.6360     78.440  0.5780    80.692  77.59
  15   0.5976     80.260  0.5442    81.852  82.98
  16   0.5564     81.440  0.5097    82.936  88.37
  17   0.5623     81.010  0.4793    84.028  93.78
  18   0.5495     81.780  0.4612    84.516  99.35
  19   0.5958     80.610  0.4399    85.404  104.74
  20   0.5189     83.010  0.4280    85.760  110.12
  21   0.4929     83.090  0.4010    86.590  115.49
  22   0.5169     83.200  0.3936    86.822  120.90
  23   0.5595     81.530  0.3786    87.348  126.32
  24   0.5051     83.410  0.3589    88.006  131.86
  25   0.5152     83.580  0.3359    88.804  137.28
  26   0.5088     83.480  0.3211    89.220  142.66
  27   0.4974     83.820  0.3156    89.474  148.06
  28   0.5003     84.410  0.2988    90.036  153.46
  29   0.5263     83.950  0.2831    90.440  158.87
  30   0.5256     84.090  0.2790    90.824  164.27
  31   0.4903     84.880  0.2705    90.936  169.84
  32   0.5080     84.870  0.2611    91.318  175.22
  33   0.4808     85.520  0.2484    91.830  180.60
  34   0.5354     85.170  0.2417    91.952  186.03
  35   0.4728     85.160  0.2391    92.070  191.47
  36   0.4816     85.250  0.2306    92.310  196.90
  37   0.4902     85.800  0.2232    92.468  202.31
  38   0.4825     85.650  0.2149    92.874  207.72
  39   0.4570     85.990  0.2034    93.206  213.11
  40   0.5007     85.820  0.2008    93.222  218.51
  41   0.4742     86.180  0.1936    93.512  223.89
  42   0.4770     86.150  0.1826    93.906  229.28
  43   0.5091     85.780  0.1783    94.166  234.68
  44   0.5018     86.120  0.1693    94.484  240.09
  45   0.4989     86.300  0.1725    94.304  245.48
  46   0.5336     85.660  0.1647    94.600  251.01
  47   0.5022     86.110  0.1605    94.606  256.40
  48   0.5308     85.450  0.1536    94.744  261.82
  49   0.4973     86.710  0.1427    95.178  267.22
  50   0.4746     86.680  0.1497    94.918  272.62
  51   0.4879     86.610  0.1404    95.264  278.01
  52   0.5315     85.560  0.1431    95.204  283.42
  53   0.4844     86.580  0.1386    95.354  288.95
  54   0.5147     86.340  0.1288    95.698  294.33
  55   0.5365     86.180  0.1304    95.698  299.73
  56   0.4901     86.150  0.1347    95.480  305.13
  57   0.5330     86.600  0.1263    95.772  310.55
  58   0.4999     87.030  0.1175    96.014  315.97
  59   0.5178     86.880  0.1167    96.186  321.39
  60   0.5191     86.500  0.1170    96.086  326.80
  61   0.4968     87.030  0.1115    96.352  332.19
  62   0.5087     87.140  0.1025    96.626  337.59
  63   0.5409     86.620  0.1023    96.536  343.00
  64   0.4952     86.730  0.1081    96.326  348.40
  65   0.5421     86.560  0.1044    96.472  353.80
  66   0.5490     87.320  0.0973    96.810  359.37
  67   0.5632     86.850  0.0957    96.778  364.76
  68   0.5699     86.290  0.0978    96.700  370.17
  69   0.5244     86.490  0.0976    96.818  375.56
  70   0.5162     87.620  0.0974    96.732  380.96
  71   0.5507     86.790  0.0879    97.030  386.36
  72   0.5002     87.090  0.0921    96.838  391.75
  73   0.5354     87.230  0.0899    97.032  397.25
  74   0.5658     87.020  0.0928    96.834  402.66
  75   0.4943     87.440  0.0946    96.894  408.04
  76   0.5055     87.460  0.0878    97.134  413.43
  77   0.5099     87.420  0.0902    96.976  418.85
  78   0.5111     87.370  0.0837    97.218  424.24
  79   0.5579     86.910  0.0799    97.334  429.73
  80   0.5570     87.170  0.0807    97.384  435.15
  81   0.5278     87.460  0.0812    97.372  440.59
  82   0.5217     86.980  0.0757    97.506  445.98
  83   0.5291     86.980  0.0831    97.296  451.39
  84   0.5134     87.800  0.0793    97.344  456.80
  85   0.5116     87.960  0.0773    97.552  462.21
  86   0.5052     87.870  0.0755    97.520  467.72
  87   0.5464     87.710  0.0698    97.654  473.14
  88   0.5331     87.720  0.0730    97.572  478.53
  89   0.5269     87.590  0.0731    97.606  483.96
  90   0.5145     88.160  0.0715    97.588  489.34
