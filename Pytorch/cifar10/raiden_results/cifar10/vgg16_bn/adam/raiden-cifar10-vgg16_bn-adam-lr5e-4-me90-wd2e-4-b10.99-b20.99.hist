Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2351     14.550  2.9582    10.894  7.24
   2   2.1104     16.540  2.2169    14.462  12.65
   3   1.9847     20.260  2.0721    17.438  18.07
   4   1.9297     22.400  1.9082    22.352  23.50
   5   1.7784     28.790  1.8218    25.834  28.91
   6   1.5685     37.290  1.6872    32.226  34.32
   7   1.4133     46.270  1.5200    40.870  39.72
   8   1.4220     49.960  1.3649    49.026  45.12
   9   1.1350     58.910  1.2296    55.638  50.73
  10   1.0525     62.440  1.1090    60.446  56.14
  11   1.0940     64.960  1.0014    64.908  61.55
  12   1.0077     67.010  0.9077    68.530  66.94
  13   0.8109     72.230  0.8485    70.876  72.34
  14   0.8203     72.230  0.8249    72.214  77.78
  15   0.8140     73.260  0.7741    74.024  83.23
  16   0.7892     73.550  0.7526    75.088  88.81
  17   0.6871     77.230  0.7155    76.538  94.24
  18   0.6776     77.840  0.7220    76.884  99.65
  19   0.8128     75.470  0.7150    78.218  105.08
  20   0.7168     77.010  0.7366    76.624  110.51
  21   0.8756     75.100  0.7390    77.812  115.92
  22   1.2614     73.970  0.8163    75.082  121.34
  23   0.8404     72.360  0.9350    73.042  126.81
  24   0.6904     76.820  0.7982    74.266  132.23
  25   0.6055     79.320  0.6649    78.720  137.62
  26   0.6047     79.720  0.5785    81.084  143.03
  27   0.6061     80.210  0.5773    81.108  148.46
  28   0.5497     81.160  0.5435    82.108  153.87
  29   0.5903     80.410  0.5488    82.402  159.30
  30   0.5458     82.480  0.5235    82.888  164.71
  31   0.5920     81.590  0.5016    83.986  170.14
  32   0.5140     83.080  0.4711    84.560  175.54
  33   0.4955     83.470  0.4553    85.260  180.96
  34   0.5764     82.230  0.5236    83.668  186.38
  35   0.4958     84.100  0.4397    85.656  191.82
  36   0.4763     84.640  0.3988    86.908  197.39
  37   0.4838     84.270  0.3782    87.716  202.83
  38   0.4640     85.420  0.3658    88.024  208.25
  39   0.5248     84.390  0.3528    88.390  213.68
  40   0.4818     85.210  0.3852    88.076  219.10
  41   0.4637     85.330  0.3842    87.540  224.53
  42   0.4555     85.660  0.3383    89.032  229.95
  43   0.4265     86.580  0.3041    90.046  235.47
  44   0.4252     86.340  0.2926    90.428  240.89
  45   0.4500     86.150  0.2863    90.542  246.31
  46   0.4318     86.950  0.2743    91.292  251.71
  47   0.3988     88.020  0.2691    91.272  257.13
  48   0.4439     86.540  0.2581    91.650  262.54
  49   0.4001     87.960  0.2521    91.876  267.97
  50   0.4017     87.610  0.2452    92.130  273.51
  51   0.4127     87.460  0.2379    92.362  278.95
  52   0.4176     87.600  0.2235    92.700  284.34
  53   0.3780     88.700  0.2152    93.102  289.75
  54   0.4055     88.190  0.2030    93.320  295.21
  55   0.4225     87.850  0.2003    93.544  300.63
  56   0.4211     87.880  0.1933    93.810  306.10
  57   0.4500     87.120  0.1947    93.730  311.54
  58   0.4149     87.790  0.1835    94.126  316.94
  59   0.4057     88.700  0.1849    94.030  322.34
  60   0.4328     87.770  0.1811    94.310  327.75
  61   0.4094     88.000  0.1707    94.594  333.19
  62   0.3999     88.870  0.1693    94.562  338.60
  63   0.4031     88.460  0.1582    94.836  344.00
  64   0.4291     88.860  0.1603    94.744  349.55
  65   0.4152     89.430  0.1530    95.086  354.97
  66   0.4414     88.210  0.1476    95.252  360.41
  67   0.4185     88.920  0.1466    95.346  365.82
  68   0.4214     88.370  0.1464    95.230  371.25
  69   0.4148     89.020  0.1448    95.420  376.67
  70   0.4206     88.890  0.1438    95.404  382.23
  71   0.4361     88.840  0.1448    95.470  387.67
  72   0.4211     89.370  0.1388    95.576  393.10
  73   0.4218     89.640  0.1310    95.786  398.52
  74   0.4093     89.040  0.1325    95.762  403.93
  75   0.4474     88.890  0.1220    96.092  409.36
  76   0.4336     89.410  0.1235    96.080  414.79
  77   0.4390     89.360  0.1254    96.056  420.19
  78   0.4393     89.020  0.1208    96.254  425.73
  79   0.4187     89.800  0.1192    96.352  431.14
  80   0.4424     88.770  0.1151    96.408  436.59
  81   0.3948     89.540  0.1221    96.242  442.01
  82   0.4005     89.760  0.1133    96.510  447.44
  83   0.4468     89.250  0.1113    96.568  452.87
  84   0.4260     89.400  0.1109    96.530  458.43
  85   0.3927     89.600  0.1095    96.522  463.85
  86   0.4145     89.840  0.1059    96.774  469.26
  87   0.4311     89.050  0.1056    96.704  474.69
  88   0.4537     89.590  0.1139    96.412  480.11
  89   0.4241     89.130  0.1024    96.744  485.51
  90   0.4080     89.750  0.1016    96.762  490.95
