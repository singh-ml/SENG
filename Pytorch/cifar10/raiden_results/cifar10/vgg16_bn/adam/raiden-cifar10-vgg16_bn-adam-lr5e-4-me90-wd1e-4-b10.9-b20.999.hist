Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1789     16.760  2.8548    11.860  7.16
   2   1.8384     25.600  1.9708    20.528  12.58
   3   1.6896     34.100  1.7046    31.088  18.01
   4   1.3546     48.080  1.4841    41.318  23.46
   5   1.1586     55.420  1.2891    50.526  28.99
   6   1.0625     61.740  1.1355    57.432  34.43
   7   0.9465     68.190  0.9685    66.104  39.85
   8   0.9426     70.090  0.8428    71.892  45.29
   9   1.0124     68.920  0.7602    75.148  50.73
  10   0.7519     76.170  0.7019    77.704  56.14
  11   0.7045     77.920  0.6497    79.254  61.69
  12   1.6439     54.580  0.6897    78.692  67.12
  13   0.6588     80.330  0.8041    75.566  72.56
  14   0.5563     83.010  0.5491    82.840  77.98
  15   0.6000     81.830  0.4990    84.410  83.41
  16   0.5179     84.060  0.4664    85.354  88.85
  17   0.5677     82.190  0.4492    85.890  94.28
  18   0.6986     78.480  1.0067    69.060  99.71
  19   0.6208     81.700  0.5777    81.862  105.15
  20   0.5684     82.400  0.4766    85.138  110.57
  21   0.5320     82.910  0.4466    85.934  115.99
  22   0.4722     84.610  0.4078    87.206  121.43
  23   0.5193     82.640  0.3797    88.050  126.86
  24   0.6866     79.470  0.3741    88.226  132.30
  25   0.6918     78.400  0.7897    78.420  137.88
  26   0.4364     85.770  0.4772    84.972  143.31
  27   0.4677     84.820  0.3802    87.924  148.77
  28   0.4267     86.540  0.3414    89.088  154.20
  29   0.4330     85.650  0.3238    89.664  159.65
  30   0.3918     86.910  0.3028    90.344  165.09
  31   0.4001     86.980  0.2949    90.528  170.51
  32   0.3977     87.430  0.2795    91.112  176.10
  33   0.3908     87.690  0.2738    91.174  181.53
  34   0.4479     86.430  0.2635    91.628  186.97
  35   1.5560     44.440  1.9913    60.294  192.41
  36   1.0404     65.400  1.2424    56.122  197.84
  37   0.8936     69.200  0.9046    69.508  203.29
  38   0.6319     78.880  0.7303    75.968  208.72
  39   0.5812     80.760  0.6044    80.424  214.31
  40   0.4982     83.530  0.5083    83.550  219.75
  41   0.4885     84.390  0.4311    85.762  225.20
  42   0.4376     85.710  0.3868    87.480  230.65
  43   0.4407     85.300  0.3629    88.252  236.10
  44   0.4445     85.730  0.4080    87.054  241.54
  45   0.7816     74.620  0.6952    82.966  247.10
  46   0.6703     77.620  1.0812    75.090  252.52
  47   0.5402     81.980  0.8765    78.456  257.94
  48   0.4477     85.260  0.4456    85.488  263.37
  49   0.4243     86.000  0.3737    87.730  268.82
  50   0.4188     85.970  0.3342    88.996  274.25
  51   0.4089     86.800  0.3088    89.878  279.70
  52   0.4009     86.920  0.2890    90.548  285.28
  53   0.4300     86.640  0.2707    91.190  290.73
  54   0.4273     86.960  0.2529    91.828  296.16
  55   0.3958     87.770  0.2463    92.042  301.61
  56   0.4137     86.930  0.2399    92.134  307.08
  57   0.4048     87.520  0.2242    92.646  312.52
  58   0.3984     87.830  0.2180    92.888  318.00
  59   0.4491     87.020  0.2101    93.166  323.57
  60   0.4009     88.310  0.2117    93.166  329.00
  61   0.3980     88.320  0.2079    93.312  334.42
  62   0.4185     87.580  0.1972    93.674  339.87
  63   0.4693     87.050  0.1873    93.968  345.32
  64   0.3849     88.590  0.1869    94.008  350.79
  65   0.4218     88.480  0.1826    94.074  356.40
  66   0.4269     88.140  0.1846    94.076  361.82
  67   0.6360     83.890  0.1965    94.374  367.26
  68   1.2622     55.500  2.2371    41.636  372.71
  69   0.7000     75.780  0.9322    67.714  378.13
  70   0.5731     82.600  0.5615    81.442  383.57
  71   0.4525     85.840  0.4536    85.260  389.01
  72   0.4989     84.450  0.3423    88.878  394.47
  73   0.3945     87.860  0.2728    90.996  400.06
  74   0.4122     87.610  0.2430    92.130  405.53
  75   0.4288     87.260  0.2159    92.892  411.00
  76   0.4580     86.590  0.2040    93.162  416.45
  77   0.4044     88.200  0.1889    93.932  421.89
  78   0.4391     88.230  0.1768    94.112  427.33
  79   0.4132     88.570  0.1717    94.424  432.76
  80   0.4516     88.110  0.1627    94.750  438.20
  81   0.4224     88.560  0.1571    95.038  443.64
  82   0.4886     87.730  0.1537    95.094  449.08
  83   0.4270     88.580  0.1477    95.198  454.52
  84   0.4424     88.480  0.1478    95.354  459.94
  85   0.4667     88.350  0.1393    95.534  465.42
  86   0.4210     88.290  0.1406    95.500  470.87
  87   0.4303     88.450  0.1375    95.632  476.31
  88   0.4864     87.480  0.1347    95.704  481.76
  89   0.4616     88.040  0.1423    95.488  487.21
  90   0.4463     88.370  0.1350    95.668  492.68
