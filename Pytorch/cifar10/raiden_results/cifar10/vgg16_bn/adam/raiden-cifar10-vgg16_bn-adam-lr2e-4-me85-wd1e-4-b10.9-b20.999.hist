Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7606     29.020  2.2925    17.452  7.09
   2   1.3810     47.600  1.5920    37.974  12.63
   3   1.1414     59.340  1.2897    52.954  18.04
   4   1.0190     65.340  1.0560    63.218  23.45
   5   0.9273     69.310  0.8924    69.966  28.86
   6   0.8318     70.990  0.7948    73.436  34.30
   7   0.7191     75.930  0.7086    76.660  39.72
   8   0.6322     79.410  0.6575    78.564  45.12
   9   0.6332     79.400  0.6066    80.236  50.54
  10   0.6820     77.520  0.5589    81.764  55.97
  11   0.5915     79.780  0.5232    82.828  61.40
  12   0.5540     81.680  0.4981    83.968  66.82
  13   0.6029     80.190  0.4681    84.828  72.26
  14   0.5412     81.700  0.4432    85.766  77.71
  15   0.5322     82.000  0.4179    86.582  83.14
  16   0.5030     83.650  0.4057    86.752  88.55
  17   0.5736     82.100  0.3810    87.638  94.12
  18   0.4594     84.970  0.3711    87.996  99.55
  19   0.5160     83.700  0.3521    88.552  104.97
  20   0.4439     85.220  0.3318    89.276  110.40
  21   0.4723     84.660  0.3173    89.782  115.80
  22   0.4574     84.970  0.3192    89.792  121.21
  23   0.4652     85.310  0.3038    90.172  126.64
  24   0.5290     83.040  0.2905    90.482  132.19
  25   0.4898     84.730  0.2816    90.944  137.63
  26   0.4297     86.340  0.2686    91.306  143.06
  27   0.4701     85.550  0.2471    91.950  148.47
  28   0.4381     86.280  0.2417    92.248  153.89
  29   0.4154     86.940  0.2770    91.216  159.32
  30   0.4347     85.890  0.2294    92.706  164.73
  31   0.4528     86.140  0.2166    92.952  170.15
  32   0.3948     87.250  0.2119    93.116  175.56
  33   0.5016     85.960  0.2059    93.398  180.96
  34   0.4510     85.710  0.2638    91.722  186.40
  35   0.4386     86.640  0.2570    91.966  191.82
  36   0.3803     87.870  0.1916    93.816  197.24
  37   0.4394     87.610  0.1746    94.462  202.67
  38   0.4413     87.220  0.1677    94.548  208.26
  39   0.4865     86.390  0.1635    94.774  213.69
  40   0.4123     87.740  0.1621    94.654  219.11
  41   0.4112     88.020  0.1539    94.962  224.55
  42   0.4599     87.590  0.1517    95.116  230.00
  43   0.4285     87.710  0.1417    95.444  235.41
  44   0.4445     87.670  0.1449    95.330  240.83
  45   0.5355     86.790  0.1452    95.320  246.39
  46   0.4374     88.320  0.1471    95.334  251.82
  47   0.5267     86.410  0.1369    95.520  257.23
  48   1.5682     77.570  0.2153    93.644  262.66
  49   0.4109     88.210  0.1991    93.706  268.11
  50   0.4689     87.640  0.1254    95.902  273.52
  51   0.4915     87.300  0.1191    96.176  278.94
  52   0.4743     88.000  0.1063    96.558  284.45
  53   0.4521     88.620  0.1113    96.430  289.88
  54   0.5042     87.750  0.1118    96.370  295.28
  55   0.4538     88.380  0.1123    96.376  300.71
  56   0.4301     88.030  0.1073    96.466  306.11
  57   0.4887     87.450  0.0997    96.710  311.54
  58   0.5109     87.450  0.1004    96.754  317.11
  59   0.4633     89.020  0.1039    96.656  322.54
  60   0.4488     89.160  0.0981    96.836  327.99
  61   0.5106     87.730  0.0969    96.904  333.39
  62   0.4599     88.750  0.0959    96.828  338.81
  63   0.4903     88.160  0.0908    97.076  344.26
  64   0.4410     88.890  0.0930    97.100  349.69
  65   0.4802     88.160  0.0885    97.118  355.09
  66   0.5440     84.950  0.2252    94.116  360.68
  67   0.4875     88.090  0.1330    95.646  366.10
  68   0.4827     88.810  0.0917    96.978  371.53
  69   0.4799     89.060  0.0769    97.460  376.97
  70   0.4968     88.540  0.0782    97.516  382.40
  71   0.4718     88.730  0.0754    97.602  387.81
  72   0.4641     89.130  0.0760    97.546  393.27
  73   0.4902     88.350  0.0723    97.610  398.81
  74   0.5401     88.240  0.0744    97.658  404.25
  75   0.4372     89.150  0.0757    97.530  409.70
  76   0.4940     88.340  0.0711    97.708  415.11
  77   0.5172     88.280  0.0737    97.592  420.52
  78   0.5118     88.490  0.0700    97.754  425.94
  79   0.5077     88.710  0.0711    97.666  431.39
  80   0.4667     89.420  0.0697    97.732  436.93
  81   0.4615     89.170  0.0682    97.864  442.38
  82   0.4674     88.720  0.0720    97.694  447.81
  83   0.5457     87.890  0.0694    97.858  453.24
  84   0.5808     87.390  0.0950    97.138  458.67
  85   0.5024     88.890  0.0778    97.546  464.11
