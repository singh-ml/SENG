Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0220     18.580  2.6835    14.198  7.05
   2   1.7029     32.510  1.8568    24.550  12.49
   3   1.3799     48.500  1.5694    38.262  17.90
   4   1.2229     56.200  1.3066    52.400  23.33
   5   1.0664     61.850  1.1172    61.140  28.76
   6   1.0579     64.410  1.0489    64.322  34.35
   7   12.7919     30.190  0.9168    69.144  39.77
   8   0.8305     71.480  0.8481    71.404  45.23
   9   0.9021     70.820  0.7856    74.144  50.66
  10   10.6172     48.570  0.8614    72.846  56.10
  11   0.7303     74.970  0.7823    74.716  61.52
  12   0.6733     78.090  0.6344    79.180  66.94
  13   0.5941     80.650  0.6952    78.150  72.48
  14   0.6614     78.370  0.6618    79.008  77.91
  15   0.6401     79.530  0.5627    81.774  83.36
  16   0.9896     69.190  0.7158    79.346  88.79
  17   0.6227     80.680  0.5984    80.988  94.22
  18   1.8048     72.600  0.5401    82.838  99.66
  19   0.6489     78.690  0.5299    82.810  105.09
  20   0.5507     82.630  0.4712    84.746  110.67
  21   0.5095     83.170  0.5384    83.664  116.09
  22   0.5559     82.760  0.4332    86.038  121.54
  23   0.5757     81.940  0.4215    86.260  126.96
  24   0.5046     84.190  0.5189    84.074  132.40
  25   0.5042     84.070  0.3925    87.356  137.82
  26   0.4559     85.560  0.3771    87.732  143.28
  27   0.4935     84.500  0.3727    88.192  148.87
  28   0.5121     83.770  0.3561    88.738  154.31
  29   0.5438     83.730  0.3600    88.544  159.73
  30   0.5879     82.890  0.3349    89.178  165.17
  31   0.4648     85.550  0.3276    89.604  170.62
  32   0.4975     85.000  0.3195    89.912  176.04
  33   0.4319     86.750  0.3051    90.332  181.50
  34   0.4901     84.800  0.2988    90.514  186.97
  35   0.4953     85.890  0.2838    90.718  192.39
  36   0.4440     86.800  0.2782    91.208  197.84
  37   0.4779     85.660  0.2706    91.366  203.29
  38   0.4712     86.120  0.2662    91.500  208.74
  39   0.4145     87.270  0.2579    91.908  214.18
  40   0.4486     86.770  0.2490    92.152  219.72
  41   0.4142     87.530  0.2492    92.098  225.18
  42   0.5979     83.860  0.2388    92.420  230.61
  43   0.4519     86.870  0.2413    92.386  236.05
  44   0.4937     86.640  0.2264    92.824  241.50
  45   0.4784     86.540  0.2263    92.856  246.94
  46   0.4263     87.950  0.2196    93.024  252.37
  47   0.5350     85.940  0.2101    93.312  257.91
  48   0.4537     86.750  0.2069    93.422  263.35
  49   0.3972     88.460  0.2111    93.418  268.78
  50   0.4152     88.690  0.1960    93.816  274.26
  51   0.4905     86.290  0.1977    93.670  279.71
  52   0.5875     84.050  0.1957    93.912  285.14
  53   0.4642     86.770  0.1901    94.006  290.58
  54   0.4011     88.770  0.1860    94.234  296.17
  55   0.4695     87.290  0.1893    94.112  301.62
  56   0.6271     84.700  0.1813    94.226  307.07
  57   0.4173     88.310  0.1788    94.422  312.51
  58   0.4633     87.510  0.1752    94.482  317.97
  59   0.4098     88.510  0.1751    94.612  323.41
  60   0.4214     88.970  0.1723    94.592  328.95
  61   0.4385     87.640  0.1735    94.616  334.40
  62   0.4039     89.020  0.1660    94.858  339.83
  63   0.4224     88.620  0.1642    94.830  345.25
  64   0.4403     88.510  0.1600    94.924  350.68
  65   0.4077     89.200  0.1614    94.964  356.14
  66   0.4542     88.220  0.1543    95.222  361.58
  67   0.4438     88.670  0.1540    95.114  367.16
  68   0.4605     88.670  0.1566    95.142  372.65
  69   0.4307     87.920  0.1576    95.168  378.08
  70   0.4306     88.940  0.1509    95.300  383.52
  71   0.4119     88.900  0.1459    95.408  388.96
  72   0.5030     87.690  0.1428    95.566  394.40
  73   0.4136     89.330  0.1507    95.370  399.82
  74   0.4024     89.200  0.1413    95.574  405.38
  75   0.4341     88.910  0.1373    95.730  410.82
  76   0.4198     88.830  0.1433    95.408  416.26
  77   0.4869     87.840  0.1393    95.686  421.68
  78   0.4756     88.270  0.1402    95.604  427.12
  79   0.4416     88.460  0.1390    95.704  432.55
  80   0.4380     88.840  0.1378    95.796  438.10
  81   0.4339     89.100  0.1326    95.762  443.58
  82   0.4660     89.030  0.1336    95.772  449.04
  83   0.4242     89.320  0.1370    95.658  454.47
  84   0.4539     88.450  0.1244    96.138  459.92
  85   0.4265     89.380  0.1338    95.850  465.36
  86   0.4161     89.510  0.1285    96.014  470.81
  87   0.4207     89.320  0.1279    95.920  476.36
  88   0.3936     89.880  0.1264    96.000  481.79
  89   0.4295     88.810  0.1338    95.912  487.25
  90   0.3989     89.850  0.1261    96.074  492.66
