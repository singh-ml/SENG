Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3030     10.000  28.0409     9.982  7.11
   2   2.3026     10.000  2.6834     9.928  12.64
   3   2.3026      9.950  2.5525     9.936  18.07
   4   2.3029     10.000  2.4639     9.904  23.48
   5   2.3708     10.080  2.6257     9.894  28.88
   6   2.3085     10.030  2.8917     9.692  34.30
   7   2.7211     10.200  3.4509    10.106  39.70
   8   10.9960     10.620  3.9863    10.290  45.25
   9   3.2315     11.200  3.3837    10.560  50.65
  10   3.2884     12.040  2.9810    11.122  56.07
  11   2.1735     16.500  2.4649    13.086  61.47
  12   1.9466     21.890  2.1963    20.128  66.86
  13   1.9079     24.610  2.0534    21.680  72.28
  14   2.0056     27.610  1.9500    24.474  77.71
  15   4.4713     30.570  1.9086    28.926  83.23
  16   1.6089     35.950  1.8143    31.244  88.61
  17   1.5376     39.780  1.6154    36.296  94.02
  18   1.4973     47.180  1.4729    43.552  99.45
  19   1.3883     49.230  1.3924    48.346  104.84
  20   1.4069     49.820  1.4136    48.528  110.24
  21   1.6752     44.550  1.5986    45.758  115.82
  22   1.4058     48.700  1.5313    45.794  121.21
  23   1.7881     38.760  1.7756    40.698  126.60
  24   1.4211     45.590  1.5598    40.326  132.02
  25   1.4746     50.210  1.4525    46.996  137.41
  26   1.4715     46.480  1.4068    50.734  142.84
  27   1.4439     47.580  1.6183    43.320  148.26
  28   1.4091     49.280  1.3974    49.206  153.65
  29   1.3502     51.850  1.4412    48.948  159.17
  30   1.1664     59.610  1.2832    53.318  164.58
  31   1.2062     57.280  1.2741    55.254  169.99
  32   1.1048     59.960  1.2371    56.262  175.39
  33   1.1187     63.000  1.0840    62.084  180.84
  34   0.9972     64.600  1.1143    61.180  186.24
  35   0.9064     68.900  0.9669    66.090  191.80
  36   1.5614     50.310  1.2285    67.398  197.22
  37   1.2325     57.790  1.3105    52.694  202.64
  38   1.0256     64.710  1.0501    63.114  208.03
  39   0.8669     70.240  0.9323    67.654  213.42
  40   0.8616     71.010  0.8622    70.330  218.81
  41   0.7992     73.450  0.8145    72.414  224.20
  42   0.7831     74.850  0.7667    74.374  229.73
  43   0.7947     74.790  0.7332    75.810  235.12
  44   0.6902     77.560  0.7018    76.702  240.50
  45   0.7906     75.670  0.6733    78.100  245.93
  46   0.7134     77.750  0.6416    79.264  251.33
  47   0.6554     79.290  0.6225    80.010  256.74
  48   0.6576     79.750  0.6145    80.322  262.17
  49   0.6471     79.530  0.6095    80.578  267.59
  50   0.6111     81.100  0.5875    81.444  273.16
  51   0.6315     80.610  0.5800    81.666  278.54
  52   0.6845     79.240  0.5702    81.934  283.95
  53   0.6260     81.580  0.5611    82.226  289.35
  54   0.6077     81.280  0.5550    82.410  294.77
  55   0.5700     81.700  0.5512    82.724  300.20
  56   0.6563     80.220  0.5487    82.696  305.75
  57   0.5707     82.150  0.5427    82.982  311.17
  58   0.5651     82.790  0.5320    83.370  316.60
  59   0.6058     81.290  0.5273    83.464  322.00
  60   0.5659     82.110  0.5219    83.534  327.39
  61   0.6037     81.370  0.5100    84.062  332.81
  62   0.5408     83.050  0.5025    84.278  338.21
  63   0.5259     83.530  0.5091    84.062  343.78
  64   0.6043     82.300  0.5120    84.006  349.18
  65   0.5286     83.500  0.4990    84.304  354.61
  66   0.5552     82.490  0.4949    84.616  360.03
  67   0.5713     83.000  0.4966    84.664  365.46
  68   0.5966     82.440  0.4956    84.368  370.88
  69   0.5530     83.330  0.4841    84.882  376.30
  70   0.5332     83.270  0.4882    84.702  381.70
  71   0.5970     82.020  0.4720    85.184  387.26
  72   0.5452     83.140  0.4774    85.212  392.67
  73   0.5207     83.650  0.4798    84.938  398.06
  74   0.5141     84.270  0.4767    85.116  403.45
  75   0.5477     83.290  0.4704    85.344  408.87
  76   0.5155     84.160  0.4781    85.062  414.30
  77   0.6037     81.230  0.4733    85.230  419.69
  78   0.5422     84.010  0.4701    85.430  425.25
  79   0.5698     83.610  0.4673    85.428  430.64
  80   0.6004     81.610  0.4705    85.442  436.08
  81   0.5237     83.680  0.4688    85.372  441.50
  82   0.6315     82.110  0.4734    85.240  446.93
  83   0.5434     83.540  0.4599    85.666  452.32
  84   0.5098     84.220  0.4703    85.428  457.73
  85   0.5481     83.300  0.4570    85.768  463.26
  86   0.5866     82.850  0.4633    85.778  468.66
  87   0.5356     83.610  0.4595    85.642  474.06
  88   0.5376     83.490  0.4593    85.722  479.47
  89   0.5910     83.130  0.4628    85.684  484.89
  90   0.5173     84.340  0.4622    85.528  490.31
