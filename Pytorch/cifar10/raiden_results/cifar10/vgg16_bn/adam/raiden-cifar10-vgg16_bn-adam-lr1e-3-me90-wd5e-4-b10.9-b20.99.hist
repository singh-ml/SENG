Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2763     12.570  3.3567    10.876  7.03
   2   2.0682     21.850  2.1505    16.794  12.42
   3   1.9589     25.470  1.8980    23.490  17.95
   4   1.6077     35.650  1.7833    30.430  23.37
   5   1.5740     38.180  1.6359    35.926  28.77
   6   2.6458     28.440  1.6285    40.366  34.18
   7   1.3529     48.110  1.6924    43.368  39.60
   8   1.9969     38.200  1.6085    45.308  45.01
   9   1.2351     54.980  1.3246    53.108  50.43
  10   1.0541     63.440  1.1181    60.848  55.85
  11   1.0330     64.510  1.0256    64.876  61.29
  12   0.9142     67.770  0.9147    68.732  66.69
  13   0.8722     72.000  0.8422    71.548  72.11
  14   0.8980     71.410  0.7864    74.292  77.55
  15   0.9207     71.010  0.7405    75.974  82.95
  16   0.7165     77.240  0.6792    78.038  88.40
  17   0.6781     78.160  0.6505    79.198  93.93
  18   3.7654     63.190  0.6508    79.838  99.35
  19   0.6089     80.210  0.7447    77.066  104.80
  20   0.6152     80.790  0.5616    82.424  110.20
  21   0.6446     79.980  0.5972    81.398  115.66
  22   1.0933     70.510  0.6073    81.990  121.09
  23   0.6425     81.390  0.5690    82.092  126.49
  24   0.7032     80.170  0.4853    84.724  131.89
  25   0.6061     81.880  0.4820    85.036  137.31
  26   0.6177     81.800  0.4692    85.430  142.73
  27   0.6547     80.300  0.4516    85.992  148.15
  28   0.6006     81.910  0.4440    86.308  153.56
  29   0.5125     84.260  0.4317    86.666  158.97
  30   0.5489     84.130  0.4225    86.756  164.41
  31   0.5204     84.440  0.4041    87.500  169.97
  32   0.4941     84.980  0.3995    87.646  175.41
  33   0.5276     85.290  0.3833    88.258  180.84
  34   0.4826     85.670  0.3806    88.368  186.26
  35   0.5716     83.060  0.3698    88.674  191.72
  36   0.4891     85.350  0.3618    89.004  197.16
  37   0.5233     84.080  0.3419    89.320  202.57
  38   0.6768     80.620  0.3439    89.384  208.11
  39   0.5338     84.410  0.3317    89.858  213.55
  40   0.5633     83.250  0.3298    89.794  218.96
  41   0.4685     85.930  0.3217    89.944  224.43
  42   0.4553     86.630  0.3202    90.298  229.84
  43   0.6230     83.690  0.3136    90.488  235.27
  44   0.4508     86.760  0.3088    90.430  240.68
  45   0.4764     86.070  0.3077    90.624  246.26
  46   0.4718     86.600  0.2918    91.068  251.71
  47   0.4439     87.370  0.2911    91.044  257.15
  48   0.4813     86.410  0.2852    91.384  262.61
  49   0.6319     83.480  0.2889    91.194  268.02
  50   0.6314     83.850  0.2811    91.256  273.44
  51   0.5913     83.220  0.2782    91.524  278.88
  52   0.4971     85.340  0.2810    91.536  284.47
  53   0.4303     87.570  0.2732    91.520  289.89
  54   0.4764     86.660  0.2669    91.808  295.33
  55   0.4476     87.050  0.2690    91.620  300.76
  56   0.5208     85.540  0.2673    91.856  306.20
  57   0.4742     87.040  0.2581    92.118  311.61
  58   0.5166     86.430  0.2564    92.130  317.01
  59   0.4506     87.870  0.2557    92.312  322.55
  60   0.4829     86.710  0.2600    92.146  328.00
  61   0.4143     88.450  0.2503    92.316  333.43
  62   0.5124     85.850  0.2462    92.594  338.83
  63   0.4053     88.810  0.2459    92.380  344.25
  64   0.4982     86.750  0.2463    92.512  349.65
  65   0.4839     85.770  0.2450    92.540  355.20
  66   0.4732     86.680  0.2347    92.710  360.64
  67   0.4427     87.390  0.2423    92.736  366.06
  68   0.4492     87.450  0.2366    92.894  371.48
  69   0.4049     88.180  0.2434    92.542  376.90
  70   0.4316     87.850  0.2421    92.648  382.32
  71   0.3942     88.720  0.2380    92.716  387.74
  72   0.4415     87.770  0.2265    93.050  393.32
  73   0.4649     87.370  0.2279    92.974  398.76
  74   0.4640     87.620  0.2313    92.796  404.17
  75   0.4337     87.790  0.2298    93.048  409.56
  76   0.4413     87.440  0.2233    93.140  414.99
  77   0.4081     88.050  0.2249    93.172  420.40
  78   0.4281     87.950  0.2256    93.196  425.83
  79   0.4385     87.710  0.2166    93.222  431.36
  80   0.4270     88.030  0.2246    93.144  436.80
  81   0.4419     88.050  0.2211    93.218  442.22
  82   0.4001     88.550  0.2216    93.280  447.63
  83   0.4616     88.560  0.2164    93.394  453.04
  84   0.4319     88.410  0.2216    93.326  458.45
  85   0.4235     88.040  0.2187    93.262  463.85
  86   0.4722     86.820  0.2127    93.614  469.38
  87   0.5163     87.300  0.2150    93.444  474.80
  88   0.4155     88.620  0.2162    93.560  480.19
  89   0.4879     86.970  0.2099    93.588  485.60
  90   0.4019     88.770  0.2078    93.754  491.05
