Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.3033     10.000  137.0756    10.286  7.02
   2   2.3032     10.000  4.4552    10.132  12.45
   3   2.3027     10.000  3.4735     9.930  17.90
   4   2.3030     10.000  2.7934     9.778  23.47
   5   2.3029     10.000  2.4718    10.172  28.91
   6   2.2960     11.300  2.5319    10.064  34.34
   7   2.3000     10.700  2.4381    10.358  39.77
   8   2.2851     10.920  2.3509    10.966  45.21
   9   2.3132     10.330  2.2594    14.404  50.68
  10   1.9141     20.940  1.9992    21.520  56.11
  11   1.8260     28.130  1.8844    26.004  61.57
  12   1.8781     33.050  1.7779    29.662  67.20
  13   1.5476     39.640  1.6036    36.946  72.64
  14   1.4458     48.910  1.4657    44.476  78.06
  15   1.3652     54.770  1.3046    53.088  83.50
  16   1.1936     60.190  1.1655    58.800  88.92
  17   1.4367     54.060  1.0760    62.714  94.36
  18   1.0020     64.960  1.0121    64.900  99.80
  19   1.1533     63.940  0.9471    67.660  105.36
  20   1.1164     67.570  0.9021    69.572  110.82
  21   0.8281     71.570  0.8568    71.580  116.28
  22   1.2158     62.780  0.8147    73.192  121.73
  23   0.8108     73.890  0.7966    73.974  127.15
  24   0.7657     75.600  0.7669    75.348  132.56
  25   0.8861     73.420  0.7568    75.658  138.03
  26   0.7421     76.460  0.7532    75.888  143.60
  27   0.9473     70.320  0.7282    76.908  149.05
  28   0.8814     73.020  0.7236    76.918  154.49
  29   0.6831     78.250  0.7053    77.190  159.92
  30   0.8286     74.700  0.6962    77.798  165.35
  31   0.8211     74.880  0.7060    77.596  170.78
  32   0.8340     74.500  0.7013    77.580  176.23
  33   0.7637     75.580  0.6947    77.888  181.83
  34   0.6954     78.160  0.6826    78.284  187.28
  35   0.7682     75.850  0.6981    78.150  192.73
  36   0.7319     76.710  0.6871    78.238  198.14
  37   0.7049     78.470  0.6702    78.842  203.58
  38   0.8296     77.690  0.6646    78.860  209.00
  39   1.3297     65.300  0.6583    79.000  214.43
  40   0.7984     77.030  0.6707    78.714  219.85
  41   1.2150     65.990  0.6602    79.162  225.42
  42   0.7861     76.280  0.6649    78.888  230.87
  43   0.7217     77.820  0.6529    79.350  236.33
  44   0.6911     78.980  0.6622    79.110  241.75
  45   0.7214     77.950  0.6539    79.730  247.20
  46   0.7072     77.230  0.6594    79.348  252.63
  47   0.6838     78.720  0.6481    79.728  258.04
  48   0.7188     78.700  0.6509    79.550  263.62
  49   0.8021     76.520  0.6357    80.130  269.07
  50   0.6719     79.490  0.6388    79.710  274.52
  51   0.6834     78.680  0.6447    79.774  279.96
  52   0.7129     78.780  0.6437    79.684  285.40
  53   1.6985     59.830  0.6369    80.008  290.83
  54   0.7430     77.070  0.6365    79.852  296.41
  55   0.7567     77.130  0.6323    80.058  301.88
  56   0.7092     77.700  0.6355    80.106  307.33
  57   0.7747     76.890  0.6343    80.014  312.78
  58   0.7207     78.420  0.6389    80.060  318.24
  59   0.6778     79.690  0.6332    79.992  323.67
  60   0.6969     78.610  0.6366    79.958  329.08
  61   0.7337     76.850  0.6288    80.382  334.54
  62   0.7125     77.520  0.6401    79.734  339.96
  63   0.6978     78.550  0.6313    80.078  345.41
  64   0.7298     77.770  0.6309    79.972  350.85
  65   0.6957     77.840  0.6224    80.542  356.27
  66   0.6289     79.880  0.6331    80.128  361.71
  67   0.6762     78.500  0.6222    80.532  367.18
  68   0.6470     79.220  0.6255    80.408  372.73
  69   0.7775     76.780  0.6293    80.360  378.14
  70   0.6159     80.810  0.6256    80.472  383.57
  71   0.6821     78.150  0.6147    80.698  389.01
  72   0.7144     78.790  0.6215    80.370  394.44
  73   0.6152     80.720  0.6230    80.564  399.89
  74   0.6350     79.950  0.6203    80.564  405.31
  75   0.6591     80.060  0.6163    80.770  410.89
  76   0.6518     80.810  0.6173    80.522  416.34
  77   0.7090     78.730  0.6140    80.846  421.76
  78   0.7960     77.150  0.6166    80.658  427.19
  79   0.6587     79.490  0.6171    80.348  432.63
  80   0.6577     80.310  0.6113    80.706  438.07
  81   0.7830     77.890  0.6089    80.716  443.63
  82   0.6531     79.620  0.6078    80.766  449.05
  83   0.7851     78.700  0.6140    80.670  454.53
  84   0.6216     80.780  0.6171    80.740  459.94
  85   0.7804     77.040  0.6049    80.964  465.39
