Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1614     16.530  3.7071    12.472  7.07
   2   1.9436     18.150  2.0736    17.658  12.45
   3   1.9059     20.980  1.9545    18.384  17.85
   4   1.8900     22.140  1.9079    19.908  23.26
   5   2.0646     17.920  1.8659    21.834  28.79
   6   1.7219     32.710  1.8113    25.122  34.22
   7   1.6667     33.580  1.7350    29.324  39.61
   8   1.9914     30.960  1.6535    32.456  45.03
   9   1.5039     42.960  1.5773    36.986  50.45
  10   1.4367     43.450  1.5089    40.982  55.87
  11   1.3575     45.570  1.4691    41.778  61.37
  12   2.4897     43.860  1.3744    45.428  66.76
  13   1.3672     45.380  1.3204    49.458  72.15
  14   33.8684     24.250  1.2258    56.550  77.57
  15   4.1183     52.310  1.2623    54.444  82.96
  16   1.0646     62.330  1.1255    60.228  88.39
  17   1.3896     60.810  1.0712    63.496  93.80
  18   1.0673     63.170  1.0961    63.292  99.20
  19   1.0524     63.340  1.0344    66.004  104.74
  20   1.1449     62.740  1.1602    63.088  110.16
  21   1.1505     64.590  0.9718    68.010  115.57
  22   1.1173     62.100  1.3019    55.762  120.97
  23   0.8696     70.640  0.9761    67.024  126.39
  24   1.0218     66.220  0.9281    69.706  131.81
  25   0.8100     72.740  1.0034    66.606  137.23
  26   0.7374     75.920  0.7833    73.872  142.78
  27   1.0248     64.410  0.7961    73.990  148.22
  28   0.7059     76.410  0.7784    74.104  153.63
  29   0.6701     77.680  0.6729    77.860  159.05
  30   0.7431     75.770  0.7567    75.974  164.47
  31   2.7466     51.040  0.8732    73.420  169.88
  32   0.9016     69.250  1.4076    61.504  175.29
  33   0.6846     77.350  0.7818    74.306  180.83
  34   0.6331     78.880  0.6634    78.212  186.26
  35   0.6041     80.410  0.6007    80.166  191.68
  36   13.1113     54.530  0.8726    76.094  197.09
  37   0.7877     76.730  0.9664    70.776  202.49
  38   0.6847     77.940  0.7395    77.054  207.90
  39   0.6674     78.400  0.7612    76.902  213.30
  40   1.1700     61.210  1.0153    69.510  218.84
  41   0.8351     72.210  0.8980    71.394  224.25
  42   0.6568     78.030  0.7351    76.242  229.66
  43   0.6293     79.140  0.6060    80.368  235.07
  44   3.9834     67.310  0.6616    80.062  240.46
  45   0.6077     80.700  0.7363    77.132  245.88
  46   0.5938     80.850  0.5928    81.050  251.41
  47   0.5387     82.450  0.5146    83.240  256.84
  48   0.5311     82.060  0.4733    84.536  262.25
  49   0.5280     83.030  0.4536    85.044  267.69
  50   0.5189     83.420  0.4437    85.592  273.09
  51   1.8193     60.750  1.5333    70.184  278.50
  52   0.7821     76.320  0.9637    71.038  283.89
  53   0.5869     80.840  0.6121    80.142  289.43
  54   0.5578     82.240  0.5111    83.250  294.85
  55   0.5028     84.000  0.4628    84.990  300.25
  56   0.4970     84.050  0.4339    85.948  305.65
  57   0.4766     84.630  0.4199    86.370  311.09
  58   0.4963     83.930  0.4035    86.874  316.51
  59   0.5290     83.630  0.5204    84.048  321.92
  60   0.4791     84.400  0.4120    86.610  327.34
  61   0.4529     85.310  0.3740    87.970  332.75
  62   0.4415     85.510  0.3560    88.572  338.18
  63   0.4760     85.340  0.3477    88.812  343.57
  64   0.4377     85.650  0.3354    89.344  349.00
  65   0.4797     85.410  0.3292    89.524  354.42
  66   0.4606     85.500  0.3226    89.558  359.83
  67   0.4374     85.950  0.3193    89.634  365.27
  68   0.5474     82.020  0.9162    76.224  370.83
  69   0.4487     85.600  0.4210    86.296  376.24
  70   0.4675     85.090  0.3538    88.594  381.65
  71   0.4307     86.330  0.3204    89.688  387.08
  72   0.4466     85.970  0.3010    90.294  392.52
  73   0.4255     87.130  0.2955    90.532  397.95
  74   0.4348     86.730  0.2775    91.074  403.50
  75   0.4579     85.940  0.2662    91.364  408.92
  76   0.4820     86.120  0.2602    91.698  414.33
  77   0.4614     87.190  0.2661    91.564  419.75
  78   0.5204     85.860  0.2585    91.816  425.18
  79   0.4486     86.850  0.2460    92.038  430.59
  80   0.4851     85.850  0.2365    92.372  436.04
  81   0.4495     86.810  0.2360    92.440  441.59
  82   0.4879     86.190  0.2349    92.598  447.02
  83   0.4329     87.950  0.2371    92.452  452.50
  84   0.4157     87.780  0.2201    92.988  457.92
  85   0.4572     87.180  0.2269    92.886  463.35
  86   10.7665     75.880  0.2554    92.356  468.77
  87   0.5125     83.740  0.7903    77.266  474.19
  88   0.4643     86.090  0.3617    88.416  479.74
  89   0.4459     87.200  0.2796    90.932  485.16
  90   0.4172     87.880  0.2381    92.362  490.58
