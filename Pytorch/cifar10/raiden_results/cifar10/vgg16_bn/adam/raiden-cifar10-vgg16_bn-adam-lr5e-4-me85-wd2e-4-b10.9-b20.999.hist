Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.0998     17.090  2.7694    12.396  7.27
   2   1.8611     24.830  1.9865    19.096  12.72
   3   1.6100     32.790  1.7884    26.076  18.14
   4   1.4765     39.640  1.5939    34.542  23.54
   5   1.4303     49.670  1.4306    42.398  28.93
   6   1.3851     51.560  1.2757    52.324  34.34
   7   1.2235     56.310  1.1027    60.780  39.87
   8   0.9782     65.160  1.0097    65.442  45.26
   9   0.8830     72.010  0.9369    68.864  50.66
  10   0.9286     70.910  0.8414    72.388  56.06
  11   0.9669     71.630  0.7552    75.616  61.50
  12   1.1665     61.320  1.2162    65.686  66.89
  13   0.7260     77.610  0.8641    71.132  72.29
  14   0.6805     78.630  0.6681    78.544  77.82
  15   0.6424     79.630  0.5963    80.932  83.23
  16   0.6562     80.600  0.6198    80.866  88.63
  17   0.5608     82.820  0.5573    82.586  94.05
  18   0.6385     79.150  0.5050    84.090  99.44
  19   0.5705     83.100  0.4834    84.824  104.85
  20   0.5194     83.640  0.4640    85.688  110.28
  21   0.5257     84.020  0.4426    85.918  115.82
  22   0.5962     81.770  0.4466    86.278  121.22
  23   0.4736     85.320  0.4698    85.540  126.64
  24   0.4784     85.280  0.3927    87.576  132.08
  25   0.4797     84.960  0.3733    88.170  137.48
  26   77.5983     22.030  0.4166    87.458  142.88
  27   0.5953     81.780  0.5205    83.912  148.29
  28   0.5831     81.850  0.5333    84.342  153.82
  29   0.5634     82.600  0.3952    87.424  159.21
  30   0.4488     85.910  0.3362    89.372  164.63
  31   0.4688     84.850  0.3105    90.206  170.04
  32   0.4053     87.030  0.2985    90.626  175.48
  33   0.3965     87.850  0.2884    90.814  180.91
  34   0.3871     87.760  0.2862    91.044  186.36
  35   0.4508     87.060  0.2763    91.424  191.77
  36   0.4319     86.310  0.2676    91.540  197.20
  37   0.4026     87.870  0.2600    91.892  202.60
  38   0.3899     88.300  0.2567    91.862  208.01
  39   0.3975     88.010  0.2452    92.232  213.43
  40   0.3934     88.180  0.2389    92.542  218.85
  41   1917.8799     10.300  0.5601    87.372  224.26
  42   0.7228     76.190  1.2337    59.372  229.78
  43   0.5711     82.450  0.5832    80.860  235.18
  44   0.4677     84.650  0.4240    86.286  240.58
  45   0.4495     85.980  0.3401    89.018  246.00
  46   0.3848     87.780  0.3092    90.170  251.41
  47   0.4529     87.210  0.3749    88.832  256.83
  48   0.4220     87.130  0.2536    91.996  262.38
  49   0.3805     88.940  0.2277    92.740  267.80
  50   0.3892     88.430  0.2151    93.148  273.22
  51   0.3682     89.020  0.2048    93.658  278.65
  52   0.4415     87.610  0.1975    93.690  284.05
  53   0.4583     87.540  0.1968    93.802  289.49
  54   0.3932     88.700  0.1916    93.926  294.90
  55   0.4118     88.050  0.1800    94.336  300.43
  56   0.4330     88.350  0.1773    94.402  305.84
  57   0.4273     88.350  0.1772    94.368  311.25
  58   0.4405     88.240  0.1688    94.690  316.68
  59   0.4576     87.730  0.1714    94.694  322.11
  60   0.4151     88.970  0.1650    94.768  327.54
  61   0.4656     88.660  0.1650    94.892  332.97
  62   0.4232     88.940  0.1643    94.824  338.44
  63   0.4253     88.300  0.1602    95.008  343.85
  64   0.4540     88.500  0.1552    95.048  349.28
  65   0.5190     87.530  0.1594    95.064  354.72
  66   0.4450     86.670  0.6034    83.092  360.15
  67   0.3886     88.400  0.2288    92.706  365.56
  68   0.3853     89.430  0.1793    94.256  370.98
  69   0.3904     88.910  0.1578    95.018  376.55
  70   0.4182     89.250  0.1430    95.492  381.99
  71   0.3906     89.470  0.1388    95.532  387.42
  72   0.4299     89.080  0.1316    95.906  392.83
  73   0.4451     89.190  0.1356    95.820  398.24
  74   0.4259     88.780  0.1310    95.854  403.69
  75   0.4409     89.250  0.1254    95.954  409.14
  76   0.4683     88.440  0.1234    96.126  414.68
  77   0.4559     88.650  0.1259    96.036  420.13
  78   0.4997     87.840  0.1292    95.948  425.58
  79   0.4097     88.930  0.1266    95.978  431.02
  80   0.4008     89.790  0.1223    96.162  436.44
  81   0.5091     87.380  0.1217    96.212  441.85
  82   0.3940     89.600  0.1237    96.242  447.26
  83   0.4427     87.650  0.3426    90.286  452.88
  84   0.3936     89.180  0.1845    94.042  458.31
  85   0.4308     88.630  0.1330    95.790  463.73
