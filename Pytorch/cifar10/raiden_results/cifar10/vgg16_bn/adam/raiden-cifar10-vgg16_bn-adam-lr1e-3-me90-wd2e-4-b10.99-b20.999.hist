Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2665     14.990  4.0114    10.960  7.24
   2   2.0820     20.740  2.2020    16.688  12.67
   3   1.9665     21.520  2.0756    19.328  18.10
   4   1.9171     21.620  1.9963    20.248  23.51
   5   1.8957     22.040  1.9571    21.000  28.91
   6   1.8753     23.840  1.9377    21.626  34.32
   7   1.8685     25.130  1.8918    23.092  39.75
   8   1.7683     28.350  1.8414    25.872  45.23
   9   1.8142     26.360  1.8241    27.092  50.64
  10   1.6987     32.250  1.7812    28.990  56.03
  11   1.6588     33.570  1.7310    31.506  61.46
  12   1.6714     33.600  1.7102    32.080  66.87
  13   1.6464     37.640  1.6650    34.956  72.28
  14   1.5639     38.800  1.6066    36.692  77.71
  15   1.5311     40.820  1.5671    38.566  83.24
  16   1.4299     42.520  1.5051    41.058  88.68
  17   1.4156     46.890  1.4243    43.838  94.09
  18   1.3180     50.860  1.3523    48.064  99.50
  19   1.3263     52.480  1.2921    52.032  104.90
  20   1.2078     56.980  1.1831    56.566  110.34
  21   1.1134     59.200  1.1352    59.128  115.76
  22   1.0558     62.580  1.0565    62.106  121.16
  23   0.9231     67.780  1.0057    64.394  126.69
  24   0.9413     67.780  0.9049    68.554  132.11
  25   0.8507     71.250  0.8543    70.938  137.54
  26   0.8054     73.870  0.7827    73.890  142.96
  27   0.7522     75.210  0.7672    74.498  148.38
  28   0.7148     77.240  0.7182    76.384  153.82
  29   0.6355     79.350  0.6733    78.254  159.22
  30   0.6248     79.930  0.6348    79.730  164.79
  31   0.6756     78.460  0.6300    79.836  170.22
  32   0.5878     81.240  0.6002    80.954  175.64
  33   0.6966     81.480  0.5467    82.702  181.08
  34   1.0528     69.100  0.8139    76.108  186.48
  35   0.7167     77.620  0.8251    74.086  191.89
  36   0.6532     80.310  0.6559    79.592  197.29
  37   0.6056     81.080  0.5682    82.160  202.86
  38   0.7318     77.230  0.7237    77.726  208.28
  39   0.5733     82.140  0.6123    80.956  213.69
  40   0.5857     82.430  0.5478    82.920  219.11
  41   0.5282     83.540  0.4911    84.590  224.51
  42   0.5024     84.240  0.4541    85.628  229.93
  43   0.4846     84.560  0.4231    86.602  235.34
  44   0.8927     75.730  0.5106    85.626  240.78
  45   0.7753     76.900  0.8869    74.982  246.34
  46   0.8186     75.850  0.6830    79.728  251.75
  47   0.6026     80.250  0.6700    79.126  257.19
  48   0.4950     83.880  0.5133    83.552  262.60
  49   0.4662     85.400  0.4469    85.604  268.02
  50   0.4434     85.620  0.4098    87.154  273.43
  51   0.4542     85.720  0.3793    87.978  278.84
  52   0.4327     86.450  0.3644    88.260  284.26
  53   0.4889     85.000  0.3719    88.232  289.84
  54   0.6468     80.390  0.5353    84.496  295.28
  55   0.5199     83.620  0.5052    84.246  300.72
  56   0.4619     85.430  0.4039    87.142  306.13
  57   0.4236     86.500  0.3614    88.642  311.56
  58   0.4244     86.980  0.3395    89.180  316.97
  59   0.4251     87.000  0.3226    89.690  322.39
  60   0.4115     86.580  0.3078    90.170  327.81
  61   0.4126     86.950  0.3062    90.134  333.34
  62   0.4422     86.610  0.2924    90.656  338.75
  63   0.4430     86.640  0.3071    90.518  344.15
  64   0.4477     86.850  0.3283    89.726  349.56
  65   0.4271     86.860  0.2940    90.738  354.95
  66   0.3981     87.990  0.2781    91.122  360.35
  67   0.4106     87.530  0.2681    91.532  365.76
  68   0.4435     86.760  0.2681    91.404  371.30
  69   0.4039     88.020  0.2607    91.814  376.73
  70   0.4060     87.930  0.2525    92.134  382.13
  71   0.4035     87.940  0.2503    92.230  387.56
  72   0.7607     84.930  0.3079    90.798  392.98
  73   0.5113     84.950  0.4061    87.556  398.38
  74   0.4150     86.920  0.3406    89.182  403.78
  75   0.4061     87.800  0.2772    91.102  409.17
  76   0.3997     88.000  0.2461    92.080  414.70
  77   0.3979     88.280  0.2333    92.712  420.11
  78   0.4014     88.550  0.2188    93.114  425.54
  79   0.4050     87.840  0.2159    93.104  430.97
  80   0.4336     87.840  0.2112    93.488  436.41
  81   0.4062     88.630  0.2154    93.262  441.81
  82   0.3991     88.460  0.2139    93.346  447.22
  83   0.4125     87.950  0.2063    93.608  452.75
  84   0.4406     87.750  0.2094    93.354  458.16
  85   0.4385     88.580  0.2009    93.778  463.60
  86   0.4038     88.280  0.2014    93.694  469.01
  87   0.4057     88.140  0.2061    93.640  474.41
  88   0.4730     86.890  0.1986    93.888  479.82
  89   0.4299     88.130  0.2001    93.762  485.23
  90   0.4265     88.790  0.1952    94.030  490.79
