Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2286     14.140  2.9342    11.454  7.08
   2   2.1879     15.140  2.2331    13.708  12.65
   3   2.0778     17.340  2.1692    15.368  18.10
   4   1.9880     20.880  2.0852    17.794  23.53
   5   1.9226     24.370  1.9471    21.208  28.98
   6   1.8493     24.810  1.8778    23.332  34.44
   7   1.8208     25.990  1.8277    25.366  39.88
   8   1.6823     30.960  1.7664    27.576  45.29
   9   1.6428     36.010  1.6759    31.808  50.84
  10   1.5200     39.630  1.5791    36.874  56.25
  11   1.4546     42.810  1.4748    42.598  61.68
  12   1.3676     48.800  1.3842    47.310  67.09
  13   1.1857     56.780  1.2757    53.132  72.52
  14   1.1213     59.580  1.1885    56.996  77.95
  15   0.9851     64.770  1.0754    61.294  83.37
  16   0.9429     66.720  0.9863    65.404  88.93
  17   0.8581     69.970  0.9107    68.462  94.40
  18   0.8401     72.190  0.8526    71.026  99.85
  19   0.8316     72.450  0.8275    72.248  105.28
  20   1.0949     71.550  0.8373    72.926  110.74
  21   0.7653     73.580  0.9203    70.474  116.18
  22   0.7666     75.070  0.7783    74.494  121.64
  23   0.6985     78.060  0.6805    77.594  127.20
  24   0.7215     76.410  0.7075    77.342  132.63
  25   0.6463     78.370  0.6937    77.828  138.06
  26   0.6077     79.980  0.6205    79.816  143.49
  27   0.5753     81.130  0.5645    81.540  148.92
  28   0.5387     82.140  0.5114    83.214  154.37
  29   0.5211     83.310  0.4858    84.034  159.96
  30   0.5153     83.550  0.4597    84.922  165.43
  31   0.5166     83.610  0.4567    85.228  170.84
  32   0.5069     84.190  0.4520    85.490  176.28
  33   0.4737     84.760  0.4065    86.860  181.75
  34   0.5386     83.040  0.4502    85.692  187.20
  35   0.7169     77.350  0.6669    80.150  192.64
  36   0.7725     76.140  0.6806    79.040  198.17
  37   0.9012     72.540  0.8456    75.060  203.64
  38   0.6548     79.430  0.7655    75.882  209.08
  39   0.5424     81.910  0.5476    82.074  214.50
  40   0.4961     83.970  0.4713    84.522  219.93
  41   0.4745     84.890  0.4264    85.958  225.37
  42   0.4295     86.110  0.3876    87.506  230.83
  43   0.4481     86.190  0.3561    88.164  236.36
  44   0.4406     86.030  0.3387    88.876  241.78
  45   0.4298     86.580  0.3244    89.300  247.24
  46   0.4267     86.700  0.3198    89.440  252.68
  47   0.9128     83.110  0.4540    86.928  258.12
  48   0.6606     78.200  0.8283    76.678  263.57
  49   1.5714     74.820  0.6234    80.528  269.02
  50   0.7818     77.480  0.8629    75.394  274.55
  51   0.5847     80.970  0.6155    80.376  279.97
  52   0.5745     81.460  0.5285    83.050  285.41
  53   0.4798     84.500  0.4621    85.090  290.85
  54   0.4277     86.040  0.3899    87.142  296.30
  55   0.4292     85.880  0.3549    88.398  301.75
  56   0.4251     86.270  0.3365    89.072  307.22
  57   0.4165     87.070  0.3106    89.588  312.77
  58   0.4204     87.190  0.2993    90.146  318.24
  59   0.4230     87.050  0.2856    90.582  323.67
  60   0.4293     87.100  0.2731    91.002  329.10
  61   0.4455     86.970  0.2699    91.106  334.53
  62   0.4272     86.920  0.2616    91.466  339.97
  63   0.4252     87.650  0.2530    91.842  345.50
  64   0.4062     87.490  0.2386    92.240  350.92
  65   0.4429     87.480  0.2346    92.414  356.34
  66   0.4444     87.530  0.2299    92.404  361.78
  67   0.4114     87.810  0.2245    92.724  367.20
  68   0.4043     88.250  0.2213    92.900  372.67
  69   0.4222     87.870  0.2105    93.246  378.10
  70   0.7249     84.220  0.2700    91.738  383.55
  71   0.5393     83.310  0.4449    86.494  389.10
  72   0.6529     78.610  0.8607    78.356  394.54
  73   0.5041     84.000  0.5162    83.602  399.99
  74   0.5298     82.720  0.4713    85.964  405.43
  75   0.4667     86.040  0.3840    87.568  410.86
  76   0.3969     87.680  0.2964    90.336  416.30
  77   0.3919     88.160  0.2387    92.196  421.77
  78   0.4071     88.100  0.2321    92.550  427.33
  79   0.4071     87.720  0.2601    91.588  432.75
  80   0.3967     88.440  0.2174    92.888  438.20
  81   0.4098     88.420  0.1998    93.468  443.62
  82   0.4270     88.170  0.1841    94.032  449.07
  83   0.3938     88.880  0.1742    94.440  454.53
  84   0.4208     88.240  0.1681    94.584  459.98
  85   0.4153     89.070  0.1611    94.858  465.53
  86   0.4100     88.640  0.1575    94.846  470.99
  87   0.4236     88.430  0.1564    94.864  476.43
  88   0.4267     88.790  0.1519    95.096  481.87
  89   0.4454     88.140  0.1482    95.294  487.32
  90   0.4563     87.970  0.1511    95.164  492.77
