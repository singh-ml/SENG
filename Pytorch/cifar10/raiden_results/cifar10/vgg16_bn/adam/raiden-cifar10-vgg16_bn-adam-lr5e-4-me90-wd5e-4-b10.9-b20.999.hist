Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2704     12.310  2.9249    11.258  7.02
   2   1.8910     21.080  2.0660    17.610  12.55
   3   1.8465     26.510  1.8247    24.870  17.97
   4   1.4737     42.100  1.6029    35.578  23.38
   5   1.4002     45.810  1.3756    47.768  28.80
   6   1.5883     53.180  1.1947    56.936  34.23
   7   0.9838     67.260  1.0417    63.838  39.66
   8   1.0533     64.430  0.9423    68.382  45.05
   9   0.9659     69.720  0.8780    71.856  50.52
  10   1.1238     67.660  0.8043    74.232  55.94
  11   3.7230     35.440  0.8489    73.760  61.33
  12   0.8099     73.260  0.9689    66.912  66.73
  13   0.7165     77.360  0.6984    77.756  72.12
  14   0.7405     75.060  0.6392    79.624  77.52
  15   0.5901     80.670  0.6303    80.412  82.94
  16   0.5922     80.940  0.5618    82.270  88.51
  17   0.6719     80.370  0.6163    81.468  93.91
  18   0.5863     82.070  0.5178    83.690  99.32
  19   0.5707     81.880  0.4833    84.922  104.74
  20   0.5880     80.150  0.5172    84.108  110.18
  21   0.5556     81.880  0.4536    85.854  115.59
  22   0.4859     84.180  0.4318    86.542  121.01
  23   0.7198     76.350  0.8361    74.480  126.54
  24   0.5829     81.490  0.5376    83.142  131.96
  25   0.4987     84.130  0.4346    86.334  137.39
  26   0.4422     85.510  0.4051    87.300  142.79
  27   0.4663     85.620  0.3856    88.064  148.22
  28   0.5174     84.050  0.3668    88.570  153.61
  29   0.4406     86.200  0.3474    88.982  159.00
  30   0.4051     87.150  0.3420    89.226  164.58
  31   0.5583     84.050  0.3336    89.436  170.01
  32   0.4670     85.300  0.3208    89.876  175.41
  33   0.4155     87.090  0.3129    90.042  180.82
  34   26.6985     46.080  0.3621    90.114  186.23
  35   0.8693     70.870  1.4116    52.050  191.64
  36   0.5724     81.480  0.6245    79.670  197.05
  37   0.4807     84.650  0.4400    85.946  202.58
  38   0.4529     85.940  0.3749    87.978  207.99
  39   0.5001     85.210  0.3388    89.352  213.43
  40   0.4533     86.270  0.3000    90.394  218.83
  41   0.4898     85.730  0.2886    90.792  224.25
  42   0.4306     86.990  0.2714    91.422  229.70
  43   0.4427     86.690  0.2705    91.466  235.12
  44   0.4078     87.940  0.2613    91.780  240.56
  45   0.5249     86.360  0.2502    92.058  245.98
  46   0.4289     86.980  0.2504    92.076  251.40
  47   0.4141     88.210  0.2385    92.484  256.83
  48   0.3983     88.270  0.2312    92.778  262.27
  49   0.4430     87.060  0.2315    92.630  267.72
  50   0.4469     87.500  0.2344    92.596  273.26
  51   0.5526     84.580  0.2293    92.800  278.68
  52   0.3948     88.340  0.2180    93.112  284.12
  53   0.4609     87.430  0.2155    93.140  289.54
  54   0.4944     87.470  0.2167    93.256  295.01
  55   0.4472     86.920  0.2178    93.120  300.43
  56   0.4345     88.140  0.2123    93.354  305.88
  57   0.4626     87.130  0.1999    93.794  311.42
  58   0.3899     88.590  0.1957    93.832  316.86
  59   0.4716     87.560  0.1905    93.920  322.27
  60   0.4465     87.370  0.1881    94.024  327.69
  61   0.4277     87.650  0.1855    94.052  333.14
  62   0.3770     89.080  0.1839    94.230  338.57
  63   0.3836     89.110  0.1871    94.126  344.03
  64   0.4549     87.630  0.1813    94.356  349.57
  65   0.4385     88.260  0.1835    94.256  355.00
  66   0.4452     88.370  0.1751    94.470  360.43
  67   0.4218     88.430  0.1767    94.410  365.85
  68   0.4889     87.340  0.1680    94.620  371.29
  69   0.5045     87.180  0.1630    95.016  376.72
  70   0.4473     88.610  0.1652    94.878  382.17
  71   0.4099     89.380  0.1687    94.734  387.73
  72   0.4210     88.330  0.1687    94.882  393.18
  73   0.4873     87.800  0.1632    94.894  398.61
  74   0.5005     87.390  0.1544    95.198  404.07
  75   0.4067     88.940  0.1582    94.958  409.51
  76   0.4882     87.510  0.1568    95.082  414.97
  77   0.4375     88.140  0.1544    95.188  420.40
  78   0.4445     88.410  0.1432    95.486  425.97
  79   0.4641     88.490  0.1443    95.548  431.40
  80   0.3852     89.520  0.1436    95.494  436.84
  81   0.3746     89.620  0.1483    95.386  442.28
  82   0.4675     88.290  0.1400    95.520  447.71
  83   0.4542     88.170  0.1410    95.586  453.15
  84   0.4392     88.520  0.1388    95.598  458.70
  85   0.5246     87.100  0.1423    95.674  464.16
  86   0.4558     89.180  0.1344    95.882  469.60
  87   0.4735     88.060  0.1325    95.780  475.04
  88   0.4397     88.910  0.1473    95.462  480.48
  89   0.3890     89.720  0.1353    95.706  485.91
  90   0.4936     87.830  0.1305    95.918  491.49
