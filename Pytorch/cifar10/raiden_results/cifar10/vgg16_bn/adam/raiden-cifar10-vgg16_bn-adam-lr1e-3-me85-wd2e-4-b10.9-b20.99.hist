Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1747     15.110  3.4884    12.830  7.20
   2   1.8149     26.890  1.9387    20.652  12.63
   3   1.7336     31.190  1.7676    26.816  18.08
   4   1.6028     38.430  1.6149    35.184  23.51
   5   1.4498     48.880  1.4558    44.156  28.94
   6   1.5568     48.840  1.3430    51.762  34.38
   7   1.4899     57.520  1.2692    56.240  39.92
   8   4.4009     51.800  1.1717    59.754  45.36
   9   1.2695     54.930  1.7422    48.988  50.78
  10   0.9873     65.090  1.1274    61.140  56.24
  11   1.5204     48.220  1.4321    56.710  61.66
  12   0.9147     67.420  1.0405    63.338  67.08
  13   0.8880     69.120  0.8745    69.450  72.51
  14   0.9130     69.690  0.9773    67.630  78.06
  15   0.8064     72.850  0.7976    72.864  83.51
  16   1.1151     63.500  0.9798    69.846  88.93
  17   8.5542     56.880  0.9284    70.650  94.38
  18   0.7940     73.080  1.0996    66.254  99.81
  19   1.1393     69.760  1.1941    65.834  105.23
  20   0.8450     74.820  0.8466    71.370  110.64
  21   0.7566     75.630  0.7036    75.934  116.24
  22   1.3711     62.190  0.8428    73.288  121.65
  23   0.6998     77.280  0.7415    75.750  127.10
  24   0.6296     78.850  0.6156    79.618  132.57
  25   0.7153     77.550  0.5943    80.460  138.02
  26   0.7315     76.170  0.5665    81.732  143.48
  27   0.5710     81.150  0.5296    82.974  148.89
  28   0.5668     81.720  0.5053    83.860  154.48
  29   0.6262     81.800  0.5028    84.004  159.94
  30   0.5154     83.700  0.4604    85.368  165.40
  31   0.6553     82.620  0.4411    85.878  170.83
  32   0.5700     81.890  0.4188    86.648  176.26
  33   0.5151     83.760  0.4120    86.892  181.68
  34   0.8948     74.490  0.3895    87.668  187.13
  35   0.5011     84.630  0.3796    87.862  192.68
  36   0.4547     86.000  0.3593    88.414  198.11
  37   0.4348     86.310  0.3754    88.152  203.55
  38   0.5699     83.180  0.3358    89.280  209.00
  39   0.5010     84.690  0.3276    89.438  214.46
  40   0.5523     83.720  0.3260    89.750  219.88
  41   0.4838     85.540  0.3135    90.136  225.29
  42   0.4469     86.840  0.3038    90.448  230.85
  43   0.4698     86.560  0.2985    90.552  236.26
  44   0.4605     86.540  0.2822    91.096  241.70
  45   0.4854     85.790  0.2758    91.386  247.15
  46   0.5833     83.920  0.2770    91.326  252.58
  47   0.4536     86.940  0.2755    91.438  258.02
  48   0.3962     88.180  0.2589    91.922  263.55
  49   0.5141     86.460  0.2532    92.144  268.98
  50   0.4373     87.190  0.2717    91.586  274.47
  51   0.4512     86.380  0.2483    92.168  279.92
  52   0.5308     85.610  0.2421    92.448  285.36
  53   0.5446     84.440  0.2408    92.608  290.79
  54   0.4228     87.720  0.2347    92.768  296.23
  55   0.6031     83.610  0.2281    92.930  301.67
  56   0.4515     86.940  0.2314    92.858  307.23
  57   0.4760     87.030  0.2223    93.156  312.69
  58   0.4878     87.140  0.2175    93.206  318.14
  59   0.4415     88.070  0.2230    93.306  323.57
  60   0.5945     85.070  0.2035    93.826  329.02
  61   0.4448     87.480  0.2129    93.454  334.46
  62   0.3977     88.880  0.2098    93.514  340.01
  63   0.4257     88.000  0.2042    93.766  345.45
  64   0.4714     87.570  0.1997    93.932  350.90
  65   0.4441     88.210  0.2012    93.802  356.32
  66   0.5036     87.240  0.1954    94.024  361.77
  67   0.4943     85.840  0.1978    93.886  367.23
  68   0.4093     88.640  0.1905    94.134  372.66
  69   0.4450     87.880  0.1898    94.144  378.28
  70   0.4131     89.020  0.1849    94.364  383.73
  71   0.5610     86.280  0.1825    94.436  389.16
  72   0.4881     86.730  0.1849    94.396  394.60
  73   0.3956     89.150  0.1788    94.496  400.02
  74   0.4815     87.680  0.1703    94.818  405.46
  75   0.5183     85.950  0.1773    94.522  410.90
  76   0.4458     88.430  0.1763    94.678  416.48
  77   0.4241     88.530  0.1705    94.736  421.95
  78   0.4738     88.290  0.1726    94.924  427.37
  79   0.4416     88.250  0.1729    94.716  432.83
  80   0.4619     88.130  0.1642    95.020  438.24
  81   0.4021     88.740  0.1657    94.960  443.69
  82   0.5007     87.340  0.1609    95.106  449.13
  83   0.4592     87.440  0.1661    94.940  454.75
  84   0.4603     88.030  0.1617    94.934  460.19
  85   0.4245     88.460  0.1612    95.126  465.60
