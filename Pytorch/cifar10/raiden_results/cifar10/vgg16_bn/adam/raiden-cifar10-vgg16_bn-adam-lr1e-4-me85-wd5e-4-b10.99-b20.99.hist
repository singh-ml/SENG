Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8067     25.510  2.1795    17.576  7.11
   2   1.5540     39.080  1.7464    29.942  12.65
   3   1.3346     49.960  1.4989    42.314  18.04
   4   1.1802     55.710  1.3237    50.460  23.48
   5   1.1133     60.180  1.1819    56.790  28.89
   6   0.9786     64.850  1.0523    62.348  34.31
   7   0.8953     68.330  0.9411    66.638  39.69
   8   0.8546     70.200  0.8613    69.752  45.11
   9   0.7795     73.120  0.7925    72.420  50.64
  10   0.7529     74.100  0.7359    74.530  56.07
  11   0.7140     75.820  0.6879    76.312  61.49
  12   0.6686     77.330  0.6527    77.680  66.89
  13   0.6451     78.520  0.6036    79.416  72.34
  14   0.6125     78.450  0.5721    80.548  77.74
  15   0.6152     79.530  0.5400    81.770  83.13
  16   0.6149     79.580  0.5131    82.538  88.58
  17   0.5874     80.970  0.4998    83.234  94.13
  18   0.5632     81.270  0.4704    84.006  99.56
  19   0.5642     81.520  0.4559    84.900  104.97
  20   0.5663     81.460  0.4402    85.104  110.39
  21   0.5901     81.400  0.4109    86.116  115.83
  22   0.5405     82.570  0.3936    86.606  121.26
  23   0.5360     82.900  0.3723    87.284  126.71
  24   0.5379     83.080  0.3564    87.768  132.26
  25   0.5554     82.950  0.3403    88.472  137.68
  26   0.5564     82.710  0.3325    88.974  143.08
  27   0.5033     83.800  0.3197    89.126  148.52
  28   0.5816     82.610  0.3111    89.440  153.97
  29   0.5310     83.300  0.3014    89.948  159.42
  30   0.5477     83.240  0.3009    90.010  164.96
  31   0.5246     84.110  0.2783    90.538  170.41
  32   0.4880     84.500  0.2751    90.726  175.83
  33   0.5283     85.040  0.2527    91.492  181.23
  34   0.4878     84.990  0.2468    91.592  186.65
  35   0.5329     84.300  0.2383    91.996  192.10
  36   0.4847     85.320  0.2407    91.912  197.51
  37   0.4867     85.410  0.2263    92.242  202.95
  38   0.4992     84.730  0.2269    92.292  208.40
  39   0.5320     85.350  0.2096    93.010  213.81
  40   0.5437     85.310  0.2047    93.114  219.20
  41   0.4870     85.840  0.1986    93.324  224.61
  42   0.4882     86.080  0.1932    93.436  230.04
  43   0.5156     85.330  0.1836    93.852  235.46
  44   0.5027     85.980  0.1817    93.832  241.01
  45   0.5575     85.220  0.1721    94.198  246.44
  46   0.5105     85.660  0.1675    94.232  251.87
  47   0.5008     86.050  0.1688    94.304  257.34
  48   0.5250     85.390  0.1667    94.430  262.76
  49   0.5039     86.330  0.1537    94.852  268.15
  50   0.4896     86.640  0.1537    94.930  273.57
  51   0.5000     86.400  0.1535    94.880  279.00
  52   0.5079     86.290  0.1429    95.196  284.54
  53   0.5236     85.950  0.1480    95.110  289.94
  54   0.5247     85.870  0.1419    95.294  295.35
  55   0.4929     86.300  0.1361    95.414  300.75
  56   0.5430     85.960  0.1295    95.746  306.19
  57   0.5220     86.340  0.1291    95.568  311.64
  58   0.5239     86.720  0.1218    95.856  317.17
  59   0.5056     86.730  0.1242    95.736  322.58
  60   0.5407     86.190  0.1190    95.944  328.00
  61   0.5107     86.730  0.1159    96.032  333.44
  62   0.5395     86.450  0.1131    96.316  338.84
  63   0.5579     86.390  0.1074    96.454  344.24
  64   0.5021     86.670  0.1139    96.150  349.66
  65   0.5175     86.690  0.1069    96.480  355.20
  66   0.4963     87.040  0.1061    96.406  360.61
  67   0.5452     86.900  0.1015    96.644  366.04
  68   0.5263     87.220  0.1005    96.592  371.46
  69   0.5256     86.940  0.1062    96.462  376.89
  70   0.5234     86.910  0.0993    96.764  382.30
  71   0.5427     86.530  0.0962    96.812  387.72
  72   0.5866     86.480  0.1033    96.628  393.25
  73   0.5811     87.240  0.0934    96.816  398.68
  74   0.5445     86.680  0.0889    97.120  404.09
  75   0.5191     87.010  0.0950    96.820  409.52
  76   0.4989     86.800  0.0969    96.748  414.94
  77   0.5277     86.490  0.0923    96.968  420.37
  78   0.5235     87.550  0.0912    96.942  425.79
  79   0.5179     87.080  0.0892    97.048  431.34
  80   0.5133     87.180  0.0882    97.044  436.78
  81   0.5361     86.740  0.0851    97.208  442.22
  82   0.5225     87.420  0.0836    97.288  447.62
  83   0.5875     86.750  0.0800    97.346  453.04
  84   0.5676     86.930  0.0797    97.444  458.46
  85   0.5329     87.400  0.0784    97.412  463.87
