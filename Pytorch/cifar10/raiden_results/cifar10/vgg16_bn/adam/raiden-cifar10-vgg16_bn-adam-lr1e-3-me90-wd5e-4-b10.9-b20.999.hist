Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2334     13.860  3.8863    11.368  6.99
   2   1.9528     19.020  2.1077    16.458  12.58
   3   1.8687     23.270  1.9336    20.246  18.01
   4   1.8159     27.290  1.8671    22.432  23.41
   5   1.7339     29.430  1.7809    26.588  28.82
   6   1.5574     36.860  1.6576    32.864  34.27
   7   1.6724     35.610  1.5748    36.774  39.69
   8   241.9940     10.620  1.5838    39.444  45.25
   9   1.4704     44.040  1.6516    36.906  50.63
  10   1.3312     46.640  1.5455    41.252  56.04
  11   1.2598     51.250  1.3098    49.246  61.46
  12   1.2407     52.810  1.3918    48.506  66.89
  13   1.5087     50.970  1.2500    55.726  72.29
  14   1.1382     61.510  1.1559    60.226  77.70
  15   1.0214     65.310  1.0403    64.554  83.26
  16   0.9253     69.120  0.8786    70.064  88.67
  17   1.0086     71.390  0.8124    72.850  94.11
  18   1.7421     58.360  1.2736    61.164  99.55
  19   0.8434     72.080  0.9176    70.678  104.97
  20   0.7061     76.680  0.7757    74.836  110.38
  21   0.8216     72.970  0.6869    77.918  115.81
  22   28.9944     14.950  0.7550    76.582  121.34
  23   0.8435     71.930  1.1444    61.266  126.80
  24   0.7406     76.340  0.7335    75.754  132.22
  25   0.6269     79.850  0.6424    79.264  137.65
  26   1.0088     71.310  0.5978    81.046  143.06
  27   1.0310     65.210  1.3277    58.360  148.47
  28   0.6562     78.730  0.8467    73.072  153.88
  29   0.6342     79.250  0.6333    79.746  159.43
  30   0.5980     80.770  0.5764    81.468  164.85
  31   2.0849     48.910  0.7701    76.584  170.28
  32   1.1944     60.620  0.9328    70.076  175.71
  33   0.5781     81.690  0.7187    76.678  181.10
  34   0.6248     80.200  0.5994    80.898  186.54
  35   0.5641     82.090  0.5638    82.274  191.95
  36   0.6195     81.050  0.5141    83.796  197.50
  37   0.6536     79.020  0.5163    83.786  202.95
  38   0.5230     83.380  0.4712    84.932  208.37
  39   0.6298     81.180  0.4663    85.212  213.78
  40   0.6287     81.530  0.4448    85.950  219.20
  41   0.5376     83.510  0.4348    86.292  224.61
  42   0.5561     83.180  0.4222    86.752  230.06
  43   1.1184     81.480  0.4184    87.012  235.63
  44   0.5403     83.610  0.5237    83.758  241.05
  45   0.5191     83.990  0.4131    87.208  246.48
  46   0.5537     83.070  0.3913    87.730  251.92
  47   0.5261     83.020  0.3931    87.782  257.34
  48   0.5462     84.140  0.3752    88.346  262.78
  49   0.4684     86.100  0.3789    88.286  268.34
  50   0.4884     84.880  0.3574    88.808  273.76
  51   0.4912     84.450  0.3595    88.818  279.22
  52   0.4384     86.330  0.3514    89.062  284.63
  53   0.5271     84.580  0.3390    89.404  290.08
  54   0.4808     85.500  0.3401    89.378  295.52
  55   0.5259     84.990  0.3275    89.822  300.96
  56   0.5492     86.300  0.3327    89.684  306.42
  57   0.4401     86.730  0.3323    89.708  311.86
  58   0.5074     84.680  0.3168    90.136  317.35
  59   0.6040     84.160  0.3111    90.260  322.80
  60   0.4756     85.710  0.3172    90.194  328.23
  61   0.5130     85.240  0.3165    90.186  333.64
  62   0.4384     86.460  0.3043    90.670  339.12
  63   0.4614     86.090  0.2997    90.770  344.71
  64   0.4605     86.370  0.2990    90.798  350.16
  65   0.4716     86.500  0.2933    90.934  355.62
  66   0.5201     84.310  0.2901    90.882  361.08
  67   0.4143     87.340  0.2846    91.174  366.53
  68   0.4392     87.210  0.2829    91.432  371.99
  69   0.4013     88.340  0.2796    91.322  377.47
  70   0.4637     86.410  0.2820    91.176  383.04
  71   0.5179     84.370  0.2761    91.474  388.50
  72   0.4552     87.270  0.2700    91.700  393.96
  73   0.4605     86.400  0.2747    91.666  399.40
  74   0.4101     87.870  0.2707    91.730  404.89
  75   0.5792     84.570  0.2607    92.056  410.33
  76   0.4319     88.270  0.2995    90.784  415.77
  77   0.4479     87.170  0.2666    91.842  421.19
  78   0.4445     87.340  0.2557    92.196  426.64
  79   0.4618     86.630  0.2525    92.198  432.06
  80   0.4547     87.280  0.2550    92.152  437.52
  81   0.4457     86.930  0.2437    92.406  442.93
  82   0.4394     87.730  0.2472    92.322  448.42
  83   0.4434     87.500  0.2528    92.186  453.97
  84   0.4870     86.770  0.2414    92.656  459.42
  85   0.4179     88.010  0.2407    92.638  464.84
  86   0.4332     87.820  0.2415    92.568  470.27
  87   0.3996     88.320  0.2402    92.668  475.70
  88   0.4839     86.840  0.2415    92.550  481.12
  89   0.4806     86.760  0.2353    92.878  486.55
  90   0.4422     87.160  0.2393    92.630  492.14
