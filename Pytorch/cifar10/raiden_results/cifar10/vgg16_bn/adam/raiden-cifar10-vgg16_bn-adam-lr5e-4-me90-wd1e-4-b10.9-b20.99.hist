Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.1620     15.150  2.7934    12.280  7.09
   2   1.7730     27.680  1.8933    23.454  12.53
   3   1.8192     38.860  1.6159    36.044  17.96
   4   1.2963     52.180  1.3520    48.068  23.37
   5   0.9375     65.400  1.1317    59.482  28.91
   6   1.0110     65.400  0.9622    67.250  34.36
   7   1.2179     69.060  0.8838    70.310  39.79
   8   0.7837     73.950  0.9311    69.812  45.19
   9   0.7439     75.630  0.7522    74.886  50.64
  10   0.9666     67.220  1.1653    69.696  56.06
  11   0.7006     77.690  0.7483    74.822  61.48
  12   0.6301     78.490  0.6350    78.970  67.04
  13   0.6998     77.130  0.5999    80.200  72.46
  14   116.4582     53.080  0.6717    79.296  77.88
  15   0.6808     77.510  0.9221    74.880  83.30
  16   1.3525     74.520  0.5891    80.790  88.74
  17   0.6086     80.600  0.6712    79.136  94.19
  18   0.5757     81.760  0.5180    83.028  99.62
  19   0.6118     80.700  0.4908    84.010  105.17
  20   0.6518     79.490  0.6360    80.588  110.58
  21   0.5723     82.320  0.4514    85.194  116.02
  22   0.8914     78.400  0.5188    83.830  121.46
  23   0.5110     84.030  0.5627    82.740  126.89
  24   0.6201     81.910  0.4076    86.740  132.31
  25   0.5531     82.330  0.3924    86.974  137.87
  26   0.7163     81.510  0.5331    84.982  143.29
  27   0.4775     84.580  0.5248    85.016  148.71
  28   0.4965     84.590  0.3567    88.222  154.17
  29   0.4982     84.900  0.3437    88.774  159.60
  30   0.4558     85.390  0.3362    89.108  165.03
  31   0.6335     81.370  0.7067    83.054  170.45
  32   0.5146     84.590  0.4024    86.944  175.91
  33   0.4599     85.990  0.3148    89.772  181.47
  34   0.5903     82.970  0.3010    90.230  186.89
  35   0.5307     84.200  0.3080    90.260  192.31
  36   0.4138     86.240  0.6360    85.754  197.75
  37   0.4460     86.380  0.2766    90.868  203.20
  38   0.4139     87.320  0.2674    91.300  208.65
  39   0.9457     85.090  0.2658    91.298  214.22
  40   0.4621     85.760  0.2785    91.094  219.66
  41   0.4732     86.010  0.2533    91.702  225.11
  42   0.4957     84.660  0.4815    87.052  230.53
  43   0.3981     87.750  0.2388    92.192  235.95
  44   0.4377     86.640  0.2268    92.582  241.39
  45   0.4423     86.450  0.2294    92.454  246.82
  46   0.4126     87.860  0.2139    93.096  252.38
  47   0.4811     86.680  0.2621    91.804  257.81
  48   0.3944     88.410  0.2082    93.244  263.24
  49   0.4778     86.510  0.1941    93.644  268.68
  50   0.4538     87.600  0.2205    93.652  274.10
  51   0.4568     87.430  0.2953    91.062  279.53
  52   0.4168     88.880  0.1689    94.366  284.97
  53   0.4338     87.360  0.1620    94.780  290.40
  54   0.3962     88.400  0.1702    94.350  295.95
  55   0.4734     87.380  0.1774    94.234  301.39
  56   0.4384     88.210  0.1713    94.394  306.81
  57   0.4425     88.390  0.1655    94.612  312.23
  58   0.4954     86.950  0.1652    94.592  317.66
  59   0.4405     88.110  0.1921    94.278  323.12
  60   0.5742     85.490  0.1466    95.174  328.68
  61   0.4230     88.570  0.2381    93.024  334.12
  62   0.4094     89.340  0.1449    95.342  339.55
  63   0.4722     87.750  0.1340    95.538  344.99
  64   0.4400     88.270  0.1426    95.396  350.44
  65   0.4175     88.550  0.1457    95.330  355.90
  66   0.5237     86.830  0.1339    95.716  361.36
  67   0.5183     87.140  0.1323    95.818  366.80
  68   0.5002     88.050  0.1264    95.896  372.36
  69   0.4803     87.790  0.1286    95.850  377.80
  70   0.4425     88.090  0.1222    96.068  383.23
  71   2.1584     84.730  0.1243    96.082  388.67
  72   0.4568     88.200  0.1235    96.052  394.10
  73   0.4990     87.940  0.1102    96.428  399.53
  74   0.4329     88.720  0.1155    96.318  405.00
  75   0.4387     88.700  0.1138    96.396  410.42
  76   0.5389     87.630  0.1147    96.364  416.03
  77   0.4557     89.300  0.1053    96.552  421.45
  78   0.4408     88.960  0.1023    96.756  426.88
  79   0.4779     88.660  0.1090    96.624  432.33
  80   0.4783     87.640  0.1056    96.692  437.75
  81   0.4735     88.250  0.1016    96.782  443.21
  82   0.4813     88.880  0.0995    96.820  448.66
  83   0.4343     89.380  0.0990    96.856  454.09
  84   0.5144     88.140  0.0982    96.994  459.52
  85   0.4740     89.480  0.0932    97.068  464.97
  86   0.4701     89.570  0.1016    96.854  470.40
  87   0.4733     89.460  0.0875    97.240  475.83
  88   0.5067     89.220  0.0913    97.134  481.24
  89   0.4384     89.850  0.0908    97.066  486.82
  90   0.4760     89.160  0.0851    97.338  492.27
