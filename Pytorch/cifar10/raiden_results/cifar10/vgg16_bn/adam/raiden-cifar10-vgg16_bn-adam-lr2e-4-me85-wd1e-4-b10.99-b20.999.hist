Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4197431296 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2276     13.920  2.5384    12.234  7.01
   2   1.9973     20.200  2.1317    15.634  12.46
   3   1.8462     23.980  1.9328    20.938  17.89
   4   1.7885     25.440  1.8388    25.480  23.42
   5   1.6512     33.710  1.7219    30.332  28.86
   6   1.4580     43.790  1.5843    36.810  34.28
   7   1.3502     48.900  1.4384    44.322  39.73
   8   1.2130     54.330  1.3122    51.048  45.14
   9   1.1339     58.460  1.1770    56.846  50.57
  10   1.0067     64.050  1.0626    61.478  56.00
  11   0.9248     66.760  0.9632    65.750  61.40
  12   0.8777     70.040  0.8757    69.296  66.93
  13   0.8321     72.250  0.8124    72.246  72.36
  14   0.7655     74.040  0.7573    74.440  77.80
  15   0.7666     74.620  0.6928    76.636  83.22
  16   0.7022     77.500  0.6552    78.164  88.66
  17   0.6373     79.140  0.6187    79.492  94.07
  18   0.6037     79.920  0.5655    81.398  99.60
  19   0.6154     80.010  0.5490    82.216  105.04
  20   0.5801     81.520  0.5197    83.094  110.45
  21   0.5402     82.570  0.5007    83.846  115.87
  22   0.5683     81.660  0.4706    84.710  121.30
  23   0.5050     83.960  0.4444    85.500  126.72
  24   0.5187     83.190  0.4218    86.300  132.12
  25   0.5315     82.620  0.4128    86.616  137.67
  26   0.4980     84.380  0.3890    87.234  143.10
  27   0.4953     83.660  0.3739    87.772  148.50
  28   0.5044     83.960  0.3735    87.880  153.91
  29   0.4676     84.700  0.3795    87.972  159.33
  30   0.4890     85.470  0.3550    88.742  164.76
  31   0.4924     84.970  0.3649    88.308  170.19
  32   0.4536     85.360  0.3259    89.570  175.87
  33   0.4765     85.700  0.3064    90.116  181.33
  34   0.4890     84.950  0.2886    90.618  186.75
  35   0.4471     85.940  0.2798    91.104  192.18
  36   0.4396     86.400  0.2649    91.448  197.62
  37   0.7562     83.470  0.3454    89.354  203.09
  38   0.5719     82.790  0.4449    86.780  208.53
  39   0.6111     80.410  0.4930    85.172  214.07
  40   0.6236     79.570  0.7216    78.942  219.49
  41   0.4778     84.380  0.4625    85.042  224.93
  42   0.4261     85.990  0.3599    88.292  230.37
  43   0.4246     86.430  0.2964    90.276  235.78
  44   0.4193     87.040  0.2697    91.068  241.22
  45   0.4051     87.340  0.2404    92.144  246.64
  46   0.4101     86.810  0.2303    92.440  252.23
  47   0.4136     87.130  0.2078    93.206  257.67
  48   0.4134     87.660  0.2041    93.254  263.09
  49   0.4402     87.780  0.1988    93.504  268.51
  50   0.4405     86.710  0.1904    93.748  273.94
  51   0.4308     87.150  0.1862    93.994  279.38
  52   0.4469     87.400  0.1899    93.830  284.96
  53   0.4367     87.680  0.1912    94.090  290.39
  54   0.4371     87.180  0.2385    92.528  295.81
  55   0.4223     87.530  0.1970    93.552  301.27
  56   0.4599     87.420  0.1744    94.270  306.71
  57   0.4199     87.930  0.1652    94.526  312.14
  58   0.4409     88.190  0.1523    95.160  317.56
  59   0.4385     87.660  0.1546    95.010  322.99
  60   0.4366     87.900  0.1451    95.272  328.41
  61   0.4667     87.610  0.1423    95.328  333.84
  62   0.4320     87.980  0.1365    95.574  339.27
  63   0.4717     87.710  0.1412    95.378  344.70
  64   0.4623     87.460  0.1566    94.882  350.13
  65   0.4686     87.100  0.1543    95.094  355.54
  66   0.5730     82.760  0.2993    92.000  361.09
  67   0.5200     83.970  0.4596    86.724  366.52
  68   0.4556     86.530  0.2617    91.438  371.94
  69   0.4445     88.100  0.1827    94.024  377.39
  70   0.4395     88.490  0.1421    95.338  382.84
  71   0.4307     88.700  0.1384    95.490  388.28
  72   0.4715     88.100  0.1192    96.084  393.69
  73   0.4584     88.500  0.1131    96.280  399.29
  74   0.4689     88.010  0.0988    96.742  404.74
  75   0.4308     89.020  0.0987    96.852  410.15
  76   0.4258     88.550  0.1013    96.754  415.61
  77   0.4909     87.820  0.0964    96.900  421.04
  78   0.5021     88.020  0.0986    96.868  426.47
  79   0.4656     88.290  0.0970    96.858  431.91
  80   0.5138     88.340  0.0955    96.754  437.35
  81   0.4604     88.760  0.0926    97.014  442.89
  82   0.4940     88.660  0.0923    96.970  448.33
  83   0.4917     88.290  0.0912    97.012  453.78
  84   0.4769     88.220  0.1042    96.640  459.19
  85   0.4908     88.020  0.0962    96.812  464.59
