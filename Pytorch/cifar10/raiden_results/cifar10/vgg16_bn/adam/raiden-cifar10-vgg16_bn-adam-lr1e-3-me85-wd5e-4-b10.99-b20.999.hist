Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2756     12.950  3.7703    11.370  7.09
   2   2.2628     13.510  2.2911    11.842  12.48
   3   2.2770     12.830  2.2804    12.120  18.04
   4   2.1677     15.980  2.2608    13.196  23.44
   5   2.1255     16.900  2.2122    14.766  28.86
   6   1.9941     20.170  2.1335    16.826  34.25
   7   1.9093     22.910  1.9944    20.190  39.64
   8   1.8634     23.280  1.9497    21.672  45.03
   9   1.8254     24.310  1.9068    23.026  50.48
  10   1.7892     27.440  1.8613    24.266  55.89
  11   1.7404     25.800  1.7985    26.916  61.29
  12   1.7077     32.110  1.6952    32.292  66.72
  13   1.5418     40.660  1.5915    37.562  72.13
  14   1.5180     44.220  1.5014    42.598  77.58
  15   1.3597     48.740  1.4087    47.786  82.99
  16   1.2549     56.490  1.2875    53.250  88.39
  17   2.0693     48.260  1.3306    53.764  93.95
  18   1.1880     57.710  1.3015    53.466  99.36
  19   1.2656     54.450  1.3257    53.890  104.77
  20   1.0371     62.160  1.1827    57.294  110.17
  21   0.9671     64.920  1.0407    63.118  115.57
  22   0.9709     66.060  0.9585    66.524  120.99
  23   0.8734     69.010  0.9812    66.350  126.40
  24   0.7906     72.660  0.8362    70.930  131.96
  25   0.7352     74.200  0.7747    73.494  137.36
  26   4.3756     54.990  0.9950    69.558  142.76
  27   1.3319     57.310  1.5355    54.062  148.17
  28   1.0784     62.330  1.3204    55.446  153.59
  29   0.8827     69.280  0.9719    66.170  158.99
  30   0.7546     74.110  0.8392    71.204  164.41
  31   0.6936     76.630  0.7447    74.886  170.02
  32   0.6960     77.270  0.6939    76.944  175.44
  33   0.6587     78.470  0.6546    78.318  180.88
  34   0.6511     78.480  0.6227    79.764  186.32
  35   0.6206     79.440  0.5954    80.432  191.75
  36   0.6454     78.720  0.5910    81.114  197.18
  37   0.6332     78.850  0.6607    78.832  202.59
  38   0.5999     80.560  0.5909    80.924  208.12
  39   0.5785     81.500  0.5391    82.634  213.54
  40   0.5499     82.440  0.5046    83.658  218.97
  41   0.5239     83.190  0.4925    83.932  224.38
  42   0.5377     83.330  0.4650    85.140  229.80
  43   0.5873     82.090  0.4859    84.588  235.20
  44   0.8495     72.360  0.8574    73.924  240.63
  45   0.6371     79.400  0.7051    77.126  246.14
  46   0.5783     81.820  0.5569    82.082  251.53
  47   0.5293     83.110  0.4942    83.910  256.93
  48   0.5029     84.320  0.4534    85.380  262.38
  49   0.5199     83.720  0.4337    85.926  267.80
  50   0.4755     85.220  0.4202    86.328  273.24
  51   0.4625     85.110  0.4034    86.918  278.79
  52   0.4942     84.830  0.3931    87.330  284.20
  53   0.4747     85.350  0.3925    87.514  289.64
  54   0.4761     85.270  0.3954    87.366  295.04
  55   0.4399     86.100  0.3771    88.028  300.45
  56   0.4812     84.860  0.3636    88.402  305.87
  57   0.4730     85.500  0.3582    88.510  311.30
  58   0.4680     85.410  0.3548    88.628  316.71
  59   0.4399     85.920  0.3395    89.120  322.26
  60   0.4625     85.970  0.3461    88.916  327.67
  61   0.4634     85.920  0.3352    89.176  333.06
  62   0.4503     86.380  0.3478    89.112  338.47
  63   0.4646     85.910  0.3894    87.606  343.90
  64   0.4348     86.440  0.3337    89.382  349.31
  65   0.4200     86.870  0.3135    90.098  354.88
  66   0.4601     86.640  0.3019    90.226  360.30
  67   0.4322     86.360  0.3066    90.232  365.69
  68   0.4399     86.580  0.2894    90.788  371.12
  69   0.4060     87.250  0.2919    90.878  376.53
  70   0.4219     87.490  0.2930    90.728  381.96
  71   0.4188     87.150  0.2805    91.016  387.39
  72   0.4445     87.050  0.2790    91.228  392.98
  73   0.4299     87.020  0.2847    90.930  398.38
  74   0.4784     86.460  0.2760    91.268  403.80
  75   0.4310     87.300  0.2768    91.328  409.19
  76   0.4609     86.080  0.2708    91.426  414.62
  77   0.4080     87.740  0.2776    91.122  420.02
  78   0.4353     87.340  0.2653    91.452  425.42
  79   0.4266     87.520  0.2803    91.180  430.96
  80   0.4179     87.430  0.2683    91.654  436.38
  81   0.4299     87.990  0.2615    91.798  441.79
  82   0.4131     88.130  0.2454    92.282  447.19
  83   0.4485     87.520  0.2593    91.916  452.60
  84   0.4125     88.170  0.2599    91.800  458.00
  85   0.4204     87.480  0.2545    92.098  463.40
