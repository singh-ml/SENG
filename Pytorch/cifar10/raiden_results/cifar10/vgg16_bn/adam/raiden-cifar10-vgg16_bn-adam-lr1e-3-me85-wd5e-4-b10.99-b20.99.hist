Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   2.2748     13.950  3.9368    11.840  7.19
   2   2.1654     15.740  2.2566    13.416  12.61
   3   2.1314     16.270  2.2197    14.528  18.06
   4   2.1002     16.800  2.1429    16.194  23.49
   5   1.8591     25.960  1.9395    21.868  28.94
   6   1.6969     32.180  1.7876    28.370  34.36
   7   1.5540     40.320  1.6449    35.698  39.92
   8   1.4505     46.710  1.4632    45.332  45.38
   9   1.2140     57.120  1.3051    52.668  50.85
  10   1.1491     61.460  1.1385    59.530  56.30
  11   0.9617     66.140  1.0118    64.564  61.75
  12   0.9193     69.320  0.9169    68.764  67.17
  13   0.8561     73.320  0.8563    71.446  72.63
  14   0.9095     71.520  0.8102    73.376  78.22
  15   0.8102     73.100  0.8651    71.902  83.65
  16   0.8495     72.840  0.7621    75.098  89.09
  17   0.6974     78.190  0.6999    77.212  94.53
  18   0.7199     76.650  0.6387    79.294  99.96
  19   0.6699     78.360  0.6233    80.202  105.41
  20   0.6707     78.280  0.6229    79.896  110.84
  21   0.6948     78.120  0.5878    81.238  116.39
  22   0.5651     81.450  0.5551    82.326  121.84
  23   0.5237     82.880  0.5170    83.444  127.26
  24   0.5581     81.770  0.4894    84.544  132.69
  25   0.5428     82.460  0.4738    85.000  138.13
  26   0.5148     83.620  0.4659    85.034  143.56
  27   0.4817     84.720  0.4478    85.802  148.99
  28   0.5192     83.770  0.4350    86.400  154.53
  29   0.4841     85.220  0.4235    86.596  159.98
  30   0.4957     85.240  0.4057    87.126  165.40
  31   0.4819     85.520  0.3885    87.872  170.85
  32   0.4847     85.380  0.3798    88.174  176.28
  33   0.4379     86.300  0.3656    88.398  181.73
  34   0.4314     86.500  0.3517    88.914  187.18
  35   0.4463     85.630  0.3481    89.062  192.73
  36   0.4593     85.420  0.3388    89.272  198.18
  37   0.4424     86.280  0.3307    89.612  203.62
  38   0.4508     86.360  0.3368    89.558  209.07
  39   0.4294     86.790  0.3222    89.916  214.50
  40   0.4039     87.440  0.3154    90.156  219.93
  41   0.4294     86.980  0.3037    90.374  225.38
  42   0.4142     86.890  0.2969    90.742  230.93
  43   0.4548     86.870  0.2891    90.972  236.35
  44   0.4338     86.890  0.2939    90.892  241.81
  45   0.4238     87.840  0.2882    91.034  247.25
  46   0.4125     87.810  0.2849    91.100  252.71
  47   0.4135     87.960  0.2811    91.084  258.13
  48   0.4118     87.820  0.2709    91.416  263.58
  49   0.3979     88.100  0.2661    91.636  269.04
  50   0.4313     87.830  0.2701    91.580  274.50
  51   0.4336     87.740  0.2712    91.634  279.94
  52   0.4089     88.130  0.2636    91.848  285.37
  53   0.4007     87.970  0.2564    92.022  290.84
  54   0.3853     88.470  0.2499    92.160  296.27
  55   0.4329     87.710  0.2441    92.418  301.84
  56   0.4166     87.710  0.2410    92.420  307.27
  57   0.4074     88.340  0.2375    92.594  312.74
  58   0.4289     87.620  0.2389    92.734  318.21
  59   0.4205     87.800  0.2401    92.404  323.67
  60   0.3942     88.640  0.2358    92.602  329.12
  61   0.3976     88.600  0.2301    92.954  334.58
  62   0.4027     87.960  0.2339    92.878  340.15
  63   0.4184     88.500  0.2222    93.180  345.58
  64   0.3731     88.640  0.2273    92.968  351.02
  65   0.3984     88.420  0.2188    93.154  356.45
  66   0.3958     88.690  0.2311    92.860  361.88
  67   0.4151     88.670  0.2211    93.144  367.30
  68   0.4359     87.670  0.2428    92.464  372.74
  69   0.3982     88.570  0.2343    92.804  378.36
  70   0.3885     89.380  0.2203    93.378  383.81
  71   0.3858     89.010  0.2186    93.278  389.24
  72   0.4449     88.410  0.2139    93.396  394.71
  73   0.4141     88.870  0.2216    93.236  400.17
  74   0.4063     88.470  0.2225    93.126  405.60
  75   0.3921     88.600  0.2102    93.416  411.14
  76   0.4038     88.600  0.2102    93.520  416.61
  77   0.3836     89.270  0.2081    93.456  422.04
  78   0.3764     89.340  0.1994    93.816  427.46
  79   0.4247     88.920  0.1999    93.900  432.89
  80   0.3748     88.960  0.2055    93.630  438.34
  81   0.3983     88.300  0.2020    93.704  443.78
  82   0.3968     88.850  0.2077    93.554  449.21
  83   0.4102     88.860  0.2006    93.760  454.65
  84   0.4028     88.830  0.1951    93.882  460.10
  85   0.4189     88.130  0.2002    93.752  465.54
