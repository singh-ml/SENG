Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4159     47.180  1.9219    28.334  7.04
   2   1.1715     57.660  1.3830    49.540  12.44
   3   1.0700     61.220  1.1568    58.470  17.86
   4   0.9119     67.030  1.0190    64.194  23.41
   5   0.8240     70.920  0.9164    68.032  28.83
   6   0.8044     71.780  0.8327    71.082  34.23
   7   0.7699     73.010  0.7653    73.672  39.66
   8   0.7235     74.980  0.7061    75.792  45.08
   9   0.7326     74.890  0.6684    77.530  50.49
  10   0.6607     77.310  0.6246    78.816  55.92
  11   0.6406     77.590  0.5876    80.202  61.48
  12   0.7077     76.960  0.5525    81.250  66.90
  13   0.6171     79.520  0.5253    82.224  72.34
  14   0.7203     75.450  0.5083    83.064  77.75
  15   0.5477     81.560  0.4779    84.054  83.16
  16   0.5929     80.000  0.4537    84.748  88.61
  17   0.5837     80.490  0.4351    85.396  94.01
  18   0.5415     81.550  0.4154    85.874  99.54
  19   0.5498     81.190  0.3963    86.690  104.96
  20   0.6056     80.240  0.3832    87.278  110.36
  21   0.5396     81.890  0.3651    87.732  115.76
  22   0.5210     82.480  0.3522    88.132  121.21
  23   0.5034     83.270  0.3390    88.646  126.64
  24   0.5233     82.850  0.3186    89.324  132.18
  25   0.5406     82.480  0.3114    89.568  137.63
  26   0.5041     83.550  0.3021    89.606  143.06
  27   0.5397     83.100  0.2902    90.388  148.50
  28   0.5047     83.880  0.2739    90.742  153.89
  29   0.4784     84.500  0.2714    90.810  159.31
  30   0.5062     84.230  0.2588    91.290  164.72
  31   0.5044     83.820  0.2487    91.630  170.23
  32   0.4861     85.310  0.2402    91.850  175.68
  33   0.5152     84.500  0.2287    92.360  181.08
  34   0.5383     83.320  0.2242    92.438  186.52
  35   0.5029     84.780  0.2148    92.726  191.94
  36   0.5032     85.280  0.2094    92.920  197.36
  37   0.4985     85.020  0.2057    93.092  202.76
  38   0.4941     85.450  0.1908    93.598  208.17
  39   0.5099     85.130  0.1882    93.626  213.58
  40   0.4545     85.570  0.1841    93.896  219.01
  41   0.5387     85.030  0.1723    94.204  224.43
  42   0.4817     85.780  0.1737    94.226  229.87
  43   0.5118     85.620  0.1653    94.424  235.31
  44   0.5726     84.010  0.1601    94.640  240.73
  45   0.5073     85.460  0.1539    94.960  246.28
  46   0.5254     86.040  0.1467    95.118  251.70
  47   0.5434     85.200  0.1434    95.180  257.11
  48   0.5246     85.820  0.1414    95.174  262.54
  49   0.5461     85.560  0.1390    95.390  267.97
  50   0.5457     85.290  0.1349    95.440  273.38
  51   0.5529     85.380  0.1327    95.656  278.80
  52   0.5480     86.000  0.1278    95.606  284.36
  53   0.5455     85.670  0.1253    95.846  289.77
  54   0.5126     86.390  0.1226    95.874  295.21
  55   0.5907     86.040  0.1165    96.094  300.63
  56   0.5284     86.070  0.1210    95.972  306.04
  57   0.5128     86.270  0.1132    96.278  311.48
  58   0.5487     85.980  0.1075    96.294  316.91
  59   0.5886     85.670  0.1057    96.556  322.46
  60   0.5749     85.350  0.0991    96.776  327.87
  61   0.5219     86.080  0.0991    96.738  333.30
  62   0.5832     85.780  0.1017    96.604  338.74
  63   0.6430     84.980  0.0971    96.780  344.16
  64   0.5817     86.000  0.0973    96.828  349.55
  65   0.6004     85.150  0.0989    96.750  354.97
  66   0.5568     86.340  0.1037    96.608  360.50
  67   0.5812     86.490  0.0886    97.012  365.92
  68   0.6108     86.140  0.0823    97.234  371.33
  69   0.6910     84.990  0.0811    97.200  376.75
  70   0.6158     85.840  0.0812    97.254  382.17
  71   0.6085     86.860  0.0800    97.404  387.57
  72   0.5745     86.390  0.0791    97.392  392.98
  73   0.5885     86.090  0.0910    97.066  398.53
  74   0.6169     86.630  0.0819    97.322  403.94
  75   0.6149     86.340  0.0788    97.376  409.35
  76   0.6339     85.780  0.0736    97.596  414.77
  77   0.5802     85.960  0.0825    97.354  420.20
  78   0.5961     86.630  0.0718    97.662  425.60
  79   0.5882     86.580  0.0696    97.672  431.03
  80   0.5915     86.440  0.0746    97.564  436.57
  81   0.6454     86.160  0.0716    97.636  442.00
  82   0.6399     86.230  0.0689    97.650  447.41
  83   0.7361     85.070  0.0704    97.684  452.82
  84   0.6710     86.830  0.0729    97.548  458.24
  85   0.6474     85.710  0.0645    97.880  463.67
