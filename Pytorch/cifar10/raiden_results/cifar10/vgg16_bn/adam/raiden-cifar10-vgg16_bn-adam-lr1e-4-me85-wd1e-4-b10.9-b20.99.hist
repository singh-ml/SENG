Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4349     45.670  1.8765    30.338  7.06
   2   1.1529     58.310  1.3586    50.476  12.49
   3   1.0619     62.450  1.1641    58.798  17.90
   4   0.9469     65.910  1.0440    63.178  23.34
   5   0.8727     69.270  0.9515    67.032  28.76
   6   0.8440     70.970  0.8646    70.034  34.16
   7   0.7480     73.850  0.7968    72.536  39.65
   8   0.7453     74.600  0.7390    74.954  45.06
   9   0.7863     73.080  0.6804    76.868  50.45
  10   0.7117     75.530  0.6413    78.094  55.87
  11   0.7378     74.850  0.5976    79.762  61.29
  12   0.6346     77.830  0.5653    80.860  66.70
  13   0.6390     78.470  0.5336    81.726  72.11
  14   0.6438     79.330  0.5089    82.722  77.66
  15   0.5977     80.110  0.4863    83.520  83.06
  16   0.5763     80.830  0.4560    84.470  88.48
  17   0.5752     80.880  0.4388    85.218  93.90
  18   0.5274     82.280  0.4159    85.916  99.31
  19   0.5345     82.210  0.4036    86.516  104.71
  20   0.5286     82.540  0.3827    87.054  110.11
  21   0.5685     82.050  0.3643    87.556  115.65
  22   0.5191     82.980  0.3555    87.904  121.05
  23   0.5267     82.860  0.3366    88.642  126.47
  24   0.5530     82.470  0.3243    88.980  131.91
  25   0.5021     83.990  0.3136    89.410  137.31
  26   0.5957     81.340  0.2953    89.992  142.73
  27   0.5044     83.390  0.2928    90.068  148.16
  28   0.5768     82.640  0.2710    90.780  153.69
  29   0.5514     83.230  0.2638    91.142  159.10
  30   0.5425     83.520  0.2515    91.372  164.53
  31   0.5820     83.240  0.2361    91.982  169.96
  32   0.5801     82.810  0.2377    92.076  175.39
  33   0.5824     83.400  0.2212    92.554  180.83
  34   0.5583     84.770  0.2118    92.872  186.25
  35   0.5766     84.150  0.2144    92.834  191.82
  36   0.5584     85.020  0.1982    93.270  197.22
  37   0.5369     84.910  0.2011    93.086  202.62
  38   0.6181     83.330  0.1884    93.686  208.04
  39   0.5099     85.030  0.1912    93.644  213.44
  40   0.6393     83.480  0.1747    94.164  218.85
  41   0.5903     83.990  0.1813    93.836  224.28
  42   0.5439     85.790  0.1666    94.236  229.82
  43   0.5455     85.080  0.1633    94.440  235.24
  44   0.5780     85.340  0.1589    94.640  240.66
  45   0.6745     83.970  0.1485    95.026  246.06
  46   0.5442     85.740  0.1551    94.806  251.49
  47   0.5746     85.200  0.1377    95.322  256.90
  48   0.6753     82.030  0.1585    95.034  262.45
  49   0.5757     86.060  0.1438    95.218  267.89
  50   0.6756     84.040  0.1309    95.672  273.30
  51   0.6007     85.520  0.1285    95.766  278.72
  52   0.6211     85.430  0.1274    95.696  284.15
  53   0.6147     85.240  0.1248    95.750  289.60
  54   0.5996     86.200  0.1214    95.970  295.04
  55   0.6217     85.370  0.1179    95.974  300.48
  56   0.5842     85.860  0.1110    96.162  306.02
  57   0.5910     85.720  0.1138    96.192  311.46
  58   0.6977     84.820  0.1080    96.338  316.87
  59   0.6267     85.700  0.1113    96.164  322.28
  60   0.6320     86.260  0.1022    96.434  327.72
  61   0.6224     86.240  0.1020    96.572  333.16
  62   0.5996     86.170  0.0966    96.686  338.73
  63   0.6389     85.690  0.1032    96.654  344.14
  64   0.5932     86.390  0.0969    96.796  349.59
  65   0.6329     85.980  0.0882    97.050  355.02
  66   0.6252     86.010  0.0903    96.930  360.44
  67   0.6549     86.050  0.0912    96.986  365.86
  68   0.6890     85.710  0.0844    97.174  371.27
  69   0.5870     86.420  0.0912    96.944  376.85
  70   0.6532     85.940  0.0838    97.274  382.24
  71   0.6254     85.940  0.0885    97.070  387.65
  72   0.6146     86.700  0.0810    97.324  393.08
  73   0.6273     86.450  0.0820    97.148  398.50
  74   0.6228     85.790  0.0752    97.532  403.94
  75   0.5929     86.230  0.0928    96.982  409.39
  76   0.6480     86.030  0.0724    97.520  414.80
  77   0.6625     86.180  0.0746    97.506  420.35
  78   0.6048     86.920  0.0719    97.558  425.77
  79   0.7148     85.090  0.0733    97.570  431.17
  80   0.6263     86.820  0.0750    97.508  436.60
  81   0.6696     86.620  0.0697    97.676  442.04
  82   0.6098     86.430  0.0752    97.464  447.47
  83   0.6243     86.880  0.0657    97.778  452.99
  84   0.6835     86.830  0.0664    97.778  458.41
  85   0.6204     87.230  0.0674    97.798  463.85
