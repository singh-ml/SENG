Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8394     27.340  2.2372    17.248  7.20
   2   1.6461     35.940  1.7608    30.254  12.60
   3   1.4334     47.140  1.5509    40.556  18.02
   4   1.2215     54.550  1.3666    49.082  23.42
   5   1.1283     59.190  1.2003    56.264  28.83
   6   1.0118     64.500  1.0695    61.866  34.22
   7   0.9342     66.570  0.9633    66.194  39.64
   8   0.8594     70.180  0.8808    69.152  45.19
   9   0.7857     73.000  0.8119    71.742  50.59
  10   0.8013     72.360  0.7449    74.218  56.00
  11   0.6966     76.160  0.6968    76.104  61.43
  12   0.6564     77.300  0.6503    77.634  66.86
  13   0.6693     77.900  0.6135    79.026  72.29
  14   0.6440     78.050  0.5879    80.144  77.74
  15   0.6312     79.210  0.5604    81.104  83.29
  16   0.6108     80.180  0.5276    81.958  88.75
  17   0.5859     80.450  0.4988    83.048  94.18
  18   0.5567     81.910  0.4851    83.666  99.60
  19   0.5709     80.780  0.4648    84.388  105.05
  20   0.5483     81.960  0.4396    85.134  110.45
  21   0.5550     82.240  0.4091    86.246  115.86
  22   0.5202     82.860  0.3968    86.680  121.39
  23   0.5187     82.980  0.3883    86.940  126.83
  24   0.5284     82.990  0.3719    87.536  132.29
  25   0.4913     83.700  0.3547    88.068  137.71
  26   0.5139     83.790  0.3458    88.356  143.12
  27   0.5088     83.720  0.3222    89.048  148.55
  28   0.5070     83.440  0.3309    88.928  153.99
  29   0.5006     84.870  0.3023    89.800  159.55
  30   0.5271     84.870  0.2817    90.448  165.00
  31   0.5097     84.550  0.2824    90.462  170.42
  32   0.4947     85.050  0.2737    90.768  175.87
  33   0.4956     84.530  0.2788    90.566  181.29
  34   0.5049     85.480  0.2631    91.062  186.73
  35   0.5050     84.600  0.2532    91.416  192.15
  36   0.5221     85.150  0.2265    92.356  197.70
  37   0.5056     84.880  0.2287    92.312  203.13
  38   0.5482     84.720  0.2305    92.218  208.55
  39   0.4971     86.110  0.2176    92.666  213.99
  40   0.5089     85.720  0.2034    93.128  219.40
  41   0.4847     85.850  0.1953    93.378  224.83
  42   0.5082     85.810  0.2012    93.234  230.26
  43   0.5293     85.410  0.1848    93.750  235.79
  44   0.5576     85.590  0.1784    94.098  241.22
  45   0.5105     85.560  0.1731    94.212  246.65
  46   0.5188     85.770  0.1692    94.284  252.08
  47   0.5274     85.580  0.1663    94.318  257.48
  48   0.5154     86.420  0.1614    94.452  262.88
  49   0.5095     86.350  0.1555    94.650  268.45
  50   0.5183     86.240  0.1515    94.958  273.87
  51   0.5289     86.200  0.1429    95.124  279.32
  52   0.5225     86.510  0.1378    95.314  284.76
  53   0.5369     86.390  0.1295    95.580  290.17
  54   0.5713     86.120  0.1326    95.590  295.56
  55   0.5510     85.900  0.1288    95.594  301.00
  56   0.5301     86.760  0.1220    95.782  306.57
  57   0.5381     86.440  0.1230    95.882  312.01
  58   0.5345     86.250  0.1176    96.026  317.43
  59   0.5912     86.560  0.1136    96.222  322.85
  60   0.5488     86.480  0.1154    96.224  328.29
  61   0.5306     86.430  0.1083    96.386  333.73
  62   0.5098     87.280  0.1103    96.214  339.17
  63   0.5192     87.010  0.1061    96.438  344.75
  64   0.5437     87.380  0.0989    96.730  350.16
  65   0.5275     86.980  0.0992    96.642  355.61
  66   0.5652     86.850  0.0989    96.660  361.02
  67   0.5667     86.720  0.0925    96.874  366.44
  68   0.5486     87.030  0.0938    96.810  371.85
  69   0.5216     87.530  0.0909    96.976  377.26
  70   0.5658     86.600  0.0905    96.896  382.83
  71   0.5660     87.350  0.0896    96.976  388.29
  72   0.5974     86.530  0.0864    97.076  393.72
  73   0.5448     86.820  0.0915    96.930  399.13
  74   0.5935     86.600  0.0834    97.314  404.56
  75   0.5576     87.580  0.0820    97.308  409.96
  76   0.5801     87.040  0.0788    97.412  415.40
  77   0.5913     86.560  0.0833    97.136  420.93
  78   0.5834     86.610  0.0851    97.216  426.34
  79   0.5262     87.850  0.0811    97.322  431.75
  80   0.5258     87.180  0.0821    97.174  437.18
  81   0.5611     86.870  0.0774    97.400  442.59
  82   0.5294     87.840  0.0765    97.518  448.01
  83   0.5572     87.150  0.0725    97.562  453.41
  84   0.6042     86.800  0.0748    97.504  458.83
  85   0.5657     87.660  0.0698    97.676  464.23
  86   0.5591     87.170  0.0703    97.648  469.66
  87   0.5665     87.270  0.0689    97.710  475.07
  88   0.5444     87.210  0.0695    97.686  480.50
  89   0.5792     87.270  0.0681    97.646  485.92
  90   0.5988     87.500  0.0705    97.608  491.35
