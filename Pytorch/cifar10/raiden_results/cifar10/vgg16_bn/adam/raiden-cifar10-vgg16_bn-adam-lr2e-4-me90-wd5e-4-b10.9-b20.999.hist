Use GPU: 0 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4196382720 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.7634     30.150  2.2976    18.000  7.25
   2   1.5606     43.230  1.6291    36.228  12.65
   3   1.2334     55.960  1.3083    52.240  18.04
   4   1.2924     57.280  1.0741    62.630  23.44
   5   0.8173     71.330  0.9059    69.194  28.84
   6   0.8536     70.590  0.8078    73.012  34.25
   7   0.6894     76.390  0.7234    75.904  39.65
   8   0.7246     76.270  0.6590    78.098  45.19
   9   0.6766     77.720  0.6191    79.712  50.60
  10   0.5772     81.110  0.5803    80.996  55.99
  11   0.6399     79.170  0.5415    82.476  61.38
  12   0.5943     80.180  0.5163    83.276  66.77
  13   0.5994     79.870  0.4808    84.380  72.15
  14   0.5515     82.040  0.4643    84.884  77.59
  15   0.5320     82.770  0.4350    86.000  83.12
  16   0.5014     83.030  0.4303    85.868  88.56
  17   0.5663     82.160  0.4067    86.914  93.99
  18   0.5039     83.430  0.3930    87.226  99.40
  19   0.5098     83.310  0.3848    87.382  104.78
  20   0.4689     85.160  0.3541    88.514  110.17
  21   0.4951     84.710  0.3394    88.862  115.57
  22   0.5376     83.110  0.3240    89.342  121.00
  23   0.4715     85.280  0.3388    89.204  126.58
  24   0.4620     85.610  0.3008    90.184  132.01
  25   0.5360     82.990  0.2954    90.440  137.39
  26   0.4382     86.400  0.2774    90.922  142.78
  27   0.4826     84.640  0.2687    91.230  148.21
  28   0.4402     86.660  0.2681    91.414  153.60
  29   0.4742     85.250  0.2559    91.884  159.14
  30   0.5420     83.800  0.2422    92.054  164.53
  31   0.5323     84.150  0.2467    91.970  169.94
  32   0.4581     86.450  0.2547    91.678  175.35
  33   0.4351     87.230  0.2235    92.832  180.79
  34   0.5658     83.280  0.2136    93.044  186.21
  35   0.4498     86.660  0.2150    93.094  191.70
  36   0.5197     85.510  0.2000    93.534  197.14
  37   0.4571     86.380  0.1962    93.498  202.55
  38   0.4226     87.290  0.1914    93.762  207.97
  39   0.5040     86.320  0.2025    93.442  213.37
  40   0.4762     86.600  0.1824    94.152  218.80
  41   0.4476     87.550  0.1759    94.250  224.21
  42   0.4147     87.940  0.1700    94.552  229.61
  43   0.4508     87.030  0.1695    94.468  235.16
  44   0.4643     87.410  0.1704    94.542  240.58
  45   0.4996     86.450  0.1656    94.526  245.97
  46   0.5268     85.730  0.1547    95.070  251.37
  47   0.4778     86.630  0.1598    94.884  256.77
  48   0.6208     84.550  0.1465    95.268  262.20
  49   0.4578     88.420  0.1516    95.118  267.61
  50   0.4874     87.180  0.1411    95.460  273.14
  51   0.5179     86.950  0.1437    95.340  278.55
  52   0.4605     87.710  0.1358    95.598  283.97
  53   0.5112     87.220  0.1341    95.706  289.39
  54   0.5642     86.220  0.1366    95.538  294.79
  55   0.4330     88.680  0.1296    95.900  300.20
  56   0.6072     85.160  0.1272    95.932  305.60
  57   0.4583     87.740  0.1278    95.832  311.16
  58   0.4589     88.670  0.1190    96.136  316.58
  59   0.5102     87.090  0.1230    96.016  322.00
  60   0.4367     88.390  0.1106    96.384  327.43
  61   0.4641     88.210  0.1122    96.426  332.85
  62   0.5143     86.930  0.1124    96.344  338.26
  63   0.5186     87.800  0.1070    96.510  343.68
  64   0.5195     87.570  0.1105    96.460  349.23
  65   0.4663     88.750  0.1104    96.460  354.66
  66   0.5007     87.860  0.1114    96.472  360.11
  67   0.4648     88.750  0.0996    96.748  365.52
  68   0.4585     88.410  0.1041    96.650  370.97
  69   0.4616     88.200  0.1052    96.586  376.39
  70   0.4448     89.370  0.1008    96.772  381.80
  71   0.5285     87.320  0.1023    96.762  387.24
  72   0.4874     88.060  0.0972    96.904  392.66
  73   0.4916     88.280  0.0963    96.926  398.10
  74   0.4686     88.230  0.0986    96.766  403.53
  75   0.5193     87.450  0.0931    96.988  408.96
  76   0.5242     88.060  0.0940    96.982  414.38
  77   0.4787     88.320  0.0899    97.154  419.81
  78   0.4170     89.450  0.0944    96.946  425.37
  79   0.4345     89.020  0.0892    97.090  430.82
  80   0.4363     89.140  0.0867    97.216  436.24
  81   0.5429     88.230  0.0879    97.188  441.65
  82   0.4550     89.260  0.0887    97.154  447.09
  83   0.4610     88.370  0.0887    97.238  452.53
  84   0.4520     89.310  0.0809    97.354  457.98
  85   0.4820     88.070  0.0822    97.418  463.53
  86   0.4829     88.760  0.0872    97.218  468.96
  87   0.4991     88.480  0.0825    97.424  474.38
  88   0.4454     89.460  0.0848    97.366  479.84
  89   0.5174     88.120  0.0826    97.430  485.28
  90   0.4568     88.970  0.0814    97.452  490.70
