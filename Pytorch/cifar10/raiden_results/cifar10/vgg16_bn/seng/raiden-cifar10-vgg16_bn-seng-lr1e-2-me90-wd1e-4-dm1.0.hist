Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2795     53.540  1.7102    36.156  7.63
   2   1.0172     63.950  1.2061    56.930  13.67
   3   0.8632     69.910  0.9881    65.452  19.49
   4   0.7279     74.570  0.8342    71.058  25.34
   5   0.6876     76.450  0.7540    74.024  31.17
   6   0.6145     79.020  0.6685    77.336  37.01
   7   0.5973     79.750  0.6118    79.316  42.85
   8   0.5667     80.730  0.5580    81.178  48.82
   9   0.5227     82.030  0.5209    82.534  54.68
  10   0.5521     80.950  0.4839    83.654  60.53
  11   0.4694     84.070  0.4521    84.794  66.37
  12   0.5291     82.120  0.4271    85.608  72.19
  13   0.4595     84.030  0.4048    86.436  78.01
  14   0.4587     84.690  0.3863    86.986  83.95
  15   0.4583     84.620  0.3584    88.010  89.78
  16   0.4532     85.170  0.3430    88.472  95.59
  17   0.4518     85.220  0.3271    88.988  101.42
  18   0.4329     85.510  0.3146    89.260  107.26
  19   0.4068     86.530  0.2915    90.206  113.11
  20   0.4199     85.980  0.2780    90.512  118.92
  21   0.3959     86.270  0.2607    91.070  124.85
  22   0.3833     87.350  0.2483    91.524  130.67
  23   0.4071     87.060  0.2327    92.310  136.52
  24   0.3958     87.110  0.2310    92.134  142.38
  25   0.3870     87.120  0.2172    92.654  148.20
  26   0.4023     86.810  0.2059    93.110  154.01
  27   0.4034     86.780  0.2025    93.148  159.97
  28   0.3810     87.860  0.1872    93.592  165.77
  29   0.3929     87.090  0.1816    93.778  171.59
  30   0.3993     87.930  0.1673    94.430  177.41
  31   0.3889     87.740  0.1623    94.432  183.24
  32   0.4149     87.190  0.1559    94.664  189.07
  33   0.4071     87.570  0.1480    94.862  194.90
  34   0.4024     87.630  0.1393    95.266  200.84
  35   0.3968     87.910  0.1328    95.460  206.67
  36   0.3965     88.030  0.1259    95.716  212.49
  37   0.4020     88.000  0.1193    95.940  218.32
  38   0.3889     88.500  0.1133    96.076  224.12
  39   0.3931     88.420  0.1069    96.362  229.95
  40   0.4217     88.220  0.1021    96.486  235.94
  41   0.4266     88.240  0.0952    96.684  241.75
  42   0.4134     88.460  0.0934    96.764  247.56
  43   0.4156     88.510  0.0906    96.884  253.39
  44   0.4392     88.240  0.0813    97.270  259.22
  45   0.4384     88.380  0.0796    97.292  265.03
  46   0.4202     88.740  0.0777    97.372  271.05
  47   0.4403     88.330  0.0708    97.594  276.85
  48   0.4388     88.560  0.0656    97.810  282.67
  49   0.4170     88.990  0.0639    97.830  288.50
  50   0.4442     88.940  0.0585    97.986  294.24
  51   0.4425     89.120  0.0553    98.096  300.08
  52   0.4460     89.020  0.0547    98.136  305.88
  53   0.4389     89.120  0.0498    98.242  311.85
  54   0.4386     89.670  0.0445    98.408  317.68
  55   0.4509     89.260  0.0452    98.436  323.49
  56   0.4446     89.460  0.0450    98.460  329.32
  57   0.4478     89.200  0.0392    98.720  335.13
  58   0.4688     89.590  0.0372    98.740  340.94
  59   0.4702     89.300  0.0354    98.816  346.86
  60   0.4624     89.750  0.0339    98.862  352.67
  61   0.4596     89.610  0.0322    98.976  358.51
  62   0.4574     89.590  0.0301    98.960  364.34
  63   0.4766     89.540  0.0269    99.106  370.14
  64   0.4734     89.390  0.0251    99.164  375.94
  65   0.4722     89.470  0.0234    99.182  381.76
  66   0.4892     89.400  0.0218    99.234  387.59
  67   0.4885     89.610  0.0227    99.236  393.39
  68   0.5051     89.440  0.0200    99.328  399.20
  69   0.4960     89.680  0.0187    99.362  405.01
  70   0.5187     89.540  0.0177    99.402  410.84
  71   0.5098     89.450  0.0164    99.450  416.66
  72   0.4998     89.760  0.0169    99.430  422.47
  73   0.5265     89.300  0.0140    99.512  428.42
  74   0.5427     89.870  0.0118    99.616  434.25
  75   0.5322     89.890  0.0123    99.600  440.07
  76   0.5349     89.590  0.0136    99.520  445.90
  77   0.5384     89.960  0.0113    99.612  451.72
  78   0.5370     89.750  0.0117    99.602  457.55
  79   0.5480     89.730  0.0098    99.680  463.53
  80   0.5404     89.940  0.0109    99.638  469.37
  81   0.5432     89.900  0.0104    99.666  475.23
  82   0.5343     89.960  0.0082    99.738  481.08
  83   0.5484     89.730  0.0080    99.746  486.90
  84   0.5485     89.940  0.0086    99.722  492.75
  85   0.5581     89.840  0.0085    99.732  498.59
  86   0.5495     89.860  0.0079    99.730  504.52
  87   0.5577     89.790  0.0089    99.704  510.34
  88   0.5759     89.820  0.0080    99.728  516.17
  89   0.5717     89.760  0.0072    99.784  521.99
  90   0.5857     89.640  0.0066    99.782  527.81
