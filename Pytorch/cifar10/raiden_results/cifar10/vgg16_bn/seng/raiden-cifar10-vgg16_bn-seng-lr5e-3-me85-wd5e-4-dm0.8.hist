Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2982     52.340  1.6973    36.618  7.61
   2   1.0229     62.850  1.2061    56.440  13.40
   3   0.8562     69.390  1.0060    64.122  19.36
   4   0.7925     72.080  0.8731    69.130  25.15
   5   0.6946     75.970  0.7848    72.680  30.96
   6   0.6541     77.790  0.7046    75.694  36.78
   7   0.6221     78.660  0.6513    77.626  42.58
   8   0.5929     79.060  0.6013    79.370  48.38
   9   0.5640     80.500  0.5552    80.980  54.38
  10   0.5424     81.140  0.5270    81.914  60.18
  11   0.5323     81.200  0.4964    83.044  65.98
  12   0.5048     82.770  0.4635    84.136  71.81
  13   0.5075     82.740  0.4489    84.778  77.63
  14   0.4907     82.990  0.4183    85.784  83.45
  15   0.4894     83.200  0.3964    86.620  89.25
  16   0.4656     83.980  0.3784    87.138  95.21
  17   0.4432     84.720  0.3590    87.732  101.01
  18   0.4617     84.560  0.3408    88.408  106.83
  19   0.4603     84.790  0.3244    88.916  112.62
  20   0.4509     84.940  0.3155    89.252  118.42
  21   0.4120     85.790  0.2991    89.800  124.21
  22   0.4722     84.680  0.2831    90.400  130.02
  23   0.4689     84.210  0.2734    90.700  135.83
  24   0.4215     85.560  0.2630    91.020  141.63
  25   0.4078     86.490  0.2513    91.214  147.43
  26   0.4179     86.220  0.2395    91.762  153.22
  27   0.4199     86.100  0.2284    92.130  159.03
  28   0.4077     86.840  0.2132    92.764  164.84
  29   0.4158     86.780  0.2107    92.756  170.79
  30   0.4300     86.360  0.1991    93.148  176.60
  31   0.4338     86.520  0.1912    93.412  182.44
  32   0.4020     87.100  0.1900    93.532  188.24
  33   0.3973     87.510  0.1764    93.850  194.07
  34   0.4100     87.200  0.1670    94.216  199.90
  35   0.3975     87.580  0.1621    94.364  205.86
  36   0.4057     87.460  0.1551    94.652  211.67
  37   0.4107     87.940  0.1402    95.286  217.45
  38   0.4192     87.360  0.1376    95.186  223.25
  39   0.4289     87.060  0.1343    95.410  229.07
  40   0.4319     87.500  0.1292    95.562  234.88
  41   0.4139     88.270  0.1210    95.794  240.70
  42   0.4250     88.090  0.1111    96.162  246.69
  43   0.4472     87.620  0.1119    96.098  252.49
  44   0.4526     87.800  0.1057    96.304  258.32
  45   0.4234     87.920  0.0990    96.614  264.13
  46   0.4245     88.240  0.0962    96.794  269.96
  47   0.4173     88.670  0.0912    96.800  275.79
  48   0.4337     88.150  0.0869    97.044  281.75
  49   0.4662     87.870  0.0787    97.238  287.58
  50   0.4553     88.260  0.0774    97.382  293.34
  51   0.4590     87.850  0.0737    97.438  299.16
  52   0.4563     87.840  0.0733    97.532  304.96
  53   0.4541     88.130  0.0661    97.706  310.76
  54   0.4462     88.560  0.0637    97.838  316.61
  55   0.4522     88.790  0.0597    97.908  322.42
  56   0.4631     88.400  0.0575    98.056  328.26
  57   0.4827     88.340  0.0563    98.092  334.06
  58   0.4740     88.650  0.0539    98.114  339.89
  59   0.4813     88.750  0.0456    98.396  345.68
  60   0.4910     88.590  0.0452    98.422  351.48
  61   0.5145     87.910  0.0426    98.564  357.40
  62   0.4889     89.050  0.0394    98.602  363.20
  63   0.5023     88.720  0.0382    98.648  369.02
  64   0.5020     88.690  0.0380    98.676  374.84
  65   0.5120     88.760  0.0349    98.788  380.68
  66   0.5110     88.900  0.0340    98.824  386.47
  67   0.5311     88.740  0.0320    98.888  392.26
  68   0.5150     89.140  0.0305    98.998  398.20
  69   0.5117     89.110  0.0269    99.144  404.00
  70   0.5110     89.290  0.0264    99.108  409.79
  71   0.5140     88.840  0.0272    99.104  415.60
  72   0.5240     89.300  0.0230    99.200  421.39
  73   0.5301     89.430  0.0232    99.184  427.19
  74   0.5300     89.140  0.0231    99.192  433.19
  75   0.5270     89.330  0.0216    99.244  439.02
  76   0.5310     89.170  0.0210    99.314  444.83
  77   0.5273     89.340  0.0195    99.338  450.67
  78   0.5257     89.460  0.0207    99.312  456.50
  79   0.5570     88.940  0.0198    99.330  462.32
  80   0.5427     89.280  0.0185    99.366  468.13
  81   0.5591     89.180  0.0150    99.484  474.09
  82   0.5574     89.180  0.0173    99.414  479.91
  83   0.5509     89.430  0.0155    99.468  485.72
  84   0.5527     89.440  0.0169    99.406  491.51
  85   0.5652     89.310  0.0166    99.446  497.30
