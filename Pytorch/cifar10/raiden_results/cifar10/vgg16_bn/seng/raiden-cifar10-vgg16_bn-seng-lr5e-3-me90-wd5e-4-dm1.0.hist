Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3198     50.890  1.7199    35.716  7.84
   2   1.1118     59.400  1.2785    53.188  13.67
   3   0.9396     66.260  1.0617    61.836  19.53
   4   0.8250     70.710  0.9207    67.540  25.38
   5   0.7412     74.130  0.8112    71.550  31.20
   6   0.6705     76.970  0.7391    74.140  37.02
   7   0.6668     77.030  0.6734    76.668  42.95
   8   0.5972     79.500  0.6213    78.590  48.80
   9   0.5917     79.150  0.5800    80.142  54.62
  10   0.5476     81.050  0.5499    81.238  60.46
  11   0.5309     81.210  0.5243    82.032  66.28
  12   0.5239     81.960  0.4858    83.266  72.10
  13   0.5155     82.400  0.4664    84.132  77.92
  14   0.5075     82.800  0.4371    85.076  83.89
  15   0.4876     83.340  0.4154    85.770  89.83
  16   0.4757     83.620  0.3988    86.366  95.68
  17   0.4874     83.470  0.3856    86.744  101.55
  18   0.4667     84.070  0.3632    87.586  107.37
  19   0.4599     84.440  0.3429    88.184  113.21
  20   0.4379     85.130  0.3300    88.586  119.06
  21   0.4676     84.460  0.3186    89.108  124.90
  22   0.4649     84.700  0.3043    89.512  130.72
  23   0.4168     86.040  0.2923    89.838  136.55
  24   0.4493     84.640  0.2768    90.446  142.41
  25   0.4334     85.770  0.2690    90.720  148.24
  26   0.4207     86.650  0.2554    91.156  154.07
  27   0.4088     86.380  0.2487    91.376  160.01
  28   0.4282     86.380  0.2339    91.994  165.87
  29   0.4401     85.670  0.2262    92.192  171.69
  30   0.4021     86.800  0.2189    92.506  177.52
  31   0.4247     86.450  0.2086    92.842  183.33
  32   0.4190     86.920  0.1987    93.174  189.15
  33   0.4131     86.490  0.1940    93.236  195.13
  34   0.4036     87.260  0.1801    93.862  200.94
  35   0.4134     87.120  0.1757    93.896  206.75
  36   0.4128     87.300  0.1636    94.274  212.56
  37   0.3957     87.340  0.1648    94.348  218.40
  38   0.4166     87.470  0.1585    94.656  224.25
  39   0.4113     87.570  0.1465    94.936  230.08
  40   0.4137     87.320  0.1406    95.096  236.06
  41   0.4340     86.920  0.1413    95.178  241.92
  42   0.4252     87.020  0.1330    95.398  247.74
  43   0.4223     87.350  0.1246    95.762  253.59
  44   0.4319     87.280  0.1217    95.802  259.41
  45   0.4175     87.730  0.1123    96.012  265.25
  46   0.4386     87.840  0.1110    96.124  271.26
  47   0.4288     87.730  0.1037    96.402  277.08
  48   0.4491     87.600  0.0993    96.476  282.90
  49   0.4440     87.810  0.0922    96.774  288.73
  50   0.4335     88.170  0.0897    96.876  294.48
  51   0.4685     87.460  0.0830    97.126  300.31
  52   0.4362     88.290  0.0822    97.188  306.13
  53   0.4581     87.790  0.0773    97.338  312.10
  54   0.4373     88.340  0.0760    97.384  317.94
  55   0.4317     88.580  0.0762    97.348  323.75
  56   0.4558     88.290  0.0663    97.756  329.57
  57   0.4700     87.970  0.0639    97.748  335.38
  58   0.4785     88.240  0.0629    97.818  341.22
  59   0.4413     88.660  0.0600    97.892  347.04
  60   0.4589     88.530  0.0548    98.102  353.01
  61   0.4884     88.090  0.0525    98.200  358.83
  62   0.4857     88.040  0.0517    98.236  364.70
  63   0.4916     88.350  0.0506    98.262  370.51
  64   0.4819     88.580  0.0436    98.520  376.35
  65   0.4891     88.620  0.0447    98.412  382.21
  66   0.4828     88.670  0.0414    98.524  388.18
  67   0.4834     88.750  0.0426    98.540  394.02
  68   0.4793     88.890  0.0385    98.668  399.85
  69   0.4941     88.840  0.0362    98.754  405.68
  70   0.5056     88.640  0.0323    98.890  411.51
  71   0.4965     88.840  0.0330    98.864  417.34
  72   0.5019     88.850  0.0305    98.946  423.29
  73   0.5127     88.860  0.0277    99.018  429.12
  74   0.5243     88.840  0.0276    99.040  434.96
  75   0.5331     88.650  0.0267    99.048  440.80
  76   0.5264     88.560  0.0306    98.910  446.61
  77   0.5199     89.110  0.0247    99.106  452.42
  78   0.5220     88.920  0.0260    99.180  458.25
  79   0.5334     88.860  0.0234    99.214  464.22
  80   0.5233     88.990  0.0208    99.306  470.05
  81   0.5342     88.930  0.0215    99.292  475.89
  82   0.5499     88.840  0.0200    99.320  481.74
  83   0.5313     89.050  0.0194    99.352  487.57
  84   0.5461     88.850  0.0172    99.424  493.41
  85   0.5494     89.090  0.0182    99.360  499.38
  86   0.5588     88.910  0.0158    99.504  505.20
  87   0.5335     89.000  0.0203    99.274  511.02
  88   0.5451     89.090  0.0168    99.414  516.85
  89   0.5651     88.990  0.0156    99.474  522.71
  90   0.5705     89.010  0.0169    99.404  528.51
