Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5469     41.260  1.9318    27.376  7.80
   2   1.3275     50.290  1.5147    43.210  13.59
   3   1.1854     56.280  1.3439    50.150  19.39
   4   1.0915     59.650  1.2233    55.174  25.20
   5   0.9987     63.970  1.1277    58.852  31.01
   6   0.9438     66.130  1.0473    62.268  36.78
   7   0.8849     68.080  0.9734    64.982  42.57
   8   0.8645     68.650  0.9229    67.158  48.52
   9   0.8215     70.500  0.8740    68.776  54.33
  10   0.7817     72.140  0.8340    70.348  60.14
  11   0.7623     72.370  0.7986    71.858  65.93
  12   0.7242     74.380  0.7622    73.214  71.73
  13   0.7023     75.030  0.7325    74.198  77.52
  14   0.6930     75.290  0.7109    74.970  83.32
  15   0.6855     75.830  0.6825    75.998  89.27
  16   0.6488     77.290  0.6569    76.914  95.08
  17   0.6517     77.110  0.6390    77.564  100.87
  18   0.6230     78.310  0.6178    78.368  106.66
  19   0.6265     78.010  0.6032    78.914  112.45
  20   0.6091     78.820  0.5822    79.612  118.25
  21   0.5888     79.400  0.5707    79.844  124.18
  22   0.5924     79.670  0.5541    80.766  130.02
  23   0.5941     79.280  0.5356    81.180  135.80
  24   0.5800     80.070  0.5297    81.578  141.59
  25   0.5733     80.720  0.5133    82.122  147.40
  26   0.5810     80.180  0.5015    82.424  153.20
  27   0.5709     80.550  0.4877    82.936  159.12
  28   0.5566     81.180  0.4751    83.534  164.90
  29   0.5813     80.460  0.4607    83.936  170.73
  30   0.5562     81.330  0.4529    84.232  176.53
  31   0.5468     81.520  0.4419    84.740  182.35
  32   0.5400     81.790  0.4336    84.884  188.15
  33   0.5396     81.770  0.4238    85.322  193.94
  34   0.5380     81.860  0.4099    85.728  199.81
  35   0.5382     81.960  0.4014    85.866  205.65
  36   0.5217     82.500  0.3974    86.046  211.43
  37   0.5152     82.810  0.3856    86.514  217.25
  38   0.5457     82.230  0.3782    86.862  223.06
  39   0.5220     83.000  0.3750    86.936  228.89
  40   0.5220     82.690  0.3638    87.236  234.73
  41   0.5319     82.530  0.3565    87.618  240.66
  42   0.5388     82.580  0.3466    88.018  246.46
  43   0.5239     82.770  0.3385    88.214  252.28
  44   0.5262     82.880  0.3325    88.330  258.06
  45   0.5282     82.720  0.3292    88.566  263.88
  46   0.5151     83.300  0.3188    88.850  269.68
  47   0.5246     83.090  0.3050    89.502  275.61
  48   0.5030     83.590  0.3128    89.224  281.39
  49   0.5236     83.460  0.3027    89.628  287.19
  50   0.5449     82.400  0.2968    89.646  292.93
  51   0.5179     83.970  0.2898    89.872  298.72
  52   0.5187     83.950  0.2805    90.400  304.50
  53   0.5102     83.910  0.2759    90.310  310.38
  54   0.5134     84.010  0.2751    90.274  316.17
  55   0.5220     84.020  0.2690    90.576  321.96
  56   0.5274     83.740  0.2639    90.944  327.76
  57   0.5250     83.700  0.2528    91.228  333.58
  58   0.5225     84.130  0.2489    91.440  339.39
  59   0.5321     83.820  0.2415    91.472  345.18
  60   0.5353     83.990  0.2374    91.706  351.15
  61   0.5364     83.580  0.2356    91.886  356.96
  62   0.5520     83.600  0.2281    91.972  362.74
  63   0.5289     84.510  0.2222    92.250  368.54
  64   0.5504     84.160  0.2186    92.338  374.34
  65   0.5325     84.210  0.2136    92.476  380.14
  66   0.5298     84.130  0.2125    92.528  385.93
  67   0.5423     84.230  0.2081    92.738  391.87
  68   0.5469     84.020  0.2011    92.918  397.67
  69   0.5351     84.570  0.2010    92.974  403.47
  70   0.5503     83.980  0.1919    93.346  409.26
  71   0.5499     84.320  0.1917    93.296  415.06
  72   0.5616     84.190  0.1865    93.404  420.84
  73   0.5792     84.210  0.1821    93.622  426.63
  74   0.5711     84.270  0.1794    93.866  432.60
  75   0.5725     84.310  0.1741    93.878  438.43
  76   0.5743     84.360  0.1730    93.928  444.24
  77   0.5536     84.410  0.1713    94.096  450.02
  78   0.5716     84.410  0.1652    94.118  455.83
  79   0.5849     84.030  0.1634    94.152  461.63
  80   0.5677     84.270  0.1584    94.484  467.44
  81   0.5862     84.120  0.1535    94.566  473.42
  82   0.5980     83.860  0.1528    94.702  479.27
  83   0.6021     84.250  0.1474    94.906  485.08
  84   0.5924     84.580  0.1425    95.024  490.90
  85   0.5750     84.700  0.1487    94.752  496.70
