Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3486     51.000  1.7184    35.702  7.66
   2   1.0203     63.340  1.2345    55.248  13.47
   3   0.9067     67.850  1.0328    63.264  19.47
   4   0.8156     71.810  0.9068    67.686  25.28
   5   0.7200     74.600  0.8012    72.112  31.10
   6   0.6883     76.340  0.7256    74.810  36.90
   7   0.6400     77.640  0.6693    76.866  42.70
   8   0.6065     79.220  0.6210    78.702  48.52
   9   0.5900     79.910  0.5813    80.124  54.35
  10   0.5620     80.770  0.5435    81.564  60.16
  11   0.5249     82.200  0.5124    82.678  66.01
  12   0.5161     82.560  0.4819    83.598  71.84
  13   0.4965     83.250  0.4574    84.306  77.64
  14   0.4949     83.250  0.4382    85.198  83.46
  15   0.4807     83.540  0.4115    85.850  89.27
  16   0.4713     83.920  0.3955    86.382  95.25
  17   0.4642     84.550  0.3783    86.988  101.07
  18   0.4499     84.630  0.3570    87.824  106.88
  19   0.4623     84.380  0.3452    87.948  112.72
  20   0.4587     84.970  0.3257    88.902  118.55
  21   0.4380     85.100  0.3188    89.092  124.36
  22   0.4576     84.600  0.2998    89.644  130.28
  23   0.4750     84.930  0.2873    89.958  136.12
  24   0.4392     86.200  0.2804    90.500  141.96
  25   0.4338     85.890  0.2664    90.848  147.76
  26   0.4577     85.140  0.2477    91.434  153.61
  27   0.4186     86.090  0.2432    91.812  159.44
  28   0.4214     86.030  0.2345    92.072  165.39
  29   0.4344     86.270  0.2262    92.260  171.22
  30   0.4072     86.630  0.2154    92.656  177.04
  31   0.4181     86.670  0.2052    92.940  182.87
  32   0.4144     86.900  0.2042    92.922  188.69
  33   0.4103     87.080  0.1887    93.452  194.51
  34   0.4339     86.720  0.1850    93.696  200.35
  35   0.4329     86.820  0.1734    94.040  206.31
  36   0.4360     86.800  0.1654    94.290  212.13
  37   0.4223     87.570  0.1644    94.374  218.00
  38   0.4417     87.180  0.1494    94.840  223.83
  39   0.4479     87.020  0.1462    94.934  229.67
  40   0.4444     86.820  0.1438    94.968  235.48
  41   0.4510     87.400  0.1309    95.440  241.42
  42   0.4396     87.650  0.1305    95.514  247.23
  43   0.4445     87.350  0.1218    95.686  253.05
  44   0.4322     87.680  0.1173    96.014  258.88
  45   0.4593     87.400  0.1092    96.172  264.69
  46   0.4406     87.720  0.1095    96.232  270.51
  47   0.4557     87.540  0.1026    96.392  276.33
  48   0.4717     87.590  0.0951    96.710  282.25
  49   0.4478     88.020  0.0902    96.902  288.10
  50   0.4639     87.990  0.0881    97.040  293.84
  51   0.4527     88.250  0.0819    97.180  299.66
  52   0.4674     88.280  0.0798    97.272  305.48
  53   0.4562     88.040  0.0796    97.254  311.32
  54   0.4777     88.070  0.0760    97.392  317.22
  55   0.4723     87.960  0.0725    97.480  323.08
  56   0.4933     88.040  0.0685    97.626  328.92
  57   0.4876     87.840  0.0646    97.820  334.75
  58   0.4875     88.380  0.0619    97.870  340.58
  59   0.4698     88.580  0.0578    98.016  346.47
  60   0.4817     88.490  0.0578    98.050  352.43
  61   0.4843     88.840  0.0554    98.034  358.26
  62   0.5016     88.570  0.0503    98.294  364.09
  63   0.5155     88.170  0.0503    98.286  369.91
  64   0.5003     88.890  0.0474    98.358  375.73
  65   0.5058     88.200  0.0450    98.446  381.58
  66   0.5028     88.340  0.0421    98.460  387.45
  67   0.5437     88.220  0.0377    98.702  393.43
  68   0.5451     88.480  0.0372    98.710  399.26
  69   0.5235     88.590  0.0402    98.618  405.08
  70   0.5295     88.920  0.0344    98.808  410.90
  71   0.5408     88.820  0.0330    98.834  416.71
  72   0.5364     88.820  0.0317    98.964  422.54
  73   0.5588     88.610  0.0337    98.866  428.36
  74   0.5494     88.700  0.0308    98.984  434.29
  75   0.5434     88.990  0.0282    99.064  440.12
  76   0.5719     88.600  0.0277    99.062  445.98
  77   0.5705     88.700  0.0268    99.066  451.81
  78   0.5788     88.650  0.0249    99.134  457.63
  79   0.5712     88.650  0.0254    99.122  463.46
  80   0.5741     88.780  0.0240    99.188  469.41
  81   0.5864     88.980  0.0223    99.210  475.24
  82   0.5770     88.600  0.0235    99.220  481.07
  83   0.5753     88.850  0.0234    99.214  486.91
  84   0.5847     88.600  0.0229    99.226  492.76
  85   0.5907     88.970  0.0201    99.326  498.59
