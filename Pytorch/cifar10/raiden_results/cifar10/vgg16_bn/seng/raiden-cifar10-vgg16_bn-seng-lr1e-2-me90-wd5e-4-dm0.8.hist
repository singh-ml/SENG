Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2225     55.460  1.6720    38.198  7.63
   2   1.0149     63.820  1.1848    57.972  13.47
   3   0.9041     68.770  0.9558    66.670  19.44
   4   0.7402     74.600  0.8303    71.504  25.26
   5   0.6816     76.730  0.7273    75.424  31.06
   6   0.6067     79.490  0.6522    78.192  36.88
   7   0.6159     78.760  0.5842    80.362  42.68
   8   0.5338     81.650  0.5442    81.700  48.50
   9   0.5228     81.920  0.5017    83.348  54.32
  10   0.5124     82.600  0.4640    84.606  60.30
  11   0.4691     84.050  0.4423    85.138  66.14
  12   0.4647     83.990  0.4130    86.200  71.99
  13   0.4516     84.920  0.3913    86.850  77.79
  14   0.4468     85.230  0.3589    87.988  83.60
  15   0.4511     84.790  0.3457    88.156  89.44
  16   0.4272     85.730  0.3369    88.566  95.25
  17   0.4169     86.050  0.3132    89.512  101.23
  18   0.4500     85.320  0.2936    90.088  107.04
  19   0.4035     86.830  0.2871    90.320  112.87
  20   0.4109     86.790  0.2695    91.050  118.69
  21   0.4036     86.470  0.2492    91.438  124.50
  22   0.3913     86.740  0.2463    91.724  130.33
  23   0.3849     87.750  0.2324    92.022  136.29
  24   0.3895     87.410  0.2200    92.538  142.11
  25   0.3997     87.750  0.2040    93.138  147.92
  26   0.3836     87.870  0.2024    93.204  153.73
  27   0.4116     87.150  0.1881    93.630  159.54
  28   0.3598     88.270  0.1812    93.908  165.36
  29   0.4063     87.190  0.1770    94.050  171.17
  30   0.3971     87.850  0.1714    94.156  177.14
  31   0.3745     88.220  0.1580    94.690  182.93
  32   0.3787     88.430  0.1516    94.880  188.75
  33   0.3882     88.730  0.1426    95.100  194.59
  34   0.3835     88.380  0.1402    95.258  200.41
  35   0.3688     88.560  0.1350    95.410  206.22
  36   0.3739     88.600  0.1263    95.736  212.04
  37   0.3759     88.760  0.1202    95.854  218.01
  38   0.3868     88.710  0.1163    96.028  223.83
  39   0.3910     88.810  0.1034    96.434  229.67
  40   0.3680     89.070  0.1026    96.586  235.51
  41   0.4063     88.830  0.0937    96.848  241.32
  42   0.3935     89.110  0.0920    96.818  247.14
  43   0.3736     89.600  0.0906    96.914  253.08
  44   0.3781     89.380  0.0861    97.028  258.91
  45   0.3850     90.180  0.0777    97.394  264.73
  46   0.4047     89.650  0.0728    97.498  270.54
  47   0.4055     89.470  0.0729    97.452  276.36
  48   0.4126     89.170  0.0701    97.558  282.23
  49   0.4181     89.660  0.0610    97.926  288.08
  50   0.4301     89.190  0.0632    97.838  293.96
  51   0.4198     89.770  0.0548    98.092  299.79
  52   0.4439     89.070  0.0532    98.202  305.63
  53   0.3965     89.790  0.0525    98.134  311.43
  54   0.4189     90.150  0.0470    98.340  317.24
  55   0.4468     89.740  0.0449    98.480  323.05
  56   0.4540     89.600  0.0399    98.648  328.99
  57   0.4284     90.350  0.0360    98.776  334.81
  58   0.4338     90.520  0.0357    98.832  340.63
  59   0.4224     90.350  0.0353    98.830  346.44
  60   0.4129     90.730  0.0296    98.958  352.24
  61   0.4781     90.010  0.0268    99.102  358.08
  62   0.4612     90.030  0.0260    99.098  363.91
  63   0.4367     90.610  0.0225    99.256  369.84
  64   0.4515     90.240  0.0248    99.166  375.66
  65   0.4389     90.910  0.0224    99.282  381.46
  66   0.4399     90.600  0.0201    99.306  387.30
  67   0.4481     90.740  0.0178    99.384  393.14
  68   0.4510     90.940  0.0157    99.488  398.97
  69   0.4460     91.000  0.0146    99.500  404.86
  70   0.4633     91.060  0.0139    99.534  410.69
  71   0.4528     91.090  0.0135    99.524  416.49
  72   0.4641     91.040  0.0112    99.620  422.35
  73   0.4642     90.980  0.0130    99.576  428.17
  74   0.4792     90.990  0.0112    99.614  434.00
  75   0.4576     90.940  0.0098    99.712  439.81
  76   0.4795     90.870  0.0089    99.724  445.73
  77   0.4948     91.050  0.0085    99.746  451.57
  78   0.5023     90.800  0.0089    99.700  457.37
  79   0.4853     91.050  0.0057    99.822  463.18
  80   0.4859     91.270  0.0072    99.746  469.00
  81   0.4837     91.110  0.0065    99.804  474.81
  82   0.4908     91.270  0.0068    99.778  480.79
  83   0.4883     91.090  0.0061    99.794  486.61
  84   0.4918     91.190  0.0074    99.752  492.45
  85   0.4900     91.110  0.0059    99.812  498.30
  86   0.5081     90.860  0.0049    99.830  504.12
  87   0.4917     91.240  0.0051    99.836  509.93
  88   0.4948     91.250  0.0044    99.854  515.73
  89   0.4891     91.260  0.0048    99.850  521.70
  90   0.4860     91.400  0.0047    99.842  527.54
