Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3248     52.180  1.7028    37.126  7.80
   2   1.0834     61.240  1.2027    57.382  13.63
   3   0.8701     69.930  0.9867    65.294  19.44
   4   0.7619     73.980  0.8588    70.064  25.27
   5   0.6587     77.780  0.7469    74.448  31.21
   6   0.6397     77.970  0.6773    77.020  37.05
   7   0.6040     79.640  0.6144    79.210  42.86
   8   0.5539     80.890  0.5673    80.860  48.70
   9   0.5338     82.210  0.5246    82.218  54.52
  10   0.5341     82.210  0.4868    83.538  60.37
  11   0.5061     82.910  0.4611    84.388  66.30
  12   0.4827     83.820  0.4335    85.408  72.11
  13   0.4620     84.270  0.4052    86.484  77.92
  14   0.5058     83.030  0.3863    87.058  83.72
  15   0.4524     84.610  0.3728    87.404  89.56
  16   0.4386     85.260  0.3507    88.416  95.39
  17   0.4165     85.790  0.3338    88.612  101.23
  18   0.4301     85.500  0.3094    89.478  107.18
  19   0.4272     85.090  0.2974    89.780  113.76
  20   0.4093     86.360  0.2819    90.478  119.58
  21   0.4170     85.940  0.2706    90.874  125.40
  22   0.4005     86.700  0.2559    91.344  131.23
  23   0.4276     85.930  0.2498    91.664  137.06
  24   0.3927     86.770  0.2325    92.198  143.05
  25   0.3952     86.930  0.2225    92.496  148.87
  26   0.3968     87.180  0.2136    92.812  154.70
  27   0.3804     87.520  0.2012    93.252  160.55
  28   0.3846     87.720  0.1929    93.408  166.38
  29   0.3823     88.090  0.1779    93.884  172.23
  30   0.3794     88.130  0.1701    94.158  178.05
  31   0.3895     87.570  0.1679    94.246  183.90
  32   0.4040     87.520  0.1523    94.772  189.88
  33   0.3923     87.780  0.1531    94.742  195.69
  34   0.3899     88.070  0.1437    95.108  201.54
  35   0.3881     87.800  0.1356    95.342  207.36
  36   0.3946     88.140  0.1300    95.572  213.20
  37   0.4226     87.600  0.1214    95.938  219.04
  38   0.3936     88.720  0.1142    96.152  225.00
  39   0.3981     88.900  0.1132    96.092  230.87
  40   0.3933     88.760  0.1026    96.486  236.67
  41   0.4073     88.760  0.1013    96.500  242.48
  42   0.3961     89.010  0.0920    96.736  248.30
  43   0.4276     88.330  0.0851    97.094  254.12
  44   0.4179     88.920  0.0805    97.278  259.94
  45   0.3983     89.450  0.0787    97.268  265.75
  46   0.4194     89.100  0.0721    97.512  271.58
  47   0.4357     88.740  0.0718    97.568  277.40
  48   0.4242     89.280  0.0703    97.626  283.25
  49   0.4463     88.860  0.0609    98.004  289.09
  50   0.4155     89.650  0.0610    97.932  294.87
  51   0.4538     88.760  0.0546    98.160  300.67
  52   0.4457     89.180  0.0515    98.234  306.62
  53   0.4540     89.350  0.0453    98.448  312.43
  54   0.4558     89.260  0.0454    98.442  318.26
  55   0.4642     89.460  0.0417    98.594  324.08
  56   0.4673     89.570  0.0399    98.686  329.88
  57   0.4604     89.490  0.0375    98.718  335.67
  58   0.4602     89.520  0.0406    98.596  341.64
  59   0.4653     89.560  0.0334    98.864  347.45
  60   0.4713     89.870  0.0326    98.872  353.28
  61   0.4804     89.770  0.0281    99.068  359.09
  62   0.4912     89.790  0.0274    99.068  364.90
  63   0.4872     89.820  0.0262    99.102  370.72
  64   0.4764     90.170  0.0222    99.270  376.54
  65   0.5057     89.960  0.0214    99.318  382.47
  66   0.5039     89.750  0.0219    99.280  388.28
  67   0.5003     89.740  0.0202    99.358  394.10
  68   0.5049     89.930  0.0182    99.428  399.95
  69   0.4972     90.010  0.0178    99.372  405.77
  70   0.5168     90.030  0.0155    99.464  411.67
  71   0.5182     90.210  0.0167    99.436  417.61
  72   0.5211     90.210  0.0140    99.520  423.45
  73   0.5311     90.160  0.0130    99.570  429.27
  74   0.5373     90.090  0.0120    99.604  435.12
  75   0.5281     90.350  0.0129    99.612  440.95
  76   0.5284     90.370  0.0116    99.616  446.80
  77   0.5395     90.270  0.0116    99.628  452.66
  78   0.5453     90.550  0.0093    99.676  458.60
  79   0.5643     90.130  0.0103    99.650  464.41
  80   0.5518     90.330  0.0111    99.650  470.21
  81   0.5431     90.230  0.0094    99.664  476.06
  82   0.5584     90.400  0.0095    99.696  481.87
  83   0.5594     90.230  0.0090    99.720  487.68
  84   0.5556     90.250  0.0087    99.720  493.64
  85   0.5630     90.280  0.0082    99.724  499.45
