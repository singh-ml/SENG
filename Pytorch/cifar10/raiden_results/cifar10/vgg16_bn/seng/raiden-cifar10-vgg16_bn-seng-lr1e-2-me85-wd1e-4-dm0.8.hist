Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3109     52.840  1.7055    36.710  7.62
   2   0.9949     64.830  1.1924    57.478  13.45
   3   0.8056     72.370  0.9722    66.346  19.28
   4   0.7865     73.060  0.8145    72.200  25.12
   5   0.6762     77.380  0.7223    75.512  30.92
   6   0.6023     79.920  0.6495    78.088  36.72
   7   0.5373     81.810  0.5901    80.172  42.65
   8   0.5166     82.630  0.5472    81.696  48.48
   9   0.5334     82.270  0.5071    83.042  54.27
  10   0.5157     82.400  0.4684    84.250  60.09
  11   0.4850     83.790  0.4432    85.190  65.90
  12   0.4731     84.150  0.4044    86.440  71.71
  13   0.4560     84.390  0.3794    87.180  77.53
  14   0.4348     84.960  0.3624    87.868  83.46
  15   0.4189     85.670  0.3423    88.442  89.25
  16   0.4127     86.130  0.3245    89.122  95.04
  17   0.4285     85.710  0.3131    89.494  100.84
  18   0.4094     86.160  0.2948    90.168  106.64
  19   0.4231     86.020  0.2792    90.534  112.45
  20   0.4090     86.230  0.2675    91.010  118.39
  21   0.3994     87.260  0.2454    91.670  124.20
  22   0.3914     86.890  0.2388    91.902  130.03
  23   0.3935     86.870  0.2274    92.360  135.86
  24   0.3807     87.500  0.2154    92.886  141.68
  25   0.3909     87.200  0.2065    92.984  147.49
  26   0.4022     86.780  0.1935    93.482  153.32
  27   0.3773     87.840  0.1830    93.820  159.26
  28   0.3890     87.640  0.1781    94.012  165.08
  29   0.3757     88.090  0.1657    94.378  170.89
  30   0.4019     87.550  0.1544    94.734  176.70
  31   0.3950     88.230  0.1544    94.794  182.54
  32   0.3912     88.320  0.1429    95.066  188.36
  33   0.3896     88.150  0.1397    95.182  194.33
  34   0.3540     88.920  0.1287    95.644  200.13
  35   0.3725     88.970  0.1200    95.890  205.97
  36   0.3880     88.920  0.1140    96.134  211.81
  37   0.3843     88.830  0.1112    96.180  217.61
  38   0.4020     89.030  0.0981    96.642  223.43
  39   0.3869     88.530  0.0967    96.664  229.25
  40   0.4182     88.560  0.0887    96.998  235.17
  41   0.3970     89.020  0.0901    96.904  240.97
  42   0.4217     88.620  0.0854    97.136  246.77
  43   0.4058     89.170  0.0758    97.468  252.59
  44   0.4102     89.120  0.0723    97.566  258.42
  45   0.4032     89.300  0.0746    97.414  264.23
  46   0.4290     88.730  0.0640    97.734  270.06
  47   0.4112     89.230  0.0646    97.774  276.03
  48   0.4326     88.940  0.0586    97.992  281.85
  49   0.4187     89.210  0.0568    98.118  287.65
  50   0.4433     89.200  0.0511    98.244  293.40
  51   0.4183     89.870  0.0470    98.364  299.20
  52   0.4360     89.530  0.0462    98.432  305.03
  53   0.4426     89.820  0.0429    98.514  310.94
  54   0.4315     89.430  0.0413    98.608  316.74
  55   0.4435     89.760  0.0369    98.712  322.58
  56   0.4566     89.660  0.0339    98.822  328.39
  57   0.4619     89.910  0.0322    98.872  334.19
  58   0.4791     89.970  0.0288    99.010  340.01
  59   0.4667     89.970  0.0298    98.986  345.96
  60   0.4736     89.810  0.0277    99.004  351.78
  61   0.4892     89.890  0.0243    99.134  357.57
  62   0.5028     89.720  0.0217    99.284  363.40
  63   0.4998     89.850  0.0225    99.252  369.20
  64   0.4826     90.210  0.0202    99.334  375.02
  65   0.4829     90.220  0.0205    99.280  380.82
  66   0.4791     90.250  0.0178    99.380  386.76
  67   0.4834     90.290  0.0164    99.418  392.57
  68   0.5018     90.040  0.0151    99.494  398.36
  69   0.5026     90.240  0.0156    99.474  404.17
  70   0.5048     90.380  0.0124    99.588  410.00
  71   0.5187     90.370  0.0119    99.606  415.79
  72   0.5186     90.280  0.0137    99.540  421.76
  73   0.5118     90.350  0.0115    99.608  427.57
  74   0.5241     90.200  0.0102    99.666  433.38
  75   0.5195     90.270  0.0109    99.624  439.21
  76   0.5334     90.260  0.0085    99.712  445.05
  77   0.5474     90.220  0.0099    99.670  450.85
  78   0.5291     90.590  0.0093    99.700  456.77
  79   0.5337     90.490  0.0083    99.742  462.60
  80   0.5328     90.580  0.0093    99.704  468.40
  81   0.5292     90.480  0.0070    99.770  474.22
  82   0.5381     90.580  0.0069    99.788  480.04
  83   0.5475     90.470  0.0071    99.752  485.84
  84   0.5458     90.440  0.0077    99.740  491.65
  85   0.5579     90.400  0.0077    99.736  497.62
