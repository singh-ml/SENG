Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5288     42.060  1.9083    28.004  7.84
   2   1.2879     52.290  1.4812    44.272  13.65
   3   1.1487     58.150  1.2961    52.188  19.47
   4   1.0574     61.540  1.1684    57.674  25.28
   5   0.9720     64.950  1.0748    61.164  31.11
   6   0.9127     66.980  1.0016    64.182  36.92
   7   0.8596     69.110  0.9394    66.466  42.92
   8   0.8162     70.560  0.8930    67.946  48.74
   9   0.7812     72.180  0.8454    69.974  54.58
  10   0.7607     72.760  0.8048    71.474  60.40
  11   0.7501     73.150  0.7643    73.224  66.23
  12   0.7010     74.930  0.7330    74.274  72.05
  13   0.6916     75.860  0.6994    75.464  77.86
  14   0.6661     76.960  0.6735    76.360  83.78
  15   0.6407     77.710  0.6474    77.404  89.59
  16   0.6352     77.840  0.6211    78.392  95.40
  17   0.6239     78.190  0.6031    78.862  101.21
  18   0.6046     78.940  0.5829    79.758  107.04
  19   0.6061     79.010  0.5656    80.166  112.86
  20   0.5806     80.030  0.5483    80.796  118.79
  21   0.5717     80.110  0.5319    81.274  124.60
  22   0.5594     80.390  0.5177    81.868  130.43
  23   0.5608     80.430  0.4974    82.802  136.23
  24   0.5399     81.370  0.4898    82.784  142.06
  25   0.5362     81.650  0.4767    83.348  147.87
  26   0.5371     81.740  0.4615    83.934  153.70
  27   0.5341     81.880  0.4489    84.316  159.63
  28   0.5243     82.440  0.4391    84.746  165.43
  29   0.5239     82.460  0.4236    85.322  171.26
  30   0.5222     82.500  0.4213    85.394  177.07
  31   0.5154     82.430  0.4059    85.916  182.91
  32   0.5219     82.700  0.3969    86.224  188.72
  33   0.5246     82.780  0.3868    86.458  194.55
  34   0.5167     83.030  0.3781    86.950  200.52
  35   0.5024     83.410  0.3707    87.178  206.34
  36   0.5135     83.200  0.3597    87.536  212.16
  37   0.5041     83.580  0.3556    87.596  217.99
  38   0.5058     83.630  0.3403    88.064  223.83
  39   0.4822     83.900  0.3326    88.322  229.66
  40   0.4973     83.560  0.3313    88.356  235.51
  41   0.5041     83.730  0.3202    88.722  241.41
  42   0.5027     83.410  0.3103    89.120  247.21
  43   0.5127     83.220  0.3025    89.472  253.02
  44   0.5021     83.680  0.2928    89.712  258.85
  45   0.5233     83.630  0.2911    89.770  264.66
  46   0.4966     83.950  0.2830    90.166  270.48
  47   0.5138     83.630  0.2742    90.370  276.41
  48   0.4874     84.130  0.2773    90.276  282.26
  49   0.4971     84.420  0.2629    90.786  288.08
  50   0.5189     84.420  0.2592    90.992  293.84
  51   0.5151     84.150  0.2481    91.282  299.67
  52   0.5031     84.430  0.2484    91.282  305.49
  53   0.5069     84.130  0.2407    91.600  311.45
  54   0.4955     84.520  0.2349    91.752  317.28
  55   0.4980     84.650  0.2340    91.872  323.10
  56   0.5098     84.600  0.2221    92.182  328.92
  57   0.5030     84.650  0.2154    92.358  334.75
  58   0.5146     84.570  0.2205    92.334  340.56
  59   0.4935     84.990  0.2037    92.848  346.40
  60   0.4992     85.360  0.2046    92.854  352.37
  61   0.5001     85.370  0.1973    93.038  358.18
  62   0.5081     85.560  0.1968    93.080  363.98
  63   0.4933     85.360  0.1912    93.368  369.82
  64   0.5428     84.250  0.1848    93.502  375.61
  65   0.4974     85.380  0.1869    93.520  381.42
  66   0.5271     84.850  0.1761    93.798  387.39
  67   0.5569     84.560  0.1772    93.834  393.22
  68   0.5438     85.120  0.1696    94.072  399.03
  69   0.5365     85.030  0.1691    93.988  404.86
  70   0.5376     85.020  0.1677    94.144  410.67
  71   0.5130     85.570  0.1600    94.398  416.48
  72   0.5216     85.410  0.1567    94.548  422.43
  73   0.5146     85.420  0.1561    94.486  428.27
  74   0.5240     85.310  0.1478    94.924  434.11
  75   0.5288     85.580  0.1461    94.900  439.92
  76   0.5274     85.960  0.1410    95.044  445.75
  77   0.5159     85.870  0.1405    95.204  451.54
  78   0.5456     85.670  0.1335    95.364  457.35
  79   0.5326     85.920  0.1325    95.376  463.28
  80   0.5273     85.900  0.1317    95.462  469.09
  81   0.5426     85.810  0.1290    95.544  474.89
  82   0.5541     85.280  0.1247    95.662  480.71
  83   0.5391     86.140  0.1203    95.736  486.55
  84   0.5540     85.950  0.1189    95.826  492.39
  85   0.5547     85.310  0.1217    95.624  498.23
  86   0.5508     85.490  0.1168    95.964  504.19
  87   0.5632     85.830  0.1130    96.094  509.99
  88   0.5475     86.080  0.1129    95.960  515.81
  89   0.5586     85.840  0.1133    96.050  521.65
  90   0.5735     85.410  0.1050    96.258  527.52
