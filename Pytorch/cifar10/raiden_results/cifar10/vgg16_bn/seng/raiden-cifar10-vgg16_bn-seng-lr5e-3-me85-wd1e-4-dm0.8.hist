Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4120     48.310  1.7094    36.126  7.73
   2   1.0353     62.520  1.2459    55.024  13.53
   3   0.8603     68.970  1.0266    63.494  19.36
   4   0.7876     71.770  0.8841    68.986  25.16
   5   0.7229     74.830  0.7818    72.592  31.14
   6   0.7191     75.070  0.7100    75.548  36.96
   7   0.6371     78.280  0.6617    77.256  42.77
   8   0.6024     79.300  0.6063    79.312  48.60
   9   0.5743     80.490  0.5712    80.394  54.42
  10   0.5532     80.960  0.5334    82.054  60.24
  11   0.5226     82.240  0.5008    82.940  66.07
  12   0.5045     82.620  0.4743    83.830  72.01
  13   0.4918     82.940  0.4470    84.778  77.82
  14   0.4763     83.490  0.4183    85.716  83.62
  15   0.4931     83.270  0.4013    86.270  89.47
  16   0.4780     83.650  0.3871    86.848  95.28
  17   0.4504     84.780  0.3609    87.614  101.08
  18   0.4394     85.430  0.3430    88.234  106.88
  19   0.4540     84.730  0.3326    88.682  112.84
  20   0.4390     85.540  0.3164    89.234  118.69
  21   0.4374     85.460  0.3043    89.544  124.55
  22   0.4515     84.860  0.2883    90.208  130.38
  23   0.4324     85.740  0.2752    90.738  136.19
  24   0.4746     85.000  0.2573    91.224  142.02
  25   0.4328     85.850  0.2577    91.202  147.96
  26   0.4282     86.130  0.2365    91.872  153.79
  27   0.4026     86.950  0.2268    92.150  159.60
  28   0.4284     86.120  0.2225    92.346  165.42
  29   0.4138     86.350  0.2126    92.620  171.26
  30   0.4407     85.970  0.1984    93.130  177.12
  31   0.4232     86.590  0.1905    93.430  183.05
  32   0.4072     86.660  0.1771    93.894  188.88
  33   0.4041     86.810  0.1780    93.922  194.70
  34   0.3925     87.510  0.1693    94.162  200.52
  35   0.4122     87.020  0.1621    94.406  206.35
  36   0.4153     87.050  0.1590    94.620  212.16
  37   0.4215     87.420  0.1446    95.044  217.99
  38   0.4085     87.890  0.1368    95.398  223.97
  39   0.4211     87.440  0.1304    95.480  229.80
  40   0.4345     87.200  0.1293    95.476  235.63
  41   0.4364     87.160  0.1238    95.746  241.44
  42   0.4440     87.550  0.1150    95.986  247.28
  43   0.4242     88.060  0.1122    96.044  253.11
  44   0.4340     87.990  0.1043    96.438  258.94
  45   0.4403     87.460  0.1026    96.400  264.91
  46   0.4443     87.990  0.0930    96.808  270.73
  47   0.4664     87.840  0.0902    96.854  276.53
  48   0.4536     87.640  0.0847    97.028  282.36
  49   0.4687     87.870  0.0840    97.094  288.15
  50   0.4886     87.850  0.0757    97.460  293.89
  51   0.4513     87.970  0.0787    97.318  299.80
  52   0.4639     87.910  0.0721    97.480  305.63
  53   0.4900     87.910  0.0664    97.702  311.45
  54   0.4676     88.620  0.0634    97.874  317.25
  55   0.4883     87.970  0.0590    97.908  323.05
  56   0.5009     88.060  0.0609    97.912  328.85
  57   0.5074     87.900  0.0559    98.088  334.80
  58   0.4853     88.370  0.0544    98.188  340.60
  59   0.5193     88.410  0.0473    98.402  346.44
  60   0.5045     88.350  0.0512    98.284  352.25
  61   0.5007     88.570  0.0503    98.310  358.06
  62   0.5245     88.220  0.0426    98.490  363.87
  63   0.5123     88.340  0.0417    98.588  369.69
  64   0.5053     88.840  0.0404    98.634  375.64
  65   0.5275     88.410  0.0382    98.654  381.47
  66   0.5242     88.460  0.0365    98.782  387.28
  67   0.5164     88.720  0.0337    98.828  393.08
  68   0.5215     88.940  0.0310    98.934  398.88
  69   0.5214     88.890  0.0334    98.918  404.69
  70   0.5111     88.950  0.0303    98.956  410.49
  71   0.5341     89.080  0.0285    99.004  416.47
  72   0.5383     88.870  0.0258    99.120  422.27
  73   0.5390     88.980  0.0284    99.040  428.10
  74   0.5462     88.500  0.0259    99.140  433.94
  75   0.5629     88.520  0.0227    99.236  439.74
  76   0.5575     88.480  0.0234    99.194  445.59
  77   0.5653     88.510  0.0222    99.252  451.54
  78   0.5546     88.600  0.0248    99.172  457.37
  79   0.5616     88.850  0.0187    99.350  463.20
  80   0.5610     88.780  0.0203    99.312  469.03
  81   0.5668     89.040  0.0214    99.342  474.84
  82   0.5777     88.920  0.0174    99.418  480.67
  83   0.5781     88.920  0.0211    99.262  486.64
  84   0.5667     89.060  0.0183    99.378  492.44
  85   0.5869     88.920  0.0169    99.422  498.26
