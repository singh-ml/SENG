Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3694     51.230  1.6806    37.674  7.79
   2   0.9742     64.390  1.2000    57.272  13.61
   3   0.8716     69.680  0.9883    65.292  19.43
   4   0.7793     72.520  0.8493    70.494  25.23
   5   0.6729     76.920  0.7475    74.350  31.03
   6   0.6206     78.530  0.6663    77.310  36.82
   7   0.5966     80.110  0.6087    79.198  42.61
   8   0.5891     79.680  0.5632    80.910  48.56
   9   0.5194     82.090  0.5160    82.530  54.35
  10   0.5362     81.650  0.4885    83.514  60.13
  11   0.5068     82.770  0.4518    84.812  65.93
  12   0.4680     83.820  0.4252    85.612  71.71
  13   0.5005     83.110  0.4014    86.332  77.53
  14   0.4855     83.330  0.3846    87.062  83.34
  15   0.4297     85.720  0.3560    87.936  89.31
  16   0.4455     84.730  0.3442    88.228  95.12
  17   0.4258     85.750  0.3202    89.280  100.92
  18   0.4227     85.920  0.2974    89.782  106.72
  19   0.4018     86.790  0.2893    90.174  112.54
  20   0.3936     86.340  0.2709    90.752  118.38
  21   0.4099     86.080  0.2645    91.112  124.35
  22   0.3850     86.700  0.2468    91.624  130.15
  23   0.4321     85.520  0.2346    91.990  135.95
  24   0.4142     86.370  0.2270    92.280  141.76
  25   0.4071     86.720  0.2120    92.880  147.58
  26   0.3802     87.520  0.2074    92.938  153.40
  27   0.3957     86.780  0.1963    93.242  159.18
  28   0.3863     87.790  0.1867    93.550  165.14
  29   0.4061     86.850  0.1788    93.924  170.96
  30   0.3828     87.880  0.1643    94.410  176.75
  31   0.4049     87.000  0.1666    94.280  182.57
  32   0.3908     87.820  0.1563    94.632  188.40
  33   0.3677     88.860  0.1466    95.066  194.21
  34   0.4089     87.910  0.1356    95.394  200.15
  35   0.3904     87.960  0.1309    95.488  205.94
  36   0.3913     88.210  0.1241    95.728  211.73
  37   0.4145     88.170  0.1197    95.914  217.52
  38   0.4330     88.080  0.1121    96.172  223.33
  39   0.3859     88.600  0.1109    96.084  229.13
  40   0.3985     88.660  0.1038    96.460  234.92
  41   0.4292     88.370  0.0939    96.818  240.85
  42   0.4348     88.670  0.0929    96.896  246.67
  43   0.4042     88.720  0.0910    96.826  252.46
  44   0.4322     88.580  0.0826    97.254  258.26
  45   0.4089     89.030  0.0757    97.428  264.05
  46   0.4220     89.170  0.0728    97.578  269.86
  47   0.4186     88.880  0.0702    97.638  275.80
  48   0.4176     89.490  0.0647    97.758  281.61
  49   0.4463     88.730  0.0629    97.840  287.44
  50   0.4479     88.730  0.0582    97.956  293.19
  51   0.4209     89.620  0.0574    98.056  298.99
  52   0.4561     89.070  0.0501    98.300  304.81
  53   0.4567     88.990  0.0471    98.412  310.62
  54   0.4412     89.290  0.0465    98.408  316.57
  55   0.4820     88.890  0.0408    98.610  322.38
  56   0.4561     89.370  0.0400    98.696  328.19
  57   0.4803     89.450  0.0344    98.758  333.99
  58   0.4734     89.280  0.0329    98.926  339.80
  59   0.4637     89.630  0.0315    98.920  345.60
  60   0.4698     89.690  0.0308    98.960  351.43
  61   0.4845     89.650  0.0271    99.078  357.34
  62   0.4697     90.040  0.0280    99.078  363.14
  63   0.4725     90.240  0.0218    99.286  368.98
  64   0.4864     89.890  0.0205    99.330  374.77
  65   0.5122     89.730  0.0185    99.380  380.58
  66   0.5026     89.850  0.0196    99.310  386.40
  67   0.4921     89.940  0.0185    99.348  392.35
  68   0.5040     90.060  0.0175    99.386  398.16
  69   0.5063     89.960  0.0160    99.486  403.98
  70   0.5245     90.010  0.0138    99.516  409.80
  71   0.4988     90.080  0.0145    99.528  415.61
  72   0.5157     89.890  0.0130    99.576  421.41
  73   0.5135     90.160  0.0139    99.540  427.20
  74   0.5158     90.110  0.0118    99.590  433.13
  75   0.5291     90.010  0.0116    99.600  438.95
  76   0.5181     90.340  0.0115    99.608  444.75
  77   0.5234     90.210  0.0099    99.676  450.53
  78   0.5297     90.210  0.0105    99.626  456.31
  79   0.5226     90.430  0.0097    99.684  462.11
  80   0.5257     90.440  0.0091    99.718  468.01
  81   0.5284     90.360  0.0084    99.704  473.82
  82   0.5387     90.480  0.0066    99.792  479.60
  83   0.5385     90.500  0.0071    99.766  485.40
  84   0.5387     90.450  0.0067    99.798  491.24
  85   0.5485     90.410  0.0068    99.778  497.04
