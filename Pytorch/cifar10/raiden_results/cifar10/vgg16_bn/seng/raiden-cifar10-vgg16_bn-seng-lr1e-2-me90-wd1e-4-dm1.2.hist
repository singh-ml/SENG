Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2914     51.630  1.7170    35.948  7.82
   2   1.1073     60.420  1.2254    55.926  13.63
   3   0.9259     67.300  1.0097    64.642  19.45
   4   0.7853     72.100  0.8718    69.678  25.31
   5   0.7102     75.220  0.7698    73.336  31.12
   6   0.6322     78.320  0.6792    76.928  36.94
   7   0.6222     78.320  0.6323    78.480  42.90
   8   0.5825     79.930  0.5830    80.374  48.78
   9   0.5364     81.900  0.5457    81.424  54.58
  10   0.5443     81.800  0.5122    82.582  60.43
  11   0.4923     82.870  0.4708    84.038  66.24
  12   0.4869     83.070  0.4461    84.862  72.08
  13   0.5149     82.330  0.4188    85.778  77.90
  14   0.4929     82.480  0.3944    86.538  83.85
  15   0.4481     84.740  0.3759    87.304  89.69
  16   0.4524     84.770  0.3509    88.040  95.52
  17   0.4588     84.110  0.3390    88.508  101.34
  18   0.4639     84.280  0.3189    89.146  107.20
  19   0.4531     84.580  0.3046    89.642  113.03
  20   0.4350     85.610  0.2912    89.998  118.88
  21   0.4324     85.470  0.2780    90.484  124.86
  22   0.4203     85.690  0.2651    90.946  130.69
  23   0.4244     86.080  0.2528    91.536  136.52
  24   0.3971     87.010  0.2385    91.786  142.35
  25   0.3923     86.300  0.2283    92.194  148.15
  26   0.4227     86.410  0.2101    92.752  153.97
  27   0.3973     87.230  0.2123    92.680  159.91
  28   0.4014     87.390  0.1988    93.202  165.73
  29   0.4044     86.520  0.1892    93.414  171.55
  30   0.3980     87.080  0.1794    93.884  177.38
  31   0.3886     87.290  0.1731    94.100  183.19
  32   0.4090     87.770  0.1600    94.492  189.04
  33   0.3960     87.830  0.1573    94.552  194.84
  34   0.4501     87.070  0.1434    95.066  200.80
  35   0.3974     88.050  0.1379    95.276  206.64
  36   0.4142     87.860  0.1302    95.498  212.44
  37   0.3974     88.160  0.1267    95.638  218.26
  38   0.4005     88.070  0.1205    95.872  224.08
  39   0.3852     88.070  0.1183    95.870  229.93
  40   0.4257     87.700  0.1038    96.484  235.89
  41   0.4140     87.890  0.1043    96.448  241.71
  42   0.4177     87.940  0.0996    96.560  247.54
  43   0.4396     87.970  0.0949    96.644  253.35
  44   0.4279     88.120  0.0904    96.870  259.17
  45   0.4555     88.090  0.0862    97.060  264.98
  46   0.4489     87.980  0.0837    97.098  270.80
  47   0.4406     88.390  0.0758    97.414  276.75
  48   0.4465     88.190  0.0730    97.486  282.56
  49   0.4400     88.560  0.0705    97.578  288.36
  50   0.4601     88.380  0.0608    97.922  294.11
  51   0.4384     88.960  0.0644    97.788  299.96
  52   0.4514     88.400  0.0610    97.894  305.80
  53   0.4852     88.260  0.0502    98.320  311.77
  54   0.4481     88.730  0.0551    98.190  317.59
  55   0.4693     88.530  0.0451    98.476  323.41
  56   0.4825     88.600  0.0441    98.536  329.26
  57   0.4826     89.060  0.0415    98.582  335.11
  58   0.4855     88.750  0.0409    98.612  340.93
  59   0.4911     89.260  0.0372    98.750  346.76
  60   0.4984     88.660  0.0368    98.750  352.72
  61   0.4863     89.230  0.0362    98.736  358.55
  62   0.5037     89.080  0.0287    99.064  364.40
  63   0.4869     89.370  0.0295    99.032  370.22
  64   0.5132     89.090  0.0266    99.114  376.04
  65   0.4985     89.160  0.0270    99.046  381.87
  66   0.5088     89.330  0.0245    99.196  387.81
  67   0.5090     89.590  0.0217    99.240  393.64
  68   0.5373     89.350  0.0212    99.308  399.48
  69   0.5312     89.130  0.0192    99.352  405.28
  70   0.5316     89.290  0.0176    99.412  411.10
  71   0.5307     89.280  0.0189    99.356  416.91
  72   0.5335     89.260  0.0176    99.430  422.85
  73   0.5216     89.540  0.0167    99.454  428.66
  74   0.5474     89.410  0.0140    99.502  434.51
  75   0.5710     89.420  0.0136    99.544  440.36
  76   0.5481     89.490  0.0123    99.614  446.21
  77   0.5546     89.780  0.0127    99.558  452.03
  78   0.5650     89.430  0.0126    99.576  457.84
  79   0.5727     89.380  0.0108    99.652  463.81
  80   0.5796     89.450  0.0098    99.672  469.61
  81   0.5783     89.570  0.0112    99.646  475.44
  82   0.5730     89.580  0.0104    99.630  481.27
  83   0.5754     89.480  0.0100    99.670  487.09
  84   0.5751     89.580  0.0103    99.666  492.89
  85   0.5849     89.590  0.0094    99.676  498.87
  86   0.5802     89.420  0.0088    99.718  504.69
  87   0.5772     89.690  0.0093    99.692  510.54
  88   0.5867     89.720  0.0081    99.738  516.39
  89   0.5792     89.450  0.0102    99.678  522.20
  90   0.5835     89.530  0.0083    99.742  528.02
