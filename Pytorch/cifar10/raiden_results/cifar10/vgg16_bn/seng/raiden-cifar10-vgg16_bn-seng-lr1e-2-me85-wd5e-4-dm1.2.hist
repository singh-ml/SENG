Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3000     52.250  1.6887    37.148  8.45
   2   1.0401     63.470  1.2168    56.482  14.37
   3   0.8922     68.580  0.9990    64.568  20.16
   4   0.7691     72.920  0.8522    70.208  25.96
   5   0.6700     76.820  0.7470    74.132  31.75
   6   0.6371     77.800  0.6756    77.098  37.54
   7   0.5921     79.690  0.6262    78.806  43.34
   8   0.5945     79.540  0.5739    80.508  49.39
   9   0.5441     80.910  0.5301    81.830  55.22
  10   0.5031     82.770  0.4927    83.254  61.03
  11   0.4974     82.970  0.4588    84.498  66.83
  12   0.5277     82.030  0.4398    85.158  72.62
  13   0.4948     83.160  0.4071    86.232  78.42
  14   0.4487     84.650  0.3898    86.882  84.21
  15   0.4387     85.290  0.3678    87.538  90.01
  16   0.4763     84.130  0.3520    88.044  95.97
  17   0.4529     84.540  0.3326    88.842  101.77
  18   0.4202     85.820  0.3208    89.162  107.56
  19   0.4304     85.760  0.3058    89.666  113.36
  20   0.4257     85.850  0.2911    90.060  119.14
  21   0.4157     86.080  0.2775    90.622  124.94
  22   0.4169     85.900  0.2597    91.104  130.73
  23   0.3774     87.600  0.2450    91.702  136.51
  24   0.4020     86.780  0.2394    91.680  142.34
  25   0.3997     87.100  0.2272    92.246  148.14
  26   0.4095     87.110  0.2146    92.732  153.97
  27   0.4087     87.030  0.2081    92.918  159.78
  28   0.4017     87.260  0.1989    93.260  165.58
  29   0.3955     87.260  0.1843    93.726  171.53
  30   0.4157     86.860  0.1843    93.742  177.32
  31   0.4074     87.600  0.1697    94.330  183.13
  32   0.4025     87.560  0.1695    94.214  188.93
  33   0.4093     87.630  0.1548    94.660  194.73
  34   0.3892     87.660  0.1519    94.840  200.55
  35   0.4205     87.780  0.1401    95.166  206.52
  36   0.3902     87.850  0.1373    95.232  212.32
  37   0.3937     88.480  0.1330    95.538  218.09
  38   0.3974     88.430  0.1221    95.916  223.92
  39   0.4056     88.380  0.1116    96.112  229.70
  40   0.3924     88.560  0.1107    96.218  235.51
  41   0.4087     88.170  0.1030    96.514  241.33
  42   0.3958     88.500  0.0997    96.574  247.28
  43   0.3980     89.110  0.0922    96.848  253.09
  44   0.3815     88.890  0.0916    96.810  258.88
  45   0.4082     88.650  0.0839    97.106  264.70
  46   0.4215     88.490  0.0781    97.316  270.52
  47   0.4052     88.980  0.0727    97.512  276.32
  48   0.3933     89.260  0.0725    97.476  282.12
  49   0.4233     88.700  0.0706    97.532  288.10
  50   0.4028     89.470  0.0604    97.946  293.81
  51   0.4127     89.490  0.0601    97.966  299.61
  52   0.4126     89.300  0.0555    98.056  305.40
  53   0.4389     88.990  0.0522    98.184  311.19
  54   0.4279     89.470  0.0516    98.300  317.01
  55   0.4360     89.550  0.0464    98.450  322.92
  56   0.4281     89.740  0.0430    98.498  328.72
  57   0.4291     89.640  0.0411    98.564  334.53
  58   0.4642     89.050  0.0375    98.734  340.36
  59   0.4493     89.350  0.0357    98.816  346.17
  60   0.4547     89.620  0.0297    98.998  351.96
  61   0.4388     89.900  0.0342    98.852  357.78
  62   0.4440     89.860  0.0300    98.964  363.58
  63   0.4621     89.980  0.0237    99.198  369.51
  64   0.4730     89.620  0.0239    99.200  375.32
  65   0.4855     89.690  0.0214    99.264  381.15
  66   0.4631     90.160  0.0199    99.336  386.95
  67   0.4643     90.140  0.0198    99.306  392.75
  68   0.4753     90.000  0.0192    99.330  398.58
  69   0.4717     90.150  0.0162    99.464  404.53
  70   0.4697     90.170  0.0154    99.468  410.32
  71   0.4748     90.430  0.0143    99.534  416.11
  72   0.4864     90.370  0.0136    99.572  421.90
  73   0.4790     90.150  0.0133    99.568  427.71
  74   0.4780     90.580  0.0110    99.624  433.53
  75   0.5009     90.290  0.0109    99.656  439.33
  76   0.4875     90.290  0.0100    99.624  445.24
  77   0.4945     90.240  0.0085    99.736  451.05
  78   0.5015     90.350  0.0093    99.694  456.85
  79   0.5054     90.320  0.0088    99.728  462.64
  80   0.4932     90.300  0.0089    99.710  468.43
  81   0.5024     90.380  0.0087    99.726  474.21
  82   0.5110     90.240  0.0083    99.742  480.01
  83   0.5038     90.420  0.0077    99.736  485.94
  84   0.5016     90.250  0.0076    99.770  491.73
  85   0.5071     90.630  0.0077    99.754  497.51
