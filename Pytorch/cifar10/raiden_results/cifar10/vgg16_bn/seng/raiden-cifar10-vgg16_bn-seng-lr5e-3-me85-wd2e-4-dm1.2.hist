Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3291     50.310  1.7299    35.370  7.94
   2   1.1123     58.680  1.2541    54.522  13.73
   3   0.9778     64.230  1.0570    61.944  19.56
   4   0.8885     68.270  0.9332    66.810  25.36
   5   0.7606     72.570  0.8393    70.768  31.19
   6   0.7307     74.260  0.7550    73.604  37.03
   7   0.6757     76.360  0.7065    75.376  42.84
   8   0.6254     77.990  0.6518    77.272  48.80
   9   0.6059     79.000  0.6066    79.192  54.65
  10   0.5735     80.210  0.5732    80.228  60.46
  11   0.5623     80.520  0.5428    81.348  66.26
  12   0.5654     80.620  0.5123    82.532  72.09
  13   0.5305     81.960  0.4898    83.264  77.90
  14   0.5112     82.320  0.4642    84.020  83.70
  15   0.5017     82.680  0.4456    84.776  89.66
  16   0.5102     82.410  0.4217    85.538  95.51
  17   0.4785     83.830  0.4070    86.130  101.32
  18   0.4736     83.640  0.3880    86.752  107.14
  19   0.4647     84.110  0.3689    87.372  112.94
  20   0.4769     83.510  0.3548    87.798  118.75
  21   0.4687     84.150  0.3416    88.304  124.68
  22   0.4512     84.570  0.3294    88.702  130.51
  23   0.4642     84.250  0.3154    89.098  136.33
  24   0.4426     85.170  0.3044    89.560  142.18
  25   0.4275     85.570  0.2886    90.052  147.98
  26   0.4489     84.680  0.2836    90.264  153.79
  27   0.4556     84.710  0.2678    90.780  159.73
  28   0.4438     85.350  0.2525    91.344  165.53
  29   0.4418     85.790  0.2452    91.696  171.37
  30   0.4274     85.670  0.2372    91.812  177.21
  31   0.4236     86.270  0.2269    92.168  183.02
  32   0.4590     85.900  0.2165    92.696  188.84
  33   0.4334     85.860  0.2114    92.690  194.67
  34   0.4576     85.110  0.2008    93.078  200.50
  35   0.4643     85.310  0.1940    93.376  206.32
  36   0.4467     85.730  0.1901    93.462  212.14
  37   0.4314     86.570  0.1789    93.786  217.98
  38   0.4238     86.410  0.1719    93.974  223.78
  39   0.4397     86.490  0.1644    94.318  229.59
  40   0.4548     86.130  0.1528    94.658  235.52
  41   0.4423     86.240  0.1559    94.594  241.36
  42   0.4335     87.070  0.1439    95.026  247.16
  43   0.4599     86.400  0.1360    95.350  252.98
  44   0.4599     86.440  0.1356    95.256  258.82
  45   0.4502     86.610  0.1276    95.548  264.62
  46   0.4377     86.800  0.1234    95.694  270.43
  47   0.4504     86.730  0.1163    96.056  276.37
  48   0.4575     86.740  0.1157    95.990  282.20
  49   0.4647     86.940  0.1084    96.226  288.03
  50   0.4529     87.190  0.1017    96.428  293.77
  51   0.4695     86.910  0.0963    96.648  299.69
  52   0.4831     87.000  0.0913    96.776  305.50
  53   0.4792     87.000  0.0903    96.838  311.43
  54   0.4932     86.720  0.0869    97.030  317.27
  55   0.4797     87.220  0.0830    97.176  323.09
  56   0.4864     87.110  0.0788    97.274  328.89
  57   0.4873     87.130  0.0739    97.438  334.75
  58   0.5054     87.400  0.0679    97.614  340.55
  59   0.4892     87.570  0.0678    97.638  346.36
  60   0.4922     87.760  0.0634    97.762  352.30
  61   0.4971     87.370  0.0627    97.884  358.14
  62   0.5086     87.540  0.0582    97.984  363.95
  63   0.5269     87.650  0.0561    98.124  369.76
  64   0.5061     87.800  0.0570    97.982  375.55
  65   0.5255     87.700  0.0543    98.186  381.41
  66   0.5287     87.510  0.0499    98.236  387.38
  67   0.5388     87.430  0.0453    98.490  393.22
  68   0.5310     87.720  0.0470    98.408  399.06
  69   0.5492     87.540  0.0432    98.538  404.89
  70   0.5366     87.610  0.0424    98.530  410.70
  71   0.5434     87.820  0.0416    98.594  416.54
  72   0.5445     88.100  0.0391    98.716  422.37
  73   0.5480     87.810  0.0362    98.724  428.30
  74   0.5642     87.630  0.0339    98.800  434.13
  75   0.5736     87.840  0.0353    98.754  439.94
  76   0.5603     87.810  0.0317    98.864  445.75
  77   0.5714     87.780  0.0343    98.834  451.61
  78   0.5593     87.940  0.0319    98.976  457.45
  79   0.5540     88.100  0.0327    98.896  463.44
  80   0.5817     88.170  0.0288    99.022  469.28
  81   0.5839     88.210  0.0287    98.970  475.10
  82   0.5915     88.070  0.0281    99.026  480.91
  83   0.6062     87.900  0.0269    99.078  486.73
  84   0.5899     88.240  0.0256    99.140  492.53
  85   0.5869     88.050  0.0288    98.982  498.46
