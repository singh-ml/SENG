Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5282     42.220  1.9171    27.968  7.77
   2   1.2998     52.850  1.4766    44.580  13.57
   3   1.1381     58.940  1.2927    52.752  19.36
   4   1.0372     62.510  1.1690    57.594  25.19
   5   0.9555     65.690  1.0699    61.432  31.11
   6   0.9209     67.350  0.9961    64.152  36.96
   7   0.8827     68.500  0.9321    66.552  42.75
   8   0.8215     71.210  0.8799    68.754  48.62
   9   0.7989     71.960  0.8324    70.494  54.42
  10   0.7504     73.790  0.7899    71.828  60.25
  11   0.7191     74.470  0.7513    73.532  66.05
  12   0.7052     75.860  0.7238    74.710  72.03
  13   0.7018     76.170  0.6943    75.566  77.84
  14   0.6667     76.870  0.6641    76.760  83.66
  15   0.6498     77.380  0.6428    77.490  89.49
  16   0.6426     77.960  0.6203    78.336  95.31
  17   0.6422     77.830  0.5998    79.186  101.12
  18   0.6231     78.290  0.5808    79.808  106.90
  19   0.5960     79.450  0.5631    80.172  112.81
  20   0.5882     80.010  0.5431    81.154  118.63
  21   0.5827     80.130  0.5294    81.494  124.42
  22   0.5834     80.320  0.5172    81.966  130.27
  23   0.5849     79.990  0.4986    82.906  136.09
  24   0.5615     80.850  0.4855    83.132  141.89
  25   0.5690     80.860  0.4754    83.586  147.69
  26   0.5602     81.260  0.4640    83.852  153.68
  27   0.5541     81.780  0.4473    84.478  159.47
  28   0.5439     82.320  0.4333    84.754  165.29
  29   0.5460     81.460  0.4264    85.248  171.11
  30   0.5309     82.110  0.4190    85.488  176.91
  31   0.5312     82.040  0.4094    85.694  182.70
  32   0.5272     82.520  0.3973    86.072  188.67
  33   0.5236     82.640  0.3832    86.580  194.49
  34   0.5353     82.160  0.3727    86.958  200.29
  35   0.5331     82.650  0.3625    87.308  206.08
  36   0.5174     83.060  0.3627    87.356  211.89
  37   0.5179     83.230  0.3537    87.700  217.71
  38   0.5266     82.640  0.3402    88.136  223.52
  39   0.5221     83.050  0.3342    88.444  229.46
  40   0.5280     82.690  0.3220    88.708  235.27
  41   0.5201     83.440  0.3157    88.874  241.07
  42   0.5234     83.470  0.3119    89.070  246.87
  43   0.5256     83.320  0.3013    89.574  252.67
  44   0.5245     83.700  0.2979    89.610  258.46
  45   0.5123     83.710  0.2902    89.842  264.29
  46   0.5132     83.980  0.2801    90.360  270.25
  47   0.5083     83.790  0.2787    90.218  276.04
  48   0.5290     83.020  0.2717    90.598  281.87
  49   0.5197     83.570  0.2625    90.890  287.69
  50   0.5509     83.210  0.2587    91.078  293.43
  51   0.5099     84.080  0.2581    90.922  299.25
  52   0.5179     83.780  0.2442    91.540  305.07
  53   0.5033     84.380  0.2401    91.508  311.02
  54   0.5269     84.120  0.2327    91.892  316.82
  55   0.5216     83.850  0.2273    92.190  322.64
  56   0.5200     84.330  0.2233    92.132  328.48
  57   0.5294     84.300  0.2162    92.474  334.30
  58   0.5316     84.200  0.2130    92.590  340.13
  59   0.5555     84.210  0.2057    92.786  346.08
  60   0.5421     84.610  0.2083    92.714  351.88
  61   0.5203     84.390  0.2035    92.882  357.72
  62   0.5400     84.530  0.1918    93.286  363.52
  63   0.5456     84.220  0.1875    93.508  369.33
  64   0.5336     84.800  0.1890    93.410  375.16
  65   0.5321     84.790  0.1793    93.666  380.98
  66   0.5391     84.290  0.1812    93.602  386.92
  67   0.5410     85.000  0.1707    94.018  392.72
  68   0.5410     84.510  0.1692    94.172  398.53
  69   0.5406     85.090  0.1635    94.194  404.32
  70   0.5499     84.760  0.1640    94.196  410.14
  71   0.5217     85.190  0.1580    94.462  415.94
  72   0.5456     84.860  0.1571    94.472  421.79
  73   0.5341     85.040  0.1577    94.472  427.73
  74   0.5596     84.770  0.1494    94.776  433.54
  75   0.5745     84.590  0.1417    95.136  439.35
  76   0.5553     85.060  0.1410    95.022  445.15
  77   0.5664     85.140  0.1403    95.000  450.96
  78   0.5448     84.870  0.1415    94.954  456.78
  79   0.5869     84.590  0.1297    95.456  462.71
  80   0.5649     84.640  0.1361    95.212  468.53
  81   0.5858     84.870  0.1277    95.514  474.33
  82   0.5666     85.330  0.1267    95.628  480.16
  83   0.5644     85.000  0.1201    95.852  486.01
  84   0.5963     85.330  0.1248    95.628  491.81
  85   0.5841     84.860  0.1150    95.978  497.63
