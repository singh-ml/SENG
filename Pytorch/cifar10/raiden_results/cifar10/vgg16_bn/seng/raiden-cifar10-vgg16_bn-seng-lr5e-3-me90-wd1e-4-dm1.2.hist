Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3898     48.900  1.7267    35.354  7.88
   2   1.0977     60.200  1.2791    53.444  13.71
   3   0.9274     66.460  1.0778    61.210  19.66
   4   0.8352     69.720  0.9479    66.428  25.47
   5   0.7486     74.110  0.8409    70.526  31.27
   6   0.7235     74.530  0.7672    73.196  37.08
   7   0.6723     76.950  0.7010    75.772  42.90
   8   0.6403     77.610  0.6508    77.300  48.69
   9   0.5924     79.320  0.6111    78.862  54.62
  10   0.6079     79.180  0.5707    80.292  60.43
  11   0.5771     80.450  0.5405    81.408  66.22
  12   0.5685     80.430  0.5132    82.386  72.06
  13   0.5353     81.680  0.4884    83.112  77.86
  14   0.5028     82.620  0.4631    84.098  83.65
  15   0.5393     80.840  0.4425    84.818  89.51
  16   0.4885     83.080  0.4178    85.546  95.43
  17   0.4925     83.610  0.4072    86.220  101.27
  18   0.4913     83.520  0.3842    86.692  107.06
  19   0.4821     83.370  0.3725    87.260  112.87
  20   0.4648     84.440  0.3571    87.820  118.70
  21   0.4903     83.290  0.3406    88.308  124.51
  22   0.4740     84.150  0.3273    88.636  130.48
  23   0.4692     84.340  0.3129    89.260  136.29
  24   0.5029     83.130  0.2991    89.554  142.11
  25   0.4641     84.890  0.2856    90.078  147.93
  26   0.4513     85.510  0.2775    90.538  153.76
  27   0.4420     85.370  0.2673    90.786  159.55
  28   0.4490     85.120  0.2565    91.094  165.36
  29   0.4407     85.690  0.2460    91.594  171.17
  30   0.4516     85.110  0.2349    91.862  177.13
  31   0.4685     85.240  0.2280    92.164  182.93
  32   0.4500     85.920  0.2173    92.484  188.73
  33   0.4609     85.280  0.2127    92.602  194.54
  34   0.4423     86.000  0.2017    93.024  200.35
  35   0.4328     86.010  0.1975    93.118  206.17
  36   0.4622     86.260  0.1879    93.490  211.98
  37   0.4647     86.080  0.1828    93.680  217.94
  38   0.4271     86.620  0.1817    93.610  223.75
  39   0.4386     86.800  0.1683    94.132  229.58
  40   0.4499     85.970  0.1568    94.502  235.40
  41   0.4392     86.750  0.1516    94.676  241.21
  42   0.4463     86.860  0.1492    94.864  247.03
  43   0.4626     86.420  0.1429    95.094  252.97
  44   0.4784     86.390  0.1371    95.342  258.77
  45   0.4510     87.050  0.1283    95.380  264.61
  46   0.4497     87.350  0.1237    95.732  270.42
  47   0.4447     87.300  0.1179    95.804  276.22
  48   0.4755     86.850  0.1127    96.056  282.04
  49   0.4951     86.550  0.1072    96.354  287.96
  50   0.4601     87.670  0.1008    96.428  293.69
  51   0.4929     87.090  0.1000    96.570  299.49
  52   0.4785     87.400  0.0985    96.540  305.32
  53   0.4731     87.330  0.0931    96.778  311.11
  54   0.4751     87.770  0.0838    97.118  316.94
  55   0.4739     87.200  0.0829    97.082  322.75
  56   0.4840     87.710  0.0801    97.174  328.58
  57   0.5001     87.410  0.0808    97.176  334.57
  58   0.4900     87.620  0.0734    97.546  340.42
  59   0.5008     87.490  0.0689    97.580  346.24
  60   0.4992     87.620  0.0700    97.534  352.04
  61   0.4932     87.670  0.0667    97.790  357.88
  62   0.5100     87.890  0.0633    97.822  363.69
  63   0.5163     87.750  0.0574    98.058  369.64
  64   0.5120     87.980  0.0578    98.028  375.46
  65   0.5127     88.130  0.0533    98.136  381.27
  66   0.5437     87.820  0.0492    98.340  387.07
  67   0.5304     87.930  0.0502    98.270  392.87
  68   0.5241     88.090  0.0481    98.332  398.71
  69   0.5404     88.330  0.0455    98.490  404.51
  70   0.5476     88.160  0.0433    98.498  410.31
  71   0.5395     87.870  0.0394    98.682  416.11
  72   0.5339     88.310  0.0406    98.596  421.93
  73   0.5470     88.240  0.0386    98.694  427.76
  74   0.5625     88.240  0.0362    98.746  433.58
  75   0.5564     88.400  0.0347    98.790  439.37
  76   0.5548     88.340  0.0340    98.810  445.18
  77   0.5735     88.100  0.0341    98.808  451.10
  78   0.5731     88.200  0.0305    98.990  456.91
  79   0.5709     88.460  0.0318    98.884  462.71
  80   0.5688     88.480  0.0315    98.984  468.51
  81   0.5879     88.220  0.0297    98.976  474.32
  82   0.5807     88.410  0.0289    99.038  480.11
  83   0.5827     88.330  0.0255    99.140  486.10
  84   0.5826     88.460  0.0251    99.112  491.93
  85   0.5730     88.390  0.0271    99.036  497.76
  86   0.5822     88.630  0.0245    99.146  503.57
  87   0.5955     88.280  0.0232    99.212  509.36
  88   0.6002     88.610  0.0232    99.214  515.19
  89   0.6101     88.340  0.0228    99.218  521.14
  90   0.5910     88.630  0.0226    99.266  526.94
