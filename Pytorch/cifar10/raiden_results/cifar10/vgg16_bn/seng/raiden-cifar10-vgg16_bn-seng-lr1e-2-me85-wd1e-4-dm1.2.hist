Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2942     52.090  1.7105    36.350  7.63
   2   1.0238     63.870  1.2189    56.356  13.48
   3   0.8578     69.440  0.9959    65.036  19.27
   4   0.7855     72.120  0.8648    69.884  25.22
   5   0.6946     76.120  0.7612    73.574  31.03
   6   0.6482     77.350  0.6823    76.560  36.87
   7   0.5942     79.470  0.6286    78.480  42.65
   8   0.5869     80.020  0.5838    80.286  48.47
   9   0.5636     80.760  0.5397    81.572  54.28
  10   0.5493     80.910  0.5086    82.928  60.24
  11   0.5334     81.570  0.4743    83.938  66.05
  12   0.5081     82.330  0.4461    84.936  71.84
  13   0.5038     83.540  0.4234    85.606  77.66
  14   0.4725     84.070  0.3974    86.492  83.47
  15   0.4412     85.090  0.3817    86.940  89.28
  16   0.4388     85.020  0.3591    87.756  95.09
  17   0.4415     84.990  0.3386    88.448  101.03
  18   0.4246     85.370  0.3233    89.050  106.84
  19   0.4534     84.470  0.3083    89.430  112.69
  20   0.4344     85.530  0.2917    90.074  118.52
  21   0.4159     85.840  0.2794    90.476  124.33
  22   0.3983     86.570  0.2666    90.886  130.15
  23   0.4093     86.400  0.2561    91.282  135.98
  24   0.4136     86.240  0.2396    91.744  141.91
  25   0.4141     86.580  0.2284    92.208  147.70
  26   0.3944     86.910  0.2187    92.552  153.50
  27   0.3977     87.310  0.2097    92.950  159.32
  28   0.3933     86.910  0.1918    93.390  165.12
  29   0.4208     86.370  0.1927    93.500  170.92
  30   0.3899     87.440  0.1848    93.778  176.84
  31   0.4061     87.060  0.1712    94.086  182.67
  32   0.3993     87.260  0.1679    94.280  188.51
  33   0.3880     87.470  0.1526    94.764  194.31
  34   0.4450     86.560  0.1508    94.702  200.11
  35   0.3904     87.860  0.1424    95.144  205.92
  36   0.4069     87.550  0.1331    95.398  211.72
  37   0.4169     87.520  0.1310    95.546  217.65
  38   0.4053     87.800  0.1204    95.798  223.46
  39   0.4023     88.160  0.1151    96.008  229.24
  40   0.4308     87.690  0.1080    96.336  235.09
  41   0.4359     87.370  0.1024    96.424  240.91
  42   0.4419     88.130  0.0981    96.680  246.70
  43   0.4264     87.820  0.0985    96.586  252.51
  44   0.3906     88.850  0.0868    96.962  258.48
  45   0.4442     88.250  0.0811    97.220  264.29
  46   0.4419     88.150  0.0824    97.198  270.14
  47   0.4400     88.610  0.0768    97.340  275.95
  48   0.4317     88.380  0.0713    97.518  281.75
  49   0.4520     88.690  0.0658    97.830  287.52
  50   0.4440     88.330  0.0642    97.742  293.37
  51   0.4274     88.900  0.0636    97.802  299.20
  52   0.4460     88.860  0.0519    98.290  305.25
  53   0.4459     88.820  0.0526    98.246  311.05
  54   0.4521     88.480  0.0530    98.166  316.85
  55   0.4622     89.060  0.0461    98.386  322.67
  56   0.4666     88.820  0.0441    98.444  328.49
  57   0.4540     88.990  0.0435    98.536  334.44
  58   0.4712     88.450  0.0376    98.738  340.26
  59   0.4591     88.910  0.0384    98.664  346.05
  60   0.4789     89.320  0.0329    98.856  351.86
  61   0.4855     88.810  0.0321    98.890  357.67
  62   0.4863     89.050  0.0308    98.952  363.50
  63   0.4888     89.250  0.0268    99.086  369.30
  64   0.5045     88.930  0.0263    99.134  375.12
  65   0.4910     89.100  0.0267    99.082  380.92
  66   0.4980     89.470  0.0231    99.222  386.73
  67   0.5185     89.130  0.0228    99.248  392.54
  68   0.5123     89.100  0.0221    99.174  398.34
  69   0.5238     89.340  0.0201    99.338  404.15
  70   0.5128     89.370  0.0186    99.370  410.10
  71   0.5139     89.150  0.0177    99.412  415.90
  72   0.5070     89.550  0.0178    99.434  421.69
  73   0.5170     89.680  0.0149    99.494  427.49
  74   0.5331     89.360  0.0143    99.518  433.30
  75   0.5238     89.600  0.0151    99.508  439.10
  76   0.5329     89.530  0.0144    99.540  444.91
  77   0.5226     89.620  0.0131    99.520  450.84
  78   0.5258     89.690  0.0119    99.598  456.64
  79   0.5255     89.690  0.0133    99.558  462.43
  80   0.5225     89.590  0.0124    99.600  468.22
  81   0.5500     89.520  0.0108    99.652  474.06
  82   0.5409     89.710  0.0116    99.608  479.86
  83   0.5559     89.670  0.0096    99.666  485.83
  84   0.5472     89.640  0.0104    99.622  491.65
  85   0.5568     89.620  0.0086    99.714  497.49
