Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3267     51.630  1.6918    36.994  7.67
   2   1.0100     63.750  1.2232    55.554  13.48
   3   0.8844     68.200  1.0168    63.968  19.29
   4   0.7816     71.940  0.8835    68.968  25.09
   5   0.7118     74.610  0.7801    72.998  30.90
   6   0.6381     78.250  0.7039    75.786  36.69
   7   0.6658     77.160  0.6460    77.664  42.48
   8   0.6254     78.210  0.6022    79.292  48.27
   9   0.5962     79.430  0.5561    81.026  54.10
  10   0.5399     81.810  0.5216    82.124  60.05
  11   0.5138     82.340  0.4897    83.196  65.86
  12   0.4834     83.440  0.4602    84.328  71.68
  13   0.4821     83.450  0.4380    85.170  77.47
  14   0.4736     83.780  0.4124    85.908  83.29
  15   0.4697     84.080  0.3979    86.520  89.12
  16   0.4537     84.490  0.3771    87.174  95.08
  17   0.4565     84.330  0.3528    87.888  100.91
  18   0.4512     84.610  0.3410    88.360  106.72
  19   0.4361     85.530  0.3293    88.604  112.55
  20   0.4476     84.600  0.3121    89.412  118.36
  21   0.4129     86.020  0.2919    90.138  124.18
  22   0.4219     85.640  0.2857    90.158  130.01
  23   0.4085     86.340  0.2727    90.706  135.95
  24   0.4633     84.810  0.2570    91.190  141.78
  25   0.4118     86.140  0.2553    91.416  147.60
  26   0.4470     85.350  0.2393    91.678  153.41
  27   0.4031     86.480  0.2281    92.130  159.22
  28   0.4055     86.520  0.2175    92.586  165.02
  29   0.4051     87.150  0.2043    92.984  170.96
  30   0.4155     86.870  0.2042    93.028  176.78
  31   0.3902     87.470  0.1917    93.444  182.57
  32   0.3934     87.480  0.1866    93.698  188.37
  33   0.4229     86.340  0.1738    94.074  194.19
  34   0.3834     87.930  0.1723    94.188  199.98
  35   0.4097     87.180  0.1550    94.638  205.88
  36   0.3967     87.670  0.1513    94.716  211.71
  37   0.3877     87.730  0.1436    94.990  217.52
  38   0.4310     87.370  0.1365    95.330  223.32
  39   0.4340     87.210  0.1347    95.286  229.14
  40   0.4132     88.170  0.1251    95.632  234.93
  41   0.4063     88.040  0.1223    95.892  240.74
  42   0.4175     87.780  0.1165    95.966  246.67
  43   0.4106     88.170  0.1098    96.292  252.46
  44   0.4181     88.470  0.1030    96.424  258.25
  45   0.4112     88.340  0.0992    96.594  264.04
  46   0.4224     88.180  0.0973    96.648  269.86
  47   0.4406     88.490  0.0950    96.818  275.68
  48   0.4254     88.440  0.0845    97.136  281.51
  49   0.4511     88.460  0.0846    97.010  287.46
  50   0.4378     88.840  0.0741    97.438  293.19
  51   0.4623     88.080  0.0748    97.398  299.00
  52   0.4357     88.880  0.0695    97.666  304.83
  53   0.4676     88.200  0.0669    97.766  310.65
  54   0.4548     88.580  0.0648    97.766  316.43
  55   0.4528     88.500  0.0626    97.818  322.37
  56   0.4691     88.530  0.0571    97.990  328.16
  57   0.4655     89.050  0.0537    98.160  333.98
  58   0.4683     88.830  0.0519    98.230  339.82
  59   0.4893     88.630  0.0508    98.242  345.65
  60   0.4677     88.680  0.0482    98.356  351.44
  61   0.4618     88.860  0.0458    98.424  357.29
  62   0.4688     89.060  0.0417    98.572  363.13
  63   0.5100     88.960  0.0378    98.684  368.92
  64   0.4700     89.390  0.0401    98.642  374.72
  65   0.4883     89.000  0.0370    98.752  380.53
  66   0.4949     89.150  0.0316    98.942  386.32
  67   0.5072     88.620  0.0313    98.886  392.15
  68   0.5131     89.190  0.0318    98.886  398.14
  69   0.4983     89.500  0.0287    99.026  403.95
  70   0.5171     88.930  0.0277    99.042  409.75
  71   0.5217     89.350  0.0284    99.052  415.54
  72   0.5120     89.120  0.0257    99.150  421.37
  73   0.5361     89.350  0.0243    99.144  427.17
  74   0.5329     89.310  0.0231    99.254  432.96
  75   0.5171     89.360  0.0247    99.180  438.88
  76   0.5214     89.150  0.0245    99.148  444.68
  77   0.5356     89.300  0.0208    99.290  450.52
  78   0.5363     89.160  0.0229    99.204  456.32
  79   0.5440     89.280  0.0193    99.338  462.11
  80   0.5466     89.350  0.0184    99.406  467.95
  81   0.5384     89.500  0.0194    99.330  473.77
  82   0.5496     89.470  0.0190    99.338  479.57
  83   0.5458     89.560  0.0176    99.420  485.41
  84   0.5443     89.630  0.0166    99.454  491.20
  85   0.5647     89.210  0.0185    99.394  496.99
