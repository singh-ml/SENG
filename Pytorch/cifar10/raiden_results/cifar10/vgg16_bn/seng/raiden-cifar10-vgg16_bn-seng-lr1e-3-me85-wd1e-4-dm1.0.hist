Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5520     41.760  1.9599    26.770  7.75
   2   1.3378     50.710  1.5364    42.250  13.54
   3   1.1998     55.660  1.3628    49.408  19.32
   4   1.1025     60.030  1.2322    54.798  25.12
   5   1.0265     63.340  1.1403    58.714  31.03
   6   0.9746     64.610  1.0645    61.616  36.84
   7   0.9271     66.710  1.0005    63.830  42.62
   8   0.8863     68.590  0.9461    65.930  48.44
   9   0.8529     69.610  0.9013    67.978  54.24
  10   0.8131     71.080  0.8625    69.188  60.03
  11   0.7982     71.610  0.8243    70.656  65.94
  12   0.7678     73.230  0.7899    72.070  71.72
  13   0.7474     74.040  0.7556    73.226  77.51
  14   0.7137     74.730  0.7323    74.226  83.30
  15   0.7006     75.310  0.7022    75.316  89.08
  16   0.6783     76.050  0.6854    75.890  94.88
  17   0.6769     75.880  0.6576    76.894  100.70
  18   0.6610     76.820  0.6382    77.754  106.62
  19   0.6519     77.520  0.6233    78.242  112.44
  20   0.6423     77.820  0.6010    78.686  118.25
  21   0.6339     78.030  0.5861    79.550  124.05
  22   0.6171     78.690  0.5721    79.970  129.82
  23   0.5996     79.350  0.5564    80.634  135.61
  24   0.5944     79.460  0.5394    81.228  141.54
  25   0.5836     79.900  0.5310    81.378  147.34
  26   0.5903     79.560  0.5173    81.974  153.14
  27   0.5683     80.050  0.5008    82.528  158.93
  28   0.5722     80.200  0.4971    82.538  164.70
  29   0.5711     80.350  0.4797    83.364  170.52
  30   0.5641     80.830  0.4701    83.500  176.31
  31   0.5665     80.890  0.4562    84.098  182.24
  32   0.5472     81.490  0.4433    84.588  188.03
  33   0.5562     81.550  0.4333    84.990  193.83
  34   0.5507     81.000  0.4250    85.166  199.64
  35   0.5492     81.330  0.4240    85.344  205.42
  36   0.5401     81.780  0.4055    85.808  211.22
  37   0.5278     82.270  0.4042    85.930  217.12
  38   0.5279     82.260  0.3919    86.310  222.93
  39   0.5338     82.130  0.3799    86.700  228.71
  40   0.5240     82.820  0.3760    86.908  234.50
  41   0.5335     82.360  0.3704    86.930  240.31
  42   0.5232     82.650  0.3644    87.282  246.12
  43   0.5396     82.420  0.3535    87.588  251.93
  44   0.5298     82.950  0.3460    87.906  257.88
  45   0.5270     83.000  0.3345    88.368  263.65
  46   0.5471     82.650  0.3351    88.246  269.45
  47   0.5307     83.000  0.3248    88.598  275.24
  48   0.5519     82.720  0.3174    89.038  281.06
  49   0.5358     83.300  0.3082    89.174  286.86
  50   0.5344     83.010  0.3020    89.582  292.74
  51   0.5211     83.330  0.3004    89.596  298.51
  52   0.5365     83.170  0.2947    89.762  304.31
  53   0.5342     83.270  0.2888    89.892  310.12
  54   0.5786     82.930  0.2763    90.422  315.92
  55   0.5379     83.280  0.2738    90.440  321.72
  56   0.5371     83.630  0.2678    90.702  327.52
  57   0.5373     83.640  0.2649    90.720  333.33
  58   0.5309     84.010  0.2582    90.984  339.14
  59   0.5328     84.190  0.2536    91.038  344.97
  60   0.5333     83.820  0.2450    91.340  350.77
  61   0.5514     83.570  0.2432    91.512  356.55
  62   0.5244     84.310  0.2406    91.558  362.35
  63   0.5231     84.720  0.2297    91.934  368.27
  64   0.5310     84.270  0.2269    92.058  374.06
  65   0.5301     84.190  0.2262    92.098  379.88
  66   0.5386     84.080  0.2185    92.320  385.67
  67   0.5499     83.930  0.2148    92.554  391.48
  68   0.5394     84.540  0.2081    92.748  397.29
  69   0.5402     84.460  0.2084    92.860  403.25
  70   0.5613     84.140  0.2060    92.808  409.04
  71   0.5551     84.570  0.1972    93.164  414.82
  72   0.5767     84.090  0.1913    93.254  420.61
  73   0.5974     83.730  0.1864    93.366  426.40
  74   0.5818     84.000  0.1840    93.546  432.22
  75   0.6040     84.050  0.1833    93.512  438.00
  76   0.5639     84.670  0.1797    93.854  443.94
  77   0.5801     84.080  0.1784    93.732  449.78
  78   0.6045     84.010  0.1718    93.954  455.58
  79   0.5701     84.480  0.1702    94.082  461.37
  80   0.5686     85.060  0.1669    94.160  467.17
  81   0.5844     84.610  0.1556    94.534  472.96
  82   0.5938     84.290  0.1581    94.374  478.91
  83   0.5838     84.660  0.1586    94.468  484.71
  84   0.5981     84.340  0.1508    94.598  490.53
  85   0.5816     84.400  0.1447    94.950  496.32
