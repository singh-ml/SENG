Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4056     47.940  1.7257    35.000  7.72
   2   1.0802     59.950  1.2662    54.036  13.54
   3   0.9222     66.650  1.0651    61.932  19.34
   4   0.9005     68.080  0.9406    66.314  25.14
   5   0.7562     73.460  0.8433    70.436  30.95
   6   0.7342     74.340  0.7710    73.060  36.77
   7   0.6836     75.890  0.6999    75.636  42.69
   8   0.6275     78.210  0.6564    77.042  48.51
   9   0.6337     78.560  0.6170    78.640  54.30
  10   0.5763     80.210  0.5744    80.068  60.11
  11   0.5491     81.010  0.5459    81.364  65.92
  12   0.5269     82.150  0.5164    82.352  71.74
  13   0.5197     82.030  0.4856    83.100  77.56
  14   0.5117     82.530  0.4676    83.990  83.46
  15   0.5208     82.850  0.4480    84.692  89.25
  16   0.4996     83.140  0.4245    85.372  95.08
  17   0.4929     82.890  0.4060    86.080  100.87
  18   0.5016     82.920  0.3867    86.758  106.70
  19   0.4883     83.220  0.3692    87.214  112.50
  20   0.4673     84.880  0.3614    87.626  118.29
  21   0.4444     85.140  0.3440    88.062  124.24
  22   0.4622     84.740  0.3280    88.646  130.06
  23   0.4548     84.850  0.3145    89.096  135.88
  24   0.4738     84.420  0.3040    89.584  141.70
  25   0.4506     85.110  0.2918    89.976  147.50
  26   0.4390     85.490  0.2800    90.212  153.29
  27   0.4373     85.730  0.2708    90.746  159.22
  28   0.4428     85.710  0.2559    91.078  165.03
  29   0.4418     85.760  0.2510    91.286  170.84
  30   0.4565     85.490  0.2393    91.794  176.64
  31   0.4312     86.170  0.2261    92.158  182.43
  32   0.4432     85.980  0.2223    92.268  188.25
  33   0.4347     86.370  0.2106    92.806  194.06
  34   0.4418     85.950  0.1969    93.148  199.99
  35   0.4397     86.330  0.1994    93.024  205.81
  36   0.4432     86.180  0.1908    93.378  211.60
  37   0.4199     86.460  0.1821    93.710  217.41
  38   0.4582     86.040  0.1752    93.890  223.24
  39   0.4328     86.770  0.1683    94.062  229.04
  40   0.4484     86.580  0.1628    94.318  235.04
  41   0.4501     86.450  0.1524    94.706  240.83
  42   0.4476     86.340  0.1459    95.012  246.64
  43   0.4280     87.050  0.1400    95.128  252.43
  44   0.4418     87.250  0.1343    95.392  258.23
  45   0.4346     87.420  0.1286    95.660  264.07
  46   0.4628     87.200  0.1230    95.734  269.86
  47   0.4446     87.020  0.1248    95.734  275.85
  48   0.4763     86.730  0.1118    96.248  281.66
  49   0.4416     87.360  0.1117    96.184  287.46
  50   0.4709     87.140  0.1031    96.360  293.19
  51   0.4872     87.390  0.1033    96.448  299.02
  52   0.4534     87.920  0.0959    96.720  304.82
  53   0.4710     87.950  0.0916    96.800  310.73
  54   0.4817     87.240  0.0885    96.886  316.53
  55   0.4891     87.360  0.0815    97.238  322.36
  56   0.4742     87.550  0.0853    97.096  328.15
  57   0.4915     87.690  0.0783    97.218  333.95
  58   0.5032     87.610  0.0731    97.448  339.77
  59   0.5141     87.540  0.0712    97.482  345.60
  60   0.5107     87.660  0.0670    97.656  351.53
  61   0.5010     87.970  0.0670    97.646  357.34
  62   0.5042     88.010  0.0634    97.804  363.13
  63   0.5148     87.870  0.0604    97.876  368.93
  64   0.5139     88.050  0.0523    98.120  374.74
  65   0.5203     87.670  0.0537    98.136  380.52
  66   0.5100     88.240  0.0518    98.218  386.32
  67   0.5188     87.750  0.0493    98.326  392.29
  68   0.5369     87.810  0.0457    98.472  398.13
  69   0.5337     88.210  0.0425    98.594  403.92
  70   0.5392     87.790  0.0441    98.528  409.71
  71   0.5404     87.610  0.0449    98.458  415.49
  72   0.5416     88.170  0.0416    98.588  421.27
  73   0.5444     88.090  0.0358    98.746  427.07
  74   0.5404     88.170  0.0365    98.668  433.00
  75   0.5588     88.250  0.0357    98.800  438.80
  76   0.5472     88.380  0.0353    98.816  444.60
  77   0.5551     88.780  0.0303    98.952  450.43
  78   0.5521     88.110  0.0338    98.840  456.26
  79   0.5601     88.410  0.0323    98.930  462.08
  80   0.5654     87.990  0.0325    98.890  468.00
  81   0.5549     88.300  0.0288    99.016  473.83
  82   0.5819     88.020  0.0289    99.044  479.63
  83   0.5536     88.540  0.0266    99.054  485.46
  84   0.5787     88.430  0.0249    99.146  491.29
  85   0.5937     88.190  0.0254    99.150  497.11
  86   0.5763     88.900  0.0248    99.144  502.92
  87   0.5914     88.670  0.0229    99.188  508.72
  88   0.5825     88.800  0.0230    99.178  514.51
  89   0.6029     88.460  0.0217    99.290  520.31
  90   0.6135     88.770  0.0231    99.184  526.13
