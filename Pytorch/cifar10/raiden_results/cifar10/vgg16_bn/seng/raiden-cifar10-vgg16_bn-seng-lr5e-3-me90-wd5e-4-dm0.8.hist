Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3627     50.800  1.6757    37.558  7.66
   2   1.0162     63.460  1.2043    56.826  13.48
   3   0.8524     70.170  1.0025    64.530  19.28
   4   0.7781     72.960  0.8675    69.518  25.08
   5   0.7007     76.170  0.7667    73.394  30.90
   6   0.6758     77.020  0.7008    75.710  36.87
   7   0.6175     78.670  0.6402    78.086  42.68
   8   0.5899     79.900  0.5910    79.710  48.48
   9   0.5617     80.570  0.5544    80.830  54.29
  10   0.5291     82.130  0.5225    82.196  60.11
  11   0.5282     82.270  0.4860    83.334  65.90
  12   0.5179     82.350  0.4654    84.168  71.84
  13   0.4973     83.210  0.4389    85.124  77.65
  14   0.4835     83.570  0.4117    85.844  83.45
  15   0.4858     83.460  0.3914    86.584  89.24
  16   0.4826     83.690  0.3751    87.372  95.06
  17   0.4511     84.900  0.3547    87.884  100.85
  18   0.4295     85.570  0.3404    88.376  106.67
  19   0.4423     85.080  0.3226    88.914  112.61
  20   0.4288     85.920  0.3136    89.192  118.42
  21   0.4559     85.050  0.3047    89.694  124.23
  22   0.4204     85.960  0.2855    90.126  130.08
  23   0.4337     86.340  0.2700    90.864  135.89
  24   0.4372     85.430  0.2564    91.268  141.71
  25   0.4146     86.100  0.2498    91.430  147.65
  26   0.4202     86.130  0.2367    91.816  153.48
  27   0.3900     86.950  0.2212    92.360  159.29
  28   0.4058     86.970  0.2162    92.600  165.09
  29   0.3966     87.040  0.2053    93.068  170.92
  30   0.3844     87.570  0.2007    93.182  176.75
  31   0.4163     86.580  0.1890    93.592  182.57
  32   0.3981     87.610  0.1864    93.580  188.50
  33   0.4093     87.130  0.1737    94.190  194.30
  34   0.3931     87.640  0.1645    94.338  200.10
  35   0.3998     87.830  0.1628    94.300  205.94
  36   0.4150     87.130  0.1509    94.790  211.76
  37   0.3990     87.520  0.1459    94.998  217.59
  38   0.4287     87.980  0.1399    95.288  223.53
  39   0.4163     87.500  0.1379    95.160  229.33
  40   0.4236     88.000  0.1311    95.460  235.14
  41   0.4143     88.050  0.1257    95.626  240.96
  42   0.4453     87.550  0.1178    95.842  246.81
  43   0.4100     88.130  0.1151    95.986  252.60
  44   0.4220     87.920  0.1077    96.344  258.40
  45   0.4200     88.410  0.0973    96.640  264.34
  46   0.4469     87.900  0.0917    96.786  270.14
  47   0.4320     88.210  0.0910    96.830  275.93
  48   0.4177     88.440  0.0923    96.872  281.74
  49   0.4488     88.220  0.0850    97.004  287.53
  50   0.4374     88.150  0.0825    97.098  293.28
  51   0.4510     88.300  0.0733    97.486  299.09
  52   0.4373     88.820  0.0750    97.404  305.02
  53   0.4383     88.770  0.0705    97.576  310.83
  54   0.4299     88.890  0.0650    97.756  316.64
  55   0.4351     89.160  0.0593    97.994  322.46
  56   0.4264     88.860  0.0598    97.958  328.27
  57   0.4607     88.820  0.0570    98.020  334.07
  58   0.4353     89.050  0.0572    98.102  339.90
  59   0.4489     89.040  0.0509    98.158  345.84
  60   0.4412     89.150  0.0515    98.278  351.67
  61   0.4757     88.870  0.0472    98.300  357.50
  62   0.4546     89.220  0.0424    98.542  363.31
  63   0.4777     89.050  0.0411    98.630  369.10
  64   0.4882     88.930  0.0399    98.608  374.91
  65   0.4644     89.290  0.0360    98.760  380.71
  66   0.4711     89.210  0.0393    98.674  386.68
  67   0.4988     88.930  0.0336    98.856  392.48
  68   0.4685     89.430  0.0353    98.790  398.31
  69   0.4853     89.410  0.0308    98.924  404.10
  70   0.4908     89.330  0.0289    98.970  409.91
  71   0.4921     89.920  0.0272    99.114  415.71
  72   0.4966     89.730  0.0246    99.194  421.56
  73   0.4929     89.770  0.0272    99.096  427.57
  74   0.5137     89.550  0.0235    99.214  433.38
  75   0.5102     89.660  0.0242    99.210  439.19
  76   0.5167     89.520  0.0217    99.224  444.99
  77   0.5058     89.580  0.0200    99.348  450.78
  78   0.5039     89.750  0.0189    99.362  456.59
  79   0.5271     89.880  0.0183    99.394  462.53
  80   0.5153     89.410  0.0210    99.298  468.34
  81   0.5238     89.730  0.0168    99.448  474.13
  82   0.5401     89.620  0.0159    99.444  479.92
  83   0.5207     89.840  0.0158    99.456  485.72
  84   0.5434     89.490  0.0158    99.448  491.54
  85   0.5353     89.730  0.0151    99.554  497.49
  86   0.5313     89.650  0.0155    99.482  503.32
  87   0.5298     90.160  0.0165    99.436  509.11
  88   0.5343     89.870  0.0143    99.524  514.90
  89   0.5426     89.840  0.0125    99.562  520.73
  90   0.5542     89.550  0.0145    99.510  526.59
