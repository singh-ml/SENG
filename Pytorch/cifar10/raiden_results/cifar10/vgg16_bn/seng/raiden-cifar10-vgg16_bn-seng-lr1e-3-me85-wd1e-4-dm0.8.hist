Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4771     44.240  1.9166    27.980  7.82
   2   1.2801     52.490  1.4701    44.982  13.59
   3   1.1217     59.610  1.2782    52.804  19.40
   4   1.0284     62.960  1.1542    58.102  25.19
   5   0.9574     65.720  1.0612    61.886  30.97
   6   0.9037     67.800  0.9871    64.416  36.80
   7   0.8638     69.270  0.9228    66.830  42.75
   8   0.8120     70.740  0.8780    68.702  48.55
   9   0.7689     72.470  0.8317    70.564  54.34
  10   0.7493     73.120  0.7852    72.314  60.13
  11   0.7334     74.180  0.7514    73.310  65.92
  12   0.7157     74.840  0.7188    74.542  71.73
  13   0.6764     76.060  0.6882    75.858  77.68
  14   0.6622     76.870  0.6636    76.746  83.47
  15   0.6383     77.660  0.6382    77.646  89.26
  16   0.6283     78.090  0.6187    78.238  95.06
  17   0.6316     78.030  0.5908    79.296  100.87
  18   0.6024     78.640  0.5761    79.752  106.70
  19   0.5956     79.490  0.5599    80.302  112.49
  20   0.5967     79.730  0.5462    80.838  118.31
  21   0.5794     80.100  0.5276    81.474  124.14
  22   0.5793     79.940  0.5147    82.000  129.96
  23   0.5740     80.460  0.4934    82.816  135.75
  24   0.5579     80.810  0.4815    83.094  141.59
  25   0.5492     81.210  0.4654    83.790  147.38
  26   0.5534     81.060  0.4559    84.012  153.29
  27   0.5377     81.790  0.4420    84.756  159.08
  28   0.5374     81.850  0.4374    84.894  164.88
  29   0.5186     81.970  0.4220    85.384  170.67
  30   0.5286     82.460  0.4145    85.572  176.50
  31   0.5477     81.440  0.4018    86.080  182.28
  32   0.5445     81.950  0.3927    86.200  188.07
  33   0.5220     82.440  0.3841    86.716  194.05
  34   0.5198     82.400  0.3719    86.930  199.87
  35   0.5164     83.250  0.3603    87.444  205.68
  36   0.5189     82.730  0.3575    87.590  211.48
  37   0.5004     83.120  0.3428    88.006  217.30
  38   0.5089     83.310  0.3405    88.318  223.09
  39   0.5062     83.340  0.3298    88.506  229.05
  40   0.5034     83.380  0.3261    88.562  234.89
  41   0.5051     83.010  0.3194    88.868  240.69
  42   0.4946     83.670  0.3074    89.236  246.50
  43   0.5059     83.840  0.3043    89.398  252.30
  44   0.4997     83.760  0.2942    89.748  258.08
  45   0.5008     84.000  0.2947    89.658  264.06
  46   0.4973     84.410  0.2818    90.286  269.87
  47   0.4940     84.200  0.2758    90.492  275.65
  48   0.5259     83.630  0.2681    90.724  281.46
  49   0.5115     84.000  0.2654    90.682  287.28
  50   0.4894     84.460  0.2609    91.104  293.00
  51   0.5267     83.990  0.2505    91.198  298.78
  52   0.5057     84.990  0.2439    91.504  304.74
  53   0.4933     84.720  0.2408    91.556  310.55
  54   0.4989     84.690  0.2380    91.734  316.36
  55   0.5138     84.310  0.2284    92.084  322.20
  56   0.5014     84.590  0.2280    92.088  328.01
  57   0.5170     84.200  0.2177    92.290  333.79
  58   0.5073     84.620  0.2138    92.508  339.58
  59   0.5216     84.810  0.2045    92.800  345.50
  60   0.5271     84.230  0.2080    92.790  351.28
  61   0.5175     84.660  0.2023    92.922  357.07
  62   0.5304     84.470  0.1948    93.220  362.85
  63   0.5209     84.990  0.1869    93.470  368.64
  64   0.5083     85.190  0.1918    93.426  374.44
  65   0.5081     84.840  0.1829    93.728  380.38
  66   0.5267     84.850  0.1790    93.834  386.22
  67   0.5241     84.770  0.1738    93.948  392.04
  68   0.5285     85.050  0.1705    93.976  397.82
  69   0.5346     85.120  0.1685    94.072  403.60
  70   0.5209     85.320  0.1613    94.346  409.39
  71   0.5419     85.170  0.1615    94.294  415.17
  72   0.5258     85.430  0.1527    94.566  421.11
  73   0.5393     85.390  0.1539    94.632  426.90
  74   0.5494     84.830  0.1498    94.822  432.71
  75   0.5595     84.990  0.1511    94.630  438.50
  76   0.5681     85.040  0.1429    94.920  444.29
  77   0.5544     84.870  0.1416    95.134  450.10
  78   0.5636     84.960  0.1352    95.270  456.07
  79   0.5549     85.220  0.1384    95.088  461.87
  80   0.5571     84.970  0.1322    95.298  467.66
  81   0.5598     85.420  0.1316    95.336  473.44
  82   0.5635     85.710  0.1244    95.622  479.23
  83   0.5575     85.380  0.1250    95.656  485.01
  84   0.5769     85.360  0.1208    95.756  490.80
  85   0.5549     85.690  0.1199    95.834  496.71
