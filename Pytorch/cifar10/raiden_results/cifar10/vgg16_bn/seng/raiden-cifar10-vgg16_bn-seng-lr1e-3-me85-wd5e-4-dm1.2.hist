Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'vgg16_bn', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.6083     38.890  1.9876    25.432  7.76
   2   1.3806     48.940  1.5691    40.584  13.59
   3   1.2463     53.680  1.4100    47.866  19.40
   4   1.1666     57.840  1.2969    52.226  25.24
   5   1.0923     60.150  1.1975    56.516  31.05
   6   1.0242     62.770  1.1234    59.190  36.82
   7   0.9853     64.310  1.0583    62.038  42.62
   8   0.9451     65.740  1.0113    63.510  48.55
   9   0.9037     67.240  0.9618    65.172  54.32
  10   0.8634     68.990  0.9229    66.858  60.14
  11   0.8395     69.950  0.8868    68.274  65.92
  12   0.8073     71.150  0.8469    69.792  71.75
  13   0.7938     71.620  0.8102    71.088  77.54
  14   0.7646     72.950  0.7887    71.968  83.48
  15   0.7460     73.690  0.7590    72.826  89.29
  16   0.7286     74.380  0.7331    74.006  95.09
  17   0.7129     74.800  0.7109    75.008  100.89
  18   0.6950     75.480  0.6877    75.898  106.70
  19   0.6733     76.670  0.6683    76.636  112.48
  20   0.6571     77.020  0.6504    77.022  118.28
  21   0.6389     77.460  0.6285    77.960  124.25
  22   0.6398     77.510  0.6087    78.568  130.06
  23   0.6224     78.100  0.5940    79.114  135.84
  24   0.6268     78.260  0.5870    79.282  141.64
  25   0.6186     78.090  0.5705    80.102  147.44
  26   0.6137     78.430  0.5539    80.610  153.29
  27   0.5922     79.130  0.5417    80.956  159.20
  28   0.5846     80.090  0.5290    81.436  165.00
  29   0.5813     79.340  0.5200    81.790  170.80
  30   0.5756     80.020  0.5035    82.486  176.62
  31   0.5827     80.030  0.4905    82.918  182.39
  32   0.5733     80.330  0.4838    82.966  188.19
  33   0.5693     80.280  0.4746    83.576  193.98
  34   0.5615     80.850  0.4612    83.976  199.92
  35   0.5479     81.030  0.4488    84.250  205.73
  36   0.5610     80.840  0.4418    84.550  211.54
  37   0.5575     81.220  0.4329    84.942  217.35
  38   0.5466     81.470  0.4252    85.136  223.13
  39   0.5396     81.660  0.4138    85.550  228.93
  40   0.5444     81.430  0.4073    85.722  234.71
  41   0.5441     81.810  0.3984    86.076  240.62
  42   0.5343     82.080  0.3916    86.166  246.43
  43   0.5315     82.050  0.3851    86.650  252.23
  44   0.5482     82.200  0.3749    86.906  258.01
  45   0.5265     82.250  0.3695    87.222  263.82
  46   0.5272     82.660  0.3637    87.188  269.62
  47   0.5280     82.580  0.3543    87.620  275.57
  48   0.5234     82.700  0.3505    87.736  281.39
  49   0.5259     82.940  0.3417    87.952  287.17
  50   0.5249     82.740  0.3316    88.292  292.94
  51   0.5225     82.730  0.3271    88.518  298.74
  52   0.5201     83.040  0.3273    88.628  304.52
  53   0.5092     83.250  0.3128    89.070  310.34
  54   0.5240     83.220  0.3062    89.094  316.13
  55   0.5211     83.670  0.3027    89.398  322.07
  56   0.5384     82.860  0.2955    89.540  327.88
  57   0.5449     82.790  0.2905    89.886  333.71
  58   0.5232     83.520  0.2848    90.064  339.49
  59   0.5221     83.140  0.2834    90.114  345.29
  60   0.5242     83.390  0.2714    90.532  351.08
  61   0.5284     83.740  0.2677    90.712  357.00
  62   0.5353     83.460  0.2595    90.932  362.78
  63   0.5421     83.600  0.2622    90.808  368.59
  64   0.5445     83.620  0.2503    91.234  374.38
  65   0.5546     83.360  0.2453    91.360  380.19
  66   0.5284     83.660  0.2491    91.268  385.98
  67   0.5326     83.720  0.2364    91.850  391.79
  68   0.5328     83.860  0.2351    91.800  397.69
  69   0.5474     83.270  0.2280    92.154  403.51
  70   0.5243     84.150  0.2262    92.118  409.31
  71   0.5453     83.600  0.2235    92.090  415.09
  72   0.5648     83.770  0.2160    92.308  420.89
  73   0.5657     83.800  0.2110    92.566  426.67
  74   0.5342     84.160  0.2087    92.676  432.47
  75   0.5535     84.710  0.2043    92.844  438.39
  76   0.5553     83.990  0.1980    93.016  444.22
  77   0.5556     83.880  0.1947    93.130  450.04
  78   0.5775     83.890  0.1933    93.336  455.85
  79   0.5500     84.270  0.1894    93.418  461.64
  80   0.5680     84.340  0.1889    93.300  467.44
  81   0.5693     84.290  0.1854    93.440  473.37
  82   0.5798     84.160  0.1756    93.774  479.15
  83   0.5744     83.910  0.1753    93.816  484.96
  84   0.5659     84.380  0.1749    93.818  490.75
  85   0.5800     84.550  0.1678    94.178  496.56
