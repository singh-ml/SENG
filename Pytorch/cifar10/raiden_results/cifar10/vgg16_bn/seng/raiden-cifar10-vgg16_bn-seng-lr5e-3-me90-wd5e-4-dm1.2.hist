Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '90', '--arch', 'vgg16_bn', '--lr-decay-epoch', '90', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/ghighdim/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7544058368 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3317     51.550  1.7232    35.584  7.78
   2   1.0534     61.900  1.2374    55.106  13.57
   3   0.8676     69.590  1.0239    63.298  19.40
   4   0.8258     70.550  0.8995    68.412  25.24
   5   0.7666     73.130  0.8124    71.462  31.05
   6   0.6859     75.830  0.7365    74.144  36.85
   7   0.6480     77.890  0.6846    76.486  42.80
   8   0.6377     77.870  0.6336    78.008  48.65
   9   0.6036     79.320  0.5897    79.500  54.47
  10   0.5866     80.310  0.5568    80.730  60.30
  11   0.5397     81.620  0.5322    81.802  66.11
  12   0.5377     81.400  0.4983    82.836  71.92
  13   0.5246     81.890  0.4809    83.530  77.88
  14   0.5117     82.640  0.4547    84.598  83.69
  15   0.4855     83.560  0.4319    85.024  89.51
  16   0.4820     83.610  0.4109    85.894  95.31
  17   0.4839     83.800  0.4002    86.404  101.10
  18   0.4857     83.570  0.3773    86.956  106.90
  19   0.4570     84.440  0.3670    87.506  112.69
  20   0.4566     84.610  0.3476    87.974  118.65
  21   0.4507     84.830  0.3352    88.648  124.43
  22   0.4573     84.840  0.3165    89.118  130.24
  23   0.4417     85.280  0.3048    89.506  136.03
  24   0.4370     85.400  0.2949    89.812  141.85
  25   0.4252     85.830  0.2848    90.270  147.69
  26   0.4580     85.100  0.2689    90.764  153.62
  27   0.4219     86.060  0.2605    90.942  159.42
  28   0.4358     85.840  0.2525    91.234  165.23
  29   0.4504     85.350  0.2377    91.886  171.02
  30   0.4205     86.050  0.2293    92.144  176.83
  31   0.4231     86.590  0.2208    92.408  182.64
  32   0.4290     86.020  0.2173    92.514  188.44
  33   0.4481     86.430  0.2070    92.730  194.36
  34   0.4264     86.450  0.1967    93.170  200.18
  35   0.4329     86.480  0.1852    93.670  205.98
  36   0.4318     86.600  0.1827    93.656  211.82
  37   0.4381     86.890  0.1747    94.050  217.66
  38   0.4298     87.180  0.1675    94.306  223.46
  39   0.4395     86.870  0.1570    94.498  229.37
  40   0.4468     86.530  0.1484    94.876  235.17
  41   0.4412     87.030  0.1553    94.590  240.99
  42   0.4343     87.500  0.1410    95.046  246.79
  43   0.4344     86.640  0.1362    95.364  252.60
  44   0.4493     87.090  0.1326    95.444  258.43
  45   0.4319     87.420  0.1219    95.760  264.25
  46   0.4397     87.240  0.1174    95.850  270.04
  47   0.4422     87.850  0.1135    96.074  275.97
  48   0.4256     87.950  0.1114    96.224  281.79
  49   0.4531     87.800  0.1024    96.448  287.59
  50   0.4536     87.900  0.0964    96.604  293.34
  51   0.4636     88.060  0.0988    96.600  299.14
  52   0.4667     87.690  0.0900    96.896  304.94
  53   0.4750     87.480  0.0881    96.906  310.73
  54   0.4781     87.490  0.0853    97.022  316.64
  55   0.4771     87.360  0.0798    97.166  322.46
  56   0.4775     87.660  0.0739    97.388  328.28
  57   0.5057     87.910  0.0755    97.396  334.07
  58   0.4870     88.270  0.0727    97.488  339.86
  59   0.4951     88.060  0.0638    97.770  345.67
  60   0.4917     87.980  0.0609    97.848  351.52
  61   0.5193     87.960  0.0573    98.044  357.31
  62   0.4909     88.420  0.0566    98.064  363.11
  63   0.5058     87.860  0.0568    98.082  368.94
  64   0.5198     87.970  0.0512    98.258  374.73
  65   0.4763     88.670  0.0544    98.152  380.54
  66   0.4934     88.610  0.0476    98.354  386.34
  67   0.5045     88.510  0.0466    98.384  392.16
  68   0.5182     88.340  0.0433    98.522  398.12
  69   0.5400     88.340  0.0398    98.662  403.93
  70   0.5327     88.400  0.0362    98.834  409.73
  71   0.5287     88.910  0.0367    98.722  415.51
  72   0.5318     88.170  0.0360    98.772  421.32
  73   0.5231     88.720  0.0352    98.798  427.27
  74   0.5260     88.730  0.0366    98.744  433.09
  75   0.5273     88.650  0.0321    98.906  438.88
  76   0.5249     88.910  0.0301    98.964  444.68
  77   0.5281     88.790  0.0299    98.994  450.48
  78   0.5288     89.010  0.0293    98.954  456.27
  79   0.5343     88.840  0.0272    99.112  462.08
  80   0.5615     88.740  0.0236    99.140  468.03
  81   0.5631     88.690  0.0257    99.128  473.87
  82   0.5602     88.700  0.0264    99.118  479.68
  83   0.5629     89.070  0.0237    99.208  485.47
  84   0.5471     88.960  0.0206    99.322  491.30
  85   0.5584     89.110  0.0235    99.212  497.09
  86   0.5610     89.150  0.0206    99.312  502.92
  87   0.5615     89.030  0.0215    99.230  508.76
  88   0.5608     89.190  0.0217    99.294  514.55
  89   0.5641     89.070  0.0197    99.330  520.34
  90   0.5647     88.930  0.0192    99.374  526.13
