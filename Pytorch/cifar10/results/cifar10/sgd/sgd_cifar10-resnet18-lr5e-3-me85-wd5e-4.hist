Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4854     44.140  1.7753    33.324  21.82
   2   1.2662     53.550  1.3852    48.966  41.81
   3   1.1232     59.310  1.1862    56.980  61.74
   4   1.0071     63.640  1.0446    62.502  81.68
   5   1.0594     64.100  0.9360    66.432  101.67
   6   0.9264     67.620  0.8453    69.910  121.62
   7   0.7975     72.240  0.7714    72.382  141.59
   8   0.7347     74.460  0.7060    74.886  161.56
   9   0.9482     69.680  0.6577    76.824  181.58
  10   0.7003     76.440  0.6182    78.172  201.58
  11   0.6726     76.820  0.5791    79.894  221.59
  12   0.6222     79.080  0.5424    81.060  241.57
  13   0.6377     78.230  0.5129    81.990  261.57
  14   0.6296     78.960  0.4870    82.700  281.54
  15   0.6252     79.780  0.4671    83.598  301.54
  16   0.6437     79.240  0.4418    84.534  321.51
  17   0.5788     81.380  0.4193    85.242  341.50
  18   0.5668     81.620  0.4030    85.976  361.53
  19   0.5168     82.760  0.3888    86.428  381.49
  20   0.5040     83.930  0.3704    87.090  401.55
  21   0.6446     80.450  0.3495    87.880  421.50
  22   0.4980     83.950  0.3391    88.132  441.47
  23   0.5569     82.380  0.3227    88.874  461.50
  24   0.4996     84.390  0.3125    89.098  481.46
  25   0.5180     83.740  0.2972    89.660  501.45
  26   0.5105     83.170  0.2871    89.876  521.39
  27   0.4835     84.340  0.2749    90.282  541.29
  28   0.4605     85.140  0.2627    90.992  561.22
  29   0.4557     85.520  0.2546    91.068  581.17
  30   0.4837     85.160  0.2417    91.552  601.11
  31   0.4857     85.020  0.2365    91.716  621.11
  32   0.4847     85.460  0.2195    92.318  641.09
  33   0.4629     86.140  0.2134    92.448  661.13
  34   0.4653     85.760  0.2041    92.772  681.11
  35   0.4962     85.540  0.1958    93.224  701.13
  36   0.4877     85.720  0.1877    93.454  721.10
  37   0.4952     85.690  0.1794    93.692  741.09
  38   0.4417     86.950  0.1691    94.142  761.09
  39   0.4592     86.260  0.1625    94.422  781.15
  40   0.4283     87.470  0.1589    94.412  801.14
  41   0.4574     87.070  0.1503    94.724  821.16
  42   0.4674     86.840  0.1478    94.754  841.14
  43   0.5086     85.990  0.1395    95.160  861.16
  44   0.4661     86.600  0.1339    95.308  881.14
  45   0.4562     87.160  0.1239    95.654  901.15
  46   0.4998     86.600  0.1158    95.966  921.16
  47   0.4609     87.460  0.1130    96.070  941.16
  48   0.4569     87.250  0.1063    96.372  961.14
  49   0.4877     86.970  0.1027    96.460  981.11
  50   0.4402     88.160  0.1033    96.340  1001.11
  51   0.5208     86.880  0.0898    97.012  1021.12
  52   0.4702     87.680  0.0905    96.912  1041.08
  53   0.4748     87.570  0.0833    97.116  1061.08
  54   0.5284     86.960  0.0801    97.238  1081.06
  55   0.5958     86.030  0.0782    97.336  1101.02
  56   0.4654     87.780  0.0750    97.452  1121.04
  57   0.5085     87.350  0.0699    97.648  1141.07
  58   0.4585     88.370  0.0667    97.800  1161.04
  59   0.4710     88.330  0.0644    97.904  1181.01
  60   0.5643     87.080  0.0608    98.020  1200.98
  61   0.4891     88.300  0.0567    98.134  1220.96
  62   0.4851     88.360  0.0564    98.154  1240.93
  63   0.4723     88.810  0.0486    98.458  1260.93
  64   0.4837     88.450  0.0486    98.448  1280.89
  65   0.4847     88.460  0.0482    98.436  1300.85
  66   0.4880     88.640  0.0444    98.632  1320.84
  67   0.5008     88.550  0.0420    98.680  1340.84
  68   0.4828     88.920  0.0408    98.764  1360.81
  69   0.4836     88.770  0.0379    98.788  1380.80
  70   0.4909     88.780  0.0378    98.876  1400.76
  71   0.4899     88.450  0.0345    98.932  1420.76
  72   0.4878     88.570  0.0330    99.036  1440.71
  73   0.4899     88.870  0.0340    98.970  1460.68
  74   0.4902     89.150  0.0306    99.130  1480.61
  75   0.4925     89.070  0.0293    99.156  1500.55
  76   0.5222     88.550  0.0288    99.182  1520.51
  77   0.5039     88.990  0.0283    99.198  1540.51
  78   0.4919     89.050  0.0266    99.264  1560.46
  79   0.5067     88.920  0.0274    99.220  1580.42
  80   0.4944     89.030  0.0252    99.312  1600.37
  81   0.5109     88.590  0.0266    99.294  1620.36
  82   0.5187     88.940  0.0237    99.392  1640.36
  83   0.5127     88.860  0.0245    99.344  1660.38
  84   0.5026     89.040  0.0242    99.300  1680.42
  85   0.5073     88.890  0.0234    99.388  1700.41
