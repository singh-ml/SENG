Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4485     46.830  1.6742    37.216  21.85
   2   1.1773     57.480  1.2602    53.874  41.80
   3   1.1042     61.920  1.0412    62.474  61.80
   4   0.9980     65.740  0.9013    67.706  81.73
   5   0.9149     69.480  0.8123    71.154  101.74
   6   0.7713     72.950  0.7184    74.526  121.70
   7   0.7635     74.080  0.6504    76.914  141.66
   8   0.6775     77.250  0.5895    79.274  161.56
   9   0.6227     78.470  0.5484    80.786  181.52
  10   0.6202     79.680  0.5013    82.430  201.44
  11   0.5883     80.340  0.4691    83.700  221.38
  12   0.6318     79.380  0.4454    84.486  241.32
  13   0.5421     82.310  0.4128    85.616  261.30
  14   0.5489     82.150  0.3907    86.438  281.33
  15   0.4868     84.440  0.3715    87.102  301.29
  16   0.5631     81.970  0.3529    87.640  321.23
  17   0.5325     83.160  0.3247    88.608  341.21
  18   0.5149     83.670  0.3118    89.124  361.17
  19   0.4489     85.370  0.3009    89.454  381.13
  20   0.4728     84.910  0.2831    89.982  401.16
  21   0.4597     85.460  0.2633    90.736  421.11
  22   0.4853     84.800  0.2502    91.212  441.04
  23   0.4681     85.230  0.2368    91.620  461.01
  24   0.4855     85.410  0.2289    91.888  480.96
  25   0.4666     85.840  0.2156    92.436  500.88
  26   0.4558     86.300  0.2085    92.678  520.81
  27   0.4877     86.020  0.1907    93.350  540.76
  28   0.4809     86.410  0.1795    93.620  560.71
  29   0.4896     86.090  0.1719    93.974  580.66
  30   0.4607     86.730  0.1652    94.172  600.60
  31   0.5464     85.760  0.1545    94.568  620.58
  32   0.4667     87.280  0.1510    94.664  640.54
  33   0.4647     87.070  0.1359    95.112  660.49
  34   0.5165     86.700  0.1275    95.538  680.44
  35   0.4589     87.930  0.1199    95.792  700.44
  36   0.5293     86.840  0.1149    95.966  720.37
  37   0.4798     87.860  0.1079    96.150  740.35
  38   0.5543     86.380  0.1058    96.298  760.33
  39   0.4471     88.590  0.0936    96.674  780.33
  40   0.4932     87.940  0.0848    97.062  800.28
  41   0.4771     88.600  0.0883    96.840  820.21
  42   0.4847     87.960  0.0797    97.206  840.16
  43   0.5196     87.830  0.0769    97.298  860.15
  44   0.4760     88.670  0.0694    97.570  880.12
  45   0.5158     88.660  0.0640    97.814  900.09
  46   0.4966     88.280  0.0621    97.838  920.06
  47   0.4819     89.000  0.0595    98.008  940.02
  48   0.5089     88.710  0.0529    98.208  959.95
  49   0.5246     88.830  0.0515    98.226  979.87
  50   0.4999     88.930  0.0470    98.440  999.79
  51   0.4726     89.160  0.0437    98.542  1019.79
  52   0.5100     88.660  0.0404    98.610  1039.74
  53   0.5256     88.910  0.0349    98.860  1059.72
  54   0.5011     89.370  0.0351    98.852  1079.67
  55   0.4984     89.440  0.0326    98.904  1099.64
  56   0.5276     89.170  0.0303    99.054  1119.60
  57   0.4995     89.520  0.0260    99.206  1139.51
  58   0.5203     89.110  0.0269    99.168  1159.47
  59   0.4928     89.800  0.0237    99.264  1179.40
  60   0.5091     89.380  0.0211    99.338  1199.37
  61   0.5148     89.690  0.0207    99.358  1219.28
  62   0.5202     89.670  0.0196    99.428  1239.22
  63   0.5205     89.790  0.0180    99.484  1259.18
  64   0.5170     89.720  0.0168    99.498  1279.13
  65   0.5344     89.450  0.0162    99.538  1299.07
  66   0.5197     89.590  0.0157    99.586  1318.98
  67   0.5202     89.640  0.0134    99.648  1338.96
  68   0.5092     89.770  0.0140    99.636  1358.90
  69   0.5203     89.740  0.0129    99.676  1378.84
  70   0.5170     89.820  0.0118    99.698  1398.76
  71   0.5259     89.870  0.0112    99.742  1418.72
  72   0.5135     89.840  0.0118    99.716  1438.66
  73   0.5150     89.840  0.0105    99.780  1458.60
  74   0.5182     89.870  0.0101    99.770  1478.56
  75   0.5268     90.000  0.0098    99.764  1498.51
  76   0.5282     89.920  0.0095    99.794  1518.51
  77   0.5197     89.980  0.0089    99.820  1538.54
  78   0.5213     89.860  0.0087    99.818  1558.47
  79   0.5207     90.150  0.0086    99.822  1578.45
  80   0.5208     90.000  0.0081    99.848  1598.40
  81   0.5253     90.220  0.0076    99.844  1618.33
  82   0.5192     90.010  0.0080    99.840  1638.26
  83   0.5234     89.980  0.0083    99.814  1658.29
  84   0.5225     90.180  0.0080    99.844  1678.28
  85   0.5205     90.100  0.0074    99.842  1698.23
  86   0.5201     90.030  0.0070    99.850  1718.20
  87   0.5210     89.930  0.0066    99.866  1738.18
  88   0.5231     90.080  0.0070    99.860  1758.18
  89   0.5228     90.220  0.0068    99.876  1778.11
  90   0.5244     90.090  0.0065    99.878  1798.12
