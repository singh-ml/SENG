Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5284     42.310  1.7475    34.212  21.87
   2   1.4315     49.880  1.3821    48.950  41.84
   3   1.1713     58.630  1.1964    56.416  61.83
   4   1.0788     61.710  1.0425    62.486  81.81
   5   0.9503     67.170  0.9306    66.646  101.85
   6   0.8759     69.420  0.8379    70.502  121.82
   7   0.8435     71.240  0.7623    73.024  141.83
   8   0.7780     73.150  0.7131    74.770  161.81
   9   0.7634     74.190  0.6570    76.748  181.81
  10   0.6967     75.610  0.6115    78.514  201.79
  11   0.6945     76.240  0.5704    80.074  221.78
  12   0.6685     77.170  0.5392    80.910  241.79
  13   0.6259     78.550  0.5073    82.238  261.78
  14   0.6065     79.060  0.4798    83.100  281.78
  15   0.5354     81.990  0.4593    83.936  301.75
  16   0.5589     81.750  0.4408    84.516  321.73
  17   0.5691     81.570  0.4191    85.410  341.73
  18   0.5041     83.490  0.4006    86.072  361.72
  19   0.5388     82.050  0.3841    86.596  381.71
  20   0.5358     82.660  0.3654    87.136  401.79
  21   0.5433     82.840  0.3463    87.996  421.76
  22   0.5225     83.440  0.3340    88.296  441.72
  23   0.5352     83.280  0.3213    88.812  461.69
  24   0.5513     81.940  0.3035    89.466  481.69
  25   0.5275     83.060  0.2967    89.540  501.73
  26   0.4968     84.540  0.2846    90.094  521.71
  27   0.4803     85.360  0.2746    90.480  541.68
  28   0.4837     84.990  0.2604    90.966  561.66
  29   0.5053     84.460  0.2530    91.340  581.68
  30   0.4978     85.480  0.2433    91.294  601.72
  31   0.4733     85.640  0.2334    91.772  621.73
  32   0.4547     86.230  0.2248    92.014  641.71
  33   0.4965     85.540  0.2147    92.478  661.69
  34   0.4740     85.760  0.2062    92.766  681.69
  35   0.4537     86.500  0.1933    93.212  701.71
  36   0.4626     86.450  0.1885    93.392  721.72
  37   0.4602     87.070  0.1807    93.612  741.66
  38   0.4846     86.220  0.1719    93.968  761.68
  39   0.4912     86.680  0.1720    93.964  781.68
  40   0.4892     86.110  0.1608    94.294  801.72
  41   0.4770     86.830  0.1524    94.570  821.74
  42   0.4953     86.970  0.1450    94.884  841.71
  43   0.4552     87.300  0.1363    95.200  861.72
  44   0.4900     86.840  0.1337    95.258  881.71
  45   0.4439     88.190  0.1311    95.466  901.72
  46   0.5098     86.890  0.1246    95.686  921.68
  47   0.4799     87.150  0.1171    95.858  941.69
  48   0.4686     87.660  0.1137    95.960  961.70
  49   0.4656     87.650  0.1102    96.090  981.75
  50   0.5077     87.140  0.1004    96.474  1001.76
  51   0.4778     87.790  0.1009    96.412  1021.73
  52   0.4456     88.240  0.0934    96.814  1041.73
  53   0.5286     87.200  0.0911    96.790  1061.71
  54   0.4709     88.080  0.0830    97.096  1081.70
  55   0.4860     87.900  0.0836    97.140  1101.69
  56   0.4871     87.930  0.0782    97.292  1121.68
  57   0.5092     88.070  0.0756    97.414  1141.66
  58   0.4761     88.250  0.0731    97.492  1161.66
  59   0.5015     87.960  0.0666    97.774  1181.65
  60   0.4884     88.220  0.0641    97.824  1201.61
  61   0.4922     88.640  0.0611    97.914  1221.61
  62   0.4780     88.590  0.0606    97.984  1241.61
  63   0.5021     88.360  0.0559    98.152  1261.57
  64   0.4890     88.420  0.0532    98.214  1281.53
  65   0.4928     88.650  0.0540    98.192  1301.48
  66   0.4851     88.600  0.0508    98.350  1321.46
  67   0.4878     88.690  0.0477    98.462  1341.47
  68   0.4945     88.530  0.0454    98.522  1361.47
  69   0.4982     88.710  0.0434    98.622  1381.52
  70   0.5081     88.710  0.0413    98.678  1401.49
  71   0.5007     88.480  0.0404    98.692  1421.53
  72   0.5012     88.720  0.0393    98.730  1441.50
  73   0.5103     88.590  0.0387    98.722  1461.47
  74   0.5100     88.680  0.0372    98.824  1481.47
  75   0.5027     88.980  0.0355    98.920  1501.41
  76   0.5149     88.640  0.0350    98.958  1521.37
  77   0.5463     88.530  0.0333    99.026  1541.36
  78   0.5178     88.750  0.0343    98.912  1561.35
  79   0.5291     88.720  0.0298    99.182  1581.35
  80   0.5103     89.000  0.0298    99.106  1601.36
  81   0.5341     88.650  0.0311    99.048  1621.35
  82   0.5209     88.950  0.0279    99.220  1641.35
  83   0.5398     88.620  0.0295    99.092  1661.33
  84   0.5141     89.000  0.0287    99.164  1681.34
  85   0.5255     88.830  0.0268    99.200  1701.35
