Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5700     41.530  1.8423    31.538  21.92
   2   1.3420     50.190  1.4520    46.068  42.16
   3   1.2323     56.260  1.2254    55.282  62.41
   4   1.0479     62.670  1.0404    62.860  82.65
   5   0.9273     67.060  0.9304    67.074  102.86
   6   0.8655     70.000  0.8372    70.638  123.05
   7   0.9681     67.470  0.7846    72.222  143.28
   8   0.8128     71.680  0.7285    74.524  163.53
   9   0.7087     75.520  0.6784    76.300  183.77
  10   0.7200     75.940  0.6383    77.904  203.96
  11   0.6499     77.770  0.6070    79.034  224.22
  12   0.7441     75.160  0.5922    79.444  244.44
  13   0.7162     75.540  0.5688    80.352  264.69
  14   0.5998     79.120  0.5487    81.096  284.91
  15   0.6385     78.090  0.5298    81.530  305.16
  16   0.6030     79.850  0.5214    82.082  325.39
  17   0.6418     78.440  0.5145    82.324  345.64
  18   0.5646     81.110  0.5157    82.194  365.89
  19   0.6008     79.490  0.5072    82.524  386.12
  20   0.5811     80.460  0.5004    82.922  406.33
  21   0.5082     82.850  0.4863    83.188  426.53
  22   0.5647     81.110  0.4802    83.546  446.71
  23   0.5866     80.450  0.4807    83.492  466.98
  24   0.6042     79.930  0.4796    83.576  487.21
  25   0.6331     79.310  0.4714    83.948  507.50
  26   0.5154     82.820  0.4613    84.288  527.71
  27   0.5719     81.250  0.4685    84.042  547.90
  28   0.5661     81.410  0.4644    84.016  568.15
  29   0.5436     82.640  0.4621    84.192  588.33
  30   0.5875     80.480  0.4580    84.354  608.55
  31   0.5200     82.510  0.4530    84.408  628.78
  32   0.5797     80.330  0.4581    84.248  648.99
  33   0.5481     82.080  0.4594    84.098  669.20
  34   0.5312     82.250  0.4595    84.246  689.42
  35   0.5568     81.440  0.4557    84.506  709.63
  36   0.5751     80.490  0.4459    84.856  729.82
  37   0.6175     79.690  0.4434    84.802  750.10
  38   0.5104     82.530  0.4541    84.318  770.35
  39   0.5205     82.730  0.4521    84.526  790.58
  40   0.5072     82.760  0.4354    85.072  810.84
  41   0.5233     82.340  0.4450    84.892  831.07
  42   0.4905     83.430  0.4388    84.958  851.32
  43   0.5291     82.090  0.4392    85.052  871.59
  44   0.4996     83.180  0.4393    84.936  891.79
  45   0.5378     81.750  0.4340    85.014  912.04
  46   0.5376     82.180  0.4438    84.898  932.28
  47   0.5622     81.060  0.4338    85.218  952.49
  48   0.5989     79.970  0.4331    85.078  972.76
  49   0.5089     83.620  0.4343    85.160  992.99
  50   0.4954     83.030  0.4268    85.290  1013.19
  51   0.5082     82.680  0.4334    85.024  1033.41
  52   0.5284     82.120  0.4370    84.852  1053.62
  53   0.5249     82.260  0.4292    85.342  1073.84
  54   0.5469     81.830  0.4278    85.324  1094.03
  55   0.5149     83.100  0.4341    85.194  1114.25
  56   0.4981     83.300  0.4242    85.674  1134.47
  57   0.4872     83.750  0.4197    85.444  1154.72
  58   0.5076     83.430  0.4279    85.508  1174.92
  59   0.4663     84.430  0.4171    85.920  1195.15
  60   0.5590     82.390  0.4195    85.602  1215.37
  61   0.5053     83.330  0.4226    85.544  1235.58
  62   0.5078     82.860  0.4256    85.444  1255.78
  63   0.4995     82.900  0.4215    85.652  1276.01
  64   0.5122     83.290  0.4203    85.606  1296.26
  65   0.4955     83.540  0.4170    85.748  1316.47
  66   0.5268     82.370  0.4223    85.458  1336.72
  67   0.4824     83.690  0.4196    85.608  1356.92
  68   0.4962     82.970  0.4163    85.628  1377.16
  69   0.5590     81.730  0.4164    85.810  1397.40
  70   0.4776     84.180  0.4142    85.986  1417.67
  71   0.4882     83.390  0.4185    85.798  1437.93
  72   0.4752     83.880  0.4183    85.656  1458.14
  73   0.5058     82.840  0.4138    85.724  1478.35
  74   0.4776     84.110  0.4185    85.580  1498.56
  75   0.5492     81.210  0.4137    85.770  1518.76
  76   0.5748     81.130  0.4171    85.678  1538.96
  77   0.4814     83.840  0.4197    85.668  1559.22
  78   0.4593     84.430  0.4144    86.050  1579.48
  79   0.5038     82.720  0.4119    85.798  1599.68
  80   0.5243     82.600  0.4078    86.052  1619.90
  81   0.5016     83.250  0.4150    85.736  1640.12
  82   0.5158     82.640  0.4168    85.672  1660.35
  83   0.7016     78.420  0.4113    85.900  1680.59
  84   0.6003     81.250  0.4068    86.020  1700.86
  85   0.4965     83.710  0.4178    85.686  1721.11
