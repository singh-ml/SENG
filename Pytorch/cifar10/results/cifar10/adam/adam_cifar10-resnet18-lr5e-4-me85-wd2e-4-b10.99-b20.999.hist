Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-4', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2482     55.890  1.4880    45.178  22.28
   2   1.0286     63.780  1.0983    60.626  42.51
   3   0.8985     69.470  0.8769    68.754  62.68
   4   0.7775     74.090  0.7421    73.786  82.93
   5   0.6568     77.820  0.6384    77.568  103.12
   6   0.5864     79.640  0.5698    80.188  123.39
   7   0.6518     78.330  0.5135    82.086  143.64
   8   0.5756     80.830  0.4753    83.408  163.87
   9   0.5530     81.940  0.4464    84.654  184.10
  10   0.5094     82.690  0.4014    86.146  204.39
  11   0.4553     84.800  0.3775    87.054  224.64
  12   0.5198     82.990  0.3524    87.922  244.90
  13   0.5059     83.270  0.3399    88.230  265.17
  14   0.4290     85.420  0.3230    88.764  285.43
  15   0.4409     85.490  0.2928    89.908  305.69
  16   0.4330     86.130  0.2895    89.914  325.98
  17   0.4204     86.320  0.2736    90.642  346.29
  18   0.3773     87.730  0.2651    90.782  366.57
  19   0.4616     85.390  0.2469    91.496  386.80
  20   0.4450     86.200  0.2367    91.726  407.05
  21   0.3730     88.270  0.2311    92.046  427.34
  22   0.3925     87.670  0.2200    92.454  447.65
  23   0.3640     89.130  0.2097    92.720  467.97
  24   0.3833     88.280  0.1881    93.596  488.24
  25   0.3673     88.740  0.1858    93.534  508.57
  26   0.4505     86.800  0.1817    93.700  528.92
  27   0.3944     88.110  0.1718    94.040  549.22
  28   0.3935     88.850  0.1712    94.076  569.49
  29   0.3491     89.720  0.1608    94.438  589.73
  30   0.4225     88.050  0.1559    94.626  610.09
  31   0.3477     90.000  0.1500    94.776  630.35
  32   0.3685     89.490  0.1442    94.908  650.64
  33   0.3601     89.680  0.1476    94.874  670.94
  34   0.3533     89.740  0.1397    95.240  691.23
  35   0.3429     89.880  0.1397    95.132  711.57
  36   0.3717     89.570  0.1346    95.364  731.85
  37   0.3781     89.900  0.1280    95.556  752.12
  38   0.3447     89.880  0.1271    95.594  772.39
  39   0.3866     89.530  0.1191    95.780  792.64
  40   0.3689     89.490  0.1215    95.776  812.98
  41   0.3643     89.850  0.1224    95.742  833.32
  42   0.3686     89.980  0.1113    96.160  853.60
  43   0.3692     90.120  0.1129    96.038  873.93
  44   0.3681     90.180  0.1071    96.280  894.19
  45   0.4060     89.780  0.1076    96.220  914.46
  46   0.3507     90.620  0.1100    96.268  934.71
  47   0.3554     90.400  0.0958    96.710  954.97
  48   0.3917     89.530  0.0939    96.716  975.23
  49   0.3948     89.860  0.0963    96.672  995.52
  50   0.3726     90.190  0.0968    96.564  1015.81
  51   0.3655     90.400  0.0955    96.726  1036.09
  52   0.3476     90.980  0.0921    96.756  1056.36
  53   0.3558     90.850  0.0901    96.904  1076.65
  54   0.3662     90.380  0.0894    96.908  1096.92
  55   0.3982     90.150  0.0852    97.014  1117.18
  56   0.3805     90.510  0.0878    96.902  1137.41
  57   0.3391     90.810  0.0881    97.048  1157.67
  58   0.3513     90.990  0.0823    97.134  1177.90
  59   0.3569     90.680  0.0838    97.094  1198.22
  60   0.3540     90.680  0.0837    97.180  1218.52
  61   0.3510     90.880  0.0775    97.314  1238.80
  62   0.4001     89.970  0.0781    97.346  1259.09
  63   0.3461     90.940  0.0801    97.206  1279.30
  64   0.3384     91.490  0.0756    97.472  1299.58
  65   0.3889     90.290  0.0787    97.354  1319.86
  66   0.3636     90.670  0.0742    97.452  1340.16
  67   0.3828     90.310  0.0737    97.426  1360.44
  68   0.3573     91.410  0.0737    97.438  1380.75
  69   0.3695     90.710  0.0762    97.290  1401.01
  70   0.3828     90.700  0.0769    97.332  1421.31
  71   0.3732     90.420  0.0688    97.682  1441.62
  72   0.3810     90.790  0.0677    97.664  1461.88
  73   0.3942     90.720  0.0705    97.612  1482.18
  74   0.3535     91.020  0.0668    97.670  1502.49
  75   0.3655     91.080  0.0672    97.684  1522.85
  76   0.3242     91.670  0.0749    97.382  1543.16
  77   0.3900     90.730  0.0703    97.574  1563.46
  78   0.3639     91.310  0.0679    97.712  1583.74
  79   0.3608     91.210  0.0663    97.796  1604.03
  80   0.3649     91.200  0.0669    97.738  1624.31
  81   0.3555     90.950  0.0716    97.544  1644.60
  82   0.4131     90.220  0.0641    97.816  1664.89
  83   0.3872     90.580  0.0641    97.894  1685.17
  84   0.3439     91.440  0.0652    97.746  1705.44
  85   0.3570     91.280  0.0671    97.782  1725.65
