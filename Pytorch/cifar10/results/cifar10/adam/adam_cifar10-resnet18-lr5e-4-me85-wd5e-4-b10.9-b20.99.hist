Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1832     57.950  1.3687    50.036  22.27
   2   0.9216     67.740  0.9292    67.076  42.48
   3   0.7931     73.560  0.7316    74.230  62.70
   4   0.8694     70.450  0.6428    77.780  82.88
   5   0.7259     75.360  0.5716    80.308  103.05
   6   0.6356     78.430  0.5169    82.222  123.27
   7   0.8124     75.230  0.4738    83.604  143.46
   8   0.5551     81.980  0.4396    84.948  163.66
   9   0.6212     79.820  0.4098    85.936  183.89
  10   0.5800     80.440  0.3869    86.646  204.11
  11   0.6614     78.560  0.3650    87.510  224.37
  12   0.4885     84.230  0.3405    88.284  244.62
  13   0.5286     82.840  0.3285    88.656  264.82
  14   0.4893     83.790  0.3083    89.466  285.02
  15   0.5052     84.550  0.2996    89.740  305.24
  16   0.4118     86.380  0.2826    90.374  325.52
  17   0.5893     81.820  0.2754    90.652  345.72
  18   0.5110     84.110  0.2639    90.958  365.93
  19   0.7532     78.140  0.2531    91.338  386.18
  20   0.5739     82.580  0.2403    91.834  406.40
  21   0.4265     86.180  0.2339    91.912  426.59
  22   0.6798     81.490  0.2254    92.292  446.84
  23   0.4481     85.960  0.2190    92.512  467.08
  24   0.3704     88.510  0.2097    92.896  487.35
  25   0.3558     88.700  0.2045    93.032  507.59
  26   0.4167     86.780  0.1988    93.192  527.82
  27   0.4206     87.440  0.1934    93.364  548.08
  28   0.4301     86.890  0.1885    93.512  568.34
  29   0.4263     86.630  0.1847    93.710  588.56
  30   0.5862     83.510  0.1814    93.742  608.84
  31   0.4599     86.710  0.1754    93.956  629.01
  32   0.3546     88.470  0.1731    94.098  649.22
  33   0.3671     89.120  0.1651    94.358  669.40
  34   0.4843     86.130  0.1599    94.574  689.59
  35   0.3948     88.470  0.1592    94.560  709.80
  36   0.4116     87.980  0.1570    94.638  730.01
  37   0.3881     88.940  0.1564    94.714  750.23
  38   0.3729     89.050  0.1505    94.846  770.46
  39   0.3785     88.820  0.1496    94.894  790.70
  40   0.3616     89.270  0.1474    94.930  810.95
  41   0.3822     88.270  0.1394    95.322  831.18
  42   0.4495     87.490  0.1404    95.140  851.37
  43   0.4137     88.410  0.1376    95.362  871.59
  44   0.4210     88.160  0.1333    95.424  891.80
  45   0.3742     89.490  0.1305    95.534  912.03
  46   0.4047     89.260  0.1357    95.324  932.27
  47   0.3854     88.990  0.1241    95.770  952.49
  48   0.3968     89.090  0.1250    95.688  972.73
  49   0.4308     87.580  0.1303    95.538  992.95
  50   0.4208     87.890  0.1205    95.878  1013.15
  51   0.3372     89.840  0.1254    95.700  1033.34
  52   0.3729     89.200  0.1174    95.914  1053.52
  53   0.4666     87.400  0.1194    95.908  1073.74
  54   0.3332     90.590  0.1169    95.896  1093.91
  55   0.4711     86.960  0.1168    95.952  1114.14
  56   0.3578     89.940  0.1175    95.950  1134.34
  57   0.3943     89.660  0.1124    96.182  1154.59
  58   0.3483     90.360  0.1137    96.102  1174.83
  59   0.3553     90.200  0.1100    96.118  1195.05
  60   0.4114     89.100  0.1100    96.276  1215.23
  61   0.3320     90.350  0.1116    96.186  1235.46
  62   0.3439     90.620  0.1091    96.346  1255.66
  63   0.3505     89.780  0.1103    96.250  1275.88
  64   0.3979     89.250  0.1041    96.486  1296.10
  65   0.3566     89.580  0.1107    96.240  1316.34
  66   0.4812     87.590  0.1030    96.642  1336.57
  67   0.4391     88.850  0.1069    96.388  1356.78
  68   0.4160     89.280  0.1043    96.392  1376.97
  69   0.3715     90.130  0.1013    96.598  1397.17
  70   0.3548     90.290  0.1008    96.484  1417.39
  71   0.4226     88.850  0.1005    96.644  1437.63
  72   0.4183     88.780  0.0950    96.764  1457.83
  73   0.4002     89.070  0.0993    96.588  1478.04
  74   0.4048     89.540  0.1038    96.476  1498.22
  75   0.3846     89.960  0.1003    96.580  1518.43
  76   0.3433     90.210  0.0987    96.684  1538.66
  77   0.4764     88.230  0.0994    96.662  1558.87
  78   0.3543     90.150  0.0963    96.672  1579.06
  79   0.3656     90.210  0.0972    96.746  1599.28
  80   0.3721     90.190  0.0935    96.786  1619.49
  81   0.3382     90.910  0.0963    96.724  1639.71
  82   0.3458     90.390  0.0964    96.746  1659.97
  83   0.3765     90.270  0.0973    96.718  1680.18
  84   0.3515     90.050  0.0948    96.866  1700.44
  85   0.3831     90.140  0.0897    96.968  1720.66
