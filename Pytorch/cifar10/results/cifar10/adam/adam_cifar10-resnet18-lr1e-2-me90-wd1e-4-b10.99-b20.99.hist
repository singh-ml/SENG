Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8708     30.670  2.1651    23.112  22.26
   2   1.7464     36.260  1.7092    36.552  42.54
   3   1.3224     51.240  1.4629    46.172  62.83
   4   1.2610     54.920  1.2505    54.610  83.06
   5   1.0303     63.630  1.0692    61.806  103.34
   6   0.9975     66.120  0.9391    66.620  123.60
   7   0.8918     69.520  0.8478    69.810  143.84
   8   0.8335     72.140  0.7607    73.232  164.06
   9   0.7580     73.820  0.7103    75.124  184.26
  10   0.6912     76.740  0.6568    77.276  204.46
  11   0.6464     78.200  0.6171    78.294  224.66
  12   0.6097     79.000  0.5878    79.676  244.86
  13   0.6550     77.960  0.5691    80.352  265.06
  14   0.6277     78.390  0.5568    80.664  285.27
  15   0.5910     79.990  0.5415    81.214  305.47
  16   0.6415     78.460  0.5336    81.612  325.68
  17   0.5740     80.350  0.5183    82.112  345.96
  18   0.5956     80.040  0.5112    82.276  366.19
  19   0.5478     81.990  0.5015    82.716  386.43
  20   0.5692     80.650  0.4941    82.950  406.68
  21   0.5905     80.720  0.4890    83.044  426.93
  22   0.6006     79.400  0.4930    82.912  447.15
  23   0.5469     81.150  0.4827    83.376  467.34
  24   0.5359     81.750  0.4750    83.592  487.53
  25   0.5618     81.380  0.4647    83.986  507.74
  26   0.5799     80.230  0.4721    83.898  528.00
  27   0.5436     82.140  0.4645    83.872  548.24
  28   0.5378     82.340  0.4576    84.328  568.44
  29   0.5548     81.570  0.4541    84.360  588.64
  30   0.5292     82.310  0.4507    84.302  608.85
  31   0.5708     81.700  0.4462    84.572  629.07
  32   0.5661     81.390  0.4506    84.382  649.29
  33   0.5264     82.190  0.4495    84.380  669.53
  34   0.5061     82.850  0.4436    84.538  689.77
  35   0.5129     82.980  0.4380    84.938  709.99
  36   0.5489     81.610  0.4388    84.716  730.21
  37   0.5222     82.870  0.4340    84.954  750.43
  38   0.5115     83.200  0.4391    84.896  770.69
  39   0.5142     82.750  0.4308    85.258  790.90
  40   0.5211     82.720  0.4325    84.874  811.11
  41   0.5667     81.300  0.4272    85.222  831.35
  42   0.5123     82.800  0.4252    85.312  851.57
  43   0.5091     82.930  0.4271    85.248  871.76
  44   0.4684     84.300  0.4244    85.504  891.99
  45   0.5117     82.730  0.4280    85.264  912.22
  46   0.5418     81.900  0.4281    85.088  932.45
  47   0.5102     82.870  0.4243    85.172  952.66
  48   0.5428     82.280  0.4156    85.656  972.93
  49   0.5034     82.980  0.4224    85.390  993.16
  50   0.5083     82.920  0.4159    85.466  1013.40
  51   0.5167     82.720  0.4175    85.568  1033.64
  52   0.5054     83.610  0.4159    85.584  1053.86
  53   0.5102     83.190  0.4168    85.550  1074.05
  54   0.4943     83.340  0.4130    85.722  1094.29
  55   0.5196     82.890  0.4119    85.794  1114.52
  56   0.5489     82.020  0.4156    85.582  1134.77
  57   0.4795     83.800  0.4141    85.854  1155.03
  58   0.4893     83.570  0.4088    85.844  1175.26
  59   0.5304     82.930  0.4133    85.636  1195.46
  60   0.5034     83.240  0.4181    85.664  1215.69
  61   0.5568     81.670  0.4110    85.762  1235.91
  62   0.5055     82.970  0.4124    85.878  1256.11
  63   0.5396     81.660  0.4088    85.900  1276.35
  64   0.4593     84.890  0.4129    85.742  1296.60
  65   0.5359     82.020  0.4101    85.778  1316.78
  66   0.5426     81.620  0.4086    85.878  1337.01
  67   0.4989     83.250  0.4051    86.074  1357.22
  68   0.4680     84.220  0.4091    85.764  1377.47
  69   0.5853     81.270  0.4052    85.994  1397.73
  70   0.5253     82.660  0.4059    86.052  1417.96
  71   0.4892     83.670  0.4111    85.818  1438.18
  72   0.4661     84.350  0.4059    86.142  1458.43
  73   0.4798     84.310  0.4034    85.922  1478.64
  74   0.6153     80.630  0.3976    86.270  1498.83
  75   0.5103     83.200  0.4019    85.982  1519.04
  76   0.5022     83.270  0.4094    85.864  1539.26
  77   0.4811     84.080  0.4022    86.182  1559.50
  78   0.4904     83.590  0.4040    86.124  1579.74
  79   0.4823     83.530  0.4057    85.984  1599.96
  80   0.4915     83.310  0.4046    86.054  1620.25
  81   0.4732     84.030  0.4009    86.108  1640.48
  82   0.4644     84.360  0.4030    86.138  1660.70
  83   0.4883     83.660  0.4032    86.146  1680.92
  84   0.4580     84.500  0.3970    86.278  1701.18
  85   0.5625     82.830  0.4003    86.292  1721.39
  86   0.5042     83.080  0.4018    86.048  1741.60
  87   0.4937     83.050  0.3996    86.154  1761.84
  88   0.5010     83.130  0.3991    86.346  1782.07
  89   0.4989     83.110  0.3998    86.248  1802.31
  90   0.4967     83.350  0.4037    86.268  1822.54
