Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3136     52.110  1.5431    43.180  22.40
   2   1.1313     59.160  1.1485    58.082  42.72
   3   0.9756     66.280  0.9514    65.792  63.05
   4   0.8532     70.730  0.8383    70.424  83.39
   5   0.7483     74.140  0.7310    74.298  103.73
   6   0.6981     76.630  0.6559    76.934  124.00
   7   0.7149     75.850  0.5911    79.414  144.39
   8   0.5892     80.100  0.5254    81.928  164.76
   9   0.5585     81.180  0.4894    83.158  185.06
  10   0.5005     82.860  0.4653    84.050  205.37
  11   0.5075     83.360  0.4260    85.282  225.70
  12   0.5065     82.840  0.3918    86.526  246.04
  13   0.5132     83.340  0.3825    86.814  266.36
  14   0.4470     85.190  0.3602    87.598  286.65
  15   0.4494     85.520  0.3276    88.876  306.95
  16   0.4189     86.210  0.3238    88.978  327.31
  17   0.4077     86.920  0.3060    89.558  347.57
  18   0.3900     87.140  0.2819    90.390  367.91
  19   0.4016     86.890  0.2723    90.700  388.22
  20   0.4046     86.800  0.2703    90.718  408.53
  21   0.4200     86.370  0.2676    90.882  428.82
  22   0.3964     87.480  0.2559    91.150  449.18
  23   0.3667     88.490  0.2378    91.812  469.46
  24   0.3598     88.110  0.2362    91.902  489.73
  25   0.3811     88.110  0.2236    92.202  510.01
  26   0.3753     88.490  0.2161    92.508  530.30
  27   0.3749     88.460  0.2078    92.810  550.59
  28   0.3533     89.060  0.1968    93.144  570.89
  29   0.3868     88.420  0.1993    93.106  591.15
  30   0.3757     88.890  0.2009    92.966  611.49
  31   0.3441     89.700  0.1786    93.872  631.77
  32   0.3575     88.880  0.1753    93.944  652.07
  33   0.3326     89.920  0.1821    93.898  672.36
  34   0.3321     89.790  0.1780    93.888  692.68
  35   0.3616     89.290  0.1665    94.380  713.04
  36   0.3591     89.520  0.1622    94.460  733.36
  37   0.3426     89.380  0.1687    94.198  753.67
  38   0.3790     89.440  0.1621    94.414  773.98
  39   0.3090     90.910  0.1556    94.640  794.32
  40   0.3453     90.120  0.1467    94.938  814.63
  41   0.3424     89.790  0.1504    94.814  834.93
  42   0.3350     90.210  0.1462    94.962  855.24
  43   0.3403     90.330  0.1365    95.274  875.53
  44   0.3467     90.210  0.1445    95.012  895.91
  45   0.3518     89.870  0.1433    95.120  916.23
  46   0.3209     90.750  0.1409    95.088  936.54
  47   0.3682     89.480  0.1366    95.296  956.85
  48   0.3815     89.480  0.1365    95.282  977.20
  49   0.3452     89.970  0.1343    95.392  997.54
  50   0.3271     89.970  0.1278    95.596  1017.84
  51   0.3570     90.150  0.1290    95.534  1038.21
  52   0.3322     90.490  0.1305    95.496  1058.51
  53   0.3187     90.710  0.1299    95.578  1078.82
  54   0.3389     90.890  0.1184    95.904  1099.14
  55   0.3169     90.770  0.1138    96.050  1119.51
  56   0.3354     90.500  0.1191    95.886  1139.89
  57   0.3504     90.250  0.1243    95.602  1160.23
  58   0.3153     90.840  0.1180    96.016  1180.59
  59   0.3498     90.430  0.1198    95.880  1200.99
  60   0.3714     89.590  0.1200    95.818  1221.30
  61   0.3376     90.560  0.1168    95.908  1241.62
  62   0.3335     91.110  0.1163    96.016  1261.96
  63   0.3510     89.810  0.1171    95.912  1282.29
  64   0.3174     91.300  0.1061    96.312  1302.59
  65   0.3645     90.330  0.1124    96.026  1322.96
  66   0.3480     90.290  0.1081    96.160  1343.31
  67   0.3444     90.470  0.1061    96.336  1363.56
  68   0.3243     91.170  0.1105    96.144  1383.83
  69   0.3277     91.550  0.1093    96.264  1404.22
  70   0.3275     91.160  0.1028    96.450  1424.52
  71   0.3316     90.720  0.1072    96.204  1444.87
  72   0.3520     90.720  0.1094    96.150  1465.23
  73   0.3485     90.420  0.1063    96.246  1485.58
  74   0.3497     90.120  0.1052    96.354  1505.94
  75   0.3156     91.030  0.1129    96.080  1526.27
  76   0.3145     91.310  0.0967    96.780  1546.57
  77   0.3480     90.610  0.1008    96.496  1566.91
  78   0.3405     90.810  0.1060    96.336  1587.22
  79   0.3276     91.200  0.1014    96.512  1607.56
  80   0.3381     90.920  0.1032    96.434  1627.91
  81   0.3345     91.100  0.1039    96.392  1648.24
  82   0.3672     90.410  0.1020    96.490  1668.53
  83   0.3909     89.650  0.0961    96.670  1688.84
  84   0.3475     91.080  0.1034    96.378  1709.20
  85   0.3302     90.960  0.0992    96.528  1729.47
  86   0.3368     90.740  0.0967    96.704  1749.79
  87   0.3293     90.990  0.1013    96.540  1770.11
  88   0.3370     91.180  0.0999    96.646  1790.42
  89   0.3359     90.840  0.0956    96.694  1810.79
  90   0.3296     91.180  0.0973    96.628  1831.09
