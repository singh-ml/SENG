Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3684     49.470  1.6284    39.574  22.02
   2   1.1959     56.940  1.2851    53.134  42.29
   3   1.0753     62.320  1.1080    59.896  62.53
   4   0.9477     66.400  0.9689    65.462  82.82
   5   0.8621     69.620  0.8719    68.960  103.07
   6   0.8003     71.720  0.7980    71.602  123.33
   7   0.7590     73.460  0.7284    74.510  143.59
   8   0.7021     75.350  0.6655    76.486  163.86
   9   0.6777     77.100  0.6189    78.130  184.08
  10   0.6258     78.090  0.5742    79.894  204.32
  11   0.5935     79.650  0.5405    81.000  224.58
  12   0.5947     79.670  0.5132    82.132  244.83
  13   0.5496     81.150  0.4758    83.324  265.08
  14   0.5903     80.220  0.4496    84.240  285.29
  15   0.5474     81.220  0.4266    85.092  305.53
  16   0.5381     82.060  0.4026    86.020  325.77
  17   0.5275     82.470  0.3829    86.692  346.02
  18   0.4866     83.800  0.3581    87.572  366.30
  19   0.5061     82.960  0.3420    88.164  386.56
  20   0.4845     83.920  0.3278    88.748  406.83
  21   0.4758     84.130  0.3113    89.316  427.09
  22   0.4689     84.380  0.2974    89.668  447.33
  23   0.4935     83.970  0.2791    90.222  467.57
  24   0.4558     85.070  0.2758    90.516  487.84
  25   0.4868     84.310  0.2587    90.962  508.10
  26   0.4775     85.060  0.2423    91.460  528.33
  27   0.4640     85.090  0.2358    91.874  548.63
  28   0.4838     84.500  0.2220    92.170  568.85
  29   0.4875     84.980  0.2080    92.848  589.15
  30   0.4855     84.400  0.1973    93.152  609.38
  31   0.4907     84.430  0.2001    92.942  629.68
  32   0.4524     85.730  0.1972    93.162  649.90
  33   0.4623     86.030  0.1822    93.630  670.13
  34   0.4505     86.860  0.1727    93.952  690.36
  35   0.5019     84.870  0.1711    94.034  710.64
  36   0.4913     85.400  0.1583    94.524  730.88
  37   0.4669     86.600  0.1523    94.630  751.13
  38   0.4534     86.630  0.1481    94.802  771.34
  39   0.4789     86.140  0.1462    94.914  791.58
  40   0.4653     86.490  0.1389    95.226  811.78
  41   0.4472     86.910  0.1363    95.322  832.00
  42   0.4548     86.950  0.1309    95.536  852.23
  43   0.4459     86.790  0.1297    95.482  872.53
  44   0.4496     87.170  0.1183    96.036  892.78
  45   0.4783     86.550  0.1157    95.962  913.02
  46   0.4629     87.190  0.1163    96.014  933.22
  47   0.4657     86.910  0.1169    95.918  953.44
  48   0.4748     86.680  0.1131    96.134  973.68
  49   0.4340     87.350  0.1097    96.162  993.95
  50   0.4374     87.780  0.1049    96.428  1014.18
  51   0.4487     87.420  0.0946    96.776  1034.43
  52   0.4522     87.480  0.0947    96.854  1054.65
  53   0.4699     87.070  0.0936    96.866  1074.89
  54   0.4678     87.470  0.0946    96.784  1095.13
  55   0.4962     86.490  0.0939    96.768  1115.38
  56   0.4374     87.690  0.0859    96.972  1135.63
  57   0.4547     87.830  0.0824    97.188  1155.85
  58   0.4515     87.560  0.0862    97.040  1176.12
  59   0.4652     87.390  0.0781    97.340  1196.35
  60   0.5206     86.980  0.0759    97.418  1216.57
  61   0.4704     87.420  0.0750    97.422  1236.78
  62   0.4632     87.580  0.0733    97.454  1257.01
  63   0.4777     87.490  0.0743    97.500  1277.26
  64   0.4513     88.230  0.0720    97.590  1297.55
  65   0.4542     87.830  0.0734    97.486  1317.77
  66   0.4458     88.210  0.0690    97.640  1338.01
  67   0.4545     88.410  0.0626    97.934  1358.28
  68   0.4737     87.900  0.0651    97.780  1378.53
  69   0.4694     87.450  0.0698    97.602  1398.75
  70   0.4518     88.300  0.0671    97.772  1418.97
  71   0.4629     88.210  0.0629    97.836  1439.21
  72   0.4554     88.160  0.0643    97.818  1459.50
  73   0.4357     88.450  0.0620    97.888  1479.74
  74   0.4563     87.940  0.0583    98.050  1499.96
  75   0.4673     88.060  0.0629    97.842  1520.21
  76   0.4544     88.650  0.0554    98.158  1540.45
  77   0.4620     88.020  0.0546    98.150  1560.73
  78   0.4435     88.340  0.0519    98.300  1580.95
  79   0.4454     88.590  0.0559    98.176  1601.26
  80   0.4543     88.680  0.0518    98.312  1621.51
  81   0.4476     88.540  0.0499    98.442  1641.75
  82   0.5001     87.730  0.0583    98.052  1662.01
  83   0.4664     88.140  0.0584    98.038  1682.29
  84   0.4498     88.460  0.0547    98.160  1702.48
  85   0.4991     88.130  0.0539    98.198  1722.68
  86   0.4709     87.980  0.0561    98.124  1742.90
  87   0.4483     88.700  0.0534    98.186  1763.17
  88   0.4698     88.600  0.0549    98.184  1783.43
  89   0.4627     88.570  0.0526    98.228  1803.68
  90   0.4727     88.170  0.0520    98.248  1823.92
