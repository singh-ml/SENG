Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3352     52.410  1.3942    48.924  22.03
   2   0.9104     67.970  0.9520    66.010  42.28
   3   0.8541     71.620  0.7352    73.872  62.52
   4   0.7427     75.350  0.6269    78.134  82.78
   5   0.7113     76.480  0.5532    80.810  103.04
   6   0.6228     79.220  0.4904    82.994  123.31
   7   0.6188     80.050  0.4435    84.528  143.56
   8   0.6011     80.390  0.4075    85.886  163.86
   9   0.5293     82.380  0.3779    86.870  184.13
  10   0.5860     82.230  0.3530    87.876  204.37
  11   0.4861     84.680  0.3283    88.696  224.62
  12   0.4871     83.830  0.3113    89.216  244.91
  13   0.4343     86.090  0.2869    90.152  265.18
  14   0.4787     85.110  0.2723    90.542  285.43
  15   0.4570     85.590  0.2598    90.988  305.73
  16   0.4930     85.070  0.2420    91.644  326.05
  17   0.4949     84.010  0.2311    91.970  346.30
  18   0.4245     86.820  0.2213    92.180  366.62
  19   0.4530     86.230  0.2082    92.708  386.90
  20   0.4818     85.850  0.1983    93.008  407.18
  21   0.4213     87.580  0.1946    93.224  427.45
  22   0.3863     87.980  0.1821    93.664  447.80
  23   0.4962     86.280  0.1739    93.990  468.07
  24   0.4337     86.880  0.1659    94.212  488.32
  25   0.3803     88.500  0.1582    94.406  508.61
  26   0.4112     87.750  0.1559    94.606  528.84
  27   0.6603     83.370  0.1486    94.892  549.09
  28   0.5694     84.890  0.1423    94.906  569.43
  29   0.4150     88.490  0.1322    95.422  589.77
  30   0.5412     86.030  0.1294    95.422  610.00
  31   0.4724     87.240  0.1316    95.424  630.26
  32   0.5167     86.710  0.1276    95.546  650.48
  33   0.3840     89.610  0.1201    95.860  670.68
  34   0.4477     87.810  0.1120    96.088  690.90
  35   0.3934     88.960  0.1129    95.994  711.09
  36   0.4844     87.840  0.1080    96.298  731.31
  37   0.4649     87.570  0.1047    96.318  751.52
  38   0.3812     89.850  0.1059    96.248  771.72
  39   0.4944     87.920  0.0943    96.706  791.94
  40   0.4466     89.000  0.0969    96.610  812.19
  41   0.5196     88.080  0.0929    96.800  832.41
  42   0.5480     86.700  0.0901    96.816  852.63
  43   0.3742     90.590  0.0882    96.894  872.84
  44   0.3909     89.930  0.0881    96.984  893.07
  45   0.4098     89.730  0.0775    97.264  913.32
  46   0.4734     88.370  0.0886    96.924  933.52
  47   0.3924     90.370  0.0811    97.198  953.72
  48   0.4470     88.870  0.0818    97.148  973.92
  49   0.4053     89.920  0.0789    97.254  994.20
  50   0.3745     90.510  0.0780    97.218  1014.44
  51   0.4004     89.800  0.0704    97.548  1034.67
  52   0.4343     89.520  0.0798    97.232  1054.92
  53   0.4228     89.410  0.0745    97.448  1075.18
  54   0.4007     90.330  0.0711    97.516  1095.49
  55   0.4536     89.320  0.0722    97.558  1115.70
  56   0.4410     89.750  0.0645    97.842  1135.92
  57   0.3503     90.840  0.0691    97.634  1156.19
  58   0.4430     89.210  0.0692    97.614  1176.41
  59   0.3631     90.910  0.0677    97.668  1196.63
  60   0.3934     90.260  0.0674    97.630  1216.86
  61   0.4727     89.040  0.0678    97.684  1237.10
  62   0.3974     90.220  0.0617    97.874  1257.35
  63   0.4294     89.770  0.0666    97.650  1277.60
  64   0.5578     87.260  0.0672    97.660  1297.84
  65   0.4167     90.660  0.0547    98.140  1318.10
  66   0.3757     90.490  0.0681    97.602  1338.37
  67   0.4182     90.040  0.0591    97.950  1358.64
  68   0.3727     90.960  0.0560    98.030  1378.85
  69   0.3794     90.850  0.0583    98.016  1399.08
  70   0.3966     90.520  0.0553    98.056  1419.27
  71   0.4769     89.500  0.0559    98.066  1439.54
  72   0.3998     90.580  0.0580    97.948  1459.83
  73   0.3688     90.640  0.0595    97.924  1480.13
  74   0.4130     90.210  0.0558    97.980  1500.34
  75   0.3755     90.580  0.0587    97.970  1520.57
  76   0.3779     90.900  0.0565    98.086  1540.85
  77   0.5417     88.500  0.0502    98.274  1561.11
  78   0.3824     90.930  0.0556    98.126  1581.36
  79   0.4155     90.620  0.0528    98.220  1601.58
  80   0.3833     91.160  0.0574    98.060  1621.84
  81   0.3938     90.830  0.0532    98.160  1642.09
  82   0.3728     91.190  0.0481    98.366  1662.33
  83   0.3456     91.190  0.0579    97.974  1682.55
  84   0.3496     91.240  0.0538    98.154  1702.78
  85   0.4961     89.430  0.0497    98.308  1722.99
  86   0.4246     90.360  0.0528    98.118  1743.28
  87   0.3882     90.630  0.0514    98.208  1763.51
  88   0.4692     89.590  0.0488    98.316  1783.77
  89   0.3856     91.100  0.0528    98.204  1804.00
  90   0.4533     90.160  0.0512    98.202  1824.20
