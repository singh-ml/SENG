Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.1035     61.920  1.4078    48.422  22.25
   2   1.4786     57.930  0.9358    66.784  42.50
   3   0.8942     70.020  0.7491    73.664  62.72
   4   0.7261     75.940  0.6355    77.986  82.96
   5   0.7437     75.180  0.5641    80.654  103.17
   6   0.6180     79.090  0.5116    82.226  123.44
   7   0.7839     75.210  0.4638    84.082  143.76
   8   0.5300     82.810  0.4304    85.300  163.96
   9   0.5505     81.720  0.4012    86.312  184.20
  10   0.5833     81.540  0.3804    86.856  204.42
  11   0.5095     83.090  0.3501    87.986  224.65
  12   0.4227     85.660  0.3348    88.506  244.94
  13   0.3989     87.030  0.3135    89.314  265.15
  14   0.4529     85.340  0.2931    89.898  285.38
  15   0.4655     85.540  0.2878    90.222  305.66
  16   0.3798     87.590  0.2739    90.736  325.85
  17   0.4833     84.540  0.2664    90.938  346.08
  18   0.3826     87.270  0.2523    91.438  366.31
  19   0.4079     86.810  0.2423    91.756  386.57
  20   0.3662     88.080  0.2367    91.824  406.80
  21   0.3972     87.790  0.2329    91.810  427.03
  22   0.4284     86.680  0.2200    92.356  447.24
  23   0.3713     88.000  0.2151    92.654  467.49
  24   0.3941     87.730  0.2072    92.850  487.81
  25   0.3808     87.620  0.1993    93.136  508.05
  26   0.3867     88.110  0.1967    93.264  528.26
  27   0.4629     86.170  0.1909    93.348  548.51
  28   0.4625     85.750  0.1870    93.470  568.73
  29   0.3833     88.090  0.1821    93.670  588.96
  30   0.3942     88.480  0.1751    93.992  609.26
  31   0.3582     88.960  0.1770    93.832  629.53
  32   0.3477     89.620  0.1673    94.216  649.80
  33   0.3870     88.470  0.1685    94.264  670.05
  34   0.3290     89.900  0.1617    94.362  690.24
  35   0.3517     89.420  0.1623    94.418  710.52
  36   0.4245     88.060  0.1588    94.430  730.78
  37   0.5620     85.510  0.1498    94.810  750.97
  38   0.3630     88.730  0.1593    94.484  771.20
  39   0.3681     89.240  0.1482    94.846  791.47
  40   0.3609     89.600  0.1456    95.008  811.69
  41   0.3833     88.670  0.1463    94.922  831.95
  42   0.3725     89.460  0.1461    94.924  852.17
  43   0.4099     88.210  0.1420    95.084  872.44
  44   0.4497     87.360  0.1406    95.046  892.67
  45   0.3359     89.790  0.1388    95.188  912.89
  46   0.3928     88.680  0.1362    95.326  933.18
  47   0.3928     89.410  0.1384    95.174  953.42
  48   0.3570     89.280  0.1339    95.276  973.70
  49   0.4041     88.760  0.1322    95.422  993.91
  50   0.3188     90.750  0.1311    95.486  1014.20
  51   0.3473     89.770  0.1312    95.542  1034.40
  52   0.3730     89.870  0.1272    95.550  1054.61
  53   0.4189     88.350  0.1252    95.670  1074.86
  54   0.3773     90.280  0.1300    95.438  1095.09
  55   0.3923     89.070  0.1198    95.884  1115.31
  56   0.3549     90.020  0.1259    95.680  1135.59
  57   0.4386     88.030  0.1220    95.668  1155.85
  58   0.3086     90.940  0.1215    95.846  1176.11
  59   0.3589     89.920  0.1134    96.044  1196.38
  60   0.3724     89.650  0.1207    95.892  1216.63
  61   0.3583     89.730  0.1185    95.850  1236.83
  62   0.3732     89.290  0.1144    96.062  1257.08
  63   0.3657     89.660  0.1183    95.944  1277.31
  64   0.3034     90.730  0.1177    95.950  1297.55
  65   0.3862     89.180  0.1143    96.108  1317.77
  66   0.3495     90.550  0.1119    96.072  1338.02
  67   0.4548     88.060  0.1099    96.234  1358.24
  68   0.3292     90.790  0.1095    96.242  1378.56
  69   0.3587     90.500  0.1122    96.064  1398.82
  70   0.4021     89.510  0.1129    96.114  1419.13
  71   0.4123     89.480  0.1094    96.194  1439.34
  72   0.3873     89.560  0.1069    96.336  1459.54
  73   0.3377     90.620  0.1147    96.014  1479.75
  74   0.3561     90.390  0.1077    96.286  1499.97
  75   0.3869     89.750  0.1079    96.238  1520.17
  76   0.3869     89.190  0.1088    96.248  1540.41
  77   0.3898     89.630  0.1065    96.428  1560.67
  78   0.3415     90.460  0.1049    96.408  1580.96
  79   0.3165     91.140  0.1087    96.322  1601.18
  80   0.4029     89.540  0.1070    96.392  1621.45
  81   0.3997     89.910  0.1048    96.474  1641.73
  82   0.3710     89.960  0.1080    96.256  1661.97
  83   0.3209     91.170  0.1054    96.330  1682.24
  84   0.4259     88.950  0.1012    96.438  1702.45
  85   0.3572     90.210  0.1050    96.388  1722.65
  86   0.3938     89.750  0.1006    96.484  1742.83
  87   0.3269     90.790  0.1028    96.418  1763.11
  88   0.3679     89.880  0.1034    96.470  1783.33
  89   0.3555     90.210  0.0975    96.602  1803.58
  90   0.3492     90.450  0.1047    96.488  1823.79
