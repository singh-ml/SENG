Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3773     50.770  1.4761    45.590  22.19
   2   1.0960     61.370  1.0697    61.516  42.42
   3   0.9842     66.550  0.8757    68.960  62.65
   4   0.7770     72.290  0.7424    73.702  82.87
   5   0.7309     75.580  0.6522    77.020  103.10
   6   0.7410     75.200  0.5803    79.850  123.33
   7   0.6559     78.080  0.5258    81.680  143.56
   8   0.6845     77.040  0.4895    83.004  163.82
   9   0.6169     79.280  0.4510    84.172  184.02
  10   0.5257     82.540  0.4195    85.260  204.26
  11   0.6120     80.460  0.3920    86.326  224.51
  12   0.5264     83.040  0.3648    87.356  244.74
  13   0.5104     82.550  0.3427    88.078  264.97
  14   0.4859     84.080  0.3210    88.808  285.22
  15   0.4666     84.440  0.3016    89.394  305.47
  16   0.4682     84.590  0.2872    90.010  325.69
  17   0.4249     86.270  0.2707    90.504  345.88
  18   0.4467     85.920  0.2565    91.076  366.09
  19   0.5441     83.500  0.2444    91.418  386.34
  20   0.4379     86.110  0.2291    91.968  406.58
  21   0.4893     84.810  0.2215    92.218  426.79
  22   0.4273     87.020  0.2059    92.808  447.05
  23   0.4583     85.580  0.1968    93.090  467.26
  24   0.4052     87.650  0.1920    93.300  487.50
  25   0.4986     85.260  0.1795    93.792  507.74
  26   0.4515     86.360  0.1748    93.952  527.95
  27   0.4794     86.440  0.1675    94.132  548.17
  28   0.4085     87.600  0.1593    94.516  568.42
  29   0.4109     88.050  0.1529    94.722  588.63
  30   0.4135     87.780  0.1463    94.918  608.88
  31   0.4090     88.700  0.1406    95.010  629.13
  32   0.4713     86.550  0.1299    95.386  649.35
  33   0.5710     84.510  0.1291    95.472  669.58
  34   0.4221     88.230  0.1306    95.432  689.82
  35   0.4472     87.480  0.1230    95.672  710.07
  36   0.4668     87.970  0.1127    96.020  730.31
  37   0.4072     88.720  0.1148    96.000  750.57
  38   0.5577     86.180  0.1080    96.208  770.80
  39   0.4483     88.080  0.1081    96.202  791.06
  40   0.5063     86.710  0.1019    96.434  811.27
  41   0.5028     86.830  0.0984    96.582  831.47
  42   0.4240     88.650  0.0988    96.622  851.69
  43   0.4265     88.770  0.0910    96.726  871.89
  44   0.4274     88.600  0.0906    96.810  892.12
  45   0.3937     88.900  0.0901    96.874  912.32
  46   0.4458     88.190  0.0892    96.898  932.59
  47   0.4618     88.480  0.0874    96.944  952.80
  48   0.4534     88.670  0.0843    97.050  973.03
  49   0.4453     88.610  0.0784    97.374  993.22
  50   0.4042     89.850  0.0775    97.318  1013.45
  51   0.4861     88.340  0.0810    97.224  1033.63
  52   0.5263     86.630  0.0757    97.342  1053.86
  53   0.5566     87.140  0.0722    97.516  1074.09
  54   0.4427     88.680  0.0711    97.550  1094.32
  55   0.5832     86.170  0.0733    97.478  1114.56
  56   0.4611     88.710  0.0713    97.506  1134.76
  57   0.4796     88.540  0.0675    97.654  1155.06
  58   0.4251     89.760  0.0675    97.676  1175.31
  59   0.4089     89.780  0.0688    97.598  1195.53
  60   0.4416     88.910  0.0636    97.772  1215.73
  61   0.4384     89.240  0.0644    97.830  1235.92
  62   0.4610     88.650  0.0631    97.834  1256.16
  63   0.5634     87.110  0.0645    97.712  1276.38
  64   0.3977     90.460  0.0583    97.970  1296.63
  65   0.4780     88.790  0.0623    97.846  1316.92
  66   0.4188     89.720  0.0612    97.956  1337.19
  67   0.4577     89.070  0.0568    98.076  1357.38
  68   0.4624     88.900  0.0587    97.958  1377.57
  69   0.4839     88.870  0.0582    97.972  1397.82
  70   0.4390     89.560  0.0565    97.996  1418.03
  71   0.4737     89.240  0.0560    98.098  1438.26
  72   0.4163     89.510  0.0570    97.998  1458.47
  73   0.4503     89.490  0.0522    98.184  1478.70
  74   0.4336     89.780  0.0516    98.200  1498.90
  75   0.4373     89.540  0.0524    98.232  1519.11
  76   0.4007     90.060  0.0517    98.254  1539.33
  77   0.4828     88.840  0.0510    98.292  1559.52
  78   0.4705     88.880  0.0490    98.276  1579.72
  79   0.5099     88.490  0.0527    98.134  1599.95
  80   0.4110     90.130  0.0505    98.280  1620.14
  81   0.6301     86.820  0.0469    98.406  1640.33
  82   0.4547     89.660  0.0507    98.258  1660.54
  83   0.4282     89.790  0.0519    98.246  1680.74
  84   0.4493     90.220  0.0478    98.348  1700.96
  85   0.4200     90.150  0.0475    98.422  1721.22
