Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3276     51.940  1.5642    41.912  22.27
   2   1.1376     59.530  1.2002    56.624  42.51
   3   1.0629     63.310  1.0271    63.402  62.80
   4   0.9450     67.320  0.9017    67.790  83.06
   5   0.8479     70.870  0.8044    71.738  103.29
   6   0.7617     73.960  0.7260    74.576  123.53
   7   0.7086     75.640  0.6649    76.668  143.82
   8   0.6697     76.550  0.6150    78.464  164.08
   9   0.6351     78.140  0.5690    80.178  184.36
  10   0.6505     77.780  0.5330    81.556  204.68
  11   0.6020     79.130  0.5024    82.358  224.98
  12   0.6214     78.930  0.4714    83.564  245.24
  13   0.5712     80.840  0.4455    84.452  265.52
  14   0.5502     81.290  0.4178    85.484  285.80
  15   0.5333     82.080  0.3965    86.132  306.06
  16   0.5595     81.820  0.3765    86.822  326.30
  17   0.5395     82.290  0.3594    87.508  346.54
  18   0.5395     82.150  0.3439    87.964  366.80
  19   0.5201     83.360  0.3247    88.748  387.09
  20   0.4912     84.150  0.3114    89.178  407.36
  21   0.4927     83.820  0.2889    89.846  427.67
  22   0.4931     84.560  0.2857    89.994  447.98
  23   0.4815     84.370  0.2667    90.740  468.29
  24   0.6012     82.070  0.2509    91.268  488.57
  25   0.5067     84.530  0.2472    91.434  508.84
  26   0.5341     83.710  0.2337    91.836  529.06
  27   0.4932     84.970  0.2188    92.356  549.34
  28   0.4756     85.350  0.2125    92.548  569.62
  29   0.4702     85.540  0.1985    93.034  589.84
  30   0.5406     83.940  0.1886    93.394  610.10
  31   0.4887     85.380  0.1827    93.644  630.38
  32   0.5000     85.580  0.1711    94.014  650.64
  33   0.5401     84.600  0.1677    94.190  670.94
  34   0.5002     85.680  0.1565    94.502  691.27
  35   0.5069     85.620  0.1473    94.718  711.57
  36   0.5012     86.240  0.1433    95.060  731.81
  37   0.5057     85.550  0.1425    95.014  752.03
  38   0.6330     83.410  0.1306    95.414  772.28
  39   0.5107     86.000  0.1276    95.410  792.51
  40   0.5407     85.810  0.1241    95.598  812.79
  41   0.4811     86.610  0.1151    95.968  833.12
  42   0.5881     85.090  0.1066    96.276  853.43
  43   0.5191     86.140  0.1059    96.222  873.69
  44   0.5018     87.000  0.1003    96.492  893.97
  45   0.4988     86.960  0.0987    96.574  914.32
  46   0.4987     86.750  0.0981    96.566  934.61
  47   0.6044     85.120  0.0933    96.706  954.87
  48   0.5354     86.630  0.0923    96.730  975.14
  49   0.6282     84.540  0.0837    97.032  995.41
  50   0.5218     86.670  0.0798    97.178  1015.68
  51   0.6981     83.800  0.0824    97.120  1035.91
  52   0.5058     87.480  0.0866    96.970  1056.22
  53   0.4982     87.480  0.0712    97.618  1076.50
  54   0.5069     87.710  0.0737    97.392  1096.72
  55   0.5530     86.790  0.0695    97.608  1117.04
  56   0.5264     87.300  0.0692    97.570  1137.31
  57   0.5500     86.710  0.0672    97.690  1157.57
  58   0.5863     86.410  0.0704    97.472  1177.82
  59   0.5106     87.550  0.0651    97.754  1198.08
  60   0.5605     86.850  0.0647    97.750  1218.31
  61   0.5464     87.080  0.0623    97.896  1238.59
  62   0.5461     87.180  0.0597    97.902  1258.84
  63   0.6112     86.110  0.0573    98.020  1279.08
  64   0.5618     87.290  0.0554    98.066  1299.39
  65   0.5279     87.500  0.0578    98.016  1319.73
  66   0.5573     87.110  0.0536    98.142  1340.04
  67   0.5428     88.020  0.0524    98.268  1360.30
  68   0.6606     85.500  0.0560    98.028  1380.59
  69   0.5432     87.420  0.0529    98.182  1400.83
  70   0.5624     87.350  0.0464    98.412  1421.11
  71   0.5560     87.350  0.0565    98.072  1441.34
  72   0.5703     87.530  0.0472    98.408  1461.67
  73   0.5522     87.720  0.0486    98.354  1481.95
  74   0.5332     87.960  0.0419    98.604  1502.22
  75   0.6177     86.800  0.0518    98.192  1522.46
  76   0.5641     87.250  0.0461    98.354  1542.75
  77   0.5678     87.150  0.0474    98.378  1563.02
  78   0.6205     86.620  0.0479    98.274  1583.29
  79   0.6210     86.520  0.0414    98.592  1603.56
  80   0.5196     88.700  0.0444    98.518  1623.78
  81   0.5601     87.560  0.0407    98.608  1644.03
  82   0.5728     87.400  0.0397    98.642  1664.37
  83   0.5439     87.490  0.0443    98.498  1684.68
  84   0.5769     87.670  0.0370    98.708  1704.97
  85   0.5970     87.650  0.0412    98.530  1725.29
