Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4038     49.060  1.5799    41.504  22.08
   2   1.1859     57.670  1.2011    56.490  42.34
   3   1.0661     62.790  1.0307    63.222  62.59
   4   0.9485     66.210  0.9067    67.580  82.91
   5   0.8114     71.080  0.8165    70.882  103.19
   6   0.7832     72.760  0.7346    73.908  123.44
   7   0.7136     75.110  0.6780    76.012  143.68
   8   0.6502     77.480  0.6123    78.486  163.90
   9   0.6683     77.110  0.5799    79.840  184.18
  10   0.6226     78.540  0.5371    81.340  204.48
  11   0.6136     79.200  0.5079    82.242  224.72
  12   0.5806     80.280  0.4740    83.390  244.93
  13   0.5772     79.970  0.4471    84.488  265.14
  14   0.5450     81.640  0.4247    85.098  285.39
  15   0.5182     82.110  0.4049    85.954  305.64
  16   0.5267     82.850  0.3838    86.654  325.91
  17   0.5191     82.450  0.3661    87.346  346.18
  18   0.6327     79.270  0.3482    88.070  366.43
  19   0.5529     82.370  0.3281    88.686  386.65
  20   0.5350     82.280  0.3187    88.944  406.87
  21   0.4768     84.230  0.2994    89.562  427.10
  22   0.5138     83.440  0.2842    90.096  447.38
  23   0.5448     83.190  0.2751    90.448  467.63
  24   0.5425     83.100  0.2602    90.882  487.91
  25   0.5338     83.660  0.2485    91.384  508.14
  26   0.5299     83.490  0.2424    91.602  528.38
  27   0.5017     84.260  0.2257    92.064  548.64
  28   0.5393     83.780  0.2178    92.418  568.90
  29   0.5535     83.720  0.2060    92.874  589.14
  30   0.5159     84.350  0.2003    92.932  609.40
  31   0.4729     85.140  0.1948    93.228  629.59
  32   0.4806     85.320  0.1821    93.616  649.84
  33   0.4907     84.790  0.1771    93.804  670.09
  34   0.4733     85.810  0.1714    93.972  690.32
  35   0.4366     86.610  0.1630    94.328  710.54
  36   0.5978     82.700  0.1598    94.452  730.83
  37   0.4662     85.880  0.1512    94.818  751.04
  38   0.5625     84.270  0.1460    94.982  771.28
  39   0.5712     83.820  0.1422    95.078  791.57
  40   0.4810     85.800  0.1351    95.406  811.80
  41   0.5012     85.750  0.1272    95.518  831.99
  42   0.5220     85.240  0.1274    95.518  852.27
  43   0.4859     85.730  0.1216    95.852  872.49
  44   0.5158     85.610  0.1168    96.046  892.76
  45   0.4771     86.740  0.1122    96.198  912.98
  46   0.4970     85.650  0.1140    95.978  933.25
  47   0.5220     86.030  0.1071    96.294  953.51
  48   0.4572     87.330  0.1006    96.594  973.75
  49   0.4960     86.860  0.1029    96.424  993.93
  50   0.5435     85.990  0.0961    96.762  1014.21
  51   0.5037     85.920  0.0959    96.722  1034.47
  52   0.4978     86.570  0.0936    96.842  1054.69
  53   0.4964     86.340  0.0918    96.846  1074.93
  54   0.4875     86.650  0.0899    96.912  1095.14
  55   0.5095     86.610  0.0849    97.140  1115.36
  56   0.5128     86.330  0.0851    97.072  1135.56
  57   0.4962     87.010  0.0794    97.314  1155.85
  58   0.5513     85.860  0.0801    97.204  1176.09
  59   0.4824     87.150  0.0818    97.156  1196.36
  60   0.4645     87.230  0.0791    97.304  1216.59
  61   0.5356     85.720  0.0750    97.436  1236.81
  62   0.4741     87.470  0.0747    97.582  1257.03
  63   0.4595     87.480  0.0755    97.522  1277.27
  64   0.5065     86.760  0.0710    97.590  1297.48
  65   0.4966     87.110  0.0702    97.536  1317.68
  66   0.4722     87.580  0.0694    97.700  1337.91
  67   0.5251     86.580  0.0675    97.702  1358.15
  68   0.5282     86.170  0.0679    97.678  1378.36
  69   0.5442     86.190  0.0673    97.700  1398.59
  70   0.4767     87.650  0.0672    97.690  1418.81
  71   0.5076     86.620  0.0608    97.978  1439.03
  72   0.4794     87.540  0.0623    97.892  1459.28
  73   0.4890     87.180  0.0611    98.016  1479.49
  74   0.4591     87.960  0.0605    97.994  1499.71
  75   0.5242     86.580  0.0613    97.954  1519.91
  76   0.4981     88.020  0.0609    97.926  1540.15
  77   0.5224     87.130  0.0522    98.282  1560.44
  78   0.5073     87.500  0.0622    97.884  1580.67
  79   0.4995     87.970  0.0564    98.118  1600.94
  80   0.4824     87.200  0.0566    98.084  1621.14
  81   0.4881     87.770  0.0588    98.086  1641.43
  82   0.4888     87.920  0.0569    98.128  1661.72
  83   0.5296     86.780  0.0554    98.160  1681.99
  84   0.5564     86.860  0.0527    98.258  1702.23
  85   0.5144     87.430  0.0551    98.160  1722.47
  86   0.4629     88.460  0.0525    98.274  1742.69
  87   0.4282     88.850  0.0541    98.214  1762.92
  88   0.4630     88.130  0.0512    98.308  1783.22
  89   0.4644     88.600  0.0530    98.248  1803.47
  90   0.5152     87.540  0.0466    98.448  1823.74
