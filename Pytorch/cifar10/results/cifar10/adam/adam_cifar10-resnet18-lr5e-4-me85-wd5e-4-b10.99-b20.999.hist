Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2574     54.260  1.5045    44.516  22.17
   2   1.0200     63.560  1.0981    60.496  42.49
   3   0.8966     68.130  0.9079    67.694  62.78
   4   0.7981     71.920  0.7643    72.696  83.10
   5   0.7496     74.620  0.6785    76.348  103.37
   6   0.6550     77.530  0.6044    79.006  123.70
   7   0.6321     79.300  0.5480    81.046  143.99
   8   0.5855     80.310  0.4936    83.092  164.30
   9   0.5164     82.500  0.4678    83.828  184.57
  10   0.4898     83.550  0.4372    85.082  204.93
  11   0.5122     83.280  0.4131    85.864  225.27
  12   0.5860     80.890  0.3841    86.848  245.58
  13   0.4546     85.490  0.3593    87.718  265.86
  14   0.4707     84.820  0.3401    88.394  286.15
  15   0.4421     85.160  0.3280    88.880  306.41
  16   0.4248     86.260  0.3132    89.312  326.69
  17   0.4241     86.450  0.3021    89.782  346.96
  18   0.3780     87.830  0.2879    90.254  367.24
  19   0.3860     87.160  0.2748    90.612  387.55
  20   0.4230     86.460  0.2695    90.812  407.88
  21   0.3857     87.740  0.2540    91.362  428.14
  22   0.3626     88.260  0.2393    91.844  448.43
  23   0.3927     87.620  0.2398    91.876  468.73
  24   0.3627     88.240  0.2323    91.956  489.02
  25   0.3769     88.530  0.2280    92.212  509.33
  26   0.4001     87.270  0.2177    92.554  529.59
  27   0.3513     89.310  0.2054    92.998  549.93
  28   0.3516     89.180  0.1949    93.454  570.25
  29   0.4066     87.830  0.1894    93.526  590.54
  30   0.3367     89.310  0.1813    93.746  610.80
  31   0.3843     88.390  0.1788    93.892  631.07
  32   0.3148     90.050  0.1831    93.770  651.34
  33   0.3423     89.520  0.1765    93.948  671.64
  34   0.3359     90.180  0.1721    94.284  691.93
  35   0.3442     89.710  0.1728    94.144  712.24
  36   0.3249     90.270  0.1550    94.686  732.52
  37   0.3478     89.490  0.1599    94.558  752.83
  38   0.3928     88.630  0.1548    94.702  773.11
  39   0.3393     90.180  0.1426    95.200  793.34
  40   0.3794     89.040  0.1440    95.148  813.60
  41   0.3369     89.750  0.1449    95.108  833.82
  42   0.3289     90.640  0.1331    95.476  854.10
  43   0.3170     90.240  0.1409    95.210  874.41
  44   0.3529     90.110  0.1363    95.356  894.67
  45   0.3564     89.640  0.1303    95.616  914.90
  46   0.3341     90.280  0.1312    95.422  935.14
  47   0.3504     89.570  0.1329    95.442  955.39
  48   0.3742     89.400  0.1296    95.656  975.66
  49   0.3450     90.000  0.1248    95.858  995.94
  50   0.3367     90.650  0.1227    95.876  1016.15
  51   0.3071     90.630  0.1217    95.802  1036.39
  52   0.3537     90.010  0.1187    95.984  1056.66
  53   0.3628     90.350  0.1169    96.044  1076.94
  54   0.3323     90.410  0.1191    95.886  1097.24
  55   0.3550     90.170  0.1191    95.948  1117.54
  56   0.3572     90.210  0.1060    96.358  1137.80
  57   0.3334     91.150  0.1105    96.186  1158.05
  58   0.3372     90.870  0.1076    96.422  1178.33
  59   0.3514     90.240  0.1113    96.192  1198.59
  60   0.3517     90.330  0.1105    96.312  1218.88
  61   0.3472     90.660  0.1103    96.194  1239.18
  62   0.3802     89.780  0.1047    96.506  1259.46
  63   0.3602     89.850  0.1001    96.654  1279.68
  64   0.3495     90.410  0.1023    96.478  1299.91
  65   0.3330     90.850  0.1005    96.610  1320.14
  66   0.3503     90.480  0.1059    96.408  1340.40
  67   0.3281     90.950  0.1004    96.580  1360.70
  68   0.3680     89.980  0.0997    96.638  1380.96
  69   0.3438     90.490  0.1035    96.514  1401.25
  70   0.3493     90.630  0.0995    96.598  1421.51
  71   0.3714     90.390  0.1021    96.570  1441.73
  72   0.3161     91.150  0.1059    96.498  1462.00
  73   0.3394     90.650  0.0919    96.814  1482.24
  74   0.3540     90.390  0.0933    96.796  1502.55
  75   0.3617     90.530  0.0934    96.790  1522.89
  76   0.3378     90.710  0.0967    96.674  1543.20
  77   0.3358     90.550  0.1038    96.568  1563.50
  78   0.3437     90.540  0.1007    96.558  1583.78
  79   0.3463     91.130  0.0886    96.964  1604.04
  80   0.3541     90.320  0.0868    97.124  1624.27
  81   0.3456     90.790  0.0906    96.968  1644.56
  82   0.3653     90.470  0.0923    96.896  1664.81
  83   0.3419     90.880  0.0979    96.772  1685.10
  84   0.3568     90.580  0.0907    96.962  1705.38
  85   0.3551     90.820  0.0924    96.928  1725.63
