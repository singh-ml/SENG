Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2906     58.240  1.3724    49.898  22.05
   2   1.0308     67.250  0.9171    67.442  42.25
   3   0.8477     71.110  0.7346    74.274  62.50
   4   0.6519     77.440  0.6297    78.244  82.75
   5   0.8074     73.640  0.5540    80.816  102.95
   6   0.7112     77.360  0.5026    82.842  123.23
   7   0.6245     79.770  0.4652    84.122  143.52
   8   0.6335     78.700  0.4292    85.168  163.75
   9   0.6171     80.350  0.3929    86.650  183.97
  10   0.5384     82.120  0.3732    87.266  204.28
  11   0.5119     83.280  0.3512    87.980  224.52
  12   0.6013     80.270  0.3320    88.486  244.74
  13   0.4925     83.630  0.3216    88.826  266.70
  14   0.4221     86.160  0.3006    89.600  286.97
  15   0.5548     82.970  0.2859    90.172  307.22
  16   0.4400     85.940  0.2738    90.548  327.44
  17   0.4226     86.420  0.2626    91.026  347.70
  18   0.4689     85.180  0.2531    91.194  367.95
  19   0.4186     86.830  0.2470    91.452  388.17
  20   0.3934     87.890  0.2345    92.016  408.39
  21   0.4833     84.550  0.2288    92.182  428.59
  22   0.3723     87.830  0.2230    92.398  448.78
  23   0.3895     88.250  0.2139    92.712  469.06
  24   0.3822     88.230  0.2107    92.628  489.32
  25   0.4443     86.790  0.2020    93.038  509.53
  26   0.4308     87.050  0.1963    93.248  529.75
  27   0.3557     88.720  0.1966    93.238  549.97
  28   0.3865     88.270  0.1866    93.562  570.20
  29   0.3961     87.830  0.1807    93.808  590.48
  30   0.4534     86.750  0.1752    93.928  610.76
  31   0.3737     89.640  0.1772    93.840  631.04
  32   0.3924     88.310  0.1667    94.278  651.25
  33   0.3792     88.820  0.1652    94.236  671.49
  34   0.4051     87.660  0.1662    94.264  691.68
  35   0.3749     89.130  0.1611    94.484  711.93
  36   0.4028     88.490  0.1561    94.716  732.17
  37   0.3644     89.100  0.1541    94.646  752.39
  38   0.3926     88.580  0.1570    94.566  772.60
  39   0.4159     88.000  0.1561    94.592  792.82
  40   0.4474     87.370  0.1467    94.950  813.04
  41   0.4098     88.360  0.1471    94.888  833.24
  42   0.4206     88.510  0.1462    94.944  853.44
  43   0.4244     88.240  0.1428    95.018  873.65
  44   0.3862     89.470  0.1415    95.058  893.86
  45   0.3756     89.520  0.1378    95.312  914.10
  46   0.4095     87.980  0.1417    95.034  934.34
  47   0.4061     88.310  0.1360    95.234  954.55
  48   0.3981     88.990  0.1347    95.414  974.76
  49   0.3643     90.170  0.1330    95.536  995.00
  50   0.3442     90.100  0.1312    95.456  1015.24
  51   0.4511     87.620  0.1294    95.536  1035.57
  52   0.3789     88.830  0.1330    95.342  1055.82
  53   0.3239     90.220  0.1283    95.634  1076.06
  54   0.3593     89.590  0.1276    95.608  1096.27
  55   0.3539     90.290  0.1248    95.692  1116.59
  56   0.4402     87.920  0.1215    95.736  1136.79
  57   0.3804     89.280  0.1259    95.646  1157.02
  58   0.3667     90.150  0.1207    95.920  1177.26
  59   0.3644     90.150  0.1164    96.018  1197.48
  60   0.3877     89.540  0.1223    95.824  1217.75
  61   0.3611     89.870  0.1237    95.740  1237.97
  62   0.3407     89.930  0.1175    96.008  1258.21
  63   0.4635     88.180  0.1173    96.050  1278.40
  64   0.3803     89.900  0.1146    96.026  1298.60
  65   0.3504     90.210  0.1161    95.998  1318.79
  66   0.3593     89.910  0.1164    96.004  1339.03
  67   0.3833     89.360  0.1174    95.902  1359.26
  68   0.3596     90.000  0.1136    96.030  1379.54
  69   0.3612     90.280  0.1135    96.018  1399.74
  70   0.3731     90.390  0.1128    96.112  1419.93
  71   0.3336     90.860  0.1107    96.164  1440.12
  72   0.3905     89.180  0.1090    96.202  1460.38
  73   0.3902     89.580  0.1097    96.292  1480.64
  74   0.3744     89.970  0.1084    96.244  1500.82
  75   0.3334     90.590  0.1070    96.300  1521.06
  76   0.3350     90.420  0.1111    96.160  1541.24
  77   0.3915     89.450  0.1079    96.354  1561.48
  78   0.3322     90.580  0.1089    96.256  1581.71
  79   0.4006     89.740  0.1062    96.306  1601.93
  80   0.3696     90.310  0.1001    96.482  1622.21
  81   0.3403     90.560  0.1098    96.292  1642.43
  82   0.3526     90.510  0.1036    96.476  1662.70
  83   0.3784     90.080  0.1075    96.296  1682.92
  84   0.4292     89.020  0.1051    96.386  1703.12
  85   0.3801     90.080  0.1061    96.396  1723.35
