Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3010     52.790  1.5669    42.266  22.17
   2   1.0857     61.170  1.1975    56.644  42.44
   3   1.0729     62.790  1.0207    63.482  62.79
   4   0.9410     68.000  0.8956    68.148  83.01
   5   0.8008     72.270  0.7956    71.898  103.22
   6   0.7380     74.220  0.7171    74.686  123.58
   7   0.8162     72.370  0.6496    77.104  143.89
   8   0.6413     77.940  0.6070    78.668  164.14
   9   0.7442     75.170  0.5629    80.120  184.39
  10   0.5959     79.160  0.5269    81.588  204.67
  11   0.6212     79.360  0.4918    82.680  224.95
  12   0.6274     78.970  0.4684    83.548  245.23
  13   0.5878     80.260  0.4415    84.528  265.48
  14   0.5888     80.110  0.4204    85.326  285.74
  15   0.6754     77.800  0.3976    86.282  306.07
  16   0.5332     82.000  0.3761    86.754  326.36
  17   0.5498     81.970  0.3571    87.724  346.68
  18   0.5327     82.000  0.3414    88.204  366.96
  19   0.4917     83.210  0.3212    88.850  387.23
  20   0.5445     82.690  0.3077    89.178  407.51
  21   0.5221     82.700  0.2903    89.984  427.77
  22   0.5082     83.770  0.2819    90.174  448.01
  23   0.5169     83.360  0.2739    90.514  468.23
  24   0.4721     84.320  0.2558    91.276  488.46
  25   0.4927     84.690  0.2391    91.704  508.69
  26   0.5424     83.310  0.2348    91.652  528.91
  27   0.5201     84.140  0.2156    92.444  549.16
  28   0.4502     85.550  0.2147    92.558  569.37
  29   0.4968     84.660  0.2074    92.732  589.60
  30   0.4904     85.280  0.1933    93.274  609.83
  31   0.4571     85.420  0.1862    93.578  630.06
  32   0.5122     84.690  0.1762    93.862  650.32
  33   0.4890     85.040  0.1751    93.984  670.58
  34   0.4631     85.990  0.1625    94.456  690.81
  35   0.5750     82.920  0.1564    94.626  711.09
  36   0.6087     82.540  0.1547    94.674  731.34
  37   0.4591     86.040  0.1519    94.708  751.61
  38   0.4735     85.550  0.1361    95.392  771.89
  39   0.4956     85.390  0.1305    95.542  792.18
  40   0.5274     85.230  0.1329    95.430  812.48
  41   0.4922     85.760  0.1232    95.808  832.73
  42   0.4751     86.310  0.1248    95.756  853.05
  43   0.5536     85.360  0.1157    96.096  873.34
  44   0.5045     85.360  0.1090    96.268  893.61
  45   0.5400     85.180  0.1093    96.216  913.88
  46   0.5326     85.400  0.1075    96.292  934.13
  47   0.4487     87.240  0.1059    96.324  954.48
  48   0.4535     87.360  0.1008    96.522  974.74
  49   0.4927     86.080  0.0988    96.732  995.05
  50   0.5259     86.150  0.0939    96.854  1015.33
  51   0.5108     85.810  0.0938    96.862  1035.62
  52   0.4511     87.290  0.0906    96.940  1055.88
  53   0.5275     85.600  0.0899    96.944  1076.13
  54   0.4683     87.250  0.0898    97.020  1096.43
  55   0.4921     86.450  0.0812    97.204  1116.75
  56   0.5406     85.760  0.0809    97.334  1137.02
  57   0.5183     86.480  0.0799    97.286  1157.30
  58   0.4980     86.780  0.0747    97.524  1177.58
  59   0.5814     84.970  0.0759    97.456  1197.86
  60   0.5032     87.090  0.0733    97.516  1218.09
  61   0.4897     87.690  0.0742    97.456  1238.35
  62   0.4811     86.910  0.0712    97.560  1258.60
  63   0.5586     85.900  0.0716    97.560  1278.87
  64   0.5453     86.200  0.0632    97.918  1299.18
  65   0.4813     87.430  0.0685    97.702  1319.46
  66   0.4692     87.620  0.0679    97.798  1339.74
  67   0.5009     86.420  0.0711    97.582  1360.00
  68   0.5387     85.820  0.0679    97.758  1380.26
  69   0.5270     86.610  0.0634    97.856  1400.54
  70   0.4859     87.800  0.0665    97.772  1420.81
  71   0.4851     87.800  0.0617    97.916  1441.05
  72   0.4832     87.450  0.0600    98.096  1461.31
  73   0.4618     88.070  0.0659    97.680  1481.57
  74   0.4650     87.850  0.0559    98.112  1501.87
  75   0.4816     87.750  0.0597    97.994  1522.13
  76   0.4753     87.660  0.0576    98.074  1542.38
  77   0.5261     86.520  0.0571    98.036  1562.65
  78   0.4826     87.680  0.0565    98.096  1582.95
  79   0.4693     87.710  0.0596    98.010  1603.22
  80   0.4843     87.560  0.0587    98.036  1623.50
  81   0.5342     86.990  0.0522    98.372  1643.73
  82   0.4737     87.800  0.0607    97.942  1664.04
  83   0.5713     86.200  0.0522    98.296  1684.31
  84   0.4806     87.510  0.0571    98.102  1704.56
  85   0.4756     88.350  0.0522    98.258  1724.78
