Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3606     50.830  1.5675    41.910  22.30
   2   1.2692     55.940  1.1991    56.492  42.59
   3   0.9733     65.630  1.0187    63.492  62.84
   4   0.9342     66.890  0.9048    67.802  83.11
   5   0.8280     70.690  0.8012    71.722  103.38
   6   0.7891     73.160  0.7275    74.288  123.68
   7   0.6881     75.590  0.6606    76.586  143.93
   8   0.6407     77.730  0.6154    78.514  164.26
   9   0.6197     79.380  0.5661    80.232  184.54
  10   0.6121     79.230  0.5347    81.430  204.82
  11   0.5667     80.560  0.4974    82.738  225.09
  12   0.5736     80.790  0.4670    83.612  245.37
  13   0.5811     80.900  0.4419    84.610  265.64
  14   0.5678     80.730  0.4165    85.562  285.87
  15   0.5506     81.750  0.4001    86.118  306.16
  16   0.5427     82.750  0.3766    86.820  326.43
  17   0.5406     83.120  0.3578    87.504  346.73
  18   0.5060     82.960  0.3396    88.104  367.06
  19   0.5252     83.410  0.3223    88.682  387.33
  20   0.5625     82.430  0.3064    89.286  407.59
  21   0.5188     83.670  0.2953    89.660  427.87
  22   0.5168     83.360  0.2734    90.424  448.15
  23   0.5052     84.000  0.2667    90.688  468.42
  24   0.4924     84.220  0.2528    91.098  488.69
  25   0.5113     84.110  0.2368    91.614  508.98
  26   0.5308     83.660  0.2324    91.860  529.26
  27   0.5360     83.870  0.2220    92.166  549.53
  28   0.5466     83.720  0.2059    92.816  569.85
  29   0.5077     84.570  0.2005    93.070  590.20
  30   0.4840     85.290  0.1937    93.128  610.53
  31   0.5219     84.980  0.1801    93.770  630.79
  32   0.4937     85.410  0.1755    93.806  651.08
  33   0.4866     86.100  0.1604    94.374  671.39
  34   0.4950     85.810  0.1610    94.414  691.65
  35   0.5567     84.560  0.1514    94.728  711.96
  36   0.5439     84.750  0.1463    94.932  732.21
  37   0.5373     85.370  0.1371    95.160  752.48
  38   0.5222     85.850  0.1334    95.236  772.77
  39   0.5959     84.100  0.1273    95.438  792.98
  40   0.4780     86.720  0.1239    95.606  813.27
  41   0.4850     87.110  0.1193    95.782  833.56
  42   0.5222     86.410  0.1104    96.224  853.86
  43   0.5008     86.320  0.1113    96.088  874.13
  44   0.5244     85.880  0.1044    96.346  894.41
  45   0.5275     86.380  0.1060    96.222  914.70
  46   0.5059     86.700  0.0932    96.746  934.96
  47   0.5695     86.250  0.0943    96.706  955.25
  48   0.5201     86.500  0.0903    96.874  975.52
  49   0.5730     85.770  0.0889    96.996  995.75
  50   0.4857     87.400  0.0893    96.918  1015.99
  51   0.5202     86.800  0.0817    97.112  1036.26
  52   0.5923     86.330  0.0766    97.296  1056.54
  53   0.5515     86.420  0.0775    97.312  1076.78
  54   0.5457     86.420  0.0707    97.512  1097.03
  55   0.5466     86.440  0.0734    97.484  1117.32
  56   0.5094     87.730  0.0692    97.562  1137.61
  57   0.5631     87.120  0.0706    97.502  1157.91
  58   0.5313     86.690  0.0675    97.658  1178.19
  59   0.5727     87.020  0.0671    97.664  1198.44
  60   0.5486     87.390  0.0648    97.710  1218.71
  61   0.5676     86.900  0.0657    97.730  1239.01
  62   0.5705     86.990  0.0616    97.872  1259.32
  63   0.5331     87.440  0.0610    97.896  1279.62
  64   0.5607     87.380  0.0589    97.952  1299.93
  65   0.6401     86.070  0.0555    98.118  1320.27
  66   0.5176     88.190  0.0574    98.070  1340.55
  67   0.5813     87.040  0.0543    98.116  1360.78
  68   0.5617     87.460  0.0591    97.926  1381.10
  69   0.5164     88.270  0.0521    98.250  1401.33
  70   0.5337     87.830  0.0545    98.088  1421.57
  71   0.5627     87.320  0.0480    98.442  1441.86
  72   0.5901     86.830  0.0494    98.310  1462.09
  73   0.5406     87.610  0.0485    98.346  1482.36
  74   0.5450     87.900  0.0460    98.458  1502.66
  75   0.6780     85.470  0.0463    98.444  1522.94
  76   0.5329     87.380  0.0501    98.276  1543.19
  77   0.5522     87.650  0.0427    98.538  1563.48
  78   0.5881     86.810  0.0445    98.460  1583.74
  79   0.5398     88.120  0.0429    98.520  1604.01
  80   0.6221     87.140  0.0439    98.538  1624.29
  81   0.5858     87.870  0.0417    98.584  1644.55
  82   0.5662     87.860  0.0433    98.514  1664.81
  83   0.5539     88.510  0.0403    98.606  1685.06
  84   0.5972     87.420  0.0425    98.538  1705.34
  85   0.5552     87.700  0.0444    98.512  1725.62
