Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5727     44.030  1.7440    35.974  21.90
   2   1.3094     54.590  1.2910    52.780  42.15
   3   1.2956     56.530  1.0182    63.434  62.42
   4   1.0031     66.100  0.8499    69.992  82.69
   5   1.2235     61.680  0.7164    74.892  102.93
   6   0.7875     73.840  0.6370    77.956  123.20
   7   0.7593     75.410  0.5860    79.594  143.47
   8   0.6312     78.920  0.5417    81.424  163.70
   9   0.6496     78.320  0.5126    82.340  183.96
  10   0.5771     80.100  0.4877    83.262  204.20
  11   0.5614     80.970  0.4617    84.292  224.44
  12   0.5427     80.960  0.4494    84.516  244.72
  13   0.4674     84.230  0.4308    85.008  265.03
  14   0.6080     79.440  0.4178    85.736  285.30
  15   0.5771     81.460  0.4082    85.980  305.57
  16   0.5898     81.430  0.3968    86.384  325.80
  17   0.5002     83.510  0.3917    86.448  346.09
  18   0.4836     84.360  0.3896    86.520  366.33
  19   0.5443     82.770  0.3798    86.924  386.60
  20   0.5263     82.990  0.3690    87.270  406.83
  21   0.4799     84.210  0.3651    87.400  427.09
  22   0.4589     84.590  0.3623    87.492  447.31
  23   0.4985     83.690  0.3500    87.958  467.58
  24   0.4792     84.390  0.3539    87.660  487.81
  25   0.5320     82.970  0.3411    88.210  508.06
  26   0.4396     85.880  0.3436    88.234  528.31
  27   0.5066     83.110  0.3390    88.448  548.57
  28   0.4441     85.400  0.3358    88.288  568.86
  29   0.4468     84.680  0.3319    88.618  589.18
  30   0.4518     84.490  0.3287    88.728  609.42
  31   0.4781     84.290  0.3278    88.620  629.71
  32   0.4804     84.150  0.3210    88.846  649.96
  33   0.4888     84.810  0.3213    88.982  670.19
  34   0.4806     85.140  0.3167    89.114  690.43
  35   0.4552     85.160  0.3186    88.922  710.67
  36   0.5069     83.980  0.3140    89.136  730.94
  37   0.4992     84.110  0.3122    89.266  751.25
  38   0.4804     83.760  0.3107    89.240  771.58
  39   0.4458     85.920  0.3068    89.448  791.80
  40   0.4241     85.990  0.3096    89.302  812.04
  41   0.4300     86.300  0.3064    89.412  832.31
  42   0.5473     82.110  0.3033    89.430  852.55
  43   0.4680     84.880  0.3026    89.652  872.80
  44   0.4493     85.870  0.2988    89.804  893.03
  45   0.5170     83.770  0.3016    89.602  913.28
  46   0.4634     85.640  0.2942    89.664  933.56
  47   0.4419     85.690  0.2941    90.010  953.81
  48   0.4400     85.820  0.2987    89.802  974.13
  49   0.4554     85.970  0.2944    89.996  994.39
  50   0.4965     84.320  0.2942    90.006  1014.63
  51   0.4535     85.660  0.2929    89.938  1034.87
  52   0.4843     85.000  0.2892    89.918  1055.12
  53   0.5182     83.080  0.2893    90.120  1075.36
  54   0.3947     86.980  0.2868    90.190  1095.57
  55   0.5405     83.550  0.2841    90.402  1115.85
  56   0.5009     84.550  0.2840    90.156  1136.19
  57   0.4764     84.590  0.2856    90.214  1156.49
  58   0.4616     84.830  0.2838    90.198  1176.73
  59   0.4102     86.410  0.2796    90.274  1197.03
  60   0.5619     82.750  0.2828    90.208  1217.32
  61   0.5998     81.220  0.2855    90.126  1237.61
  62   0.5579     82.900  0.2793    90.218  1257.88
  63   0.3891     87.240  0.2785    90.324  1278.20
  64   0.4989     84.170  0.2834    90.174  1298.46
  65   0.4078     87.080  0.2804    90.386  1318.70
  66   0.4945     84.710  0.2743    90.540  1338.98
  67   0.4605     85.700  0.2780    90.432  1359.23
  68   0.4174     86.500  0.2739    90.500  1379.52
  69   0.6488     80.160  0.2731    90.576  1399.75
  70   0.5067     83.810  0.2813    90.192  1420.05
  71   0.4871     84.680  0.2770    90.392  1440.34
  72   0.4077     86.360  0.2738    90.368  1460.60
  73   0.5464     83.270  0.2707    90.684  1480.86
  74   0.4841     85.150  0.2730    90.520  1501.11
  75   0.6520     80.530  0.2729    90.442  1521.37
  76   0.4220     86.560  0.2744    90.486  1541.65
  77   0.5103     83.930  0.2723    90.502  1561.90
  78   0.4387     85.940  0.2700    90.684  1582.15
  79   0.4344     85.780  0.2726    90.572  1602.42
  80   0.4146     86.300  0.2729    90.598  1622.74
  81   0.5039     84.220  0.2647    90.844  1643.06
  82   0.4701     84.740  0.2717    90.518  1663.29
  83   0.4296     85.960  0.2655    90.842  1683.54
  84   0.4463     85.820  0.2682    90.712  1703.79
  85   0.5069     83.870  0.2739    90.472  1724.06
