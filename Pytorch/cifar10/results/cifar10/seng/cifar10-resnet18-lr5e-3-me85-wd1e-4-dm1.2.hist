Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7648076288 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4732     44.830  1.7548    34.624  24.60
   2   1.2171     56.060  1.3426    50.736  46.82
   3   1.0634     61.650  1.1459    58.604  69.03
   4   0.9409     66.370  0.9933    64.424  91.16
   5   0.8541     69.520  0.9024    67.906  113.34
   6   0.8075     71.750  0.8299    70.574  135.62
   7   0.7567     73.610  0.7761    72.334  157.86
   8   0.7171     74.770  0.7267    74.202  180.09
   9   0.6690     76.550  0.6695    76.378  202.28
  10   0.6503     77.350  0.6303    77.858  224.49
  11   0.6213     78.570  0.5941    79.266  246.65
  12   0.6019     79.250  0.5605    80.432  268.83
  13   0.5737     80.070  0.5301    81.648  291.04
  14   0.5684     80.640  0.5027    82.362  313.22
  15   0.5444     81.330  0.4775    83.302  335.48
  16   0.5406     81.850  0.4569    83.932  357.74
  17   0.5195     82.420  0.4393    84.612  379.95
  18   0.5116     82.520  0.4128    85.590  402.17
  19   0.5036     82.770  0.4058    85.822  424.39
  20   0.4746     83.880  0.3863    86.534  446.57
  21   0.4819     84.280  0.3696    87.200  468.77
  22   0.4667     84.300  0.3537    87.724  490.96
  23   0.4607     84.560  0.3425    87.964  513.20
  24   0.4651     84.640  0.3320    88.488  535.46
  25   0.4611     84.670  0.3163    88.970  557.68
  26   0.4626     84.810  0.3059    89.372  579.90
  27   0.4445     85.260  0.2922    89.886  602.15
  28   0.4699     85.180  0.2850    89.938  624.38
  29   0.4661     85.360  0.2773    90.270  646.64
  30   0.4652     85.070  0.2661    90.682  668.89
  31   0.4540     85.870  0.2543    91.134  691.05
  32   0.4486     86.230  0.2493    91.310  713.24
  33   0.4599     86.150  0.2341    91.790  735.46
  34   0.4583     86.170  0.2333    91.796  757.68
  35   0.4532     86.250  0.2193    92.238  779.87
  36   0.4416     86.430  0.2127    92.526  802.12
  37   0.4539     85.920  0.2035    92.918  824.38
  38   0.4561     86.240  0.2016    92.910  846.54
  39   0.4402     86.760  0.1914    93.392  868.76
  40   0.4378     86.530  0.1847    93.556  890.91
  41   0.4778     85.910  0.1764    93.768  913.07
  42   0.4438     86.840  0.1755    93.870  935.22
  43   0.4611     87.030  0.1631    94.328  957.51
  44   0.4396     87.420  0.1585    94.402  979.76
  45   0.4698     86.750  0.1512    94.682  1001.96
  46   0.4585     86.880  0.1441    94.886  1024.14
  47   0.4515     87.230  0.1402    95.066  1046.36
  48   0.4542     87.280  0.1378    95.126  1068.52
  49   0.4714     87.370  0.1320    95.402  1090.73
  50   0.4602     87.560  0.1253    95.646  1112.70
  51   0.4829     86.980  0.1221    95.710  1134.91
  52   0.4638     87.550  0.1160    95.960  1157.11
  53   0.4791     87.160  0.1094    96.200  1179.31
  54   0.4686     87.530  0.1070    96.288  1201.48
  55   0.4735     87.670  0.1021    96.460  1223.72
  56   0.4735     87.920  0.0984    96.640  1245.90
  57   0.4823     87.340  0.0938    96.732  1268.05
  58   0.4954     87.220  0.0925    96.834  1290.23
  59   0.4885     87.570  0.0881    96.930  1312.36
  60   0.4984     87.410  0.0851    97.048  1334.57
  61   0.5152     87.070  0.0822    97.186  1356.73
  62   0.4960     87.990  0.0801    97.188  1378.92
  63   0.4940     87.650  0.0757    97.402  1401.11
  64   0.4944     88.020  0.0733    97.616  1423.27
  65   0.5138     87.520  0.0714    97.554  1445.51
  66   0.5142     87.760  0.0661    97.852  1467.68
  67   0.4961     87.990  0.0654    97.750  1489.89
  68   0.5083     87.830  0.0637    97.850  1512.09
  69   0.5115     87.940  0.0607    97.926  1534.27
  70   0.5051     87.990  0.0579    98.042  1556.52
  71   0.5127     87.920  0.0562    98.162  1578.65
  72   0.5167     87.780  0.0564    98.152  1600.88
  73   0.5110     88.140  0.0518    98.348  1623.08
  74   0.5155     88.260  0.0518    98.312  1645.31
  75   0.5079     88.200  0.0503    98.326  1667.51
  76   0.5201     88.050  0.0469    98.496  1689.67
  77   0.5174     88.150  0.0486    98.428  1711.84
  78   0.5355     87.720  0.0459    98.556  1734.12
  79   0.5317     87.860  0.0472    98.474  1756.27
  80   0.5211     88.200  0.0436    98.618  1778.48
  81   0.5216     88.060  0.0432    98.582  1800.68
  82   0.5295     88.090  0.0415    98.686  1822.88
  83   0.5307     88.110  0.0416    98.672  1845.08
  84   0.5229     88.180  0.0407    98.658  1867.26
  85   0.5379     88.010  0.0382    98.770  1889.45
