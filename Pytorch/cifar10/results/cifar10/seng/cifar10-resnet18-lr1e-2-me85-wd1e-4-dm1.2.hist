Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.2', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7648076288 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3324     51.040  1.6619    38.104  24.18
   2   1.0385     62.780  1.2015    56.330  46.31
   3   0.8955     68.320  0.9711    65.342  68.50
   4   0.7657     72.930  0.8270    70.614  90.68
   5   0.7031     75.640  0.7215    74.578  112.90
   6   0.6749     76.980  0.6473    77.304  135.03
   7   0.6191     78.470  0.6004    78.792  157.16
   8   0.5787     80.150  0.5457    81.016  179.34
   9   0.5883     80.310  0.5085    82.322  201.66
  10   0.5202     82.200  0.4730    83.514  223.87
  11   0.4896     83.340  0.4477    84.506  246.09
  12   0.4617     84.560  0.4150    85.460  268.32
  13   0.5481     82.340  0.3926    86.290  290.54
  14   0.4759     83.990  0.3763    86.910  312.74
  15   0.4597     84.740  0.3548    87.692  334.95
  16   0.4417     85.360  0.3335    88.296  357.16
  17   0.4449     85.860  0.3160    88.938  379.34
  18   0.4483     85.460  0.3024    89.388  401.51
  19   0.4210     86.460  0.2907    89.702  423.75
  20   0.4416     85.470  0.2728    90.460  445.97
  21   0.4342     86.170  0.2633    90.844  468.25
  22   0.4338     86.080  0.2523    91.160  490.45
  23   0.4154     86.940  0.2368    91.728  512.69
  24   0.4219     86.660  0.2231    92.084  534.83
  25   0.4364     86.590  0.2130    92.564  557.02
  26   0.4205     86.970  0.2025    92.952  579.23
  27   0.4156     87.250  0.1948    93.128  601.44
  28   0.4472     86.950  0.1821    93.576  623.62
  29   0.4197     87.780  0.1788    93.726  645.83
  30   0.4132     87.770  0.1636    94.240  668.02
  31   0.4583     86.730  0.1566    94.554  690.19
  32   0.4053     88.130  0.1504    94.694  712.37
  33   0.4312     87.920  0.1422    95.012  734.56
  34   0.4425     87.590  0.1357    95.334  756.76
  35   0.4321     87.770  0.1328    95.222  778.91
  36   0.4288     88.580  0.1215    95.660  801.08
  37   0.4152     88.820  0.1143    96.066  823.34
  38   0.4526     88.060  0.1084    96.142  845.50
  39   0.4567     88.000  0.1036    96.350  867.69
  40   0.4342     88.570  0.0977    96.592  889.93
  41   0.4537     88.440  0.0944    96.694  912.14
  42   0.4276     89.140  0.0828    97.132  934.33
  43   0.4255     88.780  0.0770    97.318  956.55
  44   0.4591     88.670  0.0766    97.276  978.80
  45   0.4506     88.740  0.0762    97.312  1000.99
  46   0.4599     88.510  0.0666    97.704  1023.14
  47   0.4705     88.600  0.0649    97.784  1045.30
  48   0.4620     89.040  0.0580    97.998  1067.48
  49   0.4751     89.020  0.0565    98.098  1089.69
  50   0.4537     89.130  0.0516    98.252  1111.66
  51   0.4497     89.520  0.0459    98.480  1133.81
  52   0.4705     89.090  0.0455    98.470  1155.94
  53   0.4756     88.880  0.0414    98.618  1178.15
  54   0.4809     89.360  0.0405    98.712  1200.36
  55   0.4825     89.120  0.0388    98.724  1222.56
  56   0.4726     89.580  0.0350    98.868  1244.77
  57   0.4732     89.110  0.0332    98.856  1266.91
  58   0.4692     89.580  0.0325    98.934  1289.13
  59   0.4736     89.360  0.0279    99.132  1311.35
  60   0.4715     89.770  0.0284    99.104  1333.59
  61   0.5016     89.390  0.0249    99.242  1355.86
  62   0.4868     89.510  0.0247    99.222  1378.08
  63   0.4803     89.700  0.0218    99.378  1400.28
  64   0.4725     89.660  0.0215    99.354  1422.48
  65   0.4726     90.110  0.0206    99.398  1444.68
  66   0.4807     89.760  0.0185    99.484  1466.84
  67   0.4829     89.860  0.0185    99.472  1489.09
  68   0.4815     89.960  0.0183    99.470  1511.29
  69   0.4808     89.990  0.0163    99.548  1533.49
  70   0.4816     89.870  0.0157    99.592  1555.64
  71   0.4848     89.900  0.0141    99.662  1577.85
  72   0.4934     90.160  0.0148    99.610  1600.10
  73   0.4851     90.000  0.0137    99.650  1622.33
  74   0.4778     90.230  0.0128    99.718  1644.50
  75   0.4846     90.060  0.0135    99.674  1666.73
  76   0.4967     90.060  0.0120    99.716  1688.90
  77   0.4959     90.220  0.0118    99.730  1711.13
  78   0.4923     89.880  0.0124    99.696  1733.33
  79   0.4870     90.030  0.0120    99.686  1755.51
  80   0.4883     89.880  0.0108    99.738  1777.67
  81   0.4907     90.040  0.0111    99.728  1799.90
  82   0.4923     89.990  0.0111    99.720  1822.03
  83   0.4902     90.070  0.0107    99.758  1844.25
  84   0.4930     90.060  0.0101    99.790  1866.38
  85   0.4921     90.310  0.0094    99.792  1888.54
