Use GPU: 0 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '1.0', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '0']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7648076288 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4395     45.510  1.7398    35.228  24.75
   2   1.1838     56.790  1.3155    51.860  46.91
   3   1.0112     63.550  1.1095    60.060  69.11
   4   0.9060     67.780  0.9615    65.540  91.37
   5   0.8058     71.310  0.8647    69.138  113.60
   6   0.7690     72.860  0.7847    72.082  135.84
   7   0.7142     75.110  0.7150    74.594  158.12
   8   0.6641     76.840  0.6545    76.906  180.31
   9   0.6484     77.410  0.6139    78.262  202.48
  10   0.5933     79.860  0.5697    80.212  224.73
  11   0.5783     80.240  0.5331    81.222  246.91
  12   0.5695     81.000  0.5049    82.336  269.09
  13   0.5380     81.640  0.4684    83.588  291.26
  14   0.5324     82.540  0.4459    84.390  313.51
  15   0.5198     82.390  0.4325    85.004  335.68
  16   0.5029     83.020  0.4072    85.856  357.83
  17   0.4999     83.220  0.3910    86.424  380.05
  18   0.4915     83.880  0.3692    87.218  402.24
  19   0.4825     84.250  0.3582    87.414  424.38
  20   0.4926     84.420  0.3445    88.016  446.58
  21   0.4673     84.950  0.3271    88.624  468.83
  22   0.4622     84.840  0.3112    89.134  491.03
  23   0.4488     85.470  0.2986    89.556  513.25
  24   0.4496     85.870  0.2893    89.978  535.40
  25   0.4588     85.620  0.2761    90.306  557.63
  26   0.4379     85.900  0.2638    90.828  579.82
  27   0.4848     85.200  0.2549    91.192  601.99
  28   0.4518     85.890  0.2480    91.378  624.21
  29   0.4344     86.340  0.2359    91.896  646.37
  30   0.4361     86.490  0.2280    92.052  668.55
  31   0.4371     86.610  0.2169    92.384  690.79
  32   0.4342     86.730  0.2068    92.870  712.98
  33   0.4478     86.600  0.2012    92.922  735.14
  34   0.4464     86.520  0.1969    92.954  757.34
  35   0.4553     86.770  0.1900    93.312  779.48
  36   0.4544     87.110  0.1801    93.686  801.67
  37   0.4498     86.850  0.1712    94.002  823.87
  38   0.4402     87.520  0.1630    94.330  846.07
  39   0.4370     87.260  0.1573    94.586  868.27
  40   0.4563     86.910  0.1514    94.678  890.40
  41   0.4382     87.320  0.1409    95.036  912.61
  42   0.4471     87.390  0.1383    95.134  934.83
  43   0.4753     87.090  0.1285    95.486  957.02
  44   0.4621     87.420  0.1292    95.494  979.31
  45   0.4828     87.030  0.1186    95.790  1001.59
  46   0.4649     87.720  0.1175    95.928  1023.81
  47   0.4963     87.330  0.1113    96.058  1046.00
  48   0.4758     87.550  0.1038    96.372  1068.21
  49   0.4568     87.770  0.1009    96.500  1090.41
  50   0.4647     88.110  0.0983    96.488  1112.42
  51   0.4703     88.100  0.0959    96.624  1134.67
  52   0.4612     88.010  0.0894    96.816  1156.90
  53   0.4878     87.670  0.0839    97.080  1179.15
  54   0.4826     88.190  0.0806    97.202  1201.43
  55   0.4640     88.490  0.0741    97.478  1223.61
  56   0.4887     88.070  0.0727    97.504  1245.77
  57   0.5067     88.030  0.0700    97.650  1267.96
  58   0.4923     88.610  0.0706    97.508  1290.13
  59   0.5000     88.140  0.0640    97.752  1312.29
  60   0.4887     88.380  0.0629    97.860  1334.50
  61   0.4986     88.690  0.0610    97.900  1356.67
  62   0.5069     88.310  0.0525    98.178  1378.88
  63   0.4977     88.740  0.0542    98.124  1401.13
  64   0.4922     88.720  0.0509    98.288  1423.31
  65   0.5208     88.540  0.0484    98.422  1445.46
  66   0.4931     88.940  0.0473    98.446  1467.66
  67   0.4934     88.730  0.0445    98.564  1489.84
  68   0.4977     88.940  0.0433    98.616  1512.09
  69   0.5065     88.700  0.0419    98.598  1534.26
  70   0.5180     88.510  0.0386    98.828  1556.46
  71   0.5159     88.710  0.0378    98.796  1578.63
  72   0.5055     88.810  0.0356    98.854  1600.76
  73   0.5189     88.770  0.0344    98.914  1623.00
  74   0.5161     88.930  0.0350    98.894  1645.22
  75   0.5147     88.880  0.0321    99.014  1667.44
  76   0.5268     88.720  0.0309    99.018  1689.75
  77   0.5282     88.970  0.0297    99.106  1711.91
  78   0.5403     88.750  0.0304    99.040  1734.09
  79   0.5287     89.020  0.0296    99.080  1756.29
  80   0.5354     88.900  0.0298    99.074  1778.53
  81   0.5270     89.010  0.0282    99.118  1800.74
  82   0.5349     89.060  0.0293    99.126  1822.93
  83   0.5321     88.880  0.0291    99.076  1845.10
  84   0.5335     88.940  0.0266    99.218  1867.32
  85   0.5340     88.810  0.0262    99.198  1889.51
