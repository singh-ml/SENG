Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6866      1.060  10.9701     1.072  24.10
   2   4.6868      1.010  10.9703     1.074  46.32
   3   4.6874      1.100  10.9688     1.068  68.50
   4   4.6870      1.050  10.9680     1.108  90.51
   5   4.6851      1.030  10.9692     1.066  112.39
   6   4.6862      1.070  10.9693     1.098  134.29
   7   4.6882      1.090  10.9689     1.008  156.20
   8   4.6855      1.070  10.9689     1.016  177.99
   9   4.6878      1.090  10.9695     1.110  200.04
  10   4.6880      1.110  10.9693     1.118  221.96
  11   4.6879      1.110  10.9703     1.112  243.74
  12   4.6864      1.080  10.9698     1.074  265.66
  13   4.6870      1.080  10.9699     1.154  287.48
  14   4.6868      1.040  10.9695     1.102  309.28
  15   4.6869      1.080  10.9695     1.140  331.39
  16   4.6863      1.060  10.9700     1.036  353.22
  17   4.6865      1.080  10.9689     1.060  375.05
  18   4.6875      1.120  10.9700     1.046  396.96
  19   4.6869      1.090  10.9695     1.064  418.85
  20   4.6893      1.110  10.9699     1.142  440.87
  21   4.6856      1.010  10.9691     1.068  462.70
  22   4.6848      1.010  10.9699     1.128  484.63
  23   4.6897      1.130  10.9691     1.092  506.67
  24   4.6872      1.030  10.9685     1.058  528.60
  25   4.6839      0.990  10.9692     1.122  550.59
  26   4.6880      1.110  10.9686     1.140  572.45
  27   4.6863      1.020  10.9697     1.110  594.48
  28   4.6887      1.090  10.9686     1.166  616.45
  29   4.6869      1.040  10.9702     1.096  638.38
  30   4.6861      1.070  10.9689     1.192  660.30
  31   4.6907      1.130  10.9696     1.056  682.35
  32   4.6881      1.110  10.9697     1.068  704.20
  33   4.6854      1.100  10.9698     1.066  726.01
  34   4.6863      1.090  10.9688     1.118  747.90
  35   4.6871      1.030  10.9690     1.146  769.72
  36   4.6870      1.060  10.9687     1.114  791.52
  37   4.6882      1.110  10.9702     1.124  813.50
  38   4.6868      1.040  10.9700     1.062  835.28
  39   4.6880      1.040  10.9684     1.064  857.35
  40   4.6861      1.050  10.9696     1.100  879.31
  41   4.6872      1.070  10.9685     1.082  901.11
  42   4.6874      1.040  10.9702     1.056  923.08
  43   4.6881      1.080  10.9693     1.056  944.95
  44   4.6867      1.020  10.9684     1.106  966.84
  45   4.6877      1.090  10.9692     1.106  988.92
  46   4.6882      1.120  10.9692     1.080  1011.03
  47   4.6863      1.090  10.9702     1.060  1032.77
  48   4.6862      1.020  10.9689     1.040  1054.86
  49   4.6856      1.030  10.9682     1.062  1076.73
  50   4.6861      1.060  10.9685     1.100  1098.62
  51   4.6874      1.110  10.9688     1.062  1120.50
  52   4.6860      1.000  10.9699     1.072  1142.42
  53   4.6874      1.100  10.9693     1.142  1164.23
  54   4.6876      1.060  10.9710     1.074  1186.42
  55   4.6854      1.080  10.9697     1.078  1208.30
  56   4.6871      1.080  10.9685     1.108  1230.09
  57   4.6867      0.990  10.9696     1.112  1252.20
  58   4.6858      1.050  10.9691     1.174  1274.10
  59   4.6880      1.080  10.9676     1.116  1295.99
  60   4.6878      1.080  10.9685     1.064  1317.83
  61   4.6860      1.070  10.9694     1.088  1339.54
  62   4.6873      1.050  10.9688     1.100  1361.32
  63   4.6850      1.020  10.9700     1.118  1383.24
  64   4.6873      1.110  10.9687     1.090  1405.09
  65   4.6872      1.080  10.9697     1.100  1426.98
  66   4.6889      1.090  10.9697     1.062  1448.85
  67   4.6893      1.110  10.9686     1.106  1470.89
  68   4.6870      1.070  10.9693     1.156  1492.71
  69   4.6874      1.110  10.9708     1.098  1514.54
  70   4.6881      1.090  10.9699     1.074  1536.55
  71   4.6887      1.100  10.9699     1.048  1558.43
  72   4.6878      1.070  10.9686     1.128  1580.44
  73   4.6870      1.050  10.9698     1.022  1602.59
  74   4.6870      1.100  10.9688     1.128  1624.49
  75   4.6873      1.040  10.9687     1.114  1646.40
  76   4.6857      1.060  10.9685     1.096  1668.16
  77   4.6867      1.070  10.9689     1.026  1690.01
  78   4.6843      1.050  10.9701     1.120  1711.75
  79   4.6900      1.150  10.9689     1.040  1733.73
  80   4.6871      1.090  10.9701     1.064  1755.56
  81   4.6863      1.090  10.9696     1.104  1777.47
  82   4.6878      1.080  10.9689     1.156  1799.37
  83   4.6859      1.080  10.9695     1.040  1821.32
  84   4.6875      1.070  10.9689     1.100  1843.34
  85   4.6874      1.100  10.9690     1.148  1865.36
