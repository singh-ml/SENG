Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '5e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 5793912832 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7282      0.850  5.9930     1.032  28.31
   2   4.7297      0.800  5.9924     1.048  56.18
   3   4.7304      0.840  5.9915     1.024  83.88
   4   4.7329      0.800  5.9919     1.014  111.38
   5   4.7321      0.830  5.9925     1.042  139.07
   6   4.7327      0.740  5.9922     0.956  166.91
   7   4.7271      0.780  5.9917     1.006  194.44
   8   4.7340      0.800  5.9929     1.006  221.62
   9   4.7360      0.780  5.9922     1.028  248.66
  10   4.7278      0.820  5.9931     1.016  275.08
  11   4.7321      0.780  5.9925     1.058  302.10
  12   4.7289      0.830  5.9929     1.008  329.11
  13   4.7295      0.810  5.9925     1.026  356.36
  14   4.7316      0.820  5.9918     1.044  383.23
  15   4.7306      0.830  5.9926     0.978  410.67
  16   4.7323      0.850  5.9925     0.986  438.00
  17   4.7293      0.810  5.9914     1.064  465.50
  18   4.7311      0.810  5.9921     1.046  492.34
  19   4.7271      0.790  5.9919     1.058  519.46
  20   4.7293      0.810  5.9919     1.006  546.91
  21   4.7344      0.830  5.9914     0.964  574.38
  22   4.7279      0.860  5.9934     0.952  601.70
  23   4.7311      0.810  5.9918     1.070  629.40
  24   4.7312      0.780  5.9922     1.026  656.33
  25   4.7281      0.790  5.9930     1.050  684.40
  26   4.7260      0.860  5.9919     1.024  711.45
  27   4.7280      0.830  5.9934     0.972  739.02
  28   4.7274      0.830  5.9926     1.000  766.52
  29   4.7328      0.860  5.9912     0.936  793.50
  30   4.7290      0.820  5.9923     1.022  821.22
  31   4.7298      0.820  5.9921     1.072  848.72
  32   4.7289      0.830  5.9933     0.996  875.96
  33   4.7331      0.830  5.9925     0.956  903.82
  34   4.7315      0.840  5.9929     0.998  931.73
  35   4.7300      0.840  5.9937     1.004  958.49
  36   4.7352      0.790  5.9929     1.022  985.61
  37   4.7310      0.820  5.9918     0.960  1012.66
  38   4.7333      0.800  5.9916     1.050  1040.42
  39   4.7285      0.810  5.9919     0.942  1067.76
  40   4.7337      0.790  5.9929     1.014  1094.91
  41   4.7321      0.820  5.9929     1.006  1122.18
  42   4.7319      0.780  5.9921     1.052  1148.85
  43   4.7318      0.810  5.9929     0.988  1176.17
  44   4.7334      0.760  5.9926     1.004  1203.38
  45   4.7301      0.810  5.9928     1.038  1230.98
  46   4.7316      0.820  5.9918     0.998  1258.33
  47   4.7353      0.810  5.9915     1.070  1285.29
  48   4.7339      0.800  5.9928     0.994  1312.66
  49   4.7259      0.810  5.9916     1.018  1340.15
  50   4.7349      0.760  5.9934     1.040  1367.58
  51   4.7338      0.800  5.9926     1.044  1395.01
  52   4.7304      0.750  5.9924     1.054  1422.08
  53   4.7317      0.790  5.9919     1.018  1449.28
  54   4.7316      0.820  5.9925     0.990  1476.38
  55   4.7260      0.830  5.9926     1.072  1504.52
  56   4.7297      0.810  5.9924     1.024  1532.21
  57   4.7288      0.800  5.9916     1.022  1559.43
  58   4.7327      0.830  5.9921     0.990  1586.16
  59   4.7304      0.830  5.9910     1.012  1613.08
  60   4.7317      0.800  5.9931     1.000  1640.50
  61   4.7321      0.800  5.9916     1.044  1666.54
  62   4.7311      0.820  5.9924     0.962  1694.31
  63   4.7342      0.780  5.9925     1.070  1721.58
  64   4.7323      0.840  5.9918     1.010  1748.93
  65   4.7299      0.760  5.9915     1.004  1776.39
  66   4.7291      0.800  5.9920     1.036  1803.66
  67   4.7339      0.820  5.9920     1.032  1831.10
  68   4.7322      0.780  5.9937     1.020  1859.04
  69   4.7348      0.780  5.9916     1.038  1886.43
  70   4.7298      0.830  5.9937     1.028  1913.66
  71   4.7313      0.800  5.9926     1.038  1941.67
  72   4.7365      0.810  5.9923     1.012  1969.72
  73   4.7274      0.830  5.9928     1.044  1997.55
  74   4.7285      0.810  5.9923     1.074  2024.32
  75   4.7321      0.780  5.9911     1.034  2051.93
  76   4.7322      0.770  5.9913     0.998  2079.46
  77   4.7310      0.870  5.9923     1.004  2105.28
  78   4.7332      0.800  5.9922     1.024  2132.47
  79   4.7275      0.800  5.9923     1.058  2160.12
  80   4.7306      0.780  5.9915     1.046  2187.34
  81   4.7275      0.830  5.9921     1.020  2214.73
  82   4.7335      0.780  5.9920     1.036  2242.20
  83   4.7289      0.820  5.9928     1.008  2269.86
  84   4.7308      0.860  5.9919     1.054  2297.20
  85   4.7307      0.810  5.9924     0.976  2324.57
