Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7003      0.840  10.9682     0.888  24.40
   2   4.6998      0.860  10.9675     0.882  47.15
   3   4.6998      0.860  10.9684     0.950  69.91
   4   4.7006      0.890  10.9689     0.910  92.44
   5   4.6995      0.820  10.9691     0.896  115.05
   6   4.7010      0.860  10.9684     0.930  137.54
   7   4.6993      0.880  10.9685     0.898  160.18
   8   4.7010      0.860  10.9668     0.870  182.69
   9   4.6995      0.870  10.9677     0.902  205.17
  10   4.6991      0.860  10.9670     0.880  227.87
  11   4.7004      0.860  10.9675     0.928  250.54
  12   4.6984      0.860  10.9687     0.880  272.98
  13   4.6999      0.870  10.9686     0.910  295.46
  14   4.6997      0.890  10.9681     0.876  317.69
  15   4.7000      0.870  10.9683     0.874  340.18
  16   4.7018      0.920  10.9675     0.912  362.96
  17   4.6992      0.870  10.9673     0.876  385.36
  18   4.7003      0.870  10.9691     0.882  407.84
  19   4.7019      0.880  10.9695     0.912  430.45
  20   4.7027      0.870  10.9691     0.860  453.13
  21   4.7007      0.900  10.9687     0.922  475.46
  22   4.7018      0.870  10.9685     0.882  498.24
  23   4.6991      0.850  10.9707     0.932  520.70
  24   4.6998      0.890  10.9690     0.892  543.10
  25   4.7017      0.850  10.9678     0.904  565.61
  26   4.6983      0.860  10.9682     0.922  588.13
  27   4.6979      0.850  10.9682     0.892  610.50
  28   4.6997      0.870  10.9679     0.880  633.05
  29   4.7018      0.860  10.9681     0.924  655.35
  30   4.7013      0.890  10.9688     0.934  677.78
  31   4.7006      0.870  10.9674     0.920  700.27
  32   4.6989      0.860  10.9689     0.876  722.62
  33   4.6998      0.850  10.9689     0.882  745.05
  34   4.6997      0.880  10.9690     0.882  767.70
  35   4.7004      0.890  10.9673     0.876  790.10
  36   4.6974      0.870  10.9677     0.884  812.35
  37   4.6993      0.890  10.9679     0.900  834.89
  38   4.7000      0.870  10.9677     0.922  857.30
  39   4.7029      0.850  10.9680     0.898  879.49
  40   4.7010      0.850  10.9678     0.906  901.93
  41   4.7000      0.900  10.9674     0.900  924.41
  42   4.6985      0.880  10.9679     0.920  947.17
  43   4.6979      0.890  10.9673     0.902  969.97
  44   4.7013      0.890  10.9688     0.880  992.52
  45   4.7006      0.870  10.9676     0.870  1015.15
  46   4.7015      0.890  10.9690     0.932  1037.74
  47   4.7007      0.830  10.9680     0.920  1060.26
  48   4.7003      0.880  10.9692     0.910  1082.74
  49   4.7015      0.900  10.9687     0.902  1105.13
  50   4.6996      0.870  10.9672     0.950  1127.62
  51   4.6980      0.850  10.9674     0.854  1150.10
  52   4.7014      0.900  10.9679     0.892  1172.51
  53   4.6986      0.860  10.9675     0.902  1194.93
  54   4.7000      0.880  10.9685     0.914  1217.27
  55   4.6999      0.880  10.9682     0.886  1239.79
  56   4.7017      0.840  10.9673     0.896  1262.26
  57   4.6990      0.880  10.9678     0.888  1284.88
  58   4.7023      0.890  10.9681     0.902  1307.46
  59   4.6995      0.870  10.9678     0.882  1329.81
  60   4.6993      0.860  10.9677     0.918  1352.55
  61   4.7009      0.830  10.9683     0.932  1375.02
  62   4.7006      0.850  10.9684     0.892  1397.44
  63   4.6979      0.860  10.9686     0.888  1420.12
  64   4.6994      0.900  10.9680     0.898  1442.61
  65   4.7002      0.870  10.9678     0.880  1465.05
  66   4.7017      0.850  10.9681     0.920  1487.74
  67   4.7006      0.890  10.9676     0.902  1510.39
  68   4.6990      0.860  10.9689     0.892  1532.96
  69   4.6985      0.860  10.9675     0.894  1555.92
  70   4.6994      0.880  10.9678     0.910  1578.48
  71   4.6984      0.870  10.9678     0.914  1601.36
  72   4.6978      0.860  10.9693     0.926  1623.61
  73   4.7016      0.870  10.9687     0.906  1646.13
  74   4.7005      0.870  10.9674     0.890  1668.37
  75   4.7023      0.920  10.9687     0.890  1690.93
  76   4.7006      0.850  10.9683     0.916  1713.32
  77   4.6987      0.870  10.9687     0.908  1736.10
  78   4.7023      0.890  10.9676     0.872  1758.32
  79   4.6999      0.850  10.9680     0.914  1780.69
  80   4.7004      0.860  10.9673     0.900  1803.38
  81   4.7022      0.920  10.9680     0.902  1826.00
  82   4.6990      0.870  10.9681     0.908  1848.31
  83   4.6994      0.850  10.9681     0.930  1870.74
  84   4.7017      0.870  10.9681     0.922  1893.36
  85   4.7000      0.860  10.9688     0.936  1915.75
