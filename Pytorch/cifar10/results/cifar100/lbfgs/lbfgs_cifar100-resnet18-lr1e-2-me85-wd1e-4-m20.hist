Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7312      1.000  6.0187     0.982  24.73
   2   4.7327      1.000  6.0184     1.012  47.87
   3   4.7320      0.950  6.0198     0.998  70.86
   4   4.7332      0.990  6.0189     1.050  93.88
   5   4.7341      1.030  6.0191     1.048  117.05
   6   4.7312      0.960  6.0194     0.960  140.02
   7   4.7340      0.990  6.0202     1.020  163.19
   8   4.7330      1.000  6.0190     1.012  186.26
   9   4.7331      1.040  6.0191     0.984  209.32
  10   4.7310      0.970  6.0193     0.954  232.58
  11   4.7326      1.010  6.0188     1.006  255.74
  12   4.7336      1.040  6.0193     1.016  278.96
  13   4.7335      1.020  6.0190     0.992  301.79
  14   4.7337      1.030  6.0192     0.930  324.91
  15   4.7341      1.030  6.0189     0.942  348.01
  16   4.7338      1.030  6.0190     1.038  371.07
  17   4.7324      1.000  6.0193     1.002  393.93
  18   4.7339      1.010  6.0185     0.938  416.97
  19   4.7342      0.970  6.0180     0.992  440.16
  20   4.7326      1.020  6.0191     0.974  463.21
  21   4.7343      0.990  6.0184     1.086  486.08
  22   4.7347      1.020  6.0186     1.004  508.92
  23   4.7334      1.020  6.0194     0.986  531.96
  24   4.7329      1.020  6.0179     0.976  554.79
  25   4.7358      1.020  6.0198     0.954  577.74
  26   4.7335      1.010  6.0169     0.976  600.70
  27   4.7365      1.010  6.0191     0.988  623.52
  28   4.7341      1.020  6.0194     0.990  646.63
  29   4.7343      1.040  6.0193     0.986  669.81
  30   4.7313      0.990  6.0185     0.932  692.97
  31   4.7344      1.010  6.0191     1.030  716.06
  32   4.7329      0.990  6.0187     0.922  738.80
  33   4.7324      1.010  6.0198     0.986  761.89
  34   4.7337      1.030  6.0199     1.008  784.93
  35   4.7347      1.030  6.0193     0.972  807.91
  36   4.7330      0.980  6.0193     0.996  830.75
  37   4.7337      1.000  6.0190     0.962  853.74
  38   4.7335      1.020  6.0177     0.982  876.73
  39   4.7327      1.000  6.0204     1.018  899.97
  40   4.7348      1.030  6.0190     0.948  922.94
  41   4.7344      1.030  6.0182     0.996  945.79
  42   4.7319      1.000  6.0195     1.032  969.01
  43   4.7325      1.030  6.0196     1.044  992.02
  44   4.7318      1.020  6.0192     1.006  1015.17
  45   4.7335      0.980  6.0186     0.976  1038.42
  46   4.7348      1.000  6.0185     1.010  1061.40
  47   4.7311      0.980  6.0189     0.986  1084.41
  48   4.7340      1.030  6.0212     0.990  1107.34
  49   4.7316      0.970  6.0195     1.002  1130.53
  50   4.7343      1.000  6.0188     0.996  1153.68
  51   4.7314      1.000  6.0215     1.016  1176.55
  52   4.7313      0.980  6.0196     0.970  1199.60
  53   4.7317      0.980  6.0198     1.034  1222.46
  54   4.7334      1.030  6.0194     0.942  1245.60
  55   4.7350      1.030  6.0184     1.020  1268.64
  56   4.7333      0.980  6.0183     0.972  1291.82
  57   4.7340      1.010  6.0190     0.982  1314.81
  58   4.7346      0.990  6.0189     0.960  1337.88
  59   4.7331      1.040  6.0198     0.984  1360.86
  60   4.7336      0.990  6.0192     0.974  1383.94
  61   4.7328      1.050  6.0192     1.024  1407.09
  62   4.7322      1.000  6.0199     0.990  1430.19
  63   4.7327      1.000  6.0187     1.008  1453.29
  64   4.7341      1.020  6.0192     0.996  1476.31
  65   4.7311      0.980  6.0183     0.996  1499.26
  66   4.7344      1.010  6.0183     0.952  1522.27
  67   4.7329      1.010  6.0185     1.040  1545.32
  68   4.7338      1.020  6.0193     1.012  1568.57
  69   4.7343      1.020  6.0195     1.014  1591.63
  70   4.7330      1.020  6.0186     0.942  1614.53
  71   4.7365      1.010  6.0193     0.990  1637.71
  72   4.7346      1.040  6.0181     0.980  1660.79
  73   4.7339      1.040  6.0210     1.028  1683.89
  74   4.7335      1.030  6.0179     1.012  1706.88
  75   4.7332      1.010  6.0200     0.992  1730.03
  76   4.7336      1.000  6.0199     1.028  1753.32
  77   4.7344      1.000  6.0197     1.028  1776.23
  78   4.7355      1.030  6.0178     0.966  1799.24
  79   4.7353      1.010  6.0193     0.964  1822.18
  80   4.7327      1.020  6.0192     0.984  1845.02
  81   4.7343      1.060  6.0182     0.966  1868.16
  82   4.7343      1.010  6.0195     1.006  1891.12
  83   4.7364      1.020  6.0197     1.012  1914.13
  84   4.7355      1.000  6.0192     1.060  1936.98
  85   4.7332      0.980  6.0196     1.012  1960.19
