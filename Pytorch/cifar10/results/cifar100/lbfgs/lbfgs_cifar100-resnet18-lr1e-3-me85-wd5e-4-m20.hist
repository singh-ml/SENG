Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '20', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6884      1.270  10.9602     1.090  24.04
   2   4.6882      1.240  10.9598     1.060  45.92
   3   4.6890      1.310  10.9609     1.044  67.98
   4   4.6877      1.270  10.9594     1.060  89.87
   5   4.6900      1.210  10.9601     1.102  111.94
   6   4.6887      1.210  10.9600     1.102  133.94
   7   4.6885      1.270  10.9599     1.038  155.95
   8   4.6877      1.280  10.9614     1.138  177.89
   9   4.6890      1.220  10.9611     1.002  199.86
  10   4.6890      1.270  10.9596     1.068  221.92
  11   4.6888      1.310  10.9605     1.102  244.12
  12   4.6885      1.290  10.9602     1.010  266.17
  13   4.6896      1.270  10.9586     1.194  288.15
  14   4.6892      1.250  10.9601     1.052  310.22
  15   4.6898      1.240  10.9603     1.082  332.33
  16   4.6889      1.230  10.9615     1.040  354.16
  17   4.6882      1.260  10.9611     1.092  376.23
  18   4.6892      1.190  10.9596     1.132  398.21
  19   4.6891      1.280  10.9600     1.056  420.25
  20   4.6891      1.260  10.9598     1.138  442.19
  21   4.6903      1.240  10.9596     1.026  464.39
  22   4.6887      1.250  10.9596     1.056  486.33
  23   4.6891      1.190  10.9582     1.162  508.32
  24   4.6889      1.260  10.9597     1.064  530.41
  25   4.6903      1.240  10.9597     1.164  552.40
  26   4.6883      1.240  10.9600     1.046  574.42
  27   4.6876      1.300  10.9596     1.050  596.46
  28   4.6888      1.240  10.9611     1.084  618.41
  29   4.6886      1.260  10.9596     1.090  640.44
  30   4.6900      1.240  10.9598     1.064  662.34
  31   4.6871      1.280  10.9607     1.084  684.34
  32   4.6886      1.320  10.9609     1.058  706.51
  33   4.6888      1.220  10.9595     1.044  728.73
  34   4.6898      1.270  10.9597     1.152  750.64
  35   4.6882      1.240  10.9601     1.096  772.81
  36   4.6866      1.300  10.9595     1.064  794.77
  37   4.6892      1.290  10.9599     1.038  816.80
  38   4.6907      1.240  10.9596     1.120  839.15
  39   4.6883      1.240  10.9597     1.072  861.29
  40   4.6876      1.320  10.9604     1.112  883.31
  41   4.6891      1.260  10.9610     1.088  905.54
  42   4.6881      1.270  10.9591     1.062  927.56
  43   4.6878      1.240  10.9600     1.104  949.48
  44   4.6892      1.280  10.9597     1.064  971.39
  45   4.6887      1.270  10.9614     1.058  993.46
  46   4.6889      1.280  10.9598     1.106  1015.35
  47   4.6885      1.250  10.9599     1.162  1037.34
  48   4.6895      1.230  10.9605     1.076  1059.45
  49   4.6883      1.270  10.9602     1.064  1081.44
  50   4.6888      1.190  10.9598     1.094  1103.61
  51   4.6881      1.240  10.9605     1.102  1125.69
  52   4.6888      1.300  10.9594     1.154  1147.68
  53   4.6896      1.260  10.9596     1.040  1169.73
  54   4.6882      1.250  10.9593     1.062  1191.67
  55   4.6905      1.270  10.9598     1.110  1213.61
  56   4.6885      1.240  10.9615     1.124  1235.65
  57   4.6892      1.240  10.9594     1.126  1257.73
  58   4.6889      1.260  10.9589     1.068  1279.90
  59   4.6899      1.280  10.9594     1.024  1302.19
  60   4.6893      1.300  10.9582     1.062  1324.27
  61   4.6873      1.300  10.9609     1.118  1346.22
  62   4.6881      1.260  10.9599     1.066  1368.25
  63   4.6905      1.250  10.9601     1.110  1390.18
  64   4.6893      1.280  10.9602     1.110  1412.06
  65   4.6892      1.250  10.9596     1.106  1433.97
  66   4.6888      1.250  10.9591     1.078  1455.78
  67   4.6880      1.210  10.9609     1.008  1477.62
  68   4.6878      1.250  10.9596     1.128  1499.46
  69   4.6887      1.230  10.9604     1.064  1521.42
  70   4.6884      1.310  10.9618     1.058  1543.60
  71   4.6887      1.260  10.9607     1.136  1565.59
  72   4.6882      1.190  10.9600     1.050  1587.43
  73   4.6900      1.260  10.9601     1.122  1609.38
  74   4.6893      1.230  10.9616     1.002  1631.46
  75   4.6888      1.300  10.9597     1.066  1653.44
  76   4.6888      1.240  10.9599     1.064  1675.46
  77   4.6881      1.250  10.9595     1.104  1697.39
  78   4.6901      1.200  10.9586     1.088  1719.41
  79   4.6887      1.230  10.9600     1.130  1741.50
  80   4.6878      1.270  10.9602     1.122  1763.46
  81   4.6894      1.230  10.9602     1.044  1785.28
  82   4.6882      1.270  10.9606     1.084  1807.37
  83   4.6885      1.200  10.9594     1.048  1829.41
  84   4.6890      1.230  10.9592     1.092  1851.36
  85   4.6890      1.260  10.9594     1.098  1873.21
