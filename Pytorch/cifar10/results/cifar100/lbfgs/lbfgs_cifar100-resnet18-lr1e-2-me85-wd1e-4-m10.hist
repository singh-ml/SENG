Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7032      0.960  5.9708     0.894  24.59
   2   4.7037      0.980  5.9713     0.932  47.29
   3   4.7034      0.960  5.9712     1.004  69.95
   4   4.7027      0.960  5.9708     0.940  92.43
   5   4.7040      0.960  5.9709     0.974  114.65
   6   4.7022      0.970  5.9711     0.928  136.60
   7   4.7046      0.990  5.9710     0.930  158.67
   8   4.7034      0.960  5.9711     0.982  180.65
   9   4.7032      0.960  5.9711     0.942  202.63
  10   4.7033      0.960  5.9716     1.014  224.74
  11   4.7039      0.960  5.9702     0.980  246.73
  12   4.7036      0.970  5.9712     0.992  268.89
  13   4.7038      0.960  5.9701     0.950  290.98
  14   4.7037      0.970  5.9710     0.966  312.99
  15   4.7029      0.960  5.9702     0.948  334.92
  16   4.7035      0.960  5.9726     0.950  357.01
  17   4.7038      0.960  5.9698     0.914  378.88
  18   4.7033      0.960  5.9712     0.956  400.72
  19   4.7026      0.960  5.9721     0.914  422.78
  20   4.7028      0.960  5.9704     0.938  444.63
  21   4.7027      0.970  5.9701     0.960  466.78
  22   4.7032      0.980  5.9710     0.968  488.92
  23   4.7027      0.970  5.9699     0.942  510.87
  24   4.7022      0.960  5.9697     0.940  532.74
  25   4.7025      0.960  5.9715     0.950  554.69
  26   4.7020      0.960  5.9712     0.936  576.66
  27   4.7034      0.980  5.9717     0.962  598.50
  28   4.7040      0.960  5.9703     0.962  620.62
  29   4.7022      0.960  5.9708     0.924  642.78
  30   4.7011      0.960  5.9708     0.960  664.79
  31   4.7034      0.970  5.9714     0.948  686.79
  32   4.7030      0.970  5.9704     0.966  708.92
  33   4.7041      0.960  5.9712     0.950  730.95
  34   4.7041      0.970  5.9712     0.936  753.15
  35   4.7046      0.960  5.9710     0.940  775.25
  36   4.7029      0.970  5.9716     0.982  797.41
  37   4.7031      0.960  5.9713     0.944  819.48
  38   4.7037      0.980  5.9704     0.968  841.67
  39   4.7026      0.960  5.9711     0.926  863.62
  40   4.7043      0.970  5.9706     0.952  885.88
  41   4.7037      0.960  5.9723     0.948  907.70
  42   4.7037      0.960  5.9712     0.966  929.77
  43   4.7037      0.970  5.9715     0.954  951.98
  44   4.7036      0.970  5.9713     0.934  973.94
  45   4.7031      0.960  5.9722     0.988  996.01
  46   4.7045      0.970  5.9694     0.952  1018.02
  47   4.7037      0.950  5.9718     0.942  1040.06
  48   4.7039      0.970  5.9711     0.968  1061.85
  49   4.7025      0.960  5.9694     0.938  1083.94
  50   4.7032      0.960  5.9697     0.960  1105.79
  51   4.7028      0.960  5.9717     0.954  1127.82
  52   4.7033      0.980  5.9702     0.956  1149.68
  53   4.7037      0.960  5.9704     0.970  1171.79
  54   4.7028      0.980  5.9706     0.944  1193.94
  55   4.7042      0.970  5.9706     0.948  1215.87
  56   4.7032      0.970  5.9706     0.934  1237.83
  57   4.7018      0.950  5.9710     0.942  1259.94
  58   4.7028      0.960  5.9701     0.992  1281.91
  59   4.7036      0.970  5.9697     0.972  1303.85
  60   4.7027      0.950  5.9716     0.950  1325.68
  61   4.7045      0.990  5.9698     0.942  1347.55
  62   4.7036      0.970  5.9708     0.952  1369.39
  63   4.7040      0.980  5.9711     0.916  1391.36
  64   4.7025      0.960  5.9703     0.924  1413.25
  65   4.7022      0.970  5.9703     0.950  1435.32
  66   4.7026      0.960  5.9716     0.926  1457.36
  67   4.7034      0.970  5.9708     0.950  1479.47
  68   4.7048      0.960  5.9699     0.952  1501.49
  69   4.7028      0.960  5.9708     0.944  1523.71
  70   4.7025      0.960  5.9708     0.936  1545.82
  71   4.7033      0.960  5.9708     0.952  1567.79
  72   4.7047      0.970  5.9717     0.970  1589.65
  73   4.7025      0.960  5.9699     0.930  1611.88
  74   4.7033      0.960  5.9704     0.972  1633.84
  75   4.7026      0.960  5.9700     0.934  1655.93
  76   4.7055      0.960  5.9700     0.950  1678.21
  77   4.7029      0.970  5.9697     0.944  1700.16
  78   4.7014      0.960  5.9707     0.942  1722.16
  79   4.7017      0.960  5.9720     0.946  1744.21
  80   4.7032      0.960  5.9704     0.952  1766.19
  81   4.7040      0.960  5.9693     0.952  1788.21
  82   4.7024      0.960  5.9700     0.932  1810.47
  83   4.7033      0.980  5.9713     0.916  1832.47
  84   4.7033      0.960  5.9709     0.958  1854.57
  85   4.7028      0.950  5.9699     0.984  1876.43
