Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '2e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7099      0.450  7.2321     0.642  24.07
   2   4.7096      0.430  7.2322     0.574  45.95
   3   4.7109      0.420  7.2334     0.620  67.96
   4   4.7086      0.450  7.2330     0.630  89.83
   5   4.7076      0.500  7.2323     0.682  111.92
   6   4.7113      0.430  7.2329     0.642  134.18
   7   4.7134      0.420  7.2326     0.600  156.40
   8   4.7108      0.450  7.2317     0.652  178.48
   9   4.7086      0.410  7.2322     0.628  200.57
  10   4.7068      0.480  7.2318     0.668  222.65
  11   4.7102      0.410  7.2327     0.584  244.97
  12   4.7092      0.440  7.2321     0.686  266.97
  13   4.7103      0.440  7.2332     0.682  289.00
  14   4.7088      0.480  7.2312     0.624  311.03
  15   4.7096      0.450  7.2329     0.590  333.18
  16   4.7094      0.450  7.2327     0.648  355.07
  17   4.7089      0.460  7.2318     0.590  377.13
  18   4.7084      0.500  7.2327     0.666  399.55
  19   4.7115      0.440  7.2308     0.642  421.69
  20   4.7085      0.450  7.2334     0.580  443.84
  21   4.7097      0.480  7.2330     0.612  466.08
  22   4.7081      0.430  7.2339     0.582  488.08
  23   4.7087      0.470  7.2324     0.658  510.41
  24   4.7087      0.420  7.2334     0.592  532.44
  25   4.7071      0.490  7.2321     0.648  554.55
  26   4.7083      0.420  7.2321     0.612  576.49
  27   4.7074      0.500  7.2313     0.682  598.52
  28   4.7094      0.440  7.2331     0.692  620.57
  29   4.7082      0.450  7.2333     0.668  642.65
  30   4.7085      0.440  7.2324     0.638  664.78
  31   4.7090      0.490  7.2309     0.602  687.05
  32   4.7092      0.420  7.2317     0.672  709.17
  33   4.7105      0.540  7.2331     0.606  731.40
  34   4.7098      0.460  7.2339     0.656  753.62
  35   4.7097      0.450  7.2329     0.616  775.33
  36   4.7080      0.520  7.2321     0.696  796.81
  37   4.7094      0.420  7.2329     0.608  818.39
  38   4.7111      0.430  7.2324     0.602  840.02
  39   4.7076      0.510  7.2324     0.616  861.77
  40   4.7101      0.460  7.2329     0.638  883.38
  41   4.7066      0.450  7.2315     0.614  905.04
  42   4.7089      0.470  7.2339     0.626  926.74
  43   4.7095      0.440  7.2324     0.614  948.22
  44   4.7091      0.500  7.2319     0.648  969.84
  45   4.7089      0.430  7.2321     0.630  991.44
  46   4.7079      0.470  7.2324     0.582  1012.88
  47   4.7099      0.450  7.2320     0.538  1034.56
  48   4.7104      0.460  7.2331     0.638  1056.10
  49   4.7084      0.490  7.2319     0.644  1077.79
  50   4.7094      0.440  7.2320     0.678  1099.31
  51   4.7069      0.500  7.2329     0.618  1120.97
  52   4.7080      0.430  7.2327     0.584  1142.62
  53   4.7084      0.480  7.2330     0.674  1164.21
  54   4.7090      0.470  7.2321     0.664  1185.82
  55   4.7100      0.480  7.2329     0.620  1207.59
  56   4.7084      0.430  7.2317     0.598  1229.33
  57   4.7095      0.450  7.2323     0.628  1251.12
  58   4.7093      0.440  7.2323     0.584  1272.89
  59   4.7078      0.450  7.2331     0.690  1294.38
  60   4.7083      0.500  7.2325     0.618  1315.92
  61   4.7097      0.490  7.2323     0.638  1337.41
  62   4.7090      0.450  7.2328     0.636  1358.98
  63   4.7100      0.420  7.2324     0.638  1380.41
  64   4.7100      0.450  7.2319     0.622  1402.04
  65   4.7103      0.450  7.2324     0.634  1423.56
  66   4.7088      0.470  7.2330     0.622  1445.04
  67   4.7107      0.420  7.2331     0.646  1466.51
  68   4.7106      0.460  7.2326     0.620  1488.07
  69   4.7083      0.450  7.2315     0.618  1509.55
  70   4.7119      0.440  7.2319     0.660  1531.00
  71   4.7105      0.520  7.2331     0.646  1552.52
  72   4.7087      0.430  7.2330     0.610  1573.99
  73   4.7088      0.470  7.2330     0.586  1595.38
  74   4.7101      0.440  7.2333     0.614  1616.88
  75   4.7076      0.440  7.2322     0.602  1638.45
  76   4.7110      0.520  7.2325     0.668  1659.91
  77   4.7107      0.480  7.2328     0.638  1681.39
  78   4.7108      0.430  7.2312     0.660  1702.82
  79   4.7093      0.440  7.2316     0.618  1724.50
  80   4.7080      0.470  7.2321     0.612  1746.01
  81   4.7073      0.480  7.2315     0.630  1767.58
  82   4.7109      0.420  7.2316     0.668  1788.99
  83   4.7079      0.440  7.2333     0.620  1810.46
  84   4.7098      0.470  7.2322     0.602  1831.89
  85   4.7070      0.520  7.2325     0.652  1853.32
  86   4.7092      0.420  7.2314     0.614  1874.86
  87   4.7102      0.460  7.2323     0.644  1896.41
  88   4.7105      0.490  7.2323     0.628  1917.95
  89   4.7086      0.470  7.2325     0.598  1939.47
  90   4.7078      0.420  7.2330     0.646  1961.04
