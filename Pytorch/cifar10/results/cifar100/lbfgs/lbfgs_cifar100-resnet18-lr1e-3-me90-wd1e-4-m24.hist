Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '-m', '24', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.6890      0.810  5.9500     0.884  24.39
   2   4.6889      0.840  5.9488     0.894  46.41
   3   4.6874      0.810  5.9497     0.890  68.54
   4   4.6876      0.810  5.9497     0.888  90.70
   5   4.6900      0.790  5.9490     0.866  112.97
   6   4.6885      0.800  5.9509     0.842  134.94
   7   4.6883      0.810  5.9512     0.890  157.07
   8   4.6879      0.790  5.9492     0.938  179.20
   9   4.6893      0.810  5.9499     0.894  201.24
  10   4.6888      0.810  5.9496     0.868  223.13
  11   4.6886      0.800  5.9500     0.934  245.13
  12   4.6889      0.790  5.9495     0.896  267.25
  13   4.6882      0.780  5.9499     0.864  289.44
  14   4.6879      0.820  5.9505     0.946  311.59
  15   4.6899      0.770  5.9504     0.836  333.58
  16   4.6901      0.840  5.9503     0.918  355.63
  17   4.6901      0.770  5.9494     0.902  377.75
  18   4.6896      0.830  5.9495     0.912  399.82
  19   4.6880      0.820  5.9512     0.938  421.88
  20   4.6882      0.780  5.9497     0.896  444.37
  21   4.6889      0.860  5.9501     0.864  466.63
  22   4.6882      0.840  5.9501     0.866  488.61
  23   4.6882      0.820  5.9490     0.904  510.56
  24   4.6885      0.800  5.9496     0.870  532.52
  25   4.6885      0.820  5.9493     0.892  554.73
  26   4.6886      0.860  5.9493     0.860  576.87
  27   4.6868      0.800  5.9500     0.942  598.93
  28   4.6899      0.790  5.9500     0.902  620.93
  29   4.6879      0.810  5.9487     0.866  643.00
  30   4.6885      0.810  5.9510     0.848  665.33
  31   4.6891      0.820  5.9490     0.924  687.39
  32   4.6877      0.790  5.9503     0.876  709.41
  33   4.6903      0.800  5.9512     0.904  731.72
  34   4.6887      0.800  5.9499     0.912  753.68
  35   4.6879      0.790  5.9496     0.946  775.74
  36   4.6884      0.810  5.9482     0.922  797.63
  37   4.6884      0.840  5.9496     0.890  819.52
  38   4.6867      0.810  5.9492     0.898  841.08
  39   4.6891      0.820  5.9503     0.906  862.69
  40   4.6894      0.820  5.9513     0.834  884.40
  41   4.6900      0.760  5.9506     0.894  905.96
  42   4.6882      0.780  5.9485     0.910  927.59
  43   4.6887      0.820  5.9491     0.948  949.36
  44   4.6885      0.820  5.9503     0.850  970.94
  45   4.6886      0.770  5.9495     0.910  992.70
  46   4.6900      0.810  5.9510     0.886  1014.34
  47   4.6885      0.810  5.9505     0.912  1035.94
  48   4.6871      0.840  5.9496     0.874  1057.57
  49   4.6896      0.810  5.9498     0.868  1079.14
  50   4.6877      0.820  5.9497     0.858  1100.74
  51   4.6893      0.810  5.9490     0.872  1122.39
  52   4.6888      0.800  5.9503     0.928  1143.92
  53   4.6879      0.810  5.9506     0.900  1165.46
  54   4.6886      0.790  5.9491     0.850  1187.02
  55   4.6874      0.810  5.9487     0.884  1208.74
  56   4.6890      0.760  5.9506     0.838  1230.37
  57   4.6869      0.850  5.9495     0.898  1252.16
  58   4.6894      0.810  5.9496     0.876  1273.80
  59   4.6908      0.780  5.9493     0.878  1295.30
  60   4.6888      0.830  5.9499     0.918  1316.90
  61   4.6889      0.800  5.9498     0.874  1338.65
  62   4.6872      0.810  5.9509     0.926  1360.26
  63   4.6888      0.820  5.9497     0.902  1381.92
  64   4.6880      0.820  5.9500     0.838  1403.69
  65   4.6878      0.760  5.9500     0.916  1425.28
  66   4.6880      0.770  5.9497     0.886  1447.13
  67   4.6875      0.820  5.9508     0.908  1468.82
  68   4.6891      0.780  5.9509     0.872  1490.58
  69   4.6882      0.790  5.9492     0.926  1512.26
  70   4.6880      0.820  5.9508     0.864  1533.91
  71   4.6882      0.810  5.9497     0.926  1555.36
  72   4.6899      0.790  5.9500     0.918  1576.92
  73   4.6872      0.840  5.9501     0.878  1598.62
  74   4.6880      0.800  5.9501     0.908  1620.26
  75   4.6879      0.770  5.9505     0.898  1642.00
  76   4.6893      0.840  5.9497     0.908  1663.72
  77   4.6878      0.800  5.9498     0.884  1685.38
  78   4.6883      0.790  5.9500     0.908  1707.06
  79   4.6889      0.800  5.9496     0.838  1728.70
  80   4.6890      0.810  5.9496     0.858  1750.33
  81   4.6885      0.810  5.9485     0.912  1771.86
  82   4.6890      0.800  5.9502     0.826  1793.63
  83   4.6877      0.810  5.9501     0.846  1815.28
  84   4.6889      0.800  5.9482     0.886  1836.94
  85   4.6892      0.800  5.9490     0.882  1858.54
  86   4.6874      0.870  5.9495     0.890  1880.20
  87   4.6884      0.830  5.9504     0.884  1901.92
  88   4.6889      0.780  5.9484     0.896  1923.63
  89   4.6890      0.790  5.9492     0.946  1945.34
  90   4.6891      0.830  5.9499     0.892  1967.03
