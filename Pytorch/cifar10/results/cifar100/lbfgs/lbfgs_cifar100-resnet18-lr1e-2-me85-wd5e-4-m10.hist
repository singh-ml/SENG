Use GPU: 2 for training
==> Running with ['main_lbfgs.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '-m', '10', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '5e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4239565312 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   4.7338      0.840  11.0158     0.886  24.75
   2   4.7325      0.840  11.0158     0.830  47.45
   3   4.7343      0.830  11.0155     0.820  69.82
   4   4.7342      0.810  11.0148     0.928  92.41
   5   4.7309      0.870  11.0159     0.802  114.92
   6   4.7341      0.870  11.0161     0.814  137.49
   7   4.7313      0.860  11.0149     0.888  160.15
   8   4.7332      0.870  11.0144     0.862  183.02
   9   4.7343      0.870  11.0151     0.800  205.43
  10   4.7343      0.850  11.0154     0.876  227.79
  11   4.7333      0.870  11.0148     0.878  250.20
  12   4.7324      0.860  11.0145     0.764  272.51
  13   4.7338      0.860  11.0156     0.836  295.24
  14   4.7353      0.840  11.0151     0.880  318.00
  15   4.7334      0.830  11.0165     0.822  340.61
  16   4.7309      0.860  11.0155     0.786  363.01
  17   4.7360      0.880  11.0146     0.816  385.74
  18   4.7364      0.860  11.0161     0.826  408.18
  19   4.7344      0.860  11.0155     0.846  430.67
  20   4.7320      0.820  11.0164     0.836  453.13
  21   4.7316      0.860  11.0145     0.836  475.79
  22   4.7379      0.890  11.0154     0.800  498.54
  23   4.7370      0.870  11.0148     0.802  521.26
  24   4.7322      0.880  11.0149     0.874  544.09
  25   4.7332      0.850  11.0148     0.842  566.83
  26   4.7323      0.870  11.0159     0.836  589.54
  27   4.7326      0.840  11.0155     0.908  612.55
  28   4.7342      0.860  11.0162     0.818  635.45
  29   4.7319      0.850  11.0152     0.830  658.18
  30   4.7314      0.890  11.0139     0.884  680.70
  31   4.7309      0.850  11.0145     0.812  703.13
  32   4.7305      0.850  11.0164     0.842  726.08
  33   4.7311      0.860  11.0142     0.850  748.64
  34   4.7361      0.910  11.0154     0.812  771.29
  35   4.7353      0.840  11.0144     0.832  794.30
  36   4.7349      0.850  11.0154     0.812  817.30
  37   4.7381      0.880  11.0146     0.870  839.74
  38   4.7341      0.870  11.0156     0.876  862.50
  39   4.7327      0.840  11.0155     0.802  885.11
  40   4.7323      0.840  11.0153     0.902  907.54
  41   4.7351      0.850  11.0153     0.848  930.55
  42   4.7347      0.880  11.0156     0.818  953.07
  43   4.7322      0.850  11.0157     0.844  975.85
  44   4.7372      0.880  11.0157     0.840  998.52
  45   4.7318      0.870  11.0157     0.876  1021.66
  46   4.7347      0.880  11.0152     0.812  1044.34
  47   4.7335      0.860  11.0152     0.824  1067.23
  48   4.7344      0.820  11.0147     0.832  1090.14
  49   4.7356      0.830  11.0157     0.904  1112.68
  50   4.7351      0.870  11.0158     0.782  1135.58
  51   4.7340      0.870  11.0154     0.810  1158.42
  52   4.7371      0.890  11.0153     0.790  1181.07
  53   4.7356      0.870  11.0159     0.826  1203.88
  54   4.7362      0.860  11.0157     0.868  1226.40
  55   4.7332      0.850  11.0150     0.846  1249.06
  56   4.7344      0.840  11.0144     0.876  1271.48
  57   4.7334      0.900  11.0161     0.836  1294.02
  58   4.7345      0.870  11.0159     0.818  1316.76
  59   4.7307      0.890  11.0147     0.842  1339.46
  60   4.7329      0.840  11.0162     0.790  1361.92
  61   4.7323      0.840  11.0155     0.886  1384.60
  62   4.7321      0.850  11.0159     0.848  1407.46
  63   4.7349      0.830  11.0161     0.816  1429.96
  64   4.7336      0.900  11.0156     0.858  1452.80
  65   4.7318      0.850  11.0150     0.838  1475.70
  66   4.7338      0.860  11.0152     0.862  1498.39
  67   4.7318      0.860  11.0165     0.786  1521.15
  68   4.7327      0.870  11.0150     0.806  1543.68
  69   4.7311      0.860  11.0130     0.794  1566.29
  70   4.7339      0.860  11.0152     0.894  1588.83
  71   4.7360      0.880  11.0152     0.806  1611.48
  72   4.7327      0.850  11.0162     0.816  1634.40
  73   4.7324      0.850  11.0156     0.878  1657.27
  74   4.7359      0.880  11.0150     0.814  1679.94
  75   4.7324      0.850  11.0150     0.868  1702.78
  76   4.7354      0.850  11.0155     0.790  1725.68
  77   4.7319      0.860  11.0152     0.826  1748.40
  78   4.7325      0.880  11.0156     0.814  1771.36
  79   4.7355      0.860  11.0150     0.882  1794.17
  80   4.7363      0.880  11.0151     0.838  1816.95
  81   4.7343      0.840  11.0158     0.846  1839.82
  82   4.7347      0.830  11.0159     0.854  1862.81
  83   4.7299      0.820  11.0151     0.860  1885.53
  84   4.7333      0.860  11.0161     0.844  1908.29
  85   4.7339      0.830  11.0157     0.776  1930.79
