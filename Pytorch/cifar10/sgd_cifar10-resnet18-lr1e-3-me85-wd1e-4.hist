Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8081     33.200  2.0519    23.444  21.85
   2   1.6286     38.810  1.7365    35.244  41.78
   3   1.5307     43.250  1.5921    40.864  61.69
   4   1.4159     47.040  1.4829    45.052  81.68
   5   1.3467     49.690  1.3999    48.436  101.64
   6   1.2743     53.270  1.3272    51.716  121.59
   7   1.2410     54.570  1.2697    53.680  141.54
   8   1.2114     55.920  1.2094    56.030  161.51
   9   1.1209     58.910  1.1527    58.330  181.46
  10   1.0937     60.730  1.0991    60.446  201.36
  11   1.0358     63.020  1.0611    61.674  221.32
  12   1.0320     63.710  1.0168    63.710  241.28
  13   0.9977     64.270  0.9822    64.978  261.25
  14   0.9599     65.510  0.9489    66.214  281.17
  15   0.9316     67.140  0.9202    66.988  301.15
  16   0.9865     66.190  0.8962    68.056  321.09
  17   0.9158     67.960  0.8722    68.836  341.03
  18   0.8520     69.820  0.8460    69.798  360.92
  19   0.8920     68.980  0.8253    70.612  380.87
  20   0.8716     69.300  0.8070    71.092  400.80
  21   0.8573     70.020  0.7919    71.622  420.72
  22   0.8534     70.230  0.7737    72.652  440.67
  23   0.8216     71.210  0.7529    73.408  460.64
  24   0.8138     72.070  0.7392    73.792  480.61
  25   0.8250     71.470  0.7230    74.386  500.58
  26   0.8157     72.180  0.7045    75.092  520.56
  27   0.7933     73.070  0.6937    75.448  540.49
  28   0.7497     73.520  0.6794    76.074  560.43
  29   0.8320     72.060  0.6605    76.616  580.40
  30   0.7665     74.170  0.6519    77.052  600.35
  31   0.7186     75.220  0.6367    77.534  620.26
  32   0.7380     74.970  0.6237    78.036  640.24
  33   0.7216     75.420  0.6093    78.336  660.22
  34   0.7020     75.570  0.5978    78.682  680.22
  35   0.6754     76.900  0.5836    79.602  700.21
  36   0.6783     76.890  0.5745    79.862  720.19
  37   0.6461     77.610  0.5673    80.092  740.14
  38   0.6438     78.030  0.5530    80.518  760.14
  39   0.6650     77.390  0.5403    81.050  780.08
  40   0.6616     77.700  0.5322    81.308  800.02
  41   0.6373     78.290  0.5179    81.880  819.93
  42   0.6470     78.600  0.5133    81.946  839.83
  43   0.6036     79.490  0.5058    82.114  859.79
  44   0.6332     78.360  0.4937    82.666  879.73
  45   0.6223     78.890  0.4860    82.964  899.65
  46   0.6231     79.300  0.4766    83.252  919.56
  47   0.6234     79.030  0.4698    83.528  939.49
  48   0.6169     79.220  0.4567    84.124  959.48
  49   0.5937     79.910  0.4562    83.946  979.47
  50   0.6150     79.530  0.4453    84.386  999.42
  51   0.6314     79.550  0.4364    84.660  1019.38
  52   0.6005     80.530  0.4272    84.890  1039.36
  53   0.5903     80.610  0.4208    85.208  1059.36
  54   0.5938     80.800  0.4143    85.612  1079.29
  55   0.5774     80.840  0.4078    85.792  1099.22
  56   0.5859     80.500  0.4045    85.784  1119.18
  57   0.5739     80.940  0.3925    86.292  1139.12
  58   0.5629     81.220  0.3865    86.418  1159.15
  59   0.5587     82.050  0.3837    86.594  1179.15
  60   0.5513     82.040  0.3766    86.840  1199.16
  61   0.5471     82.000  0.3707    87.206  1219.15
  62   0.5462     81.850  0.3633    87.184  1239.13
  63   0.5729     81.440  0.3560    87.564  1259.08
  64   0.5689     81.750  0.3528    87.584  1279.07
  65   0.5771     81.520  0.3457    87.980  1299.04
  66   0.5492     82.780  0.3423    87.914  1319.00
  67   0.5753     81.590  0.3340    88.210  1338.97
  68   0.5630     82.260  0.3336    88.202  1358.95
  69   0.5451     82.370  0.3286    88.496  1378.95
  70   0.5703     81.930  0.3201    88.824  1398.90
  71   0.5471     82.960  0.3149    89.014  1418.88
  72   0.5506     82.850  0.3090    89.114  1438.93
  73   0.5659     82.220  0.3053    89.352  1458.90
  74   0.5550     82.870  0.2995    89.446  1478.89
  75   0.5513     82.400  0.2966    89.612  1498.88
  76   0.5166     83.790  0.2923    89.828  1518.87
  77   0.5344     83.610  0.2873    89.862  1538.86
  78   0.5232     83.650  0.2839    90.026  1558.86
  79   0.5389     83.440  0.2782    90.276  1578.87
  80   0.5272     83.670  0.2748    90.322  1598.85
  81   0.5647     82.620  0.2680    90.588  1618.81
  82   0.5262     83.950  0.2656    90.894  1638.77
  83   0.5416     83.510  0.2642    90.726  1658.75
  84   0.5355     83.830  0.2576    90.980  1678.78
  85   0.5498     83.260  0.2540    91.096  1698.78
