Use GPU: 1 for training
==> Running with ['main_sgd.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.5310     43.680  1.7440    34.380  21.79
   2   1.2888     53.540  1.3792    49.192  41.74
   3   1.1460     58.990  1.1940    56.604  61.75
   4   1.0361     63.850  1.0382    62.794  81.75
   5   0.9455     66.570  0.9237    67.020  101.77
   6   0.8967     68.710  0.8380    70.172  121.75
   7   0.7638     72.850  0.7667    72.856  141.70
   8   0.7330     73.970  0.7003    75.436  161.71
   9   0.7005     76.050  0.6493    77.136  181.70
  10   0.6835     76.980  0.6126    78.602  201.69
  11   0.6117     79.120  0.5728    79.930  221.65
  12   0.6520     78.140  0.5338    81.370  241.69
  13   0.6114     79.040  0.5064    82.130  261.67
  14   0.6009     80.340  0.4861    83.050  281.66
  15   0.6065     80.450  0.4547    84.132  301.65
  16   0.5719     80.680  0.4336    84.792  321.65
  17   0.5421     82.320  0.4202    85.316  341.64
  18   0.5034     83.620  0.3978    86.160  361.68
  19   0.5230     82.370  0.3895    86.446  381.76
  20   0.5197     82.790  0.3699    87.080  401.76
  21   0.5255     82.790  0.3535    87.586  421.75
  22   0.5328     82.420  0.3367    88.238  441.74
  23   0.4963     83.670  0.3238    88.694  461.71
  24   0.5811     81.930  0.3076    89.228  481.71
  25   0.5359     82.630  0.2973    89.634  501.67
  26   0.5322     83.910  0.2871    89.782  521.63
  27   0.4789     84.780  0.2796    90.206  541.59
  28   0.4853     85.350  0.2619    90.794  561.61
  29   0.4874     84.940  0.2512    91.236  581.61
  30   0.4693     85.510  0.2471    91.434  601.58
  31   0.4922     84.900  0.2334    91.726  621.55
  32   0.5812     82.890  0.2272    91.982  641.51
  33   0.4650     85.510  0.2128    92.614  661.48
  34   0.4791     85.590  0.2124    92.518  681.50
  35   0.4564     86.180  0.2035    92.844  701.47
  36   0.4828     85.820  0.1925    93.276  721.47
  37   0.5673     84.140  0.1841    93.410  741.47
  38   0.4465     86.910  0.1762    93.834  761.44
  39   0.5088     85.840  0.1700    93.922  781.47
  40   0.5104     85.530  0.1591    94.404  801.44
  41   0.4760     86.540  0.1542    94.486  821.41
  42   0.4895     86.710  0.1496    94.696  841.37
  43   0.4866     86.020  0.1412    95.090  861.34
  44   0.4842     86.840  0.1367    95.162  881.29
  45   0.4719     86.970  0.1287    95.514  901.27
  46   0.5055     86.500  0.1270    95.516  921.26
  47   0.5266     86.410  0.1194    95.866  941.22
  48   0.5154     86.240  0.1148    96.018  961.20
  49   0.4615     87.580  0.1091    96.276  981.14
  50   0.4567     87.780  0.1039    96.344  1001.08
  51   0.4842     87.110  0.0981    96.616  1021.05
  52   0.5039     87.400  0.0920    96.784  1041.02
  53   0.4899     87.310  0.0927    96.822  1060.94
  54   0.4961     87.530  0.0846    97.076  1080.88
  55   0.4748     87.900  0.0858    97.048  1100.85
  56   0.4849     87.650  0.0834    97.096  1120.79
  57   0.5052     87.700  0.0765    97.358  1140.79
  58   0.4651     88.320  0.0769    97.312  1160.75
  59   0.4868     87.990  0.0685    97.716  1180.73
  60   0.4960     87.940  0.0654    97.832  1200.69
  61   0.4851     88.010  0.0657    97.712  1220.65
  62   0.5100     87.800  0.0590    98.020  1240.66
  63   0.4898     88.280  0.0593    98.034  1260.65
  64   0.4922     88.340  0.0573    98.094  1280.69
  65   0.5143     87.760  0.0535    98.272  1300.65
  66   0.4912     88.160  0.0498    98.372  1320.61
  67   0.5005     88.250  0.0494    98.372  1340.57
  68   0.5036     88.580  0.0471    98.448  1360.53
  69   0.5121     88.380  0.0478    98.448  1380.55
  70   0.5034     88.430  0.0465    98.496  1400.57
  71   0.5091     88.270  0.0398    98.788  1420.53
  72   0.5156     88.060  0.0426    98.600  1440.53
  73   0.4954     88.660  0.0399    98.770  1460.53
  74   0.5083     88.540  0.0385    98.772  1480.47
  75   0.5185     88.560  0.0378    98.812  1500.45
  76   0.5138     88.580  0.0366    98.856  1520.45
  77   0.5030     88.590  0.0344    98.960  1540.57
  78   0.5141     88.640  0.0339    98.938  1560.60
  79   0.5170     88.660  0.0336    98.962  1580.60
  80   0.5131     88.670  0.0343    98.940  1600.60
  81   0.5212     88.630  0.0326    98.984  1620.58
  82   0.5291     88.480  0.0329    98.992  1640.54
  83   0.5279     88.680  0.0305    99.012  1660.52
  84   0.5199     88.870  0.0303    99.084  1680.46
  85   0.5283     88.680  0.0273    99.236  1700.46
