Use GPU: 2 for training
==> Running with ['main_seng.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--damping', '0.8', '--trainset', 'cifar100', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '1e-4', '--lr-scheme', 'cosine', '--gpu', '2']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 7695761920 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   3.5782     15.090  3.9393     9.952  24.41
   2   3.0355     25.090  3.2753    20.264  46.63
   3   2.6612     32.180  2.8731    27.748  68.85
   4   2.3940     37.130  2.5417    34.230  91.06
   5   2.2366     40.650  2.2684    39.610  113.30
   6   2.0468     45.080  2.0672    44.416  135.55
   7   1.9561     47.800  1.8990    48.176  157.78
   8   1.8843     49.940  1.7543    51.556  180.01
   9   1.7888     51.350  1.6481    53.878  202.24
  10   1.7016     53.420  1.5367    56.666  224.46
  11   1.6412     54.650  1.4379    59.292  246.70
  12   1.6435     55.390  1.3645    61.306  268.89
  13   1.5605     57.170  1.2883    62.948  291.11
  14   1.5818     57.050  1.2067    64.976  313.33
  15   1.5506     57.980  1.1502    66.440  335.55
  16   1.4888     59.440  1.0874    67.928  357.80
  17   1.5391     59.300  1.0240    69.658  379.98
  18   1.4819     60.590  0.9704    71.230  402.24
  19   1.4515     61.130  0.9119    72.738  424.52
  20   1.4371     62.400  0.8681    74.272  446.70
  21   1.4714     61.800  0.8136    75.328  468.90
  22   1.4486     62.020  0.7720    76.662  491.11
  23   1.4723     62.930  0.7219    78.048  513.34
  24   1.4499     62.600  0.6801    79.348  535.51
  25   1.4425     62.780  0.6347    80.512  557.73
  26   1.4803     62.780  0.5941    81.772  580.04
  27   1.4630     63.300  0.5575    82.684  602.24
  28   1.4522     63.750  0.5246    84.028  624.46
  29   1.4675     63.600  0.4803    85.412  646.64
  30   1.4855     64.200  0.4507    86.098  668.85
  31   1.4785     64.500  0.4180    87.130  691.02
  32   1.5200     64.580  0.3836    88.256  713.25
  33   1.5091     64.320  0.3563    89.050  735.50
  34   1.5259     64.460  0.3262    90.086  757.74
  35   1.5257     64.970  0.3038    90.742  779.97
  36   1.5065     65.470  0.2751    91.808  802.14
  37   1.5375     65.180  0.2541    92.376  824.41
  38   1.5470     65.710  0.2335    93.012  846.61
  39   1.5525     65.660  0.2116    94.048  868.79
  40   1.5813     65.540  0.1939    94.498  891.00
  41   1.5837     65.570  0.1759    95.244  913.23
  42   1.5796     66.150  0.1610    95.708  935.48
  43   1.5907     66.150  0.1407    96.250  957.68
  44   1.5938     65.850  0.1305    96.696  979.87
  45   1.5955     65.930  0.1204    96.968  1002.09
  46   1.5943     66.630  0.1089    97.394  1024.29
  47   1.6042     66.630  0.0962    97.860  1046.43
  48   1.5994     66.720  0.0870    98.172  1068.68
  49   1.6080     67.020  0.0802    98.272  1090.92
  50   1.5921     67.310  0.0743    98.424  1112.93
  51   1.5869     67.150  0.0697    98.618  1135.13
  52   1.6316     66.680  0.0642    98.776  1157.35
  53   1.6187     67.260  0.0599    98.884  1179.59
  54   1.6255     67.420  0.0552    99.076  1201.86
  55   1.6300     67.390  0.0503    99.200  1224.07
  56   1.6244     67.530  0.0472    99.300  1246.32
  57   1.6109     67.680  0.0439    99.344  1268.58
  58   1.6272     67.770  0.0417    99.372  1290.77
  59   1.6398     67.180  0.0383    99.506  1312.96
  60   1.6405     67.480  0.0363    99.498  1335.15
  61   1.6445     67.750  0.0336    99.624  1357.39
  62   1.6383     67.590  0.0327    99.608  1379.58
  63   1.6407     67.790  0.0313    99.662  1401.82
  64   1.6475     67.710  0.0310    99.644  1424.00
  65   1.6537     67.720  0.0286    99.716  1446.28
  66   1.6445     67.540  0.0271    99.746  1468.50
  67   1.6469     67.920  0.0268    99.730  1490.65
  68   1.6468     67.880  0.0264    99.750  1512.85
  69   1.6507     67.870  0.0246    99.752  1535.14
  70   1.6508     67.840  0.0248    99.778  1557.32
  71   1.6553     67.980  0.0237    99.796  1579.53
  72   1.6443     68.090  0.0241    99.760  1601.71
  73   1.6506     67.970  0.0230    99.780  1623.90
  74   1.6547     67.870  0.0215    99.838  1646.26
  75   1.6626     67.900  0.0217    99.800  1668.59
  76   1.6606     68.080  0.0210    99.840  1690.80
  77   1.6625     67.760  0.0203    99.842  1713.01
  78   1.6635     67.970  0.0199    99.874  1735.24
  79   1.6592     68.300  0.0199    99.838  1757.50
  80   1.6626     68.050  0.0198    99.848  1779.79
  81   1.6661     68.020  0.0194    99.846  1802.09
  82   1.6627     67.730  0.0187    99.874  1824.32
  83   1.6665     67.840  0.0185    99.880  1846.54
  84   1.6631     67.810  0.0184    99.884  1868.72
  85   1.6628     68.020  0.0176    99.880  1890.91
