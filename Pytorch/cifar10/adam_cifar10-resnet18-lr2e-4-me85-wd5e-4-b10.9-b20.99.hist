Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2951     54.290  1.4726    45.798  22.09
   2   1.0808     61.080  1.0782    61.250  42.38
   3   0.8509     69.990  0.8788    68.756  62.58
   4   0.8707     70.530  0.7491    73.396  82.83
   5   0.7604     74.200  0.6509    77.040  103.13
   6   0.7285     76.390  0.5935    79.232  123.35
   7   0.5963     79.000  0.5332    81.324  143.63
   8   0.6105     78.860  0.4906    82.926  163.90
   9   0.6240     79.270  0.4559    84.166  184.19
  10   0.5780     81.030  0.4247    85.354  204.44
  11   0.5504     81.490  0.3995    86.070  224.71
  12   0.5692     80.840  0.3736    86.846  245.00
  13   0.5339     82.770  0.3521    87.792  265.27
  14   0.5037     83.970  0.3303    88.452  285.57
  15   0.5616     82.030  0.3136    89.144  305.86
  16   0.4494     85.150  0.2948    89.876  326.15
  17   0.4828     84.820  0.2823    90.176  346.42
  18   0.4848     83.990  0.2717    90.660  366.64
  19   0.5043     83.850  0.2574    91.062  386.93
  20   0.4728     85.260  0.2425    91.490  407.17
  21   0.4579     85.560  0.2339    91.936  427.50
  22   0.4288     86.650  0.2230    92.200  447.78
  23   0.4457     85.950  0.2122    92.690  468.02
  24   0.4012     87.160  0.2043    92.792  488.30
  25   0.4732     85.540  0.1899    93.416  508.53
  26   0.5336     84.580  0.1932    93.252  528.78
  27   0.3852     88.170  0.1796    93.796  549.11
  28   0.4820     85.420  0.1766    93.890  569.37
  29   0.4425     86.940  0.1696    94.114  589.57
  30   0.4913     85.390  0.1621    94.402  609.83
  31   0.4199     87.730  0.1564    94.666  630.07
  32   0.4166     88.280  0.1509    94.760  650.36
  33   0.4244     87.180  0.1459    94.886  670.63
  34   0.4483     86.990  0.1395    95.206  690.87
  35   0.4166     87.720  0.1363    95.294  711.12
  36   0.4474     87.320  0.1316    95.410  731.37
  37   0.4177     87.810  0.1251    95.672  751.68
  38   0.3835     89.030  0.1265    95.610  771.95
  39   0.4362     87.830  0.1236    95.724  792.23
  40   0.4136     88.010  0.1144    96.060  812.51
  41   0.3969     88.350  0.1183    95.846  832.73
  42   0.3980     89.090  0.1070    96.322  852.97
  43   0.4034     88.920  0.1123    96.104  873.19
  44   0.3827     89.140  0.1052    96.398  893.44
  45   0.3909     88.950  0.1037    96.468  913.72
  46   0.4103     88.750  0.0991    96.598  933.94
  47   0.4075     88.450  0.1006    96.574  954.16
  48   0.4213     88.360  0.0973    96.648  974.43
  49   0.3775     88.900  0.0912    96.938  994.72
  50   0.4001     88.980  0.0944    96.704  1014.98
  51   0.4076     89.670  0.0922    96.844  1035.26
  52   0.4722     87.490  0.0913    96.844  1055.54
  53   0.3991     89.160  0.0871    96.948  1075.75
  54   0.4146     88.670  0.0876    97.058  1095.98
  55   0.3904     89.290  0.0877    96.974  1116.23
  56   0.4695     87.780  0.0808    97.264  1136.48
  57   0.4131     89.080  0.0831    97.114  1156.75
  58   0.4428     88.450  0.0793    97.256  1177.02
  59   0.3931     89.700  0.0765    97.364  1197.28
  60   0.4642     87.670  0.0803    97.208  1217.55
  61   0.3979     89.000  0.0778    97.378  1237.77
  62   0.4024     89.010  0.0762    97.432  1258.00
  63   0.3907     89.480  0.0742    97.464  1278.29
  64   0.3723     89.960  0.0741    97.480  1298.58
  65   0.3852     89.690  0.0726    97.502  1318.85
  66   0.3979     89.790  0.0712    97.556  1339.10
  67   0.4661     87.880  0.0703    97.582  1359.36
  68   0.4205     88.820  0.0697    97.664  1379.62
  69   0.3866     90.050  0.0691    97.676  1399.86
  70   0.4507     88.800  0.0718    97.602  1420.10
  71   0.3719     90.160  0.0665    97.748  1440.34
  72   0.4522     88.370  0.0646    97.782  1460.57
  73   0.4243     89.110  0.0662    97.752  1480.81
  74   0.4555     88.440  0.0640    97.838  1501.01
  75   0.3665     90.370  0.0650    97.822  1521.24
  76   0.4069     89.440  0.0682    97.692  1541.51
  77   0.4310     89.220  0.0597    97.984  1561.75
  78   0.4132     88.920  0.0636    97.868  1582.04
  79   0.3859     90.110  0.0645    97.812  1602.28
  80   0.4204     89.480  0.0633    97.864  1622.52
  81   0.4018     89.440  0.0614    97.930  1642.78
  82   0.4977     87.770  0.0612    97.914  1663.03
  83   0.3802     90.400  0.0614    97.886  1683.30
  84   0.3545     90.770  0.0629    97.878  1703.52
  85   0.4805     88.030  0.0578    98.072  1723.77
