Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-4', '--weight-decay', '5e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2367     55.510  1.3896    49.086  22.20
   2   1.0486     64.970  0.9522    65.920  42.44
   3   0.7391     74.300  0.7592    73.352  62.65
   4   0.7807     73.790  0.6416    77.834  82.91
   5   1.1428     66.180  0.5638    80.508  103.15
   6   0.6765     78.020  0.5154    82.298  123.36
   7   0.6419     78.240  0.4811    83.490  143.60
   8   0.9181     73.540  0.4420    84.976  163.81
   9   0.6918     78.380  0.4171    85.616  184.01
  10   0.4827     83.270  0.3859    86.834  204.23
  11   0.5585     81.740  0.3673    87.344  224.47
  12   0.5870     82.350  0.3489    88.084  244.70
  13   0.4360     85.690  0.3366    88.442  264.94
  14   0.6666     79.340  0.3220    89.050  285.20
  15   0.4311     86.010  0.3054    89.688  305.41
  16   0.4321     86.050  0.2967    89.874  325.64
  17   0.4545     85.100  0.2807    90.528  345.87
  18   0.4517     85.590  0.2660    90.876  366.10
  19   0.4347     86.420  0.2662    91.064  386.31
  20   0.4217     86.460  0.2498    91.494  406.54
  21   0.4424     86.080  0.2448    91.716  426.74
  22   0.4901     85.270  0.2368    91.826  446.98
  23   0.4504     86.080  0.2255    92.268  467.19
  24   0.4638     85.910  0.2169    92.566  487.43
  25   0.4460     86.510  0.2061    93.050  507.63
  26   0.3471     88.760  0.2066    93.004  527.86
  27   0.4319     86.240  0.2017    93.146  548.08
  28   0.3926     87.840  0.1902    93.684  568.31
  29   0.4724     85.980  0.1881    93.702  588.55
  30   0.4613     86.500  0.1810    93.862  608.83
  31   0.3578     89.220  0.1781    94.040  629.10
  32   0.4187     86.720  0.1743    94.086  649.34
  33   0.3617     89.440  0.1716    94.208  669.54
  34   0.3670     88.750  0.1610    94.516  689.77
  35   0.3907     88.120  0.1622    94.524  710.05
  36   0.3498     89.600  0.1639    94.518  730.29
  37   0.3745     89.180  0.1574    94.588  750.49
  38   0.3865     88.580  0.1487    94.840  770.78
  39   0.3917     88.330  0.1491    94.924  791.00
  40   0.3628     89.230  0.1443    95.094  811.24
  41   0.3559     89.830  0.1427    95.150  831.50
  42   0.3771     88.940  0.1432    95.072  851.79
  43   0.4351     87.700  0.1398    95.168  872.04
  44   0.4245     88.010  0.1311    95.578  892.24
  45   0.4399     87.940  0.1348    95.306  912.45
  46   0.5594     85.870  0.1318    95.548  932.67
  47   0.3914     88.840  0.1323    95.460  952.95
  48   0.3413     90.170  0.1311    95.496  973.19
  49   0.4217     88.280  0.1266    95.684  993.43
  50   0.3579     89.650  0.1198    96.082  1013.67
  51   0.3445     90.070  0.1253    95.718  1033.94
  52   0.4041     88.600  0.1239    95.842  1054.23
  53   0.3525     89.690  0.1227    95.808  1074.47
  54   0.3250     90.410  0.1203    95.902  1094.73
  55   0.3365     90.240  0.1124    96.158  1114.98
  56   0.3280     90.770  0.1171    95.982  1135.22
  57   0.3151     90.710  0.1152    96.056  1155.48
  58   0.3357     90.300  0.1128    96.224  1175.74
  59   0.4748     87.630  0.1180    95.976  1196.01
  60   0.3857     89.390  0.1053    96.428  1216.22
  61   0.3742     89.400  0.1106    96.186  1236.46
  62   0.3493     90.150  0.1090    96.342  1256.71
  63   0.3290     90.680  0.1082    96.308  1276.97
  64   0.3451     90.150  0.1101    96.328  1297.18
  65   0.4140     88.750  0.1074    96.344  1317.44
  66   0.3584     89.950  0.1071    96.386  1337.69
  67   0.3921     89.320  0.1040    96.582  1357.93
  68   0.4468     87.960  0.1033    96.492  1378.15
  69   0.3842     89.660  0.1082    96.408  1398.39
  70   0.3274     90.700  0.1051    96.428  1418.69
  71   0.4281     88.780  0.1050    96.540  1438.97
  72   0.3903     89.490  0.0967    96.694  1459.21
  73   0.3325     90.930  0.1008    96.660  1479.44
  74   0.3660     90.010  0.0986    96.540  1499.75
  75   0.3611     90.780  0.0975    96.798  1519.99
  76   0.3646     90.680  0.0970    96.748  1540.26
  77   0.3780     90.110  0.1045    96.434  1560.53
  78   0.3616     90.210  0.0957    96.822  1580.79
  79   0.4112     89.020  0.0960    96.742  1601.04
  80   0.3485     90.630  0.1005    96.546  1621.34
  81   0.3455     90.580  0.0958    96.778  1641.58
  82   0.3484     90.490  0.0912    96.904  1661.84
  83   0.3568     90.150  0.0955    96.754  1682.06
  84   0.3404     90.540  0.0960    96.810  1702.33
  85   0.4133     89.050  0.0922    96.906  1722.59
