Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2807     53.500  1.5513    42.756  22.13
   2   1.0403     63.090  1.1637    57.878  42.39
   3   0.9098     67.180  0.9661    65.434  62.58
   4   0.8065     71.700  0.8117    71.084  82.77
   5   0.7307     74.350  0.7128    74.964  102.96
   6   0.6933     76.300  0.6379    77.566  123.20
   7   0.6043     78.790  0.5749    79.810  143.41
   8   0.5739     80.550  0.5197    81.746  163.63
   9   0.5495     81.590  0.4869    82.880  183.90
  10   0.5552     81.530  0.4469    84.350  204.11
  11   0.5185     82.830  0.4135    85.460  224.33
  12   0.4743     83.910  0.3868    86.402  244.55
  13   0.4940     83.780  0.3611    87.428  264.75
  14   0.4775     84.600  0.3446    87.978  284.95
  15   0.4732     84.440  0.3288    88.476  305.18
  16   0.4540     85.070  0.3134    88.892  325.40
  17   0.4793     84.980  0.2895    89.814  345.61
  18   0.4571     85.430  0.2718    90.600  365.86
  19   0.4229     86.730  0.2521    91.160  386.11
  20   0.4271     86.530  0.2360    91.752  406.31
  21   0.4790     85.830  0.2306    91.988  426.52
  22   0.4650     85.660  0.2237    92.118  446.73
  23   0.4257     86.760  0.2054    92.754  467.02
  24   0.4682     85.680  0.1919    93.192  487.23
  25   0.4258     87.250  0.1817    93.664  507.43
  26   0.4230     87.670  0.1704    94.066  527.64
  27   0.4322     87.230  0.1634    94.256  547.87
  28   0.4173     87.620  0.1601    94.378  568.12
  29   0.4236     87.450  0.1536    94.600  588.33
  30   0.4380     86.830  0.1472    94.780  608.54
  31   0.4352     87.560  0.1389    95.098  628.73
  32   0.4530     87.520  0.1351    95.234  648.95
  33   0.4223     87.740  0.1302    95.394  669.23
  34   0.4210     88.150  0.1231    95.676  689.47
  35   0.4341     88.220  0.1128    96.012  709.69
  36   0.4633     87.410  0.1058    96.216  729.91
  37   0.4370     88.390  0.1003    96.456  750.21
  38   0.4290     88.160  0.1022    96.358  770.46
  39   0.4418     88.440  0.1003    96.550  790.66
  40   0.4288     88.370  0.1066    96.208  810.91
  41   0.4289     88.140  0.0981    96.560  831.11
  42   0.4250     88.900  0.0897    96.918  851.34
  43   0.4316     88.870  0.0887    96.800  871.56
  44   0.4490     88.740  0.0877    96.838  891.79
  45   0.4650     88.420  0.0843    97.092  912.07
  46   0.4237     89.020  0.0808    97.126  932.31
  47   0.4117     89.570  0.0763    97.330  952.52
  48   0.4478     88.890  0.0746    97.368  972.70
  49   0.4391     88.790  0.0751    97.346  992.92
  50   0.4523     88.660  0.0747    97.362  1013.17
  51   0.4481     89.210  0.0681    97.662  1033.43
  52   0.4555     88.970  0.0709    97.524  1053.66
  53   0.4589     88.540  0.0714    97.496  1073.85
  54   0.4792     88.520  0.0663    97.656  1094.08
  55   0.4642     88.930  0.0657    97.736  1114.33
  56   0.4335     89.160  0.0692    97.514  1134.56
  57   0.4622     88.680  0.0650    97.642  1154.77
  58   0.4411     89.250  0.0572    98.056  1174.99
  59   0.4475     89.440  0.0626    97.816  1195.25
  60   0.4362     89.300  0.0580    97.986  1215.45
  61   0.4321     89.760  0.0557    98.056  1235.67
  62   0.4275     89.560  0.0536    98.124  1255.90
  63   0.4598     89.310  0.0518    98.180  1276.15
  64   0.4576     89.160  0.0553    98.056  1296.38
  65   0.4898     88.830  0.0580    97.946  1316.60
  66   0.4747     88.560  0.0588    97.918  1336.85
  67   0.4306     89.910  0.0538    98.110  1357.07
  68   0.4530     89.210  0.0564    98.030  1377.30
  69   0.4425     89.880  0.0514    98.238  1397.51
  70   0.4221     89.840  0.0476    98.340  1417.72
  71   0.4682     89.230  0.0459    98.436  1437.94
  72   0.4704     89.420  0.0503    98.234  1458.13
  73   0.4459     89.880  0.0460    98.402  1478.39
  74   0.4669     89.340  0.0423    98.506  1498.60
  75   0.4348     90.080  0.0493    98.264  1518.81
  76   0.4270     89.620  0.0436    98.512  1539.03
  77   0.4584     88.930  0.0458    98.408  1559.23
  78   0.4533     89.260  0.0510    98.164  1579.48
  79   0.4380     89.920  0.0460    98.456  1599.72
  80   0.4311     89.750  0.0443    98.470  1619.95
  81   0.4284     89.960  0.0413    98.586  1640.17
  82   0.4648     89.740  0.0467    98.378  1660.41
  83   0.4455     89.750  0.0458    98.448  1680.65
  84   0.4551     90.120  0.0373    98.724  1700.83
  85   0.4822     89.260  0.0389    98.716  1721.10
  86   0.4696     89.550  0.0413    98.542  1741.36
  87   0.4551     89.600  0.0435    98.536  1761.60
  88   0.4340     90.000  0.0414    98.534  1781.83
  89   0.4577     89.630  0.0370    98.758  1802.06
  90   0.4400     90.160  0.0396    98.654  1822.27
