Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.2268     55.470  1.4856    45.374  22.16
   2   1.0166     64.260  1.0717    61.706  42.38
   3   0.9015     68.510  0.8657    69.084  62.57
   4   0.7688     73.300  0.7443    73.804  82.77
   5   0.6896     76.330  0.6460    77.342  103.00
   6   0.7001     76.320  0.5799    79.654  123.25
   7   0.7772     74.170  0.5266    81.562  143.44
   8   0.5822     80.000  0.4846    83.060  163.65
   9   0.5776     80.880  0.4432    84.400  183.85
  10   0.5483     81.340  0.4170    85.600  204.06
  11   0.4850     83.410  0.3912    86.292  224.25
  12   0.6118     79.900  0.3625    87.478  244.46
  13   0.5157     82.690  0.3435    88.092  264.68
  14   0.5516     81.680  0.3195    88.886  284.86
  15   0.4895     84.620  0.2999    89.646  305.09
  16   0.5322     83.850  0.2840    90.118  325.32
  17   0.4450     85.430  0.2736    90.500  345.53
  18   0.4434     86.040  0.2559    91.084  365.74
  19   0.4730     85.550  0.2403    91.568  385.99
  20   0.4745     84.810  0.2283    92.022  406.24
  21   0.4616     85.290  0.2217    92.258  426.48
  22   0.4212     86.530  0.2042    92.890  446.70
  23   0.4402     86.690  0.1902    93.434  466.89
  24   0.4241     86.850  0.1823    93.648  487.12
  25   0.4722     85.860  0.1805    93.622  507.33
  26   0.4835     86.120  0.1656    94.306  527.56
  27   0.5385     85.150  0.1655    94.268  547.75
  28   0.5015     85.530  0.1521    94.728  567.98
  29   0.4697     86.740  0.1450    94.792  588.16
  30   0.4602     86.320  0.1442    95.006  608.38
  31   0.4395     87.400  0.1313    95.312  628.63
  32   0.5051     86.660  0.1275    95.470  648.85
  33   0.4995     86.080  0.1201    95.778  669.07
  34   0.4270     87.870  0.1163    95.928  689.29
  35   0.4662     87.090  0.1112    96.090  709.50
  36   0.4128     88.550  0.1067    96.264  729.72
  37   0.4788     87.170  0.1049    96.316  749.95
  38   0.4551     87.400  0.1069    96.234  770.15
  39   0.4395     88.470  0.0964    96.572  790.37
  40   0.4537     88.530  0.0942    96.728  810.61
  41   0.4103     89.000  0.0982    96.586  830.83
  42   0.5205     86.890  0.0879    96.872  851.05
  43   0.5667     85.430  0.0813    97.126  871.24
  44   0.4636     87.750  0.0857    97.002  891.45
  45   0.4569     87.860  0.0842    97.084  911.71
  46   0.4979     88.000  0.0788    97.270  931.92
  47   0.4787     87.840  0.0791    97.298  952.15
  48   0.4685     88.660  0.0701    97.468  972.39
  49   0.4923     87.730  0.0690    97.624  992.61
  50   0.4774     88.280  0.0729    97.394  1012.80
  51   0.4734     88.520  0.0694    97.548  1033.00
  52   0.5115     87.710  0.0655    97.700  1053.25
  53   0.4233     89.710  0.0712    97.462  1073.45
  54   0.4704     88.610  0.0711    97.474  1093.66
  55   0.4590     88.670  0.0662    97.658  1113.86
  56   0.4791     88.670  0.0624    97.824  1134.07
  57   0.4477     89.440  0.0590    97.914  1154.30
  58   0.4910     88.620  0.0609    97.862  1174.50
  59   0.5415     88.190  0.0581    97.964  1194.75
  60   0.4757     88.390  0.0580    97.952  1214.97
  61   0.4435     88.860  0.0554    98.082  1235.20
  62   0.4301     89.280  0.0578    97.980  1255.40
  63   0.4494     89.270  0.0523    98.196  1275.61
  64   0.4981     88.490  0.0565    98.000  1295.81
  65   0.4654     88.870  0.0498    98.316  1316.03
  66   0.5143     88.720  0.0531    98.192  1336.23
  67   0.5380     87.960  0.0559    98.074  1356.41
  68   0.5056     88.430  0.0505    98.226  1376.60
  69   0.5097     88.400  0.0493    98.272  1396.82
  70   0.4908     89.260  0.0520    98.142  1417.01
  71   0.4328     89.730  0.0471    98.406  1437.26
  72   0.4555     89.430  0.0438    98.518  1457.49
  73   0.4780     89.090  0.0499    98.202  1477.68
  74   0.4683     89.480  0.0516    98.114  1497.87
  75   0.4697     89.330  0.0437    98.498  1518.08
  76   0.4906     89.190  0.0479    98.380  1538.34
  77   0.4841     88.930  0.0477    98.342  1558.52
  78   0.4689     89.410  0.0481    98.344  1578.77
  79   0.4944     89.050  0.0420    98.578  1598.98
  80   0.5035     88.810  0.0399    98.688  1619.23
  81   0.4991     89.320  0.0443    98.436  1639.44
  82   0.4660     89.580  0.0438    98.478  1659.62
  83   0.4681     89.360  0.0409    98.604  1679.84
  84   0.4421     89.950  0.0430    98.526  1700.02
  85   0.4795     89.270  0.0385    98.690  1720.24
