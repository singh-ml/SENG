Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '85', '--arch', 'resnet18', '--lr-decay-epoch', '85', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '1e-2', '--weight-decay', '2e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.8135     32.350  2.1326    22.688  22.16
   2   1.5687     42.980  1.6482    38.458  42.37
   3   1.2846     53.760  1.3429    50.882  62.68
   4   1.0939     60.160  1.1408    59.206  82.92
   5   1.0319     63.930  1.0105    63.834  103.12
   6   1.0552     64.030  0.9097    67.674  123.34
   7   1.0793     63.850  0.8346    70.430  143.59
   8   0.7713     72.860  0.7807    72.532  163.82
   9   0.7635     73.550  0.7188    74.818  184.01
  10   0.7214     74.990  0.6870    76.090  204.22
  11   0.7772     73.280  0.6553    77.144  224.45
  12   0.6942     76.410  0.6316    77.914  244.67
  13   0.6188     78.600  0.6133    78.656  264.92
  14   0.6174     78.260  0.5950    79.342  285.13
  15   0.6676     76.810  0.5893    79.600  305.35
  16   0.6376     77.530  0.5859    79.768  325.59
  17   0.6582     77.680  0.5683    80.342  345.78
  18   0.6659     77.240  0.5596    80.638  366.01
  19   0.5831     80.160  0.5660    80.348  386.18
  20   0.6312     78.710  0.5524    80.762  406.44
  21   0.6206     78.670  0.5452    81.122  426.71
  22   0.6378     78.580  0.5453    81.176  446.92
  23   0.6763     76.190  0.5409    81.200  467.18
  24   0.5836     80.270  0.5503    80.902  487.44
  25   0.6329     79.240  0.5347    81.478  507.64
  26   0.6103     79.070  0.5310    81.676  527.93
  27   0.6644     77.600  0.5261    81.896  548.21
  28   0.5708     80.370  0.5238    81.924  568.39
  29   0.6931     77.240  0.5203    82.048  588.61
  30   0.6393     78.350  0.5213    82.188  608.82
  31   0.5961     79.450  0.5200    81.962  629.01
  32   0.6224     78.750  0.5180    82.192  649.26
  33   0.6183     79.140  0.5194    82.130  669.49
  34   0.5709     80.280  0.5131    82.272  689.68
  35   0.6329     78.840  0.5032    82.510  709.87
  36   0.5778     80.390  0.5131    82.334  730.10
  37   0.6135     79.720  0.5076    82.306  750.29
  38   0.5943     80.010  0.5099    82.336  770.46
  39   0.6199     79.220  0.5082    82.398  790.68
  40   0.5900     80.410  0.5057    82.572  810.91
  41   0.6055     79.600  0.5031    82.722  831.12
  42   0.6402     78.340  0.5061    82.616  851.31
  43   0.6164     79.500  0.5080    82.334  871.55
  44   0.5756     80.080  0.5000    82.854  891.75
  45   0.6442     79.190  0.5039    82.456  911.96
  46   0.6444     78.010  0.5055    82.546  932.14
  47   0.6006     79.850  0.5001    82.570  952.35
  48   0.5884     80.240  0.5003    82.754  972.56
  49   0.5798     79.940  0.4948    82.842  992.82
  50   0.6432     78.560  0.4989    82.760  1013.03
  51   0.6098     79.370  0.4973    82.728  1033.26
  52   0.5872     80.090  0.4978    82.774  1053.47
  53   0.7737     75.740  0.4933    83.020  1073.68
  54   0.5917     80.040  0.4891    82.910  1093.88
  55   0.6283     79.220  0.4993    82.728  1114.10
  56   0.6554     78.530  0.4918    82.996  1134.36
  57   0.6389     78.510  0.4968    82.928  1154.55
  58   0.6286     79.170  0.4857    83.214  1174.81
  59   0.6750     77.470  0.4891    83.042  1195.06
  60   0.5648     80.640  0.4808    83.458  1215.26
  61   0.5852     80.480  0.4889    82.950  1235.47
  62   0.5234     82.230  0.4824    83.312  1255.70
  63   0.5493     81.640  0.4864    83.226  1275.89
  64   0.5356     82.460  0.4874    83.208  1296.10
  65   0.5741     80.650  0.4879    83.142  1316.48
  66   0.5818     79.540  0.4811    83.466  1336.73
  67   0.5687     80.790  0.4857    83.258  1356.97
  68   0.5697     80.950  0.4834    83.280  1377.19
  69   0.5510     81.520  0.4820    83.380  1397.42
  70   0.5530     80.780  0.4843    83.184  1417.61
  71   0.6009     80.380  0.4768    83.586  1437.85
  72   0.5808     80.800  0.4825    83.264  1458.08
  73   0.5722     80.910  0.4762    83.468  1478.28
  74   0.5211     82.220  0.4754    83.708  1498.53
  75   0.5252     81.770  0.4753    83.636  1518.74
  76   0.5675     80.960  0.4770    83.640  1538.92
  77   0.5754     80.840  0.4810    83.422  1559.17
  78   0.5565     80.750  0.4768    83.522  1579.38
  79   0.5758     80.350  0.4739    83.400  1599.59
  80   0.5286     82.090  0.4774    83.588  1619.81
  81   0.5678     80.880  0.4807    83.360  1640.05
  82   0.5519     81.460  0.4769    83.400  1660.25
  83   0.6619     77.990  0.4739    83.684  1680.49
  84   0.7094     77.050  0.4787    83.508  1700.69
  85   0.6316     78.920  0.4795    83.560  1720.92
