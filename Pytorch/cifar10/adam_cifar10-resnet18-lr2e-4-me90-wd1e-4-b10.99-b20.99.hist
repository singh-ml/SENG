Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '2e-4', '--weight-decay', '1e-4', '--beta1', '0.99', '--beta2', '0.99', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.3344     50.370  1.5541    42.260  22.17
   2   1.0798     60.680  1.1936    56.708  42.39
   3   0.9564     65.900  0.9807    64.936  62.57
   4   0.8312     71.330  0.8350    70.302  82.77
   5   0.7194     75.070  0.7242    74.338  102.99
   6   0.6739     76.730  0.6425    77.352  123.20
   7   0.6222     78.760  0.5748    79.726  143.40
   8   0.5993     79.810  0.5280    81.640  163.62
   9   0.6085     79.870  0.4918    82.776  183.90
  10   0.5332     82.150  0.4572    83.990  204.15
  11   0.5225     82.170  0.4230    85.288  224.39
  12   0.4905     83.430  0.3910    86.358  244.61
  13   0.5170     82.750  0.3667    87.236  264.84
  14   0.4812     83.850  0.3489    87.676  285.04
  15   0.4607     84.730  0.3243    88.518  305.25
  16   0.4384     86.160  0.2977    89.616  325.47
  17   0.4665     84.780  0.2895    89.886  345.71
  18   0.4620     85.130  0.2696    90.602  365.91
  19   0.4773     85.170  0.2608    90.926  386.11
  20   0.4262     86.280  0.2374    91.790  406.31
  21   0.4405     86.070  0.2295    92.004  426.52
  22   0.4194     86.840  0.2221    92.234  446.71
  23   0.4003     87.540  0.2129    92.652  466.92
  24   0.4109     87.330  0.1892    93.458  487.13
  25   0.4372     87.150  0.1808    93.670  507.38
  26   0.4367     86.870  0.1793    93.552  527.59
  27   0.4196     87.600  0.1783    93.766  547.81
  28   0.4133     87.810  0.1571    94.432  568.05
  29   0.4362     87.620  0.1501    94.796  588.28
  30   0.4298     87.860  0.1425    94.868  608.50
  31   0.4684     87.480  0.1359    95.172  628.67
  32   0.3870     88.850  0.1290    95.404  648.88
  33   0.4119     88.500  0.1263    95.494  669.10
  34   0.4081     88.420  0.1170    95.894  689.29
  35   0.4370     88.160  0.1140    95.990  709.50
  36   0.4120     88.890  0.1160    95.888  729.72
  37   0.3973     88.940  0.1101    96.038  749.92
  38   0.4549     88.030  0.1021    96.394  770.11
  39   0.4262     88.770  0.1030    96.274  790.33
  40   0.4092     89.040  0.1008    96.516  810.53
  41   0.4306     88.680  0.0961    96.624  830.77
  42   0.4600     88.440  0.0932    96.718  851.04
  43   0.4050     89.180  0.0921    96.790  871.28
  44   0.4679     88.500  0.0856    97.026  891.50
  45   0.4530     88.410  0.0835    97.044  911.71
  46   0.4485     88.400  0.0772    97.286  931.91
  47   0.4450     88.940  0.0779    97.228  952.15
  48   0.4342     89.150  0.0805    97.174  972.34
  49   0.4279     89.450  0.0716    97.500  992.52
  50   0.4227     89.670  0.0779    97.254  1012.72
  51   0.4534     88.870  0.0743    97.374  1032.97
  52   0.4229     89.040  0.0728    97.442  1053.16
  53   0.4599     88.890  0.0659    97.680  1073.34
  54   0.4624     89.240  0.0685    97.654  1093.54
  55   0.4371     89.130  0.0695    97.584  1113.74
  56   0.4552     88.930  0.0632    97.826  1133.92
  57   0.4828     89.220  0.0635    97.776  1154.10
  58   0.4466     89.250  0.0637    97.760  1174.29
  59   0.4050     90.390  0.0608    97.860  1194.48
  60   0.4026     90.330  0.0555    98.064  1214.68
  61   0.4344     90.010  0.0572    98.002  1234.89
  62   0.4417     89.580  0.0554    98.086  1255.07
  63   0.4376     89.340  0.0603    97.940  1275.27
  64   0.4210     89.750  0.0549    98.134  1295.48
  65   0.4187     89.670  0.0542    98.136  1315.70
  66   0.4399     89.360  0.0552    98.086  1335.90
  67   0.4375     89.510  0.0534    98.188  1356.11
  68   0.4590     89.690  0.0513    98.188  1376.34
  69   0.4234     89.880  0.0496    98.258  1396.53
  70   0.4429     89.840  0.0527    98.156  1416.78
  71   0.4349     89.880  0.0484    98.338  1436.97
  72   0.4539     89.660  0.0512    98.248  1457.20
  73   0.4285     89.860  0.0456    98.406  1477.41
  74   0.4220     90.470  0.0425    98.534  1497.62
  75   0.4756     89.850  0.0434    98.534  1517.87
  76   0.5483     88.220  0.0488    98.238  1538.07
  77   0.4072     90.860  0.0437    98.502  1558.27
  78   0.4640     89.550  0.0428    98.550  1578.47
  79   0.4358     89.940  0.0450    98.450  1598.70
  80   0.4611     90.090  0.0451    98.448  1618.92
  81   0.4382     89.960  0.0475    98.332  1639.13
  82   0.3982     90.830  0.0448    98.502  1659.31
  83   0.4496     90.300  0.0371    98.722  1679.52
  84   0.4550     90.060  0.0440    98.448  1699.72
  85   0.4269     90.310  0.0432    98.584  1719.96
  86   0.4372     90.360  0.0395    98.694  1740.16
  87   0.4462     90.080  0.0375    98.690  1760.37
  88   0.4186     90.210  0.0396    98.690  1780.54
  89   0.4606     89.970  0.0385    98.646  1800.76
  90   0.4809     89.420  0.0422    98.550  1820.97
