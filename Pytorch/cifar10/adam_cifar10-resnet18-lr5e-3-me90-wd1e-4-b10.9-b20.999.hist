Use GPU: 1 for training
==> Running with ['main_adam.py', '--epoch', '90', '--arch', 'resnet18', '--lr-decay-epoch', '90', '--trainset', 'cifar10', '--datadir', '/data/singh/data/', '--lr', '5e-3', '--weight-decay', '1e-4', '--beta1', '0.9', '--beta2', '0.999', '--gpu', '1']
==> Building model..
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Memory peak: 4192502784 Bytes
Epoch  testloss  testacc  trainloss  trainacc  time
   1   1.4844     45.490  1.7379    35.978  21.96
   2   1.6450     47.250  1.2916    52.742  42.20
   3   1.0030     65.570  1.0473    62.342  62.38
   4   0.9686     65.190  0.9075    67.676  82.65
   5   1.0038     66.330  0.7943    72.106  102.88
   6   0.7711     73.200  0.6901    76.068  123.20
   7   0.7082     75.560  0.6329    78.034  143.44
   8   0.7021     76.840  0.5820    79.856  163.71
   9   0.8596     72.390  0.5385    81.332  183.99
  10   0.9601     70.550  0.5131    82.396  204.19
  11   0.9445     71.610  0.4875    83.264  224.46
  12   0.6127     80.180  0.4717    83.764  244.71
  13   0.6159     79.440  0.4572    84.276  265.00
  14   0.5899     79.800  0.4386    84.898  285.24
  15   0.7676     75.830  0.4301    85.290  305.47
  16   0.6739     78.340  0.4250    85.484  325.73
  17   0.5688     81.380  0.4147    85.720  345.98
  18   0.5343     82.400  0.4036    86.172  366.28
  19   0.5616     81.540  0.3969    86.416  386.55
  20   0.4865     84.420  0.3865    86.660  406.81
  21   0.5091     83.510  0.3786    86.972  427.05
  22   0.5205     82.240  0.3815    86.830  447.32
  23   0.5813     81.250  0.3634    87.524  467.58
  24   0.4344     85.100  0.3636    87.630  487.81
  25   0.5173     82.710  0.3630    87.538  508.07
  26   0.4406     84.900  0.3615    87.568  528.33
  27   0.5565     81.840  0.3473    88.052  548.60
  28   0.4654     84.600  0.3506    87.862  568.87
  29   0.4625     84.980  0.3474    87.960  589.18
  30   0.5478     82.710  0.3440    88.130  609.47
  31   0.3978     86.240  0.3409    88.214  629.71
  32   0.5135     83.230  0.3366    88.412  650.06
  33   0.4317     85.890  0.3372    88.436  670.34
  34   0.4230     85.570  0.3293    88.692  690.60
  35   0.4613     84.820  0.3284    88.676  710.89
  36   0.4165     86.410  0.3222    88.914  731.14
  37   0.4636     84.570  0.3245    88.662  751.38
  38   0.4278     85.730  0.3148    88.986  771.68
  39   0.4787     84.510  0.3127    89.132  791.93
  40   0.5250     83.610  0.3196    88.922  812.22
  41   0.4148     86.170  0.3138    89.186  832.47
  42   0.4228     85.910  0.3117    89.256  852.73
  43   0.4345     85.430  0.3148    89.112  873.02
  44   0.4122     86.790  0.3136    89.212  893.34
  45   0.4834     84.360  0.3108    89.266  913.54
  46   0.5442     83.060  0.3014    89.710  933.81
  47   0.4303     85.970  0.3038    89.470  954.11
  48   2.7923     48.710  0.3030    89.590  974.39
  49   0.4795     84.960  0.3024    89.562  994.67
  50   0.4620     84.400  0.2976    89.688  1014.91
  51   0.4630     85.200  0.2974    89.762  1035.14
  52   0.4935     83.750  0.3005    89.584  1055.47
  53   0.4328     86.310  0.2959    89.770  1075.72
  54   0.3988     86.410  0.2983    89.728  1095.97
  55   0.4391     86.360  0.2942    89.742  1116.27
  56   0.4921     84.470  0.3006    89.628  1136.56
  57   0.4556     85.420  0.2931    89.764  1156.87
  58   0.4404     85.770  0.2951    89.690  1177.13
  59   0.4683     85.560  0.2936    89.782  1197.40
  60   0.4325     86.340  0.2894    89.930  1217.67
  61   0.6340     81.220  0.2919    89.912  1237.94
  62   0.4190     86.140  0.2937    89.898  1258.21
  63   0.4216     86.980  0.2900    89.970  1278.49
  64   0.4729     84.690  0.2802    90.250  1298.74
  65   0.4289     85.880  0.2890    90.134  1319.01
  66   0.4591     85.370  0.2888    89.988  1339.31
  67   0.5245     83.450  0.2804    90.272  1359.55
  68   0.5401     82.900  0.2871    90.110  1379.85
  69   0.4680     85.380  0.2814    90.216  1400.13
  70   0.4920     85.130  0.2828    90.202  1420.35
  71   0.4042     86.940  0.2878    90.008  1440.62
  72   0.4294     86.100  0.2798    90.466  1460.94
  73   0.4316     86.280  0.2840    90.094  1481.19
  74   0.4065     86.930  0.2817    90.222  1501.49
  75   0.3947     87.360  0.2830    90.264  1521.76
  76   0.4982     85.210  0.2859    90.058  1542.06
  77   0.6116     81.350  0.2787    90.232  1562.29
  78   0.4521     85.870  0.2749    90.550  1582.57
  79   0.4019     86.970  0.2817    90.140  1602.86
  80   0.4006     86.610  0.2755    90.530  1623.16
  81   0.4102     86.500  0.2733    90.594  1643.38
  82   0.5242     84.270  0.2712    90.664  1663.64
  83   0.5464     83.640  0.2750    90.568  1683.90
  84   0.4076     86.590  0.2727    90.592  1704.21
  85   0.5039     84.400  0.2785    90.420  1724.52
  86   0.4779     84.900  0.2707    90.574  1744.83
  87   0.4730     85.020  0.2744    90.600  1765.10
  88   0.4849     84.760  0.2680    90.728  1785.33
  89   0.5323     83.880  0.2759    90.606  1805.64
  90   0.8860     77.350  0.2732    90.538  1825.88
